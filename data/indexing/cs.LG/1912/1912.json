[{"id": "1912.00003", "submitter": "David Zimmerer", "authors": "David Zimmerer, Jens Petersen, Simon A. A. Kohl and Klaus H.\n  Maier-Hein", "title": "A Case for the Score: Identifying Image Anomalies using Variational\n  Autoencoder Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through training on unlabeled data, anomaly detection has the potential to\nimpact computer-aided diagnosis by outlining suspicious regions. Previous work\non deep-learning-based anomaly detection has primarily focused on the\nreconstruction error. We argue instead, that pixel-wise anomaly ratings derived\nfrom a Variational Autoencoder based score approximation yield a theoretically\nbetter grounded and more faithful estimate. In our experiments, Variational\nAutoencoder gradient-based rating outperforms other approaches on unsupervised\npixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 09:40:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zimmerer", "David", ""], ["Petersen", "Jens", ""], ["Kohl", "Simon A. A.", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "1912.00009", "submitter": "Shiyuan Li", "authors": "Shiyuan Li", "title": "MSTDP: A More Biologically Plausible Learning", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 05:42:50 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 02:33:20 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Shiyuan", ""]]}, {"id": "1912.00015", "submitter": "Simone Rossi", "authors": "Simone Rossi and Sebastien Marmin and Maurizio Filippone", "title": "Efficient Approximate Inference with Walsh-Hadamard Variational\n  Inference", "comments": "Paper accepted at the 4th Workshop on Bayesian Deep Learning (NeurIPS\n  2019), Vancouver, Canada. arXiv admin note: substantial text overlap with\n  arXiv:1905.11248", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference offers scalable and flexible tools to tackle\nintractable Bayesian inference of modern statistical models like Bayesian\nneural networks and Gaussian processes. For largely over-parameterized models,\nhowever, the over-regularization property of the variational objective makes\nthe application of variational inference challenging. Inspired by the\nliterature on kernel methods, and in particular on structured approximations of\ndistributions of random matrices, this paper proposes Walsh-Hadamard\nVariational Inference, which uses Walsh-Hadamard-based factorization strategies\nto reduce model parameterization, accelerate computations, and increase the\nexpressiveness of the approximate posterior beyond fully factorized ones.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:22:08 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Rossi", "Simone", ""], ["Marmin", "Sebastien", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1912.00018", "submitter": "Umut \\c{S}im\\c{s}ekli", "authors": "Umut \\c{S}im\\c{s}ekli, Mert G\\\"urb\\\"uzbalaban, Thanh Huy Nguyen,\n  Ga\\\"el Richard, Levent Sagun", "title": "On the Heavy-Tailed Theory of Stochastic Gradient Descent for Deep\n  Neural Networks", "comments": "32 pages. arXiv admin note: substantial text overlap with\n  arXiv:1901.06053", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient noise (GN) in the stochastic gradient descent (SGD) algorithm is\noften considered to be Gaussian in the large data regime by assuming that the\n\\emph{classical} central limit theorem (CLT) kicks in. This assumption is often\nmade for mathematical convenience, since it enables SGD to be analyzed as a\nstochastic differential equation (SDE) driven by a Brownian motion. We argue\nthat the Gaussianity assumption might fail to hold in deep learning settings\nand hence render the Brownian motion-based analyses inappropriate. Inspired by\nnon-Gaussian natural phenomena, we consider the GN in a more general context\nand invoke the \\emph{generalized} CLT, which suggests that the GN converges to\na \\emph{heavy-tailed} $\\alpha$-stable random vector, where \\emph{tail-index}\n$\\alpha$ determines the heavy-tailedness of the distribution. Accordingly, we\npropose to analyze SGD as a discretization of an SDE driven by a L\\'{e}vy\nmotion. Such SDEs can incur `jumps', which force the SDE and its discretization\n\\emph{transition} from narrow minima to wider minima, as proven by existing\nmetastability theory and the extensions that we proved recently. In this study,\nunder the $\\alpha$-stable GN assumption, we further establish an explicit\nconnection between the convergence rate of SGD to a local minimum and the\ntail-index $\\alpha$. To validate the $\\alpha$-stable assumption, we conduct\nexperiments on common deep learning scenarios and show that in all settings,\nthe GN is highly non-Gaussian and admits heavy-tails. We investigate the tail\nbehavior in varying network architectures and sizes, loss functions, and\ndatasets. Our results open up a different perspective and shed more light on\nthe belief that SGD prefers wide minima.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:56:02 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["\u015eim\u015fekli", "Umut", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""], ["Nguyen", "Thanh Huy", ""], ["Richard", "Ga\u00ebl", ""], ["Sagun", "Levent", ""]]}, {"id": "1912.00019", "submitter": "Deniz Ekiz", "authors": "Deniz Ekiz, Yekta Said Can, Cem Ersoy", "title": "Long Short-Term Network Based Unobtrusive Perceived Workload Monitoring\n  with Consumer Grade Smartwatches in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous high perceived workload has a negative impact on the individual's\nwell-being. Prior works focused on detecting the workload with medical-grade\nwearable systems in the restricted settings, and the effect of applying deep\nlearning techniques for perceived workload detection in the wild settings is\nnot investigated. We present an unobtrusive, comfortable, pervasive and\naffordable Long Short-Term Memory Network based continuous workload monitoring\nsystem based on a smartwatch application that monitors the perceived workload\nof individuals in the wild. We make use of modern consumer-grade smartwatches.\nWe have recorded physiological data from daily life with perceived workload\nquestionnaires from subjects in their real-life environments over a month. The\nmodel was trained and evaluated with the daily-life physiological data coming\nfrom different days which makes it robust to daily changes in the heart rate\nvariability, that we use with accelerometer features to asses low and high\nworkload. Our system has the capability of removing motion-related artifacts\nand detecting perceived workload by using traditional and deep classifiers. We\ndiscussed the problems related to in the wild applications with the\nconsumer-grade smartwatches. We showed that Long Short-Term Memory Network\noutperforms traditional classifiers on discrimination of low and high workload\nwith smartwatches in the wild.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 11:11:24 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ekiz", "Deniz", ""], ["Can", "Yekta Said", ""], ["Ersoy", "Cem", ""]]}, {"id": "1912.00020", "submitter": "Tinghao Zhang", "authors": "Tinghao Zhang, Jingxu Li, Jingfeng Li, Ling Wang, Feng Li, Jie Liu", "title": "Model Embedded DRL for Intelligent Greenhouse Control", "comments": "Submitted to AAAI-20 Workshop on Artificial Intelligence of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greenhouse environment is the key to influence crops production. However, it\nis difficult for classical control methods to give precise environment\nsetpoints, such as temperature, humidity, light intensity and carbon dioxide\nconcentration for greenhouse because it is uncertain nonlinear system.\nTherefore, an intelligent close loop control framework based on model embedded\ndeep reinforcement learning (MEDRL) is designed for greenhouse environment\ncontrol. Specifically, computer vision algorithms are used to recognize growing\nperiods and sex of crops, followed by the crop growth models, which can be\ntrained with different growing periods and sex. These model outputs combined\nwith the cost factor provide the setpoints for greenhouse and feedback to the\ncontrol system in real-time. The whole MEDRL system has capability to conduct\noptimization control precisely and conveniently, and costs will be greatly\nreduced compared with traditional greenhouse control approaches.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:25:19 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Tinghao", ""], ["Li", "Jingxu", ""], ["Li", "Jingfeng", ""], ["Wang", "Ling", ""], ["Li", "Feng", ""], ["Liu", "Jie", ""]]}, {"id": "1912.00042", "submitter": "Christina Winkler", "authors": "Christina Winkler, Daniel Worrall, Emiel Hoogeboom, Max Welling", "title": "Learning Likelihoods with Conditional Normalizing Flows", "comments": "18 pages, 8 Tables, 9 Figures, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows (NFs) are able to model complicated distributions p(y) with\nstrong inter-dimensional correlations and high multimodality by transforming a\nsimple base density p(z) through an invertible neural network under the change\nof variables formula. Such behavior is desirable in multivariate structured\nprediction tasks, where handcrafted per-pixel loss-based methods inadequately\ncapture strong correlations between output dimensions. We present a study of\nconditional normalizing flows (CNFs), a class of NFs where the base density to\noutput space mapping is conditioned on an input x, to model conditional\ndensities p(y|x). CNFs are efficient in sampling and inference, they can be\ntrained with a likelihood-based objective, and CNFs, being generative flows, do\nnot suffer from mode collapse or training instabilities. We provide an\neffective method to train continuous CNFs for binary problems and in\nparticular, we apply these CNFs to super-resolution and vessel segmentation\ntasks demonstrating competitive performance on standard benchmark datasets in\nterms of likelihood and conventional metrics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:17:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Winkler", "Christina", ""], ["Worrall", "Daniel", ""], ["Hoogeboom", "Emiel", ""], ["Welling", "Max", ""]]}, {"id": "1912.00043", "submitter": "Serguei Barannikov", "authors": "Serguei Barannikov, Alexander Korotin, Dmitry Oganesyan, Daniil\n  Emtsev, Evgeny Burnaev", "title": "Barcodes as summary of objective function's topology", "comments": "19 pages, description of experiments for calculating barcodes of\n  local minima for benchmark functions is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply the canonical forms (barcodes) of gradient Morse complexes to\nexplore topology of loss surfaces. We present a novel algorithm for\ncalculations of the objective function's barcodes of local minima. We have\nconducted experiments for calculating barcodes of local minima for benchmark\nfunctions and for loss surfaces of neural networks. Our experiments confirm two\nprincipal observations for loss surfaces of neural networks. First, the\nbarcodes of local minima are located in a small lower part of the range of\nvalues of loss function of neural networks. Second, increase of the neural\nnetwork's depth brings down the barcodes of local minima. This has natural\nimplications for the neural network learning and the generalization ability.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:22:36 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 19:02:35 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Barannikov", "Serguei", ""], ["Korotin", "Alexander", ""], ["Oganesyan", "Dmitry", ""], ["Emtsev", "Daniil", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1912.00049", "submitter": "Maksym Andriushchenko", "authors": "Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, Matthias\n  Hein", "title": "Square Attack: a query-efficient black-box adversarial attack via random\n  search", "comments": "Accepted at ECCV 2020; added imperceptible perturbations, analysis of\n  examples that require more queries, results on dilated CNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Square Attack, a score-based black-box $l_2$- and\n$l_\\infty$-adversarial attack that does not rely on local gradient information\nand thus is not affected by gradient masking. Square Attack is based on a\nrandomized search scheme which selects localized square-shaped updates at\nrandom positions so that at each iteration the perturbation is situated\napproximately at the boundary of the feasible set. Our method is significantly\nmore query efficient and achieves a higher success rate compared to the\nstate-of-the-art methods, especially in the untargeted setting. In particular,\non ImageNet we improve the average query efficiency in the untargeted setting\nfor various deep networks by a factor of at least $1.8$ and up to $3$ compared\nto the recent state-of-the-art $l_\\infty$-attack of Al-Dujaili & O'Reilly.\nMoreover, although our attack is black-box, it can also outperform\ngradient-based white-box attacks on the standard benchmarks achieving a new\nstate-of-the-art in terms of the success rate. The code of our attack is\navailable at https://github.com/max-andr/square-attack.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:29:32 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 22:30:48 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 07:53:10 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Andriushchenko", "Maksym", ""], ["Croce", "Francesco", ""], ["Flammarion", "Nicolas", ""], ["Hein", "Matthias", ""]]}, {"id": "1912.00058", "submitter": "Linara Adilova", "authors": "Henning Petzka, Linara Adilova, Michael Kamp, Cristian Sminchisescu", "title": "A Reparameterization-Invariant Flatness Measure for Deep Neural Networks", "comments": "14 pages; accepted at Workshop \"Science meets Engineering of Deep\n  Learning\", 33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks is often attributed to their\nautomated, task-related feature construction. It remains an open question,\nthough, why this leads to solutions with good generalization, even in cases\nwhere the number of parameters is larger than the number of samples. Back in\nthe 90s, Hochreiter and Schmidhuber observed that flatness of the loss surface\naround a local minimum correlates with low generalization error. For several\nflatness measures, this correlation has been empirically validated. However, it\nhas recently been shown that existing measures of flatness cannot theoretically\nbe related to generalization due to a lack of invariance with respect to\nreparameterizations. We propose a natural modification of existing flatness\nmeasures that results in invariance to reparameterization.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 20:05:35 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Petzka", "Henning", ""], ["Adilova", "Linara", ""], ["Kamp", "Michael", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "1912.00071", "submitter": "Kyriakos Polymenakos", "authors": "Kyriakos Polymenakos, Luca Laurenti, Andrea Patane, Jan-Peter\n  Calliess, Luca Cardelli, Marta Kwiatkowska, Alessandro Abate, Stephen Roberts", "title": "Safety Guarantees for Planning Based on Iterative Gaussian Processes", "comments": "An earlier version of this work presented in NeurIPS-2019 Workshop on\n  Safety and Robustness in Decision Making. A shorter (but otherwise\n  equivalent) paper was accepted to the 59th Conference on Decision and Control\n  (CDC2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are widely employed in control and learning because\nof their principled treatment of uncertainty. However, tracking uncertainty for\niterative, multi-step predictions in general leads to an analytically\nintractable problem. While approximation methods exist, they do not come with\nguarantees, making it difficult to estimate their reliability and to trust\ntheir predictions. In this work, we derive formal probability error bounds for\niterative prediction and planning with GPs. Building on GP properties, we bound\nthe probability that random trajectories lie in specific regions around the\npredicted values. Namely, given a tolerance $\\epsilon > 0 $, we compute regions\naround the predicted trajectory values, such that GP trajectories are\nguaranteed to lie inside them with probability at least $1-\\epsilon$. We verify\nexperimentally that our method tracks the predictive uncertainty correctly,\neven when current approximation techniques fail. Furthermore, we show how the\nproposed bounds can be employed within a safe reinforcement learning framework\nto verify the safety of candidate control policies, guiding the synthesis of\nprovably safe controllers.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 21:13:05 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 19:01:42 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 08:33:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Polymenakos", "Kyriakos", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Calliess", "Jan-Peter", ""], ["Cardelli", "Luca", ""], ["Kwiatkowska", "Marta", ""], ["Abate", "Alessandro", ""], ["Roberts", "Stephen", ""]]}, {"id": "1912.00074", "submitter": "Pin Wang", "authors": "Pin Wang, Hanhan Li, Ching-Yao Chan", "title": "Quadratic Q-network for Learning Continuous Control for Autonomous\n  Vehicles", "comments": "Machine Learning for Autonomous Driving Workshop on NeurIPS, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning algorithms have recently been proposed to learn\ntime-sequential control policies in the field of autonomous driving. Direct\napplications of Reinforcement Learning algorithms with discrete action space\nwill yield unsatisfactory results at the operational level of driving where\ncontinuous control actions are actually required. In addition, the design of\nneural networks often fails to incorporate the domain knowledge of the\ntargeting problem such as the classical control theories in our case. In this\npaper, we propose a hybrid model by combining Q-learning and classic PID\n(Proportion Integration Differentiation) controller for handling continuous\nvehicle control problems under dynamic driving environment. Particularly,\ninstead of using a big neural network as Q-function approximation, we design a\nQuadratic Q-function over actions with multiple simple neural networks for\nfinding optimal values within a continuous space. We also build an action\nnetwork based on the domain knowledge of the control mechanism of a PID\ncontroller to guide the agent to explore optimal actions more efficiently.We\ntest our proposed approach in simulation under two common but challenging\ndriving situations, the lane change scenario and ramp merge scenario. Results\nshow that the autonomous vehicle agent can successfully learn a smooth and\nefficient driving behavior in both situations.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 21:32:32 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Pin", ""], ["Li", "Hanhan", ""], ["Chan", "Ching-Yao", ""]]}, {"id": "1912.00079", "submitter": "Eli (Omid) David", "authors": "Itay Mosafi, Eli David, Nathan S. Netanyahu", "title": "DeepMimic: Mentor-Student Unlabeled Data Based Training", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 11731, pp. 440-455, Munich, Germany, September 2019", "doi": "10.1007/978-3-030-30493-5_44", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep neural network (DNN) training approach\ncalled the \"DeepMimic\" training method. Enormous amounts of data are available\nnowadays for training usage. Yet, only a tiny portion of these data is manually\nlabeled, whereas almost all of the data are unlabeled. The training approach\npresented utilizes, in a most simplified manner, the unlabeled data to the\nfullest, in order to achieve remarkable (classification) results. Our DeepMimic\nmethod uses a small portion of labeled data and a large amount of unlabeled\ndata for the training process, as expected in a real-world scenario. It\nconsists of a mentor model and a student model. Employing a mentor model\ntrained on a small portion of the labeled data and then feeding it only with\nunlabeled data, we show how to obtain a (simplified) student model that reaches\nthe same accuracy and loss as the mentor model, on the same test set, without\nusing any of the original data labels in the training of the student model. Our\nexperiments demonstrate that even on challenging classification tasks the\nstudent network architecture can be simplified significantly with a minor\ninfluence on the performance, i.e., we need not even know the original network\narchitecture of the mentor. In addition, the time required for training the\nstudent model to reach the mentor's performance level is shorter, as a result\nof a simplified architecture and more available data. The proposed method\nhighlights the disadvantages of regular supervised training and demonstrates\nthe benefits of a less traditional training approach.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 02:31:36 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Mosafi", "Itay", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.00086", "submitter": "Chi Zhang", "authors": "Chi Zhang, Baoxiong Jia, Feng Gao, Yixin Zhu, Hongjing Lu, Song-Chun\n  Zhu", "title": "Learning Perceptual Inference by Contrasting", "comments": "NeurIPS 2019 spotlight. Project page:\n  http://wellyzhang.github.io/project/copinet.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Thinking in pictures,\" [1] i.e., spatial-temporal reasoning, effortless and\ninstantaneous for humans, is believed to be a significant ability to perform\nlogical induction and a crucial factor in the intellectual history of\ntechnology development. Modern Artificial Intelligence (AI), fueled by massive\ndatasets, deeper models, and mighty computation, has come to a stage where\n(super-)human-level performances are observed in certain specific tasks.\nHowever, current AI's ability in \"thinking in pictures\" is still far lacking\nbehind. In this work, we study how to improve machines' reasoning ability on\none challenging task of this kind: Raven's Progressive Matrices (RPM).\nSpecifically, we borrow the very idea of \"contrast effects\" from the field of\npsychology, cognition, and education to design and train a\npermutation-invariant model. Inspired by cognitive studies, we equip our model\nwith a simple inference module that is jointly trained with the perception\nbackbone. Combining all the elements, we propose the Contrastive Perceptual\nInference network (CoPINet) and empirically demonstrate that CoPINet sets the\nnew state-of-the-art for permutation-invariant models on two major datasets. We\nconclude that spatial-temporal reasoning depends on envisaging the\npossibilities consistent with the relations between objects and can be solved\nfrom pixel-level inputs.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 23:02:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Chi", ""], ["Jia", "Baoxiong", ""], ["Gao", "Feng", ""], ["Zhu", "Yixin", ""], ["Lu", "Hongjing", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1912.00106", "submitter": "Siming Ma", "authors": "Siming Ma, David Brooks, Gu-Yeon Wei", "title": "A binary-activation, multi-level weight RNN and training algorithm for\n  ADC-/DAC-free and noise-resilient processing-in-memory inference with eNVM", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for training neural networks with binary\nactivations and multi-level weights, which enables efficient\nprocessing-in-memory circuits with embedded nonvolatile memories (eNVM). Binary\nactivations obviate costly DACs and ADCs. Multi-level weights leverage\nmulti-level eNVM cells. Compared to existing algorithms, our method not only\nworks for feed-forward networks (e.g., fully-connected and convolutional), but\nalso achieves higher accuracy and noise resilience for recurrent networks. In\nparticular, we present an RNN-based trigger-word detection PIM accelerator,\nwith detailed hardware noise models and circuit co-design techniques, and\nvalidate our algorithm's high inference accuracy and robustness against a\nvariety of real hardware non-idealities.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:25:51 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 13:26:56 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:23:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ma", "Siming", ""], ["Brooks", "David", ""], ["Wei", "Gu-Yeon", ""]]}, {"id": "1912.00108", "submitter": "Raouf Dridi Dr", "authors": "Raouf Dridi, Hedayat Alghassi, Maen Obeidat, Sridhar Tayur", "title": "The Topology of Mutated Driver Pathways", "comments": "Key words: topological data analysis, cancer genomics, mutation data,\n  acute myeloid leukemia, glioblastoma multiforme, persistent homology,\n  simplicial complex, Betti numbers, algebraic topology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much progress has been made, and continues to be made, towards identifying\ncandidate mutated driver pathways in cancer. However, no systematic approach to\nunderstanding how candidate pathways relate to each other for a given cancer\n(such as Acute myeloid leukemia), and how one type of cancer may be similar or\ndifferent from another with regard to their respective pathways (Acute myeloid\nleukemia vs. Glioblastoma multiforme for instance), has emerged thus far. Our\nwork attempts to contribute to the understanding of {\\em space of pathways}\nthrough a novel topological framework. We illustrate our approach, using\nmutation data (obtained from TCGA) of two types of tumors: Acute myeloid\nleukemia (AML) and Glioblastoma multiforme (GBM). We find that the space of\npathways for AML is homotopy equivalent to a sphere, while that of GBM is\nequivalent to a genus-2 surface. We hope to trigger new types of questions\n(i.e., allow for novel kinds of hypotheses) towards a more comprehensive grasp\nof cancer.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:27:29 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Dridi", "Raouf", ""], ["Alghassi", "Hedayat", ""], ["Obeidat", "Maen", ""], ["Tayur", "Sridhar", ""]]}, {"id": "1912.00120", "submitter": "Shunshi Zhang", "authors": "Matthew Shunshi Zhang and Bradly Stadie", "title": "One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the sparse neural network literature have made it possible\nto prune many large feed forward and convolutional networks with only a small\nquantity of data. Yet, these same techniques often falter when applied to the\nproblem of recovering sparse recurrent networks. These failures are\nquantitative: when pruned with recent techniques, RNNs typically obtain worse\nperformance than they do under a simple random pruning scheme. The failures are\nalso qualitative: the distribution of active weights in a pruned LSTM or GRU\nnetwork tend to be concentrated in specific neurons and gates, and not well\ndispersed across the entire architecture. We seek to rectify both the\nquantitative and qualitative issues with recurrent network pruning by\nintroducing a new recurrent pruning objective derived from the spectrum of the\nrecurrent Jacobian. Our objective is data efficient (requiring only 64 data\npoints to prune the network), easy to implement, and produces 95% sparse GRUs\nthat significantly improve on existing baselines. We evaluate on sequential\nMNIST, Billion Words, and Wikitext.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 03:22:00 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Matthew Shunshi", ""], ["Stadie", "Bradly", ""]]}, {"id": "1912.00124", "submitter": "Jihyeon Lee", "authors": "Jihyeon Lee, Sho Arora", "title": "A Free Lunch in Generating Datasets: Building a VQG and VQA System with\n  Attention and Humans in the Loop", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their importance in training artificial intelligence systems, large\ndatasets remain challenging to acquire. For example, the ImageNet dataset\nrequired fourteen million labels of basic human knowledge, such as whether an\nimage contains a chair. Unfortunately, this knowledge is so simple that it is\ntedious for human annotators but also tacit enough such that they are\nnecessary. However, human collaborative efforts for tasks like labeling massive\namounts of data are costly, inconsistent, and prone to failure, and this method\ndoes not resolve the issue of the resulting dataset being static in nature.\nWhat if we asked people questions they want to answer and collected their\nresponses as data? This would mean we could gather data at a much lower cost,\nand expanding a dataset would simply become a matter of asking more questions.\nWe focus on the task of Visual Question Answering (VQA) and propose a system\nthat uses Visual Question Generation (VQG) to produce questions, asks them to\nsocial media users, and collects their responses. We present two models that\ncan then parse clean answers from the noisy human responses significantly\nbetter than our baselines, with the goal of eventually incorporating the\nanswers into a Visual Question Answering (VQA) dataset. By demonstrating how\nour system can collect large amounts of data at little to no cost, we envision\nsimilar systems being used to improve performance on other tasks in the future.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 03:45:17 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 17:52:03 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Lee", "Jihyeon", ""], ["Arora", "Sho", ""]]}, {"id": "1912.00127", "submitter": "Chowdhury Rahman", "authors": "Md. Hasibur Rahman, Chowdhury Rafeed Rahman, Ruhul Amin, Md. Habibur\n  Rahman Sifat and Afra Anika", "title": "A Hybrid Approach Towards Two Stage Bengali Question Classification\n  Utilizing Smart Data Balancing Technique", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-52856-0_36", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question classification (QC) is the primary step of the Question Answering\n(QA) system. Question Classification (QC) system classifies the questions in\nparticular classes so that Question Answering (QA) System can provide correct\nanswers for the questions. Our system categorizes the factoid type questions\nasked in natural language after extracting features of the questions. We\npresent a two stage QC system for Bengali. It utilizes one dimensional\nconvolutional neural network for classifying questions into coarse classes in\nthe first stage. Word2vec representation of existing words of the question\ncorpus have been constructed and used for assisting 1D CNN. A smart data\nbalancing technique has been employed for giving data hungry convolutional\nneural network the advantage of a greater number of effective samples to learn\nfrom. For each coarse class, a separate Stochastic Gradient Descent (SGD) based\nclassifier has been used in order to differentiate among the finer classes\nwithin that coarse class. TF-IDF representation of each word has been used as\nfeature for the SGD classifiers implemented as part of second stage\nclassification. Experiments show the effectiveness of our proposed method for\nBengali question classification.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 04:00:31 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 02:15:32 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 03:53:55 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Rahman", "Md. Hasibur", ""], ["Rahman", "Chowdhury Rafeed", ""], ["Amin", "Ruhul", ""], ["Sifat", "Md. Habibur Rahman", ""], ["Anika", "Afra", ""]]}, {"id": "1912.00131", "submitter": "Keith Bonawitz", "authors": "Keith Bonawitz, Fariborz Salehi, Jakub Kone\\v{c}n\\'y, Brendan McMahan,\n  Marco Gruteser", "title": "Federated Learning with Autotuned Communication-Efficient Secure\n  Aggregation", "comments": "5 pages, 3 figures. To appear at the IEEE Asilomar Conference on\n  Signals, Systems, and Computers 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning enables mobile devices to collaboratively learn a shared\ninference model while keeping all the training data on a user's device,\ndecoupling the ability to do machine learning from the need to store the data\nin the cloud. Existing work on federated learning with limited communication\ndemonstrates how random rotation can enable users' model updates to be\nquantized much more efficiently, reducing the communication cost between users\nand the server. Meanwhile, secure aggregation enables the server to learn an\naggregate of at least a threshold number of device's model contributions\nwithout observing any individual device's contribution in unaggregated form. In\nthis paper, we highlight some of the challenges of setting the parameters for\nsecure aggregation to achieve communication efficiency, especially in the\ncontext of the aggressively quantized inputs enabled by random rotation. We\nthen develop a recipe for auto-tuning communication-efficient secure\naggregation, based on specific properties of random rotation and secure\naggregation -- namely, the predictable distribution of vector entries\npost-rotation and the modular wrapping inherent in secure aggregation. We\npresent both theoretical results and initial experiments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 04:27:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bonawitz", "Keith", ""], ["Salehi", "Fariborz", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["McMahan", "Brendan", ""], ["Gruteser", "Marco", ""]]}, {"id": "1912.00134", "submitter": "Rafaela Castro Nascimento", "authors": "Rafaela Castro, Yania M. Souto, Eduardo Ogasawara, Fabio Porto and\n  Eduardo Bezerra", "title": "STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for\n  Weather Forecasting", "comments": "Accepted manuscript. Submitted to Neurocomputing, Elsevier", "journal-ref": null, "doi": "10.1016/j.neucom.2020.09.060", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Applying machine learning models to meteorological data brings many\nopportunities to the Geosciences field, such as predicting future weather\nconditions more accurately. In recent years, modeling meteorological data with\ndeep neural networks has become a relevant area of investigation. These works\napply either recurrent neural networks (RNN) or some hybrid approach mixing RNN\nand convolutional neural networks (CNN). In this work, we propose STConvS2S\n(Spatiotemporal Convolutional Sequence to Sequence Network), a deep learning\narchitecture built for learning both spatial and temporal data dependencies\nusing only convolutional layers. Our proposed architecture resolves two\nlimitations of convolutional networks to predict sequences using historical\ndata: (1) they violate the temporal order during the learning process and (2)\nthey require the lengths of the input and output sequences to be equal.\nComputational experiments using air temperature and rainfall data from South\nAmerica show that our architecture captures spatiotemporal context and that it\noutperforms or matches the results of state-of-the-art architectures for\nforecasting tasks. In particular, one of the variants of our proposed\narchitecture is 23% better at predicting future sequences and five times faster\nat training than the RNN-based model used as a baseline.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 05:19:04 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 19:36:53 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 21:07:04 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 02:00:23 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Castro", "Rafaela", ""], ["Souto", "Yania M.", ""], ["Ogasawara", "Eduardo", ""], ["Porto", "Fabio", ""], ["Bezerra", "Eduardo", ""]]}, {"id": "1912.00144", "submitter": "Huangxing Lin", "authors": "Huangxing Lin, Weihong Zeng, Xinghao Ding, Yue Huang, Chenxi Huang and\n  John Paisley", "title": "Learning Rate Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a deep neural network is highly dependent on its training,\nand finding better local optimal solutions is the goal of many optimization\nalgorithms. However, existing optimization algorithms show a preference for\ndescent paths that converge slowly and do not seek to avoid bad local optima.\nIn this work, we propose Learning Rate Dropout (LRD), a simple gradient descent\ntechnique for training related to coordinate descent. LRD empirically aids the\noptimizer to actively explore in the parameter space by randomly setting some\nlearning rates to zero; at each iteration, only parameters whose learning rate\nis not 0 are updated. As the learning rate of different parameters is dropped,\nthe optimizer will sample a new loss descent path for the current update. The\nuncertainty of the descent path helps the model avoid saddle points and bad\nlocal minima. Experiments show that LRD is surprisingly effective in\naccelerating training while preventing overfitting.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 06:58:40 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 08:43:16 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lin", "Huangxing", ""], ["Zeng", "Weihong", ""], ["Ding", "Xinghao", ""], ["Huang", "Yue", ""], ["Huang", "Chenxi", ""], ["Paisley", "John", ""]]}, {"id": "1912.00155", "submitter": "Jie Qiao", "authors": "Jie Qiao, Zijian Li, Boyan Xu, Ruichu Cai, Kun Zhang", "title": "Disentanglement Challenge: From Regularization to Reconstruction", "comments": "NeurIPS2019 Disentanglement Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of learning disentangled representation has recently attracted\nmuch attention and boils down to a competition using a new real world\ndisentanglement dataset (Gondal et al., 2019). Various methods based on\nvariational auto-encoder have been proposed to solve this problem, by enforcing\nthe independence between the representation and modifying the regularization\nterm in the variational lower bound. However recent work by Locatello et al.\n(2018) has demonstrated that the proposed methods are heavily influenced by\nrandomness and the choice of the hyper-parameter. In this work, instead of\ndesigning a new regularization term, we adopt the FactorVAE but improve the\nreconstruction performance and increase the capacity of network and the\ntraining step. The strategy turns out to be very effective and achieve the 1st\nplace in the challenge.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 08:01:24 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Qiao", "Jie", ""], ["Li", "Zijian", ""], ["Xu", "Boyan", ""], ["Cai", "Ruichu", ""], ["Zhang", "Kun", ""]]}, {"id": "1912.00157", "submitter": "Shady Abu Hussein", "authors": "Shady Abu Hussein, Tom Tirer, and Raja Giryes", "title": "Correction Filter for Single Image Super-Resolution: Robustifying\n  Off-the-Shelf Deep Super-Resolvers", "comments": "Accepted to CVPR 2020 (Oral). Code is available at\n  https://github.com/shadyabh/Correction-Filter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The single image super-resolution task is one of the most examined inverse\nproblems in the past decade. In the recent years, Deep Neural Networks (DNNs)\nhave shown superior performance over alternative methods when the acquisition\nprocess uses a fixed known downsampling kernel-typically a bicubic kernel.\nHowever, several recent works have shown that in practical scenarios, where the\ntest data mismatch the training data (e.g. when the downsampling kernel is not\nthe bicubic kernel or is not available at training), the leading DNN methods\nsuffer from a huge performance drop. Inspired by the literature on generalized\nsampling, in this work we propose a method for improving the performance of\nDNNs that have been trained with a fixed kernel on observations acquired by\nother kernels. For a known kernel, we design a closed-form correction filter\nthat modifies the low-resolution image to match one which is obtained by\nanother kernel (e.g. bicubic), and thus improves the results of existing\npre-trained DNNs. For an unknown kernel, we extend this idea and propose an\nalgorithm for blind estimation of the required correction filter. We show that\nour approach outperforms other super-resolution methods, which are designed for\ngeneral downsampling kernels.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 08:04:33 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 13:27:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Hussein", "Shady Abu", ""], ["Tirer", "Tom", ""], ["Giryes", "Raja", ""]]}, {"id": "1912.00163", "submitter": "Gaurav Sinha", "authors": "Gaurav Sinha, Ayush Chauhan, Aurghya Maiti, Naman Poddar, Pulkit Goel", "title": "Dis-entangling Mixture of Interventions on a Causal Bayesian Network\n  Using Aggregate Observations", "comments": "Accepted at the Ninth International Workshop on Statistical\n  Relational AI, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of separating a mixture of distributions, all of which\ncome from interventions on a known causal bayesian network. Given oracle access\nto marginals of all distributions resulting from interventions on the network,\nand estimates of marginals from the mixture distribution, we want to recover\nthe mixing proportions of different mixture components.\n  We show that in the worst case, mixing proportions cannot be identified using\nmarginals only. If exact marginals of the mixture distribution were known,\nunder a simple assumption of excluding a few distributions from the mixture, we\nshow that the mixing proportions become identifiable. Our identifiability proof\nis constructive and gives an efficient algorithm recovering the mixing\nproportions exactly. When exact marginals are not available, we design an\noptimization framework to estimate the mixing proportions.\n  Our problem is motivated from a real-world scenario of an e-commerce\nbusiness, where multiple interventions occur at a given time, leading to\ndeviations in expected metrics. We conduct experiments on the well known\npublicly available ALARM network and on a proprietary dataset from a large\ne-commerce company validating the performance of our method.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 09:36:23 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 11:19:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sinha", "Gaurav", ""], ["Chauhan", "Ayush", ""], ["Maiti", "Aurghya", ""], ["Poddar", "Naman", ""], ["Goel", "Pulkit", ""]]}, {"id": "1912.00167", "submitter": "Michael Luo Zhiyu", "authors": "Michael Luo, Jiahao Yao, Richard Liaw, Eric Liang, Ion Stoica", "title": "IMPACT: Importance Weighted Asynchronous Architectures with Clipped\n  Target Networks", "comments": "ICLR 2020 Publication; 14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical usage of reinforcement learning agents is often bottlenecked by\nthe duration of training time. To accelerate training, practitioners often turn\nto distributed reinforcement learning architectures to parallelize and\naccelerate the training process. However, modern methods for scalable\nreinforcement learning (RL) often tradeoff between the throughput of samples\nthat an RL agent can learn from (sample throughput) and the quality of learning\nfrom each sample (sample efficiency). In these scalable RL architectures, as\none increases sample throughput (i.e. increasing parallelization in IMPALA),\nsample efficiency drops significantly. To address this, we propose a new\ndistributed reinforcement learning algorithm, IMPACT. IMPACT extends IMPALA\nwith three changes: a target network for stabilizing the surrogate objective, a\ncircular buffer, and truncated importance sampling. In discrete action-space\nenvironments, we show that IMPACT attains higher reward and, simultaneously,\nachieves up to 30% decrease in training wall-time than that of IMPALA. For\ncontinuous control environments, IMPACT trains faster than existing scalable\nagents while preserving the sample efficiency of synchronous PPO.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 09:44:19 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 09:23:15 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 07:30:51 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Luo", "Michael", ""], ["Yao", "Jiahao", ""], ["Liaw", "Richard", ""], ["Liang", "Eric", ""], ["Stoica", "Ion", ""]]}, {"id": "1912.00177", "submitter": "Jeffrey Hawke", "authors": "Jeffrey Hawke, Richard Shen, Corina Gurau, Siddharth Sharma, Daniele\n  Reda, Nikolay Nikolov, Przemyslaw Mazur, Sean Micklethwaite, Nicolas\n  Griffiths, Amar Shah, Alex Kendall", "title": "Urban Driving with Conditional Imitation Learning", "comments": "Under submission; added acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand-crafting generalised decision-making rules for real-world urban\nautonomous driving is hard. Alternatively, learning behaviour from\neasy-to-collect human driving demonstrations is appealing. Prior work has\nstudied imitation learning (IL) for autonomous driving with a number of\nlimitations. Examples include only performing lane-following rather than\nfollowing a user-defined route, only using a single camera view or heavily\ncropped frames lacking state observability, only lateral (steering) control,\nbut not longitudinal (speed) control and a lack of interaction with traffic.\nImportantly, the majority of such systems have been primarily evaluated in\nsimulation - a simple domain, which lacks real-world complexities. Motivated by\nthese challenges, we focus on learning representations of semantics, geometry\nand motion with computer vision for IL from human driving demonstrations. As\nour main contribution, we present an end-to-end conditional imitation learning\napproach, combining both lateral and longitudinal control on a real vehicle for\nfollowing urban routes with simple traffic. We address inherent dataset bias by\ndata balancing, training our final policy on approximately 30 hours of\ndemonstrations gathered over six months. We evaluate our method on an\nautonomous vehicle by driving 35km of novel routes in European urban streets.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:24:45 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 18:17:45 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Hawke", "Jeffrey", ""], ["Shen", "Richard", ""], ["Gurau", "Corina", ""], ["Sharma", "Siddharth", ""], ["Reda", "Daniele", ""], ["Nikolov", "Nikolay", ""], ["Mazur", "Przemyslaw", ""], ["Micklethwaite", "Sean", ""], ["Griffiths", "Nicolas", ""], ["Shah", "Amar", ""], ["Kendall", "Alex", ""]]}, {"id": "1912.00178", "submitter": "Yang Feng", "authors": "Yang Feng, Wanying Xie, Shuhao Gu, Chenze Shao, Wen Zhang, Zhengxin\n  Yang, Dong Yu", "title": "Modeling Fluency and Faithfulness for Diverse Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation models usually adopt the teacher forcing strategy\nfor training which requires the predicted sequence matches ground truth word by\nword and forces the probability of each prediction to approach a 0-1\ndistribution. However, the strategy casts all the portion of the distribution\nto the ground truth word and ignores other words in the target vocabulary even\nwhen the ground truth word cannot dominate the distribution. To address the\nproblem of teacher forcing, we propose a method to introduce an evaluation\nmodule to guide the distribution of the prediction. The evaluation module\naccesses each prediction from the perspectives of fluency and faithfulness to\nencourage the model to generate the word which has a fluent connection with its\npast and future translation and meanwhile tends to form a translation\nequivalent in meaning to the source. The experiments on multiple translation\ntasks show that our method can achieve significant improvements over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:30:46 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Feng", "Yang", ""], ["Xie", "Wanying", ""], ["Gu", "Shuhao", ""], ["Shao", "Chenze", ""], ["Zhang", "Wen", ""], ["Yang", "Zhengxin", ""], ["Yu", "Dong", ""]]}, {"id": "1912.00181", "submitter": "Yang Song", "authors": "Yang Song, Qiyu Kang, and Wee Peng Tay", "title": "Error-Correcting Output Codes with Ensemble Diversity for Robust\n  Learning in Neural Networks", "comments": "Published in Proc. AAAI Conference on Artificial Intelligence, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep learning has been applied successfully in many scenarios,\nmalicious inputs with human-imperceptible perturbations can make it vulnerable\nin real applications. This paper proposes an error-correcting neural network\n(ECNN) that combines a set of binary classifiers to combat adversarial examples\nin the multi-class classification problem. To build an ECNN, we propose to\ndesign a code matrix so that the minimum Hamming distance between any two rows\n(i.e., two codewords) and the minimum shared information distance between any\ntwo columns (i.e., two partitions of class labels) are simultaneously\nmaximized. Maximizing row distances can increase the system fault tolerance\nwhile maximizing column distances helps increase the diversity between binary\nclassifiers. We propose an end-to-end training method for our ECNN, which\nallows further improvement of the diversity between binary classifiers. The\nend-to-end training renders our proposed ECNN different from the traditional\nerror-correcting output code (ECOC) based methods that train binary classifiers\nindependently. ECNN is complementary to other existing defense approaches such\nas adversarial training and can be applied in conjunction with them. We\nempirically demonstrate that our proposed ECNN is effective against the\nstate-of-the-art white-box and black-box attacks on several datasets while\nmaintaining good classification accuracy on normal examples.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:32:59 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 08:28:26 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 03:51:04 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 08:10:00 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Song", "Yang", ""], ["Kang", "Qiyu", ""], ["Tay", "Wee Peng", ""]]}, {"id": "1912.00183", "submitter": "Isac Arnekvist", "authors": "Isac Arnekvist, Dmytro Kalpakchi", "title": "[Re] Learning to Learn By Self-Critique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a reproducibility study of the paper of Antoniou and Storkey\n[2019], published at NeurIPS 2019. Our results are in parts similar to the ones\nreported in the original paper, supporting the central claim of the paper that\nthe proposed novel method, called Self-Critique and Adapt (SCA), improves the\nperformance of MAML++. The conducted additional experiments on the Caltech-UCSD\nBirds 200 dataset confirm the superiority of SCA compared to MAML++. In\naddition, the reproduced paper suggests a novel high-end version of MAML++ for\nwhich we could not reproduce the same results. We hypothesize that this is due\nto the many implementation details that were omitted in the original paper.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:49:35 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 10:39:37 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Arnekvist", "Isac", ""], ["Kalpakchi", "Dmytro", ""]]}, {"id": "1912.00186", "submitter": "Suzana Ilic", "authors": "Anugraha Sinha and Naveen Kumar and Murukesh Mohanan and MD Muhaimin\n  Rahman and Yves Quemener and Amina Mim and Suzana Ili\\'c", "title": "Quantized deep learning models on low-power edge devices for robotic\n  systems", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a quantized deep neural network deployed on a\nlow-power edge device, inferring learned motor-movements of a suspended robot\nin a defined space. This serves as the fundamental building block for the\noriginal setup, a robotic system for farms or greenhouses aimed at a wide range\nof agricultural tasks. Deep learning on edge devices and its implications could\nhave a substantial impact on farming systems in the developing world, leading\nnot only to sustainable food production and income, but also increased data\nprivacy and autonomy.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 11:27:12 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sinha", "Anugraha", ""], ["Kumar", "Naveen", ""], ["Mohanan", "Murukesh", ""], ["Rahman", "MD Muhaimin", ""], ["Quemener", "Yves", ""], ["Mim", "Amina", ""], ["Ili\u0107", "Suzana", ""]]}, {"id": "1912.00195", "submitter": "Guohao Li", "authors": "Guohao Li, Guocheng Qian, Itzel C. Delgadillo, Matthias M\\\"uller, Ali\n  Thabet, Bernard Ghanem", "title": "SGAS: Sequential Greedy Architecture Search", "comments": "Accepted at CVPR'2020. Project website:\n  https://www.deepgcns.org/auto/sgas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architecture design has become a crucial component of successful deep\nlearning. Recent progress in automatic neural architecture search (NAS) shows a\nlot of promise. However, discovered architectures often fail to generalize in\nthe final evaluation. Architectures with a higher validation accuracy during\nthe search phase may perform worse in the evaluation. Aiming to alleviate this\ncommon issue, we introduce sequential greedy architecture search (SGAS), an\nefficient method for neural architecture search. By dividing the search\nprocedure into sub-problems, SGAS chooses and prunes candidate operations in a\ngreedy fashion. We apply SGAS to search architectures for Convolutional Neural\nNetworks (CNN) and Graph Convolutional Networks (GCN). Extensive experiments\nshow that SGAS is able to find state-of-the-art architectures for tasks such as\nimage classification, point cloud classification and node classification in\nprotein-protein interaction graphs with minimal computational cost. Please\nvisit https://www.deepgcns.org/auto/sgas for more information about SGAS.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 12:39:55 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 12:55:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Li", "Guohao", ""], ["Qian", "Guocheng", ""], ["Delgadillo", "Itzel C.", ""], ["M\u00fcller", "Matthias", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1912.00200", "submitter": "Abdullah Salama", "authors": "Abdullah Salama, Oleksiy Ostapenko, Tassilo Klein, Moin Nabi", "title": "Pruning at a Glance: Global Neural Pruning for Model Compression", "comments": "Extended version of the ICASSP paper\n  (https://ieeexplore.ieee.org/document/8683224)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning models have become the dominant approach in several areas due\nto their high performance. Unfortunately, the size and hence computational\nrequirements of operating such models can be considerably high. Therefore, this\nconstitutes a limitation for deployment on memory and battery constrained\ndevices such as mobile phones or embedded systems. To address these\nlimitations, we propose a novel and simple pruning method that compresses\nneural networks by removing entire filters and neurons according to a global\nthreshold across the network without any pre-calculation of layer sensitivity.\nThe resulting model is compact, non-sparse, with the same accuracy as the\nnon-compressed model, and most importantly requires no special infrastructure\nfor deployment. We prove the viability of our method by producing highly\ncompressed models, namely VGG-16, ResNet-56, and ResNet-110 respectively on\nCIFAR10 without losing any performance compared to the baseline, as well as\nResNet-34 and ResNet-50 on ImageNet without a significant loss of accuracy. We\nalso provide a well-retrained 30% compressed ResNet-50 that slightly surpasses\nthe base model accuracy. Additionally, compressing more than 56% and 97% of\nAlexNet and LeNet-5 respectively. Interestingly, the resulted models' pruning\npatterns are highly similar to the other methods using layer sensitivity\npre-calculation step. Our method does not only exhibit good performance but\nwhat is more also easy to implement.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 13:17:48 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 09:44:06 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Salama", "Abdullah", ""], ["Ostapenko", "Oleksiy", ""], ["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1912.00215", "submitter": "Cinjon Resnick", "authors": "Cinjon Resnick, Zeping Zhan, Joan Bruna", "title": "Probing the State of the Art: A Critical Look at Visual Representation\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised research improved greatly over the past half decade, with\nmuch of the growth being driven by objectives that are hard to quantitatively\ncompare. These techniques include colorization, cyclical consistency, and\nnoise-contrastive estimation from image patches. Consequently, the field has\nsettled on a handful of measurements that depend on linear probes to adjudicate\nwhich approaches are the best. Our first contribution is to show that this test\nis insufficient and that models which perform poorly (strongly) on linear\nclassification can perform strongly (weakly) on more involved tasks like\ntemporal activity localization. Our second contribution is to analyze the\ncapabilities of five different representations. And our third contribution is a\nmuch needed new dataset for temporal activity localization.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 15:05:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Resnick", "Cinjon", ""], ["Zhan", "Zeping", ""], ["Bruna", "Joan", ""]]}, {"id": "1912.00225", "submitter": "Michael Curry", "authors": "Michael J. Curry, John P. Dickerson, Karthik Abinav Sankararaman,\n  Aravind Srinivasan, Yuhao Wan, Pan Xu", "title": "Mix and Match: Markov Chains & Mixing Times for Matching in Rideshare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rideshare platforms such as Uber and Lyft dynamically dispatch drivers to\nmatch riders' requests. We model the dispatching process in rideshare as a\nMarkov chain that takes into account the geographic mobility of both drivers\nand riders over time. Prior work explores dispatch policies in the limit of\nsuch Markov chains; we characterize when this limit assumption is valid, under\na variety of natural dispatch policies. We give explicit bounds on convergence\nin general, and exact (including constants) convergence rates for special\ncases. Then, on simulated and real transit data, we show that our bounds\ncharacterize convergence rates -- even when the necessary theoretical\nassumptions are relaxed. Additionally these policies compare well against a\nstandard reinforcement learning algorithm which optimizes for profit without\nany convergence properties.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 16:26:33 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Curry", "Michael J.", ""], ["Dickerson", "John P.", ""], ["Sankararaman", "Karthik Abinav", ""], ["Srinivasan", "Aravind", ""], ["Wan", "Yuhao", ""], ["Xu", "Pan", ""]]}, {"id": "1912.00245", "submitter": "Christian Schulz", "authors": "Christian Schulz", "title": "Scalable Graph Algorithms", "comments": "Habilitation thesis of Christian Schulz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing large complex networks recently attracted considerable interest.\nComplex graphs are useful in a wide range of applications from technological\nnetworks to biological systems like the human brain. Sometimes these networks\nare composed of billions of entities that give rise to emerging properties and\nstructures. Analyzing these structures aids us in gaining new insights about\nour surroundings. As huge networks become abundant, there is a need for\nscalable algorithms to perform analysis. A prominent example is the PageRank\nalgorithm, which is one of the measures used by web search engines such as\nGoogle to rank web pages displayed to the user. In order to find these\npatterns, massive amounts of data have to be acquired and processed. Designing\nand evaluating scalable graph algorithms to handle these data sets is a crucial\ntask on the road to understanding the underlying systems.\n  This habilitation thesis is a summary a broad spectrum of scalable graph\nalgorithms that I developed over the last six years with many coauthors. In\ngeneral, this research is based on four pillars: multilevel algorithms,\npractical kernelization, parallelization and memetic algorithms that are highly\ninterconnected. Experiments conducted indicate that our algorithms find better\nsolutions and/or are much more scalable than the previous state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 18:01:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Schulz", "Christian", ""]]}, {"id": "1912.00260", "submitter": "Chen Wang", "authors": "Junfeng Ding, Chen Wang, Cewu Lu", "title": "Transferable Force-Torque Dynamics Model for Peg-in-hole Task", "comments": "IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based force-torque dynamics to achieve model-based\ncontrol for contact-rich peg-in-hole task using force-only inputs. Learning the\nforce-torque dynamics is challenging because of the ambiguity of the\nlow-dimensional 6-d force signal and the requirement of excessive training\ndata. To tackle these problems, we propose a multi-pose force-torque state\nrepresentation, based on which a dynamics model is learned with the data\ngenerated in a sample-efficient offline fashion. In addition, by training the\ndynamics model with peg-and-holes of various shapes, scales, and elasticities,\nthe model could quickly transfer to new peg-and-holes after a small number of\ntrials. Extensive experiments show that our dynamics model could adapt to\nunseen peg-and-holes with 70% fewer samples required compared to learning from\nscratch. Along with the learned dynamics, model predictive control and\nmodel-based reinforcement learning policies achieve over 80% insertion success\nrate. Our video is available at https://youtu.be/ZAqldpVZgm4.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 20:48:33 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ding", "Junfeng", ""], ["Wang", "Chen", ""], ["Lu", "Cewu", ""]]}, {"id": "1912.00262", "submitter": "Ava Soleimany", "authors": "Ava P. Soleimany, Harini Suresh, Jose Javier Gonzalez Ortiz, Divya\n  Shanmugam, Nil Gural, John Guttag, Sangeeta N. Bhatia", "title": "Image segmentation of liver stage malaria infection with spatial\n  uncertainty sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global eradication of malaria depends on the development of drugs effective\nagainst the silent, yet obligate liver stage of the disease. The gold standard\nin drug development remains microscopic imaging of liver stage parasites in in\nvitro cell culture models. Image analysis presents a major bottleneck in this\npipeline since the parasite has significant variability in size, shape, and\ndensity in these models. As with other highly variable datasets, traditional\nsegmentation models have poor generalizability as they rely on hand-crafted\nfeatures; thus, manual annotation of liver stage malaria images remains\nstandard. To address this need, we develop a convolutional neural network\narchitecture that utilizes spatial dropout sampling for parasite segmentation\nand epistemic uncertainty estimation in images of liver stage malaria. Our\npipeline produces high-precision segmentations nearly identical to expert\nannotations, generalizes well on a diverse dataset of liver stage malaria\nparasites, and promotes independence between learned feature maps to model the\nuncertainty of generated predictions.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 20:57:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Soleimany", "Ava P.", ""], ["Suresh", "Harini", ""], ["Ortiz", "Jose Javier Gonzalez", ""], ["Shanmugam", "Divya", ""], ["Gural", "Nil", ""], ["Guttag", "John", ""], ["Bhatia", "Sangeeta N.", ""]]}, {"id": "1912.00271", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Amirali Abdolrashidi, Hang Su, Mohammed Bennamoun,\n  David Zhang", "title": "Biometrics Recognition Using Deep Learning: A Survey", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based models have been very successful in achieving\nstate-of-the-art results in many of the computer vision, speech recognition,\nand natural language processing tasks in the last few years. These models seem\na natural fit for handling the ever-increasing scale of biometric recognition\nproblems, from cellphone authentication to airport security systems. Deep\nlearning-based models have increasingly been leveraged to improve the accuracy\nof different biometric recognition systems in recent years. In this work, we\nprovide a comprehensive survey of more than 120 promising works on biometric\nrecognition (including face, fingerprint, iris, palmprint, ear, voice,\nsignature, and gait recognition), which deploy deep learning models, and show\ntheir strengths and potentials in different applications. For each biometric,\nwe first introduce the available datasets that are widely used in the\nliterature and their characteristics. We will then talk about several promising\ndeep learning works developed for that biometric, and show their performance on\npopular public benchmarks. We will also discuss some of the main challenges\nwhile using these models for biometric recognition, and possible future\ndirections to which research in this area is headed.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 22:00:57 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 14:59:36 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 19:24:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Minaee", "Shervin", ""], ["Abdolrashidi", "Amirali", ""], ["Su", "Hang", ""], ["Bennamoun", "Mohammed", ""], ["Zhang", "David", ""]]}, {"id": "1912.00283", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Evan Campbell, Angkoon Phinyomark,\n  Fran\\c{c}ois Laviolette, Benoit Gosselin and Erik Scheme", "title": "Interpreting Deep Learning Features for Myoelectric Control: A\n  Comparison with Handcrafted Features", "comments": "The first two authors shared first authorship. The last three authors\n  shared senior authorship. 32 pages", "journal-ref": "Frontiers in Bioengineering and Biotechnology, 8, 158 (2020)", "doi": "10.3389/fbioe.2020.00158", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research in myoelectric control systems primarily focuses on extracting\ndiscriminative representations from the electromyographic (EMG) signal by\ndesigning handcrafted features. Recently, deep learning techniques have been\napplied to the challenging task of EMG-based gesture recognition. The adoption\nof these techniques slowly shifts the focus from feature engineering to feature\nlearning. However, the black-box nature of deep learning makes it hard to\nunderstand the type of information learned by the network and how it relates to\nhandcrafted features. Additionally, due to the high variability in EMG\nrecordings between participants, deep features tend to generalize poorly across\nsubjects using standard training methods. Consequently, this work introduces a\nnew multi-domain learning algorithm, named ADANN, which significantly enhances\n(p=0.00004) inter-subject classification accuracy by an average of 19.40%\ncompared to standard training. Using ADANN-generated features, the main\ncontribution of this work is to provide the first topological data analysis of\nEMG-based gesture recognition for the characterisation of the information\nencoded within a deep network, using handcrafted features as landmarks. This\nanalysis reveals that handcrafted features and the learned features (in the\nearlier layers) both try to discriminate between all gestures, but do not\nencode the same information to do so. Furthermore, using convolutional network\nvisualization techniques reveal that learned features tend to ignore the most\nactivated channel during gesture contraction, which is in stark contrast with\nthe prevalence of handcrafted features designed to capture amplitude\ninformation. Overall, this work paves the way for hybrid feature sets by\nproviding a clear guideline of complementary information encoded within learned\nand handcrafted features.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 23:11:26 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:37:43 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Campbell", "Evan", ""], ["Phinyomark", "Angkoon", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Gosselin", "Benoit", ""], ["Scheme", "Erik", ""]]}, {"id": "1912.00286", "submitter": "Alexey Svyatkovskiy", "authors": "Alexey Svyatkovskiy, Julian Kates-Harbeck, William Tang", "title": "Training Distributed Deep Recurrent Neural Networks with Mixed Precision\n  on GPU Clusters", "comments": null, "journal-ref": "Published in Proceedings of the Machine Learning on HPC\n  Environments (MLHPC) at the Supercomputing conference 2017", "doi": "10.1145/3146347.3146358", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we evaluate training of deep recurrent neural networks with\nhalf-precision floats. We implement a distributed, data-parallel, synchronous\ntraining algorithm by integrating TensorFlow and CUDA-aware MPI to enable\nexecution across multiple GPU nodes and making use of high-speed interconnects.\nWe introduce a learning rate schedule facilitating neural network convergence\nat up to $O(100)$ workers.\n  Strong scaling tests performed on clusters of NVIDIA Pascal P100 GPUs show\nlinear runtime and logarithmic communication time scaling for both single and\nmixed precision training modes. Performance is evaluated on a scientific\ndataset taken from the Joint European Torus (JET) tokamak, containing\nmulti-modal time series of sensory measurements leading up to deleterious\nevents called plasma disruptions, and the benchmark Large Movie Review\nDataset~\\cite{imdb}. Half-precision significantly reduces memory and network\nbandwidth, allowing training of state-of-the-art models with over 70 million\ntrainable parameters while achieving a comparable test set performance as\nsingle precision.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 23:57:48 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Svyatkovskiy", "Alexey", ""], ["Kates-Harbeck", "Julian", ""], ["Tang", "William", ""]]}, {"id": "1912.00290", "submitter": "Yue Zhao", "authors": "Yue Zhao and Maciej K. Hryniewicki", "title": "XGBOD: Improving Supervised Outlier Detection with Unsupervised\n  Representation Learning", "comments": "Proceedings of the 2018 International Joint Conference on Neural\n  Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489605", "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new semi-supervised ensemble algorithm called XGBOD (Extreme Gradient\nBoosting Outlier Detection) is proposed, described and demonstrated for the\nenhanced detection of outliers from normal observations in various practical\ndatasets. The proposed framework combines the strengths of both supervised and\nunsupervised machine learning methods by creating a hybrid approach that\nexploits each of their individual performance capabilities in outlier\ndetection. XGBOD uses multiple unsupervised outlier mining algorithms to\nextract useful representations from the underlying data that augment the\npredictive capabilities of an embedded supervised classifier on an improved\nfeature space. The novel approach is shown to provide superior performance in\ncomparison to competing individual detectors, the full ensemble and two\nexisting representation learning based algorithms across seven outlier\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 00:09:10 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhao", "Yue", ""], ["Hryniewicki", "Maciej K.", ""]]}, {"id": "1912.00303", "submitter": "Hong Xu", "authors": "Han Zhang and Hong Xu", "title": "MANELA: A Multi-Agent Algorithm for Learning Network Embeddings", "comments": "11 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Playing an essential role in data mining, machine learning has a long history\nof being applied to networks on multifarious tasks and has played an essential\nrole in data mining. However, the discrete and sparse natures of networks often\nrender it difficult to apply machine learning directly to networks. To\ncircumvent this difficulty, one major school of thought to approach networks\nusing machine learning is via network embeddings. On the one hand, this network\nembeddings have achieved huge success on aggregated network data in recent\nyears. On the other hand, learning network embeddings on distributively stored\nnetworks still remained understudied: To the best of our knowledge, all\nexisting algorithms for learning network embeddings have hitherto been\nexclusively centralized and thus cannot be applied to these networks. To\naccommodate distributively stored networks, in this paper, we proposed a\nmulti-agent model. Under this model, we developed the multi-agent network\nembedding learning algorithm (MANELA) for learning network embeddings. We\ndemonstrate MANELA's advantages over other existing centralized network\nembedding learning algorithms both theoretically and experimentally. Finally,\nwe further our understanding in MANELA via visualization and exploration of its\nrelationship to DeepWalk.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 02:23:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Han", ""], ["Xu", "Hong", ""]]}, {"id": "1912.00306", "submitter": "Ezequiel Smucler", "authors": "Andrea Rotnitzky and Ezequiel Smucler", "title": "Efficient adjustment sets for population average treatment effect\n  estimation in non-parametric causal graphical models", "comments": "Fixed a typo in Example 1, an arrow was missing from L1 to Y in the\n  DAG and L1 was missing in the second adjustment set", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of covariate adjustment is often used for estimation of population\naverage treatment effects in observational studies. Graphical rules for\ndetermining all valid covariate adjustment sets from an assumed causal\ngraphical model are well known. Restricting attention to causal linear models,\na recent article derived two novel graphical criteria: one to compare the\nasymptotic variance of linear regression treatment effect estimators that\ncontrol for certain distinct adjustment sets and another to identify the\noptimal adjustment set that yields the least squares treatment effect estimator\nwith the smallest asymptotic variance among consistent adjusted least squares\nestimators. In this paper we show that the same graphical criteria can be used\nin non-parametric causal graphical models when treatment effects are estimated\nby contrasts involving non-parametrically adjusted estimators of the\ninterventional means. We also provide a graphical criterion for determining the\noptimal adjustment set among the minimal adjustment sets, which is valid for\nboth linear and non-parametric estimators. We provide a new graphical criterion\nfor comparing time dependent adjustment sets, that is, sets comprised by\ncovariates that adjust for future treatments and that are themselves affected\nby earlier treatments. We show by example that uniformly optimal time dependent\nadjustment sets do not always exist. In addition, for point interventions, we\nprovide a sound and complete graphical criterion for determining when a\nnon-parametric optimally adjusted estimator of an interventional mean, or of a\ncontrast of interventional means, is as efficient as an efficient estimator of\nthe same parameter that exploits the information in the conditional\nindependencies encoded in the non-parametric causal graphical model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 02:35:53 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 23:24:35 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Rotnitzky", "Andrea", ""], ["Smucler", "Ezequiel", ""]]}, {"id": "1912.00311", "submitter": "Joel Ruben Antony Moniz", "authors": "Sarthak Garg, Joel Ruben Antony Moniz, Anshu Aviral, Priyatham\n  Bollimpalli", "title": "Learning to Relate from Captions and Bounding Boxes", "comments": "ACL 2019", "journal-ref": null, "doi": "10.18653/v1/P19-1660", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel approach that predicts the relationships\nbetween various entities in an image in a weakly supervised manner by relying\non image captions and object bounding box annotations as the sole source of\nsupervision. Our proposed approach uses a top-down attention mechanism to align\nentities in captions to objects in the image, and then leverage the syntactic\nstructure of the captions to align the relations. We use these alignments to\ntrain a relation classification network, thereby obtaining both grounded\ncaptions and dense relationships. We demonstrate the effectiveness of our model\non the Visual Genome dataset by achieving a recall@50 of 15% and recall@100 of\n25% on the relationships present in the image. We also show that the model\nsuccessfully predicts relations that are not present in the corresponding\ncaptions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 03:30:00 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Garg", "Sarthak", ""], ["Moniz", "Joel Ruben Antony", ""], ["Aviral", "Anshu", ""], ["Bollimpalli", "Priyatham", ""]]}, {"id": "1912.00314", "submitter": "Xiao Zhang", "authors": "Xiao Zhang and Manish Marwah and I-ta Lee and Martin Arlitt and Dan\n  Goldwasser", "title": "ACE -- An Anomaly Contribution Explainer for Cyber-Security Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Anomaly Contribution Explainer or ACE, a tool to\nexplain security anomaly detection models in terms of the model features\nthrough a regression framework, and its variant, ACE-KL, which highlights the\nimportant anomaly contributors. ACE and ACE-KL provide insights in diagnosing\nwhich attributes significantly contribute to an anomaly by building a\nspecialized linear model to locally approximate the anomaly score that a\nblack-box model generates. We conducted experiments with these anomaly\ndetection models to detect security anomalies on both synthetic data and real\ndata. In particular, we evaluate performance on three public data sets: CERT\ninsider threat, netflow logs, and Android malware. The experimental results are\nencouraging: our methods consistently identify the correct contributing feature\nin the synthetic data where ground truth is available; similarly, for real data\nsets, our methods point a security analyst in the direction of the underlying\ncauses of an anomaly, including in one case leading to the discovery of\npreviously overlooked network scanning activity. We have made our source code\npublicly available.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:16:12 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:26:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Marwah", "Manish", ""], ["Lee", "I-ta", ""], ["Arlitt", "Martin", ""], ["Goldwasser", "Dan", ""]]}, {"id": "1912.00315", "submitter": "Hanbaek Lyu", "authors": "Yuchen Guo, Nicholas Hanoian, Zhexiao Lin, Nicholas Liskij, Hanbaek\n  Lyu, Deanna Needell, Jiahao Qu, Henry Sojico, Yuliang Wang, Zhe Xiong,\n  Zhenhong Zou", "title": "Topic-aware chatbot using Recurrent Neural Networks and Nonnegative\n  Matrix Factorization", "comments": "14 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model for a topic-aware chatbot by combining the\ntraditional Recurrent Neural Network (RNN) encoder-decoder model with a topic\nattention layer based on Nonnegative Matrix Factorization (NMF). After learning\ntopic vectors from an auxiliary text corpus via NMF, the decoder is trained so\nthat it is more likely to sample response words from the most correlated topic\nvectors. One of the main advantages in our architecture is that the user can\neasily switch the NMF-learned topic vectors so that the chatbot obtains desired\ntopic-awareness. We demonstrate our model by training on a single\nconversational data set which is then augmented with topic matrices learned\nfrom different auxiliary data sets. We show that our topic-aware chatbot not\nonly outperforms the non-topic counterpart, but also that each topic-aware\nmodel qualitatively and contextually gives the most relevant answer depending\non the topic of question.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:22:51 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 08:28:12 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Guo", "Yuchen", ""], ["Hanoian", "Nicholas", ""], ["Lin", "Zhexiao", ""], ["Liskij", "Nicholas", ""], ["Lyu", "Hanbaek", ""], ["Needell", "Deanna", ""], ["Qu", "Jiahao", ""], ["Sojico", "Henry", ""], ["Wang", "Yuliang", ""], ["Xiong", "Zhe", ""], ["Zou", "Zhenhong", ""]]}, {"id": "1912.00318", "submitter": "Yanjun Li", "authors": "Yanjun Li, Mohammad A. Rezaei, Chenglong Li, Xiaolin Li, Dapeng Wu", "title": "DeepAtom: A Framework for Protein-Ligand Binding Affinity Prediction", "comments": "Accepted IEEE BIBM 2019 paper with minor revisions", "journal-ref": "IEEE International Conference on Bioinformatics and Biomedicine\n  (BIBM 2019)", "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cornerstone of computational drug design is the calculation of binding\naffinity between two biological counterparts, especially a chemical compound,\ni.e., a ligand, and a protein. Predicting the strength of protein-ligand\nbinding with reasonable accuracy is critical for drug discovery. In this paper,\nwe propose a data-driven framework named DeepAtom to accurately predict the\nprotein-ligand binding affinity. With 3D Convolutional Neural Network (3D-CNN)\narchitecture, DeepAtom could automatically extract binding related atomic\ninteraction patterns from the voxelized complex structure. Compared with the\nother CNN based approaches, our light-weight model design effectively improves\nthe model representational capacity, even with the limited available training\ndata. With validation experiments on the PDBbind v.2016 benchmark and the\nindependent Astex Diverse Set, we demonstrate that the less feature engineering\ndependent DeepAtom approach consistently outperforms the other state-of-the-art\nscoring methods. We also compile and propose a new benchmark dataset to further\nimprove the model performances. With the new dataset as training input,\nDeepAtom achieves Pearson's R=0.83 and RMSE=1.23 pK units on the PDBbind v.2016\ncore set. The promising results demonstrate that DeepAtom models can be\npotentially adopted in computational drug development protocols such as\nmolecular docking and virtual screening.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:45:56 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Yanjun", ""], ["Rezaei", "Mohammad A.", ""], ["Li", "Chenglong", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "1912.00320", "submitter": "Dongrui Wu", "authors": "Wen Zhang and Dongrui Wu", "title": "Discriminative Joint Probability Maximum Mean Discrepancy (DJP-MMD) for\n  Domain Adaptation", "comments": "Int'l Joint Conf. on Neural Networks (IJCNN), Glasgow, UK, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum mean discrepancy (MMD) has been widely adopted in domain adaptation\nto measure the discrepancy between the source and target domain distributions.\nMany existing domain adaptation approaches are based on the joint MMD, which is\ncomputed as the (weighted) sum of the marginal distribution discrepancy and the\nconditional distribution discrepancy; however, a more natural metric may be\ntheir joint probability distribution discrepancy. Additionally, most metrics\nonly aim to increase the transferability between domains, but ignores the\ndiscriminability between different classes, which may result in insufficient\nclassification performance. To address these issues, discriminative joint\nprobability MMD (DJP-MMD) is proposed in this paper to replace the\nfrequently-used joint MMD in domain adaptation. It has two desirable\nproperties: 1) it provides a new theoretical basis for computing the\ndistribution discrepancy, which is simpler and more accurate; 2) it increases\nthe transferability and discriminability simultaneously. We validate its\nperformance by embedding it into a joint probability domain adaptation\nframework. Experiments on six image classification datasets demonstrated that\nthe proposed DJP-MMD can outperform traditional MMDs.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 04:52:41 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 19:47:44 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 08:04:37 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 15:13:57 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Zhang", "Wen", ""], ["Wu", "Dongrui", ""]]}, {"id": "1912.00330", "submitter": "Zhaoyuan Gu", "authors": "Zhaoyuan Gu, Zhenzhong Jia, Howie Choset", "title": "Adversary A3C for Robust Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous Advantage Actor Critic (A3C) is an effective Reinforcement\nLearning (RL) algorithm for a wide range of tasks, such as Atari games and\nrobot control. The agent learns policies and value function through\ntrial-and-error interactions with the environment until converging to an\noptimal policy. Robustness and stability are critical in RL; however, neural\nnetwork can be vulnerable to noise from unexpected sources and is not likely to\nwithstand very slight disturbances. We note that agents generated from mild\nenvironment using A3C are not able to handle challenging environments. Learning\nfrom adversarial examples, we proposed an algorithm called Adversary Robust A3C\n(AR-A3C) to improve the agent's performance under noisy environments. In this\nalgorithm, an adversarial agent is introduced to the learning process to make\nit more robust against adversarial disturbances, thereby making it more\nadaptive to noisy environments. Both simulations and real-world experiments are\ncarried out to illustrate the stability of the proposed algorithm. The AR-A3C\nalgorithm outperforms A3C in both clean and noisy environments.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 06:26:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gu", "Zhaoyuan", ""], ["Jia", "Zhenzhong", ""], ["Choset", "Howie", ""]]}, {"id": "1912.00331", "submitter": "Vikram Krishnamurthy", "authors": "Vikram Krishnamurthy and Daniel Angley and Robin Evans and William\n  Moran", "title": "Identifying Cognitive Radars -- Inverse Reinforcement Learning using\n  Revealed Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an inverse reinforcement learning problem involving us versus an\nenemy radar equipped with a Bayesian tracker. By observing the emissions of the\nenemy radar,how can we identify if the radar is cognitive (constrained utility\nmaximizer)? Given the observed sequence of actions taken by the enemy's radar,\nwe consider three problems: (i) Are the enemy radar's actions (waveform choice,\nbeam scheduling) consistent with constrained utility maximization? If so how\ncan we estimate the cognitive radar's utility function that is consistent with\nits actions. We formulate and solve the problem in terms of the spectra\n(eigenvalues) of the state and observation noise covariance matrices, and the\nalgebraic Riccati equation. (ii) How to construct a statistical test for\ndetecting a cognitive radar (constrained utility maximization) when we observe\nthe radar's actions in noise or the radar observes our probe signal in noise?\nWe propose a statistical detector with a tight Type-II error bound. (iii) How\ncan we optimally probe (interrogate) the enemy's radar by choosing our state to\nminimize the Type-II error of detecting if the radar is deploying an economic\nrational strategy, subject to a constraint on the Type-I detection error? We\npresent a stochastic optimization algorithm to optimize our probe signal. The\nmain analysis framework used in this paper is that of revealed preferences from\nmicroeconomics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 06:26:31 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 03:16:16 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 19:30:15 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Krishnamurthy", "Vikram", ""], ["Angley", "Daniel", ""], ["Evans", "Robin", ""], ["Moran", "William", ""]]}, {"id": "1912.00349", "submitter": "Lanqing Xue", "authors": "Lanqing Xue, Xiaopeng Li, Nevin L. Zhang", "title": "Not All Attention Is Needed: Gated Attention Network for Sequence Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks generally have fixed network structures, the\nconcept of dynamic mechanism has drawn more and more attention in recent years.\nAttention mechanisms compute input-dependent dynamic attention weights for\naggregating a sequence of hidden states. Dynamic network configuration in\nconvolutional neural networks (CNNs) selectively activates only part of the\nnetwork at a time for different inputs. In this paper, we combine the two\ndynamic mechanisms for text classification tasks. Traditional attention\nmechanisms attend to the whole sequence of hidden states for an input sentence,\nwhile in most cases not all attention is needed especially for long sequences.\nWe propose a novel method called Gated Attention Network (GA-Net) to\ndynamically select a subset of elements to attend to using an auxiliary\nnetwork, and compute attention weights to aggregate the selected elements. It\navoids a significant amount of unnecessary computation on unattended elements,\nand allows the model to pay attention to important parts of the sequence.\nExperiments in various datasets show that the proposed method achieves better\nperformance compared with all baseline models with global or local attention\nwhile requiring less computation and achieving better interpretability. It is\nalso promising to extend the idea to more complex attention-based models, such\nas transformers and seq-to-seq models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 07:57:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Xue", "Lanqing", ""], ["Li", "Xiaopeng", ""], ["Zhang", "Nevin L.", ""]]}, {"id": "1912.00350", "submitter": "Defang Chen", "authors": "Defang Chen, Jian-Ping Mei, Can Wang, Yan Feng, Chun Chen", "title": "Online Knowledge Distillation with Diverse Peers", "comments": "Accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation is an effective knowledge-transfer technique that uses predicted\ndistributions of a powerful teacher model as soft targets to train a\nless-parameterized student model. A pre-trained high capacity teacher, however,\nis not always available. Recently proposed online variants use the aggregated\nintermediate predictions of multiple student models as targets to train each\nstudent model. Although group-derived targets give a good recipe for\nteacher-free distillation, group members are homogenized quickly with simple\naggregation functions, leading to early saturated solutions. In this work, we\npropose Online Knowledge Distillation with Diverse peers (OKDDip), which\nperforms two-level distillation during training with multiple auxiliary peers\nand one group leader. In the first-level distillation, each auxiliary peer\nholds an individual set of aggregation weights generated with an\nattention-based mechanism to derive its own targets from predictions of other\nauxiliary peers. Learning from distinct target distributions helps to boost\npeer diversity for effectiveness of group-based distillation. The second-level\ndistillation is performed to transfer the knowledge in the ensemble of\nauxiliary peers further to the group leader, i.e., the model used for\ninference. Experimental results show that the proposed framework consistently\ngives better performance than state-of-the-art approaches without sacrificing\ntraining or inference complexity, demonstrating the effectiveness of the\nproposed two-level distillation framework.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 08:19:09 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 11:59:14 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Chen", "Defang", ""], ["Mei", "Jian-Ping", ""], ["Wang", "Can", ""], ["Feng", "Yan", ""], ["Chen", "Chun", ""]]}, {"id": "1912.00354", "submitter": "Farah Shamout", "authors": "Pulkit Sharma, Farah E Shamout, David A Clifton", "title": "Preserving Patient Privacy while Training a Predictive Model of\n  In-hospital Mortality", "comments": "AI for Social Good Workshop, Neurips 2019, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models can be used for pattern recognition in medical data\nin order to improve patient outcomes, such as the prediction of in-hospital\nmortality. Deep learning models, in particular, require large amounts of data\nfor model training. However, the data is often collected at different hospitals\nand sharing is restricted due to patient privacy concerns. In this paper, we\naimed to demonstrate the potential of distributed training in achieving\nstate-of-the-art performance while maintaining data privacy. Our results show\nthat training the model in the federated learning framework leads to comparable\nperformance to the traditional centralised setting. We also suggest several\nconsiderations for the success of such frameworks in future work.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 08:26:13 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Sharma", "Pulkit", ""], ["Shamout", "Farah E", ""], ["Clifton", "David A", ""]]}, {"id": "1912.00362", "submitter": "Ke Ma", "authors": "Ke Ma and Jinshan Zeng and Qianqian Xu and Xiaochun Cao and Wei Liu\n  and Yuan Yao", "title": "Fast Stochastic Ordinal Embedding with Variance Reduction and Adaptive\n  Step Size", "comments": "19 pages, 5 figures, accepted by IEEE Transaction on Knowledge and\n  Data Engineering, Conference Version: arXiv:1711.06446", "journal-ref": null, "doi": "10.1109/TKDE.2019.2956700", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation from relative similarity comparisons, often called\nordinal embedding, gains rising attention in recent years. Most of the existing\nmethods are based on semi-definite programming (\\textit{SDP}), which is\ngenerally time-consuming and degrades the scalability, especially confronting\nlarge-scale data. To overcome this challenge, we propose a stochastic algorithm\ncalled \\textit{SVRG-SBB}, which has the following features: i) achieving good\nscalability via dropping positive semi-definite (\\textit{PSD}) constraints as\nserving a fast algorithm, i.e., stochastic variance reduced gradient\n(\\textit{SVRG}) method, and ii) adaptive learning via introducing a new,\nadaptive step size called the stabilized Barzilai-Borwein (\\textit{SBB}) step\nsize. Theoretically, under some natural assumptions, we show the\n$\\boldsymbol{O}(\\frac{1}{T})$ rate of convergence to a stationary point of the\nproposed algorithm, where $T$ is the number of total iterations. Under the\nfurther Polyak-\\L{}ojasiewicz assumption, we can show the global linear\nconvergence (i.e., exponentially fast converging to a global optimum) of the\nproposed algorithm. Numerous simulations and real-world data experiments are\nconducted to show the effectiveness of the proposed algorithm by comparing with\nthe state-of-the-art methods, notably, much lower computational cost with good\nprediction performance.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 09:05:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ma", "Ke", ""], ["Zeng", "Jinshan", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Liu", "Wei", ""], ["Yao", "Yuan", ""]]}, {"id": "1912.00370", "submitter": "Mahdi Abolghasemi", "authors": "Mahdi Abolghasemi, Rob J Hyndman, Garth Tarr, Christoph Bergmeir", "title": "Machine learning applications in time series hierarchical forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical forecasting (HF) is needed in many situations in the supply\nchain (SC) because managers often need different levels of forecasts at\ndifferent levels of SC to make a decision. Top-Down (TD), Bottom-Up (BU) and\nOptimal Combination (COM) are common HF models. These approaches are static and\noften ignore the dynamics of the series while disaggregating them.\nConsequently, they may fail to perform well if the investigated group of time\nseries are subject to large changes such as during the periods of promotional\nsales. We address the HF problem of predicting real-world sales time series\nthat are highly impacted by promotion. We use three machine learning (ML)\nmodels to capture sales variations over time. Artificial neural networks (ANN),\nextreme gradient boosting (XGboost), and support vector regression (SVR)\nalgorithms are used to estimate the proportions of lower-level time series from\nthe upper level. We perform an in-depth analysis of 61 groups of time series\nwith different volatilities and show that ML models are competitive and\noutperform some well-established models in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 09:49:42 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Abolghasemi", "Mahdi", ""], ["Hyndman", "Rob J", ""], ["Tarr", "Garth", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "1912.00385", "submitter": "Ismail Elezi", "authors": "Ismail Elezi, Sebastiano Vascon, Alessandro Torcinovich, Marcello\n  Pelillo, Laura Leal-Taixe", "title": "The Group Loss for Deep Metric Learning", "comments": "Accepted to European Conference on Computer Vision (ECCV) 2020,\n  includes non-archival supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning has yielded impressive results in tasks such as\nclustering and image retrieval by leveraging neural networks to obtain highly\ndiscriminative feature embeddings, which can be used to group samples into\ndifferent classes. Much research has been devoted to the design of smart loss\nfunctions or data mining strategies for training such networks. Most methods\nconsider only pairs or triplets of samples within a mini-batch to compute the\nloss function, which is commonly based on the distance between embeddings. We\npropose Group Loss, a loss function based on a differentiable label-propagation\nmethod that enforces embedding similarity across all samples of a group while\npromoting, at the same time, low-density regions amongst data points belonging\nto different groups. Guided by the smoothness assumption that \"similar objects\nshould belong to the same group\", the proposed loss trains the neural network\nfor a classification task, enforcing a consistent labelling amongst samples\nwithin a class. We show state-of-the-art results on clustering and image\nretrieval on several datasets, and show the potential of our method when\ncombined with other techniques such as ensembles\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 11:09:57 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 20:19:30 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 03:32:58 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 17:28:44 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Elezi", "Ismail", ""], ["Vascon", "Sebastiano", ""], ["Torcinovich", "Alessandro", ""], ["Pelillo", "Marcello", ""], ["Leal-Taixe", "Laura", ""]]}, {"id": "1912.00386", "submitter": "Heeyoul Choi", "authors": "Hayoung Um and Heeyoul Choi", "title": "Active Search for Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pattern recognition or machine learning, it is a very fundamental task to\nfind nearest neighbors of a given point. All the methods for the task work\nbasically by comparing the given point to all the points in the data set. That\nis why the computational cost increases with the number of data points.\nHowever, the human visual system seems to work in a different way. When the\nhuman visual system tries to find the neighbors of one point on a map, it\ndirectly focuses on the area around the point and actively searches the\nneighbors by looking or zooming in and out around the point. In this paper, we\npropose an innovative search method for nearest neighbors, which seems very\nsimilar to how human visual system works on the task.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 11:26:26 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 14:54:30 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Um", "Hayoung", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1912.00398", "submitter": "Lei Yang", "authors": "Rujing Yao, Linlin Hou, Lei Yang, Jie Gui, Qing Yin, and Ou Wu", "title": "Deep Human Answer Understanding for Natural Reverse QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on a reverse question answering (QA) procedure, in which\nmachines proactively raise questions and humans supply the answers. This\nprocedure exists in many real human-machine interaction applications. However,\na crucial problem in human-machine interaction is answer understanding. The\nexisting solutions have relied on mandatory option term selection to avoid\nautomatic answer understanding. However, these solutions have led to unnatural\nhuman-computer interaction and negatively affected user experience. To this\nend, the current study proposes a novel deep answer understanding network,\ncalled AntNet, for reverse QA. The network consists of three new modules,\nnamely, skeleton attention for questions, relevance-aware representation of\nanswers, and multi-hop based fusion. As answer understanding for reverse QA has\nnot been explored, a new data corpus is compiled in this study. Experimental\nresults indicate that our proposed network is significantly better than\nexisting methods and those modified from classical natural language processing\ndeep models. The effectiveness of the three new modules is also verified.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 13:03:03 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 04:35:12 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yao", "Rujing", ""], ["Hou", "Linlin", ""], ["Yang", "Lei", ""], ["Gui", "Jie", ""], ["Yin", "Qing", ""], ["Wu", "Ou", ""]]}, {"id": "1912.00402", "submitter": "Shuhan Zhang", "authors": "Shuhan Zhang, Wenlong Lyu, Fan Yang, Changhao Yan, Dian Zhou, Xuan\n  Zeng", "title": "Bayesian Optimization Approach for Analog Circuit Synthesis Using Neural\n  Network", "comments": null, "journal-ref": "2019 Design, Automation & Test in Europe Conference & Exhibition\n  (DATE)", "doi": "10.23919/DATE.2019.8714788", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bayesian optimization with Gaussian process as surrogate model has been\nsuccessfully applied to analog circuit synthesis. In the traditional Gaussian\nprocess regression model, the kernel functions are defined explicitly. The\ncomputational complexity of training is O(N 3 ), and the computation complexity\nof prediction is O(N 2 ), where N is the number of training data. Gaussian\nprocess model can also be derived from a weight space view, where the original\ndata are mapped to feature space, and the kernel function is defined as the\ninner product of nonlinear features. In this paper, we propose a Bayesian\noptimization approach for analog circuit synthesis using neural network. We use\ndeep neural network to extract good feature representations, and then define\nGaussian process using the extracted features. Model averaging method is\napplied to improve the quality of uncertainty prediction. Compared to Gaussian\nprocess model with explicitly defined kernel functions, the\nneural-network-based Gaussian process model can automatically learn a kernel\nfunction from data, which makes it possible to provide more accurate\npredictions and thus accelerate the follow-up optimization procedure. Also, the\nneural-network-based model has O(N) training time and constant prediction time.\nThe efficiency of the proposed method has been verified by two real-world\nanalog circuits.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 13:13:39 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Shuhan", ""], ["Lyu", "Wenlong", ""], ["Yang", "Fan", ""], ["Yan", "Changhao", ""], ["Zhou", "Dian", ""], ["Zeng", "Xuan", ""]]}, {"id": "1912.00412", "submitter": "Eli Schwartz", "authors": "Sivan Doveh, Eli Schwartz, Chao Xue, Rogerio Feris, Alex Bronstein,\n  Raja Giryes, Leonid Karlinsky", "title": "MetAdapt: Meta-Learned Task-Adaptive Architecture for Few-Shot\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-Shot Learning (FSL) is a topic of rapidly growing interest. Typically, in\nFSL a model is trained on a dataset consisting of many small tasks (meta-tasks)\nand learns to adapt to novel tasks that it will encounter during test time.\nThis is also referred to as meta-learning. Another topic closely related to\nmeta-learning with a lot of interest in the community is Neural Architecture\nSearch (NAS), automatically finding optimal architecture instead of engineering\nit manually. In this work, we combine these two aspects of meta-learning. So\nfar, meta-learning FSL methods have focused on optimizing parameters of\npre-defined network architectures, in order to make them easily adaptable to\nnovel tasks. Moreover, it was observed that, in general, larger architectures\nperform better than smaller ones up to a certain saturation point (where they\nstart to degrade due to over-fitting). However, little attention has been given\nto explicitly optimizing the architectures for FSL, nor to an adaptation of the\narchitecture at test time to particular novel tasks. In this work, we propose\nto employ tools inspired by the Differentiable Neural Architecture Search\n(D-NAS) literature in order to optimize the architecture for FSL without\nover-fitting. Additionally, to make the architecture task adaptive, we propose\nthe concept of `MetAdapt Controller' modules. These modules are added to the\nmodel and are meta-trained to predict the optimal network connections for a\ngiven novel task. Using the proposed approach we observe state-of-the-art\nresults on two popular few-shot benchmarks: miniImageNet and FC100.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 14:04:34 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 09:27:25 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 11:44:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Doveh", "Sivan", ""], ["Schwartz", "Eli", ""], ["Xue", "Chao", ""], ["Feris", "Rogerio", ""], ["Bronstein", "Alex", ""], ["Giryes", "Raja", ""], ["Karlinsky", "Leonid", ""]]}, {"id": "1912.00438", "submitter": "Senthil Yogamani", "authors": "Mohamed Ramzy, Hazem Rashed, Ahmad El Sallab and Senthil Yogamani", "title": "RST-MODNet: Real-time Spatio-temporal Moving Object Detection for\n  Autonomous Driving", "comments": "Accepted for presentation at NeurIPS 2019 Workshop on Machine\n  Learning for Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving Object Detection (MOD) is a critical task for autonomous vehicles as\nmoving objects represent higher collision risk than static ones. The trajectory\nof the ego-vehicle is planned based on the future states of detected moving\nobjects. It is quite challenging as the ego-motion has to be modelled and\ncompensated to be able to understand the motion of the surrounding objects. In\nthis work, we propose a real-time end-to-end CNN architecture for MOD utilizing\nspatio-temporal context to improve robustness. We construct a novel time-aware\narchitecture exploiting temporal motion information embedded within sequential\nimages in addition to explicit motion maps using optical flow images.We\ndemonstrate the impact of our algorithm on KITTI dataset where we obtain an\nimprovement of 8% relative to the baselines. We compare our algorithm with\nstate-of-the-art methods and achieve competitive results on KITTI-Motion\ndataset in terms of accuracy at three times better run-time. The proposed\nalgorithm runs at 23 fps on a standard desktop GPU targeting deployment on\nembedded platforms.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 16:14:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ramzy", "Mohamed", ""], ["Rashed", "Hazem", ""], ["Sallab", "Ahmad El", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1912.00444", "submitter": "Anirudh Srinivasan", "authors": "Anirudh Srinivasan, Dzmitry Bahdanau, Maxime Chevalier-Boisvert and\n  Yoshua Bengio", "title": "Automated curriculum generation for Policy Gradients from Demonstrations", "comments": "Accepted to Deep RL Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a technique that improves the process of training\nan agent (using RL) for instruction following. We develop a training curriculum\nthat uses a nominal number of expert demonstrations and trains the agent in a\nmanner that draws parallels from one of the ways in which humans learn to\nperform complex tasks, i.e by starting from the goal and working backwards. We\ntest our method on the BabyAI platform and show an improvement in sample\nefficiency for some of its tasks compared to a PPO (proximal policy\noptimization) baseline.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:08:34 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Srinivasan", "Anirudh", ""], ["Bahdanau", "Dzmitry", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1912.00455", "submitter": "Armin Zirak", "authors": "Ebrahim Badrestani (1), Behnam Bahrak (2), Ali Elahi (2), Adib\n  Faramarzi (2), Pouria Golshanrad (2), Amin Karimi Monsefi (3), Hamid Mahini\n  (2), Armin Zirak (2) ((1) Sharif University of Technology, (2) University of\n  Tehran, (3) Shahid Beheshti University)", "title": "Real-time Travel Time Estimation Using Matrix Factorization", "comments": "21 pages, 9 figures, This research is fully supported by Tap30 co,\n  All names are listed alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the travel time of any route is of great importance for trip\nplanners, traffic operators, online taxi dispatching and ride-sharing\nplatforms, and navigation provider systems. With the advance of technology,\nmany traveling cars, including online taxi dispatch systems' vehicles are\nequipped with Global Positioning System (GPS) devices that can report the\nlocation of the vehicle every few seconds. This paper uses GPS data and the\nMatrix Factorization techniques to estimate the travel times on all road\nsegments and time intervals simultaneously. We aggregate GPS data into a\nmatrix, where each cell of the original matrix contains the average vehicle\nspeed for a segment and a specific time interval. One of the problems with this\nmatrix is its high sparsity. We use Alternating Least Squares (ALS) method\nalong with a regularization term to factorize the matrix. Since this approach\ncan solve the sparsity problem that arises from the absence of cars in many\nroad segments in a specific time interval, matrix factorization is suitable for\nestimating the travel time. Our comprehensive evaluation results using real\ndata provided by one of the largest online taxi dispatching systems in Iran,\nshows the strength of our proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:03:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Badrestani", "Ebrahim", ""], ["Bahrak", "Behnam", ""], ["Elahi", "Ali", ""], ["Faramarzi", "Adib", ""], ["Golshanrad", "Pouria", ""], ["Monsefi", "Amin Karimi", ""], ["Mahini", "Hamid", ""], ["Zirak", "Armin", ""]]}, {"id": "1912.00458", "submitter": "Leena Chennuru Vankadara", "authors": "Leena Chennuru Vankadara and Debarghya Ghoshdastidar", "title": "On the optimality of kernels for high-dimensional clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the optimality of kernel methods in high-dimensional data\nclustering. Recent works have studied the large sample performance of kernel\nclustering in the high-dimensional regime, where Euclidean distance becomes\nless informative. However, it is unknown whether popular methods, such as\nkernel k-means, are optimal in this regime. We consider the problem of\nhigh-dimensional Gaussian clustering and show that, with the exponential kernel\nfunction, the sufficient conditions for partial recovery of clusters using the\nNP-hard kernel k-means objective matches the known information-theoretic limit\nup to a factor of $\\sqrt{2}$ for large $k$. It also exactly matches the known\nupper bounds for the non-kernel setting. We also show that a semi-definite\nrelaxation of the kernel k-means procedure matches up to constant factors, the\nspectral threshold, below which no polynomial-time algorithm is known to\nsucceed. This is the first work that provides such optimality guarantees for\nthe kernel k-means as well as its convex relaxation. Our proofs demonstrate the\nutility of the less known polynomial concentration results for random variables\nwith exponentially decaying tails in a higher-order analysis of kernel methods.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:05:49 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Vankadara", "Leena Chennuru", ""], ["Ghoshdastidar", "Debarghya", ""]]}, {"id": "1912.00461", "submitter": "Abdullah Hamdi", "authors": "Abdullah Hamdi, Sara Rojas, Ali Thabet, Bernard Ghanem", "title": "AdvPC: Transferable Adversarial Perturbations on 3D Point Clouds", "comments": "Presented at European conference on computer vision (ECCV), 2020. The\n  code is available at https://github.com/ajhamdi/AdvPC", "journal-ref": "ECCV 2020", "doi": "10.1007/978-3-030-58610-2_15", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks, in which\nimperceptible perturbations to their input lead to erroneous network\npredictions. This phenomenon has been extensively studied in the image domain,\nand has only recently been extended to 3D point clouds. In this work, we\npresent novel data-driven adversarial attacks against 3D point cloud networks.\nWe aim to address the following problems in current 3D point cloud adversarial\nattacks: they do not transfer well between different networks, and they are\neasy to defend against via simple statistical methods. To this extent, we\ndevelop a new point cloud attack (dubbed AdvPC) that exploits the input data\ndistribution by adding an adversarial loss, after Auto-Encoder reconstruction,\nto the objective it optimizes. AdvPC leads to perturbations that are resilient\nagainst current defenses, while remaining highly transferable compared to\nstate-of-the-art attacks. We test AdvPC using four popular point cloud\nnetworks: PointNet, PointNet++ (MSG and SSG), and DGCNN. Our proposed attack\nincreases the attack success rate by up to 40% for those transferred to unseen\nnetworks (transferability), while maintaining a high success rate on the\nattacked network. AdvPC also increases the ability to break defenses by up to\n38% as compared to other baselines on the ModelNet40 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:13:23 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 12:16:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hamdi", "Abdullah", ""], ["Rojas", "Sara", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1912.00466", "submitter": "Nupur Kumari", "authors": "Tejus Gupta, Abhishek Sinha, Nupur Kumari, Mayank Singh, Balaji\n  Krishnamurthy", "title": "A Method for Computing Class-wise Universal Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for computing class-specific universal adversarial\nperturbations for deep neural networks. Such perturbations can induce\nmisclassification in a large fraction of images of a specific class. Unlike\nprevious methods that use iterative optimization for computing a universal\nperturbation, the proposed method employs a perturbation that is a linear\nfunction of weights of the neural network and hence can be computed much\nfaster. The method does not require any training data and has no\nhyper-parameters. The attack obtains 34% to 51% fooling rate on\nstate-of-the-art deep neural networks on ImageNet and transfers across models.\nWe also study the characteristics of the decision boundaries learned by\nstandard and adversarially trained models to understand the universal\nadversarial perturbations.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 18:22:14 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gupta", "Tejus", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Singh", "Mayank", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1912.00497", "submitter": "Himangi Mittal", "authors": "Himangi Mittal, Brian Okorn, David Held", "title": "Just Go with the Flow: Self-Supervised Scene Flow Estimation", "comments": "Accepted at CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When interacting with highly dynamic environments, scene flow allows\nautonomous systems to reason about the non-rigid motion of multiple independent\nobjects. This is of particular interest in the field of autonomous driving, in\nwhich many cars, people, bicycles, and other objects need to be accurately\ntracked. Current state-of-the-art methods require annotated scene flow data\nfrom autonomous driving scenes to train scene flow networks with supervised\nlearning. As an alternative, we present a method of training scene flow that\nuses two self-supervised losses, based on nearest neighbors and cycle\nconsistency. These self-supervised losses allow us to train our method on large\nunlabeled autonomous driving datasets; the resulting method matches current\nstate-of-the-art supervised performance using no real world annotations and\nexceeds state-of-the-art performance when combining our self-supervised\napproach with supervised learning on a smaller labeled dataset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 20:32:54 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 19:10:57 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Mittal", "Himangi", ""], ["Okorn", "Brian", ""], ["Held", "David", ""]]}, {"id": "1912.00498", "submitter": "Donghwan Lee", "authors": "Donghwan Lee, Niao He, Parameswaran Kamalaruban, Volkan Cevher", "title": "Optimization for Reinforcement Learning: From Single Agent to\n  Cooperative Agents", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2020.2976000", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews recent advances in multi-agent reinforcement learning\nalgorithms for large-scale control systems and communication networks, which\nlearn to communicate and cooperate. We provide an overview of this emerging\nfield, with an emphasis on the decentralized setting under different\ncoordination protocols. We highlight the evolution of reinforcement learning\nalgorithms from single-agent to multi-agent systems, from a distributed\noptimization perspective, and conclude with future directions and challenges,\nin the hope to catalyze the growing synergy among distributed optimization,\nsignal processing, and reinforcement learning communities.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 20:39:55 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""], ["Kamalaruban", "Parameswaran", ""], ["Cevher", "Volkan", ""]]}, {"id": "1912.00501", "submitter": "Himangi Mittal", "authors": "Himangi Mittal, Ajith Abraham, Anuja Arora", "title": "Interpreting Context of Images using Scene Graphs", "comments": "To appear in International Conference on Big Data Analytics (BDA2019)\n  (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a visual scene incorporates objects, relationships, and\ncontext. Traditional methods working on an image mostly focus on object\ndetection and fail to capture the relationship between the objects.\nRelationships can give rich semantic information about the objects in a scene.\nThe context can be conducive to comprehending an image since it will help us to\nperceive the relation between the objects and thus, give us a deeper insight\ninto the image. Through this idea, our project delivers a model that focuses on\nfinding the context present in an image by representing the image as a graph,\nwhere the nodes will the objects and edges will be the relation between them.\nThe context is found using the visual and semantic cues which are further\nconcatenated and given to the Support Vector Machines (SVM) to detect the\nrelation between two objects. This presents us with the context of the image\nwhich can be further used in applications such as similar image retrieval,\nimage captioning, or story generation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 21:32:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Mittal", "Himangi", ""], ["Abraham", "Ajith", ""], ["Arora", "Anuja", ""]]}, {"id": "1912.00508", "submitter": "Chang Li", "authors": "Chang Li, Haoyun Feng and Maarten de Rijke", "title": "Cascading Hybrid Bandits: Online Learning to Rank for Relevance and\n  Diversity", "comments": null, "journal-ref": null, "doi": "10.1145/3383313.3412245", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance ranking and result diversification are two core areas in modern\nrecommender systems. Relevance ranking aims at building a ranked list sorted in\ndecreasing order of item relevance, while result diversification focuses on\ngenerating a ranked list of items that covers a broad range of topics. In this\npaper, we study an online learning setting that aims to recommend a ranked list\nwith $K$ items that maximizes the ranking utility, i.e., a list whose items are\nrelevant and whose topics are diverse. We formulate it as the cascade hybrid\nbandits (CHB) problem. CHB assumes the cascading user behavior, where a user\nbrowses the displayed list from top to bottom, clicks the first attractive\nitem, and stops browsing the rest. We propose a hybrid contextual bandit\napproach, called CascadeHybrid, for solving this problem. CascadeHybrid models\nitem relevance and topical diversity using two independent functions and\nsimultaneously learns those functions from user click feedback. We conduct\nexperiments to evaluate CascadeHybrid on two real-world recommendation\ndatasets: MovieLens and Yahoo music datasets. Our experimental results show\nthat CascadeHybrid outperforms the baselines. In addition, we prove theoretical\nguarantees on the $n$-step performance demonstrating the soundness of\nCascadeHybrid.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 22:03:18 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 16:57:55 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 06:46:20 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Li", "Chang", ""], ["Feng", "Haoyun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1912.00509", "submitter": "Matheus Werner", "authors": "Matheus Werner, Eduardo Laber", "title": "Speeding up Word Mover's Distance and its variants via properties of\n  distances between embeddings", "comments": "Author's final version, accepted for publication at ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Mover's Distance (WMD) proposed by Kusner et al. is a distance\nbetween documents that takes advantage of semantic relations among words that\nare captured by their embeddings. This distance proved to be quite effective,\nobtaining state-of-art error rates for classification tasks, but is also\nimpracticable for large collections/documents due to its computational\ncomplexity. For circumventing this problem, variants of WMD have been proposed.\nAmong them, Relaxed Word Mover's Distance (RWMD) is one of the most successful\ndue to its simplicity, effectiveness, and also because of its fast\nimplementations.\n  Relying on assumptions that are supported by empirical properties of the\ndistances between embeddings, we propose an approach to speed up both WMD and\nRWMD. Experiments over 10 datasets suggest that our approach leads to a\nsignificant speed-up in document classification tasks while maintaining the\nsame error rates.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 22:08:32 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 18:51:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Werner", "Matheus", ""], ["Laber", "Eduardo", ""]]}, {"id": "1912.00512", "submitter": "Ugur Kursuncu", "authors": "Ugur Kursuncu, Manas Gaur and Amit Sheth", "title": "Knowledge Infused Learning (K-IL): Towards Deep Incorporation of\n  Knowledge in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning the underlying patterns in data goes beyond instance-based\ngeneralization to external knowledge represented in structured graphs or\nnetworks. Deep learning that primarily constitutes neural computing stream in\nAI has shown significant advances in probabilistically learning latent patterns\nusing a multi-layered network of computational nodes (i.e., neurons/hidden\nunits). Structured knowledge that underlies symbolic computing approaches and\noften supports reasoning, has also seen significant growth in recent years, in\nthe form of broad-based (e.g., DBPedia, Yago) and domain, industry or\napplication specific knowledge graphs. A common substrate with careful\nintegration of the two will raise opportunities to develop neuro-symbolic\nlearning approaches for AI, where conceptual and probabilistic representations\nare combined. As the incorporation of external knowledge will aid in\nsupervising the learning of features for the model, deep infusion of\nrepresentational knowledge from knowledge graphs within hidden layers will\nfurther enhance the learning process. Although much work remains, we believe\nthat knowledge graphs will play an increasing role in developing hybrid\nneuro-symbolic intelligent systems (bottom-up deep learning with top-down\nsymbolic computing) as well as in building explainable AI systems for which\nknowledge graphs will provide scaffolding for punctuating neural computing. In\nthis position paper, we describe our motivation for such a neuro-symbolic\napproach and framework that combines knowledge graph and neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 22:36:14 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 05:26:23 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kursuncu", "Ugur", ""], ["Gaur", "Manas", ""], ["Sheth", "Amit", ""]]}, {"id": "1912.00513", "submitter": "Kai Yang", "authors": "Kai Yang, Tao Fan, Tianjian Chen, Yuanming Shi, Qiang Yang", "title": "A Quasi-Newton Method Based Vertical Federated Learning Framework for\n  Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy and security becomes a major concern in building machine\nlearning models from different data providers. Federated learning shows promise\nby leaving data at providers locally and exchanging encrypted information. This\npaper studies the vertical federated learning structure for logistic regression\nwhere the data sets at two parties have the same sample IDs but own disjoint\nsubsets of features. Existing frameworks adopt the first-order stochastic\ngradient descent algorithm, which requires large number of communication\nrounds. To address the communication challenge, we propose a quasi-Newton\nmethod based vertical federated learning framework for logistic regression\nunder the additively homomorphic encryption scheme. Our approach can\nconsiderably reduce the number of communication rounds with a little additional\ncommunication cost per round. Numerical results demonstrate the advantages of\nour approach over the first-order method.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 22:36:50 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 02:18:12 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Yang", "Kai", ""], ["Fan", "Tao", ""], ["Chen", "Tianjian", ""], ["Shi", "Yuanming", ""], ["Yang", "Qiang", ""]]}, {"id": "1912.00519", "submitter": "Jayanta Dey", "authors": "Jayanta Dey, Mohammad Ariful Haque", "title": "Location Forensics of Media Recordings Utilizing Cascaded SVM and\n  Pole-matching Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Information regarding the location of power distribution grid can be\nextracted from the power signature embedded in the multimedia signals (e.g.,\naudio, video data) recorded near electrical activities. This implicit mechanism\nof identifying the origin-of-recording can be a very promising tool for\nmultimedia forensics and security applications. In this work, we have developed\na novel grid-of-origin identification system from media recording that consists\nof a number of support vector machine (SVM) followed by pole-matching (PM)\nclassifiers. First, we determine the nominal frequency of the grid (50 or 60\nHz) based on the spectral observation. Then an SVM classifier, trained for the\ndetection of a grid with a particular nominal frequency, narrows down the list\nof possible grids on the basis of different discriminating features extracted\nfrom the electric network frequency (ENF) signal. The decision of the SVM\nclassifier is then passed to the PM classifier that detects the final grid\nbased on the minimum distance between the estimated poles of test and training\ngrids. Thus, we start from the problem of classifying grids with different\nnominal frequencies and simplify the problem of classification in three stages\nbased on nominal frequency, SVM and finally using PM classifier. This cascaded\nsystem of classification ensures better accuracy (15.57% higher) compared to\ntraditional ENF-based SVM classifiers described in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 23:20:00 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Dey", "Jayanta", ""], ["Haque", "Mohammad Ariful", ""]]}, {"id": "1912.00520", "submitter": "Maxim Borisyak", "authors": "Maxim Borisyak, Tatiana Gaintseva, Andrey Ustyuzhanin", "title": "Adaptive Divergence for Rapid Adversarial Optimization", "comments": null, "journal-ref": "PeerJ Computer Science. 2020 May;6:e274", "doi": "10.7717/peerj-cs.274", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Optimization (AO) provides a reliable, practical way to match two\nimplicitly defined distributions, one of which is usually represented by a\nsample of real data, and the other is defined by a generator. Typically, AO\ninvolves training of a high-capacity model on each step of the optimization. In\nthis work, we consider computationally heavy generators, for which training of\nhigh-capacity models is associated with substantial computational costs. To\naddress this problem, we introduce a novel family of divergences, which varies\nthe capacity of the underlying model, and allows for a significant acceleration\nwith respect to the number of samples drawn from the generator. We demonstrate\nthe performance of the proposed divergences on several tasks, including tuning\nparameters of a physics simulator, namely, Pythia event generator.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 23:29:56 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Borisyak", "Maxim", ""], ["Gaintseva", "Tatiana", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "1912.00524", "submitter": "Namjoon Suh", "authors": "Namjoon Suh, Xiaoming Huo, Eric Heim, Lee Seversky", "title": "Factor Analysis on Citation, Using a Combined Latent and Logistic\n  Regression Model", "comments": "Citation network, matrix decomposition, latent variable model,\n  logistic regression model, convex optimization, alternating direction method\n  of multiplier", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a combined model, which integrates the latent factor model and the\nlogistic regression model, for the citation network. It is noticed that neither\na latent factor model nor a logistic regression model alone is sufficient to\ncapture the structure of the data. The proposed model has a latent (i.e.,\nfactor analysis) model to represents the main technological trends (a.k.a.,\nfactors), and adds a sparse component that captures the remaining ad-hoc\ndependence. Parameter estimation is carried out through the construction of a\njoint-likelihood function of edges and properly chosen penalty terms. The\nconvexity of the objective function allows us to develop an efficient\nalgorithm, while the penalty terms push towards a low-dimensional latent\ncomponent and a sparse graphical structure. Simulation results show that the\nproposed method works well in practical situations. The proposed method has\nbeen applied to a real application, which contains a citation network of\nstatisticians (Ji and Jin, 2016). Some interesting findings are reported.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 00:04:10 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Suh", "Namjoon", ""], ["Huo", "Xiaoming", ""], ["Heim", "Eric", ""], ["Seversky", "Lee", ""]]}, {"id": "1912.00527", "submitter": "Xiru Zhu", "authors": "Xiru Zhu, Fengdi Che (Equal Contribution), Tianzi Yang, Tzuyang Yu,\n  David Meger, Gregory Dudek", "title": "Detecting GAN generated errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite an impressive performance from the latest GAN for generating\nhyper-realistic images, GAN discriminators have difficulty evaluating the\nquality of an individual generated sample. This is because the task of\nevaluating the quality of a generated image differs from deciding if an image\nis real or fake. A generated image could be perfect except in a single area but\nstill be detected as fake. Instead, we propose a novel approach for detecting\nwhere errors occur within a generated image. By collaging real images with\ngenerated images, we compute for each pixel, whether it belongs to the real\ndistribution or generated distribution. Furthermore, we leverage attention to\nmodel long-range dependency; this allows detection of errors which are\nreasonable locally but not holistically. For evaluation, we show that our error\ndetection can act as a quality metric for an individual image, unlike FID and\nIS. We leverage Improved Wasserstein, BigGAN, and StyleGAN to show a ranking\nbased on our metric correlates impressively with FID scores. Our work opens the\ndoor for better understanding of GAN and the ability to select the best samples\nfrom a GAN model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 00:24:35 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhu", "Xiru", "", "Equal Contribution"], ["Che", "Fengdi", "", "Equal Contribution"], ["Yang", "Tianzi", ""], ["Yu", "Tzuyang", ""], ["Meger", "David", ""], ["Dudek", "Gregory", ""]]}, {"id": "1912.00528", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji and Behnam Neyshabur and Hanie Sedghi", "title": "The intriguing role of module criticality in the generalization of deep\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the phenomenon that some modules of deep neural networks (DNNs) are\nmore critical than others. Meaning that rewinding their parameter values back\nto initialization, while keeping other modules fixed at the trained parameters,\nresults in a large drop in the network's performance. Our analysis reveals\ninteresting properties of the loss landscape which leads us to propose a\ncomplexity measure, called module criticality, based on the shape of the\nvalleys that connects the initial and final values of the module parameters. We\nformulate how generalization relates to the module criticality, and show that\nthis measure is able to explain the superior generalization performance of some\narchitectures over others, whereas earlier measures fail to do so.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 00:27:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 18:58:50 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 20:39:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Neyshabur", "Behnam", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1912.00535", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Li Cheng, Hossein Ghanei-Yakhdan, and\n  Shohreh Kasaei", "title": "Deep Learning for Visual Tracking: A Comprehensive Survey", "comments": "Accepted Manuscript in IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3046478", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual target tracking is one of the most sought-after yet challenging\nresearch topics in computer vision. Given the ill-posed nature of the problem\nand its popularity in a broad range of real-world scenarios, a number of\nlarge-scale benchmark datasets have been established, on which considerable\nmethods have been developed and demonstrated with significant progress in\nrecent years -- predominantly by recent deep learning (DL)-based methods. This\nsurvey aims to systematically investigate the current DL-based visual tracking\nmethods, benchmark datasets, and evaluation metrics. It also extensively\nevaluates and analyzes the leading visual tracking methods. First, the\nfundamental characteristics, primary motivations, and contributions of DL-based\nmethods are summarized from nine key aspects of: network architecture, network\nexploitation, network training for visual tracking, network objective, network\noutput, exploitation of correlation filter advantages, aerial-view tracking,\nlong-term tracking, and online tracking. Second, popular visual tracking\nbenchmarks and their respective properties are compared, and their evaluation\nmetrics are summarized. Third, the state-of-the-art DL-based methods are\ncomprehensively examined on a set of well-established benchmarks of OTB2013,\nOTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by\nconducting critical analyses of these state-of-the-art trackers quantitatively\nand qualitatively, their pros and cons under various common scenarios are\ninvestigated. It may serve as a gentle use guide for practitioners to weigh\nwhen and under what conditions to choose which method(s). It also facilitates a\ndiscussion on ongoing issues and sheds light on promising research directions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:05:54 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 09:05:50 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Cheng", "Li", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "1912.00536", "submitter": "Bhagya Hettige", "authors": "Bhagya Hettige, Yuan-Fang Li, Weiqing Wang and Wray Buntine", "title": "Gaussian Embedding of Large-scale Attributed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding methods transform high-dimensional and complex graph contents\ninto low-dimensional representations. They are useful for a wide range of graph\nanalysis tasks including link prediction, node classification, recommendation\nand visualization. Most existing approaches represent graph nodes as point\nvectors in a low-dimensional embedding space, ignoring the uncertainty present\nin the real-world graphs. Furthermore, many real-world graphs are large-scale\nand rich in content (e.g. node attributes). In this work, we propose GLACE, a\nnovel, scalable graph embedding method that preserves both graph structure and\nnode attributes effectively and efficiently in an end-to-end manner. GLACE\neffectively models uncertainty through Gaussian embeddings, and supports\ninductive inference of new nodes based on their attributes. In our\ncomprehensive experiments, we evaluate GLACE on real-world graphs, and the\nresults demonstrate that GLACE significantly outperforms state-of-the-art\nembedding methods on multiple graph analysis tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:28:08 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hettige", "Bhagya", ""], ["Li", "Yuan-Fang", ""], ["Wang", "Weiqing", ""], ["Buntine", "Wray", ""]]}, {"id": "1912.00537", "submitter": "San Gultekin", "authors": "San Gultekin and John Paisley", "title": "Risk Bounds for Low Cost Bipartite Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite ranking is an important supervised learning problem; however,\nunlike regression or classification, it has a quadratic dependence on the\nnumber of samples. To circumvent the prohibitive sample cost, many recent work\nfocus on stochastic gradient-based methods. In this paper we consider an\nalternative approach, which leverages the structure of the widely-adopted\npairwise squared loss, to obtain a stochastic and low cost algorithm that does\nnot require stochastic gradients or learning rates. Using a novel uniform risk\nbound---based on matrix and vector concentration inequalities---we show that\nthe sample size required for competitive performance against the all-pairs\nbatch algorithm does not have a quadratic dependence. Generalization bounds for\nboth the batch and low cost stochastic algorithms are presented. Experimental\nresults show significant speed gain against the batch algorithm, as well as\ncompetitive performance against state-of-the-art bipartite ranking algorithms\non real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 01:35:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gultekin", "San", ""], ["Paisley", "John", ""]]}, {"id": "1912.00543", "submitter": "Eric Chen", "authors": "Puyang Wang, Eric Z. Chen, Terrence Chen, Vishal M. Patel, Shanhui Sun", "title": "Pyramid Convolutional RNN for MRI Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and accurate MRI image reconstruction from undersampled data is\ncritically important in clinical practice. Compressed sensing based methods are\nwidely used in image reconstruction but the speed is slow due to the iterative\nalgorithms. Deep learning based methods have shown promising advances in recent\nyears. However, recovering the fine details from highly undersampled data is\nstill challenging. In this paper, we introduce a novel deep learning-based\nmethod, Pyramid Convolutional RNN (PC-RNN), to reconstruct the image from\nmultiple scales. We evaluated our model on the fastMRI dataset and the results\nshow that the proposed model achieves significant improvements than other\nmethods and can recover more fine details.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 02:06:46 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 16:50:17 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 14:17:57 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 02:18:32 GMT"}, {"version": "v5", "created": "Mon, 27 Apr 2020 18:18:34 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Wang", "Puyang", ""], ["Chen", "Eric Z.", ""], ["Chen", "Terrence", ""], ["Patel", "Vishal M.", ""], ["Sun", "Shanhui", ""]]}, {"id": "1912.00544", "submitter": "Qipeng Guo", "authors": "Qipeng Guo, Xipeng Qiu, Pengfei Liu, Xiangyang Xue, Zheng Zhang", "title": "Multi-Scale Self-Attention for Text Classification", "comments": "Accepted in AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the prior knowledge, multi-scale structure, into\nself-attention modules. We propose a Multi-Scale Transformer which uses\nmulti-scale multi-head self-attention to capture features from different\nscales. Based on the linguistic perspective and the analysis of pre-trained\nTransformer (BERT) on a huge corpus, we further design a strategy to control\nthe scale distribution for each layer. Results of three different kinds of\ntasks (21 datasets) show our Multi-Scale Transformer outperforms the standard\nTransformer consistently and significantly on small and moderate size datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 02:08:00 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Guo", "Qipeng", ""], ["Qiu", "Xipeng", ""], ["Liu", "Pengfei", ""], ["Xue", "Xiangyang", ""], ["Zhang", "Zheng", ""]]}, {"id": "1912.00547", "submitter": "Alexey Svyatkovskiy", "authors": "Alexey Svyatkovskiy, Kosuke Imai, Mary Kroeger, Yuki Shiraito", "title": "Large-scale text processing pipeline with Apache Spark", "comments": null, "journal-ref": "Published in Proceedings of Big NLP workshop at the IEEE Big Data\n  Conference 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we evaluate Apache Spark for a data-intensive machine learning\nproblem. Our use case focuses on policy diffusion detection across the state\nlegislatures in the United States over time. Previous work on policy diffusion\nhas been unable to make an all-pairs comparison between bills due to\ncomputational intensity. As a substitute, scholars have studied single topic\nareas.\n  We provide an implementation of this analysis workflow as a distributed text\nprocessing pipeline with Spark dataframes and Scala application programming\ninterface. We discuss the challenges and strategies of unstructured data\nprocessing, data formats for storage and efficient access, and graph processing\nat scale.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 02:12:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Svyatkovskiy", "Alexey", ""], ["Imai", "Kosuke", ""], ["Kroeger", "Mary", ""], ["Shiraito", "Yuki", ""]]}, {"id": "1912.00552", "submitter": "Yang Ye", "authors": "Yang Ye, and Shihao Ji", "title": "Sparse Graph Attention Networks", "comments": "Published as a journal paper at IEEE TKDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have proved to be an effective representation\nlearning framework for graph-structured data, and have achieved\nstate-of-the-art performance on many practical predictive tasks, such as node\nclassification, link prediction and graph classification. Among the variants of\nGNNs, Graph Attention Networks (GATs) learn to assign dense attention\ncoefficients over all neighbors of a node for feature aggregation, and improve\nthe performance of many graph learning tasks. However, real-world graphs are\noften very large and noisy, and GATs are prone to overfitting if not\nregularized properly. Even worse, the local aggregation mechanism of GATs may\nfail on disassortative graphs, where nodes within local neighborhood provide\nmore noise than useful information for feature aggregation. In this paper, we\npropose Sparse Graph Attention Networks (SGATs) that learn sparse attention\ncoefficients under an $L_0$-norm regularization, and the learned sparse\nattentions are then used for all GNN layers, resulting in an edge-sparsified\ngraph. By doing so, we can identify noisy/task-irrelevant edges, and thus\nperform feature aggregation on most informative neighbors. Extensive\nexperiments on synthetic and real-world graph learning benchmarks demonstrate\nthe superior performance of SGATs. In particular, SGATs can remove about\n50\\%-80\\% edges from large assortative graphs, while retaining similar\nclassification accuracies. On disassortative graphs, SGATs prune majority of\nnoisy edges and outperform GATs in classification accuracies by significant\nmargins. Furthermore, the removed edges can be interpreted intuitively and\nquantitatively. To the best of our knowledge, this is the first graph learning\nalgorithm that shows significant redundancies in graphs and edge-sparsified\ngraphs can achieve similar or sometimes higher predictive performances than\noriginal graphs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 02:25:01 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 02:54:26 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ye", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "1912.00554", "submitter": "Hiroyasu Ando", "authors": "Hiroyasu Ando and Hanten Chang", "title": "Road traffic reservoir computing", "comments": "Submitted to ESANN 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing derived from recurrent neural networks is more applicable\nto real world systems than deep learning because of its low computational cost\nand potential for physical implementation. Specifically, physical reservoir\ncomputing, which replaces the dynamics of reservoir units with physical\nphenomena, has recently received considerable attention. In this study, we\npropose a method of exploiting the dynamics of road traffic as a reservoir, and\nnumerically confirm its feasibility by applying several prediction tasks based\non a simple mathematical model of the traffic flow.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 02:28:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ando", "Hiroyasu", ""], ["Chang", "Hanten", ""]]}, {"id": "1912.00574", "submitter": "Zhaoyang Lyu", "authors": "Zhaoyang Lyu, Ching-Yun Ko, Zhifeng Kong, Ngai Wong, Dahua Lin, Luca\n  Daniel", "title": "Fastened CROWN: Tightened Neural Network Robustness Certificates", "comments": "Zhaoyang Lyu and Ching-Yun Ko contributed equally, accepted to AAAI\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of deep learning applications in real life is accompanied by\nsevere safety concerns. To mitigate this uneasy phenomenon, much research has\nbeen done providing reliable evaluations of the fragility level in different\ndeep neural networks. Apart from devising adversarial attacks, quantifiers that\ncertify safeguarded regions have also been designed in the past five years. The\nsummarizing work of Salman et al. unifies a family of existing verifiers under\na convex relaxation framework. We draw inspiration from such work and further\ndemonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions\nin a given linear programming problem under mild constraints. Given this\ntheoretical result, the computationally expensive linear programming based\nmethod is shown to be unnecessary. We then propose an optimization-based\napproach \\textit{FROWN} (\\textbf{F}astened C\\textbf{ROWN}): a general algorithm\nto tighten robustness certificates for neural networks. Extensive experiments\non various networks trained individually verify the effectiveness of FROWN in\nsafeguarding larger robust regions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 03:54:20 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lyu", "Zhaoyang", ""], ["Ko", "Ching-Yun", ""], ["Kong", "Zhifeng", ""], ["Wong", "Ngai", ""], ["Lin", "Dahua", ""], ["Daniel", "Luca", ""]]}, {"id": "1912.00583", "submitter": "YeongHyeon Park", "authors": "YeongHyeon Park, Won Seok Park, and Yeong Beom Kim", "title": "Anomaly Detection in Particulate Matter Sensor using Hypothesis Pruning\n  Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World Health Organization (WHO) provides the guideline for managing the\nParticulate Matter (PM) level because when the PM level is higher, it threats\nthe human health. For managing PM level, the procedure for measuring PM value\nis needed firstly. We use Tapered Element Oscillating Microbalance (TEOM)-based\nPM measuring sensors because it shows higher cost-effectiveness than Beta\nAttenuation Monitor (BAM)-based sensor. However, TEOM-based sensor has higher\nprobability of malfunctioning than BAM-based sensor. In this paper, we call the\noverall malfunction as an anomaly, and we aim to detect anomalies for the\nmaintenance of PM measuring sensors. We propose a novel architecture for\nsolving the above aim that named as Hypothesis Pruning Generative Adversarial\nNetwork (HP-GAN). We experimentally compare the several anomaly detection\narchitectures to certify ours performing better.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 05:43:20 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 01:30:31 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Park", "YeongHyeon", ""], ["Park", "Won Seok", ""], ["Kim", "Yeong Beom", ""]]}, {"id": "1912.00589", "submitter": "Ruiqi Gao", "authors": "Ruiqi Gao, Erik Nijkamp, Diederik P. Kingma, Zhen Xu, Andrew M. Dai,\n  Ying Nian Wu", "title": "Flow Contrastive Estimation of Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a training method to jointly estimate an energy-based\nmodel and a flow-based model, in which the two models are iteratively updated\nbased on a shared adversarial value function. This joint training method has\nthe following traits. (1) The update of the energy-based model is based on\nnoise contrastive estimation, with the flow model serving as a strong noise\ndistribution. (2) The update of the flow model approximately minimizes the\nJensen-Shannon divergence between the flow model and the data distribution. (3)\nUnlike generative adversarial networks (GAN) which estimates an implicit\nprobability distribution defined by a generator model, our method estimates two\nexplicit probabilistic distributions on the data. Using the proposed method we\ndemonstrate a significant improvement on the synthesis quality of the flow\nmodel, and show the effectiveness of unsupervised feature learning by the\nlearned energy-based model. Furthermore, the proposed training method can be\neasily adapted to semi-supervised learning. We achieve competitive results to\nthe state-of-the-art semi-supervised learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 06:29:36 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:53:41 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gao", "Ruiqi", ""], ["Nijkamp", "Erik", ""], ["Kingma", "Diederik P.", ""], ["Xu", "Zhen", ""], ["Dai", "Andrew M.", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1912.00594", "submitter": "Shuang Song", "authors": "Shuang Song, David Berthelot, Afshin Rostamizadeh", "title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose using active learning based techniques to further improve the\nstate-of-the-art semi-supervised learning MixMatch algorithm. We provide a\nthorough empirical evaluation of several active-learning and baseline methods,\nwhich successfully demonstrate a significant improvement on the benchmark\nCIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy).\nWe also provide an empirical analysis of the cost trade-off between\nincrementally gathering more labeled versus unlabeled data. This analysis can\nbe used to measure the relative value of labeled/unlabeled data at different\npoints of the learning curve, where we find that although the incremental value\nof labeled data can be as much as 20x that of unlabeled, it quickly diminishes\nto less than 3x once more than 2,000 labeled example are observed. Code can be\nfound at https://github.com/google-research/mma.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 06:39:47 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 01:57:47 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Song", "Shuang", ""], ["Berthelot", "David", ""], ["Rostamizadeh", "Afshin", ""]]}, {"id": "1912.00596", "submitter": "Samuel Earp", "authors": "Samuel W. F. Earp, Pavit Noinongyao, Justin A. Cairns and Ankush\n  Ganguly", "title": "Face Detection with Feature Pyramids and Landmarks", "comments": "12 pages, 2 figures, whitepaper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate face detection and facial landmark localization are crucial to any\nface recognition system. We present a series of three single-stage RCNNs with\ndifferent sized backbones (MobileNetV2-25, MobileNetV2-100, and ResNet101) and\na six-layer feature pyramid trained exclusively on the WIDER FACE dataset. We\ncompare the face detection and landmark accuracies using eight context module\narchitectures, four proposed by previous research and four modified versions.\nWe find no evidence that any of the proposed architectures significantly\noverperform and postulate that the random initialization of the additional\nlayers is at least of equal importance. To show this we present a model that\nachieves near state-of-the-art performance on WIDER FACE and also provides high\naccuracy landmarks with a simple context module. We also present results using\nMobileNetV2 backbones, which achieve over 90% average precision on the WIDER\nFACE hard validation set while being able to run in real-time. By comparing to\nother authors, we show that our models exceed the state-of-the-art for\nsimilar-sized RCNNs and match the performance of much heavier networks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 06:54:13 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 03:39:25 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Earp", "Samuel W. F.", ""], ["Noinongyao", "Pavit", ""], ["Cairns", "Justin A.", ""], ["Ganguly", "Ankush", ""]]}, {"id": "1912.00600", "submitter": "Wenjie Sun", "authors": "Meng Qiao, Zheng Shan, Fudong Liu, Wenjie Sun", "title": "A Fast Matrix-Completion-Based Approach for Recommendation Systems", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is widely used in machine learning, engineering control,\nimage processing, and recommendation systems. Currently, a popular algorithm\nfor matrix completion is Singular Value Threshold (SVT). In this algorithm, the\nsingular value threshold should be set first. However, in a recommendation\nsystem, the dimension of the preference matrix keeps changing. Therefore, it is\ndifficult to directly apply SVT. In addition, what the users of a\nrecommendation system need is a sequence of personalized recommended results\nrather than the estimation of their scores. According to the above ideas, this\npaper proposes a novel approach named probability completion model~(PCM). By\nreducing the data dimension, the transitivity of the similar matrix, and\nsingular value decomposition, this approach quickly obtains a completion matrix\nwith the same probability distribution as the original matrix. The approach\ngreatly reduces the computation time based on the accuracy of the sacrifice\npart, and can quickly obtain a low-rank similarity matrix with data trend\napproximation properties. The experimental results show that PCM can quickly\ngenerate a complementary matrix with similar data trends as the original\nmatrix. The LCS score and efficiency of PCM are both higher than SVT.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:10:24 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 00:27:33 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Qiao", "Meng", ""], ["Shan", "Zheng", ""], ["Liu", "Fudong", ""], ["Sun", "Wenjie", ""]]}, {"id": "1912.00602", "submitter": "Chunnnan Wang", "authors": "Chunnan Wang, Hongzhi Wang, Chang Zhou, Hanxiao Chen", "title": "ExperienceThinking: Constrained Hyperparameter Optimization based on\n  Knowledge and Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are very sensitive to the hyperparameters, and\ntheir evaluations are generally expensive. Users desperately need intelligent\nmethods to quickly optimize hyperparameter settings according to known\nevaluation information, and thus reduce computational cost and promote\noptimization efficiency. Motivated by this, we propose ExperienceThinking\nalgorithm to quickly find the best possible hyperparameter configuration of\nmachine learning algorithms within a few configuration evaluations.\nExperienceThinking design two novel methods, which intelligently infer optimal\nconfigurations from two aspects: search space pruning and knowledge utilization\nrespectively. Two methods complement each other and solve the constrained\nhyperparameter optimization problems effectively. To demonstrate the benefit of\nExperienceThinking, we compare it with 3 classical hyperparameter optimization\nalgorithms with a small number of configuration evaluations. The experimental\nresults present that our proposed algorithm provides superior results and\nachieve better performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:21:05 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 05:48:17 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Chunnan", ""], ["Wang", "Hongzhi", ""], ["Zhou", "Chang", ""], ["Chen", "Hanxiao", ""]]}, {"id": "1912.00605", "submitter": "Yina Han", "authors": "Yina Han, Yuyan Li, Qingyu Liu, Yuanliang Ma", "title": "DeepLofargram: A Deep Learning based Fluctuating Dim Frequency Line\n  Detection and Recovery", "comments": null, "journal-ref": null, "doi": "10.1121/10.0002172", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of dim frequency line detection and\nrecovery in the so-called lofargram. Theoretically, time integration long\nenough can always enhance the detection characteristic. But this does not hold\nfor irregularly fluctuating lines. Deep learning has been shown to perform very\nwell for sophisticated visual inference tasks. With the composition of multiple\nprocessing layers, very complex high level representation that amplify the\nimportant aspects of input while suppresses irrelevant variations can be\nlearned. Hence we propose a new DeepLofargram, composed of deep convolutional\nneural network and its visualization counterpart. Plugging into specifically\ndesigned multi-task loss, an end-to-end training jointly learns to detect and\nrecover the spatial location of potential lines. Leveraging on this deep\narchitecture, the performance boundary is -24dB on average, and -26dB for some.\nThis is far beyond the perception of human visual and significantly improves\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:28:54 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Han", "Yina", ""], ["Li", "Yuyan", ""], ["Liu", "Qingyu", ""], ["Ma", "Yuanliang", ""]]}, {"id": "1912.00606", "submitter": "Sivan Doveh", "authors": "Sivan Doveh, Raja Giryes", "title": "DEGAS: Differentiable Efficient Generator Search", "comments": "appeared at NeurIPS 2019, Meta-Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network architecture search (NAS) achieves state-of-the-art results in\nvarious tasks such as classification and semantic segmentation. Recently, a\nreinforcement learning-based approach has been proposed for Generative\nAdversarial Networks (GANs) search. In this work, we propose an alternative\nstrategy for GAN search by using a method called DEGAS (Differentiable\nEfficient GenerAtor Search), which focuses on efficiently finding the generator\nin the GAN. Our search algorithm is inspired by the differential architecture\nsearch strategy and the Global Latent Optimization (GLO) procedure. This leads\nto both an efficient and stable GAN search. After the generator architecture is\nfound, it can be plugged into any existing framework for GAN training. For\nCTGAN, which we use in this work, the new model outperforms the original\ninception score results by 0.25 for CIFAR-10 and 0.77 for STL. It also gets\nbetter results than the RL based GAN search methods in shorter search time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:30:28 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 12:16:46 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 08:01:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Doveh", "Sivan", ""], ["Giryes", "Raja", ""]]}, {"id": "1912.00609", "submitter": "Yabing Zhu", "authors": "Yabing Zhu, Yanfeng Zhang, Huili Yang and Fangjing Wang", "title": "GANCoder: An Automatic Natural Language-to-Programming Language\n  Translation Approach based on GAN", "comments": "10pages, 4 figures", "journal-ref": "NLPCC 2019: Natural Language Processing and Chinese Computing", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose GANCoder, an automatic programming approach based on Generative\nAdversarial Networks (GAN), which can generate the same functional and logical\nprogramming language codes conditioned on the given natural language\nutterances. The adversarial training between generator and discriminator helps\ngenerator learn distribution of dataset and improve code generation quality.\nOur experimental results show that GANCoder can achieve comparable accuracy\nwith the state-of-the-art methods and is more stable when programming\nlanguages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:41:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhu", "Yabing", ""], ["Zhang", "Yanfeng", ""], ["Yang", "Huili", ""], ["Wang", "Fangjing", ""]]}, {"id": "1912.00612", "submitter": "Vladimir Puzyrev", "authors": "Vladimir Puzyrev and Andrei Swidinsky", "title": "Inversion of 1D frequency- and time-domain electromagnetic data with\n  convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.IV physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inversion of electromagnetic data finds applications in many areas of\ngeophysics. The inverse problem is commonly solved with either deterministic\noptimization methods (such as the nonlinear conjugate gradient or Gauss-Newton)\nwhich are prone to getting trapped in a local minimum, or probabilistic methods\nwhich are very computationally demanding. A recently emerging alternative is to\nemploy deep neural networks for predicting subsurface model properties from\nmeasured data. This approach is entirely data-driven, does not employ\ntraditional gradient-based techniques and provides a guess to the model\ninstantaneously. In this study, we apply deep convolutional neural networks for\n1D inversion of marine frequency-domain controlled-source electromagnetic\n(CSEM) data as well as onshore time-domain electromagnetic (TEM) data. Our\napproach yields accurate results both on synthetic and real data and provides\nthem instantaneously. Using several networks and combining their outputs from\nvarious training epochs can also provide insights into the uncertainty\ndistribution, which is found to be higher in the regions where resistivity\nanomalies are present. The proposed method opens up possibilities to estimate\nthe subsurface resistivity distribution in exploration scenarios in real time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:54:36 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Puzyrev", "Vladimir", ""], ["Swidinsky", "Andrei", ""]]}, {"id": "1912.00623", "submitter": "Eric Brachmann", "authors": "Aritra Bhowmik, Stefan Gumhold, Carsten Rother, Eric Brachmann", "title": "Reinforced Feature Points: Optimizing Feature Detection and Description\n  for a High-Level Task", "comments": "CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a core problem of computer vision: Detection and description of 2D\nfeature points for image matching. For a long time, hand-crafted designs, like\nthe seminal SIFT algorithm, were unsurpassed in accuracy and efficiency.\nRecently, learned feature detectors emerged that implement detection and\ndescription using neural networks. Training these networks usually resorts to\noptimizing low-level matching scores, often pre-defining sets of image patches\nwhich should or should not match, or which should or should not contain key\npoints. Unfortunately, increased accuracy for these low-level matching scores\ndoes not necessarily translate to better performance in high-level vision\ntasks. We propose a new training methodology which embeds the feature detector\nin a complete vision pipeline, and where the learnable parameters are trained\nin an end-to-end fashion. We overcome the discrete nature of key point\nselection and descriptor matching using principles from reinforcement learning.\nAs an example, we address the task of relative pose estimation between a pair\nof images. We demonstrate that the accuracy of a state-of-the-art\nlearning-based feature detector can be increased when trained for the task it\nis supposed to solve at test time. Our training methodology poses little\nrestrictions on the task to learn, and works for any architecture which\npredicts key point heat maps, and descriptors for key point locations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:23:10 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 08:41:46 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Bhowmik", "Aritra", ""], ["Gumhold", "Stefan", ""], ["Rother", "Carsten", ""], ["Brachmann", "Eric", ""]]}, {"id": "1912.00625", "submitter": "Mikhail Zotov", "authors": "Oleg Kalashev, Maxim Pshirkov, Mikhail Zotov", "title": "Identifying nearby sources of ultra-high-energy cosmic rays with deep\n  learning", "comments": "v2: a major extension of the 1st version, which is kept almost intact\n  as sections 1-4; 21 pages v3: to be published in JCAP. Numbers in tables\n  fixed, a few minor changes, conclusions unchanged. The code and trained\n  models are available at https://github.com/okolo/ml_cr_aniso", "journal-ref": null, "doi": "10.1088/1475-7516/2020/11/005", "report-no": null, "categories": "astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to analyse arrival directions of ultra-high-energy cosmic\nrays (UHECRs) using a classifier defined by a deep convolutional neural network\ntrained on a HEALPix grid. To illustrate a high effectiveness of the method, we\nemploy it to estimate prospects of detecting a large-scale anisotropy of UHECRs\ninduced by a nearby source with an (orbital) detector having a uniform exposure\nof the celestial sphere and compare the results with our earlier calculations\nbased on the angular power spectrum. A minimal model for extragalactic cosmic\nrays and neutrinos by Kachelrie{\\ss}, Kalashev, Ostapchenko and Semikoz (2017)\nis assumed for definiteness and nearby active galactic nuclei Centaurus A, M82,\nNGC 253, M87 and Fornax A are considered as possible sources of UHECRs. We\ndemonstrate that the proposed method drastically improves sensitivity of an\nexperiment by decreasing the minimal required amount of detected UHECRs or the\nminimal detectable fraction of from-source events several times compared to the\napproach based on the angular power spectrum. We also test robustness of the\nneural networks against different models of the large-scale Galactic magnetic\nfields and variations of the mass composition of UHECRs, and consider\nsituations when there are two nearby sources or the dominating source is not\nknown a~priori. In all cases, the neural networks demonstrate good performance\nunless the test models strongly deviate from those used for training. The\nmethod can be readily applied to the analysis of data of the Telescope Array,\nthe Pierre Auger Observatory and other cosmic ray experiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:27:19 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:12:52 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 07:49:27 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Kalashev", "Oleg", ""], ["Pshirkov", "Maxim", ""], ["Zotov", "Mikhail", ""]]}, {"id": "1912.00634", "submitter": "Chenguang Wang", "authors": "Chenguang Wang", "title": "Meta-Path Constrained Random Walk Inference for Large-Scale\n  Heterogeneous Information Networks", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous information network (HIN) has shown its power of modeling real\nworld data as a multi-typed entity-relation graph. Meta-path is the key\ncontributor to this power since it enables inference by capturing the\nproximities between entities via rich semantic links. Previous HIN studies ask\nusers to provide either 1) the meta-path(s) directly or 2) biased examples to\ngenerate the meta-path(s). However, lots of HINs (e.g., YAGO2 and Freebase)\nhave rich schema consisting of a sophisticated and large number of types of\nentities and relations. It is impractical for users to provide the meta-path(s)\nto support the large scale inference, and biased examples will result in\nincorrect meta-path based inference, thus limit the power of the meta-path. In\nthis paper, we propose a meta-path constrained inference framework to further\nrelease the ability of the meta-path, by efficiently learning the HIN inference\npatterns via a carefully designed tree structure; and performing unbiased\nrandom walk inference with little user guidance. The experiment results on\nYAGO2 and DBLP datasets show the state-of-the-art performance of the meta-path\nconstrained inference framework.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:50:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Chenguang", ""]]}, {"id": "1912.00636", "submitter": "Vrettos Moulos", "authors": "Vrettos Moulos", "title": "Optimal Best Markovian Arm Identification with Fixed Confidence", "comments": "Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a complete characterization of the sampling complexity of best\nMarkovian arm identification in one-parameter Markovian bandit models. We\nderive instance specific nonasymptotic and asymptotic lower bounds which\ngeneralize those of the IID setting. We analyze the Track-and-Stop strategy,\ninitially proposed for the IID setting, and we prove that asymptotically it is\nat most a factor of four apart from the lower bound. Our one-parameter\nMarkovian bandit model is based on the notion of an exponential family of\nstochastic matrices for which we establish many useful properties. For the\nanalysis of the Track-and-Stop strategy we derive a novel concentration\ninequality for Markov chains that may be of interest in its own right.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:54:55 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 07:15:56 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 07:36:17 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Moulos", "Vrettos", ""]]}, {"id": "1912.00643", "submitter": "Shreeviknesh Sankaran", "authors": "Sukavanan Nanjundan, Shreeviknesh Sankaran, C.R. Arjun, G. Paavai\n  Anand", "title": "Identifying the number of clusters for K-Means: A hypersphere density\n  based approach", "comments": "5 pages, 13 figures, International Conference on Computers,\n  Communication and Signal Processing - 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of K-Means algorithm is restricted by the fact that the number of\nclusters should be known beforehand. Previously suggested methods to solve this\nproblem are either ad hoc or require parametric assumptions and complicated\ncalculations. The proposed method aims to solve this conundrum by considering\ncluster hypersphere density as the factor to determine the number of clusters\nin the given dataset. The density is calculated by assuming a hypersphere\naround the cluster centroid for n-different number of clusters. The calculated\nvalues are plotted against their corresponding number of clusters and then the\noptimum number of clusters is obtained after assaying the elbow region of the\ngraph. The method is simple, easy to comprehend, and provides robust and\nreliable results.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:12:15 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 17:37:55 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nanjundan", "Sukavanan", ""], ["Sankaran", "Shreeviknesh", ""], ["Arjun", "C. R.", ""], ["Anand", "G. Paavai", ""]]}, {"id": "1912.00646", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Rob Brekelmans, Daniel Moyer, Greg Ver Steeg, Wael\n  AbdAlmageed, Premkumar Natarajan", "title": "Discovery and Separation of Features for Invariant Representation\n  Learning", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning models often associate irrelevant nuisance\nfactors with the prediction target, which hurts generalization. We propose a\nframework for training robust neural networks that induces invariance to\nnuisances through learning to discover and separate predictive and nuisance\nfactors of data. We present an information theoretic formulation of our\napproach, from which we derive training objectives and its connections with\nprevious methods. Empirical results on a wide array of datasets show that the\nproposed framework achieves state-of-the-art performance, without requiring\nnuisance annotations during training.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:17:32 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Brekelmans", "Rob", ""], ["Moyer", "Daniel", ""], ["Steeg", "Greg Ver", ""], ["AbdAlmageed", "Wael", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "1912.00650", "submitter": "Chunlin Ji", "authors": "Chunlin Ji and Haige Shen", "title": "Stochastic Variational Inference via Upper Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference (SVI) plays a key role in Bayesian deep\nlearning. Recently various divergences have been proposed to design the\nsurrogate loss for variational inference. We present a simple upper bound of\nthe evidence as the surrogate loss. This evidence upper bound (EUBO) equals to\nthe log marginal likelihood plus the KL-divergence between the posterior and\nthe proposal. We show that the proposed EUBO is tighter than previous upper\nbounds introduced by $\\chi$-divergence or $\\alpha$-divergence. To facilitate\nscalable inference, we present the numerical approximation of the gradient of\nthe EUBO and apply the SGD algorithm to optimize the variational parameters\niteratively. Simulation study with Bayesian logistic regression shows that the\nupper and lower bounds well sandwich the evidence and the proposed upper bound\nis favorably tight. For Bayesian neural network, the proposed EUBO-VI algorithm\noutperforms state-of-the-art results for various examples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:30:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ji", "Chunlin", ""], ["Shen", "Haige", ""]]}, {"id": "1912.00653", "submitter": "Melanie Schmidt", "authors": "Anup Bhattacharya, Jan Eube, Heiko R\\\"oglin, Melanie Schmidt", "title": "Noisy, Greedy and Not So Greedy k-means++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means++ algorithm due to Arthur and Vassilvitskii has become the most\npopular seeding method for Lloyd's algorithm. It samples the first center\nuniformly at random from the data set and the other $k-1$ centers iteratively\naccording to $D^2$-sampling where the probability that a data point becomes the\nnext center is proportional to its squared distance to the closest center\nchosen so far. k-means++ is known to achieve an approximation factor of $O(\\log\nk)$ in expectation. Already in the original paper on k-means++, Arthur and\nVassilvitskii suggested a variation called greedy k-means++ algorithm in which\nin each iteration multiple possible centers are sampled according to\n$D^2$-sampling and only the one that decreases the objective the most is chosen\nas a center for that iteration. It is stated as an open question whether this\nalso leads to an $O(\\log k)$-approximation (or even better). We show that this\nis not the case by presenting a family of instances on which greedy k-means++\nyields only an $\\Omega(\\ell\\cdot \\log k)$-approximation in expectation where\n$\\ell$ is the number of possible centers that are sampled in each iteration. We\nalso study a variation, which we call noisy k-means++ algorithm. In this\nvariation only one center is sampled in every iteration but not exactly by\n$D^2$-sampling anymore. Instead in each iteration an adversary is allowed to\nchange the probabilities arising from $D^2$-sampling individually for each\npoint by a factor between $1-\\epsilon_1$ and $1+\\epsilon_2$ for parameters\n$\\epsilon_1 \\in [0,1)$ and $\\epsilon_2 \\ge 0$. We prove that noisy k-means++\ncompute an $O(\\log^2 k)$-approximation in expectation. We also discuss some\napplications of this result.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:46:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Eube", "Jan", ""], ["R\u00f6glin", "Heiko", ""], ["Schmidt", "Melanie", ""]]}, {"id": "1912.00656", "submitter": "Niklas Heim", "authors": "Niklas Heim, V\\'aclav \\v{S}m\\'idl, Tom\\'a\\v{s} Pevn\\'y", "title": "Rodent: Relevance determination in differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to identify the generating, ordinary differential equation (ODE) from\na set of trajectories of a partially observed system. Our approach does not\nneed prescribed basis functions to learn the ODE model, but only a rich set of\nNeural Arithmetic Units. For maximal explainability of the learnt model, we\nminimise the state size of the ODE as well as the number of non-zero parameters\nthat are needed to solve the problem. This sparsification is realized through a\ncombination of the Variational Auto-Encoder (VAE) and Automatic Relevance\nDetermination (ARD). We show that it is possible to learn not only one specific\nmodel for a single process, but a manifold of models representing harmonic\nsignals as well as a manifold of Lotka-Volterra systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:56:43 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 11:05:28 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Heim", "Niklas", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "1912.00662", "submitter": "Javier Fernandez", "authors": "Javier Fernandez-Anakabe, Ekhi Zugasti Uriguen and Urko Zurutuza\n  Ortega", "title": "An Attribute Oriented Induction based Methodology for Data Driven\n  Predictive Maintenance", "comments": "Submitted to Journal of Intelligent Manufacturing, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute Oriented Induction (AOI) is a data mining algorithm used for\nextracting knowledge of relational data, taking into account expert knowledge.\nIt is a clustering algorithm that works by transforming the values of the\nattributes and converting an instance into others that are more generic or\nambiguous. In this way, it seeks similarities between elements to generate data\ngroupings. AOI was initially conceived as an algorithm for knowledge discovery\nin databases, but over the years it has been applied to other areas such as\nspatial patterns, intrusion detection or strategy making. In this paper, AOI\nhas been extended to the field of Predictive Maintenance. The objective is to\ndemonstrate that combining expert knowledge and data collected from the machine\ncan provide good results in the Predictive Maintenance of industrial assets. To\nthis end we adapted the algorithm and used an LSTM approach to perform both the\nAnomaly Detection (AD) and the Remaining Useful Life (RUL). The results\nobtained confirm the validity of the proposal, as the methodology was able to\ndetect anomalies, and calculate the RUL until breakage with considerable degree\nof accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:03:19 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Fernandez-Anakabe", "Javier", ""], ["Uriguen", "Ekhi Zugasti", ""], ["Ortega", "Urko Zurutuza", ""]]}, {"id": "1912.00664", "submitter": "Dmitry Slugin", "authors": "Igor Janiszewski, Dmitry Slugin, Vladimir V. Arlazarov", "title": "Training the Convolutional Neural Network with Statistical Dependence of\n  the Response on the Input Data Distortion", "comments": "Submitted and presented at The 12th International Conference on\n  Machine Vision (ICMV 2019). 8 pages, 7 figures, 14 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an approach to training a convolutional neural network\nusing information on the level of distortion of input data. The learning\nprocess is modified with an additional layer, which is subsequently deleted, so\nthe architecture of the original network does not change. As an example, the\nLeNet5 architecture network with training data based on the MNIST symbols and a\ndistortion model as Gaussian blur with a variable level of distortion is\nconsidered. This approach does not have quality loss of the network and has a\nsignificant error-free zone in responses on the test data which is absent in\nthe traditional approach to training. The responses are statistically dependent\non the level of input image's distortions and there is a presence of a strong\nrelationship between them.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:09:21 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Janiszewski", "Igor", ""], ["Slugin", "Dmitry", ""], ["Arlazarov", "Vladimir V.", ""]]}, {"id": "1912.00672", "submitter": "Zina Ibrahim", "authors": "Zina Ibrahim and Honghan Wu and Ahmed Hamoud and Lukas Stappen and\n  Richard Dobson and Andrea Agarossi", "title": "On Classifying Sepsis Heterogeneity in the ICU: Insight Using Machine\n  Learning", "comments": "3 Figures and 2 tables. Accepted for publication at the Journal of\n  American Medical Informatics Association", "journal-ref": "Journal of the American Medical Informatics Association 27 (2020)\n  437-443", "doi": "10.1093/jamia/ocz211", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current machine learning models aiming to predict sepsis from Electronic\nHealth Records (EHR) do not account for the heterogeneity of the condition,\ndespite its emerging importance in prognosis and treatment. This work\ndemonstrates the added value of stratifying the types of organ dysfunction\nobserved in patients who develop sepsis in the ICU in improving the ability to\nrecognise patients at risk of sepsis from their EHR data. Using an ICU dataset\nof 13,728 records, we identify clinically significant sepsis subpopulations\nwith distinct organ dysfunction patterns. Classification experiments using\nRandom Forest, Gradient Boost Trees and Support Vector Machines, aiming to\ndistinguish patients who develop sepsis in the ICU from those who do not, show\nthat features selected using sepsis subpopulations as background knowledge\nyield a superior performance regardless of the classification model used. Our\nfindings can steer machine learning efforts towards more personalised models\nfor complex conditions including sepsis.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:32:40 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 12:42:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ibrahim", "Zina", ""], ["Wu", "Honghan", ""], ["Hamoud", "Ahmed", ""], ["Stappen", "Lukas", ""], ["Dobson", "Richard", ""], ["Agarossi", "Andrea", ""]]}, {"id": "1912.00673", "submitter": "Henry Howard-Jenkins", "authors": "Henry Howard-Jenkins, Yiwen Li, Victor A. Prisacariu", "title": "GroSS: Group-Size Series Decomposition for Grouped Architecture Search", "comments": "Accepted for publication at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach which is able to explore the configuration of\ngrouped convolutions within neural networks. Group-size Series (GroSS)\ndecomposition is a mathematical formulation of tensor factorisation into a\nseries of approximations of increasing rank terms. GroSS allows for dynamic and\ndifferentiable selection of factorisation rank, which is analogous to a grouped\nconvolution. Therefore, to the best of our knowledge, GroSS is the first method\nto enable simultaneous training of differing numbers of groups within a single\nlayer, as well as all possible combinations between layers. In doing so, GroSS\nis able to train an entire grouped convolution architecture search-space\nconcurrently. We demonstrate this through architecture searches with\nperformance objectives on multiple datasets and networks. GroSS enables more\neffective and efficient search for grouped convolutional architectures.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:32:50 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 12:26:25 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 16:28:12 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Howard-Jenkins", "Henry", ""], ["Li", "Yiwen", ""], ["Prisacariu", "Victor A.", ""]]}, {"id": "1912.00680", "submitter": "Casper Boone", "authors": "Casper Boone, Niels de Bruin, Arjan Langerak and Fabian Stelmach", "title": "DLTPy: Deep Learning Type Inference of Python Function Signatures using\n  Natural Language Context", "comments": "10 pages, 8 figures The source code of DLTPy is publicly available at\n  https://github.com/casperboone/dltpy/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rise of machine learning, Python is an increasingly popular\nprogramming language. Python, however, is dynamically typed. Dynamic typing has\nshown to have drawbacks when a project grows, while at the same time it\nimproves developer productivity. To have the benefits of static typing,\ncombined with high developer productivity, types need to be inferred. In this\npaper, we present DLTPy: a deep learning type inference solution for the\nprediction of types in function signatures based on the natural language\ncontext (identifier names, comments and return expressions) of a function. We\nfound that DLTPy is effective and has a top-3 F1-score of 91.6%. This means\nthat in most of the cases the correct type is within the top-3 predictions. We\nconclude that natural language contained in comments and return expressions are\nbeneficial to predicting types more accurately. DLTPy does not significantly\noutperform or underperform the previous work NL2Type for Javascript, but does\nshow that similar prediction is possible for Python.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 10:55:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Boone", "Casper", ""], ["de Bruin", "Niels", ""], ["Langerak", "Arjan", ""], ["Stelmach", "Fabian", ""]]}, {"id": "1912.00682", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Ren\\'e Garello, and\n  Ronan Fablet", "title": "GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural\n  Network Representation of AIS Tracks and A Contrario Detection", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2021.3055614", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing maritime traffic patterns and detecting anomalies from them are\nkey to vessel monitoring and maritime situational awareness. We propose a novel\napproach -- referred to as GeoTrackNet -- for maritime anomaly detection from\nAIS data streams. Our model exploits state-of-the-art neural network schemes to\nlearn a probabilistic representation of AIS tracks and a contrario detection to\ndetect abnormal events. The neural network provides a new means to capture\ncomplex and heterogeneous patterns in vessels' behaviours, while the \\textit{a\ncontrario} detector takes into account the fact that the learnt distribution\nmay be location-dependent. Experiments on a real AIS dataset comprising more\nthan 4.2 million AIS messages demonstrate the relevance of the proposed method\ncompared with state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:04:56 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 12:22:43 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 21:03:37 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 12:57:09 GMT"}, {"version": "v5", "created": "Mon, 8 Feb 2021 21:08:13 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Nguyen", "Duong", ""], ["Vadaine", "Rodolphe", ""], ["Hajduch", "Guillaume", ""], ["Garello", "Ren\u00e9", ""], ["Fablet", "Ronan", ""]]}, {"id": "1912.00690", "submitter": "Benjamin Clavi\\'e", "authors": "Benjamin Clavi\\'e and Kobi Gal", "title": "EduBERT: Pretrained Deep Language Models for Learning Analytics", "comments": "Accepted for poster presentation at the 10th International Learning\n  Analytics and Knowledge (LAK20) Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of large pretrained neural networks to create contextualized word\nembeddings has drastically improved performance on several natural language\nprocessing (NLP) tasks. These computationally expensive models have begun to be\napplied to domain-specific NLP tasks such as re-hospitalization prediction from\nclinical notes. This paper demonstrates that using large pretrained models\nproduces excellent results on common learning analytics tasks. Pre-training\ndeep language models using student forum data from a wide array of online\ncourses improves performance beyond the state of the art on three text\nclassification tasks. We also show that a smaller, distilled version of our\nmodel produces the best results on two of the three tasks while limiting\ncomputational cost. We make both models available to the research community at\nlarge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:32:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Clavi\u00e9", "Benjamin", ""], ["Gal", "Kobi", ""]]}, {"id": "1912.00700", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio and Vojtech Mrazek and Muhammad Abudllah Hanif and\n  Muhammad Shafique", "title": "ReD-CaNe: A Systematic Methodology for Resilience Analysis and Design of\n  Capsule Networks under Approximations", "comments": "To appear at the 23rd Design, Automation and Test in Europe (DATE\n  2020). Grenoble, France", "journal-ref": null, "doi": "10.23919/DATE48585.2020.9116393", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Capsule Networks (CapsNets) have shown their superior\nlearning capability, compared to the traditional Convolutional Neural Networks\n(CNNs). However, the extremely high complexity of CapsNets limits their fast\ndeployment in real-world applications. Moreover, while the resilience of CNNs\nhave been extensively investigated to enable their energy-efficient\nimplementations, the analysis of CapsNets' resilience is a largely unexplored\narea, that can provide a strong foundation to investigate techniques to\novercome the CapsNets' complexity challenge.\n  Following the trend of Approximate Computing to enable energy-efficient\ndesigns, we perform an extensive resilience analysis of the CapsNets inference\nsubjected to the approximation errors. Our methodology models the errors\narising from the approximate components (like multipliers), and analyze their\nimpact on the classification accuracy of CapsNets. This enables the selection\nof approximate components based on the resilience of each operation of the\nCapsNet inference. We modify the TensorFlow framework to simulate the injection\nof approximation noise (based on the models of the approximate components) at\ndifferent computational operations of the CapsNet inference. Our results show\nthat the CapsNets are more resilient to the errors injected in the computations\nthat occur during the dynamic routing (the softmax and the update of the\ncoefficients), rather than other stages like convolutions and activation\nfunctions. Our analysis is extremely useful towards designing efficient CapsNet\nhardware accelerators with approximate components. To the best of our\nknowledge, this is the first proof-of-concept for employing approximations on\nthe specialized CapsNet hardware.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:55:46 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Marchisio", "Alberto", ""], ["Mrazek", "Vojtech", ""], ["Hanif", "Muhammad Abudllah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1912.00706", "submitter": "Roman Feldbauer", "authors": "Roman Feldbauer, Thomas Rattei and Arthur Flexer", "title": "scikit-hubness: Hubness Reduction and Approximate Neighbor Search", "comments": null, "journal-ref": null, "doi": "10.21105/joss.01957", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces scikit-hubness, a Python package for efficient nearest\nneighbor search in high-dimensional spaces. Hubness is an aspect of the curse\nof dimensionality, and is known to impair various learning tasks, including\nclassification, clustering, and visualization. scikit-hubness provides\nalgorithms for hubness analysis (\"Is my data affected by hubness?\"), hubness\nreduction (\"How can we improve neighbor retrieval in high dimensions?\"), and\napproximate neighbor search (\"Does it work for large data sets?\"). It is\nintegrated into the scikit-learn environment, enabling rapid adoption by\nPython-based machine learning researchers and practitioners. Users will find\nall functionality of the scikit-learn neighbors package, plus additional\nsupport for transparent hubness reduction and approximate nearest neighbor\nsearch. scikit-hubness is developed using several quality assessment tools and\nprinciples, such as PEP8 compliance, unit tests with high code coverage,\ncontinuous integration on all major platforms (Linux, MacOS, Windows), and\nadditional checks by LGTM. The source code is available at\nhttps://github.com/VarIr/scikit-hubness under the BSD 3-clause license. Install\nfrom the Python package index with $ pip install scikit-hubness.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:04:32 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Feldbauer", "Roman", ""], ["Rattei", "Thomas", ""], ["Flexer", "Arthur", ""]]}, {"id": "1912.00712", "submitter": "Shaogao Lv", "authors": "Shaogao Lv, Yongchao Hou, Hongwei Zhou", "title": "Financial Market Directional Forecasting With Stacked Denoising\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting stock market direction is always an amazing but challenging\nproblem in finance. Although many popular shallow computational methods (such\nas Backpropagation Network and Support Vector Machine) have extensively been\nproposed, most algorithms have not yet attained a desirable level of\napplicability. In this paper, we present a deep learning model with strong\nability to generate high level feature representations for accurate financial\nprediction. Precisely, a stacked denoising autoencoder (SDAE) from deep\nlearning is applied to predict the daily CSI 300 index, from Shanghai and\nShenzhen Stock Exchanges in China. We use six evaluation criteria to evaluate\nits performance compared with the back propagation network, support vector\nmachine. The experiment shows that the underlying financial model with deep\nmachine technology has a significant advantage for the prediction of the CSI\n300 index.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:20:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lv", "Shaogao", ""], ["Hou", "Yongchao", ""], ["Zhou", "Hongwei", ""]]}, {"id": "1912.00715", "submitter": "Anthony Constantinou", "authors": "Neville Kenneth Kitson and Anthony C. Constantinou", "title": "Learning Bayesian networks from demographic and health survey data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Child mortality from preventable diseases such as pneumonia and diarrhoea in\nlow and middle-income countries remains a serious global challenge. We combine\nknowledge with available Demographic and Health Survey (DHS) data from India,\nto construct Causal Bayesian Networks (CBNs) and investigate the factors\nassociated with childhood diarrhoea. We make use of freeware tools to learn the\ngraphical structure of the DHS data with score-based, constraint-based, and\nhybrid structure learning algorithms. We investigate the effect of missing\nvalues, sample size, and knowledge-based constraints on each of the structure\nlearning algorithms and assess their accuracy with multiple scoring functions.\nWeaknesses in the survey methodology and data available, as well as the\nvariability in the CBNs generated by the different algorithms, mean that it is\nnot possible to learn a definitive CBN from data. However, knowledge-based\nconstraints are found to be useful in reducing the variation in the graphs\nproduced by the different algorithms, and produce graphs which are more\nreflective of the likely influential relationships in the data. Furthermore,\nvaluable insights are gained into the performance and characteristics of the\nstructure learning algorithms. Two score-based algorithms in particular, TABU\nand FGES, demonstrate many desirable qualities; a) with sufficient data, they\nproduce a graph which is similar to the reference graph, b) they are relatively\ninsensitive to missing values, and c) behave well with knowledge-based\nconstraints. The results provide a basis for further investigation of the DHS\ndata and for a deeper understanding of the behaviour of the structure learning\nalgorithms when applied to real-world settings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:24:35 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 12:27:51 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kitson", "Neville Kenneth", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "1912.00723", "submitter": "Hao Wang", "authors": "Hao Wang, Hao Zeng, Jiashan Wang", "title": "Relating lp regularization and reweighted l1 regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework of iteratively reweighted l1 methods for\nsolving lp regularization problems. We prove that after some iteration k, the\niterates generated by the proposed methods have the same support and sign as\nthe limit points, and are bounded away from 0, so that the algorithm behaves\nlike solving a smooth problem in the reduced space. As a result, the global\nconvergence can be easily obtained and an update strategy for the smoothing\nparameter is proposed which can automatically terminate the updates for zero\ncomponents. We show that lp regularization problems are locally equivalent to a\nweighted l1 regularization problem and every optimal point corresponds to a\nMaximum A Posterior estimation for independently and non-identically\ndistributed Laplace prior parameters. Numerical experiments exhibit the\nbehaviors and the efficiency of our proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:47:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Hao", ""], ["Zeng", "Hao", ""], ["Wang", "Jiashan", ""]]}, {"id": "1912.00730", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, Doris Hoogeveen, Llu\\'is M\\`arquez, Alessandro\n  Moschitti, Hamdy Mubarak, Timothy Baldwin, Karin Verspoor", "title": "SemEval-2017 Task 3: Community Question Answering", "comments": "community question answering, question-question similarity,\n  question-comment similarity, answer reranking, Multi-domain Question\n  Duplicate Detection, StackExchange, English, Arabic", "journal-ref": "SemEval-2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe SemEval-2017 Task 3 on Community Question Answering. This year,\nwe reran the four subtasks from SemEval-2016:(A) Question-Comment\nSimilarity,(B) Question-Question Similarity,(C) Question-External Comment\nSimilarity, and (D) Rerank the correct answers for a new question in Arabic,\nproviding all the data from 2015 and 2016 for training, and fresh data for\ntesting. Additionally, we added a new subtask E in order to enable\nexperimentation with Multi-domain Question Duplicate Detection in a\nlarger-scale scenario, using StackExchange subforums. A total of 23 teams\nparticipated in the task, and submitted a total of 85 runs (36 primary and 49\ncontrastive) for subtasks A-D. Unfortunately, no teams participated in subtask\nE. A variety of approaches and features were used by the participating systems\nto address the different subtasks. The best systems achieved an official score\n(MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D,\nrespectively. These scores are better than the baselines, especially for\nsubtasks A-C.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:57:52 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nakov", "Preslav", ""], ["Hoogeveen", "Doris", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Moschitti", "Alessandro", ""], ["Mubarak", "Hamdy", ""], ["Baldwin", "Timothy", ""], ["Verspoor", "Karin", ""]]}, {"id": "1912.00735", "submitter": "Edouard Pineau", "authors": "Edouard Pineau", "title": "Using Laplacian Spectrum as Graph Feature Representation", "comments": "10 pages, 3 figures, 7 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs possess exotic features like variable size and absence of natural\nordering of the nodes that make them difficult to analyze and compare. To\ncircumvent this problem and learn on graphs, graph feature representation is\nrequired. A good graph representation must satisfy the preservation of\nstructural information, with two particular key attributes: consistency under\ndeformation and invariance under isomorphism. While state-of-the-art methods\nseek such properties with powerful graph neural-networks, we propose to\nleverage a simple graph feature: the graph Laplacian spectrum (GLS). We first\nremind and show that GLS satisfies the aforementioned key attributes, using a\ngraph perturbation approach. In particular, we derive bounds for the distance\nbetween two GLS that are related to the \\textit{divergence to isomorphism}, a\nstandard computationally expensive graph divergence. We finally experiment GLS\nas graph representation through consistency tests and classification tasks, and\nshow that it is a strong graph feature representation baseline.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 13:01:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Pineau", "Edouard", ""]]}, {"id": "1912.00741", "submitter": "Preslav Nakov", "authors": "Sara Rosenthal, Noura Farra, Preslav Nakov", "title": "SemEval-2017 Task 4: Sentiment Analysis in Twitter", "comments": "sentiment analysis, Twitter, classification, quantification, ranking,\n  English, Arabic", "journal-ref": null, "doi": null, "report-no": "SemEval-2017", "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the fifth year of the Sentiment Analysis in Twitter\ntask. SemEval-2017 Task 4 continues with a rerun of the subtasks of\nSemEval-2016 Task 4, which include identifying the overall sentiment of the\ntweet, sentiment towards a topic with classification on a two-point and on a\nfive-point ordinal scale, and quantification of the distribution of sentiment\ntowards a topic across a number of tweets: again on a two-point and on a\nfive-point ordinal scale. Compared to 2016, we made two changes: (i) we\nintroduced a new language, Arabic, for all subtasks, and (ii)~we made available\ninformation from the profiles of the Twitter users who posted the target\ntweets. The task continues to be very popular, with a total of 48 teams\nparticipating this year.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 13:04:35 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Rosenthal", "Sara", ""], ["Farra", "Noura", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.00742", "submitter": "Alexey Svyatkovskiy", "authors": "Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu, Neel Sundaresan", "title": "Pythia: AI-assisted Code Completion System", "comments": "Published in Proceedings of the 25th ACM SIGKDD International\n  Conference on Knowledge Discovery & Data Mining (KDD '19)", "journal-ref": null, "doi": "10.1145/3292500.3330699", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel end-to-end approach for AI-assisted code\ncompletion called Pythia. It generates ranked lists of method and API\nrecommendations which can be used by software developers at edit time. The\nsystem is currently deployed as part of Intellicode extension in Visual Studio\nCode IDE. Pythia exploits state-of-the-art large-scale deep learning models\ntrained on code contexts extracted from abstract syntax trees. It is designed\nto work at a high throughput predicting the best matching code completions on\nthe order of 100 $ms$.\n  We describe the architecture of the system, perform comparisons to\nfrequency-based approach and invocation-based Markov Chain language model, and\ndiscuss challenges serving Pythia models on lightweight client devices.\n  The offline evaluation results obtained on 2700 Python open source software\nGitHub repositories show a top-5 accuracy of 92\\%, surpassing the baseline\nmodels by 20\\% averaged over classes, for both intra and cross-project\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 04:22:48 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Svyatkovskiy", "Alexey", ""], ["Zhao", "Ying", ""], ["Fu", "Shengyu", ""], ["Sundaresan", "Neel", ""]]}, {"id": "1912.00752", "submitter": "Yining Wang", "authors": "Yining Wang, Mingzhe Chen, Zhaohui Yang, Tao Luo, and Walid Saad", "title": "Deep Learning for Optimal Deployment of UAVs with Visible Light\n  Communications", "comments": "This paper has been accepted by IEEE Transactions on Wireless\n  Communications. arXiv admin note: text overlap with arXiv:1909.07554", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of dynamical deployment of unmanned aerial\nvehicles (UAVs) equipped with visible light communication (VLC) capabilities\nfor optimizing the energy efficiency of UAV-enabled networks is studied. In the\nstudied model, the UAVs can simultaneously provide communications and\nillumination to service ground users. Since ambient illumination increases the\ninterference over VLC links while reducing the illumination threshold of the\nUAVs, it is necessary to consider the illumination distribution of the target\narea for UAV deployment optimization. This problem is formulated as an\noptimization problem which jointly optimizes UAV deployment, user association,\nand power efficiency while meeting the illumination and communication\nrequirements of users. To solve this problem, an algorithm that combines the\nmachine learning framework of gated recurrent units (GRUs) with convolutional\nneural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the\nlong-term historical illumination distribution and predict the future\nillumination distribution. Given the prediction of illumination distribution,\nthe original nonconvex optimization problem can be divided into two\nsub-problems and is then solved using a low-complexity, iterative algorithm.\nThen, the proposed algorithm enables UAVs to determine the their deployment and\nuser association to minimize the total transmit power. Simulation results using\nreal data from the Earth observations group (EOG) at NOAA/NCEI show that the\nproposed approach can achieve up to 68.9% reduction in total transmit power\ncompared to a conventional optimal UAV deployment that does not consider the\nillumination distribution and user association.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:03:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 08:01:04 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 14:08:12 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Wang", "Yining", ""], ["Chen", "Mingzhe", ""], ["Yang", "Zhaohui", ""], ["Luo", "Tao", ""], ["Saad", "Walid", ""]]}, {"id": "1912.00756", "submitter": "Siming Zheng", "authors": "Siming Zheng, Rahmita Wirza O.K. Rahmat, Fatimah Khalid, Nurul Amelina\n  Nasharuddin", "title": "Learning scale-variant features for robust iris authentication with deep\n  learning based ensemble framework", "comments": "This is the second revision for updating the formation, logical and\n  image captions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, mobile Internet has accelerated the proliferation of smart\nmobile development. The mobile payment, mobile security and privacy protection\nhave become the focus of widespread attention. Iris recognition becomes a\nhigh-security authentication technology in these fields, it is widely used in\ndistinct science fields in biometric authentication fields. The Convolutional\nNeural Network (CNN) is one of the mainstream deep learning approaches for\nimage recognition, whereas its anti-noise ability is weak and needs a certain\namount of memory to train in image classification tasks. Under these conditions\nwe put forward a fine-tuning neural network model based on the Mask R-CNN and\nInception V4 neural network model, which integrates every component in an\noverall system that combines the iris detection, extraction, and recognition\nfunction as an iris recognition system. The proposed framework has the\ncharacteristics of scalability and high availability; it not only can learn\npart-whole relationships of the iris image but also enhancing the robustness of\nthe whole framework. Importantly, the proposed model can be trained using the\ndifferent spectrum of samples, such as Visible Wavelength (VW) and Near\nInfrared (NIR) iris biometric databases. The recognition average accuracy of\n99.10% is achieved while executing in the mobile edge calculation device of the\nJetson Nano.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 13:25:05 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:27:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zheng", "Siming", ""], ["Rahmat", "Rahmita Wirza O. K.", ""], ["Khalid", "Fatimah", ""], ["Nasharuddin", "Nurul Amelina", ""]]}, {"id": "1912.00759", "submitter": "Antonio M. Sudoso", "authors": "Veronica Piccialli, Antonio M. Sudoso", "title": "Improving Non-Intrusive Load Disaggregation through an Attention-Based\n  Deep Neural Network", "comments": null, "journal-ref": "Energies 2021, 14(4), 847", "doi": "10.3390/en14040847", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy disaggregation, known in the literature as Non-Intrusive Load\nMonitoring (NILM), is the task of inferring the power demand of the individual\nappliances given the aggregate power demand recorded by a single smart meter\nwhich monitors multiple appliances. In this paper, we propose a deep neural\nnetwork that combines a regression subnetwork with a classification subnetwork\nfor solving the NILM problem. Specifically, we improve the generalization\ncapability of the overall architecture by including an encoder-decoder with a\ntailored attention mechanism in the regression subnetwork. The attention\nmechanism is inspired by the temporal attention that has been successfully\napplied in neural machine translation, text summarization, and speech\nrecognition. The experiments conducted on two publicly available datasets--REDD\nand UK-DALE--show that our proposed deep neural network outperforms the\nstate-of-the-art in all the considered experimental conditions. We also show\nthat modeling attention translates into the network's ability to correctly\ndetect the turning on or off an appliance and to locate signal sections with\nhigh power consumption, which are of extreme interest in the field of energy\ndisaggregation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 21:48:27 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 21:02:13 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 18:52:00 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Piccialli", "Veronica", ""], ["Sudoso", "Antonio M.", ""]]}, {"id": "1912.00761", "submitter": "Alice Xiang", "authors": "Alice Xiang and Inioluwa Deborah Raji", "title": "On the Legal Compatibility of Fairness Definitions", "comments": "6 pages, Workshop on Human-Centric Machine Learning at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Past literature has been effective in demonstrating ideological gaps in\nmachine learning (ML) fairness definitions when considering their use in\ncomplex socio-technical systems. However, we go further to demonstrate that\nthese definitions often misunderstand the legal concepts from which they\npurport to be inspired, and consequently inappropriately co-opt legal language.\nIn this paper, we demonstrate examples of this misalignment and discuss the\ndifferences in ML terminology and their legal counterparts, as well as what\nboth the legal and ML fairness communities can learn from these tensions. We\nfocus this paper on U.S. anti-discrimination law since the ML fairness research\ncommunity regularly references terms from this body of law.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:28:46 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Xiang", "Alice", ""], ["Raji", "Inioluwa Deborah", ""]]}, {"id": "1912.00772", "submitter": "Cameron Wolfe", "authors": "Cameron R. Wolfe, Keld T. Lundgaard", "title": "E-Stitchup: Data Augmentation for Pre-Trained Embeddings", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose data augmentation methods for embeddings from\npre-trained deep learning models that take a weighted combination of a pair of\ninput embeddings, as inspired by Mixup, and combine such augmentation with\nextra label softening. These methods are shown to significantly increase\nclassification accuracy, reduce training time, and improve confidence\ncalibration of a downstream model that is trained with them. As a result of\nsuch improved confidence calibration, the model output can be more intuitively\ninterpreted and used to accurately identify out-of-distribution data by\napplying an appropriate confidence threshold to model predictions. The\nidentified out-of-distribution data can then be prioritized for labeling, thus\nfocusing labeling effort on data that is more likely to boost model\nperformance. These findings, we believe, lay a solid foundation for improving\nthe classification performance and calibration of models that use pre-trained\nembeddings as input and provide several benefits that prove extremely useful in\na production-level deep learning system.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 04:10:31 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 14:14:12 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wolfe", "Cameron R.", ""], ["Lundgaard", "Keld T.", ""]]}, {"id": "1912.00773", "submitter": "Xiaoshan Yang", "authors": "Yi Huang, Xiaoshan Yang, and Changsheng Xu", "title": "Time-Guided High-Order Attention Model of Longitudinal Heterogeneous\n  Healthcare Data", "comments": "PRICAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to potential applications in chronic disease management and personalized\nhealthcare, the EHRs data analysis has attracted much attention of both\nresearchers and practitioners. There are three main challenges in modeling\nlongitudinal and heterogeneous EHRs data: heterogeneity, irregular temporality\nand interpretability. A series of deep learning methods have made remarkable\nprogress in resolving these challenges. Nevertheless, most of existing\nattention models rely on capturing the 1-order temporal dependencies or 2-order\nmultimodal relationships among feature elements. In this paper, we propose a\ntime-guided high-order attention (TGHOA) model. The proposed method has three\nmajor advantages. (1) It can model longitudinal heterogeneous EHRs data via\ncapturing the 3-order correlations of different modalities and the irregular\ntemporal impact of historical events. (2) It can be used to identify the\npotential concerns of medical features to explain the reasoning process of the\nhealthcare model. (3) It can be easily expanded into cases with more modalities\nand flexibly applied in different prediction tasks. We evaluate the proposed\nmethod in two tasks of mortality prediction and disease ranking on two real\nworld EHRs datasets. Extensive experimental results show the effectiveness of\nthe proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 03:15:24 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Huang", "Yi", ""], ["Yang", "Xiaoshan", ""], ["Xu", "Changsheng", ""]]}, {"id": "1912.00775", "submitter": "Leonardo Zepeda-N\\'u\\~nez", "authors": "Leonardo Zepeda-N\\'u\\~nez and Yixiao Chen and Jiefu Zhang and Weile\n  Jia and Linfeng Zhang and Lin Lin", "title": "Deep Density: circumventing the Kohn-Sham equations via symmetry\n  preserving neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently developed Deep Potential [Phys. Rev. Lett. 120, 143001, 2018] is\na powerful method to represent general inter-atomic potentials using deep\nneural networks. The success of Deep Potential rests on the proper treatment of\nlocality and symmetry properties of each component of the network. In this\npaper, we leverage its network structure to effectively represent the mapping\nfrom the atomic configuration to the electron density in Kohn-Sham density\nfunction theory (KS-DFT). By directly targeting at the self-consistent electron\ndensity, we demonstrate that the adapted network architecture, called the Deep\nDensity, can effectively represent the electron density as the linear\ncombination of contributions from many local clusters. The network is\nconstructed to satisfy the translation, rotation, and permutation symmetries,\nand is designed to be transferable to different system sizes. We demonstrate\nthat using a relatively small number of training snapshots, Deep Density\nachieves excellent performance for one-dimensional insulating and metallic\nsystems, as well as systems with mixed insulating and metallic characters. We\nalso demonstrate its performance for real three-dimensional systems, including\nsmall organic molecules, as well as extended systems such as water (up to $512$\nmolecules) and aluminum (up to $256$ atoms).\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:18:24 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""], ["Chen", "Yixiao", ""], ["Zhang", "Jiefu", ""], ["Jia", "Weile", ""], ["Zhang", "Linfeng", ""], ["Lin", "Lin", ""]]}, {"id": "1912.00778", "submitter": "Itay Lieder", "authors": "Itay Lieder, Meirav Segal, Eran Avidan, Asaf Cohen, Tom Hope", "title": "Learning a faceted customer segmentation for discovering new business\n  opportunities at Intel", "comments": "3 pages, 4 figures, Published in proceedings of IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sales and marketing organizations within large enterprises, identifying\nand understanding new markets, customers and partners is a key challenge.\nIntel's Sales and Marketing Group (SMG) faces similar challenges while growing\nin new markets and domains and evolving its existing business. In today's\ncomplex technological and commercial landscape, there is need for intelligent\nautomation supporting a fine-grained understanding of businesses in order to\nhelp SMG sift through millions of companies across many geographies and\nlanguages and identify relevant directions. We present a system developed in\nour company that mines millions of public business web pages, and extracts a\nfaceted customer representation. We focus on two key customer aspects that are\nessential for finding relevant opportunities: industry segments (ranging from\nbroad verticals such as healthcare, to more specific fields such as 'video\nanalytics') and functional roles (e.g., 'manufacturer' or 'retail'). To address\nthe challenge of labeled data collection, we enrich our data with external\ninformation gleaned from Wikipedia, and develop a semi-supervised multi-label,\nmulti-lingual deep learning model that parses customer website texts and\nclassifies them into their respective facets. Our system scans and indexes\ncompanies as part of a large-scale knowledge graph that currently holds tens of\nmillions of connected entities with thousands being fetched, enriched and\nconnected to the graph by the hour in real time, and also supports knowledge\nand insight discovery. In experiments conducted in our company, we are able to\nsignificantly boost the performance of sales personnel in the task of\ndiscovering new customers and commercial partnership opportunities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:48:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lieder", "Itay", ""], ["Segal", "Meirav", ""], ["Avidan", "Eran", ""], ["Cohen", "Asaf", ""], ["Hope", "Tom", ""]]}, {"id": "1912.00781", "submitter": "Mircea-Dan Hernest", "authors": "Dan Hernest", "title": "Experiments with a PCCoder extension", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in synthesis of programs written in some Domain Specific\nLanguage (DSL) by means of neural networks from a limited set of inputs-output\ncorrespondences such as DeepCoder and its PCCoder reimplementation/optimization\nproved the efficiency of this kind of approach to automatic program generation\nin a DSL language that although limited in scope is universal in the sense that\nprograms can be translated to basically any programming language. We experiment\nwith the extension of the DSL of DeepCoder/PCCoder with symbols IFI and IFL\nwhich denote functional expressions of the If ramification (test) instruction\nfor types Int and List. We notice an increase (doubling) of the size of the\ntraining set, the number of parameters of the trained neural network and of the\ntime spent looking for the program synthesized from limited sets of\ninputs-output correspondences. The result is positive in the sense of\npreserving the accuracy of applying synthesis on randomly generated test sets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:57:33 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 05:46:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hernest", "Dan", ""]]}, {"id": "1912.00782", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila Coopamootoo, Karen Elliott,\n  Carlos Gonzalez Zelaya, Aad van Moorsel", "title": "The relationship between trust in AI and trustworthy machine learning\n  technologies", "comments": "This submission has been accepted in ACM FAT* 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build AI-based systems that users and the public can justifiably trust one\nneeds to understand how machine learning technologies impact trust put in these\nservices. To guide technology developments, this paper provides a systematic\napproach to relate social science concepts of trust with the technologies used\nin AI-based services and products. We conceive trust as discussed in the ABI\n(Ability, Benevolence, Integrity) framework and use a recently proposed mapping\nof ABI on qualities of technologies. We consider four categories of machine\nlearning technologies, namely these for Fairness, Explainability, Auditability\nand Safety (FEAS) and discuss if and how these possess the required qualities.\nTrust can be impacted throughout the life cycle of AI-based systems, and we\nintroduce the concept of Chain of Trust to discuss technological needs for\ntrust in different stages of the life cycle. FEAS has obvious relations with\nknown frameworks and therefore we relate FEAS to a variety of international\nPrincipled AI policy and technology frameworks that have emerged in recent\nyears.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:36:13 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 11:59:43 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila", ""], ["Elliott", "Karen", ""], ["Zelaya", "Carlos Gonzalez", ""], ["van Moorsel", "Aad", ""]]}, {"id": "1912.00789", "submitter": "Xin Mao", "authors": "Xin Mao, Zhaoyu Su, Pin Siang Tan, Jun Kang Chow, Yu-Hsing Wang", "title": "Is Discriminator a Good Feature Extractor?", "comments": "12 pages, 3 figures, two tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discriminator from generative adversarial nets (GAN) has been used by\nresearchers as a feature extractor in transfer learning and appeared worked\nwell. However, there are also studies that believe this is the wrong research\ndirection because intuitively the task of the discriminator focuses on\nseparating the real samples from the generated ones, making features extracted\nin this way useless for most of the downstream tasks. To avoid this dilemma, we\nfirst conducted a thorough theoretical analysis of the relationship between the\ndiscriminator task and the features extracted. We found that the connection\nbetween the task of the discriminator and the feature is not as strong as was\nthought, for that the main factor restricting the feature learned by the\ndiscriminator is not the task, but is the need to prevent the entire GAN model\nfrom mode collapse during the training. From this perspective and combined with\nfurther analyses, we found that to avoid mode collapse, the features extracted\nby the discriminator are not guided to be different for the real samples, but\ndivergence without noise is indeed allowed and occupies a large proportion of\nthe feature space. This makes the features more robust and helps answer the\nquestion as to why the discriminator can succeed as a feature extractor in\nrelated research. Consequently, to expose the essence of the discriminator\nextractor as different from other extractors, we analyze the counterpart of the\ndiscriminator extractor, the classifier extractor that assigns the target\nsamples to different categories. We found the performance of the discriminator\nextractor may be inferior to the classifier based extractor when the source\nclassification task is similar to the target task, which is the common case,\nbut the ability to avoid noise prevents the discriminator from being replaced\nby the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 13:59:32 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 07:41:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mao", "Xin", ""], ["Su", "Zhaoyu", ""], ["Tan", "Pin Siang", ""], ["Chow", "Jun Kang", ""], ["Wang", "Yu-Hsing", ""]]}, {"id": "1912.00796", "submitter": "Andreas Look", "authors": "Andreas Look and Melih Kandemir", "title": "Differential Bayesian Neural Nets", "comments": null, "journal-ref": "4th workshop on Bayesian Deep Learning (NeurIPS 2019), Vancouver,\n  Canada", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations (N-ODEs) are a powerful building block\nfor learning systems, which extend residual networks to a continuous-time\ndynamical system. We propose a Bayesian version of N-ODEs that enables\nwell-calibrated quantification of prediction uncertainty, while maintaining the\nexpressive power of their deterministic counterpart. We assign Bayesian Neural\nNets (BNNs) to both the drift and the diffusion terms of a Stochastic\nDifferential Equation (SDE) that models the flow of the activation map in time.\nWe infer the posterior on the BNN weights using a straightforward adaptation of\nStochastic Gradient Langevin Dynamics (SGLD). We illustrate significantly\nimproved stability on two synthetic time series prediction tasks and report\nbetter model fit on UCI regression benchmarks with our method when compared to\nits non-Bayesian counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:03:55 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:14:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Look", "Andreas", ""], ["Kandemir", "Melih", ""]]}, {"id": "1912.00805", "submitter": "Donghwan Shin", "authors": "Fitash Ul Haq, Donghwan Shin, Shiva Nejati, Lionel Briand", "title": "Comparing Offline and Online Testing of Deep Neural Networks: An\n  Autonomous Car Case Study", "comments": null, "journal-ref": null, "doi": "10.1109/ICST46399.2020.00019", "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing body of research on developing testing techniques for Deep\nNeural Networks (DNN). We distinguish two general modes of testing for DNNs:\nOffline testing where DNNs are tested as individual units based on test\ndatasets obtained independently from the DNNs under test, and online testing\nwhere DNNs are embedded into a specific application and tested in a close-loop\nmode in interaction with the application environment. In addition, we identify\ntwo sources for generating test datasets for DNNs: Datasets obtained from\nreal-life and datasets generated by simulators. While offline testing can be\nused with datasets obtained from either sources, online testing is largely\nconfined to using simulators since online testing within real-life applications\ncan be time-consuming, expensive and dangerous. In this paper, we study the\nfollowing two important questions aiming to compare test datasets and testing\nmodes for DNNs: First, can we use simulator-generated data as a reliable\nsubstitute to real-world data for the purpose of DNN testing? Second, how do\nonline and offline testing results differ and complement each other? Though\nthese questions are generally relevant to all autonomous systems, we study them\nin the context of automated driving systems where, as study subjects, we use\nDNNs automating end-to-end control of cars' steering actuators. Our results\nshow that simulator-generated datasets are able to yield DNN prediction errors\nthat are similar to those obtained by testing DNNs with real-life datasets.\nFurther, offline testing is more optimistic than online testing as many safety\nviolations identified by online testing could not be identified by offline\ntesting, while large prediction errors generated by offline testing always led\nto severe safety violations detectable by online testing.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 16:54:36 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Haq", "Fitash Ul", ""], ["Shin", "Donghwan", ""], ["Nejati", "Shiva", ""], ["Briand", "Lionel", ""]]}, {"id": "1912.00818", "submitter": "Manoj Ghuhan Arivazhagan", "authors": "Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, Sunav\n  Choudhary", "title": "Federated Learning with Personalization Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The emerging paradigm of federated learning strives to enable collaborative\ntraining of machine learning models on the network edge without centrally\naggregating raw data and hence, improving data privacy. This sharply deviates\nfrom traditional machine learning and necessitates the design of algorithms\nrobust to various sources of heterogeneity. Specifically, statistical\nheterogeneity of data across user devices can severely degrade the performance\nof standard federated averaging for traditional machine learning applications\nlike personalization with deep learning. This paper pro-posesFedPer, a base +\npersonalization layer approach for federated training of deep feedforward\nneural networks, which can combat the ill-effects of statistical heterogeneity.\nWe demonstrate effectiveness ofFedPerfor non-identical data partitions\nofCIFARdatasetsand on a personalized image aesthetics dataset from Flickr.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:29:00 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Arivazhagan", "Manoj Ghuhan", ""], ["Aggarwal", "Vinay", ""], ["Singh", "Aaditya Kumar", ""], ["Choudhary", "Sunav", ""]]}, {"id": "1912.00824", "submitter": "David Dahmen", "authors": "David Dahmen, Matthieu Gilson, Moritz Helias", "title": "Capacity of the covariance perceptron", "comments": null, "journal-ref": "Journal of Physics A: Mathematical and Theoretical 53 (2020)\n  354002", "doi": "10.1088/1751-8121/ab82dd", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical perceptron is a simple neural network that performs a binary\nclassification by a linear mapping between static inputs and outputs and\napplication of a threshold. For small inputs, neural networks in a stationary\nstate also perform an effectively linear input-output transformation, but of an\nentire time series. Choosing the temporal mean of the time series as the\nfeature for classification, the linear transformation of the network with\nsubsequent thresholding is equivalent to the classical perceptron. Here we show\nthat choosing covariances of time series as the feature for classification maps\nthe neural network to what we call a 'covariance perceptron'; a mapping between\ncovariances that is bilinear in terms of weights. By extending Gardner's theory\nof connections to this bilinear problem, using a replica symmetric mean-field\ntheory, we compute the pattern and information capacities of the covariance\nperceptron in the infinite-size limit. Closed-form expressions reveal superior\npattern capacity in the binary classification task compared to the classical\nperceptron in the case of a high-dimensional input and low-dimensional output.\nFor less convergent networks, the mean perceptron classifies a larger number of\nstimuli. However, since covariances span a much larger input and output space\nthan means, the amount of stored information in the covariance perceptron\nexceeds the classical counterpart. For strongly convergent connectivity it is\nsuperior by a factor equal to the number of input neurons. Theoretical\ncalculations are validated numerically for finite size systems using a\ngradient-based optimization of a soft-margin, as well as numerical solvers for\nthe NP hard quadratically constrained quadratic programming problem, to which\ntraining can be mapped.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:40:57 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 07:11:49 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Dahmen", "David", ""], ["Gilson", "Matthieu", ""], ["Helias", "Moritz", ""]]}, {"id": "1912.00827", "submitter": "Ben Adlam", "authors": "Ben Adlam, Jake Levinson, and Jeffrey Pennington", "title": "A Random Matrix Perspective on Mixtures of Nonlinearities for Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinguishing characteristics of modern deep learning systems is\nthat they typically employ neural network architectures that utilize enormous\nnumbers of parameters, often in the millions and sometimes even in the\nbillions. While this paradigm has inspired significant research on the\nproperties of large networks, relatively little work has been devoted to the\nfact that these networks are often used to model large complex datasets, which\nmay themselves contain millions or even billions of constraints. In this work,\nwe focus on this high-dimensional regime in which both the dataset size and the\nnumber of features tend to infinity. We analyze the performance of a simple\nregression model trained on the random features $F=f(WX+B)$ for a random weight\nmatrix $W$ and random bias vector $B$, obtaining an exact formula for the\nasymptotic training error on a noisy autoencoding task. The role of the bias\ncan be understood as parameterizing a distribution over activation functions,\nand our analysis directly generalizes to such distributions, even those not\nexpressible with a traditional additive bias. Intriguingly, we find that a\nmixture of nonlinearities can outperform the best single nonlinearity on the\nnoisy autoecndoing task, suggesting that mixtures of nonlinearities might be\nuseful for approximate kernel methods or neural network architecture design.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:43:16 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Adlam", "Ben", ""], ["Levinson", "Jake", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "1912.00832", "submitter": "Geir Kjetil Nilsen Mr", "authors": "Geir K. Nilsen and Antonella Z. Munthe-Kaas and Hans J. Skaug and\n  Morten Brun", "title": "Epistemic Uncertainty Quantification in Deep Learning Classification by\n  the Delta Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Delta method is a classical procedure for quantifying epistemic\nuncertainty in statistical models, but its direct application to deep neural\nnetworks is prevented by the large number of parameters $P$. We propose a low\ncost variant of the Delta method applicable to $L_2$-regularized deep neural\nnetworks based on the top $K$ eigenpairs of the Fisher information matrix. We\naddress efficient computation of full-rank approximate eigendecompositions in\nterms of either the exact inverse Hessian, the inverse outer-products of\ngradients approximation or the so-called Sandwich estimator. Moreover, we\nprovide a bound on the approximation error for the uncertainty of the\npredictive class probabilities. We observe that when the smallest eigenvalue of\nthe Fisher information matrix is near the $L_2$-regularization rate, the\napproximation error is close to zero even when $K\\ll P$. A demonstration of the\nmethodology is presented using a TensorFlow implementation, and we show that\nmeaningful rankings of images based on predictive uncertainty can be obtained\nfor two LeNet-based neural networks using the MNIST and CIFAR-10 datasets.\nFurther, we observe that false positives have on average a higher predictive\nepistemic uncertainty than true positives. This suggests that there is\nsupplementing information in the uncertainty measure not captured by the\nclassification alone.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 14:53:10 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 12:20:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Nilsen", "Geir K.", ""], ["Munthe-Kaas", "Antonella Z.", ""], ["Skaug", "Hans J.", ""], ["Brun", "Morten", ""]]}, {"id": "1912.00835", "submitter": "Sneha Mehta", "authors": "Sneha Mehta, Huzefa Rangwala, Naren Ramakrishnan", "title": "Low Rank Factorization for Compact Multi-Head Self-Attention", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective representation learning from text has been an active area of\nresearch in the fields of NLP and text mining. Attention mechanisms have been\nat the forefront in order to learn contextual sentence representations. Current\nstate-of-the-art approaches for many NLP tasks use large pre-trained language\nmodels such as BERT, XLNet and so on for learning representations. These models\nare based on the Transformer architecture that involves recurrent blocks of\ncomputation consisting of multi-head self-attention and feedforward networks.\nOne of the major bottlenecks largely contributing to the computational\ncomplexity of the Transformer models is the self-attention layer, that is both\ncomputationally expensive and parameter intensive. In this work, we introduce a\nnovel multi-head self-attention mechanism operating on GRUs that is shown to be\ncomputationally cheaper and more parameter efficient than self-attention\nmechanism proposed in Transformers for text classification tasks. The\nefficiency of our approach mainly stems from two optimizations; 1) we use\nlow-rank matrix factorization of the affinity matrix to efficiently get\nmultiple attention distributions instead of having separate parameters for each\nhead 2) attention scores are obtained by querying a global context vector\ninstead of densely querying all the words in the sentence. We evaluate the\nperformance of the proposed model on tasks such as sentiment analysis from\nmovie reviews, predicting business ratings from reviews and classifying news\narticles into topics. We find that the proposed approach matches or outperforms\na series of strong baselines and is more parameter efficient than comparable\nmulti-head approaches. We also perform qualitative analyses to verify that the\nproposed approach is interpretable and captures context-dependent word\nimportance.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:01:51 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 03:36:37 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mehta", "Sneha", ""], ["Rangwala", "Huzefa", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1912.00838", "submitter": "Peng Xiao Dr", "authors": "Peng Xiao, Bin Liao and Nikos Deligiannis", "title": "DeepFPC: Deep Unfolding of a Fixed-Point Continuation Algorithm for\n  Sparse Signal Recovery from Quantized Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeepFPC, a novel deep neural network designed by unfolding the\niterations of the fixed-point continuation algorithm with one-sided l1-norm\n(FPC-l1), which has been proposed for solving the 1-bit compressed sensing\nproblem. The network architecture resembles that of deep residual learning and\nincorporates prior knowledge about the signal structure (i.e., sparsity),\nthereby offering interpretability by design. Once DeepFPC is properly trained,\na sparse signal can be recovered fast and accurately from quantized\nmeasurements. The proposed model is evaluated in the task of\ndirection-of-arrival (DOA) estimation and is shown to outperform\nstate-of-the-art algorithms, namely, the iterative FPC-l1 algorithm and the\n1-bit MUSIC method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:00:21 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:51:54 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 08:43:11 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Xiao", "Peng", ""], ["Liao", "Bin", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1912.00846", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Subhadeep Dey, Hwanhee Lee, Kyomin Jung", "title": "Attentive Modality Hopping Mechanism for Speech Emotion Recognition", "comments": "5 pages, Accepted as a conference paper at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore the impact of visual modality in addition to speech\nand text for improving the accuracy of the emotion detection system. The\ntraditional approaches tackle this task by fusing the knowledge from the\nvarious modalities independently for performing emotion classification. In\ncontrast to these approaches, we tackle the problem by introducing an attention\nmechanism to combine the information. In this regard, we first apply a neural\nnetwork to obtain hidden representations of the modalities. Then, the attention\nmechanism is defined to select and aggregate important parts of the video data\nby conditioning on the audio and text data. Furthermore, the attention\nmechanism is again applied to attend important parts of the speech and textual\ndata, by considering other modality. Experiments are performed on the standard\nIEMOCAP dataset using all three modalities (audio, text, and video). The\nachieved results show a significant improvement of 3.65% in terms of weighted\naccuracy compared to the baseline system.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:23:23 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 02:18:37 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dey", "Subhadeep", ""], ["Lee", "Hwanhee", ""], ["Jung", "Kyomin", ""]]}, {"id": "1912.00848", "submitter": "Pieter-Jan Kindermans", "authors": "Wei Wen, Hanxiao Liu, Hai Li, Yiran Chen, Gabriel Bender, Pieter-Jan\n  Kindermans", "title": "Neural Predictor for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search methods are effective but often use complex\nalgorithms to come up with the best architecture. We propose an approach with\nthree basic steps that is conceptually much simpler. First we train N random\narchitectures to generate N (architecture, validation accuracy) pairs and use\nthem to train a regression model that predicts accuracy based on the\narchitecture. Next, we use this regression model to predict the validation\naccuracies of a large number of random architectures. Finally, we train the\ntop-K predicted architectures and deploy the model with the best validation\nresult. While this approach seems simple, it is more than 20 times as sample\nefficient as Regularized Evolution on the NASBench-101 benchmark and can\ncompete on ImageNet with more complex approaches based on weight sharing, such\nas ProxylessNAS.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:10:59 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wen", "Wei", ""], ["Liu", "Hanxiao", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""], ["Bender", "Gabriel", ""], ["Kindermans", "Pieter-Jan", ""]]}, {"id": "1912.00852", "submitter": "Nora Vogt", "authors": "Nora Vogt", "title": "CNNs, LSTMs, and Attention Networks for Pathology Detection in Medical\n  Data", "comments": "Master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the weakly supervised task of electrocardiogram (ECG) rhythm\nclassification, convolutional neural networks (CNNs) and long short-term memory\n(LSTM) networks are two increasingly popular classification models. This work\ninvestigates whether a combination of both architectures to so-called\nconvolutional long short-term memory (ConvLSTM) networks can improve\nclassification performances by explicitly capturing morphological as well as\ntemporal features of raw ECG records. In addition, various attention mechanisms\nare studied to localize and visualize record sections of abnormal morphology\nand irregular rhythm. The resulting saliency maps are supposed to not only\nallow for a better network understanding but to also improve clinicians'\nacceptance of automatic diagnosis in order to avoid the technique being labeled\nas a black box. In further experiments, attention mechanisms are actively\nincorporated into the training process by learning a few additional attention\ngating parameters in a CNN model. An 8-fold cross validation is finally carried\nout on the PhysioNet Computing in Cardiology (CinC) challenge 2017 to compare\nthe performances of standard CNN models, ConvLSTMs, and attention gated CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:19:41 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Vogt", "Nora", ""]]}, {"id": "1912.00858", "submitter": "Fanhua Shang", "authors": "Fanhua Shang, Bingkun Wei, Hongying Liu, Yuanyuan Liu and Jiacheng\n  Zhuo", "title": "Efficient Relaxed Gradient Support Pursuit for Sparsity Constrained\n  Non-convex Optimization", "comments": "7 pages, 3 figures, Appeared at the Data Science Meets Optimization\n  Workshop (DSO) at IJCAI'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale non-convex sparsity-constrained problems have recently gained\nextensive attention. Most existing deterministic optimization methods (e.g.,\nGraSP) are not suitable for large-scale and high-dimensional problems, and thus\nstochastic optimization methods with hard thresholding (e.g., SVRGHT) become\nmore attractive. Inspired by GraSP, this paper proposes a new general relaxed\ngradient support pursuit (RGraSP) framework, in which the sub-algorithm only\nrequires to satisfy a slack descent condition. We also design two specific\nsemi-stochastic gradient hard thresholding algorithms. In particular, our\nalgorithms have much less hard thresholding operations than SVRGHT, and their\naverage per-iteration cost is much lower (i.e., O(d) vs. O(d log(d)) for\nSVRGHT), which leads to faster convergence. Our experimental results on both\nsynthetic and real-world datasets show that our algorithms are superior to the\nstate-of-the-art gradient hard thresholding methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:25:31 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Shang", "Fanhua", ""], ["Wei", "Bingkun", ""], ["Liu", "Hongying", ""], ["Liu", "Yuanyuan", ""], ["Zhuo", "Jiacheng", ""]]}, {"id": "1912.00862", "submitter": "Fei Li", "authors": "Fei Li and Hong Yu", "title": "ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated ICD coding, which assigns the International Classification of\nDisease codes to patient visits, has attracted much research attention since it\ncan save time and labor for billing. The previous state-of-the-art model\nutilized one convolutional layer to build document representations for\npredicting ICD codes. However, the lengths and grammar of text fragments, which\nare closely related to ICD coding, vary a lot in different documents.\nTherefore, a flat and fixed-length convolutional architecture may not be\ncapable of learning good document representations. In this paper, we proposed a\nMulti-Filter Residual Convolutional Neural Network (MultiResCNN) for ICD\ncoding. The innovations of our model are two-folds: it utilizes a multi-filter\nconvolutional layer to capture various text patterns with different lengths and\na residual convolutional layer to enlarge the receptive field. We evaluated the\neffectiveness of our model on the widely-used MIMIC dataset. On the full code\nset of MIMIC-III, our model outperformed the state-of-the-art model in 4 out of\n6 evaluation metrics. On the top-50 code set of MIMIC-III and the full code set\nof MIMIC-II, our model outperformed all the existing and state-of-the-art\nmodels in all evaluation metrics. The code is available at\nhttps://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:23:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Li", "Fei", ""], ["Yu", "Hong", ""]]}, {"id": "1912.00864", "submitter": "Makoto Nakatsuji Ph. D.", "authors": "Makoto Nakatsuji, Sohei Okui", "title": "Conclusion-Supplement Answer Generation for Non-Factoid Questions", "comments": "AAAI-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the goal of conclusion-supplement answer generation for\nnon-factoid questions, which is a critical issue in the field of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), as users often\nrequire supplementary information before accepting a conclusion. The current\nencoder-decoder framework, however, has difficulty generating such answers,\nsince it may become confused when it tries to learn several different long\nanswers to the same non-factoid question. Our solution, called an ensemble\nnetwork, goes beyond single short sentences and fuses logically connected\nconclusion statements and supplementary statements. It extracts the context\nfrom the conclusion decoder's output sequence and uses it to create\nsupplementary decoder states on the basis of an attention mechanism. It also\nassesses the closeness of the question encoder's output sequence and the\nseparate outputs of the conclusion and supplement decoders as well as their\ncombination. As a result, it generates answers that match the questions and\nhave natural-sounding supplementary sequences in line with the context\nexpressed by the conclusion sequence. Evaluations conducted on datasets\nincluding \"Love Advice\" and \"Arts & Humanities\" categories indicate that our\nmodel outputs much more accurate results than the tested baseline models do.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:06:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nakatsuji", "Makoto", ""], ["Okui", "Sohei", ""]]}, {"id": "1912.00871", "submitter": "Kaden Griffith", "authors": "Kaden Griffith and Jugal Kalita", "title": "Solving Arithmetic Word Problems Automatically Using Transformer and\n  Unambiguous Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing accurate and automatic solvers of math word problems has proven\nto be quite challenging. Prior attempts using machine learning have been\ntrained on corpora specific to math word problems to produce arithmetic\nexpressions in infix notation before answer computation. We find that\ncustom-built neural networks have struggled to generalize well. This paper\noutlines the use of Transformer networks trained to translate math word\nproblems to equivalent arithmetic expressions in infix, prefix, and postfix\nnotations. In addition to training directly on domain-specific corpora, we use\nan approach that pre-trains on a general text corpus to provide foundational\nlanguage abilities to explore if it improves performance. We compare results\nproduced by a large number of neural configurations and find that most\nconfigurations outperform previously reported approaches on three of four\ndatasets with significant increases in accuracy of over 20 percentage points.\nThe best neural approaches boost accuracy by almost 10% on average when\ncompared to the previous state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:42:06 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Griffith", "Kaden", ""], ["Kalita", "Jugal", ""]]}, {"id": "1912.00872", "submitter": "Matt Chapman-Rounds", "authors": "Matt Chapman-Rounds, Marc-Andre Schulz, Erik Pazos, Konstantinos\n  Georgatzis", "title": "EMAP: Explanation by Minimal Adversarial Perturbation", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern instance-based model-agnostic explanation methods (LIME, SHAP, L2X)\nare of great use in data-heavy industries for model diagnostics, and for\nend-user explanations. These methods generally return either a weighting or\nsubset of input features as an explanation of the classification of an\ninstance. An alternative literature argues instead that counterfactual\ninstances provide a more useable characterisation of a black box classifier's\ndecisions. We present EMAP, a neural network based approach which returns as\nExplanation the Minimal Adversarial Perturbation to an instance required to\ncause the underlying black box model to missclassify. We show that this\napproach combines the two paradigms, recovering the output of feature-weighting\nmethods in continuous feature spaces, whilst also indicating the direction in\nwhich the nearest counterfactuals can be found. Our method also provides an\nimplicit confidence estimate in its own explanations, adding a clarity to model\ndiagnostics other methods lack. Additionally, EMAP improves upon the speed of\nsampling-based methods such as LIME by an order of magnitude, allowing for\nmodel explanations in time-critical applications, or at the dataset level,\nwhere sampling-based methods are infeasible. We extend our approach to\ncategorical features using a partitioned Gumbel layer, and demonstrate its\nefficacy on several standard datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:48:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Chapman-Rounds", "Matt", ""], ["Schulz", "Marc-Andre", ""], ["Pazos", "Erik", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1912.00873", "submitter": "Ehsan Kharazmi", "authors": "E. Kharazmi, Z. Zhang, G. E. Karniadakis", "title": "Variational Physics-Informed Neural Networks For Solving Partial\n  Differential Equations", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) [31] use automatic differentiation\nto solve partial differential equations (PDEs) by penalizing the PDE in the\nloss function at a random set of points in the domain of interest. Here, we\ndevelop a Petrov-Galerkin version of PINNs based on the nonlinear approximation\nof deep neural networks (DNNs) by selecting the {\\em trial space} to be the\nspace of neural networks and the {\\em test space} to be the space of Legendre\npolynomials. We formulate the \\textit{variational residual} of the PDE using\nthe DNN approximation by incorporating the variational form of the problem into\nthe loss function of the network and construct a \\textit{variational\nphysics-informed neural network} (VPINN). By integrating by parts the integrand\nin the variational form, we lower the order of the differential operators\nrepresented by the neural networks, hence effectively reducing the training\ncost in VPINNs while increasing their accuracy compared to PINNs that\nessentially employ delta test functions. For shallow networks with one hidden\nlayer, we analytically obtain explicit forms of the \\textit{variational\nresidual}. We demonstrate the performance of the new formulation for several\nexamples that show clear advantages of VPINNs over PINNs in terms of both\naccuracy and speed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:51:39 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kharazmi", "E.", ""], ["Zhang", "Z.", ""], ["Karniadakis", "G. E.", ""]]}, {"id": "1912.00874", "submitter": "Sebastian Schmon", "authors": "Jack K Fitzsimons, Sebastian M Schmon, Stephen J Roberts", "title": "Implicit Priors for Knowledge Sharing in Bayesian Neural Networks", "comments": "5 pages, 2 figures", "journal-ref": "4th workshop on Bayesian Deep Learning (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian interpretations of neural network have a long history, dating back\nto early work in the 1990's and have recently regained attention because of\ntheir desirable properties like uncertainty estimation, model robustness and\nregularisation. We want to discuss here the application of Bayesian models to\nknowledge sharing between neural networks. Knowledge sharing comes in different\nfacets, such as transfer learning, model distillation and shared embeddings.\nAll of these tasks have in common that learned \"features\" ought to be shared\nacross different networks. Theoretically rooted in the concepts of Bayesian\nneural networks this work has widespread application to general deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:52:33 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Fitzsimons", "Jack K", ""], ["Schmon", "Sebastian M", ""], ["Roberts", "Stephen J", ""]]}, {"id": "1912.00879", "submitter": "Xiyao Ma", "authors": "Xiyao Ma, Qile Zhu, Yanlin Zhou, Xiaolin Li, Dapeng Wu", "title": "Improving Question Generation with Sentence-level Semantic Matching and\n  Answer Position Inferring", "comments": "Revised version of paper accepted to Thirty-fourth AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking an answer and its context as input, sequence-to-sequence models have\nmade considerable progress on question generation. However, we observe that\nthese approaches often generate wrong question words or keywords and copy\nanswer-irrelevant words from the input. We believe that lacking global question\nsemantics and exploiting answer position-awareness not well are the key root\ncauses. In this paper, we propose a neural question generation model with two\nconcrete modules: sentence-level semantic matching and answer position\ninferring. Further, we enhance the initial state of the decoder by leveraging\nthe answer-aware gated fusion mechanism. Experimental results demonstrate that\nour model outperforms the state-of-the-art (SOTA) models on SQuAD and MARCO\ndatasets. Owing to its generality, our work also improves the existing models\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:57:40 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:38:15 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 03:13:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ma", "Xiyao", ""], ["Zhu", "Qile", ""], ["Zhou", "Yanlin", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "1912.00888", "submitter": "Nils Lukas", "authors": "Nils Lukas, Yuxuan Zhang, Florian Kerschbaum", "title": "Deep Neural Network Fingerprinting by Conferrable Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning as a Service, a provider trains a deep neural network and\ngives many users access. The hosted (source) model is susceptible to model\nstealing attacks, where an adversary derives a surrogate model from API access\nto the source model. For post hoc detection of such attacks, the provider needs\na robust method to determine whether a suspect model is a surrogate of their\nmodel. We propose a fingerprinting method for deep neural network classifiers\nthat extracts a set of inputs from the source model so that only surrogates\nagree with the source model on the classification of such inputs. These inputs\nare a subclass of transferable adversarial examples which we call conferrable\nadversarial examples that exclusively transfer with a target label from a\nsource model to its surrogates. We propose a new method to generate these\nconferrable adversarial examples. We present an extensive study on the\nirremovability of our fingerprint against fine-tuning, weight pruning,\nretraining, retraining with different architectures, three model extraction\nattacks from related work, transfer learning, adversarial training, and two new\nadaptive attacks. Our fingerprint is robust against distillation, related model\nextraction attacks, and even transfer learning when the attacker has no access\nto the model provider's dataset. Our fingerprint is the first method that\nreaches a ROC AUC of 1.0 in verifying surrogates, compared to a ROC AUC of 0.63\nby previous fingerprints.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:11:56 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 01:09:43 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 00:00:56 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 18:19:24 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Lukas", "Nils", ""], ["Zhang", "Yuxuan", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1912.00894", "submitter": "Nikolas Nuesken", "authors": "A. Duncan and N. Nuesken and L. Szpruch", "title": "On the geometry of Stein variational gradient descent", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference problems require sampling or approximating\nhigh-dimensional probability distributions. The focus of this paper is on the\nrecently introduced Stein variational gradient descent methodology, a class of\nalgorithms that rely on iterated steepest descent steps with respect to a\nreproducing kernel Hilbert space norm. This construction leads to interacting\nparticle systems, the mean-field limit of which is a gradient flow on the space\nof probability distributions equipped with a certain geometrical structure. We\nleverage this viewpoint to shed some light on the convergence properties of the\nalgorithm, in particular addressing the problem of choosing a suitable positive\ndefinite kernel function. Our analysis leads us to considering certain\nnondifferentiable kernels with adjusted tails. We demonstrate significant\nperforms gains of these in various numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:20:05 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Duncan", "A.", ""], ["Nuesken", "N.", ""], ["Szpruch", "L.", ""]]}, {"id": "1912.00895", "submitter": "Kehinde Owoeye Mr", "authors": "Kehinde Owoeye", "title": "Learning to smell for wellness", "comments": "10 pages, 1 figure", "journal-ref": "Workshop on AI for Social Good workshop NeurIPS (2019), Vancouver,\n  Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning to automatically perceive smell is becoming increasingly important\nwith applications in monitoring the quality of food and drinks for healthy\nliving. In todays age of proliferation of internet of things devices, the\ndeployment of electronic nose otherwise known as smell sensors is on the\nincrease for a variety of olfaction applications with the aid of machine\nlearning models. These models are trained to classify food and drink quality\ninto several categories depending on the granularity of interest. However,\nmodels trained to smell in one domain rarely perform adequately when used in\nanother domain. In this work, we consider a problem where only few samples are\navailable in the target domain and we are faced with the task of leveraging\nknowledge from another domain with relatively abundant data to make reliable\ninference in the target domain. We propose a weakly supervised domain\nadaptation framework where we demonstrate that by building multiple models in a\nmixture of supervised and unsupervised framework, we can generalise effectively\nfrom one domain to another. We evaluate our approach on several datasets of\nbeef cuts and quality collected across different conditions and environments.\nWe empirically show via several experiments that our approach perform\ncompetitively compared to a variety of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:20:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Owoeye", "Kehinde", ""]]}, {"id": "1912.00905", "submitter": "Roberta Falcone", "authors": "Roberta Falcone, Angela Montanari, Laura Anderlucci", "title": "Matrix sketching for supervised classification with imbalanced classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix sketching is a recently developed data compression technique. An input\nmatrix A is efficiently approximated with a smaller matrix B, so that B\npreserves most of the properties of A up to some guaranteed approximation\nratio. In so doing numerical operations on big data sets become faster.\nSketching algorithms generally use random projections to compress the original\ndataset and this stochastic generation process makes them amenable to\nstatistical analysis. The statistical properties of sketching algorithms have\nbeen widely studied in the context of multiple linear regression. In this paper\nwe propose matrix sketching as a tool for rebalancing class sizes in supervised\nclassification with imbalanced classes. It is well-known in fact that class\nimbalance may lead to poor classification performances especially as far as the\nminority class is concerned.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:33:15 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Falcone", "Roberta", ""], ["Montanari", "Angela", ""], ["Anderlucci", "Laura", ""]]}, {"id": "1912.00941", "submitter": "Le-Ha Hoang", "authors": "Le-Ha Hoang, Muhammad Abdullah Hanif, Muhammad Shafique", "title": "FT-ClipAct: Resilience Analysis of Deep Neural Networks and Improving\n  their Fault Tolerance using Clipped Activation", "comments": "The 23rd Design, Automation and Test in Europe (DATE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are widely being adopted for safety-critical\napplications, e.g., healthcare and autonomous driving. Inherently, they are\nconsidered to be highly error-tolerant. However, recent studies have shown that\nhardware faults that impact the parameters of a DNN (e.g., weights) can have\ndrastic impacts on its classification accuracy. In this paper, we perform a\ncomprehensive error resilience analysis of DNNs subjected to hardware faults\n(e.g., permanent faults) in the weight memory. The outcome of this analysis is\nleveraged to propose a novel error mitigation technique which squashes the\nhigh-intensity faulty activation values to alleviate their impact. We achieve\nthis by replacing the unbounded activation functions with their clipped\nversions. We also present a method to systematically define the clipping values\nof the activation functions that result in increased resilience of the networks\nagainst faults. We evaluate our technique on the AlexNet and the VGG-16 DNNs\ntrained for the CIFAR-10 dataset. The experimental results show that our\nmitigation technique significantly improves the resilience of the DNNs to\nfaults. For example, the proposed technique offers on average 68.92%\nimprovement in the classification accuracy of resilience-optimized VGG-16 model\nat 1e-5 fault rate, when compared to the base network without any fault\nmitigation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:14:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hoang", "Le-Ha", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1912.00947", "submitter": "Siddhartha Verma", "authors": "Sumit Vashishtha and Siddhartha Verma", "title": "Restoring Chaos Using Deep Reinforcement Learning", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": "10.1063/5.0002047", "report-no": null, "categories": "nlin.AO cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A catastrophic bifurcation in non-linear dynamical systems, called crisis,\noften leads to their convergence to an undesirable non-chaotic state after some\ninitial chaotic transients. Preventing such behavior has proved to be quite\nchallenging. We demonstrate that deep Reinforcement Learning (RL) is able to\nrestore chaos in a transiently-chaotic regime of the Lorenz system of\nequations. Without requiring any a priori knowledge of the underlying dynamics\nof the governing equations, the RL agent discovers an effective perturbation\nstrategy for sustaining the chaotic trajectory. We analyze the agent's\nautonomous control-decisions, and identify and implement a simple control-law\nthat successfully restores chaos in the Lorenz system. Our results demonstrate\nthe utility of using deep RL for controlling the occurrence of catastrophes and\nextreme-events in non-linear dynamical systems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:03:16 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Vashishtha", "Sumit", ""], ["Verma", "Siddhartha", ""]]}, {"id": "1912.00949", "submitter": "Feng Wu", "authors": "Yixiang Wang and Feng Wu", "title": "Multi-Agent Deep Reinforcement Learning with Adaptive Policies", "comments": "arXiv admin note: text overlap with arXiv:1706.02275 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to address one aspect of the non-stationarity\nproblem in multi-agent reinforcement learning (RL), where the other agents may\nalter their policies due to environment changes during execution. This violates\nthe Markov assumption that governs most single-agent RL methods and is one of\nthe key challenges in multi-agent RL. To tackle this, we propose to train\nmultiple policies for each agent and postpone the selection of the best policy\nat execution time. Specifically, we model the environment non-stationarity with\na finite set of scenarios and train policies fitting each scenario. In addition\nto multiple policies, each agent also learns a policy predictor to determine\nwhich policy is the best with its local information. By doing so, each agent is\nable to adapt its policy when the environment changes and consequentially the\nother agents alter their policies during execution. We empirically evaluated\nour method on a variety of common benchmark problems proposed for multi-agent\ndeep RL in the literature. Our experimental results show that the agents\ntrained by our algorithm have better adaptiveness in changing environments and\noutperform the state-of-the-art methods in all the tested environments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:23:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Yixiang", ""], ["Wu", "Feng", ""]]}, {"id": "1912.00953", "submitter": "Yan Wu", "authors": "Yan Wu, Jeff Donahue, David Balduzzi, Karen Simonyan, Timothy\n  Lillicrap", "title": "LOGAN: Latent Optimisation for Generative Adversarial Networks", "comments": "Improved writing, added new analysis and evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative adversarial networks requires balancing of delicate\nadversarial dynamics. Even with careful tuning, training may diverge or end up\nin a bad equilibrium with dropped modes. In this work, we improve CS-GAN with\nnatural gradient-based latent optimisation and show that it improves\nadversarial dynamics by enhancing interactions between the discriminator and\nthe generator. Our experiments demonstrate that latent optimisation can\nsignificantly improve GAN training, obtaining state-of-the-art performance for\nthe ImageNet ($128 \\times 128$) dataset. Our model achieves an Inception Score\n(IS) of $148$ and an Fr\\'echet Inception Distance (FID) of $3.4$, an\nimprovement of $17\\%$ and $32\\%$ in IS and FID respectively, compared with the\nbaseline BigGAN-deep model with the same architecture and number of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:30:05 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:53:32 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wu", "Yan", ""], ["Donahue", "Jeff", ""], ["Balduzzi", "David", ""], ["Simonyan", "Karen", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1912.00958", "submitter": "Surabhi Punjabi", "authors": "Surabhi Punjabi, Harish Arsikere, Sri Garimella", "title": "Language Model Bootstrapping Using Neural Machine Translation For\n  Conversational Speech Recognition", "comments": "Accepted by IEEE ASRU workshop, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building conversational speech recognition systems for new languages is\nconstrained by the availability of utterances that capture user-device\ninteractions. Data collection is both expensive and limited by the speed of\nmanual transcription. In order to address this, we advocate the use of neural\nmachine translation as a data augmentation technique for bootstrapping language\nmodels. Machine translation (MT) offers a systematic way of incorporating\ncollections from mature, resource-rich conversational systems that may be\navailable for a different language. However, ingesting raw translations from a\ngeneral purpose MT system may not be effective owing to the presence of named\nentities, intra sentential code-switching and the domain mismatch between the\nconversational data being translated and the parallel text used for MT\ntraining. To circumvent this, we explore the following domain adaptation\ntechniques: (a) sentence embedding based data selection for MT training, (b)\nmodel finetuning, and (c) rescoring and filtering translated hypotheses. Using\nHindi as the experimental testbed, we translate US English utterances to\nsupplement the transcribed collections. We observe a relative word error rate\nreduction of 7.8-15.6%, depending on the bootstrapping phase. Fine grained\nanalysis reveals that translation particularly aids the interaction scenarios\nwhich are underrepresented in the transcribed data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:42:58 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Punjabi", "Surabhi", ""], ["Arsikere", "Harish", ""], ["Garimella", "Sri", ""]]}, {"id": "1912.00965", "submitter": "Rizal Fathony", "authors": "Rizal Fathony and J. Zico Kolter", "title": "AP-Perf: Incorporating Generic Performance Metrics in Differentiable\n  Learning", "comments": "Appears in the Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that enables practitioners to conveniently incorporate\ncustom non-decomposable performance metrics into differentiable learning\npipelines, notably those based upon neural network architectures. Our approach\nis based on the recently developed adversarial prediction framework, a\ndistributionally robust approach that optimizes a metric in the worst case\ngiven the statistical summary of the empirical distribution. We formulate a\nmarginal distribution technique to reduce the complexity of optimizing the\nadversarial prediction formulation over a vast range of non-decomposable\nmetrics. We demonstrate how easy it is to write and incorporate complex custom\nmetrics using our provided tool. Finally, we show the effectiveness of our\napproach various classification tasks on tabular datasets from the UCI\nrepository and benchmark datasets, as well as image classification tasks. The\ncode for our proposed method is available at\nhttps://github.com/rizalzaf/AdversarialPrediction.jl.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:53:05 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:58:44 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Fathony", "Rizal", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1912.00967", "submitter": "Louis-Pascal A. C. Xhonneux", "authors": "Louis-Pascal A. C. Xhonneux, Meng Qu, and Jian Tang", "title": "Continuous Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on the connection between graph neural networks and\ntraditional dynamical systems. We propose continuous graph neural networks\n(CGNN), which generalise existing graph neural networks with discrete dynamics\nin that they can be viewed as a specific discretisation scheme. The key idea is\nhow to characterise the continuous dynamics of node representations, i.e. the\nderivatives of node representations, w.r.t. time. Inspired by existing\ndiffusion-based methods on graphs (e.g. PageRank and epidemic models on social\nnetworks), we define the derivatives as a combination of the current node\nrepresentations, the representations of neighbors, and the initial values of\nthe nodes. We propose and analyse two possible dynamics on graphs---including\neach dimension of node representations (a.k.a. the feature channel) change\nindependently or interact with each other---both with theoretical\njustification. The proposed continuous graph neural networks are robust to\nover-smoothing and hence allow us to build deeper networks, which in turn are\nable to capture the long-range dependencies between nodes. Experimental results\non the task of node classification demonstrate the effectiveness of our\nproposed approach over competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:59:12 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 21:55:28 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 14:32:36 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Xhonneux", "Louis-Pascal A. C.", ""], ["Qu", "Meng", ""], ["Tang", "Jian", ""]]}, {"id": "1912.00969", "submitter": "Youtian Lin", "authors": "Youtian Lin and Pengming Feng and Jian Guan and Wenwu Wang and\n  Jonathon Chambers", "title": "IENet: Interacting Embranchment One Stage Anchor Free Detector for\n  Orientation Aerial Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection in aerial images is a challenging task due to the lack of\nvisible features and variant orientation of objects. Significant progress has\nbeen made recently for predicting targets from aerial images with horizontal\nbounding boxes (HBBs) and oriented bounding boxes (OBBs) using two-stage\ndetectors with region based convolutional neural networks (R-CNN), involving\nobject localization in one stage and object classification in the other.\nHowever, the computational complexity in two-stage detectors is often high,\nespecially for orientational object detection, due to anchor matching and using\nregions of interest (RoI) pooling for feature extraction. In this paper, we\npropose a one-stage anchor free detector for orientational object detection,\nnamely, an interactive embranchment network (IENet), which is built upon a\ndetector with prediction in per-pixel fashion. First, a novel geometric\ntransformation is employed to better represent the oriented object in angle\nprediction, then a branch interactive module with a self-attention mechanism is\ndeveloped to fuse features from classification and box regression branches.\nFinally, we introduce an enhanced intersection over union (IoU) loss for OBB\ndetection, which is computationally more efficient than regular polygon IoU.\nExperiments conducted demonstrate the effectiveness and the superiority of our\nproposed method, as compared with state-of-the-art detectors.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:02:30 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 03:58:08 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Lin", "Youtian", ""], ["Feng", "Pengming", ""], ["Guan", "Jian", ""], ["Wang", "Wenwu", ""], ["Chambers", "Jonathon", ""]]}, {"id": "1912.00979", "submitter": "Yufan Zhou", "authors": "Yufan Zhou, Changyou Chen, Jinhui Xu", "title": "KernelNet: A Data-Dependent Kernel Parameterization for Deep Generative\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with kernels is an important concept in machine learning. Standard\napproaches for kernel methods often use predefined kernels that require careful\nselection of hyperparameters. To mitigate this burden, we propose in this paper\na framework to construct and learn a data-dependent kernel based on random\nfeatures and implicit spectral distributions that are parameterized by deep\nneural networks. The constructed network (called KernelNet) can be applied to\ndeep generative modeling in various scenarios, including two popular learning\nparadigms in deep generative models, MMD-GAN and implicit Variational\nAutoencoder (VAE). We show that our proposed kernel indeed exists in\napplications and is guaranteed to be positive definite. Furthermore, the\ninduced Maximum Mean Discrepancy (MMD) can endow the continuity property in\nweak topology by simple regularization. Extensive experiments indicate that our\nproposed KernelNet consistently achieves better performance compared to related\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:15:43 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 04:45:45 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 02:50:37 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Zhou", "Yufan", ""], ["Chen", "Changyou", ""], ["Xu", "Jinhui", ""]]}, {"id": "1912.00981", "submitter": "Samuel Drews", "authors": "Samuel Drews and Aws Albarghouthi and Loris D'Antoni", "title": "Proving Data-Poisoning Robustness in Decision Trees", "comments": "Changes: revisions to main text for clarity of presentation, and\n  corrections to proofs in the appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are brittle, and small changes in the training data\ncan result in different predictions. We study the problem of proving that a\nprediction is robust to data poisoning, where an attacker can inject a number\nof malicious elements into the training set to influence the learned model. We\ntarget decision-tree models, a popular and simple class of machine learning\nmodels that underlies many complex learning techniques. We present a sound\nverification technique based on abstract interpretation and implement it in a\ntool called Antidote. Antidote abstractly trains decision trees for an\nintractably large space of possible poisoned datasets. Due to the soundness of\nour abstraction, Antidote can produce proofs that, for a given input, the\ncorresponding prediction would not have changed had the training set been\ntampered with or not. We demonstrate the effectiveness of Antidote on a number\nof popular datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:20:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 22:40:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Drews", "Samuel", ""], ["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""]]}, {"id": "1912.00982", "submitter": "Nils Rethmeier", "authors": "Nils Rethmeier and Vageesh Kumar Saxena and Isabelle Augenstein", "title": "TX-Ray: Quantifying and Explaining Model-Knowledge Transfer in\n  (Un-)Supervised NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While state-of-the-art NLP explainability (XAI) methods focus on explaining\nper-sample decisions in supervised end or probing tasks, this is insufficient\nto explain and quantify model knowledge transfer during (un-)supervised\ntraining. Thus, for TX-Ray, we modify the established computer vision\nexplainability principle of 'visualizing preferred inputs of neurons' to make\nit usable transfer analysis and NLP. This allows one to analyze, track and\nquantify how self- or supervised NLP models first build knowledge abstractions\nin pretraining (1), and then transfer these abstractions to a new domain (2),\nor adapt them during supervised fine-tuning (3). TX-Ray expresses neurons as\nfeature preference distributions to quantify fine-grained knowledge transfer or\nadaptation and guide human analysis. We find that, similar to Lottery Ticket\nbased pruning, TX-Ray based pruning can improve test set generalization and\nthat it can reveal how early stages of self-supervision automatically learn\nlinguistic abstractions like parts-of-speech.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:21:31 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 10:18:41 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 14:24:44 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Rethmeier", "Nils", ""], ["Saxena", "Vageesh Kumar", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1912.00993", "submitter": "Pierre-Luc Delisle", "authors": "Pierre-Luc Delisle, Benoit Anctil-Robitaille, Christian Desrosiers,\n  Herve Lombaert", "title": "Adversarial normalization for multi domain image segmentation", "comments": "Submitted to ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image normalization is a critical step in medical imaging. This step is often\ndone on a per-dataset basis, preventing current segmentation algorithms from\nthe full potential of exploiting jointly normalized information across multiple\ndatasets. To solve this problem, we propose an adversarial normalization\napproach for image segmentation which learns common normalizing functions\nacross multiple datasets while retaining image realism. The adversarial\ntraining provides an optimal normalizer that improves both the segmentation\naccuracy and the discrimination of unrealistic normalizing functions. Our\ncontribution therefore leverages common imaging information from multiple\ndomains. The optimality of our common normalizer is evaluated by combining\nbrain images from both infants and adults. Results on the challenging iSEG and\nMRBrainS datasets reveal the potential of our adversarial normalization\napproach for segmentation, with Dice improvements of up to 59.6% over the\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 18:52:45 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 18:43:05 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Delisle", "Pierre-Luc", ""], ["Anctil-Robitaille", "Benoit", ""], ["Desrosiers", "Christian", ""], ["Lombaert", "Herve", ""]]}, {"id": "1912.01032", "submitter": "Zhiwei Zhang", "authors": "Anastasios Kyrillidis, Anshumali Shrivastava, Moshe Y. Vardi, Zhiwei\n  Zhang", "title": "FourierSAT: A Fourier Expansion-Based Algebraic Framework for Solving\n  Hybrid Boolean Constraints", "comments": "The paper was accepted by Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI 2020). V2 (Feb 24): Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.IT cs.LG math.IT math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Boolean SATisfiability problem (SAT) is of central importance in computer\nscience. Although SAT is known to be NP-complete, progress on the engineering\nside, especially that of Conflict-Driven Clause Learning (CDCL) and Local\nSearch SAT solvers, has been remarkable. Yet, while SAT solvers aimed at\nsolving industrial-scale benchmarks in Conjunctive Normal Form (CNF) have\nbecome quite mature, SAT solvers that are effective on other types of\nconstraints, e.g., cardinality constraints and XORs, are less well studied; a\ngeneral approach to handling non-CNF constraints is still lacking. In addition,\nprevious work indicated that for specific classes of benchmarks, the running\ntime of extant SAT solvers depends heavily on properties of the formula and\ndetails of encoding, instead of the scale of the benchmarks, which adds\nuncertainty to expectations of running time.\n  To address the issues above, we design FourierSAT, an incomplete SAT solver\nbased on Fourier analysis of Boolean functions, a technique to represent\nBoolean functions by multilinear polynomials. By such a reduction to continuous\noptimization, we propose an algebraic framework for solving systems consisting\nof different types of constraints. The idea is to leverage gradient information\nto guide the search process in the direction of local improvements. Empirical\nresults demonstrate that FourierSAT is more robust than other solvers on\ncertain classes of benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 19:01:29 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 17:51:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kyrillidis", "Anastasios", ""], ["Shrivastava", "Anshumali", ""], ["Vardi", "Moshe Y.", ""], ["Zhang", "Zhiwei", ""]]}, {"id": "1912.01051", "submitter": "Zitao Li", "authors": "Zitao Li, Tianhao Wang, Milan Lopuha\\\"a-Zwakenberg, Boris Skoric,\n  Ninghui Li", "title": "Estimating Numerical Distributions under Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When collecting information, local differential privacy (LDP) relieves the\nconcern of privacy leakage from users' perspective, as user's private\ninformation is randomized before sent to the aggregator. We study the problem\nof recovering the distribution over a numerical domain while satisfying LDP.\nWhile one can discretize a numerical domain and then apply the protocols\ndeveloped for categorical domains, we show that taking advantage of the\nnumerical nature of the domain results in better trade-off of privacy and\nutility. We introduce a new reporting mechanism, called the square wave SW\nmechanism, which exploits the numerical nature in reporting. We also develop an\nExpectation Maximization with Smoothing (EMS) algorithm, which is applied to\naggregated histograms from the SW mechanism to estimate the original\ndistributions. Extensive experiments demonstrate that our proposed approach, SW\nwith EMS, consistently outperforms other methods in a variety of utility\nmetrics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 19:26:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Zitao", ""], ["Wang", "Tianhao", ""], ["Lopuha\u00e4-Zwakenberg", "Milan", ""], ["Skoric", "Boris", ""], ["Li", "Ninghui", ""]]}, {"id": "1912.01054", "submitter": "Nicholas Heller", "authors": "Nicholas Heller, Fabian Isensee, Klaus H. Maier-Hein, Xiaoshuai Hou,\n  Chunmei Xie, Fengyi Li, Yang Nan, Guangrui Mu, Zhiyong Lin, Miofei Han, Guang\n  Yao, Yaozong Gao, Yao Zhang, Yixin Wang, Feng Hou, Jiawei Yang, Guangwei\n  Xiong, Jiang Tian, Cheng Zhong, Jun Ma, Jack Rickman, Joshua Dean, Bethany\n  Stai, Resha Tejpaul, Makinna Oestreich, Paul Blake, Heather Kaluzniak,\n  Shaneabbas Raza, Joel Rosenberg, Keenan Moore, Edward Walczak, Zachary\n  Rengel, Zach Edgerton, Ranveer Vasdev, Matthew Peterson, Sean McSweeney,\n  Sarah Peterson, Arveen Kalapara, Niranjan Sathianathen, Nikolaos\n  Papanikolopoulos, Christopher Weight", "title": "The state of the art in kidney and kidney tumor segmentation in\n  contrast-enhanced CT imaging: Results of the KiTS19 Challenge", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of literature linking anatomic and geometric\ncharacteristics of kidney tumors to perioperative and oncologic outcomes.\nSemantic segmentation of these tumors and their host kidneys is a promising\ntool for quantitatively characterizing these lesions, but its adoption is\nlimited due to the manual effort required to produce high-quality 3D\nsegmentations of these structures. Recently, methods based on deep learning\nhave shown excellent results in automatic 3D segmentation, but they require\nlarge datasets for training, and there remains little consensus on which\nmethods perform best. The 2019 Kidney and Kidney Tumor Segmentation challenge\n(KiTS19) was a competition held in conjunction with the 2019 International\nConference on Medical Image Computing and Computer Assisted Intervention\n(MICCAI) which sought to address these issues and stimulate progress on this\nautomatic segmentation problem. A training set of 210 cross sectional CT images\nwith kidney tumors was publicly released with corresponding semantic\nsegmentation masks. 106 teams from five continents used this data to develop\nautomated systems to predict the true segmentation masks on a test set of 90 CT\nimages for which the corresponding ground truth segmentations were kept\nprivate. These predictions were scored and ranked according to their average So\nrensen-Dice coefficient between the kidney and tumor across all 90 cases. The\nwinning team achieved a Dice of 0.974 for kidney and 0.851 for tumor,\napproaching the inter-annotator performance on kidney (0.983) but falling short\non tumor (0.923). This challenge has now entered an \"open leaderboard\" phase\nwhere it serves as a challenging benchmark in 3D semantic segmentation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 19:32:53 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 19:38:51 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Heller", "Nicholas", ""], ["Isensee", "Fabian", ""], ["Maier-Hein", "Klaus H.", ""], ["Hou", "Xiaoshuai", ""], ["Xie", "Chunmei", ""], ["Li", "Fengyi", ""], ["Nan", "Yang", ""], ["Mu", "Guangrui", ""], ["Lin", "Zhiyong", ""], ["Han", "Miofei", ""], ["Yao", "Guang", ""], ["Gao", "Yaozong", ""], ["Zhang", "Yao", ""], ["Wang", "Yixin", ""], ["Hou", "Feng", ""], ["Yang", "Jiawei", ""], ["Xiong", "Guangwei", ""], ["Tian", "Jiang", ""], ["Zhong", "Cheng", ""], ["Ma", "Jun", ""], ["Rickman", "Jack", ""], ["Dean", "Joshua", ""], ["Stai", "Bethany", ""], ["Tejpaul", "Resha", ""], ["Oestreich", "Makinna", ""], ["Blake", "Paul", ""], ["Kaluzniak", "Heather", ""], ["Raza", "Shaneabbas", ""], ["Rosenberg", "Joel", ""], ["Moore", "Keenan", ""], ["Walczak", "Edward", ""], ["Rengel", "Zachary", ""], ["Edgerton", "Zach", ""], ["Vasdev", "Ranveer", ""], ["Peterson", "Matthew", ""], ["McSweeney", "Sean", ""], ["Peterson", "Sarah", ""], ["Kalapara", "Arveen", ""], ["Sathianathen", "Niranjan", ""], ["Papanikolopoulos", "Nikolaos", ""], ["Weight", "Christopher", ""]]}, {"id": "1912.01070", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Pat Verga, Neha Choudhary, Andrew McCallum", "title": "Simultaneously Linking Entities and Extracting Relations from Biomedical\n  Text Without Mention-level Supervision", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of text often involves reasoning about entities and\ntheir relationships. This requires identifying textual mentions of entities,\nlinking them to a canonical concept, and discerning their relationships. These\ntasks are nearly always viewed as separate components within a pipeline, each\nrequiring a distinct model and training data. While relation extraction can\noften be trained with readily available weak or distant supervision, entity\nlinkers typically require expensive mention-level supervision -- which is not\navailable in many domains. Instead, we propose a model which is trained to\nsimultaneously produce entity linking and relation decisions while requiring no\nmention-level annotations. This approach avoids cascading errors that arise\nfrom pipelined methods and more accurately predicts entity relationships from\ntext. We show that our model outperforms a state-of-the art entity linking and\nrelation extraction pipeline on two biomedical datasets and can drastically\nimprove the overall recall of the system.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 20:37:18 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bansal", "Trapit", ""], ["Verga", "Pat", ""], ["Choudhary", "Neha", ""], ["McCallum", "Andrew", ""]]}, {"id": "1912.01089", "submitter": "Zhengze Zhou", "authors": "Zhengze Zhou, Lucas Mentch, Giles Hooker", "title": "$V$-statistics and Variance Estimation", "comments": "This version supersedes the previous technical report titled\n  \"Asymptotic Normality and Variance Estimation For Supervised Ensembles\".\n  Extensive simulations are added and we also provide a more detailed\n  discussion on the bias phenomenon in variance estimation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a general framework for analyzing asymptotics of\n$V$-statistics. Previous literature on limiting distribution mainly focuses on\nthe cases when $n \\to \\infty$ with fixed kernel size $k$. Under some regularity\nconditions, we demonstrate asymptotic normality when $k$ grows with $n$ by\nutilizing existing results for $U$-statistics. The key in our approach lies in\na mathematical reduction to $U$-statistics by designing an equivalent kernel\nfor $V$-statistics. We also provide a unified treatment on variance estimation\nfor both $U$- and $V$-statistics by observing connections to existing methods\nand proposing an empirically more accurate estimator. Ensemble methods such as\nrandom forests, where multiple base learners are trained and aggregated for\nprediction purposes, serve as a running example throughout the paper because\nthey are a natural and flexible application of $V$-statistics.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:42:19 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 02:08:01 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhou", "Zhengze", ""], ["Mentch", "Lucas", ""], ["Hooker", "Giles", ""]]}, {"id": "1912.01094", "submitter": "Kevin Matthew Stangl", "authors": "Avrim Blum, Kevin Stangl", "title": "Recovering from Biased Data: Can Fairness Constraints Improve Accuracy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple fairness constraints have been proposed in the literature, motivated\nby a range of concerns about how demographic groups might be treated unfairly\nby machine learning classifiers. In this work we consider a different\nmotivation; learning from biased training data. We posit several ways in which\ntraining data may be biased, including having a more noisy or negatively biased\nlabeling process on members of a disadvantaged group, or a decreased prevalence\nof positive or negative examples from the disadvantaged group, or both.\n  Given such biased training data, Empirical Risk Minimization (ERM) may\nproduce a classifier that not only is biased but also has suboptimal accuracy\non the true data distribution. We examine the ability of fairness-constrained\nERM to correct this problem. In particular, we find that the Equal Opportunity\nfairness constraint (Hardt, Price, and Srebro 2016) combined with ERM will\nprovably recover the Bayes Optimal Classifier under a range of bias models. We\nalso consider other recovery methods including reweighting the training data,\nEqualized Odds, and Demographic Parity. These theoretical results provide\nadditional motivation for considering fairness interventions even if an actor\ncares primarily about accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:00:14 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Blum", "Avrim", ""], ["Stangl", "Kevin", ""]]}, {"id": "1912.01096", "submitter": "Shen Zhang", "authors": "Shen Zhang, Fei Ye, Bingnan Wang, Thomas G. Habetler", "title": "Semi-Supervised Learning of Bearing Anomaly Detection via Deep\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the data-driven approaches applied to bearing fault diagnosis up to\ndate are established in the supervised learning paradigm, which usually\nrequires a large set of labeled data collected a priori. In practical\napplications, however, obtaining accurate labels based on real-time bearing\nconditions can be far more challenging than simply collecting a huge amount of\nunlabeled data using various sensors. In this paper, we thus propose a\nsemi-supervised learning approach for bearing anomaly detection using\nvariational autoencoder (VAE) based deep generative models, which allows for\neffective utilization of dataset when only a small subset of data have labels.\nFinally, a series of experiments is performed using both the Case Western\nReserve University (CWRU) bearing dataset and the University of Cincinnati's\nCenter for Intelligent Maintenance Systems (IMS) dataset. The experimental\nresults demonstrate that the proposed semi-supervised learning scheme greatly\noutperforms two mainstream semi-supervised learning approaches and a baseline\nsupervised convolutional neural network approach, with the overall accuracy\nimprovement ranging between 3% to 30% using different proportions of labeled\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:10:39 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 03:29:37 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Shen", ""], ["Ye", "Fei", ""], ["Wang", "Bingnan", ""], ["Habetler", "Thomas G.", ""]]}, {"id": "1912.01098", "submitter": "Sandeep Silwal", "authors": "Rikhav Shah, Sandeep Silwal", "title": "Using Dimensionality Reduction to Optimize t-SNE", "comments": "11th Annual Workshop on Optimization for Machine Learning (OPT2019 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-SNE is a popular tool for embedding multi-dimensional datasets into two or\nthree dimensions. However, it has a large computational cost, especially when\nthe input data has many dimensions. Many use t-SNE to embed the output of a\nneural network, which is generally of much lower dimension than the original\ndata. This limits the use of t-SNE in unsupervised scenarios. We propose using\n\\textit{random} projections to embed high dimensional datasets into relatively\nfew dimensions, and then using t-SNE to obtain a two dimensional embedding. We\nshow that random projections preserve the desirable clustering achieved by\nt-SNE, while dramatically reducing the runtime of finding the embedding.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:12:16 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Shah", "Rikhav", ""], ["Silwal", "Sandeep", ""]]}, {"id": "1912.01100", "submitter": "Vincenzo Lomonaco PhD", "authors": "Lorenzo Pellegrini, Gabriele Graffieti, Vincenzo Lomonaco, Davide\n  Maltoni", "title": "Latent Replay for Real-Time Continual Learning", "comments": "Pre-print v3: 13 pages, 9 figures, 10 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks at the edge on light computational devices,\nembedded systems and robotic platforms is nowadays very challenging. Continual\nlearning techniques, where complex models are incrementally trained on small\nbatches of new data, can make the learning problem tractable even for CPU-only\nembedded devices enabling remarkable levels of adaptiveness and autonomy.\nHowever, a number of practical problems need to be solved: catastrophic\nforgetting before anything else. In this paper we introduce an original\ntechnique named \"Latent Replay\" where, instead of storing a portion of past\ndata in the input space, we store activations volumes at some intermediate\nlayer. This can significantly reduce the computation and storage required by\nnative rehearsal. To keep the representation stable and the stored activations\nvalid we propose to slow-down learning at all the layers below the latent\nreplay one, leaving the layers above free to learn at full pace. In our\nexperiments we show that Latent Replay, combined with existing continual\nlearning techniques, achieves state-of-the-art performance on complex video\nbenchmarks such as CORe50 NICv2 (with nearly 400 small and highly non-i.i.d.\nbatches) and OpenLORIS. Finally, we demonstrate the feasibility of nearly\nreal-time continual learning on the edge through the deployment of the proposed\ntechnique on a smartphone device.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:16:32 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 09:50:32 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Pellegrini", "Lorenzo", ""], ["Graffieti", "Gabriele", ""], ["Lomonaco", "Vincenzo", ""], ["Maltoni", "Davide", ""]]}, {"id": "1912.01101", "submitter": "Aaron Defazio", "authors": "Aaron Defazio", "title": "Offset Sampling Improves Deep Learning based Accelerated MRI\n  Reconstructions by Exploiting Symmetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning approaches to accelerated MRI take a matrix of sampled\nFourier-space lines as input and produce a spatial image as output. In this\nwork we show that by careful choice of the offset used in the sampling\nprocedure, the symmetries in k-space can be better exploited, producing higher\nquality reconstructions than given by standard equally-spaced samples or\nrandomized samples motivated by compressed sensing.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:29:26 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 17:06:58 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Defazio", "Aaron", ""]]}, {"id": "1912.01105", "submitter": "Javier Trejos", "authors": "Jeffry Chavarria-Molina, Juan Jose Fallas-Monge, Javier Trejos-Zelaya", "title": "Clustering via Ant Colonies: Parameter Analysis and Improvement of the\n  Algorithm", "comments": "19 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An ant colony optimization approach for partitioning a set of objects is\nproposed. In order to minimize the intra-variance, or within sum-of-squares, of\nthe partitioned classes, we construct ant-like solutions by a constructive\napproach that selects objects to be put in a class with a probability that\ndepends on the distance between the object and the centroid of the class\n(visibility) and the pheromone trail; the latter depends on the class\nmemberships that have been defined along the iterations. The procedure is\nimproved with the application of K-means algorithm in some iterations of the\nant colony method. We performed a simulation study in order to evaluate the\nmethod with a Monte Carlo experiment that controls some sensitive parameters of\nthe clustering problem. After some tuning of the parameters, the method has\nalso been applied to some benchmark real-data sets. Encouraging results were\nobtained in nearly all cases.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:38:31 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chavarria-Molina", "Jeffry", ""], ["Fallas-Monge", "Juan Jose", ""], ["Trejos-Zelaya", "Javier", ""]]}, {"id": "1912.01108", "submitter": "David Inouye", "authors": "David I. Inouye, Liu Leqi, Joon Sik Kim, Bryon Aragam, Pradeep\n  Ravikumar", "title": "Automated Dependence Plots", "comments": "In Uncertainty in Artificial Intelligence (UAI 2020). Camera-ready\n  version. Code is available at https://github.com/davidinouye/adp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical applications of machine learning, it is necessary to look beyond\nstandard metrics such as test accuracy in order to validate various qualitative\nproperties of a model. Partial dependence plots (PDP), including\ninstance-specific PDPs (i.e., ICE plots), have been widely used as a visual\ntool to understand or validate a model. Yet, current PDPs suffer from two main\ndrawbacks: (1) a user must manually sort or select interesting plots, and (2)\nPDPs are usually limited to plots along a single feature. To address these\ndrawbacks, we formalize a method for automating the selection of interesting\nPDPs and extend PDPs beyond showing single features to show the model response\nalong arbitrary directions, for example in raw feature space or a latent space\narising from some generative model. We demonstrate the usefulness of our\nautomated dependence plots (ADP) across multiple use-cases and datasets\nincluding model selection, bias detection, understanding out-of-sample\nbehavior, and exploring the latent space of a generative model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:46:55 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 15:56:08 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 21:00:01 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Inouye", "David I.", ""], ["Leqi", "Liu", ""], ["Kim", "Joon Sik", ""], ["Aragam", "Bryon", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1912.01109", "submitter": "Ngoc L\\^e", "authors": "Ngoc C. L\\^e, Ngoc-Yen Nguyen, and Anh-Duong Trinh", "title": "On the Vietnamese Name Entity Recognition: A Deep Learning Method\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) plays an important role in text-based\ninformation retrieval. In this paper, we combine Bidirectional Long Short-Term\nMemory (Bi-LSTM) \\cite{hochreiter1997,schuster1997} with Conditional Random\nField (CRF) \\cite{lafferty2001} to create a novel deep learning model for the\nNER problem. Each word as input of the deep learning model is represented by a\nWord2vec-trained vector. A word embedding set trained from about one million\narticles in 2018 collected through a Vietnamese news portal (baomoi.com). In\naddition, we concatenate a Word2Vec\\cite{mikolov2013}-trained vector with\nsemantic feature vector (Part-Of-Speech (POS) tagging, chunk-tag) and hidden\nsyntactic feature vector (extracted by Bi-LSTM nerwork) to achieve the (so far\nbest) result in Vietnamese NER system. The result was conducted on the data set\nVLSP2016 (Vietnamese Language and Speech Processing 2016 \\cite{vlsp2016})\ncompetition.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 13:28:37 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["L\u00ea", "Ngoc C.", ""], ["Nguyen", "Ngoc-Yen", ""], ["Trinh", "Anh-Duong", ""]]}, {"id": "1912.01110", "submitter": "Vijini Supun Keerthisrini Pilana Liyanage", "authors": "Vijini Liyanage and Surangika Ranathunga", "title": "A Multi-language Platform for Generating Algebraic Mathematical Word\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for automatically generating mathematical word problems\nare deprived of customizability and creativity due to the inherent nature of\ntemplate-based mechanisms they employ. We present a solution to this problem\nwith the use of deep neural language generation mechanisms. Our approach uses a\nCharacter Level Long Short Term Memory Network (LSTM) to generate word\nproblems, and uses POS (Part of Speech) tags to resolve the constraints found\nin the generated problems. Our approach is capable of generating Mathematics\nWord Problems in both English and Sinhala languages with an accuracy over 90%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:50:45 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Liyanage", "Vijini", ""], ["Ranathunga", "Surangika", ""]]}, {"id": "1912.01111", "submitter": "Jayanta Mandi", "authors": "Dipankar Chakrabarti, Neelam Patodia, Udayan Bhattacharya, Indranil\n  Mitra, Satyaki Roy, Jayanta Mandi, Nandini Roy, Prasun Nandy", "title": "Use of Artificial Intelligence to Analyse Risk in Legal Documents for a\n  Better Decision Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Assessing risk for voluminous legal documents such as request for proposal;\ncontracts is tedious and error prone. We have developed \"risk-o-meter\", a\nframework, based on machine learning and natural language processing to review\nand assess risks of any legal document. Our framework uses Paragraph Vector, an\nunsupervised model to generate vector representation of text. This enables the\nframework to learn contextual relations of legal terms and generate sensible\ncontext aware embedding. The framework then feeds the vector space into a\nsupervised classification algorithm to predict whether a paragraph belongs to a\nper-defined risk category or not. The framework thus extracts risk prone\nparagraphs. This technique efficiently overcomes the limitations of\nkeyword-based search. We have achieved an accuracy of 91% for the risk category\nhaving the largest training dataset. This framework will help organizations\noptimize effort to identify risk from large document base with minimal human\nintervention and thus will help to have risk mitigated sustainable growth. Its\nmachine learning capability makes it scalable to uncover relevant information\nfrom any type of document apart from legal documents, provided the library is\nper-populated and rich.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:07:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chakrabarti", "Dipankar", ""], ["Patodia", "Neelam", ""], ["Bhattacharya", "Udayan", ""], ["Mitra", "Indranil", ""], ["Roy", "Satyaki", ""], ["Mandi", "Jayanta", ""], ["Roy", "Nandini", ""], ["Nandy", "Prasun", ""]]}, {"id": "1912.01115", "submitter": "Karol Chlasta", "authors": "Karol Chlasta, Krzysztof Wo{\\l}k, Izabela Krejtz", "title": "Automated speech-based screening of depression using deep convolutional\n  neural networks", "comments": "10 pages, 8 figures and 2 tables, HCist 2019 - 8th International\n  Conference on Health and Social Care Information Systems and Technologies\n  (16-18 October 2019, Sousse, Tunisia)", "journal-ref": "Procedia Computer Science 164 (2019) 618-628", "doi": "10.1016/j.procs.2019.12.228", "report-no": null, "categories": "cs.LG cs.CV cs.CY cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection and treatment of depression is essential in promoting\nremission, preventing relapse, and reducing the emotional burden of the\ndisease. Current diagnoses are primarily subjective, inconsistent across\nprofessionals, and expensive for individuals who may be in urgent need of help.\nThis paper proposes a novel approach to automated depression detection in\nspeech using convolutional neural network (CNN) and multipart interactive\ntraining. The model was tested using 2568 voice samples obtained from 77\nnon-depressed and 30 depressed individuals. In experiment conducted, data were\napplied to residual CNNs in the form of spectrograms, images auto-generated\nfrom audio samples. The experimental results obtained using different ResNet\narchitectures gave a promising baseline accuracy reaching 77%.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:58:40 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chlasta", "Karol", ""], ["Wo\u0142k", "Krzysztof", ""], ["Krejtz", "Izabela", ""]]}, {"id": "1912.01116", "submitter": "Jeremy Gordon", "authors": "Jeremy Gordon, David Rawlinson, Subutai Ahmad", "title": "Long Distance Relationships without Time Travel: Boosting the\n  Performance of a Sparse Predictive Autoencoder in Sequence Modeling", "comments": "9 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence learning tasks such as language modelling, Recurrent Neural\nNetworks must learn relationships between input features separated by time.\nState of the art models such as LSTM and Transformer are trained by\nbackpropagation of losses into prior hidden states and inputs held in memory.\nThis allows gradients to flow from present to past and effectively learn with\nperfect hindsight, but at a significant memory cost. In this paper we show that\nit is possible to train high performance recurrent networks using information\nthat is local in time, and thereby achieve a significantly reduced memory\nfootprint. We describe a predictive autoencoder called bRSM featuring recurrent\nconnections, sparse activations, and a boosting rule for improved cell\nutilization. The architecture demonstrates near optimal performance on a\nnon-deterministic (stochastic) partially-observable sequence learning task\nconsisting of high-Markov-order sequences of MNIST digits. We find that this\nmodel learns these sequences faster and more completely than an LSTM, and offer\nseveral possible explanations why the LSTM architecture might struggle with the\npartially observable sequence structure in this task. We also apply our model\nto a next word prediction task on the Penn Treebank (PTB) dataset. We show that\na 'flattened' RSM network, when paired with a modern semantic word embedding\nand the addition of boosting, achieves 103.5 PPL (a 20-point improvement over\nthe best N-gram models), beating ordinary RNNs trained with BPTT and\napproaching the scores of early LSTM implementations. This work provides\nencouraging evidence that strong results on challenging tasks such as language\nmodelling may be possible using less memory intensive, biologically-plausible\ntraining regimes.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 23:00:13 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Gordon", "Jeremy", ""], ["Rawlinson", "David", ""], ["Ahmad", "Subutai", ""]]}, {"id": "1912.01122", "submitter": "Zhou Yang", "authors": "Zhou Yang, Spencer Bradshaw, Rattikorn Hewett, and Fang Jin", "title": "Discovering Opioid Use Patterns from Social Media for Relapse Prevention", "comments": "7 pages, and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The United States is currently experiencing an unprecedented opioid crisis,\nand opioid overdose has become a leading cause of injury and death. Effective\nopioid addiction recovery calls for not only medical treatments, but also\nbehavioral interventions for impacted individuals. In this paper, we study\ncommunication and behavior patterns of patients with opioid use disorder (OUD)\nfrom social media, intending to demonstrate how existing information from\ncommon activities, such as online social networking, might lead to better\nprediction, evaluation, and ultimately prevention of relapses. Through a\nmulti-disciplinary and advanced novel analytic perspective, we characterize\nopioid addiction behavior patterns by analyzing opioid groups from Reddit.com -\nincluding modeling online discussion topics, analyzing text co-occurrence and\ncorrelations, and identifying emotional states of people with OUD. These\nquantitative analyses are of practical importance and demonstrate innovative\nways to use information from online social media, to create technology that can\nassist in relapse prevention.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 23:15:02 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Yang", "Zhou", ""], ["Bradshaw", "Spencer", ""], ["Hewett", "Rattikorn", ""], ["Jin", "Fang", ""]]}, {"id": "1912.01130", "submitter": "Zhou Yang", "authors": "Zhou Yang, Vinay Jayachandra Reddy, Rashmi Kesidi, Fang Jin", "title": "Addict Free -- A Smart and Connected Relapse Intervention Mobile App", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is widely acknowledged that addiction relapse is highly associated with\nspatial-temporal factors such as some specific places or time periods. Current\nstudies suggest that those factors can be utilized for better relapse\ninterventions, however, there is no relapse prevention application that makes\nuse of those factors. In this paper, we introduce a mobile app called \"Addict\nFree\", which records user profiles, tracks relapse history and summarizes\nrecovering statistics to help users better understand their recovering\nsituations. Also, this app builds a relapse recovering community, which allows\nusers to ask for advice and encouragement, and share relapse prevention\nexperience. Moreover, machine learning algorithms that ingest spatial and\ntemporal factors are utilized to predict relapse, based on which helpful\naddiction diversion activities are recommended by a recovering recommendation\nalgorithm. By interacting with users, this app targets at providing smart\nsuggestions that aim to stop relapse, especially for alcohol and tobacco\naddiction users.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 23:38:22 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Yang", "Zhou", ""], ["Reddy", "Vinay Jayachandra", ""], ["Kesidi", "Rashmi", ""], ["Jin", "Fang", ""]]}, {"id": "1912.01137", "submitter": "Pitoyo Hartono", "authors": "Pitoyo Hartono", "title": "Mixing autoencoder with classifier: conceptual data visualization", "comments": null, "journal-ref": "IEEE Access, vol. 8, no. 1, pp. 105301-105310, 2020", "doi": "10.1109/ACCESS.2020.2999155", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short paper, a neural network that is able to form a low dimensional\ntopological hidden representation is explained. The neural network can be\ntrained as an autoencoder, a classifier or mix of both, and produces different\nlow dimensional topological map for each of them. When it is trained as an\nautoencoder, the inherent topological structure of the data can be visualized,\nwhile when it is trained as a classifier, the topological structure is further\nconstrained by the concept, for example the labels the data, hence the\nvisualization is not only structural but also conceptual. The proposed neural\nnetwork significantly differ from many dimensional reduction models, primarily\nin its ability to execute both supervised and unsupervised dimensional\nreduction. The neural network allows multi perspective visualization of the\ndata, and thus giving more flexibility in data analysis. This paper is\nsupported by preliminary but intuitive visualization experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 00:33:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 07:46:11 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 10:27:28 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hartono", "Pitoyo", ""]]}, {"id": "1912.01139", "submitter": "Hao Huang", "authors": "Fei Huang and Hao Huang", "title": "Event Ticket Price Prediction with Deep Neural Network on\n  Spatial-Temporal Sparse Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Event ticket price prediction is important to marketing strategy for any\nsports team or musical ensemble. An accurate prediction model can help the\nmarketing team to make promotion plan more effectively and efficiently.\nHowever, given all the historical transaction records, it is challenging to\npredict the sale price of the remaining seats at any future timestamp, not only\nbecause that the sale price is relevant to a lot of features (seat locations,\ndate-to-event of the transaction, event date, team performance, etc.), but also\nbecause of the temporal and spatial sparsity in the dataset. For a\ngame/concert, the ticket selling price of one seat is only observable once at\nthe time of sale. Furthermore, some seats may not even be purchased (therefore\nno record available). In fact, data sparsity is commonly encountered in many\nprediction problems. Here, we propose a bi-level optimizing deep neural network\nto address the curse of spatio-temporal sparsity. Specifically, we introduce\ncoarsening and refining layers, and design a bi-level loss function to\nintegrate different level of loss for better prediction accuracy. Our model can\ndiscover the interrelations among ticket sale price, seat locations, selling\ntime, event information, etc. Experiments show that our proposed model\noutperforms other benchmark methods in real-world ticket selling price\nprediction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 00:53:57 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 22:03:40 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Huang", "Fei", ""], ["Huang", "Hao", ""]]}, {"id": "1912.01144", "submitter": "Seyed Mostafa Mousavi", "authors": "S.Mostafa Mousavi and Gregory C. Beroza", "title": "Bayesian-Deep-Learning Estimation of Earthquake Location from\n  Single-Station Observations", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2020.2988770", "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning method for single-station earthquake location,\nwhich we approach as a regression problem using two separate Bayesian neural\nnetworks. We use a multi-task temporal-convolutional neural network to learn\nepicentral distance and P travel time from 1-minute seismograms. The network\nestimates epicentral distance and P travel time with absolute mean errors of\n0.23 km and 0.03 s respectively, along with their epistemic and aleatory\nuncertainties. We design a separate multi-input network using standard\nconvolutional layers to estimate the back-azimuth angle, and its epistemic\nuncertainty. This network estimates the direction from which seismic waves\narrive to the station with a mean error of 1 degree. Using this information, we\nestimate the epicenter, origin time, and depth along with their confidence\nintervals. We use a global dataset of earthquake signals recorded within 1\ndegree (~112 km) from the event to build the model and to demonstrate its\nperformance. Our model can predict epicenter, origin time, and depth with mean\nerrors of 7.3 km, 0.4 second, and 6.7 km respectively, at different locations\naround the world. Our approach can be used for fast earthquake source\ncharacterization with a limited number of observations, and also for estimating\nlocation of earthquakes that are sparsely recorded -- either because they are\nsmall or because stations are widely separated.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 01:20:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mousavi", "S. Mostafa", ""], ["Beroza", "Gregory C.", ""]]}, {"id": "1912.01148", "submitter": "Antonio Busson", "authors": "Eduardo Betine Bucker, Antonio Jos\\'e Grandson Busson, Ruy Luiz\n  Milidi\\'u, S\\'ergio Colcher, Bruno Pereira Dias, Andr\\'e Bulc\\~ao", "title": "A Deep Convolutional Network for Seismic Shot-Gather Image Quality\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning-based models such as Convolutional Neural Networks, have led to\nsignificant advancements in several areas of computing applications. Seismogram\nquality assurance is a relevant Geophysics task, since in the early stages of\nseismic processing, we are required to identify and fix noisy sail lines. In\nthis work, we introduce a real-world seismogram quality classification dataset\nbased on 6,613 examples, manually labeled by human experts as good, bad or\nugly, according to their noise intensity. This dataset is used to train a CNN\nclassifier for seismic shot-gathers quality prediction. In our empirical\nevaluation, we observe an F1-score of 93.56% in the test set.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 01:48:20 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bucker", "Eduardo Betine", ""], ["Busson", "Antonio Jos\u00e9 Grandson", ""], ["Milidi\u00fa", "Ruy Luiz", ""], ["Colcher", "S\u00e9rgio", ""], ["Dias", "Bruno Pereira", ""], ["Bulc\u00e3o", "Andr\u00e9", ""]]}, {"id": "1912.01149", "submitter": "Yizheng Chen", "authors": "Yizheng Chen, Shiqi Wang, Weifan Jiang, Asaf Cidon, Suman Jana", "title": "Cost-Aware Robust Tree Ensembles for Security Applications", "comments": "USENIX Security 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are various costs for attackers to manipulate the features of security\nclassifiers. The costs are asymmetric across features and to the directions of\nchanges, which cannot be precisely captured by existing cost models based on\n$L_p$-norm robustness. In this paper, we utilize such domain knowledge to\nincrease the attack cost of evading classifiers, specifically, tree ensemble\nmodels that are widely used by security tasks. We propose a new cost modeling\nmethod to capture the feature manipulation cost as constraint, and then we\nintegrate the cost-driven constraint into the node construction process to\ntrain robust tree ensembles. During the training process, we use the constraint\nto find data points that are likely to be perturbed given the feature\nmanipulation cost, and we use a new robust training algorithm to optimize the\nquality of the trees. Our cost-aware training method can be applied to\ndifferent types of tree ensembles, including gradient boosted decision trees\nand random forest models. Using Twitter spam detection as the case study, our\nevaluation results show that we can increase the attack cost by 10.6X compared\nto the baseline. Moreover, our robust training method using cost-driven\nconstraint can achieve higher accuracy, lower false positive rate, and stronger\ncost-aware robustness than the state-of-the-art training method using\n$L_\\infty$-norm cost model. Our code is available at\nhttps://github.com/surrealyz/growtrees.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:02:59 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 22:06:14 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 18:04:40 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 15:38:15 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 02:07:27 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chen", "Yizheng", ""], ["Wang", "Shiqi", ""], ["Jiang", "Weifan", ""], ["Cidon", "Asaf", ""], ["Jana", "Suman", ""]]}, {"id": "1912.01163", "submitter": "Brighter Agyemang", "authors": "Brighter Agyemang and Wei-Ping Wu and Michael Y. Kpiebaareh and\n  Ebenezer Nanor", "title": "Drug-Target Indication Prediction by Integrating End-to-End Learning and\n  Fingerprints", "comments": "Accepted at IEEE ICCWAMTIP 2019", "journal-ref": null, "doi": "10.1109/ICCWAMTIP47768.2019.9067510", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-Aided Drug Discovery research has proven to be a promising direction\nin drug discovery. In recent years, Deep Learning approaches have been applied\nto problems in the domain such as Drug-Target Interaction Prediction and have\nshown improvements over traditional screening methods. An existing challenge is\nhow to represent compound-target pairs in deep learning models. While several\nrepresentation methods exist, such descriptor schemes tend to complement one\nanother in many instances, as reported in the literature. In this study, we\npropose a multi-view architecture trained adversarially to leverage this\ncomplementary behavior by integrating both differentiable and predefined\nmolecular descriptors. We conduct experiments on clinically relevant benchmark\ndatasets to demonstrate the potential of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:43:19 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 04:25:02 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Agyemang", "Brighter", ""], ["Wu", "Wei-Ping", ""], ["Kpiebaareh", "Michael Y.", ""], ["Nanor", "Ebenezer", ""]]}, {"id": "1912.01166", "submitter": "Dongrui Wu", "authors": "He He and Dongrui Wu", "title": "Different Set Domain Adaptation for Brain-Computer Interfaces: A Label\n  Alignment Approach", "comments": "IEEE Trans. on Neural Systems and Rehabilitation Engineering, 2020", "journal-ref": "IEEE Trans. on Neural Systems and Rehabilitation Engineering,\n  28(5), pp. 1091-1108, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brain-computer interface (BCI) system usually needs a long calibration\nsession for each new subject/task to adjust its parameters, which impedes its\ntransition from the laboratory to real-world applications. Domain adaptation,\nwhich leverages labeled data from auxiliary subjects/tasks (source domains),\nhas demonstrated its effectiveness in reducing such calibration effort.\nCurrently, most domain adaptation approaches require the source domains to have\nthe same feature space and label space as the target domain, which limits their\napplications, as the auxiliary data may have different feature spaces and/or\ndifferent label spaces. This paper considers different set domain adaptation\nfor BCIs, i.e., the source and target domains have different label spaces. We\nintroduce a practical setting of different label sets for BCIs, and propose a\nnovel label alignment (LA) approach to align the source label space with the\ntarget label space. It has three desirable properties: 1) LA only needs as few\nas one labeled sample from each class of the target subject; 2) LA can be used\nas a preprocessing step before different feature extraction and classification\nalgorithms; and, 3) LA can be integrated with other domain adaptation\napproaches to achieve even better performance. Experiments on two motor imagery\ndatasets demonstrated the effectiveness of LA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:46:56 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 18:05:56 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 21:11:36 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 02:51:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["He", "He", ""], ["Wu", "Dongrui", ""]]}, {"id": "1912.01170", "submitter": "Mahdi Haghifam", "authors": "Mahdi Haghifam, Vincent Y. F. Tan, Ashish Khisti", "title": "Sequential Classification with Empirically Observed Statistics", "comments": "17 Pages, 5 Figures. To appear in the IEEE Transactions on\n  Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by real-world machine learning applications, we consider a\nstatistical classification task in a sequential setting where test samples\narrive sequentially. In addition, the generating distributions are unknown and\nonly a set of empirically sampled sequences are available to a decision maker.\nThe decision maker is tasked to classify a test sequence which is known to be\ngenerated according to either one of the distributions. In particular, for the\nbinary case, the decision maker wishes to perform the classification task with\nminimum number of the test samples, so, at each step, she declares that either\nhypothesis 1 is true, hypothesis 2 is true, or she requests for an additional\ntest sample. We propose a classifier and analyze the type-I and type-II error\nprobabilities. We demonstrate the significant advantage of our sequential\nscheme compared to an existing non-sequential classifier proposed by Gutman.\nFinally, we extend our setup and results to the multi-class classification\nscenario and again demonstrate that the variable-length nature of the problem\naffords significant advantages as one can achieve the same set of exponents as\nGutman's fixed-length setting but without having the rejection option.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:59:38 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 13:27:16 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 03:04:07 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Haghifam", "Mahdi", ""], ["Tan", "Vincent Y. F.", ""], ["Khisti", "Ashish", ""]]}, {"id": "1912.01171", "submitter": "Dongrui Wu", "authors": "Zihan Liu and Lubin Meng and Xiao Zhang and Weili Fang and Dongrui Wu", "title": "Universal Adversarial Perturbations for CNN Classifiers in EEG-Based\n  BCIs", "comments": null, "journal-ref": "Journal of Neural Engineering, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple convolutional neural network (CNN) classifiers have been proposed\nfor electroencephalogram (EEG) based brain-computer interfaces (BCIs). However,\nCNN models have been found vulnerable to universal adversarial perturbations\n(UAPs), which are small and example-independent, yet powerful enough to degrade\nthe performance of a CNN model, when added to a benign example. This paper\nproposes a novel total loss minimization (TLM) approach to generate UAPs for\nEEG-based BCIs. Experimental results demonstrated the effectiveness of TLM on\nthree popular CNN classifiers for both target and non-target attacks. We also\nverified the transferability of UAPs in EEG-based BCI systems. To our\nknowledge, this is the first study on UAPs of CNN classifiers in EEG-based\nBCIs. UAPs are easy to construct, and can attack BCIs in real-time, exposing a\npotentially critical security concern of BCIs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:00:08 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 22:38:54 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 20:34:58 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 16:03:24 GMT"}, {"version": "v5", "created": "Thu, 24 Jun 2021 02:03:24 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Liu", "Zihan", ""], ["Meng", "Lubin", ""], ["Zhang", "Xiao", ""], ["Fang", "Weili", ""], ["Wu", "Dongrui", ""]]}, {"id": "1912.01172", "submitter": "Smitha Milli", "authors": "Ravit Dotan and Smitha Milli", "title": "Value-laden Disciplinary Shifts in Machine Learning", "comments": "Accepted to FAT* 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning models are increasingly used for high-stakes decision\nmaking, scholars have sought to intervene to ensure that such models do not\nencode undesirable social and political values. However, little attention thus\nfar has been given to how values influence the machine learning discipline as a\nwhole. How do values influence what the discipline focuses on and the way it\ndevelops? If undesirable values are at play at the level of the discipline,\nthen intervening on particular models will not suffice to address the problem.\nInstead, interventions at the disciplinary-level are required. This paper\nanalyzes the discipline of machine learning through the lens of philosophy of\nscience. We develop a conceptual framework to evaluate the process through\nwhich types of machine learning models (e.g. neural networks, support vector\nmachines, graphical models) become predominant. The rise and fall of\nmodel-types is often framed as objective progress. However, such disciplinary\nshifts are more nuanced. First, we argue that the rise of a model-type is\nself-reinforcing--it influences the way model-types are evaluated. For example,\nthe rise of deep learning was entangled with a greater focus on evaluations in\ncompute-rich and data-rich environments. Second, the way model-types are\nevaluated encodes loaded social and political values. For example, a greater\nfocus on evaluations in compute-rich and data-rich environments encodes values\nabout centralization of power, privacy, and environmental concerns.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:01:27 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Dotan", "Ravit", ""], ["Milli", "Smitha", ""]]}, {"id": "1912.01180", "submitter": "Yi Zhang", "authors": "Yi Zhang, Xinyue Wei, Weichao Qiu, Zihao Xiao, Gregory D. Hager and\n  Alan Yuille", "title": "RSA: Randomized Simulation as Augmentation for Robust Human Action\n  Recognition", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the rapid growth in datasets for video activity, stable robust\nactivity recognition with neural networks remains challenging. This is in large\npart due to the explosion of possible variation in video -- including lighting\nchanges, object variation, movement variation, and changes in surrounding\ncontext. An alternative is to make use of simulation data, where all of these\nfactors can be artificially controlled. In this paper, we propose the\nRandomized Simulation as Augmentation (RSA) framework which augments real-world\ntraining data with synthetic data to improve the robustness of action\nrecognition networks. We generate large-scale synthetic datasets with\nrandomized nuisance factors. We show that training with such extra data, when\nappropriately constrained, can significantly improve the performance of the\nstate-of-the-art I3D networks or, conversely, reduce the number of labeled real\nvideos needed to achieve good performance. Experiments on two real-world\ndatasets NTU RGB+D and VIRAT demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:45:45 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Yi", ""], ["Wei", "Xinyue", ""], ["Qiu", "Weichao", ""], ["Xiao", "Zihao", ""], ["Hager", "Gregory D.", ""], ["Yuille", "Alan", ""]]}, {"id": "1912.01181", "submitter": "Xin Ma", "authors": "Xin Ma, Guorong Wu, Won Hwa Kim", "title": "Multi-resolution Graph Neural Network for Identifying Disease-specific\n  Variations in Brain Connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution Neural Network (CNN) recently have been adopted in several\nneuroimaging studies for diagnosis capturing disease-specific changes in the\nbrain. While many of these methods are designed to work with images in $\\mathbb\nR^n$ exploiting regular structure of the domain, they are not well-suited to\nanalyze data with irregular structure such as brain connectivity. As there is\nsignificant interest in understanding the altered interactions between\ndifferent brain regions that lead to neuro-disorders, it is important to\ndevelop data-driven methods that work with a population of graph data for\ntraditional prediction tasks. In this regime, we propose a novel CNN-based\nframework with adaptive graph transforms to learn the most disease-relevant\nconnectome feature maps which have the highest discrimination power across\ndiagnostic categories. The backbone of our framework is a multi-resolution\nrepresentation of the graph matrix which is steered by a set of wavelet-like\ngraph transforms. In this context, our supervised graph learning framework\noutperforms conventional graph methods that predict diagnostic label only based\non the underlying individual graph. Our extensive experiments on two real\ndatasets of functional and structural brain networks show that our\nmulti-resolution framework achieves significantly higher accuracy, precision\nand recall in predicting diagnostic labels and identifying disease-specific\nbrain connectivities that are associated with brain disorders such as\nAttention-Deficit/Hyperactivity Disorder (ADHD) and Alzheimer's Disease (AD).\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:46:14 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ma", "Xin", ""], ["Wu", "Guorong", ""], ["Kim", "Won Hwa", ""]]}, {"id": "1912.01188", "submitter": "Kevin Lu", "authors": "Kevin Lu, Igor Mordatch, Pieter Abbeel", "title": "Adaptive Online Planning for Continual Lifelong Learning", "comments": "Originally published in NeurIPS Deep RL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning control in an online reset-free lifelong learning scenario,\nwhere mistakes can compound catastrophically into the future and the underlying\ndynamics of the environment may change. Traditional model-free policy learning\nmethods have achieved successes in difficult tasks due to their broad\nflexibility, but struggle in this setting, as they can activate failure modes\nearly in their lifetimes which are difficult to recover from and face\nperformance degradation as dynamics change. On the other hand, model-based\nplanning methods learn and adapt quickly, but require prohibitive levels of\ncomputational resources. We present a new algorithm, Adaptive Online Planning\n(AOP), that achieves strong performance in this setting by combining\nmodel-based planning with model-free learning. By approximating the uncertainty\nof the model-free components and the planner performance, AOP is able to call\nupon more extensive planning only when necessary, leading to reduced\ncomputation times, while still gracefully adapting behaviors in the face of\nunpredictable changes in the world -- even when traditional RL fails.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 04:29:01 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 05:28:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lu", "Kevin", ""], ["Mordatch", "Igor", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1912.01189", "submitter": "Jeremiah Zhe Liu", "authors": "Jeremiah Zhe Liu", "title": "Variable Selection with Rigorous Uncertainty Quantification using Deep\n  Bayesian Neural Networks: Posterior Concentration and Bernstein-von Mises\n  Phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops rigorous theoretical basis for the fact that deep Bayesian\nneural network (BNN) is an effective tool for high-dimensional variable\nselection with rigorous uncertainty quantification. We develop new Bayesian\nnon-parametric theorems to show that a properly configured deep BNN (1) learns\nthe variable importance effectively in high dimensions, and its learning rate\ncan sometimes \"break\" the curse of dimensionality. (2) BNN's uncertainty\nquantification for variable importance is rigorous, in the sense that its 95%\ncredible intervals for variable importance indeed covers the truth 95% of the\ntime (i.e., the Bernstein-von Mises (BvM) phenomenon). The theoretical results\nsuggest a simple variable selection algorithm based on the BNN's credible\nintervals. Extensive simulation confirms the theoretical findings and shows\nthat the proposed algorithm outperforms existing classic and\nneural-network-based variable selection methods, particularly in high\ndimensions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 04:36:21 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Liu", "Jeremiah Zhe", ""]]}, {"id": "1912.01192", "submitter": "Tiancheng Jin", "authors": "Chi Jin, Tiancheng Jin, Haipeng Luo, Suvrit Sra, Tiancheng Yu", "title": "Learning Adversarial MDPs with Bandit Feedback and Unknown Transition", "comments": "Fix a bug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning in episodic finite-horizon Markov\ndecision processes with an unknown transition function, bandit feedback, and\nadversarial losses. We propose an efficient algorithm that achieves\n$\\mathcal{\\tilde{O}}(L|X|\\sqrt{|A|T})$ regret with high probability, where $L$\nis the horizon, $|X|$ is the number of states, $|A|$ is the number of actions,\nand $T$ is the number of episodes. To the best of our knowledge, our algorithm\nis the first to ensure $\\mathcal{\\tilde{O}}(\\sqrt{T})$ regret in this\nchallenging setting; in fact it achieves the same regret bound as (Rosenberg &\nMansour, 2019a) that considers an easier setting with full-information\nfeedback. Our key technical contributions are two-fold: a tighter confidence\nset for the transition function, and an optimistic loss estimator that is\ninversely weighted by an $\\textit{upper occupancy bound}$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:04:40 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 05:06:43 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 04:36:59 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 13:38:22 GMT"}, {"version": "v5", "created": "Mon, 2 Nov 2020 07:13:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Jin", "Chi", ""], ["Jin", "Tiancheng", ""], ["Luo", "Haipeng", ""], ["Sra", "Suvrit", ""], ["Yu", "Tiancheng", ""]]}, {"id": "1912.01197", "submitter": "Zhao Kang", "authors": "Zhao Kang and Xiao Lu and Yiwei Lu and Chong Peng and Zenglin Xu", "title": "Structure Learning with Similarity Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging on the underlying low-dimensional structure of data, low-rank and\nsparse modeling approaches have achieved great success in a wide range of\napplications. However, in many applications the data can display structures\nbeyond simply being low-rank or sparse. Fully extracting and exploiting hidden\nstructure information in the data is always desirable and favorable. To reveal\nmore underlying effective manifold structure, in this paper, we explicitly\nmodel the data relation. Specifically, we propose a structure learning\nframework that retains the pairwise similarities between the data points.\nRather than just trying to reconstruct the original data based on\nself-expression, we also manage to reconstruct the kernel matrix, which\nfunctions as similarity preserving. Consequently, this technique is\nparticularly suitable for the class of learning problems that are sensitive to\nsample similarity, e.g., clustering and semisupervised classification. To take\nadvantage of representation power of deep neural network, a deep auto-encoder\narchitecture is further designed to implement our model. Extensive experiments\non benchmark data sets demonstrate that our proposed framework can consistently\nand significantly improve performance on both evaluation tasks. We conclude\nthat the quality of structure learning can be enhanced if similarity\ninformation is incorporated.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:25:08 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Kang", "Zhao", ""], ["Lu", "Xiao", ""], ["Lu", "Yiwei", ""], ["Peng", "Chong", ""], ["Xu", "Zenglin", ""]]}, {"id": "1912.01198", "submitter": "Quanquan Gu", "authors": "Yuan Cao and Zhiying Fang and Yue Wu and Ding-Xuan Zhou and Quanquan\n  Gu", "title": "Towards Understanding the Spectral Bias of Deep Learning", "comments": "29 pages, 7 figures. This version adds more experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intriguing phenomenon observed during training neural networks is the\nspectral bias, which states that neural networks are biased towards learning\nless complex functions. The priority of learning functions with low complexity\nmight be at the core of explaining generalization ability of neural network,\nand certain efforts have been made to provide theoretical explanation for\nspectral bias. However, there is still no satisfying theoretical result\njustifying the underlying mechanism of spectral bias. In this paper, we give a\ncomprehensive and rigorous explanation for spectral bias and relate it with the\nneural tangent kernel function proposed in recent work. We prove that the\ntraining process of neural networks can be decomposed along different\ndirections defined by the eigenfunctions of the neural tangent kernel, where\neach direction has its own convergence rate and the rate is determined by the\ncorresponding eigenvalue. We then provide a case study when the input data is\nuniformly distributed over the unit sphere, and show that lower degree\nspherical harmonics are easier to be learned by over-parameterized neural\nnetworks. Finally, we provide numerical experiments to demonstrate the\ncorrectness of our theory. Our experimental results also show that our theory\ncan tolerate certain model misspecification in terms of the input data\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:34:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 04:19:21 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 17:51:35 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Cao", "Yuan", ""], ["Fang", "Zhiying", ""], ["Wu", "Yue", ""], ["Zhou", "Ding-Xuan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1912.01201", "submitter": "Zhao Kang", "authors": "Juncheng Lv and Zhao Kang and Boyu Wang and Luping Ji and Zenglin Xu", "title": "Multi-view Subspace Clustering via Partition Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering is an important approach to analyze multi-view data in\nan unsupervised way. Among various methods, the multi-view subspace clustering\napproach has gained increasing attention due to its encouraging performance.\nBasically, it integrates multi-view information into graphs, which are then fed\ninto spectral clustering algorithm for final result. However, its performance\nmay degrade due to noises existing in each individual view or inconsistency\nbetween heterogeneous features. Orthogonal to current work, we propose to fuse\nmulti-view information in a partition space, which enhances the robustness of\nMulti-view clustering. Specifically, we generate multiple partitions and\nintegrate them to find the shared partition. The proposed model unifies graph\nlearning, generation of basic partitions, and view weight learning. These three\ncomponents co-evolve towards better quality outputs. We have conducted\ncomprehensive experiments on benchmark datasets and our empirical results\nverify the effectiveness and robustness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:48:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lv", "Juncheng", ""], ["Kang", "Zhao", ""], ["Wang", "Boyu", ""], ["Ji", "Luping", ""], ["Xu", "Zenglin", ""]]}, {"id": "1912.01202", "submitter": "Jie Li", "authors": "Rui Hou, Jie Li, Arjun Bhargava, Allan Raventos, Vitor Guizilini, Chao\n  Fang, Jerome Lynch, Adrien Gaidon", "title": "Real-Time Panoptic Segmentation from Dense Detections", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Panoptic segmentation is a complex full scene parsing task requiring\nsimultaneous instance and semantic segmentation at high resolution. Current\nstate-of-the-art approaches cannot run in real-time, and simplifying these\narchitectures to improve efficiency severely degrades their accuracy. In this\npaper, we propose a new single-shot panoptic segmentation network that\nleverages dense detections and a global self-attention mechanism to operate in\nreal-time with performance approaching the state of the art. We introduce a\nnovel parameter-free mask construction method that substantially reduces\ncomputational complexity by efficiently reusing information from the object\ndetection and semantic segmentation sub-tasks. The resulting network has a\nsimple data flow that does not require feature map re-sampling or clustering\npost-processing, enabling significant hardware acceleration. Our experiments on\nthe Cityscapes and COCO benchmarks show that our network works at 30 FPS on\n1024x2048 resolution, trading a 3% relative performance degradation from the\ncurrent state of the art for up to 440% faster inference.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:50:02 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 18:05:28 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 23:08:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hou", "Rui", ""], ["Li", "Jie", ""], ["Bhargava", "Arjun", ""], ["Raventos", "Allan", ""], ["Guizilini", "Vitor", ""], ["Fang", "Chao", ""], ["Lynch", "Jerome", ""], ["Gaidon", "Adrien", ""]]}, {"id": "1912.01203", "submitter": "Lifeng Tan", "authors": "Lifeng Tan, Cong Jin, Zhiyuan Cheng, Xin Lv, Leiyu Song", "title": "Music Style Classification with Compared Methods in XGB and BPNN", "comments": "5 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientists have used many different classification methods to solve the\nproblem of music classification. But the efficiency of each classification is\ndifferent. In this paper, we propose two compared methods on the task of music\nstyle classification. More specifically, feature extraction for representing\ntimbral texture, rhythmic content and pitch content are proposed. Comparative\nevaluations on performances of two classifiers were conducted for music\nclassification with different styles. The result shows that XGB is better\nsuited for small datasets than BPNN\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:54:52 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Tan", "Lifeng", ""], ["Jin", "Cong", ""], ["Cheng", "Zhiyuan", ""], ["Lv", "Xin", ""], ["Song", "Leiyu", ""]]}, {"id": "1912.01206", "submitter": "Nilesh Ahuja", "authors": "Mahesh Subedar, Nilesh Ahuja, Ranganath Krishnan, Ibrahima J. Ndiour,\n  Omesh Tickoo", "title": "Deep Probabilistic Models to Detect Data Poisoning Attacks", "comments": "To appear in Bayesian Deep Learning Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning attacks compromise the integrity of machine-learning models by\nintroducing malicious training samples to influence the results during test\ntime. In this work, we investigate backdoor data poisoning attack on deep\nneural networks (DNNs) by inserting a backdoor pattern in the training images.\nThe resulting attack will misclassify poisoned test samples while maintaining\nhigh accuracies for the clean test-set. We present two approaches for detection\nof such poisoned samples by quantifying the uncertainty estimates associated\nwith the trained models. In the first approach, we model the outputs of the\nvarious layers (deep features) with parametric probability distributions learnt\nfrom the clean held-out dataset. At inference, the likelihoods of deep features\nw.r.t these distributions are calculated to derive uncertainty estimates. In\nthe second approach, we use Bayesian deep neural networks trained with\nmean-field variational inference to estimate model uncertainty associated with\nthe predictions. The uncertainty estimates from these methods are used to\ndiscriminate clean from the poisoned samples.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 05:58:51 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Subedar", "Mahesh", ""], ["Ahuja", "Nilesh", ""], ["Krishnan", "Ranganath", ""], ["Ndiour", "Ibrahima J.", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1912.01211", "submitter": "Quanquan Gu", "authors": "Tao Jin and Pan Xu and Quanquan Gu and Farzad Farnoud", "title": "Rank Aggregation via Heterogeneous Thurstone Preference Models", "comments": "36 pages, 2 figures, 8 tables. In AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Heterogeneous Thurstone Model (HTM) for aggregating ranked\ndata, which can take the accuracy levels of different users into account. By\nallowing different noise distributions, the proposed HTM model maintains the\ngenerality of Thurstone's original framework, and as such, also extends the\nBradley-Terry-Luce (BTL) model for pairwise comparisons to heterogeneous\npopulations of users. Under this framework, we also propose a rank aggregation\nalgorithm based on alternating gradient descent to estimate the underlying item\nscores and accuracy levels of different users simultaneously from noisy\npairwise comparisons. We theoretically prove that the proposed algorithm\nconverges linearly up to a statistical error which matches that of the\nstate-of-the-art method for the single-user BTL model. We evaluate the proposed\nHTM model and algorithm on both synthetic and real data, demonstrating that it\noutperforms existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 06:23:19 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Jin", "Tao", ""], ["Xu", "Pan", ""], ["Gu", "Quanquan", ""], ["Farnoud", "Farzad", ""]]}, {"id": "1912.01219", "submitter": "Wei Ping", "authors": "Wei Ping, Kainan Peng, Kexin Zhao, Zhao Song", "title": "WaveFlow: A Compact Flow-based Model for Raw Audio", "comments": "Published at ICML 2020. Code and pre-trained models:\n  https://github.com/PaddlePaddle/Parakeet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose WaveFlow, a small-footprint generative flow for raw\naudio, which is directly trained with maximum likelihood. It handles the\nlong-range structure of 1-D waveform with a dilated 2-D convolutional\narchitecture, while modeling the local variations using expressive\nautoregressive functions. WaveFlow provides a unified view of likelihood-based\nmodels for 1-D data, including WaveNet and WaveGlow as special cases. It\ngenerates high-fidelity speech as WaveNet, while synthesizing several orders of\nmagnitude faster as it only requires a few sequential steps to generate very\nlong waveforms with hundreds of thousands of time-steps. Furthermore, it can\nsignificantly reduce the likelihood gap that has existed between autoregressive\nmodels and flow-based models for efficient synthesis. Finally, our\nsmall-footprint WaveFlow has only 5.91M parameters, which is 15$\\times$ smaller\nthan WaveGlow. It can generate 22.05 kHz high-fidelity audio 42.6$\\times$\nfaster than real-time (at a rate of 939.3 kHz) on a V100 GPU without engineered\ninference kernels.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 07:00:13 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 21:45:31 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 21:35:04 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 20:10:12 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ping", "Wei", ""], ["Peng", "Kainan", ""], ["Zhao", "Kexin", ""], ["Song", "Zhao", ""]]}, {"id": "1912.01234", "submitter": "Armin K\\\"uper", "authors": "Armin K\\\"uper and Steffen Waldherr", "title": "Numerical Gaussian process Kalman filtering", "comments": "6 pages, 3 figures, this work has been accepted by IFAC for\n  publication (\\copyright 2020 IFAC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we introduce numerical Gaussian process Kalman filtering\n(GPKF). Numerical Gaussian processes have recently been developed to simulate\nspatiotemporal models. The contribution of this paper is to embed numerical\nGaussian processes into the recursive Kalman filter equations. This embedding\nenables us to do Kalman filtering on infinite-dimensional systems using\nGaussian processes. This is possible because i) we are obtaining a linear model\nfrom numerical Gaussian processes, and ii) the states of this model are by\ndefinition Gaussian distributed random variables. Convenient properties of the\nnumerical GPKF are that no spatial discretization of the model is necessary,\nand manual setting up of the Kalman filter, that is fine-tuning the process and\nmeasurement noise levels by hand is not required, as they are learned online\nfrom the data stream. We showcase the capability of the numerical GPKF in a\nsimulation study of the advection equation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 08:09:27 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 13:27:03 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["K\u00fcper", "Armin", ""], ["Waldherr", "Steffen", ""]]}, {"id": "1912.01238", "submitter": "Patrick Chen", "authors": "Patrick H. Chen, Wei Wei, Cho-jui Hsieh, Bo Dai", "title": "Overcoming Catastrophic Forgetting by Generative Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method to overcome catastrophic forgetting by\nadding generative regularization to Bayesian inference framework. Bayesian\nmethod provides a general framework for continual learning. We could further\nconstruct a generative regularization term for all given classification models\nby leveraging energy-based models and Langevin-dynamic sampling to enrich the\nfeatures learned in each task. By combining discriminative and generative loss\ntogether, we empirically show that the proposed method outperforms\nstate-of-the-art methods on a variety of tasks, avoiding catastrophic\nforgetting in continual learning. In particular, the proposed method\noutperforms baseline methods over 15% on the Fashion-MNIST dataset and 10% on\nthe CUB dataset\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 08:17:46 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 07:43:43 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 06:22:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Patrick H.", ""], ["Wei", "Wei", ""], ["Hsieh", "Cho-jui", ""], ["Dai", "Bo", ""]]}, {"id": "1912.01241", "submitter": "Jaemoon Lee", "authors": "Jaemoon Lee, Hoda Shajari", "title": "A Hidden Variables Approach to Multilabel Logistic Regression", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilabel classification is an important problem in a wide range of domains\nsuch as text categorization and music annotation. In this paper, we present a\nprobabilistic model, Multilabel Logistic Regression with Hidden variables\n(MLRH), which extends the standard logistic regression by introducing hidden\nvariables. Hidden variables make it possible to go beyond the conventional\nmulticlass logistic regression by relaxing the one-hot-encoding constraint. We\ndefine a new joint distribution of labels and hidden variables which enables us\nto obtain one classifier for multilabel classification. Our experimental\nstudies on a set of benchmark datasets demonstrate that the probabilistic model\ncan achieve competitive performance compared with other multilabel learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 08:33:55 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lee", "Jaemoon", ""], ["Shajari", "Hoda", ""]]}, {"id": "1912.01242", "submitter": "Qinge Xie", "authors": "Qinge Xie and Tiancheng Guo and Yang Chen and Yu Xiao and Xin Wang and\n  Ben Y. Zhao", "title": "\"How do urban incidents affect traffic speed?\" A Deep Graph\n  Convolutional Network for Incident-driven Traffic Speed Prediction", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate traffic speed prediction is an important and challenging topic for\ntransportation planning. Previous studies on traffic speed prediction\npredominately used spatio-temporal and context features for prediction.\nHowever, they have not made good use of the impact of urban traffic incidents.\nIn this work, we aim to make use of the information of urban incidents to\nachieve a better prediction of traffic speed. Our incident-driven prediction\nframework consists of three processes. First, we propose a critical incident\ndiscovery method to discover urban traffic incidents with high impact on\ntraffic speed. Second, we design a binary classifier, which uses deep learning\nmethods to extract the latent incident impact features from the middle layer of\nthe classifier. Combining above methods, we propose a Deep Incident-Aware Graph\nConvolutional Network (DIGC-Net) to effectively incorporate urban traffic\nincident, spatio-temporal, periodic and context features for traffic speed\nprediction. We conduct experiments on two real-world urban traffic datasets of\nSan Francisco and New York City. The results demonstrate the superior\nperformance of our model compare to the competing benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 08:39:55 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Xie", "Qinge", ""], ["Guo", "Tiancheng", ""], ["Chen", "Yang", ""], ["Xiao", "Yu", ""], ["Wang", "Xin", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "1912.01249", "submitter": "Dvir Ginzburg", "authors": "Dvir Ginzburg, Dan Raviv", "title": "Cyclic Functional Mapping: Self-supervised correspondence between\n  non-isometric deformable shapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first utterly self-supervised network for dense correspondence\nmapping between non-isometric shapes. The task of alignment in non-Euclidean\ndomains is one of the most fundamental and crucial problems in computer vision.\nAs 3D scanners can generate highly complex and dense models, the mission of\nfinding dense mappings between those models is vital. The novelty of our\nsolution is based on a cyclic mapping between metric spaces, where the distance\nbetween a pair of points should remain invariant after the full cycle. As the\nsame learnable rules that generate the point-wise descriptors apply in both\ndirections, the network learns invariant structures without any labels while\ncoping with non-isometric deformations. We show here state-of-the-art-results\nby a large margin for a variety of tasks compared to known self-supervised and\nsupervised methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:11:25 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ginzburg", "Dvir", ""], ["Raviv", "Dan", ""]]}, {"id": "1912.01261", "submitter": "Jonathan Lee", "authors": "Jonathan Lee, Ching-An Cheng, Ken Goldberg, Byron Boots", "title": "Continuous Online Learning and New Insights to Online Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning is a powerful tool for analyzing iterative algorithms.\nHowever, the classic adversarial setup sometimes fails to capture certain\nregularity in online problems in practice. Motivated by this, we establish a\nnew setup, called Continuous Online Learning (COL), where the gradient of\nonline loss function changes continuously across rounds with respect to the\nlearner's decisions. We show that COL covers and more appropriately describes\nmany interesting applications, from general equilibrium problems (EPs) to\noptimization in episodic MDPs. Using this new setup, we revisit the difficulty\nof achieving sublinear dynamic regret. We prove that there is a fundamental\nequivalence between achieving sublinear dynamic regret in COL and solving\ncertain EPs, and we present a reduction from dynamic regret to both static\nregret and convergence rate of the associated EP. At the end, we specialize\nthese new insights into online imitation learning and show improved\nunderstanding of its learning stability.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:44:56 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lee", "Jonathan", ""], ["Cheng", "Ching-An", ""], ["Goldberg", "Ken", ""], ["Boots", "Byron", ""]]}, {"id": "1912.01266", "submitter": "Simon Meyer Lauritsen", "authors": "Simon Meyer Lauritsen, Mads Kristensen, Mathias Vassard Olsen, Morten\n  Skaarup Larsen, Katrine Meyer Lauritsen, Marianne Johansson J{\\o}rgensen,\n  Jeppe Lange, Bo Thiesson", "title": "Explainable artificial intelligence model to predict acute critical\n  illness from electronic health records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an explainable artificial intelligence (AI) early warning score\n(xAI-EWS) system for early detection of acute critical illness. While\nmaintaining a high predictive performance, our system explains to the clinician\non which relevant electronic health records (EHRs) data the prediction is\ngrounded. Acute critical illness is often preceded by deterioration of\nroutinely measured clinical parameters, e.g., blood pressure and heart rate.\nEarly clinical prediction is typically based on manually calculated screening\nmetrics that simply weigh these parameters, such as Early Warning Scores (EWS).\nThe predictive performance of EWSs yields a tradeoff between sensitivity and\nspecificity that can lead to negative outcomes for the patient. Previous work\non EHR-trained AI systems offers promising results with high levels of\npredictive performance in relation to the early, real-time prediction of acute\ncritical illness. However, without insight into the complex decisions by such\nsystem, clinical translation is hindered. In this letter, we present our\nxAI-EWS system, which potentiates clinical translation by accompanying a\nprediction with information on the EHR data explaining it.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:52:20 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lauritsen", "Simon Meyer", ""], ["Kristensen", "Mads", ""], ["Olsen", "Mathias Vassard", ""], ["Larsen", "Morten Skaarup", ""], ["Lauritsen", "Katrine Meyer", ""], ["J\u00f8rgensen", "Marianne Johansson", ""], ["Lange", "Jeppe", ""], ["Thiesson", "Bo", ""]]}, {"id": "1912.01268", "submitter": "Martino Sorbaro", "authors": "Martino Sorbaro, Qian Liu, Massimo Bortone, Sadique Sheik", "title": "Optimizing the energy consumption of spiking neural networks for\n  neuromorphic applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last few years, spiking neural networks have been demonstrated to\nperform on par with regular convolutional neural networks. Several works have\nproposed methods to convert a pre-trained CNN to a Spiking CNN without a\nsignificant sacrifice of performance. We demonstrate first that\nquantization-aware training of CNNs leads to better accuracy in SNNs. One of\nthe benefits of converting CNNs to spiking CNNs is to leverage the sparse\ncomputation of SNNs and consequently perform equivalent computation at a lower\nenergy consumption. Here we propose an efficient optimization strategy to train\nspiking networks at lower energy consumption, while maintaining similar\naccuracy levels. We demonstrate results on the MNIST-DVS and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:54:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:53:25 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sorbaro", "Martino", ""], ["Liu", "Qian", ""], ["Bortone", "Massimo", ""], ["Sheik", "Sadique", ""]]}, {"id": "1912.01274", "submitter": "Matan Haroush", "authors": "Matan Haroush, Itay Hubara, Elad Hoffer, and Daniel Soudry", "title": "The Knowledge Within: Methods for Data-Free Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an extensive amount of research has been focused on compressing and\naccelerating Deep Neural Networks (DNN). So far, high compression rate\nalgorithms require part of the training dataset for a low precision\ncalibration, or a fine-tuning process. However, this requirement is\nunacceptable when the data is unavailable or contains sensitive information, as\nin medical and biometric use-cases. We present three methods for generating\nsynthetic samples from trained models. Then, we demonstrate how these samples\ncan be used to calibrate and fine-tune quantized models without using any real\ndata in the process. Our best performing method has a negligible accuracy\ndegradation compared to the original training set. This method, which leverages\nintrinsic batch normalization layers' statistics of the trained model, can be\nused to evaluate data similarity. Our approach opens a path towards genuine\ndata-free model compression, alleviating the need for training data during\nmodel deployment.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 10:01:51 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 19:00:35 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Haroush", "Matan", ""], ["Hubara", "Itay", ""], ["Hoffer", "Elad", ""], ["Soudry", "Daniel", ""]]}, {"id": "1912.01277", "submitter": "Christian Sch\\\"on", "authors": "Christian Sch\\\"on, Jens Dittrich", "title": "Make Thunderbolts Less Frightening -- Predicting Extreme Weather Using\n  Deep Learning", "comments": "similar to the version accepted as poster for the workshop \"Tackling\n  Climate Change with Machine Learning\" at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019) in Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting severe weather conditions is still a very challenging and\ncomputationally expensive task due to the enormous amount of data and the\ncomplexity of the underlying physics. Machine learning approaches and\nespecially deep learning have however shown huge improvements in many research\nareas dealing with large datasets in recent years. In this work, we tackle one\nspecific sub-problem of weather forecasting, namely the prediction of\nthunderstorms and lightning. We propose the use of a convolutional neural\nnetwork architecture inspired by UNet++ and ResNet to predict thunderstorms as\na binary classification problem based on satellite images and lightnings\nrecorded in the past. We achieve a probability of detection of more than 94%\nfor lightnings within the next 15 minutes while at the same time minimizing the\nfalse alarm ratio compared to previous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 10:17:48 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 08:01:37 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Sch\u00f6n", "Christian", ""], ["Dittrich", "Jens", ""]]}, {"id": "1912.01293", "submitter": "Ruiqi Wang", "authors": "R.Q. Wang, W.Z. Wang, D.Z. Zhao, G.H. Chen and D.S.Luo", "title": "Scene recognition based on DNN and game theory with its applications in\n  human-robot interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene recognition model based on the DNN and game theory with its\napplications in human-robot interaction is proposed in this paper. The use of\ndeep learning methods in the field of scene recognition is still in its\ninfancy, but has become an important trend in the future. As the innovative\nidea of the paper, we propose the following novelties. (1) In this paper, the\nimage registration problem is transformed into a problem of minimum energy in\nMarkov Random Field to finalize the image pre-processing task. Game theory is\nused to find the optimal. (2) We select neighboring homogeneous sample features\nand the neighboring heterogeneous sample features for the extracted sample\nfeatures to build a triple and modify the traditional neural network to propose\nthe novel DNN for scene understanding. (3) The robot control is well combined\nto guide the robot vision for multiple tasks. The experiment is then conducted\nto validate the overall performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 10:54:38 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 14:32:09 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 09:05:28 GMT"}, {"version": "v4", "created": "Fri, 10 Jan 2020 11:03:24 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Wang", "R. Q.", ""], ["Wang", "W. Z.", ""], ["Zhao", "D. Z.", ""], ["Chen", "G. H.", ""], ["Luo", "D. S.", ""]]}, {"id": "1912.01300", "submitter": "Xinyang Jiang", "authors": "Zhihui Zhu, Xinyang Jiang, Feng Zheng, Xiaowei Guo, Feiyue Huang,\n  Weishi Zheng, Xing Sun", "title": "Viewpoint-Aware Loss with Angular Regularization for Person\n  Re-Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although great progress in supervised person re-identification (Re-ID) has\nbeen made recently, due to the viewpoint variation of a person, Re-ID remains a\nmassive visual challenge. Most existing viewpoint-based person Re-ID methods\nproject images from each viewpoint into separated and unrelated sub-feature\nspaces. They only model the identity-level distribution inside an individual\nviewpoint but ignore the underlying relationship between different viewpoints.\nTo address this problem, we propose a novel approach, called\n\\textit{Viewpoint-Aware Loss with Angular Regularization }(\\textbf{VA-reID}).\nInstead of one subspace for each viewpoint, our method projects the feature\nfrom different viewpoints into a unified hypersphere and effectively models the\nfeature distribution on both the identity-level and the viewpoint-level. In\naddition, rather than modeling different viewpoints as hard labels used for\nconventional viewpoint classification, we introduce viewpoint-aware adaptive\nlabel smoothing regularization (VALSR) that assigns the adaptive soft label to\nfeature representation. VALSR can effectively solve the ambiguity of the\nviewpoint cluster label assignment. Extensive experiments on the Market1501 and\nDukeMTMC-reID datasets demonstrated that our method outperforms the\nstate-of-the-art supervised Re-ID methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:10:29 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhu", "Zhihui", ""], ["Jiang", "Xinyang", ""], ["Zheng", "Feng", ""], ["Guo", "Xiaowei", ""], ["Huang", "Feiyue", ""], ["Zheng", "Weishi", ""], ["Sun", "Xing", ""]]}, {"id": "1912.01303", "submitter": "Quoc Hung Ngo", "authors": "Quoc Hung Ngo and Nhien-An Le-Khac and Tahar Kechadi", "title": "Predicting Soil pH by Using Nearest Fields", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-34885-4", "report-no": "LNAI, volume 11927", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In precision agriculture (PA), soil sampling and testing operation is prior\nto planting any new crop. It is an expensive operation since there are many\nsoil characteristics to take into account. This paper gives an overview of soil\ncharacteristics and their relationships with crop yield and soil profiling. We\npropose an approach for predicting soil pH based on nearest neighbour fields.\nIt implements spatial radius queries and various regression techniques in data\nmining. We use soil dataset containing about 4,000 fields profiles to evaluate\nthem and analyse their robustness. A comparative study indicates that LR, SVR,\nand GBRT techniques achieved high accuracy, with the R_2 values of about 0.718\nand MAE values of 0.29. The experimental results showed that the proposed\napproach is very promising and can contribute significantly to PA.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:20:45 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Ngo", "Quoc Hung", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1912.01308", "submitter": "Othmane Mazhar", "authors": "Othmane Mazhar, Cristian R. Rojas, Carlo Fischione and Mohammad R.\n  Hesamzadeh", "title": "Bayesian Model Selection for Change Point Detection and Clustering", "comments": "37 page, 4 figures, Proceedings of the 35th International Conference\n  on Machine Learning (ICML), PMLR 80:3433-3442, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the new problem of estimating a piece-wise constant signal with\nthe purpose of detecting its change points and the levels of clusters. Our\napproach is to model it as a nonparametric penalized least square model\nselection on a family of models indexed over the collection of partitions of\nthe design points and propose a computationally efficient algorithm to\napproximately solve it. Statistically, minimizing such a penalized criterion\nyields an approximation to the maximum a posteriori probability (MAP)\nestimator. The criterion is then analyzed and an oracle inequality is derived\nusing a Gaussian concentration inequality. The oracle inequality is used to\nderive on one hand conditions for consistency and on the other hand an adaptive\nupper bound on the expected square risk of the estimator, which statistically\nmotivates our approximation. Finally, we apply our algorithm to simulated data\nto experimentally validate the statistical guarantees and illustrate its\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:28:05 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Mazhar", "Othmane", ""], ["Rojas", "Cristian R.", ""], ["Fischione", "Carlo", ""], ["Hesamzadeh", "Mohammad R.", ""]]}, {"id": "1912.01321", "submitter": "Zifeng Wang", "authors": "Zifeng Wang and Hong Zhu and Zhenhua Dong and Xiuqiang He and Shao-Lun\n  Huang", "title": "Less Is Better: Unweighted Data Subsampling via Influence Function", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the time of Big Data, training complex models on large-scale data sets is\nchallenging, making it appealing to reduce data volume for saving computation\nresources by subsampling. Most previous works in subsampling are weighted\nmethods designed to help the performance of subset-model approach the\nfull-set-model, hence the weighted methods have no chance to acquire a\nsubset-model that is better than the full-set-model. However, we question that\nhow can we achieve better model with less data? In this work, we propose a\nnovel Unweighted Influence Data Subsampling (UIDS) method, and prove that the\nsubset-model acquired through our method can outperform the full-set-model.\nBesides, we show that overly confident on a given test set for sampling is\ncommon in Influence-based subsampling methods, which can eventually cause our\nsubset-model's failure in out-of-sample test. To mitigate it, we develop a\nprobabilistic sampling scheme to control the worst-case risk over all\ndistributions close to the empirical distribution. The experiment results\ndemonstrate our methods superiority over existed subsampling methods in diverse\ntasks, such as text classification, image classification, click-through\nprediction, etc.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:48:53 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 00:56:52 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 05:16:12 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Wang", "Zifeng", ""], ["Zhu", "Hong", ""], ["Dong", "Zhenhua", ""], ["He", "Xiuqiang", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "1912.01326", "submitter": "Adrien Deli\\`ege Mr", "authors": "Anthony Cioppa, Adrien Deli\\`ege, Silvio Giancola, Bernard Ghanem,\n  Marc Van Droogenbroeck, Rikke Gade, Thomas B. Moeslund", "title": "A Context-Aware Loss Function for Action Spotting in Soccer Videos", "comments": "Accepted for CVPR2020 main conference. This document contains 8 pages\n  + references + supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In video understanding, action spotting consists in temporally localizing\nhuman-induced events annotated with single timestamps. In this paper, we\npropose a novel loss function that specifically considers the temporal context\nnaturally present around each action, rather than focusing on the single\nannotated frame to spot. We benchmark our loss on a large dataset of soccer\nvideos, SoccerNet, and achieve an improvement of 12.8% over the baseline. We\nshow the generalization capability of our loss for generic activity proposals\nand detection on ActivityNet, by spotting the beginning and the end of each\nactivity. Furthermore, we provide an extended ablation study and display\nchallenging cases for action spotting in soccer videos. Finally, we\nqualitatively illustrate how our loss induces a precise temporal understanding\nof actions and show how such semantic knowledge can be used for automatic\nhighlights generation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:59:55 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 17:08:43 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 13:53:26 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Cioppa", "Anthony", ""], ["Deli\u00e8ge", "Adrien", ""], ["Giancola", "Silvio", ""], ["Ghanem", "Bernard", ""], ["Van Droogenbroeck", "Marc", ""], ["Gade", "Rikke", ""], ["Moeslund", "Thomas B.", ""]]}, {"id": "1912.01329", "submitter": "Jingyue Lu", "authors": "Jingyue Lu and M. Pawan Kumar", "title": "Neural Network Branching for Neural Network Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification of neural networks is essential for their deployment in\nsafety-critical areas. Many available formal verification methods have been\nshown to be instances of a unified Branch and Bound (BaB) formulation. We\npropose a novel framework for designing an effective branching strategy for\nBaB. Specifically, we learn a graph neural network (GNN) to imitate the strong\nbranching heuristic behaviour. Our framework differs from previous methods for\nlearning to branch in two main aspects. Firstly, our framework directly treats\nthe neural network we want to verify as a graph input for the GNN. Secondly, we\ndevelop an intuitive forward and backward embedding update schedule.\nEmpirically, our framework achieves roughly $50\\%$ reduction in both the number\nof branches and the time required for verification on various convolutional\nnetworks when compared to the best available hand-designed branching strategy.\nIn addition, we show that our GNN model enjoys both horizontal and vertical\ntransferability. Horizontally, the model trained on easy properties performs\nwell on properties of increased difficulty levels. Vertically, the model\ntrained on small neural networks achieves similar performance on large neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 12:12:29 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lu", "Jingyue", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1912.01369", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu, Ian Whalen, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman,\n  Wolfgang Banzhaf, Vishnu Naresh Boddeti", "title": "Multi-Objective Evolutionary Design of Deep Convolutional Neural\n  Networks for Image Classification", "comments": "Published in IEEE Transactions on Evolutionary Computation, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early advancements in convolutional neural networks (CNNs) architectures are\nprimarily driven by human expertise and by elaborate design processes.\nRecently, neural architecture search was proposed with the aim of automating\nthe network design process and generating task-dependent architectures. While\nexisting approaches have achieved competitive performance in image\nclassification, they are not well suited to problems where the computational\nbudget is limited for two reasons: (1) the obtained architectures are either\nsolely optimized for classification performance, or only for one deployment\nscenario; (2) the search process requires vast computational resources in most\napproaches. To overcome these limitations, we propose an evolutionary algorithm\nfor searching neural architectures under multiple objectives, such as\nclassification performance and floating-point operations (FLOPs). The proposed\nmethod addresses the first shortcoming by populating a set of architectures to\napproximate the entire Pareto frontier through genetic operations that\nrecombine and modify architectural components progressively. Our approach\nimproves computational efficiency by carefully down-scaling the architectures\nduring the search as well as reinforcing the patterns commonly shared among\npast successful architectures through Bayesian model learning. The integration\nof these two main contributions allows an efficient design of architectures\nthat are competitive and in most cases outperform both manually and\nautomatically designed architectures on benchmark image classification\ndatasets: CIFAR, ImageNet, and human chest X-ray. The flexibility provided from\nsimultaneously obtaining multiple architecture choices for different compute\nrequirements further differentiates our approach from other methods in the\nliterature. Code is available at https://github.com/mikelzc1990/nsganetv1\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 13:57:25 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 18:38:21 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 13:35:27 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lu", "Zhichao", ""], ["Whalen", "Ian", ""], ["Dhebar", "Yashesh", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik", ""], ["Banzhaf", "Wolfgang", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "1912.01389", "submitter": "Taesun Moon", "authors": "Taesun Moon, Parul Awasthy, Jian Ni, Radu Florian", "title": "Towards Lingua Franca Named Entity Recognition with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction is an important task in NLP, enabling the automatic\nextraction of data for relational database filling. Historically, research and\ndata was produced for English text, followed in subsequent years by datasets in\nArabic, Chinese (ACE/OntoNotes), Dutch, Spanish, German (CoNLL evaluations),\nand many others. The natural tendency has been to treat each language as a\ndifferent dataset and build optimized models for each. In this paper we\ninvestigate a single Named Entity Recognition model, based on a multilingual\nBERT, that is trained jointly on many languages simultaneously, and is able to\ndecode these languages with better accuracy than models trained only on one\nlanguage. To improve the initial model, we study the use of regularization\nstrategies such as multitask learning and partial gradient updates. In addition\nto being a single model that can tackle multiple languages (including code\nswitch), the model could be used to make zero-shot predictions on a new\nlanguage, even ones for which training data is not available, out of the box.\nThe results show that this model not only performs competitively with\nmonolingual models, but it also achieves state-of-the-art results on the\nCoNLL02 Dutch and Spanish datasets, OntoNotes Arabic and Chinese datasets.\nMoreover, it performs reasonably well on unseen languages, achieving\nstate-of-the-art for zero-shot on three CoNLL languages.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:48:02 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 18:23:41 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Moon", "Taesun", ""], ["Awasthy", "Parul", ""], ["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "1912.01394", "submitter": "Elahe Arani", "authors": "Elahe Arani, Shabbir Marzban, Andrei Pata and Bahram Zonooz", "title": "RGPNet: A Real-Time General Purpose Semantic Segmentation", "comments": "Accepted at IEEE Winter Conference on Applications of Computer Vision\n  (WACV, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a real-time general purpose semantic segmentation architecture,\nRGPNet, which achieves significant performance gain in complex environments.\nRGPNet consists of a light-weight asymmetric encoder-decoder and an adaptor.\nThe adaptor helps preserve and refine the abstract concepts from multiple\nlevels of distributed representations between the encoder and decoder. It also\nfacilitates the gradient flow from deeper layers to shallower layers. Our\nexperiments demonstrate that RGPNet can generate segmentation results in\nreal-time with comparable accuracy to the state-of-the-art non-real-time heavy\nmodels. Moreover, towards green AI, we show that using an optimized\nlabel-relaxation technique with progressive resizing can reduce the training\ntime by up to 60% while preserving the performance. We conclude that RGPNet\nobtains a better speed-accuracy trade-off across multiple datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 14:24:55 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 11:19:38 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Arani", "Elahe", ""], ["Marzban", "Shabbir", ""], ["Pata", "Andrei", ""], ["Zonooz", "Bahram", ""]]}, {"id": "1912.01398", "submitter": "So Takamoto", "authors": "So Takamoto, Satoshi Izumi, Ju Li", "title": "TeaNet: universal neural network interatomic potential inspired by\n  iterative electronic relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A universal interatomic potential applicable to arbitrary elements and\nstructures is urgently needed in computational materials science. Graph\nconvolution-based neural network is a promising approach by virtue of its\nability to express complex relations. Thus far, it has been thought to\nrepresent a completely different approach from physics-based interatomic\npotentials. In this paper, we show that these two methods can be regarded as\ndifferent representations of the same tight-binding electronic relaxation\nframework, where atom-based and overlap integral or \"bond\"-based Hamiltonian\ninformation are propagated in a directional fashion. Based on this unified\nview, we propose a new model, named the tensor embedded atom network (TeaNet),\nwhere the stacked network model is associated with the electronic total energy\nrelaxation calculation. Furthermore, Tersoff-style angular interaction is\ntranslated into graph convolution architecture through the incorporation of\nEuclidean tensor values. Our model can represent and transfer spatial\ninformation. TeaNet shows great performance in both the robustness of\ninteratomic potentials and the expressive power of neural networks. We\ndemonstrate that arbitrary chemistry involving the first 18 elements on the\nperiodic table (H to Ar) can be realized by our model, including C-H molecular\nstructures, metals, amorphous SiO${}_2$, and water.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 08:47:16 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Takamoto", "So", ""], ["Izumi", "Satoshi", ""], ["Li", "Ju", ""]]}, {"id": "1912.01412", "submitter": "Guillaume Lample", "authors": "Guillaume Lample, Fran\\c{c}ois Charton", "title": "Deep Learning for Symbolic Mathematics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have a reputation for being better at solving statistical or\napproximate problems than at performing calculations or working with symbolic\ndata. In this paper, we show that they can be surprisingly good at more\nelaborated tasks in mathematics, such as symbolic integration and solving\ndifferential equations. We propose a syntax for representing mathematical\nproblems, and methods for generating large datasets that can be used to train\nsequence-to-sequence models. We achieve results that outperform commercial\nComputer Algebra Systems such as Matlab or Mathematica.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:05:24 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Lample", "Guillaume", ""], ["Charton", "Fran\u00e7ois", ""]]}, {"id": "1912.01413", "submitter": "Alex Turpin", "authors": "Alex Turpin, Gabriella Musarra, Valentin Kapitany, Francesco Tonolini,\n  Ashley Lyons, Ilya Starshynov, Federica Villa, Enrico Conca, Francesco\n  Fioranelli, Roderick Murray-Smith, Daniele Faccio", "title": "Spatial images from temporal data", "comments": "This is the final version as published in Optica Vol. 7, Issue 8, pp.\n  900-905 (2020)", "journal-ref": null, "doi": "10.1364/OPTICA.392465", "report-no": null, "categories": "eess.IV cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional paradigms for imaging rely on the use of a spatial structure,\neither in the detector (pixels arrays) or in the illumination (patterned\nlight). Removal of the spatial structure in the detector or illumination, i.e.,\nimaging with just a single-point sensor, would require solving a very strongly\nill-posed inverse retrieval problem that to date has not been solved. Here, we\ndemonstrate a data-driven approach in which full 3D information is obtained\nwith just a single-point, single-photon avalanche diode that records the\narrival time of photons reflected from a scene that is illuminated with short\npulses of light. Imaging with single-point time-of-flight (temporal) data opens\nnew routes in terms of speed, size, and functionality. As an example, we show\nhow the training based on an optical time-of-flight camera enables a compact\nradio-frequency impulse radio detection and ranging transceiver to provide 3D\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:36:08 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 08:55:06 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Turpin", "Alex", ""], ["Musarra", "Gabriella", ""], ["Kapitany", "Valentin", ""], ["Tonolini", "Francesco", ""], ["Lyons", "Ashley", ""], ["Starshynov", "Ilya", ""], ["Villa", "Federica", ""], ["Conca", "Enrico", ""], ["Fioranelli", "Francesco", ""], ["Murray-Smith", "Roderick", ""], ["Faccio", "Daniele", ""]]}, {"id": "1912.01419", "submitter": "Lorenzo Dall'Amico", "authors": "Lorenzo Dall'Amico, Romain Couillet, Nicolas Tremblay", "title": "Optimal Laplacian regularization for sparse spectral community detection", "comments": null, "journal-ref": "ICASSP 2020-2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization of the classical Laplacian matrices was empirically shown to\nimprove spectral clustering in sparse networks. It was observed that small\nregularizations are preferable, but this point was left as a heuristic\nargument. In this paper we formally determine a proper regularization which is\nintimately related to alternative state-of-the-art spectral techniques for\nsparse graphs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 14:43:07 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 08:21:44 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Dall'Amico", "Lorenzo", ""], ["Couillet", "Romain", ""], ["Tremblay", "Nicolas", ""]]}, {"id": "1912.01422", "submitter": "Anthony Constantinou", "authors": "Norman Fenton, Martin Neil and Anthony Constantinou", "title": "Simpson's Paradox and the implications for medical trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Simpson's paradox, and explains its serious implications\nfor randomised control trials. In particular, we show that for any number of\nvariables we can simulate the result of a controlled trial which uniformly\npoints to one conclusion (such as 'drug is effective') for every possible\ncombination of the variable states, but when a previously unobserved\nconfounding variable is included every possible combination of the variables\nstate points to the opposite conclusion ('drug is not effective'). In other\nwords no matter how many variables are considered, and no matter how\n'conclusive' the result, one cannot conclude the result is truly 'valid' since\nthere is theoretically an unobserved confounding variable that could completely\nreverse the result.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 14:47:16 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Fenton", "Norman", ""], ["Neil", "Martin", ""], ["Constantinou", "Anthony", ""]]}, {"id": "1912.01439", "submitter": "Amedeo Esposito", "authors": "Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa", "title": "Generalization Error Bounds Via R\\'enyi-, $f$-Divergences and Maximal\n  Leakage", "comments": "arXiv admin note: text overlap with arXiv:1903.01777", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, the probability of an event under some joint distribution is\nbounded by measuring it with the product of the marginals instead (which is\ntypically easier to analyze) together with a measure of the dependence between\nthe two random variables. These results find applications in adaptive data\nanalysis, where multiple dependencies are introduced and in learning theory,\nwhere they can be employed to bound the generalization error of a learning\nalgorithm. Bounds are given in terms of Sibson's Mutual Information,\n$\\alpha-$Divergences, Hellinger Divergences, and $f-$Divergences. A case of\nparticular interest is the Maximal Leakage (or Sibson's Mutual Information of\norder infinity), since this measure is robust to post-processing and composes\nadaptively. The corresponding bound can be seen as a generalization of\nclassical bounds, such as Hoeffding's and McDiarmid's inequalities, to the case\nof dependent random variables.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 11:04:52 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 07:49:23 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 12:38:40 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Esposito", "Amedeo Roberto", ""], ["Gastpar", "Michael", ""], ["Issa", "Ibrahim", ""]]}, {"id": "1912.01440", "submitter": "Chenye Wu", "authors": "Jiaman Wu, Zhiqi Wang, Chenye Wu, Kui Wang, Yang Yu", "title": "A Data-driven Storage Control Framework for Dynamic Pricing", "comments": "arXiv admin note: text overlap with arXiv:1911.06963", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic pricing is both an opportunity and a challenge to the demand side. It\nis an opportunity as it better reflects the real time market conditions and\nhence enables an active demand side. However, demand's active participation\ndoes not necessarily lead to benefits. The challenge conventionally comes from\nthe limited flexible resources and limited intelligent devices in demand side.\nThe decreasing cost of storage system and the widely deployed smart meters\ninspire us to design a data-driven storage control framework for dynamic\nprices. We first establish a stylized model by assuming the knowledge and\nstructure of dynamic price distributions, and design the optimal storage\ncontrol policy. Based on Gaussian Mixture Model, we propose a practical\ndata-driven control framework, which helps relax the assumptions in the\nstylized model. Numerical studies illustrate the remarkable performance of the\nproposed data-driven framework.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 12:13:41 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Wu", "Jiaman", ""], ["Wang", "Zhiqi", ""], ["Wu", "Chenye", ""], ["Wang", "Kui", ""], ["Yu", "Yang", ""]]}, {"id": "1912.01443", "submitter": "Aleksey Buzmakov", "authors": "Aleksey Buzmakov, Daria Semenova, Maria Temirkaeva", "title": "The Comparison of Methods for Individual Treatment Effect Detection", "comments": "12 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, treatment effect estimation at the individual level is a vital problem\nin many areas of science and business. For example, in marketing, estimates of\nthe treatment effect are used to select the most efficient promo-mechanics; in\nmedicine, individual treatment effects are used to determine the optimal dose\nof medication for each patient and so on. At the same time, the question on\nchoosing the best method, i.e., the method that ensures the smallest predictive\nerror (for instance, RMSE) or the highest total (average) value of the effect,\nremains open. Accordingly, in this paper we compare the effectiveness of\nmachine learning methods for estimation of individual treatment effects. The\ncomparison is performed on the Criteo Uplift Modeling Dataset. In this paper we\nshow that the combination of the Logistic Regression method and the Difference\nScore method as well as Uplift Random Forest method provide the best\ncorrectness of Individual Treatment Effect prediction on the top 30\\%\nobservations of the test dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 15:05:13 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Buzmakov", "Aleksey", ""], ["Semenova", "Daria", ""], ["Temirkaeva", "Maria", ""]]}, {"id": "1912.01447", "submitter": "Xu Shen", "authors": "Xu Shen, Xinmei Tian, Anfeng He, Shaoyan Sun, Dacheng Tao", "title": "Transform-Invariant Convolutional Neural Networks for Image\n  Classification and Search", "comments": "Accepted by ACM Multimedia. arXiv admin note: text overlap with\n  arXiv:1911.12682", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved state-of-the-art results\non many visual recognition tasks. However, current CNN models still exhibit a\npoor ability to be invariant to spatial transformations of images. Intuitively,\nwith sufficient layers and parameters, hierarchical combinations of convolution\n(matrix multiplication and non-linear activation) and pooling operations should\nbe able to learn a robust mapping from transformed input images to\ntransform-invariant representations. In this paper, we propose randomly\ntransforming (rotation, scale, and translation) feature maps of CNNs during the\ntraining stage. This prevents complex dependencies of specific rotation, scale,\nand translation levels of training images in CNN models. Rather, each\nconvolutional kernel learns to detect a feature that is generally helpful for\nproducing the transform-invariant answer given the combinatorially large\nvariety of transform levels of its input feature maps. In this way, we do not\nrequire any extra training supervision or modification to the optimization\nprocess and training images. We show that random transformation provides\nsignificant improvements of CNNs on many benchmark tasks, including small-scale\nimage recognition, large-scale image recognition, and image retrieval. The code\nis available at https://github.com/jasonustc/caffe-multigpu/tree/TICNN.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:09:21 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["He", "Anfeng", ""], ["Sun", "Shaoyan", ""], ["Tao", "Dacheng", ""]]}, {"id": "1912.01448", "submitter": "Daniel McNamee", "authors": "Daniel McNamee", "title": "Hierarchical model-based policy optimization: from actions to action\n  sequences and back", "comments": "NeurIPS 2019 Optimization Foundations of Reinforcement Learning\n  Workshop. v2: typos fixed, minor edits for improved clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a normative framework for hierarchical model-based policy\noptimization based on applying second-order methods in the space of all\npossible state-action paths. The resulting natural path gradient performs\npolicy updates in a manner which is sensitive to the long-range correlational\nstructure of the induced stationary state-action densities. We demonstrate that\nthe natural path gradient can be computed exactly given an environment dynamics\nmodel and depends on expressions akin to higher-order successor\nrepresentations. In simulation, we show that the priorization of local policy\nupdates in the resulting policy flow indeed reflects the intuitive state-space\nhierarchy in several toy problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 19:01:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 13:11:31 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["McNamee", "Daniel", ""]]}, {"id": "1912.01449", "submitter": "Min Yang", "authors": "Cong Xu, Min Yang and Jin Zhang", "title": "A Fast deflation Method for Sparse Principal Component Analysis via\n  Subspace Projections", "comments": "4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of conventional sparse principal component analysis (SPCA)\non high-dimensional data sets has become a time consuming work. In this paper,\na series of subspace projections are constructed efficiently by using Household\nQR factorization. With the aid of these subspace projections, a fast deflation\nmethod, called SPCA-SP, is developed for SPCA. This method keeps a good\ntradeoff between various criteria, including sparsity, orthogonality, explained\nvariance, balance of sparsity, and computational cost. Comparative experiments\non the benchmark data sets confirm the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 15:10:11 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 00:04:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Xu", "Cong", ""], ["Yang", "Min", ""], ["Zhang", "Jin", ""]]}, {"id": "1912.01450", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang and Beilun Wang", "title": "Fast and Scalable Estimator for Sparse and Unit-Rank Higher-Order\n  Regression Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.12965", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because tensor data appear more and more frequently in various scientific\nresearches and real-world applications, analyzing the relationship between\ntensor features and the univariate outcome becomes an elementary task in many\nfields. To solve this task, we propose \\underline{Fa}st \\underline{S}parse\n\\underline{T}ensor \\underline{R}egression model (FasTR) based on so-called\nunit-rank CANDECOMP/PARAFAC decomposition. FasTR first decomposes the tensor\ncoefficient into component vectors and then estimates each vector with $\\ell_1$\nregularized regression. Because of the independence of component vectors, FasTR\nis able to solve in a parallel way and the time complexity is proved to be\nsuperior to previous models. We evaluate the performance of FasTR on several\nsimulated datasets and a real-world fMRI dataset. Experiment results show that,\ncompared with four baseline models, in every case, FasTR can compute a better\nsolution within less time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 06:59:05 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Wang", "Beilun", ""]]}, {"id": "1912.01451", "submitter": "Richard Tomsett", "authors": "Richard Tomsett, Dan Harborne, Supriyo Chakraborty, Prudhvi Gurram,\n  Alun Preece", "title": "Sanity Checks for Saliency Metrics", "comments": "Accepted for publication at the Thirty Fourth AAAI conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are a popular approach to creating post-hoc explanations of\nimage classifier outputs. These methods produce estimates of the relevance of\neach pixel to the classification output score, which can be displayed as a\nsaliency map that highlights important pixels. Despite a proliferation of such\nmethods, little effort has been made to quantify how good these saliency maps\nare at capturing the true relevance of the pixels to the classifier output\n(i.e. their \"fidelity\"). We therefore investigate existing metrics for\nevaluating the fidelity of saliency methods (i.e. saliency metrics). We find\nthat there is little consistency in the literature in how such metrics are\ncalculated, and show that such inconsistencies can have a significant effect on\nthe measured fidelity. Further, we apply measures of reliability developed in\nthe psychometric testing literature to assess the consistency of saliency\nmetrics when applied to individual saliency maps. Our results show that\nsaliency metrics can be statistically unreliable and inconsistent, indicating\nthat comparative rankings between saliency methods generated using such metrics\ncan be untrustworthy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:30:56 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Tomsett", "Richard", ""], ["Harborne", "Dan", ""], ["Chakraborty", "Supriyo", ""], ["Gurram", "Prudhvi", ""], ["Preece", "Alun", ""]]}, {"id": "1912.01467", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "Linear Convergence of Frank-Wolfe for Rank-One Matrix Recovery Without\n  Strong Convexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider convex optimization problems which are widely used as convex\nrelaxations for low-rank matrix recovery problems. In particular, in several\nimportant problems, such as phase retrieval and robust PCA, the underlying\nassumption in many cases is that the optimal solution is rank-one. In this\npaper we consider a simple and natural sufficient condition on the objective so\nthat the optimal solution to these relaxations is indeed unique and rank-one.\nMainly, we show that under this condition, the standard Frank-Wolfe method with\nline-search (i.e., without any tuning of parameters whatsoever), which only\nrequires a single rank-one SVD computation per iteration, finds an\n$\\epsilon$-approximated solution in only $O(\\log{1/\\epsilon})$ iterations (as\nopposed to the previous best known bound of $O(1/\\epsilon)$), despite the fact\nthat the objective is not strongly convex. We consider several variants of the\nbasic method with improved complexities, as well as an extension motivated by\nrobust PCA, and finally, an extension to nonsmooth problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 15:29:11 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1912.01487", "submitter": "Salah Ghamizi", "authors": "Salah Ghamizi, Maxime Cordy, Mike Papadakis and Yves Le Traon", "title": "Adversarial Embedding: A robust and elusive Steganography and\n  Watermarking technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose adversarial embedding, a new steganography and watermarking\ntechnique that embeds secret information within images. The key idea of our\nmethod is to use deep neural networks for image classification and adversarial\nattacks to embed secret information within images. Thus, we use the attacks to\nembed an encoding of the message within images and the related deep neural\nnetwork outputs to extract it. The key properties of adversarial attacks\n(invisible perturbations, nontransferability, resilience to tampering) offer\nguarantees regarding the confidentiality and the integrity of the hidden\nmessages. We empirically evaluate adversarial embedding using more than 100\nmodels and 1,000 messages. Our results confirm that our embedding passes\nunnoticed by both humans and steganalysis methods, while at the same time\nimpedes illicit retrieval of the message (less than 13% recovery rate when the\ninterceptor has some knowledge about our model), and is resilient to soft and\n(to some extent) aggressive image tampering (up to 100% recovery rate under\njpeg compression). We further develop our method by proposing a new type of\nadversarial attack which improves the embedding density (amount of hidden\ninformation) of our method to up to 10 bits per pixel.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:05:13 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ghamizi", "Salah", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "1912.01493", "submitter": "Eli (Omid) David", "authors": "Ishai Rosenberg, Guillaume Sicard, Eli David", "title": "End-to-End Deep Neural Networks and Transfer Learning for Automatic\n  Analysis of Nation-State Malware", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.09666", "journal-ref": "Entropy, Vol. 20, No. 5, pp. 390-401, May 2018", "doi": "10.3390/e20050390", "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware allegedly developed by nation-states, also known as advanced\npersistent threats (APT), are becoming more common. The task of attributing an\nAPT to a specific nation-state or classifying it to the correct APT family is\nchallenging for several reasons. First, each nation-state has more than a\nsingle cyber unit that develops such malware, rendering traditional authorship\nattribution algorithms useless. Furthermore, the dataset of such available APTs\nis still extremely small. Finally, those APTs use state-of-the-art evasion\ntechniques, making feature extraction challenging. In this paper, we use a deep\nneural network (DNN) as a classifier for nation-state APT attribution. We\nrecord the dynamic behavior of the APT when run in a sandbox and use it as raw\ninput for the neural network, allowing the DNN to learn high level feature\nabstractions of the APTs itself. We also use the same raw features for APT\nfamily classification. Finally, we use the feature abstractions learned by the\nAPT family classifier to solve the attribution problem. Using a test set of\n1000 Chinese and Russian developed APTs, we achieved an accuracy rate of 98.6%.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:21:26 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Rosenberg", "Ishai", ""], ["Sicard", "Guillaume", ""], ["David", "Eli", ""]]}, {"id": "1912.01494", "submitter": "Eli (Omid) David", "authors": "Ido Cohen, Eli David, Nathan S. Netanyahu", "title": "Supervised and Unsupervised End-to-End Deep Learning for Gene Ontology\n  Classification of Neural In Situ Hybridization Images", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.09663", "journal-ref": "Entropy, Vol. 21, No. 3, pp. 221-238, February 2019", "doi": "10.3390/e21030221", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, large datasets of high-resolution mammalian neural images\nhave become available, which has prompted active research on the analysis of\ngene expression data. Traditional image processing methods are typically\napplied for learning functional representations of genes, based on their\nexpressions in these brain images. In this paper, we describe a novel\nend-to-end deep learning-based method for generating compact representations of\nin situ hybridization (ISH) images, which are invariant-to-translation. In\ncontrast to traditional image processing methods, our method relies, instead,\non deep convolutional denoising autoencoders (CDAE) for processing raw pixel\ninputs, and generating the desired compact image representations. We provide an\nin-depth description of our deep learning-based approach, and present extensive\nexperimental results, demonstrating that representations extracted by CDAE can\nhelp learn features of functional gene ontology categories for their\nclassification in a highly accurate manner. Our methods improve the previous\nstate-of-the-art classification rate (Liscovitch, et al.) from an average AUC\nof 0.92 to 0.997, i.e., it achieves 96% reduction in error rate. Furthermore,\nthe representation vectors generated due to our method are more compact in\ncomparison to previous state-of-the-art methods, allowing for a more efficient\nhigh-level representation of images. These results are obtained with\nsignificantly downsampled images in comparison to the original high-resolution\nones, further underscoring the robustness of our proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 01:20:12 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Cohen", "Ido", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.01506", "submitter": "Rodrigo de Lamare", "authors": "H. Ruan and R. C. de Lamare", "title": "Study of Distributed Robust Beamforming with Low-Rank and\n  Cross-Correlation Techniques", "comments": "14 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1712.01115", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a novel robust distributed beamforming (RDB)\napproach based on low-rank and cross-correlation techniques. The proposed RDB\napproach mitigates the effects of channel errors in wireless networks equipped\nwith relays based on the exploitation of the cross-correlation between the\nreceived data from the relays at the destination and the system output and\nlow-rank techniques. The relay nodes are equipped with an amplify-and-forward\n(AF) protocol and the channel errors are modeled using an additive matrix\nperturbation, which results in degradation of the system performance. The\nproposed method, denoted low-rank and cross-correlation RDB (LRCC-RDB),\nconsiders a total relay transmit power constraint in the system and the goal of\nmaximizing the output signal-to-interference-plus-noise ratio (SINR). We carry\nout a performance analysis of the proposed LRCC-RDB technique along with a\ncomputational complexity study. The proposed LRCC-RDB does not require any\ncostly online optimization procedure and simulations show an excellent\nperformance as compared to previously reported algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 01:29:47 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Ruan", "H.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1912.01513", "submitter": "Jan Feyereisl", "authors": "Marek Rosa and Olga Afanasjeva and Simon Andersson and Joseph Davidson\n  and Nicholas Guttenberg and Petr Hlubu\\v{c}ek and Martin Poliak and Jaroslav\n  V\\'itku and Jan Feyereisl", "title": "BADGER: Learning to (Learn [Learning Algorithms] through Multi-Agent\n  Communication)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel memory-based multi-agent meta-learning\narchitecture and learning procedure that allows for learning of a shared\ncommunication policy that enables the emergence of rapid adaptation to new and\nunseen environments by learning to learn learning algorithms through\ncommunication. Behavior, adaptation and learning to adapt emerges from the\ninteractions of homogeneous experts inside a single agent. The proposed\narchitecture should allow for generalization beyond the level seen in existing\nmethods, in part due to the use of a single policy shared by all experts within\nthe agent as well as the inherent modularity of 'Badger'.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:36:42 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Rosa", "Marek", ""], ["Afanasjeva", "Olga", ""], ["Andersson", "Simon", ""], ["Davidson", "Joseph", ""], ["Guttenberg", "Nicholas", ""], ["Hlubu\u010dek", "Petr", ""], ["Poliak", "Martin", ""], ["V\u00edtku", "Jaroslav", ""], ["Feyereisl", "Jan", ""]]}, {"id": "1912.01521", "submitter": "Oren Barkan", "authors": "Oren Barkan", "title": "Multiscale Self Attentive Convolutions for Vision and Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self attention mechanisms have become a key building block in many\nstate-of-the-art language understanding models. In this paper, we show that the\nself attention operator can be formulated in terms of 1x1 convolution\noperations. Following this observation, we propose several novel operators:\nFirst, we introduce a 2D version of self attention that is applicable for 2D\nsignals such as images. Second, we present the 1D and 2D Self Attentive\nConvolutions (SAC) operator that generalizes self attention beyond 1x1\nconvolutions to 1xm and nxm convolutions, respectively. While 1D and 2D self\nattention operate on individual words and pixels, SAC operates on m-grams and\nimage patches, respectively. Third, we present a multiscale version of SAC\n(MSAC) which analyzes the input by employing multiple SAC operators that vary\nby filter size, in parallel. Finally, we explain how MSAC can be utilized for\nvision and language modeling, and further harness MSAC to form a cross\nattentive image similarity machinery.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:51:09 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Barkan", "Oren", ""]]}, {"id": "1912.01522", "submitter": "Akhil Meethal", "authors": "Akhil Meethal and Marco Pedersoli and Soufiane Belharbi and Eric\n  Granger", "title": "Convolutional STN for Weakly Supervised Object Localization", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised object localization is a challenging task in which the\nobject of interest should be localized while learning its appearance.\nState-of-the-art methods recycle the architecture of a standard CNN by using\nthe activation maps of the last layer for localizing the object. While this\napproach is simple and works relatively well, object localization relies on\ndifferent features than classification, thus, a specialized localization\nmechanism is required during training to improve performance. In this paper, we\npropose a convolutional, multi-scale spatial localization network that provides\naccurate localization for the object of interest. Experimental results on\nCUB-200-2011 and ImageNet datasets show that our proposed approach provides\ncompetitive performance for weakly supervised localization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:51:11 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 23:16:53 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Meethal", "Akhil", ""], ["Pedersoli", "Marco", ""], ["Belharbi", "Soufiane", ""], ["Granger", "Eric", ""]]}, {"id": "1912.01530", "submitter": "Joani Mitro", "authors": "John Mitros and Brian Mac Namee", "title": "On the Validity of Bayesian Neural Networks for Uncertainty Estimation", "comments": "AICS2019, fixed typos, figures, tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are versatile parametric models utilised\nsuccessfully in a diverse number of tasks and domains. However, they have\nlimitations---particularly from their lack of robustness and over-sensitivity\nto out of distribution samples. Bayesian Neural Networks, due to their\nformulation under the Bayesian framework, provide a principled approach to\nbuilding neural networks that address these limitations. This paper describes a\nstudy that empirically evaluates and compares Bayesian Neural Networks to their\nequivalent point estimate Deep Neural Networks to quantify the predictive\nuncertainty induced by their parameters, as well as their performance in view\nof this uncertainty. In this study, we evaluated and compared three point\nestimate deep neural networks against comparable Bayesian neural network\nalternatives using two well-known benchmark image classification datasets\n(CIFAR-10 and SVHN).\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:18:08 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 21:38:54 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Mitros", "John", ""], ["Mac Namee", "Brian", ""]]}, {"id": "1912.01540", "submitter": "Himalaya Jain", "authors": "Himalaya Jain, Spyros Gidaris, Nikos Komodakis, Patrick P\\'erez and\n  Matthieu Cord", "title": "QUEST: Quantized embedding space for transferring knowledge", "comments": "Accepted at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation refers to the process of training a compact student\nnetwork to achieve better accuracy by learning from a high capacity teacher\nnetwork. Most of the existing knowledge distillation methods direct the student\nto follow the teacher by matching the teacher's output, feature maps or their\ndistribution. In this work, we propose a novel way to achieve this goal: by\ndistilling the knowledge through a quantized space. According to our method,\nthe teacher's feature maps are quantized to represent the main visual concepts\nencompassed in the feature maps. The student is then asked to predict the\nquantized representation, which thus forms the task that the student uses to\nlearn from the teacher. Despite its simplicity, we show that our approach is\nable to yield results that improve the state of the art on knowledge\ndistillation. To that end, we provide an extensive evaluation across several\nnetwork architectures and most commonly used benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:38:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 18:34:19 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jain", "Himalaya", ""], ["Gidaris", "Spyros", ""], ["Komodakis", "Nikos", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "1912.01548", "submitter": "Zachary Chase", "authors": "Zachary Chase", "title": "Experimental Evidence for Asymptotic Non-Optimality of Comb Adversary\n  Strategy", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the problem of prediction with expert advice in the adversarial setting\nwith finite stopping time, we give strong computer evidence that the comb\nstrategy for $k=5$ experts is not asymptotically optimal, thereby giving strong\nevidence against a conjecture of Gravin, Peres, and Sivan.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:50:32 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chase", "Zachary", ""]]}, {"id": "1912.01553", "submitter": "Joel Michelson", "authors": "Joel Michelson, Joshua H. Palmer, Aneesha Dasari, Maithilee Kunda", "title": "Learning Spatially Structured Image Transformations Using Planar Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning image transformations is essential to the idea of mental simulation\nas a method of cognitive inference. We take a connectionist modeling approach,\nusing planar neural networks to learn fundamental imagery transformations, like\ntranslation, rotation, and scaling, from perceptual experiences in the form of\nimage sequences. We investigate how variations in network topology, training\ndata, and image shape, among other factors, affect the efficiency and\neffectiveness of learning visual imagery transformations, including\neffectiveness of transfer to operating on new types of data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:54:35 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 00:46:43 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Michelson", "Joel", ""], ["Palmer", "Joshua H.", ""], ["Dasari", "Aneesha", ""], ["Kunda", "Maithilee", ""]]}, {"id": "1912.01557", "submitter": "Xinyang Gu", "authors": "Jingbin Liu, Xinyang Gu, Shuai Liu", "title": "Policy Optimization Reinforcement Learning with Entropy Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularization is an important idea in reinforcement learning, with\ngreat success in recent algorithms like Soft Q Network (SQN) and Soft\nActor-Critic (SAC1). In this work, we extend this idea into the on-policy\nrealm. We propose the soft policy gradient theorem (SPGT) for on-policy maximum\nentropy reinforcement learning. With SPGT, a series of new policy optimization\nalgorithms are derived, such as SPG, SA2C, SA3C, SDDPG, STRPO, SPPO, SIMPALA\nand so on. We find that SDDPG is equivalent to SAC1. For policy gradient, the\npolicy network is often represented as a Gaussian distribution with a global\naction variance, which damages the representation capacity. We introduce a\nlocal action variance for policy network and find it can work collaboratively\nwith the idea of entropy regularization. Our method outperforms prior works on\na range of benchmark tasks. Furthermore, our method can be easily extended to\nlarge scale experiment with great stability and parallelism.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:01:32 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 03:28:45 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 05:51:08 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Liu", "Jingbin", ""], ["Gu", "Xinyang", ""], ["Liu", "Shuai", ""]]}, {"id": "1912.01580", "submitter": "Thanapapas Horsuwan", "authors": "Thanapapas Horsuwan, Kasidis Kanwatchara, Peerapon Vateekul, Boonserm\n  Kijsirikul", "title": "A Comparative Study of Pretrained Language Models on Thai Social Text\n  Categorization", "comments": "12 pages, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ever-growing volume of data of user-generated content on social media\nprovides a nearly unlimited corpus of unlabeled data even in languages where\nresources are scarce. In this paper, we demonstrate that state-of-the-art\nresults on two Thai social text categorization tasks can be realized by\npretraining a language model on a large noisy Thai social media corpus of over\n1.26 billion tokens and later fine-tuned on the downstream classification\ntasks. Due to the linguistically noisy and domain-specific nature of the\ncontent, our unique data preprocessing steps designed for Thai social media\nwere utilized to ease the training comprehension of the model. We compared four\nmodern language models: ULMFiT, ELMo with biLSTM, OpenAI GPT, and BERT. We\nsystematically compared the models across different dimensions including speed\nof pretraining and fine-tuning, perplexity, downstream classification\nbenchmarks, and performance in limited pretraining data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:26:13 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 07:47:56 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Horsuwan", "Thanapapas", ""], ["Kanwatchara", "Kasidis", ""], ["Vateekul", "Peerapon", ""], ["Kijsirikul", "Boonserm", ""]]}, {"id": "1912.01588", "submitter": "Karl Cobbe", "authors": "Karl Cobbe, Christopher Hesse, Jacob Hilton, John Schulman", "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Procgen Benchmark, a suite of 16 procedurally generated\ngame-like environments designed to benchmark both sample efficiency and\ngeneralization in reinforcement learning. We believe that the community will\nbenefit from increased access to high quality training environments, and we\nprovide detailed experimental protocols for using this benchmark. We\nempirically demonstrate that diverse environment distributions are essential to\nadequately train and evaluate RL agents, thereby motivating the extensive use\nof procedural content generation. We then use this benchmark to investigate the\neffects of scaling model size, finding that larger models significantly improve\nboth sample efficiency and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:34:03 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 18:39:26 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cobbe", "Karl", ""], ["Hesse", "Christopher", ""], ["Hilton", "Jacob", ""], ["Schulman", "John", ""]]}, {"id": "1912.01592", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John\n  Shawe-Taylor", "title": "Towards an Integrative Educational Recommender for Lifelong Learners", "comments": "In Proceedings of AAAI Conference on Artificial Intelligence 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most ambitious use cases of computer-assisted learning is to build\na recommendation system for lifelong learning. Most recommender algorithms\nexploit similarities between content and users, overseeing the necessity to\nleverage sensible learning trajectories for the learner. Lifelong learning thus\npresents unique challenges, requiring scalable and transparent models that can\naccount for learner knowledge and content novelty simultaneously, while also\nretaining accurate learners representations for long periods of time. We\nattempt to build a novel educational recommender, that relies on an integrative\napproach combining multiple drivers of learners engagement. Our first step\ntowards this goal is TrueLearn, which models content novelty and background\nknowledge of learners and achieves promising performance while retaining a\nhuman interpretable learner model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:40:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1912.01597", "submitter": "Konstantin Mishchenko", "authors": "Dmitry Kovalev and Konstantin Mishchenko and Peter Richt\\'arik", "title": "Stochastic Newton and Cubic Newton Methods with Simple Local\n  Linear-Quadratic Rates", "comments": "16 pages, 2 figures, 3 algorithms, 2 theorems, 7 lemmas; to be\n  presented at the NeurIPS workshop \"Beyond First Order Methods in ML\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new remarkably simple stochastic second-order methods for\nminimizing the average of a very large number of sufficiently smooth and\nstrongly convex functions. The first is a stochastic variant of Newton's method\n(SN), and the second is a stochastic variant of cubically regularized Newton's\nmethod (SCN). We establish local linear-quadratic convergence results. Unlike\nexisting stochastic variants of second order methods, which require the\nevaluation of a large number of gradients and/or Hessians in each iteration to\nguarantee convergence, our methods do not have this shortcoming. For instance,\nthe simplest variants of our methods in each iteration need to compute the\ngradient and Hessian of a {\\em single} randomly selected function only. In\ncontrast to most existing stochastic Newton and quasi-Newton methods, our\napproach guarantees local convergence faster than with first-order oracle and\nadapts to the problem's curvature. Interestingly, our method is not unbiased,\nso our theory provides new intuition for designing new stochastic methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:51:05 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Kovalev", "Dmitry", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1912.01599", "submitter": "Eren Can K{\\i}z{\\i}lda\\u{g}", "authors": "David Gamarnik, Eren C. K{\\i}z{\\i}lda\\u{g}, Ilias Zadik", "title": "Stationary Points of Shallow Neural Networks with Quadratic Activation\n  Function", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the teacher-student setting of learning shallow neural networks\nwith quadratic activations and planted weight matrix $W^*\\in\\mathbb{R}^{m\\times\nd}$, where $m$ is the width of the hidden layer and $d\\le m$ is the data\ndimension. We study the optimization landscape associated with the empirical\nand the population squared risk of the problem. Under the assumption the\nplanted weights are full-rank we obtain the following results. First, we\nestablish that the landscape of the empirical risk admits an \"energy barrier\"\nseparating rank-deficient $W$ from $W^*$: if $W$ is rank deficient, then its\nrisk is bounded away from zero by an amount we quantify. We then couple this\nresult by showing that, assuming number $N$ of samples grows at least like a\npolynomial function of $d$, all full-rank approximate stationary points of the\nempirical risk are nearly global optimum. These two results allow us to prove\nthat gradient descent, when initialized below the energy barrier, approximately\nminimizes the empirical risk and recovers the planted weights in\npolynomial-time. Next, we show that initializing below this barrier is in fact\neasily achieved when the weights are randomly generated under relatively weak\nassumptions. We show that provided the network is sufficiently\noverparametrized, initializing with an appropriate multiple of the identity\nsuffices to obtain a risk below the energy barrier. At a technical level, the\nlast result is a consequence of the semicircle law for the Wishart ensemble and\ncould be of independent interest. Finally, we study the minimizers of the\nempirical risk and identify a simple necessary and sufficient geometric\ncondition on the training data under which any minimizer has necessarily zero\ngeneralization error. We show that as soon as $N\\ge N^*=d(d+1)/2$, randomly\ngenerated data enjoys this geometric condition almost surely, while that ceases\nto be true if $N<N^*$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:52:37 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:21:23 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 22:02:14 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Gamarnik", "David", ""], ["K\u0131z\u0131lda\u011f", "Eren C.", ""], ["Zadik", "Ilias", ""]]}, {"id": "1912.01603", "submitter": "Danijar Hafner", "authors": "Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi", "title": "Dream to Control: Learning Behaviors by Latent Imagination", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned world models summarize an agent's experience to facilitate learning\ncomplex behaviors. While learning world models from high-dimensional sensory\ninputs is becoming feasible through deep learning, there are many potential\nways for deriving behaviors from them. We present Dreamer, a reinforcement\nlearning agent that solves long-horizon tasks from images purely by latent\nimagination. We efficiently learn behaviors by propagating analytic gradients\nof learned state values back through trajectories imagined in the compact state\nspace of a learned world model. On 20 challenging visual control tasks, Dreamer\nexceeds existing approaches in data-efficiency, computation time, and final\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:57:16 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:07:58 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 17:10:58 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hafner", "Danijar", ""], ["Lillicrap", "Timothy", ""], ["Ba", "Jimmy", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1912.01649", "submitter": "Samuel Ainsworth", "authors": "Samuel Ainsworth, Matt Barnes, Siddhartha Srinivasa", "title": "Mo' States Mo' Problems: Emergency Stop Mechanisms from Observation", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many environments, only a relatively small subset of the complete state\nspace is necessary in order to accomplish a given task. We develop a simple\ntechnique using emergency stops (e-stops) to exploit this phenomenon. Using\ne-stops significantly improves sample complexity by reducing the amount of\nrequired exploration, while retaining a performance bound that efficiently\ntrades off the rate of convergence with a small asymptotic sub-optimality gap.\nWe analyze the regret behavior of e-stops and present empirical results in\ndiscrete and continuous settings demonstrating that our reset mechanism can\nprovide order-of-magnitude speedups on top of existing reinforcement learning\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 19:41:37 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Ainsworth", "Samuel", ""], ["Barnes", "Matt", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1912.01666", "submitter": "Leena Chennuru Vankadara", "authors": "Leena Chennuru Vankadara, Siavash Haghiri, Michael Lohaus, Faiz Ul\n  Wahab, Ulrike von Luxburg", "title": "Insights into Ordinal Embedding Algorithms: A Systematic Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of ordinal embedding is to find a Euclidean representation of a\nset of abstract items, using only answers to triplet comparisons of the form\n\"Is item $i$ closer to the item $j$ or item $k$?\". In recent years, numerous\nalgorithms have been proposed to solve this problem. However, there does not\nexist a fair and thorough assessment of these embedding methods and therefore\nseveral key questions remain unanswered: Which algorithms scale better with\nincreasing sample size or dimension? Which ones perform better when the\nembedding dimension is small or few triplet comparisons are available? In our\npaper, we address these questions and provide the first comprehensive and\nsystematic empirical evaluation of existing algorithms as well as a new neural\nnetwork approach. In the large triplet regime, we find that simple, relatively\nunknown, non-convex methods consistently outperform all other algorithms,\nincluding elaborate approaches based on neural networks or landmark approaches.\nThis finding can be explained by our insight that many of the non-convex\noptimization approaches do not suffer from local optima. In the low triplet\nregime, our neural network approach is either competitive or significantly\noutperforms all the other methods. Our comprehensive assessment is enabled by\nour unified library of popular embedding algorithms that leverages GPU\nresources and allows for fast and accurate embeddings of millions of data\npoints.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:06:36 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 18:05:04 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 17:00:46 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 15:41:20 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2020 13:46:48 GMT"}, {"version": "v6", "created": "Wed, 2 Dec 2020 22:09:59 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Vankadara", "Leena Chennuru", ""], ["Haghiri", "Siavash", ""], ["Lohaus", "Michael", ""], ["Wahab", "Faiz Ul", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1912.01667", "submitter": "Siddhant Bhambri", "authors": "Siddhant Bhambri, Sumanyu Muku, Avinash Tulasi, Arun Balaji Buduru", "title": "A Survey of Black-Box Adversarial Attacks on Computer Vision Models", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has seen tremendous advances in the past few years, which\nhas lead to deep learning models being deployed in varied applications of\nday-to-day life. Attacks on such models using perturbations, particularly in\nreal-life scenarios, pose a severe challenge to their applicability, pushing\nresearch into the direction which aims to enhance the robustness of these\nmodels. After the introduction of these perturbations by Szegedy et al. [1],\nsignificant amount of research has focused on the reliability of such models,\nprimarily in two aspects - white-box, where the adversary has access to the\ntargeted model and related parameters; and the black-box, which resembles a\nreal-life scenario with the adversary having almost no knowledge of the model\nto be attacked. To provide a comprehensive security cover, it is essential to\nidentify, study, and build defenses against such attacks. Hence, in this paper,\nwe propose to present a comprehensive comparative study of various black-box\nadversarial attacks and defense techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:06:49 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 07:33:59 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 09:17:38 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bhambri", "Siddhant", ""], ["Muku", "Sumanyu", ""], ["Tulasi", "Avinash", ""], ["Buduru", "Arun Balaji", ""]]}, {"id": "1912.01668", "submitter": "Jialin Ding", "authors": "Vikram Nathan, Jialin Ding, Mohammad Alizadeh, Tim Kraska", "title": "Learning Multi-dimensional Indexes", "comments": null, "journal-ref": null, "doi": "10.1145/3318464.3380579", "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scanning and filtering over multi-dimensional tables are key operations in\nmodern analytical database engines. To optimize the performance of these\noperations, databases often create clustered indexes over a single dimension or\nmulti-dimensional indexes such as R-trees, or use complex sort orders (e.g.,\nZ-ordering). However, these schemes are often hard to tune and their\nperformance is inconsistent across different datasets and queries. In this\npaper, we introduce Flood, a multi-dimensional in-memory index that\nautomatically adapts itself to a particular dataset and workload by jointly\noptimizing the index structure and data storage. Flood achieves up to three\norders of magnitude faster performance for range scans with predicates than\nstate-of-the-art multi-dimensional indexes or sort orders on real-world\ndatasets and workloads. Our work serves as a building block towards an\nend-to-end learned database system.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:10:31 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Nathan", "Vikram", ""], ["Ding", "Jialin", ""], ["Alizadeh", "Mohammad", ""], ["Kraska", "Tim", ""]]}, {"id": "1912.01679", "submitter": "Julian Salazar", "authors": "Shaoshi Ling, Yuzong Liu, Julian Salazar, Katrin Kirchhoff", "title": "Deep Contextualized Acoustic Representations For Semi-Supervised Speech\n  Recognition", "comments": "Accepted to ICASSP 2020 (oral)", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053176", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to semi-supervised automatic speech recognition\n(ASR). We first exploit a large amount of unlabeled audio data via\nrepresentation learning, where we reconstruct a temporal slice of filterbank\nfeatures from past and future context frames. The resulting deep contextualized\nacoustic representations (DeCoAR) are then used to train a CTC-based end-to-end\nASR system using a smaller amount of labeled audio data. In our experiments, we\nshow that systems trained on DeCoAR consistently outperform ones trained on\nconventional filterbank features, giving 42% and 19% relative improvement over\nthe baseline on WSJ eval92 and LibriSpeech test-clean, respectively. Our\napproach can drastically reduce the amount of labeled data required;\nunsupervised training on LibriSpeech then supervision with 100 hours of labeled\ndata achieves performance on par with training on all 960 hours directly.\nPre-trained models and code will be released online.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 20:32:50 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 17:55:35 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Ling", "Shaoshi", ""], ["Liu", "Yuzong", ""], ["Salazar", "Julian", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1912.01703", "submitter": "Soumith Chintala", "authors": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury,\n  Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga,\n  Alban Desmaison, Andreas K\\\"opf, Edward Yang, Zach DeVito, Martin Raison,\n  Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai,\n  Soumith Chintala", "title": "PyTorch: An Imperative Style, High-Performance Deep Learning Library", "comments": "12 pages, 3 figures, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning frameworks have often focused on either usability or speed, but\nnot both. PyTorch is a machine learning library that shows that these two goals\nare in fact compatible: it provides an imperative and Pythonic programming\nstyle that supports code as a model, makes debugging easy and is consistent\nwith other popular scientific computing libraries, while remaining efficient\nand supporting hardware accelerators such as GPUs.\n  In this paper, we detail the principles that drove the implementation of\nPyTorch and how they are reflected in its architecture. We emphasize that every\naspect of PyTorch is a regular Python program under the full control of its\nuser. We also explain how the careful and pragmatic implementation of the key\ncomponents of its runtime enables them to work together to achieve compelling\nperformance.\n  We demonstrate the efficiency of individual subsystems, as well as the\noverall speed of PyTorch on several common benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 22:06:05 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Paszke", "Adam", ""], ["Gross", "Sam", ""], ["Massa", "Francisco", ""], ["Lerer", "Adam", ""], ["Bradbury", "James", ""], ["Chanan", "Gregory", ""], ["Killeen", "Trevor", ""], ["Lin", "Zeming", ""], ["Gimelshein", "Natalia", ""], ["Antiga", "Luca", ""], ["Desmaison", "Alban", ""], ["K\u00f6pf", "Andreas", ""], ["Yang", "Edward", ""], ["DeVito", "Zach", ""], ["Raison", "Martin", ""], ["Tejani", "Alykhan", ""], ["Chilamkurthy", "Sasank", ""], ["Steiner", "Benoit", ""], ["Fang", "Lu", ""], ["Bai", "Junjie", ""], ["Chintala", "Soumith", ""]]}, {"id": "1912.01706", "submitter": "Nicolas Garneau", "authors": "Nicolas Garneau, Mathieu Godbout, David Beauchemin, Audrey Durand, Luc\n  Lamontagne", "title": "A Robust Self-Learning Method for Fully Unsupervised Cross-Lingual\n  Mappings of Word Embeddings: Making the Method Robustly Reproducible as Well", "comments": "Accept in REPROLANG@LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we reproduce the experiments of Artetxe et al. (2018b)\nregarding the robust self-learning method for fully unsupervised cross-lingual\nmappings of word embeddings. We show that the reproduction of their method is\nindeed feasible with some minor assumptions. We further investigate the\nrobustness of their model by introducing four new languages that are less\nsimilar to English than the ones proposed by the original paper. In order to\nassess the stability of their model, we also conduct a grid search over\nsensible hyperparameters. We then propose key recommendations applicable to any\nresearch project in order to deliver fully reproducible research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 22:07:47 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:30:50 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Garneau", "Nicolas", ""], ["Godbout", "Mathieu", ""], ["Beauchemin", "David", ""], ["Durand", "Audrey", ""], ["Lamontagne", "Luc", ""]]}, {"id": "1912.01715", "submitter": "Ali Shafti", "authors": "Jonas Tjomsland, Ali Shafti, A. Aldo Faisal", "title": "Human-Robot Collaboration via Deep Reinforcement Learning of Real-World\n  Interactions", "comments": "Presented at NeurIPS'19 Workshop on Robot Learning: Control and\n  Interaction in the Real World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robotic setup for real-world testing and evaluation of\nhuman-robot and human-human collaborative learning. Leveraging the\nsample-efficiency of the Soft Actor-Critic algorithm, we have implemented a\nrobotic platform able to learn a non-trivial collaborative task with a human\npartner, without pre-training in simulation, and using only 30 minutes of\nreal-world interactions. This enables us to study Human-Robot and Human-Human\ncollaborative learning through real-world interactions. We present preliminary\nresults, showing that state-of-the-art deep learning methods can take\nhuman-robot collaborative learning a step closer to that of humans interacting\nwith each other.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:07:23 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tjomsland", "Jonas", ""], ["Shafti", "Ali", ""], ["Faisal", "A. Aldo", ""]]}, {"id": "1912.01718", "submitter": "Dylan Troop", "authors": "Dylan Troop, Fr\\'ed\\'eric Godin, Jia Yuan Yu", "title": "Risk-Averse Action Selection Using Extreme Value Theory Estimates of the\n  CVaR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide variety of sequential decision making problems, it can be important\nto estimate the impact of rare events in order to minimize risk exposure. A\npopular risk measure is the conditional value-at-risk (CVaR), which is commonly\nestimated by averaging observations that occur beyond a quantile at a given\nconfidence level. When this confidence level is very high, this estimation\nmethod can exhibit high variance due to the limited number of samples above the\ncorresponding quantile. To mitigate this problem, extreme value theory can be\nused to derive an estimator for the CVaR that uses extrapolation beyond\navailable samples. This estimator requires the selection of a threshold\nparameter to work well, which is a difficult challenge that has been widely\nstudied in the extreme value theory literature. In this paper, we present an\nestimation procedure for the CVaR that combines extreme value theory and a\nrecently introduced method of automated threshold selection by\n\\cite{bader2018automated}. Under appropriate conditions, we estimate the tail\nrisk using a generalized Pareto distribution. We compare empirically this\nestimation procedure with the commonly used method of sample averaging, and\nshow an improvement in performance for some distributions. We finally show how\nthe estimation procedure can be used in reinforcement learning by applying our\nmethod to the multi-arm bandit problem where the goal is to avoid catastrophic\nrisk.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 22:19:35 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 18:28:54 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Troop", "Dylan", ""], ["Godin", "Fr\u00e9d\u00e9ric", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1912.01730", "submitter": "Chen Xing", "authors": "Chen Xing, Sercan Arik, Zizhao Zhang, Tomas Pfister", "title": "Distance-Based Learning from Errors for Confidence Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are poorly calibrated when trained in\nconventional ways. To improve confidence calibration of DNNs, we propose a\nnovel training method, distance-based learning from errors (DBLE). DBLE bases\nits confidence estimation on distances in the representation space. In DBLE, we\nfirst adapt prototypical learning to train classification models. It yields a\nrepresentation space where the distance between a test sample and its ground\ntruth class center can calibrate the model's classification performance. At\ninference, however, these distances are not available due to the lack of ground\ntruth labels. To circumvent this by inferring the distance for every test\nsample, we propose to train a confidence model jointly with the classification\nmodel. We integrate this into training by merely learning from mis-classified\ntraining samples, which we show to be highly beneficial for effective learning.\nOn multiple datasets and DNN architectures, we demonstrate that DBLE\noutperforms alternative single-model confidence calibration approaches. DBLE\nalso achieves comparable performance with computationally-expensive ensemble\napproaches with lower computational cost and lower number of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 22:51:51 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 03:44:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xing", "Chen", ""], ["Arik", "Sercan", ""], ["Zhang", "Zizhao", ""], ["Pfister", "Tomas", ""]]}, {"id": "1912.01734", "submitter": "Jesse Thomason", "authors": "Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson\n  Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox", "title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday\n  Tasks", "comments": "Computer Vision and Pattern Recognition (CVPR) 2020 ;\n  https://askforalfred.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ALFRED (Action Learning From Realistic Environments and\nDirectives), a benchmark for learning a mapping from natural language\ninstructions and egocentric vision to sequences of actions for household tasks.\nALFRED includes long, compositional tasks with non-reversible state changes to\nshrink the gap between research benchmarks and real-world applications. ALFRED\nconsists of expert demonstrations in interactive visual environments for 25k\nnatural language directives. These directives contain both high-level goals\nlike \"Rinse off a mug and place it in the coffee maker.\" and low-level language\ninstructions like \"Walk to the coffee maker on the right.\" ALFRED tasks are\nmore complex in terms of sequence length, action space, and language than\nexisting vision-and-language task datasets. We show that a baseline model based\non recent embodied vision-and-language tasks performs poorly on ALFRED,\nsuggesting that there is significant room for developing innovative grounded\nvisual language understanding models with this benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 23:18:59 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 01:18:33 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Shridhar", "Mohit", ""], ["Thomason", "Jesse", ""], ["Gordon", "Daniel", ""], ["Bisk", "Yonatan", ""], ["Han", "Winson", ""], ["Mottaghi", "Roozbeh", ""], ["Zettlemoyer", "Luke", ""], ["Fox", "Dieter", ""]]}, {"id": "1912.01762", "submitter": "Yuan Xue", "authors": "Yuan Xue, Denny Zhou, Nan Du, Andrew Dai, Zhen Xu, Kun Zhang, Claire\n  Cui", "title": "Deep Physiological State Space Model for Clinical Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical forecasting based on electronic medical records (EMR) can uncover\nthe temporal correlations between patients' conditions and outcomes from\nsequences of longitudinal clinical measurements. In this work, we propose an\nintervention-augmented deep state space generative model to capture the\ninteractions among clinical measurements and interventions by explicitly\nmodeling the dynamics of patients' latent states. Based on this model, we are\nable to make a joint prediction of the trajectories of future observations and\ninterventions. Empirical evaluations show that our proposed model compares\nfavorably to several state-of-the-art methods on real EMR data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 01:38:55 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Xue", "Yuan", ""], ["Zhou", "Denny", ""], ["Du", "Nan", ""], ["Dai", "Andrew", ""], ["Xu", "Zhen", ""], ["Zhang", "Kun", ""], ["Cui", "Claire", ""]]}, {"id": "1912.01786", "submitter": "Haoguo Hu", "authors": "Haoguo Hu and Philip Chu", "title": "Predicting Lake Erie Wave Heights using XGBoost", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dangerous large wave put the coastal communities and vessels operating under\nthreats and wave predictions are strongly needed for early warnings. While\nnumerical wave models, such as WAVEWATCH III (WW3), are useful to provide\nspatially continuous information to supplement in situ observations, however,\nthey often require intensive computational costs. An attractive alternative is\nmachine-learning method, which can potentially provide comparable performance\nof numerical wave models but only requires a small fraction of computational\ncosts. In this study, we applied and tested a novel machine learning method\nbased on XGBoost for predicting waves in Lake Erie in 2016-2017. In this study,\nbuoy data from 1994 to 2017 were processed for model training and testing. We\ntrained the model with data from 1994-2015, then used the trained model to\npredict 2016 and 2017 wave features. The mean absolute error of wave height is\nabout 0.11-0.18 m and the maximum error is 1.14-1.95 m, depending on location\nand year. For comparison, an unstructured WW3 model was implemented in Lake\nErie for simulating wind generated waves. The WW3 results were compared with\nbuoy data from National Data Buoy Center in Lake Erie, the mean absolute error\nof wave height is about 0.12-0.48 m and the maximum error is about 1.03-2.93 m.\nThe results show that WW3 underestimates wave height spikes during strong wind\nevents and The XGBoost improves prediction on wave height spikes. The XGBoost\nruns much faster than WW3. For a model year run on a supercomputer, WW3 needs\n12 hours with 60 CPUs while XGBoost needs only 10 minutes with 1 CPU. In\nsummary, the XGBoost provided comparable performance for our simulations in\nLake Erie wave height and the computational time required was about 0.02 % of\nthe numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 03:51:16 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Hu", "Haoguo", ""], ["Chu", "Philip", ""]]}, {"id": "1912.01790", "submitter": "Abulikemu Abuduweili", "authors": "Abulikemu Abuduweili and Changliu Liu", "title": "Robust Online Model Adaptation by Extended Kalman Filter with\n  Exponential Moving Average and Dynamic Multi-Epoch Strategy", "comments": "2nd Annual Conference on Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High fidelity behavior prediction of intelligent agents is critical in many\napplications. However, the prediction model trained on the training set may not\ngeneralize to the testing set due to domain shift and time variance. The\nchallenge motivates the adoption of online adaptation algorithms to update\nprediction models in real-time to improve the prediction performance. Inspired\nby Extended Kalman Filter (EKF), this paper introduces a series of online\nadaptation methods, which are applicable to neural network-based models. A base\nadaptation algorithm Modified EKF with forgetting factor (MEKF$_\\lambda$) is\nintroduced first, followed by exponential moving average filtering techniques.\nThen this paper introduces a dynamic multi-epoch update strategy to effectively\nutilize samples received in real time. With all these extensions, we propose a\nrobust online adaptation algorithm: MEKF with Exponential Moving Average and\nDynamic Multi-Epoch strategy (MEKF$_{\\text{EMA-DME}}$). The proposed algorithm\noutperforms existing methods as demonstrated in experiments. The source code is\nopen-sourced in the following link\nhttps://github.com/intelligent-control-lab/MEKF_MAME.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 04:16:42 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 08:20:53 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 06:33:43 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Abuduweili", "Abulikemu", ""], ["Liu", "Changliu", ""]]}, {"id": "1912.01792", "submitter": "Yawen Zhang", "authors": "Songtao Lu, Yawen Zhang, Yunlong Wang, Christina Mack", "title": "Learn Electronic Health Records by Fully Decentralized Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning opens a number of research opportunities due to its high\ncommunication efficiency in distributed training problems within a star\nnetwork. In this paper, we focus on improving the communication efficiency for\nfully decentralized federated learning over a graph, where the algorithm\nperforms local updates for several iterations and then enables communications\namong the nodes. In such a way, the communication rounds of exchanging the\ncommon interest of parameters can be saved significantly without loss of\noptimality of the solutions. Multiple numerical simulations based on large,\nreal-world electronic health record databases showcase the superiority of the\ndecentralized federated learning compared with classic methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 04:28:05 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 01:31:36 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Lu", "Songtao", ""], ["Zhang", "Yawen", ""], ["Wang", "Yunlong", ""], ["Mack", "Christina", ""]]}, {"id": "1912.01805", "submitter": "Minghao Xu", "authors": "Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian,\n  Wenjun Zhang", "title": "Adversarial Domain Adaptation with Domain Mixup", "comments": "Accepted as oral presentation at 34th AAAI Conference on Artificial\n  Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on domain adaptation reveal the effectiveness of adversarial\nlearning on filling the discrepancy between source and target domains. However,\ntwo common limitations exist in current adversarial-learning-based methods.\nFirst, samples from two domains alone are not sufficient to ensure\ndomain-invariance at most part of latent space. Second, the domain\ndiscriminator involved in these methods can only judge real or fake with the\nguidance of hard label, while it is more reasonable to use soft scores to\nevaluate the generated images or features, i.e., to fully utilize the\ninter-domain information. In this paper, we present adversarial domain\nadaptation with domain mixup (DM-ADA), which guarantees domain-invariance in a\nmore continuous latent space and guides the domain discriminator in judging\nsamples' difference relative to source and target domains. Domain mixup is\njointly conducted on pixel and feature level to improve the robustness of\nmodels. Extensive experiments prove that the proposed approach can achieve\nsuperior performance on tasks with various degrees of domain shift and data\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 05:45:43 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Xu", "Minghao", ""], ["Zhang", "Jian", ""], ["Ni", "Bingbing", ""], ["Li", "Teng", ""], ["Wang", "Chengjie", ""], ["Tian", "Qi", ""], ["Zhang", "Wenjun", ""]]}, {"id": "1912.01809", "submitter": "Ruimeng Hu", "authors": "Jiequn Han, Ruimeng Hu", "title": "Deep Fictitious Play for Finding Markovian Nash Equilibrium in\n  Multi-Agent Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep neural network-based algorithm to identify the Markovian\nNash equilibrium of general large $N$-player stochastic differential games.\nFollowing the idea of fictitious play, we recast the $N$-player game into $N$\ndecoupled decision problems (one for each player) and solve them iteratively.\nThe individual decision problem is characterized by a semilinear\nHamilton-Jacobi-Bellman equation, to solve which we employ the recently\ndeveloped deep BSDE method. The resulted algorithm can solve large $N$-player\ngames for which conventional numerical methods would suffer from the curse of\ndimensionality. Multiple numerical examples involving identical or\nheterogeneous agents, with risk-neutral or risk-sensitive objectives, are\ntested to validate the accuracy of the proposed algorithm in large group games.\nEven for a fifty-player game with the presence of common noise, the proposed\nalgorithm still finds the approximate Nash equilibrium accurately, which, to\nour best knowledge, is difficult to achieve by other numerical algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 05:55:03 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 03:59:07 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Han", "Jiequn", ""], ["Hu", "Ruimeng", ""]]}, {"id": "1912.01810", "submitter": "Xiulong Yang", "authors": "Xiulong Yang, and Shihao Ji", "title": "Learning with Multiplicative Perturbations", "comments": "Accepted as a conference paper at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Training (AT) and Virtual Adversarial Training (VAT) are the\nregularization techniques that train Deep Neural Networks (DNNs) with\nadversarial examples generated by adding small but worst-case perturbations to\ninput examples. In this paper, we propose xAT and xVAT, new adversarial\ntraining algorithms, that generate \\textbf{multiplicative} perturbations to\ninput examples for robust training of DNNs. Such perturbations are much more\nperceptible and interpretable than their \\textbf{additive} counterparts\nexploited by AT and VAT. Furthermore, the multiplicative perturbations can be\ngenerated transductively or inductively while the standard AT and VAT only\nsupport a transductive implementation. We conduct a series of experiments that\nanalyze the behavior of the multiplicative perturbations and demonstrate that\nxAT and xVAT match or outperform state-of-the-art classification accuracies\nacross multiple established benchmarks while being about 30\\% faster than their\nadditive counterparts. Furthermore, the resulting DNNs also demonstrate\ndistinct weight distributions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 05:58:45 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:36:47 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Yang", "Xiulong", ""], ["Ji", "Shihao", ""]]}, {"id": "1912.01816", "submitter": "Eli (Omid) David", "authors": "Evyatar Illouz, Eli David, and Nathan S. Netanyahu", "title": "Handwriting-Based Gender Classification Using End-to-End Deep Neural\n  Networks", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 11141, pp. 613-621, Rhodes, Greece, October 2018", "doi": "10.1007/978-3-030-01424-7_60", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting-based gender classification is a well-researched problem that has\nbeen approached mainly by traditional machine learning techniques. In this\npaper, we propose a novel deep learning-based approach for this task.\nSpecifically, we present a convolutional neural network (CNN), which performs\nautomatic feature extraction from a given handwritten image, followed by\nclassification of the writer's gender. Also, we introduce a new dataset of\nlabeled handwritten samples, in Hebrew and English, of 405 participants.\nComparing the gender classification accuracy on this dataset against human\nexaminers, our results show that the proposed deep learning-based approach is\nsubstantially more accurate than that of humans.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 06:24:31 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Illouz", "Evyatar", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.01823", "submitter": "Pedro Savarese", "authors": "Pedro Savarese and David McAllester and Sudarshan Babu and Michael\n  Maire", "title": "Domain-independent Dominance of Adaptive Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a simplified analysis of adaptive methods, we derive AvaGrad, a new\noptimizer which outperforms SGD on vision tasks when its adaptability is\nproperly tuned. We observe that the power of our method is partially explained\nby a decoupling of learning rate and adaptability, greatly simplifying\nhyperparameter search. In light of this observation, we demonstrate that,\nagainst conventional wisdom, Adam can also outperform SGD on vision tasks, as\nlong as the coupling between its learning rate and adaptability is taken into\naccount. In practice, AvaGrad matches the best results, as measured by\ngeneralization accuracy, delivered by any existing optimizer (SGD or adaptive)\nacross image classification (CIFAR, ImageNet) and character-level language\nmodelling (Penn Treebank) tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 06:58:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 08:03:32 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 01:25:23 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Savarese", "Pedro", ""], ["McAllester", "David", ""], ["Babu", "Sudarshan", ""], ["Maire", "Michael", ""]]}, {"id": "1912.01825", "submitter": "Lars Ruthotto", "authors": "Lars Ruthotto, Stanley Osher, Wuchen Li, Levon Nurbekyan, Samy Wu Fung", "title": "A Machine Learning Framework for Solving High-Dimensional Mean Field\n  Game and Mean Field Control Problems", "comments": "21 pages, 13 figures, 2 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field games (MFG) and mean field control (MFC) are critical classes of\nmulti-agent models for efficient analysis of massive populations of interacting\nagents. Their areas of application span topics in economics, finance, game\ntheory, industrial engineering, crowd motion, and more. In this paper, we\nprovide a flexible machine learning framework for the numerical solution of\npotential MFG and MFC models. State-of-the-art numerical methods for solving\nsuch problems utilize spatial discretization that leads to a\ncurse-of-dimensionality. We approximately solve high-dimensional problems by\ncombining Lagrangian and Eulerian viewpoints and leveraging recent advances\nfrom machine learning. More precisely, we work with a Lagrangian formulation of\nthe problem and enforce the underlying Hamilton-Jacobi-Bellman (HJB) equation\nthat is derived from the Eulerian formulation. Finally, a tailored neural\nnetwork parameterization of the MFG/MFC solution helps us avoid any spatial\ndiscretization. Our numerical results include the approximate solution of\n100-dimensional instances of optimal transport and crowd motion problems on a\nstandard work station and a validation using an Eulerian solver in two\ndimensions. These results open the door to much-anticipated applications of MFG\nand MFC models that were beyond reach with existing numerical methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 06:59:59 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 18:41:41 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 01:15:01 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ruthotto", "Lars", ""], ["Osher", "Stanley", ""], ["Li", "Wuchen", ""], ["Nurbekyan", "Levon", ""], ["Fung", "Samy Wu", ""]]}, {"id": "1912.01831", "submitter": "Preslav Nakov", "authors": "Evgeni Stefchov, Galia Angelova, Preslav Nakov", "title": "Towards Constructing a Corpus for Studying the Effects of Treatments and\n  Substances Reported in PubMed Abstracts", "comments": "medical relation extraction, rationale extraction, effects and\n  treatments, bioNLP", "journal-ref": "AIMSA-2016: The 17th International Conference on Artificial\n  Intelligence: Methodology, Systems, Applications", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the construction of an annotated corpus of PubMed abstracts\nreporting about positive, negative or neutral effects of treatments or\nsubstances. Our ultimate goal is to annotate one sentence (rationale) for each\nabstract and to use this resource as a training set for text classification of\neffects discussed in PubMed abstracts. Currently, the corpus consists of 750\nabstracts. We describe the automatic processing that supports the corpus\nconstruction, the manual annotation activities and some features of the medical\nlanguage in the abstracts selected for the annotated corpus. It turns out that\nrecognizing the terminology and the abbreviations is key for determining the\nrationale sentence. The corpus will be applied to improve our classifier, which\ncurrently has accuracy of 78.80% achieved with normalization of the abstract\nterms based on UMLS concepts from specific semantic groups and an SVM with a\nlinear kernel. Finally, we discuss some other possible applications of this\ncorpus.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 07:22:32 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Stefchov", "Evgeni", ""], ["Angelova", "Galia", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.01834", "submitter": "Weiwei Cai", "authors": "Weiwei Cai, Zhanguo Wei", "title": "PiiGAN: Generative Adversarial Networks for Pluralistic Image Inpainting", "comments": null, "journal-ref": "in IEEE Access, vol. 8, pp. 48451-48463, 2020", "doi": "10.1109/ACCESS.2020.2979348", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest methods based on deep learning have achieved amazing results\nregarding the complex work of inpainting large missing areas in an image. But\nthis type of method generally attempts to generate one single \"optimal\" result,\nignoring many other plausible results. Considering the uncertainty of the\ninpainting task, one sole result can hardly be regarded as a desired\nregeneration of the missing area. In view of this weakness, which is related to\nthe design of the previous algorithms, we propose a novel deep generative model\nequipped with a brand new style extractor which can extract the style feature\n(latent vector) from the ground truth. Once obtained, the extracted style\nfeature and the ground truth are both input into the generator. We also craft a\nconsistency loss that guides the generated image to approximate the ground\ntruth. After iterations, our generator is able to learn the mapping of styles\ncorresponding to multiple sets of vectors. The proposed model can generate a\nlarge number of results consistent with the context semantics of the image.\nMoreover, we evaluated the effectiveness of our model on three datasets, i.e.,\nCelebA, PlantVillage, and MauFlex. Compared to state-of-the-art inpainting\nmethods, this model is able to offer desirable inpainting results with both\nbetter quality and higher diversity. The code and model will be made available\non https://github.com/vivitsai/PiiGAN.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 07:44:41 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 07:49:07 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Cai", "Weiwei", ""], ["Wei", "Zhanguo", ""]]}, {"id": "1912.01849", "submitter": "Dominik Linzner", "authors": "Dominik Linzner and Heinz Koeppl", "title": "A Variational Perturbative Approach to Planning in Graph-based Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinating multiple interacting agents to achieve a common goal is a\ndifficult task with huge applicability. This problem remains hard to solve,\neven when limiting interactions to be mediated via a static interaction-graph.\nWe present a novel approximate solution method for multi-agent Markov decision\nproblems on graphs, based on variational perturbation theory. We adopt the\nstrategy of planning via inference, which has been explored in various prior\nworks. We employ a non-trivial extension of a novel high-order variational\nmethod that allows for approximate inference in large networks and has been\nshown to surpass the accuracy of existing variational methods. To compare our\nmethod to two state-of-the-art methods for multi-agent planning on graphs, we\napply the method different standard GMDP problems. We show that in cases, where\nthe goal is encoded as a non-local cost function, our method performs well,\nwhile state-of-the-art methods approach the performance of random guess. In a\nfinal experiment, we demonstrate that our method brings significant improvement\nfor synchronization tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 08:36:58 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:43:46 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Linzner", "Dominik", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1912.01853", "submitter": "Sumon Bose Mr.", "authors": "Sumon Kumar Bose, Bapi Kar, Mohendra Roy, Pradeep Kumar\n  Gopalakrishnan, Zhang Lei, Aakash Patil and Arindam Basu", "title": "ADEPOS: A Novel Approximate Computing Framework for Anomaly Detection\n  Systems and its Implementation in 65nm CMOS", "comments": "14 pages", "journal-ref": "Preprint TCAS-I 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To overcome the energy and bandwidth limitations of traditional IoT systems,\nedge computing or information extraction at the sensor node has become popular.\nHowever, now it is important to create very low energy information extraction\nor pattern recognition systems. In this paper, we present an approximate\ncomputing method to reduce the computation energy of a specific type of IoT\nsystem used for anomaly detection (e.g. in predictive maintenance, epileptic\nseizure detection, etc). Termed as Anomaly Detection Based Power Savings\n(ADEPOS), our proposed method uses low precision computing and low complexity\nneural networks at the beginning when it is easy to distinguish healthy data.\nHowever, on the detection of anomalies, the complexity of the network and\ncomputing precision are adaptively increased for accurate predictions. We show\nthat ensemble approaches are well suited for adaptively changing network size.\nTo validate our proposed scheme, a chip has been fabricated in UMC65nm process\nthat includes an MSP430 microprocessor along with an on-chip switching mode\nDC-DC converter for dynamic voltage and frequency scaling. Using NASA bearing\ndataset for machine health monitoring, we show that using ADEPOS we can achieve\n8.95X saving of energy along the lifetime without losing any detection\naccuracy. The energy savings are obtained by reducing the execution time of the\nneural network on the microprocessor.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 09:01:12 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Bose", "Sumon Kumar", ""], ["Kar", "Bapi", ""], ["Roy", "Mohendra", ""], ["Gopalakrishnan", "Pradeep Kumar", ""], ["Lei", "Zhang", ""], ["Patil", "Aakash", ""], ["Basu", "Arindam", ""]]}, {"id": "1912.01865", "submitter": "Yunjey Choi", "authors": "Yunjey Choi, Youngjung Uh, Jaejun Yoo, Jung-Woo Ha", "title": "StarGAN v2: Diverse Image Synthesis for Multiple Domains", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A good image-to-image translation model should learn a mapping between\ndifferent visual domains while satisfying the following properties: 1)\ndiversity of generated images and 2) scalability over multiple domains.\nExisting methods address either of the issues, having limited diversity or\nmultiple models for all domains. We propose StarGAN v2, a single framework that\ntackles both and shows significantly improved results over the baselines.\nExperiments on CelebA-HQ and a new animal faces dataset (AFHQ) validate our\nsuperiority in terms of visual quality, diversity, and scalability. To better\nassess image-to-image translation models, we release AFHQ, high-quality animal\nfaces with large inter- and intra-domain differences. The code, pretrained\nmodels, and dataset can be found at https://github.com/clovaai/stargan-v2.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 09:42:22 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 07:09:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Choi", "Yunjey", ""], ["Uh", "Youngjung", ""], ["Yoo", "Jaejun", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1912.01879", "submitter": "Halit Murat G\\\"ursu", "authors": "Serkut Ayva\\c{s}{\\i}k, H. Murat G\\\"ursu, Wolfgang Kellerer", "title": "Veni Vidi Dixi: Reliable Wireless Communication with Depth Images", "comments": "Accepted for publication in CoNext 2019 with reproducibility badges.\n  The measurements and the processing codes are available at\n  https://gitlab.lrz.de/lkn_measurements/vvd_measurements for your evaluation", "journal-ref": null, "doi": "10.1145/3359989.3365418", "report-no": null, "categories": "cs.IT cs.CV cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upcoming industrial revolution requires deployment of critical wireless\nsensor networks for automation and monitoring purposes. However, the\nreliability of the wireless communication is rendered unpredictable by mobile\nelements in the communication environment such as humans or mobile robots which\nlead to dynamically changing radio environments. Changes in the wireless\nchannel can be monitored with frequent pilot transmission. However, that would\nstress the battery life of sensors. In this work a new wireless channel\nestimation technique, Veni Vidi Dixi, VVD, is proposed. VVD leverages the\nredundant information in depth images obtained from the surveillance cameras in\nthe communication environment and utilizes Convolutional Neural Networks CNNs\nto map the depth images of the communication environment to complex wireless\nchannel estimations. VVD increases the wireless communication reliability\nwithout the need for frequent pilot transmission and with no additional\ncomplexity on the receiver. The proposed method is tested by conducting\nmeasurements in an indoor environment with a single mobile human. Up to authors\nbest knowledge our work is the first to obtain complex wireless channel\nestimation from only depth images without any pilot transmission. The collected\nwireless trace, depth images and codes are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 10:21:34 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Ayva\u015f\u0131k", "Serkut", ""], ["G\u00fcrsu", "H. Murat", ""], ["Kellerer", "Wolfgang", ""]]}, {"id": "1912.01899", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Zhenfeng Zhu, Xingxing Zhang, Zhizhe Liu, Jian Cheng, Yao\n  Zhao", "title": "Distribution-induced Bidirectional Generative Adversarial Network for\n  Graph Representation Learning", "comments": "Accepted to CVPR2020. 10 pages, 5 figures, 4 tables, fixed a error in\n  the Figure.1", "journal-ref": "booktitle={Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition}, pages={7224--7233}, year={2020}", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning aims to encode all nodes of a graph into\nlow-dimensional vectors that will serve as input of many compute vision tasks.\nHowever, most existing algorithms ignore the existence of inherent data\ndistribution and even noises. This may significantly increase the phenomenon of\nover-fitting and deteriorate the testing accuracy. In this paper, we propose a\nDistribution-induced Bidirectional Generative Adversarial Network (named DBGAN)\nfor graph representation learning. Instead of the widely used normal\ndistribution assumption, the prior distribution of latent representation in our\nDBGAN is estimated in a structure-aware way, which implicitly bridges the graph\nand feature spaces by prototype learning. Thus discriminative and robust\nrepresentations are generated for all nodes. Furthermore, to improve their\ngeneralization ability while preserving representation ability, the\nsample-level and distribution-level consistency is well balanced via a\nbidirectional adversarial learning framework. An extensive group of experiments\nare then carefully designed and presented, demonstrating that our DBGAN obtains\nremarkably more favorable trade-off between representation and robustness, and\nmeanwhile is dimension-efficient, over currently available alternatives in\nvarious tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 11:23:36 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 14:14:18 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 01:35:07 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zheng", "Shuai", ""], ["Zhu", "Zhenfeng", ""], ["Zhang", "Xingxing", ""], ["Liu", "Zhizhe", ""], ["Cheng", "Jian", ""], ["Zhao", "Yao", ""]]}, {"id": "1912.01909", "submitter": "Erik Nijkamp", "authors": "Erik Nijkamp, Bo Pang, Tian Han, Linqi Zhou, Song-Chun Zhu, Ying Nian\n  Wu", "title": "Learning Multi-layer Latent Variable Model via Variational Optimization\n  of Short Run MCMC for Approximate Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the fundamental problem of learning deep generative models\nthat consist of multiple layers of latent variables organized in top-down\narchitectures. Such models have high expressivity and allow for learning\nhierarchical representations. Learning such a generative model requires\ninferring the latent variables for each training example based on the posterior\ndistribution of these latent variables. The inference typically requires Markov\nchain Monte Caro (MCMC) that can be time consuming. In this paper, we propose\nto use noise initialized non-persistent short run MCMC, such as finite step\nLangevin dynamics initialized from the prior distribution of the latent\nvariables, as an approximate inference engine, where the step size of the\nLangevin dynamics is variationally optimized by minimizing the Kullback-Leibler\ndivergence between the distribution produced by the short run MCMC and the\nposterior distribution. Our experiments show that the proposed method\noutperforms variational auto-encoder (VAE) in terms of reconstruction error and\nsynthesis quality. The advantage of the proposed method is that it is simple\nand automatic without the need to design an inference model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 11:42:14 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 20:14:18 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 21:20:30 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 10:16:11 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 22:54:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Nijkamp", "Erik", ""], ["Pang", "Bo", ""], ["Han", "Tian", ""], ["Zhou", "Linqi", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1912.01927", "submitter": "Holger Trittenbach", "authors": "Holger Trittenbach, Klemens B\\\"ohm, Ira Assent", "title": "Active Learning of SVDD Hyperparameter Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Data Description is a popular method for outlier detection.\nHowever, its usefulness largely depends on selecting good hyperparameter values\n-- a difficult problem that has received significant attention in literature.\nExisting methods to estimate hyperparameter values are purely heuristic, and\nthe conditions under which they work well are unclear. In this article, we\npropose LAMA (Local Active Min-Max Alignment), the first principled approach to\nestimate SVDD hyperparameter values by active learning. The core idea bases on\nkernel alignment, which we adapt to active learning with small sample sizes. In\ncontrast to many existing approaches, LAMA provides estimates for both SVDD\nhyperparameters. These estimates are evidence-based, i.e., rely on actual class\nlabels, and come with a quality score. This eliminates the need for manual\nvalidation, an issue with current heuristics. LAMA outperforms state-of-the-art\ncompetitors in extensive experiments on real-world data. In several cases, LAMA\neven yields results close to the empirical upper bound.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 12:25:43 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Trittenbach", "Holger", ""], ["B\u00f6hm", "Klemens", ""], ["Assent", "Ira", ""]]}, {"id": "1912.01933", "submitter": "Ahmed Abdelwahab", "authors": "Ahmed Abdelwahab and Niels Landwehr", "title": "Deep Distributional Sequence Embeddings Based on a Wasserstein Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning employs deep neural networks to embed instances into a\nmetric space such that distances between instances of the same class are small\nand distances between instances from different classes are large. In most\nexisting deep metric learning techniques, the embedding of an instance is given\nby a feature vector produced by a deep neural network and Euclidean distance or\ncosine similarity defines distances between these vectors. In this paper, we\nstudy deep distributional embeddings of sequences, where the embedding of a\nsequence is given by the distribution of learned deep features across the\nsequence. This has the advantage of capturing statistical information about the\ndistribution of patterns within the sequence in the embedding. When embeddings\nare distributions rather than vectors, measuring distances between embeddings\ninvolves comparing their respective distributions. We propose a distance metric\nbased on Wasserstein distances between the distributions and a corresponding\nloss function for metric learning, which leads to a novel end-to-end trainable\nembedding model. We empirically observe that distributional embeddings\noutperform standard vector embeddings and that training with the proposed\nWasserstein metric outperforms training with other distance functions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 12:43:28 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Abdelwahab", "Ahmed", ""], ["Landwehr", "Niels", ""]]}, {"id": "1912.01937", "submitter": "Ziming Liu", "authors": "Ziming Liu, Zheng Zhang", "title": "Quantum-Inspired Hamiltonian Monte Carlo for Bayesian Sampling", "comments": "38 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is an efficient Bayesian sampling method that\ncan make distant proposals in the parameter space by simulating a Hamiltonian\ndynamical system. Despite its popularity in machine learning and data science,\nHMC is inefficient to sample from spiky and multimodal distributions. Motivated\nby the energy-time uncertainty relation from quantum mechanics, we propose a\nQuantum-Inspired Hamiltonian Monte Carlo algorithm (QHMC). This algorithm\nallows a particle to have a random mass matrix with a probability distribution\nrather than a fixed mass. We prove the convergence property of QHMC and further\nshow why such a random mass can improve the performance when we sample a broad\nclass of distributions. In order to handle the big training data sets in\nlarge-scale machine learning, we develop a stochastic gradient version of QHMC\nusing Nos{\\'e}-Hoover thermostat called QSGNHT, and we also provide theoretical\njustifications about its steady-state distributions. Finally in the\nexperiments, we demonstrate the effectiveness of QHMC and QSGNHT on synthetic\nexamples, bridge regression, image denoising and neural network pruning. The\nproposed QHMC and QSGNHT can indeed achieve much more stable and accurate\nsampling results on the test cases.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 12:56:35 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 07:14:03 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 02:53:09 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Liu", "Ziming", ""], ["Zhang", "Zheng", ""]]}, {"id": "1912.01956", "submitter": "Eva-Maria Walz", "authors": "Tilmann Gneiting and Eva-Maria Walz", "title": "Receiver operating characteristic (ROC) movies, universal ROC (UROC)\n  curves, and coefficient of predictive ability (CPA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout science and technology, receiver operating characteristic (ROC)\ncurves and associated area under the curve (AUC) measures constitute powerful\ntools for assessing the predictive abilities of features, markers and tests in\nbinary classification problems. Despite its immense popularity, ROC analysis\nhas been subject to a fundamental restriction, in that it applies to\ndichotomous (yes or no) outcomes only. Here we introduce ROC movies and\nuniversal ROC (UROC) curves that apply to just any linearly ordered outcome,\nalong with an associated coefficient of predictive ability (CPA) measure. CPA\nequals the area under the UROC curve, and admits appealing interpretations in\nterms of probabilities and rank based covariances. For binary outcomes CPA\nequals AUC, and for pairwise distinct outcomes CPA relates linearly to\nSpearman's coefficient, in the same way that the C index relates linearly to\nKendall's coefficient. ROC movies, UROC curves, and CPA nest and generalize the\ntools of classical ROC analysis, and are bound to supersede them in a wealth of\napplications. Their usage is illustrated in data examples from biomedicine and\nmeteorology, where rank based measures yield new insights in the WeatherBench\ncomparison of the predictive performance of convolutional neural networks and\nphysical-numerical models for weather prediction.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 21:16:47 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 13:43:45 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 14:46:15 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Gneiting", "Tilmann", ""], ["Walz", "Eva-Maria", ""]]}, {"id": "1912.01966", "submitter": "Sebastian Guendel", "authors": "Sebastian Guendel and Andreas Maier", "title": "Epoch-wise label attacks for robustness against label noise", "comments": "Accepted at BVM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current accessibility to large medical datasets for training\nconvolutional neural networks is tremendously high. The associated dataset\nlabels are always considered to be the real \"ground truth\". However, the\nlabeling procedures often seem to be inaccurate and many wrong labels are\nintegrated. This may have fatal consequences on the performance of both\ntraining and evaluation. In this paper, we show the impact of label noise in\nthe training set on a specific medical problem based on chest X-ray images.\nWith a simple one-class problem, the classification of tuberculosis, we measure\nthe performance on a clean evaluation set when training with label-corrupt\ndata. We develop a method to compete with incorrectly labeled data during\ntraining by randomly attacking labels on individual epochs. The network tends\nto be robust when flipping correct labels for a single epoch and initiates a\ngood step to the optimal minimum on the error surface when flipping noisy\nlabels. On a baseline with an AUC (Area under Curve) score of 0.924, the\nperformance drops to 0.809 when 30% of our training data is misclassified. With\nour approach the baseline performance could almost be maintained, the\nperformance raised to 0.918.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 13:39:21 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 14:47:37 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Guendel", "Sebastian", ""], ["Maier", "Andreas", ""]]}, {"id": "1912.01969", "submitter": "Fabian Hinder", "authors": "Fabian Hinder, Andr\\'e Artelt and Barbara Hammer", "title": "A probability theoretic approach to drifting data in continuous time\n  domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of drift refers to the phenomenon that the distribution, which is\nunderlying the observed data, changes over time. Albeit many attempts were made\nto deal with drift, formal notions of drift are application-dependent and\nformulated in various degrees of abstraction and mathematical coherence. In\nthis contribution, we provide a probability theoretical framework, that allows\na formalization of drift in continuous time, which subsumes popular notions of\ndrift. In particular, it sheds some light on common practice such as\nchange-point detection or machine learning methodologies in the presence of\ndrift. It gives rise to a new characterization of drift in terms of stochastic\ndependency between data and time. This particularly intuitive formalization\nenables us to design a new, efficient drift detection method. Further, it\ninduces a technology, to decompose observed data into a drifting and a\nnon-drifting part.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 13:42:07 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Hinder", "Fabian", ""], ["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1912.01978", "submitter": "Mahum Naseer", "authors": "Mahum Naseer, Mishal Fatima Minhas, Faiq Khalid, Muhammad Abdullah\n  Hanif, Osman Hasan, Muhammad Shafique", "title": "FANNet: Formal Analysis of Noise Tolerance, Training Bias and Input\n  Sensitivity in Neural Networks", "comments": "To appear at the 23rd Design, Automation and Test in Europe (DATE\n  2020). Grenoble, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a constant improvement in the network architectures and training\nmethodologies, Neural Networks (NNs) are increasingly being deployed in\nreal-world Machine Learning systems. However, despite their impressive\nperformance on \"known inputs\", these NNs can fail absurdly on the \"unseen\ninputs\", especially if these real-time inputs deviate from the training dataset\ndistributions, or contain certain types of input noise. This indicates the low\nnoise tolerance of NNs, which is a major reason for the recent increase of\nadversarial attacks. This is a serious concern, particularly for\nsafety-critical applications, where inaccurate results lead to dire\nconsequences. We propose a novel methodology that leverages model checking for\nthe Formal Analysis of Neural Network (FANNet) under different input noise\nranges. Our methodology allows us to rigorously analyze the noise tolerance of\nNNs, their input node sensitivity, and the effects of training bias on their\nperformance, e.g., in terms of classification accuracy. For evaluation, we use\na feed-forward fully-connected NN architecture trained for the Leukemia\nclassification. Our experimental results show $\\pm 11\\%$ noise tolerance for\nthe given trained network, identify the most sensitive input nodes, and confirm\nthe biasness of the available training dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 12:42:47 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 22:38:46 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Naseer", "Mahum", ""], ["Minhas", "Mishal Fatima", ""], ["Khalid", "Faiq", ""], ["Hanif", "Muhammad Abdullah", ""], ["Hasan", "Osman", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1912.01987", "submitter": "Edwin D. Simpson", "authors": "Edwin Simpson, Iryna Gurevych", "title": "Scalable Bayesian Preference Learning for Crowds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable Bayesian preference learning method for jointly\npredicting the preferences of individuals as well as the consensus of a crowd\nfrom pairwise labels. Peoples' opinions often differ greatly, making it\ndifficult to predict their preferences from small amounts of personal data.\nIndividual biases also make it harder to infer the consensus of a crowd when\nthere are few labels per item. We address these challenges by combining matrix\nfactorisation with Gaussian processes, using a Bayesian approach to account for\nuncertainty arising from noisy and sparse data. Our method exploits input\nfeatures, such as text embeddings and user metadata, to predict preferences for\nnew items and users that are not in the training set. As previous solutions\nbased on Gaussian processes do not scale to large numbers of users, items or\npairwise labels, we propose a stochastic variational inference approach that\nlimits computational and memory costs. Our experiments on a recommendation task\nshow that our method is competitive with previous approaches despite our\nscalable inference approximation. We demonstrate the method's scalability on a\nnatural language processing task with thousands of users and items, and show\nimprovements over the state of the art on this task. We make our software\npublicly available for future work.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 13:56:38 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 20:01:44 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Simpson", "Edwin", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1912.01991", "submitter": "Ishan Misra", "authors": "Ishan Misra, Laurens van der Maaten", "title": "Self-Supervised Learning of Pretext-Invariant Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of self-supervised learning from images is to construct image\nrepresentations that are semantically meaningful via pretext tasks that do not\nrequire semantic annotations for a large training set of images. Many pretext\ntasks lead to representations that are covariant with image transformations. We\nargue that, instead, semantic representations ought to be invariant under such\ntransformations. Specifically, we develop Pretext-Invariant Representation\nLearning (PIRL, pronounced as \"pearl\") that learns invariant representations\nbased on pretext tasks. We use PIRL with a commonly used pretext task that\ninvolves solving jigsaw puzzles. We find that PIRL substantially improves the\nsemantic quality of the learned image representations. Our approach sets a new\nstate-of-the-art in self-supervised learning from images on several popular\nbenchmarks for self-supervised learning. Despite being unsupervised, PIRL\noutperforms supervised pre-training in learning image representations for\nobject detection. Altogether, our results demonstrate the potential of\nself-supervised learning of image representations with good invariance\nproperties.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 13:59:48 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Misra", "Ishan", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1912.02008", "submitter": "Benjamin Aubin", "authors": "Benjamin Aubin, Bruno Loureiro, Antoine Baker, Florent Krzakala and\n  Lenka Zdeborov\\'a", "title": "Exact asymptotics for phase retrieval and compressed sensing with random\n  generative priors", "comments": "13+3 pages, 7 figures, v2 revised and accepted at MSML", "journal-ref": "Proceedings of The First Mathematical and Scientific Machine\n  Learning Conference, PMLR 107:55-73, 2020", "doi": null, "report-no": null, "categories": "math.ST cond-mat.dis-nn cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of compressed sensing and of (real-valued) phase\nretrieval with random measurement matrix. We derive sharp asymptotics for the\ninformation-theoretically optimal performance and for the best known polynomial\nalgorithm for an ensemble of generative priors consisting of fully connected\ndeep neural networks with random weight matrices and arbitrary activations. We\ncompare the performance to sparse separable priors and conclude that generative\npriors might be advantageous in terms of algorithmic performance. In\nparticular, while sparsity does not allow to perform compressive phase\nretrieval efficiently close to its information-theoretic limit, it is found\nthat under the random generative prior compressed phase retrieval becomes\ntractable.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:20:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 07:40:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Aubin", "Benjamin", ""], ["Loureiro", "Bruno", ""], ["Baker", "Antoine", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1912.02015", "submitter": "Zimin Chen", "authors": "Zimin Chen, Steve Kommrusch, Martin Monperrus", "title": "Using Sequence-to-Sequence Learning for Repairing C Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software vulnerabilities affect all businesses and research is being done to\navoid, detect or repair them. In this article, we contribute a new technique\nfor automatic vulnerability fixing. We present a system that uses the rich\nsoftware development history that can be found on GitHub to train an AI system\nthat generates patches. We apply sequence-to-sequence learning on a big dataset\nof code changes and we evaluate the trained system on real world\nvulnerabilities from the CVE database. The result shows the feasibility of\nusing sequence-to-sequence learning for fixing software vulnerabilities.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:27:34 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Chen", "Zimin", ""], ["Kommrusch", "Steve", ""], ["Monperrus", "Martin", ""]]}, {"id": "1912.02039", "submitter": "Paul Irofti", "authors": "Andrei Patrascu and Paul Irofti", "title": "Stochastic proximal splitting algorithm for composite minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supported by the recent contributions in multiple branches, the first-order\nsplitting algorithms became central for structured nonsmooth optimization. In\nthe large-scale or noisy contexts, when only stochastic information on the\nsmooth part of the objective function is available, the extension of proximal\ngradient schemes to stochastic oracles is based on proximal tractability of the\nnonsmooth component and it has been deeply analyzed in the literature. However,\nthere remained gaps illustrated by composite models where the nonsmooth term is\nnot proximally tractable anymore. In this note we tackle composite optimization\nproblems, where the access only to stochastic information on both smooth and\nnonsmooth components is assumed, using a stochastic proximal first-order scheme\nwith stochastic proximal updates. We provide $\\mathcal{O}\\left( \\frac{1}{k}\n\\right)$ the iteration complexity (in expectation of squared distance to the\noptimal set) under the strong convexity assumption on the objective function.\nEmpirical behavior is illustrated by numerical tests on parametric sparse\nrepresentation models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:05:03 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 15:23:04 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 13:44:27 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Patrascu", "Andrei", ""], ["Irofti", "Paul", ""]]}, {"id": "1912.02057", "submitter": "Xin Dong", "authors": "Yuhang Li, Xin Dong, Sai Qian Zhang, Haoli Bai, Yuanpeng Chen, Wei\n  Wang", "title": "RTN: Reparameterized Ternary Network", "comments": "To appear at AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deploy deep neural networks on resource-limited devices, quantization has\nbeen widely explored. In this work, we study the extremely low-bit networks\nwhich have tremendous speed-up, memory saving with quantized activation and\nweights. We first bring up three omitted issues in extremely low-bit networks:\nthe squashing range of quantized values; the gradient vanishing during\nbackpropagation and the unexploited hardware acceleration of ternary networks.\nBy reparameterizing quantized activation and weights vector with full precision\nscale and offset for fixed ternary vector, we decouple the range and magnitude\nfrom the direction to extenuate the three issues. Learnable scale and offset\ncan automatically adjust the range of quantized values and sparsity without\ngradient vanishing. A novel encoding and computation pat-tern are designed to\nsupport efficient computing for our reparameterized ternary network (RTN).\nExperiments on ResNet-18 for ImageNet demonstrate that the proposed RTN finds a\nmuch better efficiency between bitwidth and accuracy, and achieves up to 26.76%\nrelative accuracy improvement compared with state-of-the-art methods. Moreover,\nwe validate the proposed computation pattern on Field Programmable Gate Arrays\n(FPGA), and it brings 46.46x and 89.17x savings on power and area respectively\ncompared with the full precision convolution.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:31:25 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 22:01:57 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Li", "Yuhang", ""], ["Dong", "Xin", ""], ["Zhang", "Sai Qian", ""], ["Bai", "Haoli", ""], ["Chen", "Yuanpeng", ""], ["Wang", "Wei", ""]]}, {"id": "1912.02059", "submitter": "Zheyuan Wang", "authors": "Zheyuan Wang and Matthew Gombolay", "title": "Learning to Dynamically Coordinate Multi-Robot Teams in Graph Attention\n  Networks", "comments": "This paper has been extended to an article in IEEE Robotics and\n  Automation Letters (DOI: 10.1109/LRA.2020.3002198)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing interest in integrating advanced robotics within manufacturing has\nspurred a renewed concentration in developing real-time scheduling solutions to\ncoordinate human-robot collaboration in this environment. Traditionally, the\nproblem of scheduling agents to complete tasks with temporal and spatial\nconstraints has been approached either with exact algorithms, which are\ncomputationally intractable for large-scale, dynamic coordination, or\napproximate methods that require domain experts to craft heuristics for each\napplication. We seek to overcome the limitations of these conventional methods\nby developing a novel graph attention network formulation to automatically\nlearn features of scheduling problems to allow their deployment. To learn\neffective policies for combinatorial optimization problems via machine\nlearning, we combine imitation learning on smaller problems with deep\nQ-learning on larger problems, in a non-parametric framework, to allow for\nfast, near-optimal scheduling of robot teams. We show that our network-based\npolicy finds at least twice as many solutions over prior state-of-the-art\nmethods in all testing scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:32:53 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 20:20:33 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Wang", "Zheyuan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "1912.02065", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Omar Darwish, Christopher Parsons, Dami\n  Rebergen, John W Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Safety and Robustness in Decision Making: Deep Bayesian Recurrent Neural\n  Networks for Somatic Variant Calling in Cancer", "comments": "Safety and Robustness in Decision Making Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The genomic profile underlying an individual tumor can be highly informative\nin the creation of a personalized cancer treatment strategy for a given\npatient; a practice known as precision oncology. This involves next generation\nsequencing of a tumor sample and the subsequent identification of genomic\naberrations, such as somatic mutations, to provide potential candidates of\ntargeted therapy. The identification of these aberrations from sequencing noise\nand germline variant background poses a classic classification-style problem.\nThis has been previously broached with many different supervised machine\nlearning methods, including deep-learning neural networks. However, these\nneural networks have thus far not been tailored to give any indication of\nconfidence in the mutation call, meaning an oncologist could be targeting a\nmutation with a low probability of being true. To address this, we present here\na deep bayesian recurrent neural network for cancer variant calling, which\nshows no degradation in performance compared to standard neural networks. This\napproach enables greater flexibility through different priors to avoid\noverfitting to a single dataset. We will be incorporating this approach into\nsoftware for oncologists to obtain safe, robust, and statistically confident\nsomatic mutation calls for precision oncology treatment choices.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:47:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Darwish", "Omar", ""], ["Parsons", "Christopher", ""], ["Rebergen", "Dami", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1912.02074", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Bo Dai, Ilya Kostrikov, Yinlam Chow, Lihong Li, Dale\n  Schuurmans", "title": "AlgaeDICE: Policy Gradient from Arbitrary Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications of reinforcement learning (RL), interactions\nwith the environment are limited due to cost or feasibility. This presents a\nchallenge to traditional RL algorithms since the max-return objective involves\nan expectation over on-policy samples. We introduce a new formulation of\nmax-return optimization that allows the problem to be re-expressed by an\nexpectation over an arbitrary behavior-agnostic and off-policy data\ndistribution. We first derive this result by considering a regularized version\nof the dual max-return objective before extending our findings to unregularized\nobjectives through the use of a Lagrangian formulation of the linear\nprogramming characterization of Q-values. We show that, if auxiliary dual\nvariables of the objective are optimized, then the gradient of the off-policy\nobjective is exactly the on-policy policy gradient, without any use of\nimportance weighting. In addition to revealing the appealing theoretical\nproperties of this approach, we also show that it delivers good practical\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 16:06:10 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nachum", "Ofir", ""], ["Dai", "Bo", ""], ["Kostrikov", "Ilya", ""], ["Chow", "Yinlam", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1912.02098", "submitter": "Siddarth Srinivasan", "authors": "Sandesh Adhikary, Siddarth Srinivasan, Geoff Gordon, Byron Boots", "title": "Expressiveness and Learning of Hidden Quantum Markov Models", "comments": "arXiv admin note: text overlap with arXiv:1903.03730", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending classical probabilistic reasoning using the quantum mechanical view\nof probability has been of recent interest, particularly in the development of\nhidden quantum Markov models (HQMMs) to model stochastic processes. However,\nthere has been little progress in characterizing the expressiveness of such\nmodels and learning them from data. We tackle these problems by showing that\nHQMMs are a special subclass of the general class of observable operator models\n(OOMs) that do not suffer from the \\emph{negative probability problem} by\ndesign. We also provide a feasible retraction-based learning algorithm for\nHQMMs using constrained gradient descent on the Stiefel manifold of model\nparameters. We demonstrate that this approach is faster and scales to larger\nmodels than previous learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:51:19 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Adhikary", "Sandesh", ""], ["Srinivasan", "Siddarth", ""], ["Gordon", "Geoff", ""], ["Boots", "Byron", ""]]}, {"id": "1912.02109", "submitter": "Bill Yang Cai", "authors": "Bill Cai, Xiaojiang Li, Carlo Ratti", "title": "Quantifying Urban Canopy Cover with Deep Convolutional Neural Networks", "comments": "NeurIPS 2019 Workshop on Climate Change AI at Vancouver, British\n  Columbia, Canada. arXiv admin note: text overlap with arXiv:1808.04754", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban canopy cover is important to mitigate the impact of climate change.\nYet, existing quantification of urban greenery is either manual and not\nscalable, or use traditional computer vision methods that are inaccurate. We\ntrain deep convolutional neural networks (DCNNs) on datasets used for\nself-driving cars to estimate urban greenery instead, and find that our\nsemantic segmentation and direct end-to-end estimation method are more accurate\nand scalable, reducing mean absolute error of estimating the Green View Index\n(GVI) metric from 10.1% to 4.67%. With the revised DCNN methods, the Treepedia\nproject was able to scale and analyze canopy cover in 22 cities\ninternationally, sparking interest and action in public policy and research\nfields.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 17:14:53 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Cai", "Bill", ""], ["Li", "Xiaojiang", ""], ["Ratti", "Carlo", ""]]}, {"id": "1912.02119", "submitter": "Walter Vinci", "authors": "Walter Vinci, Lorenzo Buffoni, Hossein Sadeghi, Amir Khoshaman, Evgeny\n  Andriyash, Mohammad H. Amin", "title": "A Path Towards Quantum Advantage in Training Deep Generative Models with\n  Quantum Annealers", "comments": "20 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of quantum-classical hybrid (QCH) algorithms is critical to\nachieve state-of-the-art computational models. A QCH variational autoencoder\n(QVAE) was introduced in Ref. [1] by some of the authors of this paper. QVAE\nconsists of a classical auto-encoding structure realized by traditional deep\nneural networks to perform inference to, and generation from, a discrete latent\nspace. The latent generative process is formalized as thermal sampling from\neither a quantum or classical Boltzmann machine (QBM or BM). This setup allows\nquantum-assisted training of deep generative models by physically simulating\nthe generative process with quantum annealers. In this paper, we have\nsuccessfully employed D-Wave quantum annealers as Boltzmann samplers to perform\nquantum-assisted, end-to-end training of QVAE. The hybrid structure of QVAE\nallows us to deploy current-generation quantum annealers in QCH generative\nmodels to achieve competitive performance on datasets such as MNIST. The\nresults presented in this paper suggest that commercially available quantum\nannealers can be deployed, in conjunction with well-crafted classical deep\nneutral networks, to achieve competitive results in unsupervised and\nsemisupervised tasks on large-scale datasets. We also provide evidence that our\nsetup is able to exploit large latent-space (Q)BMs, which develop slowly mixing\nmodes. This expressive latent space results in slow and inefficient classical\nsampling, and paves the way to achieve quantum advantage with quantum annealing\nin realistic sampling applications.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:03:34 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Vinci", "Walter", ""], ["Buffoni", "Lorenzo", ""], ["Sadeghi", "Hossein", ""], ["Khoshaman", "Amir", ""], ["Andriyash", "Evgeny", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1912.02143", "submitter": "Antoine Maillard", "authors": "Antoine Maillard and G\\'erard Ben Arous and Giulio Biroli", "title": "Landscape Complexity for the Empirical Risk of Generalized Linear Models", "comments": "18 pages and 18 pages appendix. Update to match the published version\n  (v2). Corrections of remaining small typos (v3)", "journal-ref": "Proceedings of The First Mathematical and Scientific Machine\n  Learning Conference, PMLR 107:287-327, 2020", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to obtain the average and the typical value of the number\nof critical points of the empirical risk landscape for generalized linear\nestimation problems and variants. This represents a substantial extension of\nprevious applications of the Kac-Rice method since it allows to analyze the\ncritical points of high dimensional non-Gaussian random functions. We obtain a\nrigorous explicit variational formula for the annealed complexity, which is the\nlogarithm of the average number of critical points at fixed value of the\nempirical risk. This result is simplified, and extended, using the non-rigorous\nKac-Rice replicated method from theoretical physics. In this way we find an\nexplicit variational formula for the quenched complexity, which is generally\ndifferent from its annealed counterpart, and allows to obtain the number of\ncritical points for typical instances up to exponential accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:47:24 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:12:42 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 09:22:09 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Maillard", "Antoine", ""], ["Arous", "G\u00e9rard Ben", ""], ["Biroli", "Giulio", ""]]}, {"id": "1912.02149", "submitter": "Vitor Guizilini", "authors": "Vitor Guizilini, Ransalu Senanayake and Fabio Ramos", "title": "Dynamic Hilbert Maps: Real-Time Occupancy Predictions in Changing\n  Environment", "comments": "International Conference on Robotics and Automation (ICRA), Montreal,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning instantaneous occupancy levels\nof dynamic environments and predicting future occupancy levels. Due to the\ncomplexity of most real-world environments, such as urban streets or crowded\nareas, the efficient and robust incorporation of temporal dependencies into\notherwise static occupancy models remains a challenge. We propose a method to\ncapture the spatial uncertainty of moving objects and incorporate this\nuncertainty information into a continuous occupancy map represented in a rich\nhigh-dimensional feature space. Experiments performed using LIDAR data verified\nthe real-time performance of the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:55:08 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Guizilini", "Vitor", ""], ["Senanayake", "Ransalu", ""], ["Ramos", "Fabio", ""]]}, {"id": "1912.02153", "submitter": "Hanwei Zhang", "authors": "Hanwei Zhang, Yannis Avrithis, Teddy Furon, Laurent Amsaleg", "title": "Walking on the Edge: Fast, Low-Distortion Adversarial Examples", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TIFS.2020.3021899", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples of deep neural networks are receiving ever increasing\nattention because they help in understanding and reducing the sensitivity to\ntheir input. This is natural given the increasing applications of deep neural\nnetworks in our everyday lives. When white-box attacks are almost always\nsuccessful, it is typically only the distortion of the perturbations that\nmatters in their evaluation.\n  In this work, we argue that speed is important as well, especially when\nconsidering that fast attacks are required by adversarial training. Given more\ntime, iterative methods can always find better solutions. We investigate this\nspeed-distortion trade-off in some depth and introduce a new attack called\nboundary projection (BP) that improves upon existing methods by a large margin.\nOur key idea is that the classification boundary is a manifold in the image\nspace: we therefore quickly reach the boundary and then optimize distortion on\nthis manifold.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:04:53 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 12:07:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Zhang", "Hanwei", ""], ["Avrithis", "Yannis", ""], ["Furon", "Teddy", ""], ["Amsaleg", "Laurent", ""]]}, {"id": "1912.02154", "submitter": "Francisco Ibarrola", "authors": "Nicol\\'as Nieto, Francisco Ibarrola, Victoria Peterson, Hugo Rufiner\n  and Ruben Spies", "title": "Extreme Learning Machine design for dealing with unrepresentative\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme Learning Machines (ELMs) have become a popular tool in the field of\nArtificial Intelligence due to their very high training speed and\ngeneralization capabilities. Another advantage is that they have a single\nhyper-parameter that must be tuned up: the number of hidden nodes. Most\ntraditional approaches dictate that this parameter should be chosen smaller\nthan the number of available training samples in order to avoid over-fitting.\nIn fact, it has been proved that choosing the number of hidden nodes equal to\nthe number of training samples yields a perfect training classification with\nprobability 1 (w.r.t. the random parameter initialization). In this article we\nargue that in spite of this, in some cases it may be beneficial to choose a\nmuch larger number of hidden nodes, depending on certain properties of the\ndata. We explain why this happens and show some examples to illustrate how the\nmodel behaves. In addition, we present a pruning algorithm to cope with the\nadditional computational burden associated to the enlarged ELM. Experimental\nresults using electroencephalography (EEG) signals show an improvement in\nperformance with respect to traditional ELM approaches, while diminishing the\nextra computing time associated to the use of large architectures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:06:58 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nieto", "Nicol\u00e1s", ""], ["Ibarrola", "Francisco", ""], ["Peterson", "Victoria", ""], ["Rufiner", "Hugo", ""], ["Spies", "Ruben", ""]]}, {"id": "1912.02160", "submitter": "Tao Wu", "authors": "Pierre Br\\'echet, Tao Wu, Thomas M\\\"ollenhoff, Daniel Cremers", "title": "Informative GANs via Structured Regularization of Optimal Transport", "comments": "Presented at the Optimal Transport and Machine Learning Workshop,\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the challenge of disentangled representation learning in generative\nadversarial networks (GANs) from the perspective of regularized optimal\ntransport (OT). Specifically, a smoothed OT loss gives rise to an implicit\ntransportation plan between the latent space and the data space. Based on this\ntheoretical observation, we exploit a structured regularization on the\ntransportation plan to encourage a prescribed latent subspace to be\ninformative. This yields the formulation of a novel informative OT-based GAN.\nBy convex duality, we obtain the equivalent view that this leads to perturbed\nground costs favoring sparsity in the informative latent dimensions.\nPractically, we devise a stable training algorithm for the proposed informative\nGAN. Our experiments support the hypothesis that such regularizations\neffectively yield the discovery of disentangled and interpretable latent\nrepresentations. Our work showcases potential power of a regularized OT\nframework in the context of generative modeling through its access to the\ntransport plan. Further challenges are addressed in this line.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:25:38 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Br\u00e9chet", "Pierre", ""], ["Wu", "Tao", ""], ["M\u00f6llenhoff", "Thomas", ""], ["Cremers", "Daniel", ""]]}, {"id": "1912.02163", "submitter": "Nicholas Wilkins", "authors": "Nicholas Wilkins, Michael Johnson, Ifeoma Nwogu", "title": "Regression with Uncertainty Quantification in Large Scale Complex Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While several methods for predicting uncertainty on deep networks have been\nrecently proposed, they do not readily translate to large and complex datasets.\nIn this paper we utilize a simplified form of the Mixture Density Networks\n(MDNs) to produce a one-shot approach to quantify uncertainty in regression\nproblems. We show that our uncertainty bounds are on-par or better than other\nreported existing methods. When applied to standard regression benchmark\ndatasets, we show an improvement in predictive log-likelihood and\nroot-mean-square-error when compared to existing state-of-the-art methods. We\nalso demonstrate this method's efficacy on stochastic, highly volatile\ntime-series data where stock prices are predicted for the next time interval.\nThe resulting uncertainty graph summarizes significant anomalies in the stock\nprice chart. Furthermore, we apply this method to the task of age estimation\nfrom the challenging IMDb-Wiki dataset of half a million face images. We\nsuccessfully predict the uncertainties associated with the prediction and\nempirically analyze the underlying causes of the uncertainties. This\nuncertainty quantification can be used to pre-process low quality datasets and\nfurther enable learning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:29:14 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Wilkins", "Nicholas", ""], ["Johnson", "Michael", ""], ["Nwogu", "Ifeoma", ""]]}, {"id": "1912.02164", "submitter": "Rosanne Liu", "authors": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank,\n  Piero Molino, Jason Yosinski, Rosanne Liu", "title": "Plug and Play Language Models: A Simple Approach to Controlled Text\n  Generation", "comments": "ICLR 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large transformer-based language models (LMs) trained on huge text corpora\nhave shown unparalleled generation capabilities. However, controlling\nattributes of the generated language (e.g. switching topic or sentiment) is\ndifficult without modifying the model architecture or fine-tuning on\nattribute-specific data and entailing the significant cost of retraining. We\npropose a simple alternative: the Plug and Play Language Model (PPLM) for\ncontrollable language generation, which combines a pretrained LM with one or\nmore simple attribute classifiers that guide text generation without any\nfurther training of the LM. In the canonical scenario we present, the attribute\nmodels are simple classifiers consisting of a user-specified bag of words or a\nsingle learned layer with 100,000 times fewer parameters than the LM. Sampling\nentails a forward and backward pass in which gradients from the attribute model\npush the LM's hidden activations and thus guide the generation. Model samples\ndemonstrate control over a range of topics and sentiment styles, and extensive\nautomated and human annotated evaluations show attribute alignment and fluency.\nPPLMs are flexible in that any combination of differentiable attribute models\nmay be used to steer text generation, which will allow for diverse and creative\napplications beyond the examples given in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:32:15 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 01:02:25 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 06:05:58 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 05:33:49 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Dathathri", "Sumanth", ""], ["Madotto", "Andrea", ""], ["Lan", "Janice", ""], ["Hung", "Jane", ""], ["Frank", "Eric", ""], ["Molino", "Piero", ""], ["Yosinski", "Jason", ""], ["Liu", "Rosanne", ""]]}, {"id": "1912.02165", "submitter": "Rati Gelashvili", "authors": "Rati Gelashvili, Nir Shavit, Aleksandar Zlateski", "title": "L3 Fusion: Fast Transformed Convolutions on CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast convolutions via transforms, either Winograd or FFT, had emerged as a\npreferred way of performing the computation of convolutional layers, as it\ngreatly reduces the number of required operations. Recent work shows that, for\nmany layer structures, a well--designed implementation of fast convolutions can\ngreatly utilize modern CPUs, significantly reducing the compute time. However,\nthe generous amount of shared L3 cache present on modern CPUs is often\nneglected, and the algorithms are optimized solely for the private L2 cache. In\nthis paper we propose an efficient `L3 Fusion` algorithm that is specifically\ndesigned for CPUs with significant amount of shared L3 cache. Using the\nhierarchical roofline model, we show that in many cases, especially for layers\nwith fewer channels, the `L3 fused` approach can greatly outperform standard 3\nstage one provided by big vendors such as Intel. We validate our theoretical\nfindings, by benchmarking our `L3 fused` implementation against publicly\navailable state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:34:58 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Gelashvili", "Rati", ""], ["Shavit", "Nir", ""], ["Zlateski", "Aleksandar", ""]]}, {"id": "1912.02166", "submitter": "Roland Molontay", "authors": "G\\'abor Horv\\'ath, Edith Kov\\'acs, Roland Molontay, Szabolcs\n  Nov\\'aczki", "title": "Copula-based anomaly scoring and localization for large-scale,\n  high-dimensional continuous data", "comments": "27 pages, 12 figures, accepted at ACM Transactions on Intelligent\n  Systems and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anomaly detection method presented by this paper has a special feature:\nit does not only indicate whether an observation is anomalous or not but also\ntells what exactly makes an anomalous observation unusual. Hence, it provides\nsupport to localize the reason of the anomaly.\n  The proposed approach is model-based; it relies on the multivariate\nprobability distribution associated with the observations. Since the rare\nevents are present in the tails of the probability distributions, we use copula\nfunctions, that are able to model the fat-tailed distributions well. The\npresented procedure scales well; it can cope with a large number of\nhigh-dimensional samples. Furthermore, our procedure can cope with missing\nvalues, too, which occur frequently in high-dimensional data sets.\n  In the second part of the paper, we demonstrate the usability of the method\nthrough a case study, where we analyze a large data set consisting of the\nperformance counters of a real mobile telecommunication network. Since such\nnetworks are complex systems, the signs of sub-optimal operation can remain\nhidden for a potentially long time. With the proposed procedure, many such\nhidden issues can be isolated and indicated to the network operator.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:35:54 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Horv\u00e1th", "G\u00e1bor", ""], ["Kov\u00e1cs", "Edith", ""], ["Molontay", "Roland", ""], ["Nov\u00e1czki", "Szabolcs", ""]]}, {"id": "1912.02175", "submitter": "V\\'it Musil", "authors": "Marin Vlastelica and Anselm Paulus and V\\'it Musil and Georg Martius\n  and Michal Rol\\'inek", "title": "Differentiation of Blackbox Combinatorial Solvers", "comments": "ICLR 2020 conference paper (spotlight). The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving fusion of deep learning with combinatorial algorithms promises\ntransformative changes to artificial intelligence. One possible approach is to\nintroduce combinatorial building blocks into neural networks. Such end-to-end\narchitectures have the potential to tackle combinatorial problems on raw input\ndata such as ensuring global consistency in multi-object tracking or route\nplanning on maps in robotics. In this work, we present a method that implements\nan efficient backward pass through blackbox implementations of combinatorial\nsolvers with linear objective functions. We provide both theoretical and\nexperimental backing. In particular, we incorporate the Gurobi MIP solver,\nBlossom V algorithm, and Dijkstra's algorithm into architectures that extract\nsuitable features from raw inputs for the traveling salesman problem, the\nmin-cost perfect matching problem and the shortest path problem. The code is\navailable at https://github.com/martius-lab/blackbox-backprop.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:54:42 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 20:44:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Vlastelica", "Marin", ""], ["Paulus", "Anselm", ""], ["Musil", "V\u00edt", ""], ["Martius", "Georg", ""], ["Rol\u00ednek", "Michal", ""]]}, {"id": "1912.02178", "submitter": "Hossein Mobahi", "authors": "Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, Samy\n  Bengio", "title": "Fantastic Generalization Measures and Where to Find Them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization of deep networks has been of great interest in recent years,\nresulting in a number of theoretically and empirically motivated complexity\nmeasures. However, most papers proposing such measures study only a small set\nof models, leaving open the question of whether the conclusion drawn from those\nexperiments would remain valid in other settings. We present the first large\nscale study of generalization in deep networks. We investigate more then 40\ncomplexity measures taken from both theoretical bounds and empirical studies.\nWe train over 10,000 convolutional networks by systematically varying commonly\nused hyperparameters. Hoping to uncover potentially causal relationships\nbetween each measure and generalization, we analyze carefully controlled\nexperiments and show surprising failures of some measures as well as promising\nmeasures for further research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 18:58:26 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Jiang", "Yiding", ""], ["Neyshabur", "Behnam", ""], ["Mobahi", "Hossein", ""], ["Krishnan", "Dilip", ""], ["Bengio", "Samy", ""]]}, {"id": "1912.02182", "submitter": "Maurizio Tesconi", "authors": "Marco Avvenuti, Salvatore Bellomo, Stefano Cresci, Leonardo Nizzoli,\n  Maurizio Tesconi", "title": "Towards better social crisis data with HERMES: Hybrid sensing for\n  EmeRgency ManagEment System", "comments": null, "journal-ref": "Pervasive and Mobile Computing 67, 2020", "doi": "10.1016/j.pmcj.2020.101225", "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People involved in mass emergencies increasingly publish information-rich\ncontents in online social networks (OSNs), thus acting as a distributed and\nresilient network of human sensors. In this work, we present HERMES, a system\ndesigned to enrich the information spontaneously disclosed by OSN users in the\naftermath of disasters. HERMES leverages a mixed data collection strategy,\ncalled hybrid crowdsensing, and state-of-the-art AI techniques. Evaluated in\nreal-world emergencies, HERMES proved to increase: (i) the amount of the\navailable damage information; (ii) the density (up to 7x) and the variety (up\nto 18x) of the retrieved geographic information; (iii) the geographic coverage\n(up to 30%) and granularity.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:25:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Avvenuti", "Marco", ""], ["Bellomo", "Salvatore", ""], ["Cresci", "Stefano", ""], ["Nizzoli", "Leonardo", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1912.02222", "submitter": "Martin Ellis", "authors": "Joyce Fang, Martin Ellis, Bin Li, Siyao Liu, Yasaman Hosseinkashi,\n  Michael Revow, Albert Sadovnikov, Ziyuan Liu, Peng Cheng, Sachin Ashok, David\n  Zhao, Ross Cutler, Yan Lu, Johannes Gehrke", "title": "Reinforcement learning for bandwidth estimation and congestion control\n  in real-time communications", "comments": "Workshop on ML for Systems at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandwidth estimation and congestion control for real-time communications\n(i.e., audio and video conferencing) remains a difficult problem, despite many\nyears of research. Achieving high quality of experience (QoE) for end users\nrequires continual updates due to changing network architectures and\ntechnologies. In this paper, we apply reinforcement learning for the first time\nto the problem of real-time communications (RTC), where we seek to optimize\nuser-perceived quality. We present initial proof-of-concept results, where we\nlearn an agent to control sending rate in an RTC system, evaluating using both\nnetwork simulation and real Internet video calls. We discuss the challenges we\nobserved, particularly in designing realistic reward functions that reflect\nQoE, and in bridging the gap between the training environment and real-world\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 19:19:14 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Fang", "Joyce", ""], ["Ellis", "Martin", ""], ["Li", "Bin", ""], ["Liu", "Siyao", ""], ["Hosseinkashi", "Yasaman", ""], ["Revow", "Michael", ""], ["Sadovnikov", "Albert", ""], ["Liu", "Ziyuan", ""], ["Cheng", "Peng", ""], ["Ashok", "Sachin", ""], ["Zhao", "David", ""], ["Cutler", "Ross", ""], ["Lu", "Yan", ""], ["Gehrke", "Johannes", ""]]}, {"id": "1912.02233", "submitter": "Li Wang", "authors": "Zitong Wang and Li Wang and Raymond Chan and Tieyong Zeng", "title": "Large-Scale Semi-Supervised Learning via Graph Structure Learning over\n  High-Dense Points", "comments": "25 Pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on developing a novel scalable graph-based semi-supervised learning\n(SSL) method for a small number of labeled data and a large amount of unlabeled\ndata. Due to the lack of labeled data and the availability of large-scale\nunlabeled data, existing SSL methods usually encounter either suboptimal\nperformance because of an improper graph or the high computational complexity\nof the large-scale optimization problem. In this paper, we propose to address\nboth challenging problems by constructing a proper graph for graph-based SSL\nmethods. Different from existing approaches, we simultaneously learn a small\nset of vertexes to characterize the high-dense regions of the input data and a\ngraph to depict the relationships among these vertexes. A novel approach is\nthen proposed to construct the graph of the input data from the learned graph\nof a small number of vertexes with some preferred properties. Without\nexplicitly calculating the constructed graph of inputs, two transductive\ngraph-based SSL approaches are presented with the computational complexity in\nlinear with the number of input data. Extensive experiments on synthetic data\nand real datasets of varied sizes demonstrate that the proposed method is not\nonly scalable for large-scale data, but also achieve good classification\nperformance, especially for extremely small number of labels.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:00:47 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Wang", "Zitong", ""], ["Wang", "Li", ""], ["Chan", "Raymond", ""], ["Zeng", "Tieyong", ""]]}, {"id": "1912.02235", "submitter": "Lukas Zorich", "authors": "Lukas Zorich, Karim Pichara, Pavlos Protopapas", "title": "Streaming Classification of Variable Stars", "comments": null, "journal-ref": null, "doi": "10.1093/mnras/stz3426", "report-no": null, "categories": "astro-ph.IM astro-ph.GA astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, automatic classification of variable stars has received\nsubstantial attention. Using machine learning techniques for this task has\nproven to be quite useful. Typically, machine learning classifiers used for\nthis task require to have a fixed training set, and the training process is\nperformed offline. Upcoming surveys such as the Large Synoptic Survey Telescope\n(LSST) will generate new observations daily, where an automatic classification\nsystem able to create alerts online will be mandatory. A system with those\ncharacteristics must be able to update itself incrementally. Unfortunately,\nafter training, most machine learning classifiers do not support the inclusion\nof new observations in light curves, they need to re-train from scratch.\nNaively re-training from scratch is not an option in streaming settings, mainly\nbecause of the expensive pre-processing routines required to obtain a vector\nrepresentation of light curves (features) each time we include new\nobservations. In this work, we propose a streaming probabilistic classification\nmodel; it uses a set of newly designed features that work incrementally. With\nthis model, we can have a machine learning classifier that updates itself in\nreal time with new observations. To test our approach, we simulate a streaming\nscenario with light curves from CoRot, OGLE and MACHO catalogs. Results show\nthat our model achieves high classification performance, staying an order of\nmagnitude faster than traditional classification approaches.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:09:56 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zorich", "Lukas", ""], ["Pichara", "Karim", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "1912.02241", "submitter": "Jing Bi", "authors": "Jing Bi, Vikas Dhiman, Tianyou Xiao, Chenliang Xu", "title": "Learning from Interventions using Hierarchical Policies for Safe\n  Learning", "comments": "Accepted for publication at the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Demonstrations (LfD) via Behavior Cloning (BC) works well on\nmultiple complex tasks. However, a limitation of the typical LfD approach is\nthat it requires expert demonstrations for all scenarios, including those in\nwhich the algorithm is already well-trained. The recently proposed Learning\nfrom Interventions (LfI) overcomes this limitation by using an expert overseer.\nThe expert overseer only intervenes when it suspects that an unsafe action is\nabout to be taken. Although LfI significantly improves over LfD, the\nstate-of-the-art LfI fails to account for delay caused by the expert's reaction\ntime and only learns short-term behavior. We address these limitations by 1)\ninterpolating the expert's interventions back in time, and 2) by splitting the\npolicy into two hierarchical levels, one that generates sub-goals for the\nfuture and another that generates actions to reach those desired sub-goals.\nThis sub-goal prediction forces the algorithm to learn long-term behavior while\nalso being robust to the expert's reaction time. Our experiments show that LfI\nusing sub-goals in a hierarchical policy framework trains faster and achieves\nbetter asymptotic performance than typical LfD.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:28:51 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Bi", "Jing", ""], ["Dhiman", "Vikas", ""], ["Xiao", "Tianyou", ""], ["Xu", "Chenliang", ""]]}, {"id": "1912.02249", "submitter": "Senthil Yogamani", "authors": "Michal Uricar, Ganesh Sistu, Hazem Rashed, Antonin Vobecky, Varun Ravi\n  Kumar, Pavel Krizek, Fabian Burger and Senthil Yogamani", "title": "Let's Get Dirty: GAN Based Data Augmentation for Camera Lens Soiling\n  Detection in Autonomous Driving", "comments": "Camera ready version + supplementary material. Accepted for\n  presentation at Winter Conference on Applications of Computer Vision 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide-angle fisheye cameras are commonly used in automated driving for parking\nand low-speed navigation tasks. Four of such cameras form a surround-view\nsystem that provides a complete and detailed view of the vehicle. These cameras\nare directly exposed to harsh environmental settings and can get soiled very\neasily by mud, dust, water, frost. Soiling on the camera lens can severely\ndegrade the visual perception algorithms, and a camera cleaning system\ntriggered by a soiling detection algorithm is increasingly being deployed.\nWhile adverse weather conditions, such as rain, are getting attention recently,\nthere is only limited work on general soiling. The main reason is the\ndifficulty in collecting a diverse dataset as it is a relatively rare event. We\npropose a novel GAN based algorithm for generating unseen patterns of soiled\nimages. Additionally, the proposed method automatically provides the\ncorresponding soiling masks eliminating the manual annotation cost.\nAugmentation of the generated soiled images for training improves the accuracy\nof soiling detection tasks significantly by 18% demonstrating its usefulness.\nThe manually annotated soiling dataset and the generated augmentation dataset\nwill be made public. We demonstrate the generalization of our fisheye trained\nGAN model on the Cityscapes dataset. We provide an empirical evaluation of the\ndegradation of the semantic segmentation algorithm with the soiled data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:01:06 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 22:07:23 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 21:13:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Uricar", "Michal", ""], ["Sistu", "Ganesh", ""], ["Rashed", "Hazem", ""], ["Vobecky", "Antonin", ""], ["Kumar", "Varun Ravi", ""], ["Krizek", "Pavel", ""], ["Burger", "Fabian", ""], ["Yogamani", "Senthil", ""]]}, {"id": "1912.02254", "submitter": "Yongcan Cao", "authors": "Huixin Zhan, Wei-Ming Lin, and Yongcan Cao", "title": "Deep Model Compression Via Two-Stage Deep Reinforcement Learning", "comments": "To appear in ECML/PKDD 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides accuracy, the model size of convolutional neural networks (CNN)\nmodels is another important factor considering limited hardware resources in\npractical applications. For example, employing deep neural networks on mobile\nsystems requires the design of accurate yet fast CNN for low latency in\nclassification and object detection. To fulfill the need, we aim at obtaining\nCNN models with both high testing accuracy and small size to address resource\nconstraints in many embedded devices. In particular, this paper focuses on\nproposing a generic reinforcement learning-based model compression approach in\na two-stage compression pipeline: pruning and quantization. The first stage of\ncompression, i.e., pruning, is achieved via exploiting deep reinforcement\nlearning (DRL) to co-learn the accuracy and the FLOPs updated after layer-wise\nchannel pruning and element-wise variational pruning via information dropout.\nThe second stage, i.e., quantization, is achieved via a similar DRL approach\nbut focuses on obtaining the optimal bits representation for individual layers.\nWe further conduct experimental results on CIFAR-10 and ImageNet datasets. For\nthe CIFAR-10 dataset, the proposed method can reduce the size of VGGNet by 9x\nfrom 20.04MB to 2.2MB with a slight accuracy increase. For the ImageNet\ndataset, the proposed method can reduce the size of VGG-16 by 33x from 138MB to\n4.14MB with no accuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:34:19 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 12:20:48 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zhan", "Huixin", ""], ["Lin", "Wei-Ming", ""], ["Cao", "Yongcan", ""]]}, {"id": "1912.02258", "submitter": "Raj Dasgupta", "authors": "Prithviraj Dasgupta and Joseph B. Collins", "title": "A Survey of Game Theoretic Approaches for Adversarial Machine Learning\n  in Cybersecurity Tasks", "comments": "13 pages, 2 figures, 1 table", "journal-ref": "AI Magazine, 40(2), 31-43 (2019)", "doi": "10.1609/aimag.v40i2.2847", "report-no": null, "categories": "cs.CR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are currently used extensively for automating\nvarious cybersecurity tasks. Most of these techniques utilize supervised\nlearning algorithms that rely on training the algorithm to classify incoming\ndata into different categories, using data encountered in the relevant domain.\nA critical vulnerability of these algorithms is that they are susceptible to\nadversarial attacks where a malicious entity called an adversary deliberately\nalters the training data to misguide the learning algorithm into making\nclassification errors. Adversarial attacks could render the learning algorithm\nunsuitable to use and leave critical systems vulnerable to cybersecurity\nattacks. Our paper provides a detailed survey of the state-of-the-art\ntechniques that are used to make a machine learning algorithm robust against\nadversarial attacks using the computational framework of game theory. We also\ndiscuss open problems and challenges and possible directions for further\nresearch that would make deep machine learning-based systems more robust and\nreliable for cybersecurity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:42:15 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Dasgupta", "Prithviraj", ""], ["Collins", "Joseph B.", ""]]}, {"id": "1912.02260", "submitter": "Jessica Thompson", "authors": "Jessica A.F. Thompson, Yoshua Bengio, Marc Schoenwiesner", "title": "The effect of task and training on intermediate representations in\n  convolutional neural networks revealed with modified RV similarity analysis", "comments": "4 pages, 4 figures, Conference on Cognitive Computational\n  Neuroscience 2019", "journal-ref": null, "doi": "10.32470/CCN.2019.1300-0", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Centered Kernel Alignment (CKA) was recently proposed as a similarity metric\nfor comparing activation patterns in deep networks. Here we experiment with the\nmodified RV-coefficient (RV2), which has very similar properties as CKA while\nbeing less sensitive to dataset size. We compare the representations of\nnetworks that received varying amounts of training on different layers: a\nstandard trained network (all parameters updated at every step), a freeze\ntrained network (layers gradually frozen during training), random networks\n(only some layers trained), and a completely untrained network. We found that\nRV2 was able to recover expected similarity patterns and provide interpretable\nsimilarity matrices that suggested hypotheses about how representations are\naffected by different training recipes. We propose that the superior\nperformance achieved by freeze training can be attributed to representational\ndifferences in the penultimate layer. Our comparisons of random networks\nsuggest that the inputs and targets serve as anchors on the representations in\nthe lowest and highest layers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:43:57 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Thompson", "Jessica A. F.", ""], ["Bengio", "Yoshua", ""], ["Schoenwiesner", "Marc", ""]]}, {"id": "1912.02262", "submitter": "Nima Safaei", "authors": "Nima Safaei and Ivan A. Sergienko", "title": "Correspondent Banking Networks: Theory and Experiment", "comments": "32 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ the mathematical programming approach in conjunction with the graph\ntheory to study the structure of correspondent banking networks. Optimizing the\nnetwork requires decisions to be made to onboard, terminate or restrict the\nbank relationships to optimize the size and overall risk of the network. This\nstudy provides theoretical foundation to detect the components, the removal of\nwhich does not affect some key properties of the network such as connectivity\nand diameter. We find that the correspondent banking networks have a feature we\ncall k-accessibility, which helps to drastically reduce the computational\nburden required for finding the above mentioned components. We prove a number\nof fundamental theorems related to k-accessible directed graphs, which should\nbe also applicable beyond the particular problem of financial networks. The\ntheoretical findings are verified through the data from a large international\nbank.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:46:28 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 14:50:44 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Safaei", "Nima", ""], ["Sergienko", "Ivan A.", ""]]}, {"id": "1912.02263", "submitter": "Steffen Rendle", "authors": "Steffen Rendle", "title": "Evaluation Metrics for Item Recommendation under Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of item recommendation requires ranking a large catalogue of items\ngiven a context. Item recommendation algorithms are evaluated using ranking\nmetrics that depend on the positions of relevant items. To speed up the\ncomputation of metrics, recent work often uses sampled metrics where only a\nsmaller set of random items and the relevant items are ranked. This paper\ninvestigates sampled metrics in more detail and shows that sampled metrics are\ninconsistent with their exact version. Sampled metrics do not persist relative\nstatements, e.g., 'algorithm A is better than B', not even in expectation.\nMoreover the smaller the sampling size, the less difference between metrics,\nand for very small sampling size, all metrics collapse to the AUC metric.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 21:48:42 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Rendle", "Steffen", ""]]}, {"id": "1912.02270", "submitter": "Donghwan Lee", "authors": "Donghwan Lee and Niao He", "title": "A Unified Switching System Perspective and O.D.E. Analysis of Q-Learning\n  Algorithms", "comments": "This paper has been accepted in NeurIPS2020", "journal-ref": "NeurIPS2020", "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a unified framework for analyzing a large family\nof Q-learning algorithms, based on switching system perspectives and ODE-based\nstochastic approximation. We show that the nonlinear ODE models associated with\nthese Q-learning algorithms can be formulated as switched linear systems, and\nanalyze their asymptotic stability by leveraging existing switching system\ntheories. Our approach provides the first O.D.E. analysis of the asymptotic\nconvergence of various Q-learning algorithms, including asynchronous Q-learning\nand averaging Q-learning. We also extend the approach to analyze Q-learning\nwith linear function approximation and derive a new sufficient condition for\nits convergence.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:01:44 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 08:40:55 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 05:28:51 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""]]}, {"id": "1912.02276", "submitter": "Kiwan Maeng", "authors": "Kiwan Maeng, Iskender Kushan, Brandon Lucia, Ashish Kapoor", "title": "Enhancing Stratospheric Weather Analyses and Forecasts by Deploying\n  Sensors from a Weather Balloon", "comments": "NeurIPS 2019 Workshop: Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to analyze and forecast stratospheric weather conditions is\nfundamental to addressing climate change. However, our capacity to collect data\nin the stratosphere is limited by sparsely deployed weather balloons. We\npropose a framework to collect stratospheric data by releasing a contrail of\ntiny sensor devices as a weather balloon ascends. The key machine learning\nchallenges are determining when and how to deploy a finite collection of\nsensors to produce a useful data set. We decide when to release sensors by\nmodeling the deviation of a forecast from actual stratospheric conditions as a\nGaussian process. We then implement a novel hardware system that is capable of\noptimally releasing sensors from a rising weather balloon. We show that this\ndata engineering framework is effective through real weather balloon flights,\nas well as simulations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:07:05 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Maeng", "Kiwan", ""], ["Kushan", "Iskender", ""], ["Lucia", "Brandon", ""], ["Kapoor", "Ashish", ""]]}, {"id": "1912.02279", "submitter": "Beidi Chen", "authors": "Beidi Chen, Weiyang Liu, Zhiding Yu, Jan Kautz, Anshumali Shrivastava,\n  Animesh Garg, Anima Anandkumar", "title": "Angular Visual Hardness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent convolutional neural networks (CNNs) have led to impressive\nperformance but often suffer from poor calibration. They tend to be\noverconfident, with the model confidence not always reflecting the underlying\ntrue ambiguity and hardness. In this paper, we propose angular visual hardness\n(AVH), a score given by the normalized angular distance between the sample\nfeature embedding and the target classifier to measure sample hardness. We\nvalidate this score with an in-depth and extensive scientific study, and\nobserve that CNN models with the highest accuracy also have the best AVH\nscores. This agrees with an earlier finding that state-of-art models improve on\nthe classification of harder examples. We observe that the training dynamics of\nAVH is vastly different compared to the training loss. Specifically, AVH\nquickly reaches a plateau for all samples even though the training loss keeps\nimproving. This suggests the need for designing better loss functions that can\ntarget harder examples more effectively. We also find that AVH has a\nstatistically significant correlation with human visual hardness. Finally, we\ndemonstrate the benefit of AVH to a variety of applications such as\nself-training for domain adaptation and domain generalization.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:12:42 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 00:23:12 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 00:23:39 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 20:58:01 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chen", "Beidi", ""], ["Liu", "Weiyang", ""], ["Yu", "Zhiding", ""], ["Kautz", "Jan", ""], ["Shrivastava", "Anshumali", ""], ["Garg", "Animesh", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1912.02280", "submitter": "Riccardo Volpi", "authors": "Riccardo Volpi, Luigi Malag\\`o", "title": "Natural Alpha Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an embedding for a large collection of items is a popular approach\nto overcome the computational limitations associated to one-hot encodings. The\naim of item embedding is to learn a low dimensional space for the\nrepresentations, able to capture with its geometry relevant features or\nrelationships for the data at hand. This can be achieved for example by\nexploiting adjacencies among items in large sets of unlabelled data. In this\npaper we interpret in an Information Geometric framework the item embeddings\nobtained from conditional models. By exploiting the $\\alpha$-geometry of the\nexponential family, first introduced by Amari, we introduce a family of natural\n$\\alpha$-embeddings represented by vectors in the tangent space of the\nprobability simplex, which includes as a special case standard approaches\navailable in the literature. A typical example is given by word embeddings,\ncommonly used in natural language processing, such as Word2Vec and GloVe. In\nour analysis, we show how the $\\alpha$-deformation parameter can impact on\nstandard evaluation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:13:16 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 12:55:44 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Volpi", "Riccardo", ""], ["Malag\u00f2", "Luigi", ""]]}, {"id": "1912.02283", "submitter": "Benjamin Coleman", "authors": "Benjamin Coleman, Anshumali Shrivastava", "title": "Sub-linear RACE Sketches for Approximate Kernel Density Estimation on\n  Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel density estimation is a simple and effective method that lies at the\nheart of many important machine learning applications. Unfortunately, kernel\nmethods scale poorly for large, high dimensional datasets. Approximate kernel\ndensity estimation has a prohibitively high memory and computation cost,\nespecially in the streaming setting. Recent sampling algorithms for high\ndimensional densities can reduce the computation cost but cannot operate\nonline, while streaming algorithms cannot handle high dimensional datasets due\nto the curse of dimensionality. We propose RACE, an efficient sketching\nalgorithm for kernel density estimation on high-dimensional streaming data.\nRACE compresses a set of N high dimensional vectors into a small array of\ninteger counters. This array is sufficient to estimate the kernel density for a\nlarge class of kernels. Our sketch is practical to implement and comes with\nstrong theoretical guarantees. We evaluate our method on real-world\nhigh-dimensional datasets and show that our sketch achieves 10x better\ncompression compared to competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:17:36 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Coleman", "Benjamin", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1912.02290", "submitter": "Samuel Kessler", "authors": "Samuel Kessler, Vu Nguyen, Stefan Zohren, Stephen Roberts", "title": "Hierarchical Indian Buffet Neural Networks for Bayesian Continual\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We place an Indian Buffet process (IBP) prior over the structure of a\nBayesian Neural Network (BNN), thus allowing the complexity of the BNN to\nincrease and decrease automatically. We further extend this model such that the\nprior on the structure of each hidden layer is shared globally across all\nlayers, using a Hierarchical-IBP (H-IBP). We apply this model to the problem of\nresource allocation in Continual Learning (CL) where new tasks occur and the\nnetwork requires extra resources. Our model uses online variational inference\nwith reparameterisation of the Bernoulli and Beta distributions, which\nconstitute the IBP and H-IBP priors. As we automatically learn the number of\nweights in each layer of the BNN, overfitting and underfitting problems are\nlargely overcome. We show empirically that our approach offers a competitive\nedge over existing methods in CL.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:43:31 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 15:48:35 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 19:54:01 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 16:50:00 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Kessler", "Samuel", ""], ["Nguyen", "Vu", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "1912.02292", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak,\n  Ilya Sutskever", "title": "Deep Double Descent: Where Bigger Models and More Data Hurt", "comments": "G.K. and Y.B. contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a variety of modern deep learning tasks exhibit a\n\"double-descent\" phenomenon where, as we increase model size, performance first\ngets worse and then gets better. Moreover, we show that double descent occurs\nnot just as a function of model size, but also as a function of the number of\ntraining epochs. We unify the above phenomena by defining a new complexity\nmeasure we call the effective model complexity and conjecture a generalized\ndouble descent with respect to this measure. Furthermore, our notion of model\ncomplexity allows us to identify certain regimes where increasing (even\nquadrupling) the number of train samples actually hurts test performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:47:31 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Kaplun", "Gal", ""], ["Bansal", "Yamini", ""], ["Yang", "Tristan", ""], ["Barak", "Boaz", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1912.02302", "submitter": "Joseph Daws Jr", "authors": "Joseph Daws and Clayton Webster", "title": "Analysis of Deep Neural Networks with Quasi-optimal polynomial\n  approximation rates", "comments": "13 pages submitted to MSML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the existence of a deep neural network capable of approximating a\nwide class of high-dimensional approximations. The construction of the proposed\nneural network is based on a quasi-optimal polynomial approximation. We show\nthat this network achieves an error rate that is sub-exponential in the number\nof polynomial functions, $M$, used in the polynomial approximation. The\ncomplexity of the network which achieves this sub-exponential rate is shown to\nbe algebraic in $M$.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 23:19:58 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Daws", "Joseph", ""], ["Webster", "Clayton", ""]]}, {"id": "1912.02305", "submitter": "Paul Hill Mr", "authors": "P.R. Hill, A. Kumar, M. Temimi and D.R. Bull", "title": "HABNet: Machine Learning, Remote Sensing Based Detection and Prediction\n  of Harmful Algal Blooms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the application of machine learning techniques to\ndevelop a state-of-the-art detection and prediction system for spatiotemporal\nevents found within remote sensing data; specifically, Harmful Algal Bloom\nevents (HABs). We propose an HAB detection system based on: a ground truth\nhistorical record of HAB events, a novel spatiotemporal datacube representation\nof each event (from MODIS and GEBCO bathymetry data) and a variety of machine\nlearning architectures utilising state-of-the-art spatial and temporal analysis\nmethods based on Convolutional Neural Networks (CNNs), Long Short-Term Memory\n(LSTM) components together with Random Forest and Support Vector Machine (SVM)\nclassification methods.\n  This work has focused specifically on the case study of the detection of\nKarenia Brevis Algae (K. brevis) HAB events within the coastal waters of\nFlorida (over 2850 events from 2003 to 2018; an order of magnitude larger than\nany previous machine learning detection study into HAB events).\n  The development of multimodal spatiotemporal datacube data structures and\nassociated novel machine learning methods give a unique architecture for the\nautomatic detection of environmental events. Specifically, when applied to the\ndetection of HAB events it gives a maximum detection accuracy of 91% and a\nKappa coefficient of 0.81 for the Florida data considered.\n  A HAB forecast system was also developed where a temporal subset of each\ndatacube was used to predict the presence of a HAB in the future. This system\nwas not significantly less accurate than the detection system being able to\npredict with 86% accuracy up to 8 days in the future.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 23:30:52 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 12:21:59 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Hill", "P. R.", ""], ["Kumar", "A.", ""], ["Temimi", "M.", ""], ["Bull", "D. R.", ""]]}, {"id": "1912.02314", "submitter": "Adam Yedidia", "authors": "Miika Aittala, Prafull Sharma, Lukas Murmann, Adam B. Yedidia, Gregory\n  W. Wornell, William T. Freeman, Fredo Durand", "title": "Computational Mirrors: Blind Inverse Light Transport by Deep Matrix\n  Factorization", "comments": "14 pages, 5 figures, Advances in Neural Information Processing\n  Systems 2019", "journal-ref": "Aittala, Miika, et al. \"Computational Mirrors: Blind Inverse Light\n  Transport by Deep Matrix Factorization.\" Advances in Neural Information\n  Processing Systems. 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recover a video of the motion taking place in a hidden scene by observing\nchanges in indirect illumination in a nearby uncalibrated visible region. We\nsolve this problem by factoring the observed video into a matrix product\nbetween the unknown hidden scene video and an unknown light transport matrix.\nThis task is extremely ill-posed, as any non-negative factorization will\nsatisfy the data. Inspired by recent work on the Deep Image Prior, we\nparameterize the factor matrices using randomly initialized convolutional\nneural networks trained in a one-off manner, and show that this results in\ndecompositions that reflect the true motion in the hidden scene.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 00:06:20 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Aittala", "Miika", ""], ["Sharma", "Prafull", ""], ["Murmann", "Lukas", ""], ["Yedidia", "Adam B.", ""], ["Wornell", "Gregory W.", ""], ["Freeman", "William T.", ""], ["Durand", "Fredo", ""]]}, {"id": "1912.02315", "submitter": "Jiasen Lu", "authors": "Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, Stefan Lee", "title": "12-in-1: Multi-Task Vision and Language Representation Learning", "comments": "Jiasen Lu and Vedanuj Goswami contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of vision-and-language research focuses on a small but diverse set of\nindependent tasks and supporting datasets often studied in isolation; however,\nthe visually-grounded language understanding skills required for success at\nthese tasks overlap significantly. In this work, we investigate these\nrelationships between vision-and-language tasks by developing a large-scale,\nmulti-task training regime. Our approach culminates in a single model on 12\ndatasets from four broad categories of task including visual question\nanswering, caption-based image retrieval, grounding referring expressions, and\nmulti-modal verification. Compared to independently trained single-task models,\nthis represents a reduction from approximately 3 billion parameters to 270\nmillion while simultaneously improving performance by 2.05 points on average\nacross tasks. We use our multi-task framework to perform in-depth analysis of\nthe effect of joint training diverse tasks. Further, we show that finetuning\ntask-specific models from our single multi-task model can lead to further\nimprovements, achieving performance at or above the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 00:07:35 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 21:39:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lu", "Jiasen", ""], ["Goswami", "Vedanuj", ""], ["Rohrbach", "Marcus", ""], ["Parikh", "Devi", ""], ["Lee", "Stefan", ""]]}, {"id": "1912.02316", "submitter": "Malhar Jere", "authors": "Malhar Jere, Loris Rossi, Briland Hitaj, Gabriela Ciocarlie, Giacomo\n  Boracchi, Farinaz Koushanfar", "title": "Scratch that! An Evolution-based Adversarial Attack against Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study black-box adversarial attacks for image classifiers in a constrained\nthreat model, where adversaries can only modify a small fraction of pixels in\nthe form of scratches on an image. We show that it is possible for adversaries\nto generate localized \\textit{adversarial scratches} that cover less than $5\\%$\nof the pixels in an image and achieve targeted success rates of $98.77\\%$ and\n$97.20\\%$ on ImageNet and CIFAR-10 trained ResNet-50 models, respectively. We\ndemonstrate that our scratches are effective under diverse shapes, such as\nstraight lines or parabolic B\\a'ezier curves, with single or multiple colors.\nIn an extreme condition, in which our scratches are a single color, we obtain a\ntargeted attack success rate of $66\\%$ on CIFAR-10 with an order of magnitude\nfewer queries than comparable attacks. We successfully launch our attack\nagainst Microsoft's Cognitive Services Image Captioning API and propose various\nmitigation strategies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 00:11:34 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 01:46:06 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 16:11:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Jere", "Malhar", ""], ["Rossi", "Loris", ""], ["Hitaj", "Briland", ""], ["Ciocarlie", "Gabriela", ""], ["Boracchi", "Giacomo", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1912.02322", "submitter": "Shijian Li", "authors": "Matthew LeMay and Shijian Li and Tian Guo", "title": "Perseus: Characterizing Performance and Cost of Multi-Tenant Serving for\n  CNN Models", "comments": "8 pages, 5 figures, and 6 tables. In proceedings of International\n  Conference on Cloud Engineering (IC2E) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are increasingly used for end-user applications,\nsupporting both novel features such as facial recognition, and traditional\nfeatures, e.g. web search. To accommodate high inference throughput, it is\ncommon to host a single pre-trained Convolutional Neural Network (CNN) in\ndedicated cloud-based servers with hardware accelerators such as Graphics\nProcessing Units (GPUs). However, GPUs can be orders of magnitude more\nexpensive than traditional Central Processing Unit (CPU) servers. These\nresources could also be under-utilized facing dynamic workloads, which may\nresult in inflated serving costs. One potential way to alleviate this problem\nis by allowing hosted models to share the underlying resources, which we refer\nto as multi-tenant inference serving. One of the key challenges is maximizing\nthe resource efficiency for multi-tenant serving given hardware with diverse\ncharacteristics, models with unique response time Service Level Agreement\n(SLA), and dynamic inference workloads. In this paper, we present Perseus, a\nmeasurement framework that provides the basis for understanding the performance\nand cost trade-offs of multi-tenant model serving. We implemented Perseus in\nPython atop a popular cloud inference server called Nvidia TensorRT Inference\nServer. Leveraging Perseus, we evaluated the inference throughput and cost for\nserving various models and demonstrated that multi-tenant model serving led to\nup to 12% cost reduction.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 00:35:43 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 22:02:51 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["LeMay", "Matthew", ""], ["Li", "Shijian", ""], ["Guo", "Tian", ""]]}, {"id": "1912.02332", "submitter": "Zelin Ye", "authors": "Zelin Ye, Yan Hao, Liang Xu, Rui Zhu, Cewu Lu", "title": "3D Objectness Estimation via Bottom-up Regret Grouping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D objectness estimation, namely discovering semantic objects from 3D scene,\nis a challenging and significant task in 3D understanding. In this paper, we\npropose a 3D objectness method working in a bottom-up manner. Beginning with\nover-segmented 3D segments, we iteratively group them into object proposals by\nlearning an ingenious grouping predictor to determine whether two 3D segments\ncan be grouped or not. To enhance robustness, a novel regret mechanism is\npresented to withdraw incorrect grouping operations. Hence the irreparable\nconsequences brought by mistaken grouping in prior bottom-up works can be\ngreatly reduced. Our experiments show that our method outperforms\nstate-of-the-art 3D objectness methods with a small number of proposals in two\ndifficult datasets, GMU-kitchen and CTD. Further ablation study also\ndemonstrates the effectiveness of our grouping predictor and regret mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 01:20:56 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ye", "Zelin", ""], ["Hao", "Yan", ""], ["Xu", "Liang", ""], ["Zhu", "Rui", ""], ["Lu", "Cewu", ""]]}, {"id": "1912.02338", "submitter": "Liliang Ren", "authors": "Liliang Ren, Gen Sun and Jiaman Wu", "title": "RoNGBa: A Robustly Optimized Natural Gradient Boosting Training Approach\n  with Leaf Number Clipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural gradient has been recently introduced to the field of boosting to\nenable the generic probabilistic predication capability. Natural gradient\nboosting shows promising performance improvements on small datasets due to\nbetter training dynamics, but it suffers from slow training speed overhead\nespecially for large datasets. We present a replication study of NGBoost(Duan\net al., 2019) training that carefully examines the impacts of key\nhyper-parameters under the circumstance of best-first decision tree learning.\nWe find that with the regularization of leaf number clipping, the performance\nof NGBoost can be largely improved via a better choice of hyperparameters.\nExperiments show that our approach significantly beats the state-of-the-art\nperformance on various kinds of datasets from the UCI Machine Learning\nRepository while still has up to 4.85x speed up compared with the original\napproach of NGBoost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 01:38:34 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ren", "Liliang", ""], ["Sun", "Gen", ""], ["Wu", "Jiaman", ""]]}, {"id": "1912.02351", "submitter": "Joshua Chang", "authors": "Joshua C. Chang and Shashaank Vattikuti and Carson C. Chow", "title": "Probabilistically-autoencoded horseshoe-disentangled multidomain\n  item-response theory models", "comments": "Presented as poster at the NeurIPS 2019 Bayesian Deep Learning\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Item response theory (IRT) is a non-linear generative probabilistic paradigm\nfor using exams to identify, quantify, and compare latent traits of\nindividuals, relative to their peers, within a population of interest. In\npre-existing multidimensional IRT methods, one requires a factorization of the\ntest items. For this task, linear exploratory factor analysis is used, making\nIRT a posthoc model. We propose skipping the initial factor analysis by using a\nsparsity-promoting horseshoe prior to perform factorization directly within the\nIRT model so that all training occurs in a single self-consistent step. Being a\nhierarchical Bayesian model, we adapt the WAIC to the problem of dimensionality\nselection. IRT models are analogous to probabilistic autoencoders. By binding\nthe generative IRT model to a Bayesian neural network (forming a probabilistic\nautoencoder), one obtains a scoring algorithm consistent with the interpretable\nBayesian model. In some IRT applications the black-box nature of a neural\nnetwork scoring machine is desirable. In this manuscript, we demonstrate\nwithin-IRT factorization and comment on scoring approaches.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 02:28:47 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Chang", "Joshua C.", ""], ["Vattikuti", "Shashaank", ""], ["Chow", "Carson C.", ""]]}, {"id": "1912.02365", "submitter": "Yair Carmon", "authors": "Yossi Arjevani, Yair Carmon, John C. Duchi, Dylan J. Foster, Nathan\n  Srebro and Blake Woodworth", "title": "Lower Bounds for Non-Convex Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We lower bound the complexity of finding $\\epsilon$-stationary points (with\ngradient norm at most $\\epsilon$) using stochastic first-order methods. In a\nwell-studied model where algorithms access smooth, potentially non-convex\nfunctions through queries to an unbiased stochastic gradient oracle with\nbounded variance, we prove that (in the worst case) any algorithm requires at\nleast $\\epsilon^{-4}$ queries to find an $\\epsilon$ stationary point. The lower\nbound is tight, and establishes that stochastic gradient descent is minimax\noptimal in this model. In a more restrictive model where the noisy gradient\nestimates satisfy a mean-squared smoothness property, we prove a lower bound of\n$\\epsilon^{-3}$ queries, establishing the optimality of recently proposed\nvariance reduction techniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 03:37:44 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Arjevani", "Yossi", ""], ["Carmon", "Yair", ""], ["Duchi", "John C.", ""], ["Foster", "Dylan J.", ""], ["Srebro", "Nathan", ""], ["Woodworth", "Blake", ""]]}, {"id": "1912.02368", "submitter": "Abdul Rahman Kreidieh", "authors": "Abdul Rahman Kreidieh, Glen Berseth, Brandon Trabucco, Samyak\n  Parajuli, Sergey Levine, Alexandre M. Bayen", "title": "Inter-Level Cooperation in Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical models for deep reinforcement learning (RL) have emerged as\npowerful methods for generating meaningful control strategies in difficult long\ntime horizon tasks. Training of said hierarchical models, however, continue to\nsuffer from instabilities that limit their applicability. In this paper, we\naddress instabilities that arise from the concurrent optimization of\ngoal-assignment and goal-achievement policies. Drawing connections between this\nconcurrent optimization scheme and communication and cooperation in multi-agent\nRL, we redefine the standard optimization procedure to explicitly promote\ncooperation between these disparate tasks. Our method is demonstrated to\nachieve superior results to existing techniques in a set of difficult long time\nhorizon tasks, and serves to expand the scope of solvable tasks by hierarchical\nreinforcement learning. Videos of the results are available at:\nhttps://sites.google.com/berkeley.edu/cooperative-hrl.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 03:56:44 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 08:46:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kreidieh", "Abdul Rahman", ""], ["Berseth", "Glen", ""], ["Trabucco", "Brandon", ""], ["Parajuli", "Samyak", ""], ["Levine", "Sergey", ""], ["Bayen", "Alexandre M.", ""]]}, {"id": "1912.02373", "submitter": "Hossein Kamalzadeh", "authors": "Hossein Kamalzadeh, Saeid Nassim Sobhan, Azam Boskabadi, Mohsen\n  Hatami, Amin Gharehyakheh", "title": "Modeling and Prediction of Iran's Steel Consumption Based on Economic\n  Activity Using Support Vector Machines", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The steel industry has great impacts on the economy and the environment of\nboth developed and underdeveloped countries. The importance of this industry\nand these impacts have led many researchers to investigate the relationship\nbetween a country's steel consumption and its economic activity resulting in\nthe so-called intensity of use model. This paper investigates the validity of\nthe intensity of use model for the case of Iran's steel consumption and extends\nthis hypothesis by using the indexes of economic activity to model the steel\nconsumption. We use the proposed model to train support vector machines and\npredict the future values for Iran's steel consumption. The paper provides\ndetailed correlation tests for the factors used in the model to check for their\nrelationships with the steel consumption. The results indicate that Iran's\nsteel consumption is strongly correlated with its economic activity following\nthe same pattern as the economy has been in the last four decades.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 04:13:35 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Kamalzadeh", "Hossein", ""], ["Sobhan", "Saeid Nassim", ""], ["Boskabadi", "Azam", ""], ["Hatami", "Mohsen", ""], ["Gharehyakheh", "Amin", ""]]}, {"id": "1912.02379", "submitter": "Vishvak Murahari", "authors": "Vishvak Murahari, Dhruv Batra, Devi Parikh, Abhishek Das", "title": "Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art\n  Baseline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work in visual dialog has focused on training deep neural models on\nVisDial in isolation. Instead, we present an approach to leverage pretraining\non related vision-language datasets before transferring to visual dialog. We\nadapt the recently proposed ViLBERT (Lu et al., 2019) model for multi-turn\nvisually-grounded conversations. Our model is pretrained on the Conceptual\nCaptions and Visual Question Answering datasets, and finetuned on VisDial. Our\nbest single model outperforms prior published work (including model ensembles)\nby more than 1% absolute on NDCG and MRR. Next, we find that additional\nfinetuning using \"dense\" annotations in VisDial leads to even higher NDCG --\nmore than 10% over our base model -- but hurts MRR -- more than 17% below our\nbase model! This highlights a trade-off between the two primary metrics -- NDCG\nand MRR -- which we find is due to dense annotations not correlating well with\nthe original ground-truth answers to questions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 04:51:11 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 03:12:26 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Murahari", "Vishvak", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Das", "Abhishek", ""]]}, {"id": "1912.02386", "submitter": "Justin Cosentino", "authors": "Justin Cosentino, Federico Zaiter, Dan Pei, Jun Zhu", "title": "The Search for Sparse, Robust Neural Networks", "comments": "The Safety and Robustness in Decision Making Workshop at the 33rd\n  Conference on Neural InformationProcessing Systems (NeurIPS 2019), Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on deep neural network pruning has shown there exist sparse\nsubnetworks that achieve equal or improved accuracy, training time, and loss\nusing fewer network parameters when compared to their dense counterparts.\nOrthogonal to pruning literature, deep neural networks are known to be\nsusceptible to adversarial examples, which may pose risks in security- or\nsafety-critical applications. Intuition suggests that there is an inherent\ntrade-off between sparsity and robustness such that these characteristics could\nnot co-exist. We perform an extensive empirical evaluation and analysis testing\nthe Lottery Ticket Hypothesis with adversarial training and show this approach\nenables us to find sparse, robust neural networks. Code for reproducing\nexperiments is available here:\nhttps://github.com/justincosentino/robust-sparse-networks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:06:35 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Cosentino", "Justin", ""], ["Zaiter", "Federico", ""], ["Pei", "Dan", ""], ["Zhu", "Jun", ""]]}, {"id": "1912.02387", "submitter": "Preslav Nakov", "authors": "Sara Rosenthal, Saif M Mohammad, Preslav Nakov, Alan Ritter, Svetlana\n  Kiritchenko, Veselin Stoyanov", "title": "SemEval-2015 Task 10: Sentiment Analysis in Twitter", "comments": "Sentiment analysis, sentiment towards a topic, quantification,\n  microblog sentiment analysis; Twitter opinion mining", "journal-ref": "SemEval-2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the 2015 iteration of the SemEval shared task on\nSentiment Analysis in Twitter. This was the most popular sentiment analysis\nshared task to date with more than 40 teams participating in each of the last\nthree years. This year's shared task competition consisted of five sentiment\nprediction subtasks. Two were reruns from previous years: (A) sentiment\nexpressed by a phrase in the context of a tweet, and (B) overall sentiment of a\ntweet. We further included three new subtasks asking to predict (C) the\nsentiment towards a topic in a single tweet, (D) the overall sentiment towards\na topic in a set of tweets, and (E) the degree of prior polarity of a phrase.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:08:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Rosenthal", "Sara", ""], ["Mohammad", "Saif M", ""], ["Nakov", "Preslav", ""], ["Ritter", "Alan", ""], ["Kiritchenko", "Svetlana", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1912.02390", "submitter": "Vasant Honavar", "authors": "Sanghack Lee and Vasant Honavar", "title": "Towards Robust Relational Causal Discovery", "comments": "14 pages", "journal-ref": "Proceedings of the 35th Conference on Uncertainty in Artificial\n  Intelligence, UAI 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal relationships from relational\ndata. Existing approaches rely on queries to a relational conditional\nindependence (RCI) oracle to establish and orient causal relations in such a\nsetting. In practice, queries to a RCI oracle have to be replaced by reliable\ntests for RCI against available data. Relational data present several unique\nchallenges in testing for RCI. We study the conditions under which traditional\niid-based conditional independence (CI) tests yield reliable answers to RCI\nqueries against relational data. We show how to conduct CI tests against\nrelational data to robustly recover the underlying relational causal structure.\nResults of our experiments demonstrate the effectiveness of our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:13:22 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lee", "Sanghack", ""], ["Honavar", "Vasant", ""]]}, {"id": "1912.02398", "submitter": "Jie An", "authors": "Jie An, Haoyi Xiong, Jun Huan and Jiebo Luo", "title": "Ultrafast Photorealistic Style Transfer via Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key challenge in photorealistic style transfer is that an algorithm\nshould faithfully transfer the style of a reference photo to a content photo\nwhile the generated image should look like one captured by a camera. Although\nseveral photorealistic style transfer algorithms have been proposed, they need\nto rely on post- and/or pre-processing to make the generated images look\nphotorealistic. If we disable the additional processing, these algorithms would\nfail to produce plausible photorealistic stylization in terms of detail\npreservation and photorealism. In this work, we propose an effective solution\nto these issues. Our method consists of a construction step (C-step) to build a\nphotorealistic stylization network and a pruning step (P-step) for\nacceleration. In the C-step, we propose a dense auto-encoder named PhotoNet\nbased on a carefully designed pre-analysis. PhotoNet integrates a feature\naggregation module (BFA) and instance normalized skip links (INSL). To generate\nfaithful stylization, we introduce multiple style transfer modules in the\ndecoder and INSLs. PhotoNet significantly outperforms existing algorithms in\nterms of both efficiency and effectiveness. In the P-step, we adopt a neural\narchitecture search method to accelerate PhotoNet. We propose an automatic\nnetwork pruning framework in the manner of teacher-student learning for\nphotorealistic stylization. The network architecture named PhotoNAS resulted\nfrom the search achieves significant acceleration over PhotoNet while keeping\nthe stylization effects almost intact. We conduct extensive experiments on both\nimage and video transfer. The results show that our method can produce\nfavorable results while achieving 20-30 times acceleration in comparison with\nthe existing state-of-the-art approaches. It is worth noting that the proposed\nalgorithm accomplishes better performance without any pre- or post-processing.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:51:54 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 12:56:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["An", "Jie", ""], ["Xiong", "Haoyi", ""], ["Huan", "Jun", ""], ["Luo", "Jiebo", ""]]}, {"id": "1912.02399", "submitter": "Yujia Li", "authors": "Tanbin Rahman, Yujia Li, Tianzhou Ma, Lu Tang, George Tseng", "title": "A sparse negative binomial mixture model for clustering RNA-seq count\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering with variable selection is a challenging yet critical task for\nmodern small-n-large-p data. Existing methods based on sparse Gaussian mixture\nmodels or sparse K-means provide solutions to continuous data. With the\nprevalence of RNA-seq technology and lack of count data modeling for\nclustering, the current practice is to normalize count expression data into\ncontinuous measures and apply existing models with Gaussian assumption. In this\npaper, we develop a negative binomial mixture model with lasso or fused lasso\ngene regularization to cluster samples (small n) with high-dimensional gene\nfeatures (large p). EM algorithm and Bayesian information criterion are used\nfor inference and determining tuning parameters. The method is compared with\nexisting methods using extensive simulations and two real transcriptomic\napplications in rat brain and breast cancer studies. The result shows superior\nperformance of the proposed count data model in clustering accuracy, feature\nselection and biological interpretation in pathways.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:55:36 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 21:49:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Rahman", "Tanbin", ""], ["Li", "Yujia", ""], ["Ma", "Tianzhou", ""], ["Tang", "Lu", ""], ["Tseng", "George", ""]]}, {"id": "1912.02400", "submitter": "Matthew Fontaine", "authors": "Matthew C. Fontaine, Julian Togelius, Stefanos Nikolaidis, Amy K.\n  Hoover", "title": "Covariance Matrix Adaptation for the Rapid Illumination of Behavior\n  Space", "comments": "Accepted to GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3390232", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the challenge of finding a diverse collection of quality\nsolutions on complex continuous domains. While quality diver-sity (QD)\nalgorithms like Novelty Search with Local Competition (NSLC) and MAP-Elites are\ndesigned to generate a diverse range of solutions, these algorithms require a\nlarge number of evaluations for exploration of continuous spaces. Meanwhile,\nvariants of the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) are\namong the best-performing derivative-free optimizers in single-objective\ncontinuous domains. This paper proposes a new QD algorithm called Covariance\nMatrix Adaptation MAP-Elites (CMA-ME). Our new algorithm combines the\nself-adaptation techniques of CMA-ES with archiving and mapping techniques for\nmaintaining diversity in QD. Results from experiments based on standard\ncontinuous optimization benchmarks show that CMA-ME finds better-quality\nsolutions than MAP-Elites; similarly, results on the strategic game Hearthstone\nshow that CMA-ME finds both a higher overall quality and broader diversity of\nstrategies than both CMA-ES and MAP-Elites. Overall, CMA-ME more than doubles\nthe performance of MAP-Elites using standard QD performance metrics. These\nresults suggest that QD algorithms augmented by operators from state-of-the-art\noptimization algorithms can yield high-performing methods for simultaneously\nexploring and optimizing continuous search spaces, with significant\napplications to design, testing, and reinforcement learning among other\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 06:06:42 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 09:47:00 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Fontaine", "Matthew C.", ""], ["Togelius", "Julian", ""], ["Nikolaidis", "Stefanos", ""], ["Hoover", "Amy K.", ""]]}, {"id": "1912.02401", "submitter": "Megha Nawhal", "authors": "Megha Nawhal, Mengyao Zhai, Andreas Lehrmann, Leonid Sigal, Greg Mori", "title": "Generating Videos of Zero-Shot Compositions of Actions and Objects", "comments": "Accepted at ECCV'20; Project Page:\n  https://www.sfu.ca/~mnawhal/projects/zs_hoi_generation.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity videos involve rich, varied interactions between people and\nobjects. In this paper we develop methods for generating such videos -- making\nprogress toward addressing the important, open problem of video generation in\ncomplex scenes. In particular, we introduce the task of generating human-object\ninteraction videos in a zero-shot compositional setting, i.e., generating\nvideos for action-object compositions that are unseen during training, having\nseen the target action and target object separately. This setting is\nparticularly important for generalization in human activity video generation,\nobviating the need to observe every possible action-object combination in\ntraining and thus avoiding the combinatorial explosion involved in modeling\ncomplex scenes. To generate human-object interaction videos, we propose a novel\nadversarial framework HOI-GAN which includes multiple discriminators focusing\non different aspects of a video. To demonstrate the effectiveness of our\nproposed framework, we perform extensive quantitative and qualitative\nevaluation on two challenging datasets: EPIC-Kitchens and\n20BN-Something-Something v2.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 06:09:13 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 18:21:27 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 06:40:50 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 06:01:52 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Nawhal", "Megha", ""], ["Zhai", "Mengyao", ""], ["Lehrmann", "Andreas", ""], ["Sigal", "Leonid", ""], ["Mori", "Greg", ""]]}, {"id": "1912.02405", "submitter": "Hossein Kamalzadeh", "authors": "Hossein Kamalzadeh, Abbas Ahmadi, Saeed Mansour", "title": "Clustering Time-Series by a Novel Slope-Based Similarity Measure\n  Considering Particle Swarm Optimization", "comments": "27 pages, 8 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been an increase in the studies on time-series data mining\nspecifically time-series clustering due to the vast existence of time-series in\nvarious domains. The large volume of data in the form of time-series makes it\nnecessary to employ various techniques such as clustering to understand the\ndata and to extract information and hidden patterns. In the field of clustering\nspecifically, time-series clustering, the most important aspects are the\nsimilarity measure used and the algorithm employed to conduct the clustering.\nIn this paper, a new similarity measure for time-series clustering is developed\nbased on a combination of a simple representation of time-series, slope of each\nsegment of time-series, Euclidean distance and the so-called dynamic time\nwarping. It is proved in this paper that the proposed distance measure is\nmetric and thus indexing can be applied. For the task of clustering, the\nParticle Swarm Optimization algorithm is employed. The proposed similarity\nmeasure is compared to three existing measures in terms of various criteria\nused for the evaluation of clustering algorithms. The results indicate that the\nproposed similarity measure outperforms the rest in almost every dataset used\nin this paper.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 06:22:04 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Kamalzadeh", "Hossein", ""], ["Ahmadi", "Abbas", ""], ["Mansour", "Saeed", ""]]}, {"id": "1912.02411", "submitter": "Marcos M. Vasconcelos", "authors": "Marcos M. Vasconcelos and Urbashi Mitra", "title": "Data-driven sensor scheduling for remote estimation in wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor scheduling is a well studied problem in signal processing and control\nwith numerous applications. Despite its successful history, most of the related\nliterature assumes the knowledge of the underlying probabilistic model of the\nsensor measurements such as the correlation structure or the entire joint\nprobability density function. Herein, a framework for sensor scheduling for\nremote estimation is introduced in which the system design and the scheduling\ndecisions are based solely on observed data. Unicast and broadcast networks and\ncorresponding receivers are considered. In both cases, the empirical risk\nminimization can be posed as a difference-of-convex optimization problem and\nlocally optimal solutions are obtained efficiently by applying the\nconvex-concave procedure. Our results are independent of the data's probability\ndensity function, correlation structure and the number of sensors.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 07:11:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Vasconcelos", "Marcos M.", ""], ["Mitra", "Urbashi", ""]]}, {"id": "1912.02413", "submitter": "Xiu-Shen Wei", "authors": "Boyan Zhou and Quan Cui and Xiu-Shen Wei and Zhao-Min Chen", "title": "BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed\n  Visual Recognition", "comments": "Accepted by CVPR 2020; Our work won the first place in the\n  iNaturalist 2019 large scale species classification competition, and our code\n  is open-source and available at https://github.com/Megvii-Nanjing/BBN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work focuses on tackling the challenging but natural visual recognition\ntask of long-tailed data distribution (i.e., a few classes occupy most of the\ndata, while most classes have rarely few samples). In the literature, class\nre-balancing strategies (e.g., re-weighting and re-sampling) are the prominent\nand effective methods proposed to alleviate the extreme imbalance for dealing\nwith long-tailed problems. In this paper, we firstly discover that these\nre-balancing methods achieving satisfactory recognition accuracy owe to that\nthey could significantly promote the classifier learning of deep networks.\nHowever, at the same time, they will unexpectedly damage the representative\nability of the learned deep features to some extent. Therefore, we propose a\nunified Bilateral-Branch Network (BBN) to take care of both representation\nlearning and classifier learning simultaneously, where each branch does perform\nits own duty separately. In particular, our BBN model is further equipped with\na novel cumulative learning strategy, which is designed to first learn the\nuniversal patterns and then pay attention to the tail data gradually. Extensive\nexperiments on four benchmark datasets, including the large-scale iNaturalist\nones, justify that the proposed BBN can significantly outperform\nstate-of-the-art methods. Furthermore, validation experiments can demonstrate\nboth our preliminary discovery and effectiveness of tailored designs in BBN for\nlong-tailed problems. Our method won the first place in the iNaturalist 2019\nlarge scale species classification competition, and our code is open-source and\navailable at https://github.com/Megvii-Nanjing/BBN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 07:32:28 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 06:07:03 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 16:48:26 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 09:34:38 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhou", "Boyan", ""], ["Cui", "Quan", ""], ["Wei", "Xiu-Shen", ""], ["Chen", "Zhao-Min", ""]]}, {"id": "1912.02423", "submitter": "Kevin Kuo", "authors": "Kevin Kuo", "title": "Generative Synthesis of Insurance Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the impediments in advancing actuarial research and developing open\nsource assets for insurance analytics is the lack of realistic publicly\navailable datasets. In this work, we develop a workflow for synthesizing\ninsurance datasets leveraging CTGAN, a recently proposed neural network\narchitecture for generating tabular data. Applying the proposed workflow to\npublicly available data in the domains of general insurance pricing and life\ninsurance shock lapse modeling, we evaluate the synthesized datasets from a few\nperspectives: machine learning efficacy, distributions of variables, and\nstability of model parameters. This workflow is implemented via an R interface\nto promote adoption by researchers and data owners.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 07:49:31 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 03:46:00 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Kuo", "Kevin", ""]]}, {"id": "1912.02427", "submitter": "Qing Qu", "authors": "Qing Qu, Yuexiang Zhai, Xiao Li, Yuqian Zhang, Zhihui Zhu", "title": "Analysis of the Optimization Landscapes for Overcomplete Representation\n  Learning", "comments": "68 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonconvex optimization landscapes for learning overcomplete\nrepresentations, including learning (i) sparsely used overcomplete dictionaries\nand (ii) convolutional dictionaries, where these unsupervised learning problems\nfind many applications in high-dimensional data analysis. Despite the empirical\nsuccess of simple nonconvex algorithms, theoretical justifications of why these\nmethods work so well are far from satisfactory. In this work, we show these\nproblems can be formulated as $\\ell^4$-norm optimization problems with\nspherical constraint, and study the geometric properties of their nonconvex\noptimization landscapes. For both problems, we show the nonconvex objectives\nhave benign (global) geometric structures, in the sense that every local\nminimizer is close to one of the target solutions and every saddle point\nexhibits negative curvature. This discovery enables the development of\nguaranteed global optimization methods using simple initializations. For both\nproblems, we show the nonconvex objectives have benign geometric structures --\nevery local minimizer is close to one of the target solutions and every saddle\npoint exhibits negative curvature -- either in the entire space or within a\nsufficiently large region. This discovery ensures local search algorithms (such\nas Riemannian gradient descent) with simple initializations approximately find\nthe target solutions. Finally, numerical experiments justify our theoretical\ndiscoveries.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 08:14:24 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:54:46 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Qu", "Qing", ""], ["Zhai", "Yuexiang", ""], ["Li", "Xiao", ""], ["Zhang", "Yuqian", ""], ["Zhu", "Zhihui", ""]]}, {"id": "1912.02461", "submitter": "Po-Chun Hsu", "authors": "Po-chun Hsu, Chun-hsuan Wang, Andy T. Liu, Hung-yi Lee", "title": "Towards Robust Neural Vocoding for Speech Generation: A Survey", "comments": "Submitted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural vocoders have been widely used in speech synthesis tasks,\nincluding text-to-speech and voice conversion. However, when encountering data\ndistribution mismatch between training and inference, neural vocoders trained\non real data often degrade in voice quality for unseen scenarios. In this\npaper, we train four common neural vocoders, including WaveNet, WaveRNN,\nFFTNet, Parallel WaveGAN alternately on five different datasets. To study the\nrobustness of neural vocoders, we evaluate the models using acoustic features\nfrom seen/unseen speakers, seen/unseen languages, a text-to-speech model, and a\nvoice conversion model. We found out that the speaker variety is much more\nimportant for achieving a universal vocoder than the language. Through our\nexperiments, we show that WaveNet and WaveRNN are more suitable for\ntext-to-speech models, while Parallel WaveGAN is more suitable for voice\nconversion applications. Great amount of subjective MOS results in naturalness\nfor all vocoders are presented for future studies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 09:45:16 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 04:02:33 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 10:19:48 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Hsu", "Po-chun", ""], ["Wang", "Chun-hsuan", ""], ["Liu", "Andy T.", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1912.02493", "submitter": "Victor Picheny", "authors": "Victor Picheny, Sattar Vakili, Artem Artemev", "title": "Ordinal Bayesian Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a powerful tool to solve expensive black-box\nproblems, but fails when the stationary assumption made on the objective\nfunction is strongly violated, which is the case in particular for\nill-conditioned or discontinuous objectives. We tackle this problem by\nproposing a new Bayesian optimisation framework that only considers the\nordering of variables, both in the input and output spaces, to fit a Gaussian\nprocess in a latent space. By doing so, our approach is agnostic to the\noriginal metrics on the original spaces. We propose two algorithms,\nrespectively based on an optimistic strategy and on Thompson sampling. For the\noptimistic strategy we prove an optimal performance under the measure of regret\nin the latent space. We illustrate the capability of our framework on several\nchallenging toy problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:46:06 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Picheny", "Victor", ""], ["Vakili", "Sattar", ""], ["Artemev", "Artem", ""]]}, {"id": "1912.02494", "submitter": "Tomaso Fontanini", "authors": "Tomaso Fontanini, Eleonora Iotti, Luca Donati and Andrea Prati", "title": "MetalGAN: Multi-Domain Label-Less Image Synthesis Using cGANs and\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image synthesis is currently one of the most addressed image processing topic\nin computer vision and deep learning fields of study. Researchers have tackled\nthis problem focusing their efforts on its several challenging problems, e.g.\nimage quality and size, domain and pose changing, architecture of the networks,\nand so on. Above all, producing images belonging to different domains by using\na single architecture is a very relevant goal for image generation. In fact, a\nsingle multi-domain network would allow greater flexibility and robustness in\nthe image synthesis task than other approaches. This paper proposes a novel\narchitecture and a training algorithm, which are able to produce multi-domain\noutputs using a single network. A small portion of a dataset is intentionally\nused, and there are no hard-coded labels (or classes). This is achieved by\ncombining a conditional Generative Adversarial Network (cGAN) for image\ngeneration and a Meta-Learning algorithm for domain switch, and we called our\napproach MetalGAN. The approach has proved to be appropriate for solving the\nmulti-domain problem and it is validated on facial attribute transfer, using\nCelebA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:47:08 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 09:40:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Fontanini", "Tomaso", ""], ["Iotti", "Eleonora", ""], ["Donati", "Luca", ""], ["Prati", "Andrea", ""]]}, {"id": "1912.02499", "submitter": "Caterina Urban", "authors": "Caterina Urban, Maria Christakis, Valentin W\\\"ustholz, Fuyuan Zhang", "title": "Perfectly Parallel Fairness Certification of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CY cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is growing concern that machine-learning models, which\ncurrently assist or even automate decision making, reproduce, and in the worst\ncase reinforce, bias of the training data. The development of tools and\ntechniques for certifying fairness of these models or describing their biased\nbehavior is, therefore, critical. In this paper, we propose a perfectly\nparallel static analysis for certifying causal fairness of feed-forward neural\nnetworks used for classification of tabular data. When certification succeeds,\nour approach provides definite guarantees, otherwise, it describes and\nquantifies the biased behavior. We design the analysis to be sound, in practice\nalso exact, and configurable in terms of scalability and precision, thereby\nenabling pay-as-you-go certification. We implement our approach in an\nopen-source tool and demonstrate its effectiveness on models trained with\npopular datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:59:28 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 13:31:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Urban", "Caterina", ""], ["Christakis", "Maria", ""], ["W\u00fcstholz", "Valentin", ""], ["Zhang", "Fuyuan", ""]]}, {"id": "1912.02503", "submitter": "Anna Harutyunyan", "authors": "Anna Harutyunyan, Will Dabney, Thomas Mesnard, Mohammad Azar, Bilal\n  Piot, Nicolas Heess, Hado van Hasselt, Greg Wayne, Satinder Singh, Doina\n  Precup, Remi Munos", "title": "Hindsight Credit Assignment", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of efficient credit assignment in reinforcement\nlearning. In order to efficiently and meaningfully utilize new data, we propose\nto explicitly assign credit to past decisions based on the likelihood of them\nhaving led to the observed outcome. This approach uses new information in\nhindsight, rather than employing foresight. Somewhat surprisingly, we show that\nvalue functions can be rewritten through this lens, yielding a new family of\nalgorithms. We study the properties of these algorithms, and empirically show\nthat they successfully address important credit assignment challenges, through\na set of illustrative tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 11:05:27 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Harutyunyan", "Anna", ""], ["Dabney", "Will", ""], ["Mesnard", "Thomas", ""], ["Azar", "Mohammad", ""], ["Piot", "Bilal", ""], ["Heess", "Nicolas", ""], ["van Hasselt", "Hado", ""], ["Wayne", "Greg", ""], ["Singh", "Satinder", ""], ["Precup", "Doina", ""], ["Munos", "Remi", ""]]}, {"id": "1912.02522", "submitter": "Arsha Nagrani", "authors": "Joon Son Chung, Arsha Nagrani, Ernesto Coto, Weidi Xie, Mitchell\n  McLaren, Douglas A Reynolds and Andrew Zisserman", "title": "VoxSRC 2019: The first VoxCeleb Speaker Recognition Challenge", "comments": "ISCA Archive", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The VoxCeleb Speaker Recognition Challenge 2019 aimed to assess how well\ncurrent speaker recognition technology is able to identify speakers in\nunconstrained or `in the wild' data. It consisted of: (i) a publicly available\nspeaker recognition dataset from YouTube videos together with ground truth\nannotation and standardised evaluation software; and (ii) a public challenge\nand workshop held at Interspeech 2019 in Graz, Austria. This paper outlines the\nchallenge and provides its baselines, results and discussions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:00:45 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Chung", "Joon Son", ""], ["Nagrani", "Arsha", ""], ["Coto", "Ernesto", ""], ["Xie", "Weidi", ""], ["McLaren", "Mitchell", ""], ["Reynolds", "Douglas A", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1912.02523", "submitter": "Eduardo Soares Mr", "authors": "Plamen Angelov, Eduardo Soares", "title": "Towards Explainable Deep Neural Networks (xDNN)", "comments": "Preprint submitted to the Neural Networks Journal for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an elegant solution that is directly addressing the\nbottlenecks of the traditional deep learning approaches and offers a clearly\nexplainable internal architecture that can outperform the existing methods,\nrequires very little computational resources (no need for GPUs) and short\ntraining times (in the order of seconds). The proposed approach, xDNN is using\nprototypes. Prototypes are actual training data samples (images), which are\nlocal peaks of the empirical data distribution called typicality as well as of\nthe data density. This generative model is identified in a closed form and\nequates to the pdf but is derived automatically and entirely from the training\ndata with no user- or problem-specific thresholds, parameters or intervention.\nThe proposed xDNN offers a new deep learning architecture that combines\nreasoning and learning in a synergy. It is non-iterative and non-parametric,\nwhich explains its efficiency in terms of time and computational resources.\nFrom the user perspective, the proposed approach is clearly understandable to\nhuman users. We tested it on some well-known benchmark data sets such as iRoads\nand Caltech-256. xDNN outperforms the other methods including deep learning in\nterms of accuracy, time to train and offers a clearly explainable classifier.\nIn fact, the result on the very hard Caltech-256 problem (which has 257\nclasses) represents a world record.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:01:15 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Angelov", "Plamen", ""], ["Soares", "Eduardo", ""]]}, {"id": "1912.02527", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Warped Input Gaussian Processes for Time Series Forecasting", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Gaussian process-based model for handling of non-stationarity.\nThe warping is achieved non-parametrically, through imposing a prior on the\nrelative change of distance between subsequent observation inputs. The model\nallows the use of general gradient optimization algorithms for training and\nincurs only a small computational overhead on training and prediction. The\nmodel finds its applications in forecasting in non-stationary time series with\neither gradually varying volatility, presence of change points, or a\ncombination thereof. We evaluate the model on synthetic and real-world time\nseries data comparing against both baseline and known state-of-the-art\napproaches and show that the model exhibits state-of-the-art forecasting\nperformance at a lower implementation and computation cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:11:54 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1912.02532", "submitter": "Jan Malte Lichtenberg", "authors": "Jan Malte Lichtenberg and \\\"Ozg\\\"ur \\c{S}im\\c{s}ek", "title": "Iterative Policy-Space Expansion in Reinforcement Learning", "comments": "Workshop on Biological and Artificial Reinforcement Learning at the\n  33rd Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals solve a difficult problem much more easily when they are\npresented with a sequence of problems that starts simple and slowly increases\nin difficulty. We explore this idea in the context of reinforcement learning.\nRather than providing the agent with an externally provided curriculum of\nprogressively more difficult tasks, the agent solves a single task utilizing a\ndecreasingly constrained policy space. The algorithm we propose first learns to\ncategorize features into positive and negative before gradually learning a more\nrefined policy. Experimental results in Tetris demonstrate superior learning\nrate of our approach when compared to existing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 12:32:15 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Lichtenberg", "Jan Malte", ""], ["\u015eim\u015fek", "\u00d6zg\u00fcr", ""]]}, {"id": "1912.02566", "submitter": "Gr\\'egoire Mialon", "authors": "Gr\\'egoire Mialon, Alexandre d'Aspremont, Julien Mairal", "title": "Screening Data Points in Empirical Risk Minimization via Ellipsoidal\n  Regions and Safe Loss Functions", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design simple screening tests to automatically discard data samples in\nempirical risk minimization without losing optimization guarantees. We derive\nloss functions that produce dual objectives with a sparse solution. We also\nshow how to regularize convex losses to ensure such a dual sparsity-inducing\nproperty, and propose a general method to design screening tests for\nclassification or regression based on ellipsoidal approximations of the optimal\nset. In addition to producing computational gains, our approach also allows us\nto compress a dataset into a subset of representative points.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 13:30:01 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 15:52:16 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 14:17:24 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Mialon", "Gr\u00e9goire", ""], ["d'Aspremont", "Alexandre", ""], ["Mairal", "Julien", ""]]}, {"id": "1912.02572", "submitter": "Jiaxi Liu", "authors": "Jiaxi Liu, Yidong Zhang, Xiaoqing Wang, Yuming Deng, Xingyu Wu", "title": "Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an end-to-end framework for addressing the problem\nof dynamic pricing on E-commerce platform using methods based on deep\nreinforcement learning (DRL). By using four groups of different business data\nto represent the states of each time period, we model the dynamic pricing\nproblem as a Markov Decision Process (MDP). Compared with the state-of-the-art\nDRL-based dynamic pricing algorithms, our approaches make the following three\ncontributions. First, we extend the discrete set problem to the continuous\nprice set. Second, instead of using revenue as the reward function directly, we\ndefine a new function named difference of revenue conversion rates (DRCR).\nThird, the cold-start problem of MDP is tackled by pre-training and evaluation\nusing some carefully chosen historical sales data. Our approaches are evaluated\nby both offline evaluation method using real dataset of Alibaba Inc., and\nonline field experiments on Tmall.com, a major online shopping website owned by\nAlibaba Inc.. In particular, experiment results suggest that DRCR is a more\nappropriate reward function than revenue, which is widely used by current\nliterature. In the end, field experiments, which last for months on 1000 stock\nkeeping units (SKUs) of products demonstrate that continuous price sets have\nbetter performance than discrete sets and show that our approaches\nsignificantly outperformed the manual pricing by operation experts.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 13:41:03 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Liu", "Jiaxi", ""], ["Zhang", "Yidong", ""], ["Wang", "Xiaoqing", ""], ["Deng", "Yuming", ""], ["Wu", "Xingyu", ""]]}, {"id": "1912.02574", "submitter": "Sanchita Basak", "authors": "Sanchita Basak, Fangzhou Sun, Saptarshi Sengupta and Abhishek Dubey", "title": "Data-Driven Optimization of Public Transit Schedule", "comments": "20 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bus transit systems are the backbone of public transportation in the United\nStates. An important indicator of the quality of service in such\ninfrastructures is on-time performance at stops, with published transit\nschedules playing an integral role governing the level of success of the\nservice. However there are relatively few optimization architectures leveraging\nstochastic search that focus on optimizing bus timetables with the objective of\nmaximizing probability of bus arrivals at timepoints with delays within desired\non-time ranges. In addition to this, there is a lack of substantial research\nconsidering monthly and seasonal variations of delay patterns integrated with\nsuch optimization strategies. To address these,this paper makes the following\ncontributions to the corpus of studies on transit on-time performance\noptimization: (a) an unsupervised clustering mechanism is presented which\ngroups months with similar seasonal delay patterns, (b) the problem is\nformulated as a single-objective optimization task and a greedy algorithm, a\ngenetic algorithm (GA) as well as a particle swarm optimization (PSO) algorithm\nare employed to solve it, (c) a detailed discussion on empirical results\ncomparing the algorithms are provided and sensitivity analysis on\nhyper-parameters of the heuristics are presented along with execution times,\nwhich will help practitioners looking at similar problems. The analyses\nconducted are insightful in the local context of improving public transit\nscheduling in the Nashville metro region as well as informative from a global\nperspective as an elaborate case study which builds upon the growing corpus of\nempirical studies using nature-inspired approaches to transit schedule\noptimization.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 03:28:11 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Basak", "Sanchita", ""], ["Sun", "Fangzhou", ""], ["Sengupta", "Saptarshi", ""], ["Dubey", "Abhishek", ""]]}, {"id": "1912.02580", "submitter": "Francesco Farina", "authors": "Francesco Farina", "title": "Collective Learning", "comments": "update references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the concept of collective learning (CL) which\nexploits the notion of collective intelligence in the field of distributed\nsemi-supervised learning. The proposed framework draws inspiration from the\nlearning behavior of human beings, who alternate phases involving\ncollaboration, confrontation and exchange of views with other consisting of\nstudying and learning on their own. On this regard, CL comprises two main\nphases: a self-training phase in which learning is performed on local private\n(labeled) data only and a collective training phase in which proxy-labels are\nassigned to shared (unlabeled) data by means of a consensus-based algorithm. In\nthe considered framework, heterogeneous systems can be connected over the same\nnetwork, each with different computational capabilities and resources and\neveryone in the network may take advantage of the cooperation and will\neventually reach higher performance with respect to those it can reach on its\nown. An extensive experimental campaign on an image classification problem\nemphasizes the properties of CL by analyzing the performance achieved by the\ncooperating agents.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:08:34 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 15:39:57 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Farina", "Francesco", ""]]}, {"id": "1912.02588", "submitter": "Ren Wang", "authors": "Ren Wang, Meng Wang, Jinjun Xiong", "title": "Tensor Recovery from Noisy and Multi-Level Quantized Measurements", "comments": null, "journal-ref": null, "doi": "10.1186/s13634-020-00698-z", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order tensors can represent scores in a rating system, frames in a\nvideo, and images of the same subject. In practice, the measurements are often\nhighly quantized due to the sampling strategies or the quality of devices.\nExisting works on tensor recovery have focused on data losses and random\nnoises. Only a few works consider tensor recovery from quantized measurements\nbut are restricted to binary measurements. This paper, for the first time,\naddresses the problem of tensor recovery from multi-level quantized\nmeasurements. Leveraging the low-rank property of the tensor, this paper\nproposes a nonconvex optimization problem for tensor recovery. We provide a\ntheoretical upper bound of the recovery error, which diminishes to zero when\nthe sizes of dimensions increase to infinity. Our error bound significantly\nimproves over the existing results in one-bit tensor recovery and quantized\nmatrix recovery. A tensor-based alternating proximal gradient descent algorithm\nwith a convergence guarantee is proposed to solve the nonconvex problem. Our\nrecovery method can handle data losses and do not need the information of the\nquantization rule. The method is validated on synthetic data, image datasets,\nand music recommender datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:27:25 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Wang", "Ren", ""], ["Wang", "Meng", ""], ["Xiong", "Jinjun", ""]]}, {"id": "1912.02590", "submitter": "Nikita Kazeev", "authors": "Maxim Borisyak, Nikita Kazeev", "title": "Machine Learning on sWeighted Data", "comments": "Submitted to Journal of Physics: Conference Series (ACAT-2019\n  proceedings)", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012088", "report-no": null, "categories": "hep-ex cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analysis in high energy physics has to deal with data samples produced\nfrom different sources. One of the most widely used ways to unfold their\ncontributions is the sPlot technique. It uses the results of a maximum\nlikelihood fit to assign weights to events. Some weights produced by sPlot are\nby design negative. Negative weights make it difficult to apply machine\nlearning methods. The loss function becomes unbounded. This leads to divergent\nneural network training. In this paper we propose a mathematically rigorous way\nto transform the weights obtained by sPlot into class probabilities conditioned\non observables, thus enabling to apply any machine learning algorithm\nout-of-the-box.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 17:06:11 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Borisyak", "Maxim", ""], ["Kazeev", "Nikita", ""]]}, {"id": "1912.02591", "submitter": "Woosung Choi", "authors": "Woosung Choi and Minseok Kim and Jaehwa Chung and Daewon Lee and\n  Soonyoung Jung", "title": "Investigating U-Nets with various Intermediate Blocks for\n  Spectrogram-based Singing Voice Separation", "comments": "8 pages 4 tables 6 figures, accepted to ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singing Voice Separation (SVS) tries to separate singing voice from a given\nmixed musical signal. Recently, many U-Net-based models have been proposed for\nthe SVS task, but there were no existing works that evaluate and compare\nvarious types of intermediate blocks that can be used in the U-Net\narchitecture. In this paper, we introduce a variety of intermediate spectrogram\ntransformation blocks. We implement U-nets based on these blocks and train them\non complex-valued spectrograms to consider both magnitude and phase. These\nnetworks are then compared on the SDR metric. When using a particular block\ncomposed of convolutional and fully-connected layers, it achieves\nstate-of-the-art SDR on the MUSDB singing voice separation task by a large\nmargin of 0.9 dB. Our code and models are available online.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 07:46:19 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 13:56:59 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 16:39:49 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Choi", "Woosung", ""], ["Kim", "Minseok", ""], ["Chung", "Jaehwa", ""], ["Lee", "Daewon", ""], ["Jung", "Soonyoung", ""]]}, {"id": "1912.02592", "submitter": "Ajith Suresh", "authors": "Harsh Chaudhari, Ashish Choudhury, Arpita Patra, Ajith Suresh", "title": "ASTRA: High Throughput 3PC over Rings with Application to Secure\n  Prediction", "comments": "This article is the full and extended version of an article appeared\n  in ACM CCSW 2019", "journal-ref": null, "doi": "10.1145/3338466.3358922", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The concrete efficiency of secure computation has been the focus of many\nrecent works. In this work, we present concretely-efficient protocols for\nsecure $3$-party computation (3PC) over a ring of integers modulo $2^{\\ell}$\ntolerating one corruption, both with semi-honest and malicious security. Owing\nto the fact that computation over ring emulates computation over the real-world\nsystem architectures, secure computation over ring has gained momentum of late.\n  Cast in the offline-online paradigm, our constructions present the most\nefficient online phase in concrete terms. In the semi-honest setting, our\nprotocol requires communication of $2$ ring elements per multiplication gate\nduring the {\\it online} phase, attaining a per-party cost of {\\em less than one\nelement}. This is achieved for the first time in the regime of 3PC. In the {\\it\nmalicious} setting, our protocol requires communication of $4$ elements per\nmultiplication gate during the online phase, beating the state-of-the-art\nprotocol by $5$ elements. Realized with both the security notions of selective\nabort and fairness, the malicious protocol with fairness involves slightly more\ncommunication than its counterpart with abort security for the output gates\n{\\em alone}.\n  We apply our techniques from $3$PC in the regime of secure server-aided\nmachine-learning (ML) inference for a range of prediction functions-- linear\nregression, linear SVM regression, logistic regression, and linear SVM\nclassification. Our setting considers a model-owner with trained model\nparameters and a client with a query, with the latter willing to learn the\nprediction of her query based on the model parameters of the former. The inputs\nand computation are outsourced to a set of three non-colluding servers. Our\nconstructions catering to both semi-honest and the malicious world, invariably\nperform better than the existing constructions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:30:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Chaudhari", "Harsh", ""], ["Choudhury", "Ashish", ""], ["Patra", "Arpita", ""], ["Suresh", "Ajith", ""]]}, {"id": "1912.02598", "submitter": "Bo Luo", "authors": "Bo Luo and Qiang Xu", "title": "Region-Wise Attack: On Efficient Generation of Robust Physical\n  Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are shown to be susceptible to adversarial\nexample attacks. Most existing works achieve this malicious objective by\ncrafting subtle pixel-wise perturbations, and they are difficult to launch in\nthe physical world due to inevitable transformations (e.g., different\nphotographic distances and angles). Recently, there are a few research works on\ngenerating physical adversarial examples, but they generally require the\ndetails of the model a priori, which is often impractical. In this work, we\npropose a novel physical adversarial attack for arbitrary black-box DNN models,\nnamely Region-Wise Attack. To be specific, we present how to efficiently search\nfor regionwise perturbations to the inputs and determine their shapes,\nlocations and colors via both top-down and bottom-up techniques. In addition,\nwe introduce two fine-tuning techniques to further improve the robustness of\nour attack. Experimental results demonstrate the efficacy and robustness of the\nproposed Region-Wise Attack in real world.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:38:00 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 10:30:15 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Luo", "Bo", ""], ["Xu", "Qiang", ""]]}, {"id": "1912.02605", "submitter": "Shihua Zhang", "authors": "Zhiyang Zhang and Shihua Zhang", "title": "Towards Understanding Residual and Dilated Dense Neural Networks via\n  Convolutional Sparse Coding", "comments": "13 pages, 8 figures", "journal-ref": "National Science Review (2020)", "doi": null, "report-no": "nwaa159", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) and its variants have led to many\nstate-of-art results in various fields. However, a clear theoretical\nunderstanding about them is still lacking. Recently, multi-layer convolutional\nsparse coding (ML-CSC) has been proposed and proved to equal such simply\nstacked networks (plain networks). Here, we think three factors in each layer\nof it including the initialization, the dictionary design and the number of\niterations greatly affect the performance of ML-CSC. Inspired by these\nconsiderations, we propose two novel multi-layer models--residual convolutional\nsparse coding model (Res-CSC) and mixed-scale dense convolutional sparse coding\nmodel (MSD-CSC), which have close relationship with the residual neural network\n(ResNet) and mixed-scale (dilated) dense neural network (MSDNet), respectively.\nMathematically, we derive the shortcut connection in ResNet as a special case\nof a new forward propagation rule on ML-CSC. We find a theoretical\ninterpretation of the dilated convolution and dense connection in MSDNet by\nanalyzing MSD-CSC, which gives a clear mathematical understanding about them.\nWe implement the iterative soft thresholding algorithm (ISTA) and its fast\nversion to solve Res-CSC and MSD-CSC, which can employ the unfolding operation\nfor further improvements. At last, extensive numerical experiments and\ncomparison with competing methods demonstrate their effectiveness using three\ntypical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 14:46:01 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 03:01:51 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Zhang", "Zhiyang", ""], ["Zhang", "Shihua", ""]]}, {"id": "1912.02606", "submitter": "Vineet Kumar", "authors": "Karthikeya Racharla, Vineet Kumar, Chaudhari Bhushan Jayant, Ankit\n  Khairkar, Paturu Harish", "title": "Predominant Musical Instrument Classification based on Spectral Features", "comments": "Appeared in Proceedings of SPIN 2020", "journal-ref": null, "doi": "10.1109/SPIN48934.2020.9071125", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to examine one of the cornerstone problems of Musical\nInstrument Retrieval (MIR), in particular, instrument classification. IRMAS\n(Instrument recognition in Musical Audio Signals) data set is chosen for this\npurpose. The data includes musical clips recorded from various sources in the\nlast century, thus having a wide variety of audio quality. We have presented a\nvery concise summary of past work in this domain. Having implemented various\nsupervised learning algorithms for this classification task, SVM classifier has\noutperformed the other state-of-the-art models with an accuracy of 79%. We also\nimplemented Unsupervised techniques out of which Hierarchical Clustering has\nperformed well.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 07:43:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 18:53:52 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Racharla", "Karthikeya", ""], ["Kumar", "Vineet", ""], ["Jayant", "Chaudhari Bhushan", ""], ["Khairkar", "Ankit", ""], ["Harish", "Paturu", ""]]}, {"id": "1912.02610", "submitter": "Verena Heu{\\ss}er", "authors": "Verena Heusser, Niklas Freymuth, Stefan Constantin, Alex Waibel", "title": "Bimodal Speech Emotion Recognition Using Pre-Trained Language Models", "comments": "Life-Long Learning for Spoken Language Systems ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition is a challenging task and an important step\ntowards more natural human-machine interaction. We show that pre-trained\nlanguage models can be fine-tuned for text emotion recognition, achieving an\naccuracy of 69.5% on Task 4A of SemEval 2017, improving upon the previous state\nof the art by over 3% absolute. We combine these language models with speech\nemotion recognition, achieving results of 73.5% accuracy when using provided\ntranscriptions and speech data on a subset of four classes of the IEMOCAP\ndataset. The use of noise-induced transcriptions and speech data results in an\naccuracy of 71.4%. For our experiments, we created IEmoNet, a modular and\nadaptable bimodal framework for speech emotion recognition based on pre-trained\nlanguage models. Lastly, we discuss the idea of using an emotional classifier\nas a reward for reinforcement learning as a step towards more successful and\nconvenient human-machine interaction.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 23:25:20 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Heusser", "Verena", ""], ["Freymuth", "Niklas", ""], ["Constantin", "Stefan", ""], ["Waibel", "Alex", ""]]}, {"id": "1912.02613", "submitter": "Yin-Jyun Luo", "authors": "Yin-Jyun Luo, Chin-Chen Hsu, Kat Agres, Dorien Herremans", "title": "Singing Voice Conversion with Disentangled Representations of Singer and\n  Vocal Technique Using Variational Autoencoders", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a flexible framework that deals with both singer conversion and\nsingers vocal technique conversion. The proposed model is trained on\nnon-parallel corpora, accommodates many-to-many conversion, and leverages\nrecent advances of variational autoencoders. It employs separate encoders to\nlearn disentangled latent representations of singer identity and vocal\ntechnique separately, with a joint decoder for reconstruction. Conversion is\ncarried out by simple vector arithmetic in the learned latent spaces. Both a\nquantitative analysis as well as a visualization of the converted spectrograms\nshow that our model is able to disentangle singer identity and vocal technique\nand successfully perform conversion of these attributes. To the best of our\nknowledge, this is the first work to jointly tackle conversion of singer\nidentity and vocal technique based on a deep learning approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 03:50:08 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 15:45:57 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 03:33:46 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Luo", "Yin-Jyun", ""], ["Hsu", "Chin-Chen", ""], ["Agres", "Kat", ""], ["Herremans", "Dorien", ""]]}, {"id": "1912.02615", "submitter": "Wim Boes", "authors": "Wim Boes and Hugo Van hamme", "title": "Audiovisual Transformer Architectures for Large-Scale Classification and\n  Synchronization of Weakly Labeled Audio Events", "comments": null, "journal-ref": "Proceedings of the 27th ACM International Conference on Multimedia\n  (MM '19). ACM, New York, NY, USA, 1961-1969", "doi": "10.1145/3343031.3350873", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the task of environmental event classification by drawing\ninspiration from the transformer neural network architecture used in machine\ntranslation. We modify this attention-based feedforward structure in such a way\nthat allows the resulting model to use audio as well as video to compute sound\nevent predictions. We perform extensive experiments with these adapted\ntransformers on an audiovisual data set, obtained by appending relevant visual\ninformation to an existing large-scale weakly labeled audio collection. The\nemployed multi-label data contains clip-level annotation indicating the\npresence or absence of 17 classes of environmental sounds, and does not include\ntemporal information. We show that the proposed modified transformers strongly\nimprove upon previously introduced models and in fact achieve state-of-the-art\nresults. We also make a compelling case for devoting more attention to research\nin multimodal audiovisual classification by proving the usefulness of visual\ninformation for the task at hand,namely audio event recognition. In addition,\nwe visualize internal attention patterns of the audiovisual transformers and in\ndoing so demonstrate their potential for performing multimodal synchronization.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:26:37 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Boes", "Wim", ""], ["Van hamme", "Hugo", ""]]}, {"id": "1912.02620", "submitter": "Tian Xia", "authors": "Tian Xia, Agisilaos Chartsias, Chengjia Wang, Sotirios A. Tsaftaris", "title": "Learning to synthesise the ageing brain without longitudinal data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How will my face look when I get older? Or, for a more challenging question:\nHow will my brain look when I get older? To answer this question one must\ndevise (and learn from data) a multivariate auto-regressive function which\ngiven an image and a desired target age generates an output image. While\ncollecting data for faces may be easier, collecting longitudinal brain data is\nnot trivial. We propose a deep learning-based method that learns to simulate\nsubject-specific brain ageing trajectories without relying on longitudinal\ndata. Our method synthesises images conditioned on two factors: age (a\ncontinuous variable), and status of Alzheimer's Disease (AD, an ordinal\nvariable). With an adversarial formulation we learn the joint distribution of\nbrain appearance, age and AD status, and define reconstruction losses to\naddress the challenging problem of preserving subject identity. We compare with\nseveral benchmarks using two widely used datasets. We evaluate the quality and\nrealism of synthesised images using ground-truth longitudinal data and a\npre-trained age predictor. We show that, despite the use of cross-sectional\ndata, our model learns patterns of gray matter atrophy in the middle temporal\ngyrus in patients with AD. To demonstrate generalisation ability, we train on\none dataset and evaluate predictions on the other. In conclusion, our model\nshows an ability to separate age, disease influence and anatomy using only 2D\ncross-sectional data that should should be useful in large studies into\nneurodegenerative disease, that aim to combine several data sources. To\nfacilitate such future studies by the community at large our code is made\navailable at https://github.com/xiat0616/BrainAgeing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:12:19 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 12:37:51 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 09:49:48 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 09:15:03 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xia", "Tian", ""], ["Chartsias", "Agisilaos", ""], ["Wang", "Chengjia", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "1912.02624", "submitter": "Ruihan Zhao", "authors": "Ruihan Zhao, Stas Tiomkin, Pieter Abbeel", "title": "Learning Efficient Representation for Intrinsic Motivation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual Information between agent Actions and environment States (MIAS)\nquantifies the influence of agent on its environment. Recently, it was found\nthat the maximization of MIAS can be used as an intrinsic motivation for\nartificial agents. In literature, the term empowerment is used to represent the\nmaximum of MIAS at a certain state. While empowerment has been shown to solve a\nbroad range of reinforcement learning problems, its calculation in arbitrary\ndynamics is a challenging problem because it relies on the estimation of mutual\ninformation. Existing approaches, which rely on sampling, are limited to low\ndimensional spaces, because high-confidence distribution-free lower bounds for\nmutual information require exponential number of samples. In this work, we\ndevelop a novel approach for the estimation of empowerment in unknown dynamics\nfrom visual observation only, without the need to sample for MIAS. The core\nidea is to represent the relation between action sequences and future states\nusing a stochastic dynamic model in latent space with a specific form. This\nallows us to efficiently compute empowerment with the \"Water-Filling\" algorithm\nfrom information theory. We construct this embedding with deep neural networks\ntrained on a sophisticated objective function. Our experimental results show\nthat the designed embedding preserves information-theoretic properties of the\noriginal dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 07:48:40 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 01:06:37 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 23:07:25 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Ruihan", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1912.02628", "submitter": "Song Fang", "authors": "Song Fang, Quanyan Zhu", "title": "Fundamental Limitations in Sequential Prediction and Recursive\n  Algorithms: $\\mathcal{L}_{p}$ Bounds via an Entropic Analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.06742.\n  text overlap with arXiv:1912.05541", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we obtain fundamental $\\mathcal{L}_{p}$ bounds in sequential\nprediction and recursive algorithms via an entropic analysis. Both classes of\nproblems are examined by investigating the underlying entropic relationships of\nthe data and/or noises involved, and the derived lower bounds may all be\nquantified in a conditional entropy characterization. We also study the\nconditions to achieve the generic bounds from an innovations' viewpoint.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 16:52:15 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 15:56:59 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1912.02629", "submitter": "Marieh Alaghband", "authors": "Niloofar Yousefi, Marie Alaghband, Ivan Garibay", "title": "A Comprehensive Survey on Machine Learning Techniques and User\n  Authentication Approaches for Credit Card Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of credit card usage, the volume of credit card misuse also\nhas significantly increased. As a result, financial organizations are working\nhard on developing and deploying credit card fraud detection methods, in order\nto adapt to ever-evolving, increasingly sophisticated defrauding strategies and\nidentifying illicit transactions as quickly as possible to protect themselves\nand their customers. Compounding on the complex nature of such adverse\nstrategies, credit card fraudulent activities are rare events compared to the\nnumber of legitimate transactions. Hence, the challenge to develop fraud\ndetection that are accurate and efficient is substantially intensified and, as\na consequence, credit card fraud detection has lately become a very active area\nof research. In this work, we provide a survey of current techniques most\nrelevant to the problem of credit card fraud detection. We carry out our survey\nin two main parts. In the first part,we focus on studies utilizing classical\nmachine learning models, which mostly employ traditional transnational features\nto make fraud predictions. These models typically rely on some static physical\ncharacteristics, such as what the user knows (knowledge-based method), or what\nhe/she has access to (object-based method). In the second part of our survey,\nwe review more advanced techniques of user authentication, which use behavioral\nbiometrics to identify an individual based on his/her unique behavior while\nhe/she is interacting with his/her electronic devices. These approaches rely on\nhow people behave (instead of what they do), which cannot be easily forged. By\nproviding an overview of current approaches and the results reported in the\nliterature, this survey aims to drive the future research agenda for the\ncommunity in order to develop more accurate, reliable and scalable models of\ncredit card fraud detection.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:40:39 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Yousefi", "Niloofar", ""], ["Alaghband", "Marie", ""], ["Garibay", "Ivan", ""]]}, {"id": "1912.02631", "submitter": "Ajith Suresh", "authors": "Harsh Chaudhari, Rahul Rachuri, Ajith Suresh", "title": "Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning", "comments": "This work appeared at the 26th Annual Network and Distributed System\n  Security Symposium (NDSS) 2020. Update: An improved version of this framework\n  is available at arXiv:2106.02850", "journal-ref": null, "doi": "10.14722/ndss.2020.23005", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning has started to be deployed in fields such as healthcare and\nfinance, which propelled the need for and growth of privacy-preserving machine\nlearning (PPML). We propose an actively secure four-party protocol (4PC), and a\nframework for PPML, showcasing its applications on four of the most\nwidely-known machine learning algorithms -- Linear Regression, Logistic\nRegression, Neural Networks, and Convolutional Neural Networks. Our 4PC\nprotocol tolerating at most one malicious corruption is practically efficient\nas compared to the existing works. We use the protocol to build an efficient\nmixed-world framework (Trident) to switch between the Arithmetic, Boolean, and\nGarbled worlds. Our framework operates in the offline-online paradigm over\nrings and is instantiated in an outsourced setting for machine learning. Also,\nwe propose conversions especially relevant to privacy-preserving machine\nlearning. The highlights of our framework include using a minimal number of\nexpensive circuits overall as compared to ABY3. This can be seen in our\ntechnique for truncation, which does not affect the online cost of\nmultiplication and removes the need for any circuits in the offline phase. Our\nB2A conversion has an improvement of $\\mathbf{7} \\times$ in rounds and\n$\\mathbf{18} \\times$ in the communication complexity. The practicality of our\nframework is argued through improvements in the benchmarking of the\naforementioned algorithms when compared with ABY3. All the protocols are\nimplemented over a 64-bit ring in both LAN and WAN settings. Our improvements\ngo up to $\\mathbf{187} \\times$ for the training phase and $\\mathbf{158} \\times$\nfor the prediction phase when observed over LAN and WAN.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:06:39 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:08:04 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chaudhari", "Harsh", ""], ["Rachuri", "Rahul", ""], ["Suresh", "Ajith", ""]]}, {"id": "1912.02636", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Chad Brown, Cezary Kaliszyk, Josef Urban", "title": "Exploration of Neural Machine Translation in Autoformalization of\n  Mathematics in Mizar", "comments": "The 9th ACM SIGPLAN International Conference on Certified Programs\n  and Proofs", "journal-ref": null, "doi": "10.1145/3372885.3373827", "report-no": null, "categories": "cs.LO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we share several experiments trying to automatically translate\ninformal mathematics into formal mathematics. In our context informal\nmathematics refers to human-written mathematical sentences in the LaTeX format;\nand formal mathematics refers to statements in the Mizar language. We conducted\nour experiments against three established neural network-based machine\ntranslation models that are known to deliver competitive results on translating\nbetween natural languages. To train these models we also prepared four\ninformal-to-formal datasets. We compare and analyze our results according to\nwhether the model is supervised or unsupervised. In order to augment the data\navailable for auto-formalization and improve the results, we develop a custom\ntype-elaboration mechanism and integrate it in the supervised translation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:13:15 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:29:01 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Wang", "Qingxiang", ""], ["Brown", "Chad", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1912.02641", "submitter": "Kian Hsiang Low", "authors": "Tong Teng and Jie Chen and Yehong Zhang and Kian Hsiang Low", "title": "Scalable Variational Bayesian Kernel Selection for Sparse Gaussian\n  Process Regression", "comments": "34th AAAI Conference on Artificial Intelligence (AAAI 2020), Extended\n  version with derivations, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a variational Bayesian kernel selection (VBKS) algorithm\nfor sparse Gaussian process regression (SGPR) models. In contrast to existing\nGP kernel selection algorithms that aim to select only one kernel with the\nhighest model evidence, our proposed VBKS algorithm considers the kernel as a\nrandom variable and learns its belief from data such that the uncertainty of\nthe kernel can be interpreted and exploited to avoid overconfident GP\npredictions. To achieve this, we represent the probabilistic kernel as an\nadditional variational variable in a variational inference (VI) framework for\nSGPR models where its posterior belief is learned together with that of the\nother variational variables (i.e., inducing variables and kernel\nhyperparameters). In particular, we transform the discrete kernel belief into a\ncontinuous parametric distribution via reparameterization in order to apply VI.\nThough it is computationally challenging to jointly optimize a large number of\nhyperparameters due to many kernels being evaluated simultaneously by our VBKS\nalgorithm, we show that the variational lower bound of the log-marginal\nlikelihood can be decomposed into an additive form such that each additive term\ndepends only on a disjoint subset of the variational variables and can thus be\noptimized independently. Stochastic optimization is then used to maximize the\nvariational lower bound by iteratively improving the variational approximation\nof the exact posterior belief via stochastic gradient ascent, which incurs\nconstant time per iteration and hence scales to big data. We empirically\nevaluate the performance of our VBKS algorithm on synthetic and massive\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:23:10 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Teng", "Tong", ""], ["Chen", "Jie", ""], ["Zhang", "Yehong", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "1912.02644", "submitter": "Marissa Connor", "authors": "Marissa Connor, Christopher Rozell", "title": "Representing Closed Transformation Paths in Encoded Network Latent Space", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative networks have been widely used for learning mappings from a\nlow-dimensional latent space to a high-dimensional data space. In many cases,\ndata transformations are defined by linear paths in this latent space. However,\nthe Euclidean structure of the latent space may be a poor match for the\nunderlying latent structure in the data. In this work, we incorporate a\ngenerative manifold model into the latent space of an autoencoder in order to\nlearn the low-dimensional manifold structure from the data and adapt the latent\nspace to accommodate this structure. In particular, we focus on applications in\nwhich the data has closed transformation paths which extend from a starting\npoint and return to nearly the same point. Through experiments on data with\nnatural closed transformation paths, we show that this model introduces the\nability to learn the latent dynamics of complex systems, generate\ntransformation paths, and classify samples that belong on the same\ntransformation path.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:27:26 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Connor", "Marissa", ""], ["Rozell", "Christopher", ""]]}, {"id": "1912.02651", "submitter": "Maede Zolanvari", "authors": "Maede Zolanvari, Marcio A. Teixeira, Raj Jain", "title": "Effect of Imbalanced Datasets on Security of Industrial IoT Using\n  Machine Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.05771", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been shown to be suitable for securing\nplatforms for IT systems. However, due to the fundamental differences between\nthe industrial internet of things (IIoT) and regular IT networks, a special\nperformance review needs to be considered. The vulnerabilities and security\nrequirements of IIoT systems demand different considerations. In this paper, we\nstudy the reasons why machine learning must be integrated into the security\nmechanisms of the IIoT, and where it currently falls short in having a\nsatisfactory performance. The challenges and real-world considerations\nassociated with this matter are studied in our experimental design. We use an\nIIoT testbed resembling a real industrial plant to show our proof of concept.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 20:16:47 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Zolanvari", "Maede", ""], ["Teixeira", "Marcio A.", ""], ["Jain", "Raj", ""]]}, {"id": "1912.02655", "submitter": "Mehak Gupta", "authors": "Mehak Gupta, Thao-Ly T. Phan, Timothy Bunnell, Rahmatollah Beheshti", "title": "Obesity Prediction with EHR Data: A deep learning approach with\n  interpretable elements", "comments": "19 pages, 4 Tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Childhood obesity is a major public health challenge. Obesity in early\nchildhood and adolescence can lead to obesity and other health problems in\nadulthood. Early prediction and identification of the children at a high risk\nof developing childhood obesity may help in engaging earlier and more effective\ninterventions to prevent and manage this and other related health conditions.\nExisting predictive tools designed for childhood obesity primarily rely on\ntraditional regression-type methods without exploiting longitudinal patterns of\nchildren's data (ignoring data temporality). In this paper, we present a\nmachine learning model specifically designed for predicting future obesity\npatterns from generally available items on children's medical history. To do\nthis, we have used a large unaugmented EHR (Electronic Health Record) dataset\nfrom a major pediatric health system in the US. We adopt a general LSTM (long\nshort-term memory) network architecture for our model for training over dynamic\n(sequential) and static (demographic) EHR data. We have additionally included a\nset embedding and attention layers to compute the feature ranking of each\ntimestamp and attention scores of each hidden layer corresponding to each input\ntimestamp. These feature ranking and attention scores added interpretability at\nboth the features and the timestamp-level.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:41:27 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 23:26:34 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 16:10:04 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 19:21:07 GMT"}, {"version": "v5", "created": "Fri, 29 May 2020 21:58:07 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Gupta", "Mehak", ""], ["Phan", "Thao-Ly T.", ""], ["Bunnell", "Timothy", ""], ["Beheshti", "Rahmatollah", ""]]}, {"id": "1912.02671", "submitter": "Giovanni Morrone", "authors": "Ander Arriandiaga, Giovanni Morrone, Luca Pasa, Leonardo Badino,\n  Chiara Bartolozzi", "title": "Audio-Visual Target Speaker Enhancement on Multi-Talker Environment\n  using Event-Driven Cameras", "comments": "Accepted at ISCAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to address audio-visual target speaker enhancement in\nmulti-talker environments using event-driven cameras. State of the art\naudio-visual speech separation methods shows that crucial information is the\nmovement of the facial landmarks related to speech production. However, all\napproaches proposed so far work offline, using frame-based video input, making\nit difficult to process an audio-visual signal with low latency, for online\napplications. In order to overcome this limitation, we propose the use of\nevent-driven cameras and exploit compression, high temporal resolution and low\nlatency, for low cost and low latency motion feature extraction, going towards\nonline embedded audio-visual speech processing. We use the event-driven optical\nflow estimation of the facial landmarks as input to a stacked Bidirectional\nLSTM trained to predict an Ideal Amplitude Mask that is then used to filter the\nnoisy audio, to obtain the audio signal of the target speaker. The presented\napproach performs almost on par with the frame-based approach, with very low\nlatency and computational cost.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:01:14 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 11:31:15 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Arriandiaga", "Ander", ""], ["Morrone", "Giovanni", ""], ["Pasa", "Luca", ""], ["Badino", "Leonardo", ""], ["Bartolozzi", "Chiara", ""]]}, {"id": "1912.02686", "submitter": "Koki Kishimoto", "authors": "Koki Kishimoto, Katsuhiko Hayashi, Genki Akai, Masashi Shimbo", "title": "Binarized Canonical Polyadic Decomposition for Knowledge Graph\n  Completion", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.02970", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods based on vector embeddings of knowledge graphs have been actively\npursued as a promising approach to knowledge graph completion.However,\nembedding models generate storage-inefficient representations, particularly\nwhen the number of entities and relations, and the dimensionality of the\nreal-valued embedding vectors are large. We present a binarized\nCANDECOMP/PARAFAC(CP) decomposition algorithm, which we refer to as B-CP, where\nreal-valued parameters are replaced by binary values to reduce model size.\nMoreover, we show that a fast score computation technique can be developed with\nbitwise operations. We prove that B-CP is fully expressive by deriving a bound\non the size of its embeddings. Experimental results on several benchmark\ndatasets demonstrate that the proposed method successfully reduces model size\nby more than an order of magnitude while maintaining task performance at the\nsame level as the real-valued CP model.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 05:13:53 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Kishimoto", "Koki", ""], ["Hayashi", "Katsuhiko", ""], ["Akai", "Genki", ""], ["Shimbo", "Masashi", ""]]}, {"id": "1912.02696", "submitter": "Reazul Hasan Russel", "authors": "Reazul Hasan Russel, Bahram Behzadian, Marek Petrik", "title": "Optimizing Norm-Bounded Weighted Ambiguity Sets for Robust MDPs", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.10786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal policies in Markov decision processes (MDPs) are very sensitive to\nmodel misspecification. This raises serious concerns about deploying them in\nhigh-stake domains. Robust MDPs (RMDP) provide a promising framework to\nmitigate vulnerabilities by computing policies with worst-case guarantees in\nreinforcement learning. The solution quality of an RMDP depends on the\nambiguity set, which is a quantification of model uncertainties. In this paper,\nwe propose a new approach for optimizing the shape of the ambiguity sets for\nRMDPs. Our method departs from the conventional idea of constructing a\nnorm-bounded uniform and symmetric ambiguity set. We instead argue that the\nstructure of a near-optimal ambiguity set is problem specific. Our proposed\nmethod computes a weight parameter from the value functions, and these weights\nthen drive the shape of the ambiguity sets. Our theoretical analysis\ndemonstrates the rationale of the proposed idea. We apply our method to several\ndifferent problem domains, and the empirical results further furnish the\npractical promise of weighted near-optimal ambiguity sets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:38:57 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Russel", "Reazul Hasan", ""], ["Behzadian", "Bahram", ""], ["Petrik", "Marek", ""]]}, {"id": "1912.02703", "submitter": "Craig Ganoe", "authors": "Xing Meng, Craig H. Ganoe, Ryan T. Sieberg, Yvonne Y. Cheung, Saeed\n  Hassanpour", "title": "Self-Supervised Contextual Language Representation of Radiology Reports\n  to Improve the Identification of Communication Urgency", "comments": "Accepted in AMIA 2020 Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have recently achieved high-performance in\nbiomedical text analysis. However, a major bottleneck in the widespread\napplication of these methods is obtaining the required large amounts of\nannotated training data, which is resource intensive and time consuming. Recent\nprogress in self-supervised learning has shown promise in leveraging large text\ncorpora without explicit annotations. In this work, we built a self-supervised\ncontextual language representation model using BERT, a deep bidirectional\ntransformer architecture, to identify radiology reports requiring prompt\ncommunication to the referring physicians. We pre-trained the BERT model on a\nlarge unlabeled corpus of radiology reports and used the resulting contextual\nrepresentations in a final text classifier for communication urgency. Our model\nachieved a precision of 97.0%, recall of 93.3%, and F-measure of 95.1% on an\nindependent test set in identifying radiology reports for prompt communication,\nand significantly outperformed the previous state-of-the-art model based on\nword2vec representations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:33:23 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Meng", "Xing", ""], ["Ganoe", "Craig H.", ""], ["Sieberg", "Ryan T.", ""], ["Cheung", "Yvonne Y.", ""], ["Hassanpour", "Saeed", ""]]}, {"id": "1912.02707", "submitter": "Eli (Omid) David", "authors": "Daniel Rika, Dror Sholomon, Eli David, Nathan S. Netanyahu", "title": "A Novel Hybrid Scheme Using Genetic Algorithms and Deep Learning for the\n  Reconstruction of Portuguese Tile Panels", "comments": null, "journal-ref": "ACM Genetic and Evolutionary Computation Conference (GECCO), pages\n  1319-1327, Prague, Czech Republic, July 2019", "doi": "10.1145/3321707.3321821", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel scheme, based on a unique combination of genetic\nalgorithms (GAs) and deep learning (DL), for the automatic reconstruction of\nPortuguese tile panels, a challenging real-world variant of the jigsaw puzzle\nproblem (JPP) with important national heritage implications. Specifically, we\nintroduce an enhanced GA-based puzzle solver, whose integration with a novel\nDL-based compatibility measure (DLCM) yields state-of-the-art performance,\nregarding the above application. Current compatibility measures consider\ntypically (the chromatic information of) edge pixels (between adjacent tiles),\nand help achieve high accuracy for the synthetic JPP variant. However, such\nmeasures exhibit rather poor performance when applied to the Portuguese tile\npanels, which are susceptible to various real-world effects, e.g.,\nmonochromatic panels, non-squared tiles, edge degradation, etc. To overcome\nsuch difficulties, we have developed a novel DLCM to extract high-level\ntexture/color statistics from the entire tile information.\n  Integrating this measure with our enhanced GA-based puzzle solver, we have\ndemonstrated, for the first time, how to deal most effectively with large-scale\nreal-world problems, such as the Portuguese tile problem. Specifically, we have\nachieved 82% accuracy for the reconstruction of Portuguese tile panels with\nunknown piece rotation and puzzle dimension (compared to merely 3.5% average\naccuracy achieved by the best method known for solving this problem variant).\nThe proposed method outperforms even human experts in several cases, correcting\ntheir mistakes in the manual tile assembly.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 06:24:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Rika", "Daniel", ""], ["Sholomon", "Dror", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.02714", "submitter": "Brandon Trabucco", "authors": "Brandon Trabucco, Albert Qu, Simon Li, Ganeshkumar Ashokavardhanan", "title": "Inferring the Optimal Policy using Markov Chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates methods for estimating the optimal stochastic control\npolicy for a Markov Decision Process with unknown transition dynamics and an\nunknown reward function. This form of model-free reinforcement learning\ncomprises many real world systems such as playing video games, simulated\ncontrol tasks, and real robot locomotion. Existing methods for estimating the\noptimal stochastic control policy rely on high variance estimates of the policy\ndescent. However, these methods are not guaranteed to find the optimal\nstochastic policy, and the high variance gradient estimates make convergence\nunstable. In order to resolve these problems, we propose a technique using\nMarkov Chain Monte Carlo to generate samples from the posterior distribution of\nthe parameters conditioned on being optimal. Our method provably converges to\nthe globally optimal stochastic policy, and empirically similar variance\ncompared to the policy gradient.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:08:24 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Trabucco", "Brandon", ""], ["Qu", "Albert", ""], ["Li", "Simon", ""], ["Ashokavardhanan", "Ganeshkumar", ""]]}, {"id": "1912.02721", "submitter": "Amitava Banerjee", "authors": "Amitava Banerjee, Jaideep Pathak, Rajarshi Roy, Juan G. Restrepo,\n  Edward Ott", "title": "Using Machine Learning to Assess Short Term Causal Dependence and Infer\n  Network Links", "comments": "28 pages, 4 Figures, Accepted in Chaos", "journal-ref": "Chaos 29, 121104 (2019)", "doi": "10.1063/1.5134845", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and test a general machine-learning-based technique for the\ninference of short term causal dependence between state variables of an unknown\ndynamical system from time series measurements of its state variables. Our\ntechnique leverages the results of a machine learning process for short time\nprediction to achieve our goal. The basic idea is to use the machine learning\nto estimate the elements of the Jacobian matrix of the dynamical flow along an\norbit. The type of machine learning that we employ is reservoir computing. We\npresent numerical tests on link inference of a network of interacting dynamical\nnodes. It is seen that dynamical noise can greatly enhance the effectiveness of\nour technique, while observational noise degrades the effectiveness. We believe\nthat the competition between these two opposing types of noise will be the key\nfactor determining the success of causal inference in many of the most\nimportant application situations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:57:49 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Banerjee", "Amitava", ""], ["Pathak", "Jaideep", ""], ["Roy", "Rajarshi", ""], ["Restrepo", "Juan G.", ""], ["Ott", "Edward", ""]]}, {"id": "1912.02724", "submitter": "Dominik Janzing", "authors": "Dominik Janzing, Kailash Budhathoki, Lenon Minorics, and Patrick\n  Bl\\\"obaum", "title": "Causal structure based root cause analysis of outliers", "comments": "11 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a formal approach to identify 'root causes' of outliers observed\nin $n$ variables $X_1,\\dots,X_n$ in a scenario where the causal relation\nbetween the variables is a known directed acyclic graph (DAG). To this end, we\nfirst introduce a systematic way to define outlier scores. Further, we\nintroduce the concept of 'conditional outlier score' which measures whether a\nvalue of some variable is unexpected *given the value of its parents* in the\nDAG, if one were to assume that the causal structure and the corresponding\nconditional distributions are also valid for the anomaly. Finally, we quantify\nto what extent the high outlier score of some target variable can be attributed\nto outliers of its ancestors. This quantification is defined via Shapley values\nfrom cooperative game theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:00:20 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Janzing", "Dominik", ""], ["Budhathoki", "Kailash", ""], ["Minorics", "Lenon", ""], ["Bl\u00f6baum", "Patrick", ""]]}, {"id": "1912.02729", "submitter": "Benjamin Aubin", "authors": "Alia Abbara, Benjamin Aubin, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Rademacher complexity and spin glasses: A link between the replica and\n  statistical theories of learning", "comments": "15 + 10 pages, v2 revised and accepted at MSML", "journal-ref": "Proceedings of The First Mathematical and Scientific Machine\n  Learning Conference, PMLR 107:27-54, 2020", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical learning theory provides bounds of the generalization gap, using\nin particular the Vapnik-Chervonenkis dimension and the Rademacher complexity.\nAn alternative approach, mainly studied in the statistical physics literature,\nis the study of generalization in simple synthetic-data models. Here we discuss\nthe connections between these approaches and focus on the link between the\nRademacher complexity in statistical learning and the theories of\ngeneralization for typical-case synthetic models from statistical physics,\ninvolving quantities known as Gardner capacity and ground state energy. We show\nthat in these models the Rademacher complexity is closely related to the ground\nstate energy computed by replica theories. Using this connection, one may\nreinterpret many results of the literature as rigorous Rademacher bounds in a\nvariety of models in the high-dimensional statistics limit. Somewhat\nsurprisingly, we also show that statistical learning theory provides\npredictions for the behavior of the ground-state energies in some full replica\nsymmetry breaking models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:09:17 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 09:00:11 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Abbara", "Alia", ""], ["Aubin", "Benjamin", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1912.02738", "submitter": "Jin Xu", "authors": "Jin Xu, Jean-Francois Ton, Hyunjik Kim, Adam R. Kosiorek, Yee Whye Teh", "title": "MetaFun: Meta-Learning with Iterative Functional Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a functional encoder-decoder approach to supervised meta-learning,\nwhere labeled data is encoded into an infinite-dimensional functional\nrepresentation rather than a finite-dimensional one. Furthermore, rather than\ndirectly producing the representation, we learn a neural update rule resembling\nfunctional gradient descent which iteratively improves the representation. The\nfinal representation is used to condition the decoder to make predictions on\nunlabeled data. Our approach is the first to demonstrates the success of\nencoder-decoder style meta-learning methods like conditional neural processes\non large-scale few-shot classification benchmarks such as miniImageNet and\ntieredImageNet, where it achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:25:13 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 23:18:39 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 11:41:43 GMT"}, {"version": "v4", "created": "Sun, 16 Aug 2020 10:21:10 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xu", "Jin", ""], ["Ton", "Jean-Francois", ""], ["Kim", "Hyunjik", ""], ["Kosiorek", "Adam R.", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1912.02743", "submitter": "Azim Ahmadzadeh", "authors": "Azim Ahmadzadeh, Sushant S. Mahajan, Dustin J. Kempton, Rafal A.\n  Angryk, and Shihao Ji", "title": "Toward Filament Segmentation Using Deep Neural Networks", "comments": "10 pages, 10 figures, 1 table, accepted in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use a well-known deep neural network framework, called Mask R-CNN, for\nidentification of solar filaments in full-disk H-alpha images from Big Bear\nSolar Observatory (BBSO). The image data, collected from BBSO's archive, are\nintegrated with the spatiotemporal metadata of filaments retrieved from the\nHeliophysics Events Knowledgebase (HEK) system. This integrated data is then\ntreated as the ground-truth in the training process of the model. The available\nspatial metadata are the output of a currently running filament-detection\nmodule developed and maintained by the Feature Finding Team; an international\nconsortium selected by NASA. Despite the known challenges in the identification\nand characterization of filaments by the existing module, which in turn are\ninherited into any other module that intends to learn from such outputs, Mask\nR-CNN shows promising results. Trained and validated on two years worth of BBSO\ndata, this model is then tested on the three following years. Our case-by-case\nand overall analyses show that Mask R-CNN can clearly compete with the existing\nmodule and in some cases even perform better. Several cases of false positives\nand false negatives, that are correctly segmented by this model are also shown.\nThe overall advantages of using the proposed model are two-fold: First, deep\nneural networks' performance generally improves as more annotated data, or\nbetter annotations are provided. Second, such a model can be scaled up to\ndetect other solar events, as well as a single multi-purpose module. The\nresults presented in this study introduce a proof of concept in benefits of\nemploying deep neural networks for detection of solar events, and in\nparticular, filaments.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:45:41 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ahmadzadeh", "Azim", ""], ["Mahajan", "Sushant S.", ""], ["Kempton", "Dustin J.", ""], ["Angryk", "Rafal A.", ""], ["Ji", "Shihao", ""]]}, {"id": "1912.02757", "submitter": "Balaji Lakshminarayanan", "authors": "Stanislav Fort, Huiyi Hu, Balaji Lakshminarayanan", "title": "Deep Ensembles: A Loss Landscape Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep ensembles have been empirically shown to be a promising approach for\nimproving accuracy, uncertainty and out-of-distribution robustness of deep\nlearning models. While deep ensembles were theoretically motivated by the\nbootstrap, non-bootstrap ensembles trained with just random initialization also\nperform well in practice, which suggests that there could be other explanations\nfor why deep ensembles work well. Bayesian neural networks, which learn\ndistributions over the parameters of the network, are theoretically\nwell-motivated by Bayesian principles, but do not perform as well as deep\nensembles in practice, particularly under dataset shift. One possible\nexplanation for this gap between theory and practice is that popular scalable\nvariational Bayesian methods tend to focus on a single mode, whereas deep\nensembles tend to explore diverse modes in function space. We investigate this\nhypothesis by building on recent work on understanding the loss landscape of\nneural networks and adding our own exploration to measure the similarity of\nfunctions in the space of predictions. Our results show that random\ninitializations explore entirely different modes, while functions along an\noptimization trajectory or sampled from the subspace thereof cluster within a\nsingle mode predictions-wise, while often deviating significantly in the weight\nspace. Developing the concept of the diversity--accuracy plane, we show that\nthe decorrelation power of random initializations is unmatched by popular\nsubspace sampling methods. Finally, we evaluate the relative effects of\nensembling, subspace based methods and ensembles of subspace based methods, and\nthe experimental results validate our hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:48:18 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:57:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Fort", "Stanislav", ""], ["Hu", "Huiyi", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1912.02762", "submitter": "George Papamakarios", "authors": "George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir\n  Mohamed, Balaji Lakshminarayanan", "title": "Normalizing Flows for Probabilistic Modeling and Inference", "comments": "Review article, 64 pages, 9 figures. Published in the Journal of\n  Machine Learning Research (see https://jmlr.org/papers/v22/19-1028.html)", "journal-ref": "Journal of Machine Learning Research, 22(57):1-64, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows provide a general mechanism for defining expressive\nprobability distributions, only requiring the specification of a (usually\nsimple) base distribution and a series of bijective transformations. There has\nbeen much recent work on normalizing flows, ranging from improving their\nexpressive power to expanding their application. We believe the field has now\nmatured and is in need of a unified perspective. In this review, we attempt to\nprovide such a perspective by describing flows through the lens of\nprobabilistic modeling and inference. We place special emphasis on the\nfundamental principles of flow design, and discuss foundational topics such as\nexpressive power and computational trade-offs. We also broaden the conceptual\nframing of flows by relating them to more general probability transformations.\nLastly, we summarize the use of flows for tasks such as generative modeling,\napproximate inference, and supervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:55:27 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 10:47:26 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Papamakarios", "George", ""], ["Nalisnick", "Eric", ""], ["Rezende", "Danilo Jimenez", ""], ["Mohamed", "Shakir", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1912.02765", "submitter": "Ishaq Aden-Ali", "authors": "Ishaq Aden-Ali, Hassan Ashtiani", "title": "On the Sample Complexity of Learning Sum-Product Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-Product Networks (SPNs) can be regarded as a form of deep graphical\nmodels that compactly represent deeply factored and mixed distributions. An SPN\nis a rooted directed acyclic graph (DAG) consisting of a set of leaves\n(corresponding to base distributions), a set of sum nodes (which represent\nmixtures of their children distributions) and a set of product nodes\n(representing the products of its children distributions).\n  In this work, we initiate the study of the sample complexity of PAC-learning\nthe set of distributions that correspond to SPNs. We show that the sample\ncomplexity of learning tree structured SPNs with the usual type of leaves\n(i.e., Gaussian or discrete) grows at most linearly (up to logarithmic factors)\nwith the number of parameters of the SPN. More specifically, we show that the\nclass of distributions that corresponds to tree structured Gaussian SPNs with\n$k$ mixing weights and $e$ ($d$-dimensional Gaussian) leaves can be learned\nwithin Total Variation error $\\epsilon$ using at most\n$\\widetilde{O}(\\frac{ed^2+k}{\\epsilon^2})$ samples. A similar result holds for\ntree structured SPNs with discrete leaves.\n  We obtain the upper bounds based on the recently proposed notion of\ndistribution compression schemes. More specifically, we show that if a (base)\nclass of distributions $\\mathcal{F}$ admits an \"efficient\" compression, then\nthe class of tree structured SPNs with leaves from $\\mathcal{F}$ also admits an\nefficient compression.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:57:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:18:11 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Aden-Ali", "Ishaq", ""], ["Ashtiani", "Hassan", ""]]}, {"id": "1912.02771", "submitter": "Dimitris Tsipras", "authors": "Alexander Turner, Dimitris Tsipras, Aleksander Madry", "title": "Label-Consistent Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been demonstrated to be vulnerable to backdoor\nattacks. Specifically, by injecting a small number of maliciously constructed\ninputs into the training set, an adversary is able to plant a backdoor into the\ntrained model. This backdoor can then be activated during inference by a\nbackdoor trigger to fully control the model's behavior. While such attacks are\nvery effective, they crucially rely on the adversary injecting arbitrary inputs\nthat are---often blatantly---mislabeled. Such samples would raise suspicion\nupon human inspection, potentially revealing the attack. Thus, for backdoor\nattacks to remain undetected, it is crucial that they maintain\nlabel-consistency---the condition that injected inputs are consistent with\ntheir labels. In this work, we leverage adversarial perturbations and\ngenerative models to execute efficient, yet label-consistent, backdoor attacks.\nOur approach is based on injecting inputs that appear plausible, yet are hard\nto classify, hence causing the model to rely on the (easier-to-learn) backdoor\ntrigger.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:05:59 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 23:16:45 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Turner", "Alexander", ""], ["Tsipras", "Dimitris", ""], ["Madry", "Aleksander", ""]]}, {"id": "1912.02781", "submitter": "Balaji Lakshminarayanan", "authors": "Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer,\n  Balaji Lakshminarayanan", "title": "AugMix: A Simple Data Processing Method to Improve Robustness and\n  Uncertainty", "comments": "Code available at https://github.com/google-research/augmix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks can achieve high accuracy when the training\ndistribution and test distribution are identically distributed, but this\nassumption is frequently violated in practice. When the train and test\ndistributions are mismatched, accuracy can plummet. Currently there are few\ntechniques that improve robustness to unforeseen data shifts encountered during\ndeployment. In this work, we propose a technique to improve the robustness and\nuncertainty estimates of image classifiers. We propose AugMix, a data\nprocessing technique that is simple to implement, adds limited computational\noverhead, and helps models withstand unforeseen corruptions. AugMix\nsignificantly improves robustness and uncertainty measures on challenging image\nclassification benchmarks, closing the gap between previous methods and the\nbest possible performance in some cases by more than half.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:18:10 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 06:16:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hendrycks", "Dan", ""], ["Mu", "Norman", ""], ["Cubuk", "Ekin D.", ""], ["Zoph", "Barret", ""], ["Gilmer", "Justin", ""], ["Lakshminarayanan", "Balaji", ""]]}, {"id": "1912.02783", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Josip Djolonga, Marvin Ritter, Aravindh Mahendran,\n  Xiaohua Zhai, Neil Houlsby, Sylvain Gelly, Mario Lucic", "title": "Self-Supervised Learning of Video-Induced Visual Invariances", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for self-supervised learning of transferable\nvisual representations based on Video-Induced Visual Invariances (VIVI). We\nconsider the implicit hierarchy present in the videos and make use of (i)\nframe-level invariances (e.g. stability to color and contrast perturbations),\n(ii) shot/clip-level invariances (e.g. robustness to changes in object\norientation and lighting conditions), and (iii) video-level invariances\n(semantic relationships of scenes across shots/clips), to define a holistic\nself-supervised loss. Training models using different variants of the proposed\nframework on videos from the YouTube-8M (YT8M) data set, we obtain\nstate-of-the-art self-supervised transfer learning results on the 19 diverse\ndownstream tasks of the Visual Task Adaptation Benchmark (VTAB), using only\n1000 labels per task. We then show how to co-train our models jointly with\nlabeled images, outperforming an ImageNet-pretrained ResNet-50 by 0.8 points\nwith 10x fewer labeled images, as well as the previous best supervised model by\n3.7 points using the full ImageNet data set.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:20:31 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 18:29:28 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Tschannen", "Michael", ""], ["Djolonga", "Josip", ""], ["Ritter", "Marvin", ""], ["Mahendran", "Aravindh", ""], ["Zhai", "Xiaohua", ""], ["Houlsby", "Neil", ""], ["Gelly", "Sylvain", ""], ["Lucic", "Mario", ""]]}, {"id": "1912.02792", "submitter": "Hugo Bertiche", "authors": "Hugo Bertiche, Meysam Madadi and Sergio Escalera", "title": "CLOTH3D: Clothed 3D Humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CLOTH3D, the first big scale synthetic dataset of 3D\nclothed human sequences. CLOTH3D contains a large variability on garment type,\ntopology, shape, size, tightness and fabric. Clothes are simulated on top of\nthousands of different pose sequences and body shapes, generating realistic\ncloth dynamics. We provide the dataset with a generative model for cloth\ngeneration. We propose a Conditional Variational Auto-Encoder (CVAE) based on\ngraph convolutions (GCVAE) to learn garment latent spaces. This allows for\nrealistic generation of 3D garments on top of SMPL model for any pose and\nshape.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:34:26 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 14:46:05 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bertiche", "Hugo", ""], ["Madadi", "Meysam", ""], ["Escalera", "Sergio", ""]]}, {"id": "1912.02794", "submitter": "Muni Sreenivas Pydi", "authors": "Muni Sreenivas Pydi, Varun Jog", "title": "Adversarial Risk via Optimal Transport and Optimal Couplings", "comments": "Revised version with 43 pages and 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning algorithms perform poorly on adversarially\nmanipulated data. Adversarial risk quantifies the error of classifiers in\nadversarial settings; adversarial classifiers minimize adversarial risk. In\nthis paper, we analyze adversarial risk and adversarial classifiers from an\noptimal transport perspective. We show that the optimal adversarial risk for\nbinary classification with 0-1 loss is determined by an optimal transport cost\nbetween the probability distributions of the two classes. We develop optimal\ntransport plans (probabilistic couplings) for univariate distributions such as\nthe normal, the uniform, and the triangular distribution. We also derive\noptimal adversarial classifiers in these settings. Our analysis leads to\nalgorithm-independent fundamental limits on adversarial risk, which we\ncalculate for several real-world datasets. We extend our results to general\nloss functions under convexity and smoothness assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:39:07 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 04:27:28 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Pydi", "Muni Sreenivas", ""], ["Jog", "Varun", ""]]}, {"id": "1912.02803", "submitter": "Samuel Schoenholz", "authors": "Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander A. Alemi,\n  Jascha Sohl-Dickstein, Samuel S. Schoenholz", "title": "Neural Tangents: Fast and Easy Infinite Neural Networks in Python", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Tangents is a library designed to enable research into infinite-width\nneural networks. It provides a high-level API for specifying complex and\nhierarchical neural network architectures. These networks can then be trained\nand evaluated either at finite-width as usual or in their infinite-width limit.\nInfinite-width networks can be trained analytically using exact Bayesian\ninference or using gradient descent via the Neural Tangent Kernel.\nAdditionally, Neural Tangents provides tools to study gradient descent training\ndynamics of wide but finite networks in either function space or weight space.\n  The entire library runs out-of-the-box on CPU, GPU, or TPU. All computations\ncan be automatically distributed over multiple accelerators with near-linear\nscaling in the number of devices. Neural Tangents is available at\nwww.github.com/google/neural-tangents. We also provide an accompanying\ninteractive Colab notebook.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:51:57 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Novak", "Roman", ""], ["Xiao", "Lechao", ""], ["Hron", "Jiri", ""], ["Lee", "Jaehoon", ""], ["Alemi", "Alexander A.", ""], ["Sohl-Dickstein", "Jascha", ""], ["Schoenholz", "Samuel S.", ""]]}, {"id": "1912.02805", "submitter": "Xingyu Liu", "authors": "Xingyu Liu, Rico Jonschkowski, Anelia Angelova, Kurt Konolige", "title": "KeyPose: Multi-View 3D Labeling and Keypoint Estimation for Transparent\n  Objects", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the 3D pose of desktop objects is crucial for applications such as\nrobotic manipulation. Many existing approaches to this problem require a depth\nmap of the object for both training and prediction, which restricts them to\nopaque, lambertian objects that produce good returns in an RGBD sensor. In this\npaper we forgo using a depth sensor in favor of raw stereo input. We address\ntwo problems: first, we establish an easy method for capturing and labeling 3D\nkeypoints on desktop objects with an RGB camera; and second, we develop a deep\nneural network, called $KeyPose$, that learns to accurately predict object\nposes using 3D keypoints, from stereo input, and works even for transparent\nobjects. To evaluate the performance of our method, we create a dataset of 15\nclear objects in five classes, with 48K 3D-keypoint labeled images. We train\nboth instance and category models, and show generalization to new textures,\nposes, and objects. KeyPose surpasses state-of-the-art performance in 3D pose\nestimation on this dataset by factors of 1.5 to 3.5, even in cases where the\ncompeting method is provided with ground-truth depth. Stereo input is essential\nfor this performance as it improves results compared to using monocular input\nby a factor of 2. We will release a public version of the data capture and\nlabeling pipeline, the transparent object database, and the KeyPose models and\nevaluation code. Project website: https://sites.google.com/corp/view/keypose.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:54:07 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 21:46:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Xingyu", ""], ["Jonschkowski", "Rico", ""], ["Angelova", "Anelia", ""], ["Konolige", "Kurt", ""]]}, {"id": "1912.02807", "submitter": "Jessica Hamrick", "authors": "Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Tobias\n  Pfaff, Theophane Weber, Lars Buesing, Peter W. Battaglia", "title": "Combining Q-Learning and Search with Amortized Value Estimates", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Search with Amortized Value Estimates\" (SAVE), an approach for\ncombining model-free Q-learning with model-based Monte-Carlo Tree Search\n(MCTS). In SAVE, a learned prior over state-action values is used to guide\nMCTS, which estimates an improved set of state-action values. The new\nQ-estimates are then used in combination with real experience to update the\nprior. This effectively amortizes the value computation performed by MCTS,\nresulting in a cooperative relationship between model-free learning and\nmodel-based search. SAVE can be implemented on top of any Q-learning agent with\naccess to a model, which we demonstrate by incorporating it into agents that\nperform challenging physical reasoning tasks and Atari. SAVE consistently\nachieves higher rewards with fewer training steps, and---in contrast to typical\nmodel-based search approaches---yields strong performance with very small\nsearch budgets. By combining real experience with information computed during\nsearch, SAVE demonstrates that it is possible to improve on both the\nperformance of model-free learning and the computational cost of planning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:54:23 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 13:59:10 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hamrick", "Jessica B.", ""], ["Bapst", "Victor", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Pfaff", "Tobias", ""], ["Weber", "Theophane", ""], ["Buesing", "Lars", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "1912.02851", "submitter": "Fabio Valerio Massoli", "authors": "Fabio Valerio Massoli, Giuseppe Amato, Fabrizio Falchi", "title": "Cross-Resolution Learning for Face Recognition", "comments": null, "journal-ref": "Image and Vision Computing Volume 99, July 2020, 103927", "doi": "10.1016/j.imavis.2020.103927", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have reached extremely high performances on the\nFace Recognition task. Largely used datasets, such as VGGFace2, focus on\ngender, pose and age variations trying to balance them to achieve better\nresults. However, the fact that images have different resolutions is not\nusually discussed and resize to 256 pixels before cropping is used. While\nspecific datasets for very low resolution faces have been proposed, less\nattention has been payed on the task of cross-resolution matching. Such\nscenarios are of particular interest for forensic and surveillance systems in\nwhich it usually happens that a low-resolution probe has to be matched with\nhigher-resolution galleries. While it is always possible to either increase the\nresolution of the probe image or to reduce the size of the gallery images, to\nthe best of our knowledge an extensive experimentation of cross-resolution\nmatching was missing in the recent deep learning based literature. In the\ncontext of low- and cross-resolution Face Recognition, the contributions of our\nwork are: i) we proposed a training method to fine-tune a state-of-the-art\nmodel in order to make it able to extract resolution-robust deep features; ii)\nwe tested our models on the benchmark datasets IJB-B/C considering images at\nboth full and low resolutions in order to show the effectiveness of the\nproposed training algorithm. To the best of our knowledge, this is the first\nwork testing extensively the performance of a FR model in a cross-resolution\nscenario; iii) we tested our models on the low resolution and low quality\ndatasets QMUL-SurvFace and TinyFace and showed their superior performances,\neven though we did not train our model on low-resolution faces only and our\nmain focus was cross-resolution; iv) we showed that our approach can be more\neffective with respect to preprocessing faces with super resolution techniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 19:40:35 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Massoli", "Fabio Valerio", ""], ["Amato", "Giuseppe", ""], ["Falchi", "Fabrizio", ""]]}, {"id": "1912.02864", "submitter": "Stanislav Sobolevsky", "authors": "Urwa Muaz, Stanislav Sobolevsky", "title": "Transfer Learning from an Auxiliary Discriminative Task for Unsupervised\n  Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised anomaly detection from high dimensional data like mobility\nnetworks is a challenging task. Study of different approaches of feature\nengineering from such high dimensional data have been a focus of research in\nthis field. This study aims to investigate the transferability of features\nlearned by network classification to unsupervised anomaly detection. We propose\nuse of an auxiliary classification task to extract features from unlabelled\ndata by supervised learning, which can be used for unsupervised anomaly\ndetection. We validate this approach by designing experiments to detect\nanomalies in mobility network data from New York and Taipei, and compare the\nresults to traditional unsupervised feature learning approaches of PCA and\nautoencoders. We find that our feature learning approach yields best anomaly\ndetection performance for both datasets, outperforming other studied\napproaches. This establishes the utility of this approach to feature\nengineering, which can be applied to other problems of similar nature.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 20:26:21 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Muaz", "Urwa", ""], ["Sobolevsky", "Stanislav", ""]]}, {"id": "1912.02875", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map\n  Them to Actions", "comments": "22 pages, 81 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We transform reinforcement learning (RL) into a form of supervised learning\n(SL) by turning traditional RL on its head, calling this Upside Down RL (UDRL).\nStandard RL predicts rewards, while UDRL instead uses rewards as task-defining\ninputs, together with representations of time horizons and other computable\nfunctions of historic and desired future data. UDRL learns to interpret these\ninput observations as commands, mapping them to actions (or action\nprobabilities) through SL on past (possibly accidental) experience. UDRL\ngeneralizes to achieve high rewards or other goals, through input commands such\nas: get lots of reward within at most so much time! A separate paper [63] on\nfirst experiments with UDRL shows that even a pilot version of UDRL can\noutperform traditional baseline algorithms on certain challenging RL problems.\nWe also also conceptually simplify an approach [60] for teaching a robot to\nimitate humans. First videotape humans imitating the robot's current behaviors,\nthen let the robot learn through SL to map the videos (as input commands) to\nthese behaviors, then let it generalize and imitate videos of humans executing\npreviously unknown behavior. This Imitate-Imitator concept may actually explain\nwhy biological evolution has resulted in parents who imitate the babbling of\ntheir babies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:10:08 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:55:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "1912.02877", "submitter": "Rupesh Kumar Srivastava", "authors": "Rupesh Kumar Srivastava, Pranav Shyam, Filipe Mutz, Wojciech\n  Ja\\'skowski, J\\\"urgen Schmidhuber", "title": "Training Agents using Upside-Down Reinforcement Learning", "comments": "NNAISENSE Technical Report. 17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Reinforcement Learning (RL) algorithms either predict rewards\nwith value functions or maximize them using policy search. We study an\nalternative: Upside-Down Reinforcement Learning (Upside-Down RL or UDRL), that\nsolves RL problems primarily using supervised learning techniques. Many of its\nmain principles are outlined in a companion report [34]. Here we present the\nfirst concrete implementation of UDRL and demonstrate its feasibility on\ncertain episodic learning problems. Experimental results show that its\nperformance can be surprisingly competitive with, and even exceed that of\ntraditional baseline algorithms developed over decades of research.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:13:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Srivastava", "Rupesh Kumar", ""], ["Shyam", "Pranav", ""], ["Mutz", "Filipe", ""], ["Ja\u015bkowski", "Wojciech", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1912.02892", "submitter": "Jayson Luc Peterson", "authors": "J. Luc Peterson, Ben Bay, Joe Koning, Peter Robinson, Jessica Semler,\n  Jeremy White, Rushil Anirudh, Kevin Athey, Peer-Timo Bremer, Francesco Di\n  Natale, David Fox, Jim A. Gaffney, Sam A. Jacobs, Bhavya Kailkhura, Bogdan\n  Kustowski, Steven Langer, Brian Spears, Jayaraman Thiagarajan, Brian Van\n  Essen, Jae-Seung Yeom", "title": "Enabling Machine Learning-Ready HPC Ensembles with Merlin", "comments": "28 pages, 9 figures; Submitted to FGCS", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-821884", "categories": "cs.DC cs.LG physics.comp-ph physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing complexity of computational and experimental facilities,\nmany scientific researchers are turning to machine learning (ML) techniques to\nanalyze large scale ensemble data. With complexities such as multi-component\nworkflows, heterogeneous machine architectures, parallel file systems, and\nbatch scheduling, care must be taken to facilitate this analysis in a high\nperformance computing (HPC) environment. In this paper, we present Merlin, a\nworkflow framework to enable large ML-friendly ensembles of scientific HPC\nsimulations. By augmenting traditional HPC with distributed compute\ntechnologies, Merlin aims to lower the barrier for scientific subject matter\nexperts to incorporate ML into their analysis. In addition to its design, we\ndescribe some example applications that Merlin has enabled on leadership-class\nHPC resources, such as the ML-augmented optimization of nuclear fusion\nexperiments and the calibration of infectious disease models to study the\nprogression of and possible mitigation strategies for COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:40:07 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 21:52:14 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Peterson", "J. Luc", ""], ["Bay", "Ben", ""], ["Koning", "Joe", ""], ["Robinson", "Peter", ""], ["Semler", "Jessica", ""], ["White", "Jeremy", ""], ["Anirudh", "Rushil", ""], ["Athey", "Kevin", ""], ["Bremer", "Peer-Timo", ""], ["Di Natale", "Francesco", ""], ["Fox", "David", ""], ["Gaffney", "Jim A.", ""], ["Jacobs", "Sam A.", ""], ["Kailkhura", "Bhavya", ""], ["Kustowski", "Bogdan", ""], ["Langer", "Steven", ""], ["Spears", "Brian", ""], ["Thiagarajan", "Jayaraman", ""], ["Van Essen", "Brian", ""], ["Yeom", "Jae-Seung", ""]]}, {"id": "1912.02893", "submitter": "Miguel L\\'azaro-Gredilla", "authors": "Miguel Lazaro-Gredilla, Wolfgang Lehrach, Dileep George", "title": "Learning undirected models via query training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical amortized inference in variational autoencoders is specialized for a\nsingle probabilistic query. Here we propose an inference network architecture\nthat generalizes to unseen probabilistic queries. Instead of an encoder-decoder\npair, we can train a single inference network directly from data, using a cost\nfunction that is stochastic not only over samples, but also over queries. We\ncan use this network to perform the same inference tasks as we would in an\nundirected graphical model with hidden variables, without having to deal with\nthe intractable partition function. The results can be mapped to the learning\nof an actual undirected model, which is a notoriously hard problem. Our network\nalso marginalizes nuisance variables as required. We show that our approach\ngeneralizes to unseen probabilistic queries on also unseen test data, providing\nfast and flexible inference. Experiments show that this approach outperforms or\nmatches PCD and AdVIL on 9 benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 21:42:52 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Lazaro-Gredilla", "Miguel", ""], ["Lehrach", "Wolfgang", ""], ["George", "Dileep", ""]]}, {"id": "1912.02906", "submitter": "Guannan Qu", "authors": "Guannan Qu, Adam Wierman, Na Li", "title": "Scalable Reinforcement Learning of Localized Policies for Multi-Agent\n  Networked Systems", "comments": "Added experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning (RL) in a setting with a network of agents\nwhose states and actions interact in a local manner where the objective is to\nfind localized policies such that the (discounted) global reward is maximized.\nA fundamental challenge in this setting is that the state-action space size\nscales exponentially in the number of agents, rendering the problem intractable\nfor large networks. In this paper, we propose a Scalable Actor-Critic (SAC)\nframework that exploits the network structure and finds a localized policy that\nis a $O(\\rho^\\kappa)$-approximation of a stationary point of the objective for\nsome $\\rho\\in(0,1)$, with complexity that scales with the local state-action\nspace size of the largest $\\kappa$-hop neighborhood of the network.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:44:07 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:42:18 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Qu", "Guannan", ""], ["Wierman", "Adam", ""], ["Li", "Na", ""]]}, {"id": "1912.02907", "submitter": "Ukash Nakarmi", "authors": "Jeffrey Ma, Ukash Nakarmi, Cedric Yue Sik Kin, Christopher Sandino,\n  Joseph Y. Cheng, Ali B. Syed, Peter Wei, John M. Pauly, Shreyas Vasanawala", "title": "Diagnostic Image Quality Assessment and Classification in Medical\n  Imaging: Opportunities and Challenges", "comments": "4 pages, 8 Figures, Conference Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic Resonance Imaging (MRI) suffers from several artifacts, the most\ncommon of which are motion artifacts. These artifacts often yield images that\nare of non-diagnostic quality. To detect such artifacts, images are\nprospectively evaluated by experts for their diagnostic quality, which\nnecessitates patient-revisits and rescans whenever non-diagnostic quality scans\nare encountered. This motivates the need to develop an automated framework\ncapable of accessing medical image quality and detecting diagnostic and\nnon-diagnostic images. In this paper, we explore several convolutional neural\nnetwork-based frameworks for medical image quality assessment and investigate\nseveral challenges therein.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:44:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Ma", "Jeffrey", ""], ["Nakarmi", "Ukash", ""], ["Kin", "Cedric Yue Sik", ""], ["Sandino", "Christopher", ""], ["Cheng", "Joseph Y.", ""], ["Syed", "Ali B.", ""], ["Wei", "Peter", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas", ""]]}, {"id": "1912.02911", "submitter": "Davood Karimi", "authors": "Davood Karimi, Haoran Dou, Simon K. Warfield, Ali Gholipour", "title": "Deep learning with noisy labels: exploring techniques and remedies in\n  medical image analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Supervised training of deep learning models requires large labeled datasets.\nThere is a growing interest in obtaining such datasets for medical image\nanalysis applications. However, the impact of label noise has not received\nsufficient attention. Recent studies have shown that label noise can\nsignificantly impact the performance of deep learning models in many machine\nlearning and computer vision applications. This is especially concerning for\nmedical applications, where datasets are typically small, labeling requires\ndomain expertise and suffers from high inter- and intra-observer variability,\nand erroneous predictions may influence decisions that directly impact human\nhealth. In this paper, we first review the state-of-the-art in handling label\nnoise in deep learning. Then, we review studies that have dealt with label\nnoise in deep learning for medical image analysis. Our review shows that recent\nprogress on handling label noise in deep learning has gone largely unnoticed by\nthe medical image analysis community. To help achieve a better understanding of\nthe extent of the problem and its potential remedies, we conducted experiments\nwith three medical imaging datasets with different types of label noise, where\nwe investigated several existing strategies and developed new methods to combat\nthe negative effect of label noise. Based on the results of these experiments\nand our review of the literature, we have made recommendations on methods that\ncan be used to alleviate the effects of different types of label noise on deep\nmodels trained for medical image analysis. We hope that this article helps the\nmedical image analysis researchers and developers in choosing and devising new\ntechniques that effectively handle label noise in deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:58:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 16:14:37 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 04:18:09 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 22:45:57 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Karimi", "Davood", ""], ["Dou", "Haoran", ""], ["Warfield", "Simon K.", ""], ["Gholipour", "Ali", ""]]}, {"id": "1912.02915", "submitter": "Reza Soleymanifar", "authors": "Reza Soleymanifar, Amber Srivastava, Carolyn Beck, Srinivasa Salapaka", "title": "A Clustering Approach to Edge Controller Placement in Software Defined\n  Networks with Cost Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce two novel deterministic annealing based clustering\nalgorithms to address the problem of Edge Controller Placement (ECP) in\nwireless edge networks. These networks lie at the core of the fifth generation\n(5G) wireless systems and beyond. These algorithms, ECP-LL and ECP-LB, address\nthe dominant leader-less and leader-based controller placement topologies and\nhave linear computational complexity in terms of network size, maximum number\nof clusters and dimensionality of data. Each algorithm tries to place\ncontrollers close to edge node clusters and not far away from other controllers\nto maintain a reasonable balance between synchronization and delay costs. While\nthe ECP problem can be conveniently expressed as a multi-objective mixed\ninteger non-linear program (MINLP), our algorithms outperform state of art\nMINLP solver, BARON both in terms of accuracy and speed. Our proposed\nalgorithms have the competitive edge of avoiding poor local minima through a\nShannon entropy term in the clustering objective function. Most ECP algorithms\nare highly susceptible to poor local minima and greatly depend on\ninitialization.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:07:35 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Soleymanifar", "Reza", ""], ["Srivastava", "Amber", ""], ["Beck", "Carolyn", ""], ["Salapaka", "Srinivasa", ""]]}, {"id": "1912.02918", "submitter": "Fabio Valerio Massoli", "authors": "Fabio Valerio Massoli, Fabio Carrara, Giuseppe Amato, Fabrizio Falchi", "title": "Detection of Face Recognition Adversarial Attacks", "comments": null, "journal-ref": "Computer Vision and Image Understanding Volume 202, January 2021,\n  103103", "doi": "10.1016/j.cviu.2020.103103", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning methods have become state-of-the-art for solving tasks such as\nFace Recognition (FR). Unfortunately, despite their success, it has been\npointed out that these learning models are exposed to adversarial inputs -\nimages to which an imperceptible amount of noise for humans is added to\nmaliciously fool a neural network - thus limiting their adoption in real-world\napplications. While it is true that an enormous effort has been spent in order\nto train robust models against this type of threat, adversarial detection\ntechniques have recently started to draw attention within the scientific\ncommunity. A detection approach has the advantage that it does not require to\nre-train any model, thus it can be added on top of any system. In this context,\nwe present our work on adversarial samples detection in forensics mainly\nfocused on detecting attacks against FR systems in which the learning model is\ntypically used only as a features extractor. Thus, in these cases, train a more\nrobust classifier might not be enough to defence a FR system. In this frame,\nthe contribution of our work is four-fold: i) we tested our recently proposed\nadversarial detection approach against classifier attacks, i.e. adversarial\nsamples crafted to fool a FR neural network acting as a classifier; ii) using a\nk-Nearest Neighbor (kNN) algorithm as a guidance, we generated deep features\nattacks against a FR system based on a DL model acting as features extractor,\nfollowed by a kNN which gives back the query identity based on features\nsimilarity; iii) we used the deep features attacks to fool a FR system on the\n1:1 Face Verification task and we showed their superior effectiveness with\nrespect to classifier attacks in fooling such type of system; iv) we used the\ndetectors trained on classifier attacks to detect deep features attacks, thus\nshowing that such approach is generalizable to different types of offensives.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:24:33 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Massoli", "Fabio Valerio", ""], ["Carrara", "Fabio", ""], ["Amato", "Giuseppe", ""], ["Falchi", "Fabrizio", ""]]}, {"id": "1912.02919", "submitter": "Stephanie L. Hyland", "authors": "Stephanie L. Hyland and Shruti Tople", "title": "An Empirical Study on the Intrinsic Privacy of SGD", "comments": "17 pages, 11 figures, 7 tables; v3 edits: emphasised empirical nature\n  of work, added more analyses, fixed some errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take the first step towards understanding whether the intrinsic randomness\nof stochastic gradient descent (SGD) can be leveraged for privacy, for any\ngiven dataset and model. In doing so, we hope to mitigate the trade-off between\nprivacy and performance for models trained with differential-privacy (DP)\nguarantees. Our main contribution is a large-scale empirical analysis of SGD on\nconvex and non-convex objectives, on four datasets. We evaluate the inherent\nvariability in SGD and calculate the intrinsic data-dependent\n$\\epsilon_i(\\mathcal{D})$ values due to the inherent noise. We show that the\nvariability in model parameters due to random sampling almost always exceeds\nthat due to changes in the data. We show that the existing theoretical bound on\nthe sensitivity of SGD with convex objectives is not tight. For logistic\nregression, we observe that SGD provides intrinsic $\\epsilon_i(\\mathcal{D})$\nvalues between 3.95 and 23.10 across four datasets, dropping to between 1.25\nand 4.22 using the tight empirical sensitivity bound. For neural networks, we\nreport high $\\epsilon_i(\\mathcal{D})$ values (>40) owing to their larger\nparameter count. Next, we propose a method to augment the intrinsic noise of\nSGD to achieve the desired target $\\epsilon$. Our augmented SGD produces models\nthat outperform existing approaches with the same privacy target, closing the\ngap to noiseless utility between 0.03% and 36.31% for logistic regression. We\nfurther explore the role of the number of steps of SGD, and demonstrate that\nour estimates are stable. Our experiments provide concrete evidence that\nchanging the seed in SGD has a far greater impact on the model's weights than\nexcluding any given training example. By accounting for this intrinsic\nrandomness - subject to necessary assumptions, we can achieve a consistent and\nstatistically significant improvement in utility, without sacrificing further\nprivacy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:28:05 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:08:31 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 11:46:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hyland", "Stephanie L.", ""], ["Tople", "Shruti", ""]]}, {"id": "1912.02927", "submitter": "Manoj Penmetcha", "authors": "Manoj Penmetcha, Shyam Sundar Kannan, Byung-Cheol Min", "title": "Smart Cloud: Scalable Cloud Robotic Architecture for Web-powered\n  Multi-Robot Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots have inherently limited onboard processing, storage, and power\ncapabilities. Cloud computing resources have the potential to provide\nsignificant advantages for robots in many applications. However, to make use of\nthese resources, frameworks must be developed that facilitate robot\ninteractions with cloud services. In this paper, we propose a cloud-based\narchitecture called Smart Cloud that intends to overcome the physical\nlimitations of single- or multi-robot systems through massively parallel\ncomputation, provided on demand by cloud services. Smart Cloud is implemented\non Amazon Web Services (AWS) and available for robots running on the Robot\nOperating System (ROS) and on the non-ROS systems. Smart Cloud features a\nfirst-of-its-kind architecture that incorporates JavaScript-based libraries to\nrun various robotic applications related to machine learning and other methods.\nThis paper presents the architecture and its performance in terms of CPU usage\nand latency, and finally validates it for navigation and machine learning\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 00:12:50 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:00:47 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 08:24:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Penmetcha", "Manoj", ""], ["Kannan", "Shyam Sundar", ""], ["Min", "Byung-Cheol", ""]]}, {"id": "1912.02937", "submitter": "Shaofei Wang", "authors": "Shaofei Wang, Vishnu Lokhande, Maneesh Singh, Konrad Kording, Julian\n  Yarkony", "title": "End-to-end Training of CNN-CRF via Differentiable Dual-Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer vision (CV) is often based on convolutional neural networks\n(CNNs) that excel at hierarchical feature extraction. The previous generation\nof CV approaches was often based on conditional random fields (CRFs) that excel\nat modeling flexible higher order interactions. As their benefits are\ncomplementary they are often combined. However, these approaches generally use\nmean-field approximations and thus, arguably, did not directly optimize the\nreal problem. Here we revisit dual-decomposition-based approaches to CRF\noptimization, an alternative to the mean-field approximation. These algorithms\ncan efficiently and exactly solve sub-problems and directly optimize a convex\nupper bound of the real problem, providing optimality certificates on the way.\nOur approach uses a novel fixed-point iteration algorithm which enjoys\ndual-monotonicity, dual-differentiability and high parallelism. The whole\nsystem, CRF and CNN can thus be efficiently trained using back-propagation. We\ndemonstrate the effectiveness of our system on semantic image segmentation,\nshowing consistent improvement over baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 00:49:48 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wang", "Shaofei", ""], ["Lokhande", "Vishnu", ""], ["Singh", "Maneesh", ""], ["Kording", "Konrad", ""], ["Yarkony", "Julian", ""]]}, {"id": "1912.02938", "submitter": "Akshay Kamath", "authors": "Akshay Kamath and Sushrut Karmalkar and Eric Price", "title": "Lower Bounds for Compressed Sensing with Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of compressed sensing is to learn a structured signal $x$ from a\nlimited number of noisy linear measurements $y \\approx Ax$. In traditional\ncompressed sensing, \"structure\" is represented by sparsity in some known basis.\nInspired by the success of deep learning in modeling images, recent work\nstarting with~\\cite{BJPD17} has instead considered structure to come from a\ngenerative model $G: \\mathbb{R}^k \\to \\mathbb{R}^n$. We present two results\nestablishing the difficulty of this latter task, showing that existing bounds\nare tight. First, we provide a lower bound matching the~\\cite{BJPD17} upper\nbound for compressed sensing from $L$-Lipschitz generative models $G$. In\nparticular, there exists such a function that requires roughly $\\Omega(k \\log\nL)$ linear measurements for sparse recovery to be possible. This holds even for\nthe more relaxed goal of \\emph{nonuniform} recovery. Second, we show that\ngenerative models generalize sparsity as a representation of structure. In\nparticular, we construct a ReLU-based neural network $G: \\mathbb{R}^{2k} \\to\n\\mathbb{R}^n$ with $O(1)$ layers and $O(kn)$ activations per layer, such that\nthe range of $G$ contains all $k$-sparse vectors.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 00:51:51 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Kamath", "Akshay", ""], ["Karmalkar", "Sushrut", ""], ["Price", "Eric", ""]]}, {"id": "1912.02942", "submitter": "Junyu Chen", "authors": "Junyu Chen, Ye Li, Yong Du, Eric C. Frey", "title": "Generating Anthropomorphic Phantoms Using Fully Unsupervised Deformable\n  Image Registration with Convolutional Neural Networks", "comments": null, "journal-ref": "Med. Phys., 47: 6366-6380 (2020)", "doi": "10.1002/mp.14545", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: Computerized phantoms play an essential role in various\napplications of medical imaging research. Although the existing computerized\nphantoms can model anatomical variations through organ and phantom scaling,\nthis does not provide a way to fully reproduce anatomical variations seen in\nhumans. However, having a population of phantoms that models the variations in\npatient anatomy and, in nuclear medicine, uptake realization is essential for\ncomprehensive validation and training. In this work, we present a novel image\nregistration method for creating highly anatomically detailed anthropomorphic\nphantoms from a single digital phantom. Methods: We propose a\ndeep-learning-based registration algorithm to predict deformation parameters\nfor warping an XCAT phantom to a patient CT scan. This proposed algorithm\noptimizes a novel SSIM-based objective function for a given image pair\nindependently of the training data and thus is truly and fully unsupervised. We\nevaluate the proposed method on a publicly available low-dose CT dataset from\nTCIA. Results: The performance of the proposed model was compared with that of\nseveral state-of-the-art methods, and outperformed them by more than 8%,\nmeasured by the SSIM and less than 30%, by the MSE. Conclusion: A\ndeep-learning-based unsupervised registration method was developed to create\nanthropomorphic phantoms while providing \"gold-standard\" anatomies that can be\nused as the basis for modeling organ properties. Significance: Experimental\nresults demonstrate the effectiveness of the proposed method. The resulting\nanthropomorphic phantom is highly realistic. Combined with realistic\nsimulations of the image formation process, the generated phantoms could serve\nin many applications of medical imaging research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:31:34 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 16:39:13 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 20:41:37 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Junyu", ""], ["Li", "Ye", ""], ["Du", "Yong", ""], ["Frey", "Eric C.", ""]]}, {"id": "1912.02943", "submitter": "P. M. Krafft", "authors": "Michael Katell, Meg Young, Bernease Herman, Dharma Dailey, Aaron Tam,\n  Vivian Guetler, Corinne Binz, Daniella Raz, P. M. Krafft", "title": "An Algorithmic Equity Toolkit for Technology Audits by Community\n  Advocates and Activists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wave of recent scholarship documenting the discriminatory harms of\nalgorithmic systems has spurred widespread interest in algorithmic\naccountability and regulation. Yet effective accountability and regulation is\nstymied by a persistent lack of resources supporting public understanding of\nalgorithms and artificial intelligence. Through interactions with a US-based\ncivil rights organization and their coalition of community organizations, we\nidentify a need for (i) heuristics that aid stakeholders in distinguishing\nbetween types of analytic and information systems in lay language, and (ii)\nrisk assessment tools for such systems that begin by making algorithms more\nlegible. The present work delivers a toolkit to achieve these aims. This paper\nboth presents the Algorithmic Equity Toolkit (AEKit) Equity as an artifact, and\ndetails how our participatory process shaped its design. Our work fits within\nhuman-computer interaction scholarship as a demonstration of the value of HCI\nmethods and approaches to problems in the area of algorithmic transparency and\naccountability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:32:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Katell", "Michael", ""], ["Young", "Meg", ""], ["Herman", "Bernease", ""], ["Dailey", "Dharma", ""], ["Tam", "Aaron", ""], ["Guetler", "Vivian", ""], ["Binz", "Corinne", ""], ["Raz", "Daniella", ""], ["Krafft", "P. M.", ""]]}, {"id": "1912.02945", "submitter": "Thanh-Trung Trinh", "authors": "Thanh-Trung Trinh, Dinh-Minh Vu, Masaomi Kimura", "title": "A pedestrian path-planning model in accordance with obstacle's danger\n  with reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.1145/3388176.3388187", "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most microscopic pedestrian navigation models use the concept of \"forces\"\napplied to the pedestrian agents to replicate the navigation environment. While\nthe approach could provide believable results in regular situations, it does\nnot always resemble natural pedestrian navigation behaviour in many typical\nsettings. In our research, we proposed a novel approach using reinforcement\nlearning for simulation of pedestrian agent path planning and collision\navoidance problem. The primary focus of this approach is using human perception\nof the environment and danger awareness of interferences. The implementation of\nour model has shown that the path planned by the agent shares many similarities\nwith a human pedestrian in several aspects such as following common walking\nconventions and human behaviours.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:40:43 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Trinh", "Thanh-Trung", ""], ["Vu", "Dinh-Minh", ""], ["Kimura", "Masaomi", ""]]}, {"id": "1912.02947", "submitter": "Zhaoqiang Chen", "authors": "Zhaoqiang Chen, Qun Chen, Boyi Hou, Tianyi Duan, Zhanhuai Li and\n  Guoliang Li", "title": "Towards Interpretable and Learnable Risk Analysis for Entity Resolution", "comments": "14 pages, Accepted to SIGMOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning-based entity resolution has been widely studied. However,\nsome entity pairs may be mislabeled by machine learning models and existing\nstudies do not study the risk analysis problem -- predicting and interpreting\nwhich entity pairs are mislabeled. In this paper, we propose an interpretable\nand learnable framework for risk analysis, which aims to rank the labeled pairs\nbased on their risks of being mislabeled. We first describe how to\nautomatically generate interpretable risk features, and then present a\nlearnable risk model and its training technique. Finally, we empirically\nevaluate the performance of the proposed approach on real data. Our extensive\nexperiments have shown that the learning risk model can identify the mislabeled\npairs with considerably higher accuracy than the existing alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:59:43 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Chen", "Zhaoqiang", ""], ["Chen", "Qun", ""], ["Hou", "Boyi", ""], ["Duan", "Tianyi", ""], ["Li", "Zhanhuai", ""], ["Li", "Guoliang", ""]]}, {"id": "1912.02958", "submitter": "Zhengkun Tian", "authors": "Zhengkun Tian, Jiangyan Yi, Ye Bai, Jianhua Tao, Shuai Zhang, Zhengqi\n  Wen", "title": "Synchronous Transformers for End-to-End Speech Recognition", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most of the attention-based sequence-to-sequence models, the decoder\npredicts the output sequence conditioned on the entire input sequence processed\nby the encoder. The asynchronous problem between the encoding and decoding\nmakes these models difficult to be applied for online speech recognition. In\nthis paper, we propose a model named synchronous transformer to address this\nproblem, which can predict the output sequence chunk by chunk. Once a\nfixed-length chunk of the input sequence is processed by the encoder, the\ndecoder begins to predict symbols immediately. During training, a\nforward-backward algorithm is introduced to optimize all the possible alignment\npaths. Our model is evaluated on a Mandarin dataset AISHELL-1. The experiments\nshow that the synchronous transformer is able to perform encoding and decoding\nsynchronously, and achieves a character error rate of 8.91% on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 03:05:12 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 03:49:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tian", "Zhengkun", ""], ["Yi", "Jiangyan", ""], ["Bai", "Ye", ""], ["Tao", "Jianhua", ""], ["Zhang", "Shuai", ""], ["Wen", "Zhengqi", ""]]}, {"id": "1912.02967", "submitter": "Dustin Morrill", "authors": "Ryan D'Orazio, Dustin Morrill, James R. Wright, Michael Bowling", "title": "Alternative Function Approximation Parameterizations for Solving Games:\n  An Analysis of $f$-Regression Counterfactual Regret Minimization", "comments": "11 pages, includes appendix", "journal-ref": "Nineteenth International Conference on Autonomous Agents and\n  Multi-Agent Systems, 9-13 May 2020, Auckland, New Zealand", "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function approximation is a powerful approach for structuring large decision\nproblems that has facilitated great achievements in the areas of reinforcement\nlearning and game playing. Regression counterfactual regret minimization (RCFR)\nis a simple algorithm for approximately solving imperfect information games\nwith normalized rectified linear unit (ReLU) parameterized policies. In\ncontrast, the more conventional softmax parameterization is standard in the\nfield of reinforcement learning and yields a regret bound with a better\ndependence on the number of actions. We derive approximation error-aware regret\nbounds for $(\\Phi, f)$-regret matching, which applies to a general class of\nlink functions and regret objectives. These bounds recover a tighter bound for\nRCFR and provide a theoretical justification for RCFR implementations with\nalternative policy parameterizations ($f$-RCFR), including softmax. We provide\nexploitability bounds for $f$-RCFR with the polynomial and exponential link\nfunctions in zero-sum imperfect information games and examine empirically how\nthe link function interacts with the severity of the approximation. We find\nthat the previously studied ReLU parameterization performs better when the\napproximation error is small while the softmax parameterization can perform\nbetter when the approximation error is large.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 03:32:29 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 20:40:46 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 19:30:16 GMT"}, {"version": "v4", "created": "Mon, 27 Apr 2020 20:33:50 GMT"}, {"version": "v5", "created": "Fri, 1 May 2020 15:01:30 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["D'Orazio", "Ryan", ""], ["Morrill", "Dustin", ""], ["Wright", "James R.", ""], ["Bowling", "Michael", ""]]}, {"id": "1912.02968", "submitter": "Alexandre Tartakovsky", "authors": "QiZhi He and David Brajas-Solano and Guzel Tartakovsky and Alexandre\n  M. Tartakovsky", "title": "Physics-Informed Neural Networks for Multiphysics Data Assimilation with\n  Application to Subsurface Transport", "comments": null, "journal-ref": null, "doi": "10.1016/j.advwatres.2020.103610", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data assimilation for parameter and state estimation in subsurface transport\nproblems remains a significant challenge due to the sparsity of measurements,\nthe heterogeneity of porous media, and the high computational cost of forward\nnumerical models. We present a physics-informed deep neural networks (DNNs)\nmachine learning method for estimating space-dependent hydraulic conductivity,\nhydraulic head, and concentration fields from sparse measurements. In this\napproach, we employ individual DNNs to approximate the unknown parameters\n(e.g., hydraulic conductivity) and states (e.g., hydraulic head and\nconcentration) of a physical system, and jointly train these DNNs by minimizing\nthe loss function that consists of the governing equations residuals in\naddition to the error with respect to measurement data. We apply this approach\nto assimilate conductivity, hydraulic head, and concentration measurements for\njoint inversion of the conductivity, hydraulic head, and concentration fields\nin a steady-state advection--dispersion problem. We study the accuracy of the\nphysics-informed DNN approach with respect to data size, number of variables\n(conductivity and head versus conductivity, head, and concentration), DNNs\nsize, and DNN initialization during training. We demonstrate that the\nphysics-informed DNNs are significantly more accurate than standard data-driven\nDNNs when the training set consists of sparse data. We also show that the\naccuracy of parameter estimation increases as additional variables are inverted\njointly.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 03:33:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["He", "QiZhi", ""], ["Brajas-Solano", "David", ""], ["Tartakovsky", "Guzel", ""], ["Tartakovsky", "Alexandre M.", ""]]}, {"id": "1912.02973", "submitter": "Albert Zhao", "authors": "Albert Zhao and Tong He and Yitao Liang and Haibin Huang and Guy Van\n  den Broeck and Stefano Soatto", "title": "SAM: Squeeze-and-Mimic Networks for Conditional Visual Driving Policy\n  Learning", "comments": "Conference on Robot Learning (CoRL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a policy learning approach to map visual inputs to driving\ncontrols conditioned on turning command that leverages side tasks on semantics\nand object affordances via a learned representation trained for driving. To\nlearn this representation, we train a squeeze network to drive using\nannotations for the side task as input. This representation encodes the\ndriving-relevant information associated with the side task while ideally\nthrowing out side task-relevant but driving-irrelevant nuisances. We then train\na mimic network to drive using only images as input and use the squeeze\nnetwork's latent representation to supervise the mimic network via a mimicking\nloss. Notably, we do not aim to achieve the side task nor to learn features for\nit; instead, we aim to learn, via the mimicking loss, a representation of the\nside task annotations directly useful for driving. We test our approach using\nthe CARLA simulator. In addition, we introduce a more challenging but realistic\nevaluation protocol that considers a run that reaches the destination\nsuccessful only if it does not violate common traffic rules. A video\nsummarizing this work is available at https://youtu.be/ipKAMzmJpMs , and code\nis available at https://github.com/twsq/sam-driving .\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 04:41:51 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 07:50:13 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhao", "Albert", ""], ["He", "Tong", ""], ["Liang", "Yitao", ""], ["Huang", "Haibin", ""], ["Broeck", "Guy Van den", ""], ["Soatto", "Stefano", ""]]}, {"id": "1912.02975", "submitter": "Xingyou Song", "authors": "Xingyou Song, Yiding Jiang, Stephen Tu, Yilun Du, Behnam Neyshabur", "title": "Observational Overfitting in Reinforcement Learning", "comments": "Published as a conference paper in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major component of overfitting in model-free reinforcement learning (RL)\ninvolves the case where the agent may mistakenly correlate reward with certain\nspurious features from the observations generated by the Markov Decision\nProcess (MDP). We provide a general framework for analyzing this scenario,\nwhich we use to design multiple synthetic benchmarks from only modifying the\nobservation space of an MDP. When an agent overfits to different observation\nspaces even if the underlying MDP dynamics is fixed, we term this observational\noverfitting. Our experiments expose intriguing properties especially with\nregards to implicit regularization, and also corroborate results from previous\nworks in RL generalization and supervised learning (SL).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 04:52:16 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 04:04:43 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Song", "Xingyou", ""], ["Jiang", "Yiding", ""], ["Tu", "Stephen", ""], ["Du", "Yilun", ""], ["Neyshabur", "Behnam", ""]]}, {"id": "1912.02983", "submitter": "Eli (Omid) David", "authors": "Katia Huri, Eli David, Nathan S. Netanyahu", "title": "DeepEthnic: Multi-Label Ethnic Classification from Face Images", "comments": null, "journal-ref": "International Conference on Artificial Neural Networks (ICANN),\n  Springer LNCS, Vol. 11141, pp. 604-612, Rhodes, Greece, October 2018", "doi": "10.1007/978-3-030-01424-7_59", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethnic group classification is a well-researched problem, which has been\npursued mainly during the past two decades via traditional approaches of image\nprocessing and machine learning. In this paper, we propose a method of\nclassifying an image face into an ethnic group by applying transfer learning\nfrom a previously trained classification network for large-scale data\nrecognition. Our proposed method yields state-of-the-art success rates of\n99.02%, 99.76%, 99.2%, and 96.7%, respectively, for the four ethnic groups:\nAfrican, Asian, Caucasian, and Indian.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 05:59:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Huri", "Katia", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.02984", "submitter": "Qiangeng Xu", "authors": "Qiangeng Xu, Xudong Sun, Cho-Ying Wu, Panqu Wang, Ulrich Neumann", "title": "Grid-GCN for Fast and Scalable Point Cloud Learning", "comments": null, "journal-ref": "Proceedings of the IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR 2020)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the sparsity and irregularity of the point cloud data, methods that\ndirectly consume points have become popular. Among all point-based models,\ngraph convolutional networks (GCN) lead to notable performance by fully\npreserving the data granularity and exploiting point interrelation. However,\npoint-based networks spend a significant amount of time on data structuring\n(e.g., Farthest Point Sampling (FPS) and neighbor points querying), which limit\nthe speed and scalability. In this paper, we present a method, named Grid-GCN,\nfor fast and scalable point cloud learning. Grid-GCN uses a novel data\nstructuring strategy, Coverage-Aware Grid Query (CAGQ). By leveraging the\nefficiency of grid space, CAGQ improves spatial coverage while reducing the\ntheoretical time complexity. Compared with popular sampling methods such as\nFarthest Point Sampling (FPS) and Ball Query, CAGQ achieves up to 50X speed-up.\nWith a Grid Context Aggregation (GCA) module, Grid-GCN achieves\nstate-of-the-art performance on major point cloud classification and\nsegmentation benchmarks with significantly faster runtime than previous\nstudies. Remarkably, Grid-GCN achieves the inference speed of 50fps on ScanNet\nusing 81920 points per scene as input.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 05:59:40 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 01:38:35 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 22:44:27 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 05:32:33 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 03:37:00 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Qiangeng", ""], ["Sun", "Xudong", ""], ["Wu", "Cho-Ying", ""], ["Wang", "Panqu", ""], ["Neumann", "Ulrich", ""]]}, {"id": "1912.02986", "submitter": "Fei Feng Ms.", "authors": "Fei Feng, Wotao Yin, Lin F. Yang", "title": "How Does an Approximate Model Help in Reinforcement Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key approaches to save samples in reinforcement learning (RL) is\nto use knowledge from an approximate model such as its simulator. However, how\nmuch does an approximate model help to learn a near-optimal policy of the true\nunknown model? Despite numerous empirical studies of transfer reinforcement\nlearning, an answer to this question is still elusive. In this paper, we study\nthe sample complexity of RL while an approximate model of the environment is\nprovided. For an unknown Markov decision process (MDP), we show that the\napproximate model can effectively reduce the complexity by eliminating\nsub-optimal actions from the policy searching space. In particular, we provide\nan algorithm that uses $\\widetilde{O}(N/(1-\\gamma)^3/\\varepsilon^2)$ samples in\na generative model to learn an $\\varepsilon$-optimal policy, where $\\gamma$ is\nthe discount factor and $N$ is the number of near-optimal actions in the\napproximate model. This can be much smaller than the learning-from-scratch\ncomplexity $\\widetilde{\\Theta}(SA/(1-\\gamma)^3/\\varepsilon^2)$, where $S$ and\n$A$ are the sizes of state and action spaces respectively. We also provide a\nlower bound showing that the above upper bound is nearly-tight if the value gap\nbetween near-optimal actions and sub-optimal actions in the approximate model\nis sufficiently large. Our results provide a very precise characterization of\nhow an approximate model helps reinforcement learning when no additional\nassumption on the model is posed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:05:59 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:42:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Feng", "Fei", ""], ["Yin", "Wotao", ""], ["Yang", "Lin F.", ""]]}, {"id": "1912.02989", "submitter": "Ziming Liu", "authors": "Ziming Liu, Yixuan Wang, Zizhao Han and Dian Wu", "title": "Influenza Modeling Based on Massive Feature Engineering and\n  International Flow Deconvolution", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we focus on the analysis of the potential factors driving\nthe spread of influenza, and possible policies to mitigate the adverse effects\nof the disease. To be precise, we first invoke discrete Fourier transform (DFT)\nto conclude a yearly periodic regional structure in the influenza activity,\nthus safely restricting ourselves to the analysis of the yearly influenza\nbehavior. Then we collect a massive number of possible region-wise indicators\ncontributing to the influenza mortality, such as consumption, immunization,\nsanitation, water quality, and other indicators from external data, with $1170$\ndimensions in total. We extract significant features from the high dimensional\nindicators using a combination of data analysis techniques, including matrix\ncompletion, support vector machines (SVM), autoencoders, and principal\ncomponent analysis (PCA). Furthermore, we model the international flow of\nmigration and trade as a convolution on regional influenza activity, and solve\nthe deconvolution problem as higher-order perturbations to the linear\nregression, thus separating regional and international factors related to the\ninfluenza mortality. Finally, both the original model and the perturbed model\nare tested on regional examples, as validations of our models. Pertaining to\nthe policy, we make a proposal based on the connectivity data along with the\npreviously extracted significant features to alleviate the impact of influenza,\nas well as efficiently propagate and carry out the policies. We conclude that\nenvironmental features and economic features are of significance to the\ninfluenza mortality. The model can be easily adapted to model other types of\ninfectious diseases.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:11:31 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Liu", "Ziming", ""], ["Wang", "Yixuan", ""], ["Han", "Zizhao", ""], ["Wu", "Dian", ""]]}, {"id": "1912.02990", "submitter": "Preslav Nakov", "authors": "Sara Rosenthal, Preslav Nakov, Alan Ritter, Veselin Stoyanov", "title": "SemEval-2014 Task 9: Sentiment Analysis in Twitter", "comments": "Sentiment analysis, microblog sentiment analysis, Twitter opinion\n  mining, sarcasm, LiveJournal, SMS", "journal-ref": "SemEval-2014", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Sentiment Analysis in Twitter task, ran as part of\nSemEval-2014. It is a continuation of the last year's task that ran\nsuccessfully as part of SemEval-2013. As in 2013, this was the most popular\nSemEval task; a total of 46 teams contributed 27 submissions for subtask A (21\nteams) and 50 submissions for subtask B (44 teams). This year, we introduced\nthree new test sets: (i) regular tweets, (ii) sarcastic tweets, and (iii)\nLiveJournal sentences. We further tested on (iv) 2013 tweets, and (v) 2013 SMS\nmessages. The highest F1-score on (i) was achieved by NRC-Canada at 86.63 for\nsubtask A and by TeamX at 70.96 for subtask B.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:23:19 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Rosenthal", "Sara", ""], ["Nakov", "Preslav", ""], ["Ritter", "Alan", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1912.02992", "submitter": "Jiahao Su", "authors": "Jiahao Su, Milan Cvitkovic, Furong Huang", "title": "Sampling-Free Learning of Bayesian Quantized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian learning of model parameters in neural networks is important in\nscenarios where estimates with well-calibrated uncertainty are important. In\nthis paper, we propose Bayesian quantized networks (BQNs), quantized neural\nnetworks (QNNs) for which we learn a posterior distribution over their discrete\nparameters. We provide a set of efficient algorithms for learning and\nprediction in BQNs without the need to sample from their parameters or\nactivations, which not only allows for differentiable learning in QNNs, but\nalso reduces the variance in gradients. We evaluate BQNs on MNIST,\nFashion-MNIST, KMNIST and CIFAR10 image classification datasets, compared\nagainst bootstrap ensemble of QNNs (E-QNN). We demonstrate BQNs achieve both\nlower predictive errors and better-calibrated uncertainties than E-QNN (with\nless than 20% of the negative log-likelihood).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:27:06 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Su", "Jiahao", ""], ["Cvitkovic", "Milan", ""], ["Huang", "Furong", ""]]}, {"id": "1912.02997", "submitter": "Tomohiko Mizutani", "authors": "Tomohiko Mizutani", "title": "Improved Analysis of Spectral Algorithm for Clustering", "comments": "20 pages. Revised Theorem 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral algorithms are graph partitioning algorithms that partition a node\nset of a graph into groups by using a spectral embedding map. Clustering\ntechniques based on the algorithms are referred to as spectral clustering and\nare widely used in data analysis. To gain a better understanding of why\nspectral clustering is successful, Peng et al. (2015) and Kolev and Mehlhorn\n(2016) studied the behavior of a certain type of spectral algorithm for a class\nof graphs, called well-clustered graphs. Specifically, they put an assumption\non graphs and showed the performance guarantee of the spectral algorithm under\nit. The algorithm they studied used the spectral embedding map developed by Shi\nand Malic (2000). In this paper, we improve on their results, giving a better\nperformance guarantee under a weaker assumption. We also evaluate the\nperformance of the spectral algorithm with the spectral embedding map developed\nby Ng et al. (2001).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:32:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:59:34 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 07:29:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Mizutani", "Tomohiko", ""]]}, {"id": "1912.02998", "submitter": "Preslav Nakov", "authors": "Francisco Guzm\\'an, Llu\\'is M\\`arquez, Preslav Nakov", "title": "Machine Translation Evaluation Meets Community Question Answering", "comments": "community question answering, machine translation evaluation,\n  pairwise ranking, learning to rank", "journal-ref": "Annual meeting of the Association for Computational Linguistics\n  (ACL-2016)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the applicability of machine translation evaluation (MTE) methods\nto a very different problem: answer ranking in community Question Answering. In\nparticular, we adopt a pairwise neural network (NN) architecture, which\nincorporates MTE features, as well as rich syntactic and semantic embeddings,\nand which efficiently models complex non-linear interactions. The evaluation\nresults show state-of-the-art performance, with sizeable contribution from both\nthe MTE features and from the pairwise NN architecture.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 06:35:21 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Guzm\u00e1n", "Francisco", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.03011", "submitter": "Chengchao Zhao", "authors": "Zhi-Qin John Xu, Jiwei Zhang, Yaoyu Zhang, Chengchao Zhao", "title": "A priori generalization error for two-layer ReLU neural network through\n  minimum norm solution", "comments": "There is a error in this paper that the scale of initialization in\n  this paper is different from the NTK regime. So, the generalization error of\n  the neural network in the NTK regime is baseless", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on estimating \\emph{a priori} generalization error of two-layer ReLU\nneural networks (NNs) trained by mean squared error, which only depends on\ninitial parameters and the target function, through the following research\nline. We first estimate \\emph{a priori} generalization error of finite-width\ntwo-layer ReLU NN with constraint of minimal norm solution, which is proved by\n\\cite{zhang2019type} to be an equivalent solution of a linearized (w.r.t.\nparameter) finite-width two-layer NN. As the width goes to infinity, the\nlinearized NN converges to the NN in Neural Tangent Kernel (NTK) regime\n\\citep{jacot2018neural}. Thus, we can derive the \\emph{a priori} generalization\nerror of two-layer ReLU NN in NTK regime. The distance between NN in a NTK\nregime and a finite-width NN with gradient training is estimated by\n\\cite{arora2019exact}. Based on the results in \\cite{arora2019exact}, our work\nproves an \\emph{a priori} generalization error bound of two-layer ReLU NNs.\nThis estimate uses the intrinsic implicit bias of the minimum norm solution\nwithout requiring extra regularity in the loss function. This \\emph{a priori}\nestimate also implies that NN does not suffer from curse of dimensionality, and\na small generalization error can be achieved without requiring exponentially\nlarge number of neurons. In addition the research line proposed in this paper\ncan also be used to study other properties of the finite-width network, such as\nthe posterior generalization error.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 08:04:02 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 14:15:21 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 05:47:41 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhang", "Jiwei", ""], ["Zhang", "Yaoyu", ""], ["Zhao", "Chengchao", ""]]}, {"id": "1912.03015", "submitter": "Nam Hee Kim", "authors": "Nam Hee Kim, Zhaoming Xie, and Michiel van de Panne", "title": "Learning to Correspond Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many dynamical systems exhibit similar structure, as often captured by\nhand-designed simplified models that can be used for analysis and control. We\ndevelop a method for learning to correspond pairs of dynamical systems via a\nlearned latent dynamical system. Given trajectory data from two dynamical\nsystems, we learn a shared latent state space and a shared latent dynamics\nmodel, along with an encoder-decoder pair for each of the original systems.\nWith the learned correspondences in place, we can use a simulation of one\nsystem to produce an imagined motion of its counterpart. We can also simulate\nin the learned latent dynamics and synthesize the motions of both corresponding\nsystems, as a form of bisimulation. We demonstrate the approach using pairs of\ncontrolled bipedal walkers, as well as by pairing a walker with a controlled\npendulum.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 08:21:49 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 23:25:07 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 20:39:08 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kim", "Nam Hee", ""], ["Xie", "Zhaoming", ""], ["van de Panne", "Michiel", ""]]}, {"id": "1912.03026", "submitter": "Weijian Pan", "authors": "Liang Huang, Weijian Pan, You Zhang, LiPing Qian, Nan Gao and Yuan Wu", "title": "Data Augmentation for Deep Learning-based Radio Modulation\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently been applied to automatically classify the\nmodulation categories of received radio signals without manual experience.\nHowever, training deep learning models requires massive volume of data. An\ninsufficient training data will cause serious overfitting problem and degrade\nthe classification accuracy. To cope with small dataset, data augmentation has\nbeen widely used in image processing to expand the dataset and improve the\nrobustness of deep learning models. However, in wireless communication areas,\nthe effect of different data augmentation methods on radio modulation\nclassification has not been studied yet. In this paper, we evaluate different\ndata augmentation methods via a state-of-the-art deep learning-based modulation\nclassifier. Based on the characteristics of modulated signals, three\naugmentation methods are considered, i.e., rotation, flip, and Gaussian noise,\nwhich can be applied in both training phase and inference phase of the deep\nlearning algorithm. Numerical results show that all three augmentation methods\ncan improve the classification accuracy. Among which, the rotation augmentation\nmethod outperforms the flip method, both of which achieve higher classification\naccuracy than the Gaussian noise method. Given only 12.5% of training dataset,\na joint rotation and flip augmentation policy can achieve even higher\nclassification accuracy than the baseline with initial 100% training dataset\nwithout augmentation. Furthermore, with data augmentation, radio modulation\ncategories can be successfully classified using shorter radio samples, leading\nto a simplified deep learning model and shorter the classification response\ntime.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 08:56:43 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 01:30:52 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Huang", "Liang", ""], ["Pan", "Weijian", ""], ["Zhang", "You", ""], ["Qian", "LiPing", ""], ["Gao", "Nan", ""], ["Wu", "Yuan", ""]]}, {"id": "1912.03035", "submitter": "Marcus Bloice", "authors": "Marcus D. Bloice, Peter M. Roth, Andreas Holzinger", "title": "Performing Arithmetic Using a Neural Network Trained on Digit\n  Permutation Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neural network is trained to perform simple arithmetic using\nimages of concatenated handwritten digit pairs. A convolutional neural network\nwas trained with images consisting of two side-by-side handwritten digits,\nwhere the image's label is the summation of the two digits contained in the\ncombined image. Crucially, the network was tested on permutation pairs that\nwere not present during training in an effort to see if the network could learn\nthe task of addition, as opposed to simply mapping images to labels. A dataset\nwas generated for all possible permutation pairs of length 2 for the digits 0-9\nusing MNIST as a basis for the images, with one thousand samples generated for\neach permutation pair. For testing the network, samples generated from\npreviously unseen permutation pairs were fed into the trained network, and its\npredictions measured. Results were encouraging, with the network achieving an\naccuracy of over 90% on some permutation train/test splits. This suggests that\nthe network learned at first digit recognition, and subsequently the further\ntask of addition based on the two recognised digits. As far as the authors are\naware, no previous work has concentrated on learning a mathematical operation\nin this way.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:23:25 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Bloice", "Marcus D.", ""], ["Roth", "Peter M.", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1912.03036", "submitter": "Vera Shalaeva", "authors": "Vera Shalaeva (LIG), Alireza Fakhrizadeh Esfahani (CRIStAL), Pascal\n  Germain (SIERRA), Mihaly Petreczky (CRIStAL)", "title": "Improved PAC-Bayesian Bounds for Linear Regression", "comments": null, "journal-ref": "Thirty-Fourth AAAI Conference on Artificial Intelligence, Feb\n  2020, New York, United States", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we improve the PAC-Bayesian error bound for linear regression\nderived in Germain et al. [10]. The improvements are twofold. First, the\nproposed error bound is tighter, and converges to the generalization loss with\na well-chosen temperature parameter. Second, the error bound also holds for\ntraining data that are not independently sampled. In particular, the error\nbound applies to certain time series generated by well-known classes of\ndynamical models, such as ARX models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:24:56 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Shalaeva", "Vera", "", "LIG"], ["Esfahani", "Alireza Fakhrizadeh", "", "CRIStAL"], ["Germain", "Pascal", "", "SIERRA"], ["Petreczky", "Mihaly", "", "CRIStAL"]]}, {"id": "1912.03041", "submitter": "Wenya Wang", "authors": "Wenya Wang and Sinno Jialin Pan", "title": "Integrating Deep Learning with Logic Fusion for Information Extraction", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction (IE) aims to produce structured information from an\ninput text, e.g., Named Entity Recognition and Relation Extraction. Various\nattempts have been proposed for IE via feature engineering or deep learning.\nHowever, most of them fail to associate the complex relationships inherent in\nthe task itself, which has proven to be especially crucial. For example, the\nrelation between 2 entities is highly dependent on their entity types. These\ndependencies can be regarded as complex constraints that can be efficiently\nexpressed as logical rules. To combine such logic reasoning capabilities with\nlearning capabilities of deep neural networks, we propose to integrate logical\nknowledge in the form of first-order logic into a deep learning system, which\ncan be trained jointly in an end-to-end manner. The integrated framework is\nable to enhance neural outputs with knowledge regularization via logic rules,\nand at the same time update the weights of logic rules to comply with the\ncharacteristics of the training data. We demonstrate the effectiveness and\ngeneralization of the proposed model on multiple IE tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:38:23 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Wang", "Wenya", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "1912.03046", "submitter": "Yiding Zhang", "authors": "Yiding Zhang, Xiao Wang, Xunqiang Jiang, Chuan Shi, Yanfang Ye", "title": "Hyperbolic Graph Attention Network", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) has shown superior performance in dealing with\ngraphs, which has attracted considerable research attention recently. However,\nmost of the existing GNN models are primarily designed for graphs in Euclidean\nspaces. Recent research has proven that the graph data exhibits non-Euclidean\nlatent anatomy. Unfortunately, there was rarely study of GNN in non-Euclidean\nsettings so far. To bridge this gap, in this paper, we study the GNN with\nattention mechanism in hyperbolic spaces at the first attempt. The research of\nhyperbolic GNN has some unique challenges: since the hyperbolic spaces are not\nvector spaces, the vector operations (e.g., vector addition, subtraction, and\nscalar multiplication) cannot be carried. To tackle this problem, we employ the\ngyrovector spaces, which provide an elegant algebraic formalism for hyperbolic\ngeometry, to transform the features in a graph; and then we propose the\nhyperbolic proximity based attention mechanism to aggregate the features.\nMoreover, as mathematical operations in hyperbolic spaces could be more\ncomplicated than those in Euclidean spaces, we further devise a novel\nacceleration strategy using logarithmic and exponential mappings to improve the\nefficiency of our proposed model. The comprehensive experimental results on\nfour real-world datasets demonstrate the performance of our proposed hyperbolic\ngraph attention network model, by comparisons with other state-of-the-art\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:54:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Zhang", "Yiding", ""], ["Wang", "Xiao", ""], ["Jiang", "Xunqiang", ""], ["Shi", "Chuan", ""], ["Ye", "Yanfang", ""]]}, {"id": "1912.03048", "submitter": "Adrien Guille", "authors": "Jean Dupuy and Adrien Guille and Julien Jacques", "title": "Document Network Embedding: Coping for Missing Content and Missing Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Searching through networks of documents is an important task. A promising\npath to improve the performance of information retrieval systems in this\ncontext is to leverage dense node and content representations learned with\nembedding techniques. However, these techniques cannot learn representations\nfor documents that are either isolated or whose content is missing. To tackle\nthis issue, assuming that the topology of the network and the content of the\ndocuments correlate, we propose to estimate the missing node representations\nfrom the available content representations, and conversely. Inspired by recent\nadvances in machine translation, we detail in this paper how to learn a linear\ntransformation from a set of aligned content and node representations. The\nprojection matrix is efficiently calculated in terms of the singular value\ndecomposition. The usefulness of the proposed method is highlighted by the\nimproved ability to predict the neighborhood of nodes whose links are\nunobserved based on the projected content representations, and to retrieve\nsimilar documents when content is missing, based on the projected node\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 10:09:20 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Dupuy", "Jean", ""], ["Guille", "Adrien", ""], ["Jacques", "Julien", ""]]}, {"id": "1912.03049", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort, Andrei Stoian, David Filliat", "title": "Regularization Shortcomings for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most machine learning algorithms, training data is assumed to be\nindependent and identically distributed (iid). When it is not the case, the\nalgorithm's performances are challenged, leading to the famous phenomenon of\ncatastrophic forgetting. Algorithms dealing with it are gathered in the\nContinual Learning research field. In this paper, we study the regularization\nbased approaches to continual learning and show that those approaches can not\nlearn to discriminate classes from different tasks in an elemental continual\nbenchmark: the class-incremental scenario. We make theoretical reasoning to\nprove this shortcoming and illustrate it with examples and experiments.\nMoreover, we show that it can have some important consequences on continual\nmulti-tasks reinforcement learning or in pre-trained models used for continual\nlearning. We believe that highlighting and understanding the shortcomings of\nregularization strategies will help us to use them more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 10:11:18 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 12:10:55 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 17:25:56 GMT"}, {"version": "v4", "created": "Sun, 4 Apr 2021 00:21:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""], ["Stoian", "Andrei", ""], ["Filliat", "David", ""]]}, {"id": "1912.03063", "submitter": "Corentin Kervadec", "authors": "Corentin Kervadec (LIRIS), Grigory Antipov, Moez Baccouche, Christian\n  Wolf (LIRIS)", "title": "Weak Supervision helps Emergence of Word-Object Alignment and improves\n  Vision-Language Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large adoption of the self-attention (i.e. transformer model) and\nBERT-like training principles has recently resulted in a number of high\nperforming models on a large panoply of vision-and-language problems (such as\nVisual Question Answering (VQA), image retrieval, etc.). In this paper we claim\nthat these State-Of-The-Art (SOTA) approaches perform reasonably well in\nstructuring information inside a single modality but, despite their impressive\nperformances , they tend to struggle to identify fine-grained inter-modality\nrelationships. Indeed, such relations are frequently assumed to be implicitly\nlearned during training from application-specific losses, mostly cross-entropy\nfor classification. While most recent works provide inductive bias for\ninter-modality relationships via cross attention modules, in this work, we\ndemonstrate (1) that the latter assumption does not hold, i.e. modality\nalignment does not necessarily emerge automatically, and (2) that adding weak\nsupervision for alignment between visual objects and words improves the quality\nof the learned models on tasks requiring reasoning. In particular , we\nintegrate an object-word alignment loss into SOTA vision-language reasoning\nmodels and evaluate it on two tasks VQA and Language-driven Comparison of\nImages. We show that the proposed fine-grained inter-modality supervision\nsignificantly improves performance on both tasks. In particular, this new\nlearning signal allows obtaining SOTA-level performances on GQA dataset (VQA\ntask) with pre-trained models without finetuning on the task, and a new SOTA on\nNLVR2 dataset (Language-driven Comparison of Images). Finally, we also\nillustrate the impact of the contribution on the models reasoning by\nvisualizing attention distributions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 11:04:08 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Kervadec", "Corentin", "", "LIRIS"], ["Antipov", "Grigory", "", "LIRIS"], ["Baccouche", "Moez", "", "LIRIS"], ["Wolf", "Christian", "", "LIRIS"]]}, {"id": "1912.03074", "submitter": "Emilie Kaufmann", "authors": "Cindy Trinh (ENS Paris Saclay), Emilie Kaufmann (CNRS, CRIStAL,\n  SEQUEL), Claire Vernade, Richard Combes (L2S)", "title": "Solving Bernoulli Rank-One Bandits with Unimodal Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Rank-One Bandits (Katarya et al, (2017a,b)) are a simple framework\nfor regret minimization problems over rank-one matrices of arms. The initially\nproposed algorithms are proved to have logarithmic regret, but do not match the\nexisting lower bound for this problem. We close this gap by first proving that\nrank-one bandits are a particular instance of unimodal bandits, and then\nproviding a new analysis of Unimodal Thompson Sampling (UTS), initially\nproposed by Paladino et al (2017). We prove an asymptotically optimal regret\nbound on the frequentist regret of UTS and we support our claims with\nsimulations showing the significant improvement of our method compared to the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 11:53:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Trinh", "Cindy", "", "ENS Paris Saclay"], ["Kaufmann", "Emilie", "", "CNRS, CRIStAL,\n  SEQUEL"], ["Vernade", "Claire", "", "L2S"], ["Combes", "Richard", "", "L2S"]]}, {"id": "1912.03120", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Mohammad H. Jafari, Sidney Fels, Theresa Tsang, Purang\n  Abolmaesumi", "title": "A Study into Echocardiography View Conversion", "comments": "Workshop of Medical Imaging Meets NeurIPS, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transthoracic echo is one of the most common means of cardiac studies in the\nclinical routines. During the echo exam, the sonographer captures a set of\nstandard cross sections (echo views) of the heart. Each 2D echo view cuts\nthrough the 3D cardiac geometry via a unique plane. Consequently, different\nviews share some limited information. In this work, we investigate the\nfeasibility of generating a 2D echo view using another view based on\nadversarial generative models. The objective optimized to train the\nview-conversion model is based on the ideas introduced by LSGAN, PatchGAN and\nConditional GAN (cGAN). The size and length of the left ventricle in the\ngenerated target echo view is compared against that of the target ground-truth\nto assess the validity of the echo view conversion. Results show that there is\na correlation of 0.50 between the LV areas and 0.49 between the LV lengths of\nthe generated target frames and the real target frames.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:44:59 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Abdi", "Amir H.", ""], ["Jafari", "Mohammad H.", ""], ["Fels", "Sidney", ""], ["Tsang", "Theresa", ""], ["Abolmaesumi", "Purang", ""]]}, {"id": "1912.03126", "submitter": "Nicolas Rougier", "authors": "Ikram Chraibi Kaadoud and Nicolas P. Rougier and Fr\\'ed\\'eric\n  Alexandre", "title": "Knowledge extraction from the learning of sequences in a long short term\n  memory (LSTM) architecture", "comments": "18 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a general method to extract knowledge from a recurrent neural\nnetwork (Long Short Term Memory) that has learnt to detect if a given input\nsequence is valid or not, according to an unknown generative automaton. Based\non the clustering of the hidden states, we explain how to build and validate an\nautomaton that corresponds to the underlying (unknown) automaton, and allows to\npredict if a given sequence is valid or not. The method is illustrated on\nartificial grammars (Reber's grammar variations) as well as on a real use-case\nwhose underlying grammar is unknown.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 14:00:21 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Kaadoud", "Ikram Chraibi", ""], ["Rougier", "Nicolas P.", ""], ["Alexandre", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1912.03130", "submitter": "Md Mahfuzur Rahman", "authors": "U. Mahmood, M. M. Rahman, A. Fedorov, Z. Fu, V. D. Calhoun, S. M. Plis", "title": "Learnt dynamics generalizes across tasks, datasets, and populations", "comments": "11 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1911.06813", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differentiating multivariate dynamic signals is a difficult learning problem\nas the feature space may be large yet often only a few training examples are\navailable. Traditional approaches to this problem either proceed from\nhandcrafted features or require large datasets to combat the m >> n problem. In\nthis paper, we show that the source of the problem---signal dynamics---can be\nused to our advantage and noticeably improve classification performance on a\nrange of discrimination tasks when training data is scarce. We demonstrate that\nself-supervised pre-training guided by signal dynamics produces embedding that\ngeneralizes across tasks, datasets, data collection sites, and data\ndistributions. We perform an extensive evaluation of this approach on a range\nof tasks including simulated data, keyword detection problem, and a range of\nfunctional neuroimaging data, where we show that a single embedding learnt on\nhealthy subjects generalizes across a number of disorders, age groups, and\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:21:50 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mahmood", "U.", ""], ["Rahman", "M. M.", ""], ["Fedorov", "A.", ""], ["Fu", "Z.", ""], ["Calhoun", "V. D.", ""], ["Plis", "S. M.", ""]]}, {"id": "1912.03132", "submitter": "Vladimir Kobzar", "authors": "Vladimir A. Kobzar, Robert V. Kohn, Zhilei Wang", "title": "New Potential-Based Bounds for the Geometric-Stopping Version of\n  Prediction with Expert Advice", "comments": "To appear in MSML2020. arXiv admin note: text overlap with\n  arXiv:1911.01641", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the classic machine learning problem of online prediction\nwith expert advice. A new potential-based framework for the fixed horizon\nversion of this problem has been recently developed using verification\narguments from optimal control theory. This paper extends this framework to the\nrandom (geometric) stopping version. To obtain explicit bounds, we construct\npotentials for the geometric version from potentials used for the fixed horizon\nversion of the problem. This construction leads to new explicit lower and upper\nbounds associated with specific adversary and player strategies. While there\nare several known lower bounds in the fixed horizon setting, our lower bounds\nappear to be the first such results in the geometric stopping setting with an\narbitrary number of experts. Our framework also leads in some cases to improved\nupper bounds. For two and three experts, our bounds are optimal to leading\norder.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 03:53:55 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:00:22 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Kobzar", "Vladimir A.", ""], ["Kohn", "Robert V.", ""], ["Wang", "Zhilei", ""]]}, {"id": "1912.03133", "submitter": "Aristotelis Papadopoulos", "authors": "Aristotelis-Angelos Papadopoulos, Nazim Shaikh, Mohammad Reza Rajati", "title": "Why Should we Combine Training and Post-Training Methods for\n  Out-of-Distribution Detection?", "comments": "Preprint, 9 pages. arXiv admin note: text overlap with\n  arXiv:1906.03509", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to achieve superior results in classification\ntasks. However, it has been recently shown that they are incapable to detect\nexamples that are generated by a distribution which is different than the one\nthey have been trained on since they are making overconfident prediction for\nOut-Of-Distribution (OOD) examples. OOD detection has attracted a lot of\nattention recently. In this paper, we review some of the most seminal recent\nalgorithms in the OOD detection field, we divide those methods into training\nand post-training and we experimentally show how the combination of the former\nwith the latter can achieve state-of-the-art results in the OOD detection task.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 04:24:14 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Papadopoulos", "Aristotelis-Angelos", ""], ["Shaikh", "Nazim", ""], ["Rajati", "Mohammad Reza", ""]]}, {"id": "1912.03135", "submitter": "Preslav Nakov", "authors": "Francisco Guzman, Shafiq Joty, Lluis Marquez, Preslav Nakov", "title": "Pairwise Neural Machine Translation Evaluation", "comments": "machine translation evaluation, machine translation, pairwise\n  ranking, learning to rank. arXiv admin note: substantial text overlap with\n  arXiv:1710.02095", "journal-ref": "Conference of the Association for Computational Linguistics\n  (ACL'2015)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for machine translation evaluation using neural\nnetworks in a pairwise setting, where the goal is to select the better\ntranslation from a pair of hypotheses, given the reference translation. In this\nframework, lexical, syntactic and semantic information from the reference and\nthe two hypotheses is compacted into relatively small distributed vector\nrepresentations, and fed into a multi-layer neural network that models the\ninteraction between each of the hypotheses and the reference, as well as\nbetween the two hypotheses. These compact representations are in turn based on\nword and sentence embeddings, which are learned using neural networks. The\nframework is flexible, allows for efficient learning and classification, and\nyields correlation with humans that rivals the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:17:05 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Guzman", "Francisco", ""], ["Joty", "Shafiq", ""], ["Marquez", "Lluis", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.03154", "submitter": "Tim Zajic", "authors": "Tim Zajic", "title": "Non-asymptotic error bounds for scaled underdamped Langevin MCMC", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have derived non-asymptotic upper bounds for convergence of\nunderdamped Langevin MCMC. We revisit these bound and consider introducing\nscaling terms in the underlying underdamped Langevin equation. In particular,\nwe provide conditions under which an appropriate scaling allows to improve the\nerror bounds in terms of the condition number of the underlying density of\ninterest.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 14:39:04 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Zajic", "Tim", ""]]}, {"id": "1912.03192", "submitter": "Sven Gowal", "authors": "Sven Gowal, Chongli Qin, Po-Sen Huang, Taylan Cemgil, Krishnamurthy\n  Dvijotham, Timothy Mann, Pushmeet Kohli", "title": "Achieving Robustness in the Wild via Adversarial Mixing with\n  Disentangled Representations", "comments": "Accepted at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has made the surprising finding that state-of-the-art deep\nlearning models sometimes fail to generalize to small variations of the input.\nAdversarial training has been shown to be an effective approach to overcome\nthis problem. However, its application has been limited to enforcing invariance\nto analytically defined transformations like $\\ell_p$-norm bounded\nperturbations. Such perturbations do not necessarily cover plausible real-world\nvariations that preserve the semantics of the input (such as a change in\nlighting conditions). In this paper, we propose a novel approach to express and\nformalize robustness to these kinds of real-world transformations of the input.\nThe two key ideas underlying our formulation are (1) leveraging disentangled\nrepresentations of the input to define different factors of variations, and (2)\ngenerating new input images by adversarially composing the representations of\ndifferent images. We use a StyleGAN model to demonstrate the efficacy of this\nframework. Specifically, we leverage the disentangled latent representations\ncomputed by a StyleGAN model to generate perturbations of an image that are\nsimilar to real-world variations (like adding make-up, or changing the\nskin-tone of a person) and train models to be invariant to these perturbations.\nExtensive experiments show that our method improves generalization and reduces\nthe effect of spurious correlations (reducing the error rate of a \"smile\"\ndetector by 21% for example).\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:56:53 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 09:33:57 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Gowal", "Sven", ""], ["Qin", "Chongli", ""], ["Huang", "Po-Sen", ""], ["Cemgil", "Taylan", ""], ["Dvijotham", "Krishnamurthy", ""], ["Mann", "Timothy", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1912.03193", "submitter": "Luca Sabbioni", "authors": "Lorenzo Bisi, Luca Sabbioni, Edoardo Vittori, Matteo Papini, Marcello\n  Restelli", "title": "Risk-Averse Trust Region Optimization for Reward-Volatility Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world decision-making problems, for instance in the fields of\nfinance, robotics or autonomous driving, keeping uncertainty under control is\nas important as maximizing expected returns. Risk aversion has been addressed\nin the reinforcement learning literature through risk measures related to the\nvariance of returns. However, in many cases, the risk is measured not only on a\nlong-term perspective, but also on the step-wise rewards (e.g., in trading, to\nensure the stability of the investment bank, it is essential to monitor the\nrisk of portfolio positions on a daily basis). In this paper, we define a novel\nmeasure of risk, which we call reward volatility, consisting of the variance of\nthe rewards under the state-occupancy measure. We show that the reward\nvolatility bounds the return variance so that reducing the former also\nconstrains the latter. We derive a policy gradient theorem with a new objective\nfunction that exploits the mean-volatility relationship, and develop an\nactor-only algorithm. Furthermore, thanks to the linearity of the Bellman\nequations defined under the new objective function, it is possible to adapt the\nwell-known policy gradient algorithms with monotonic improvement guarantees\nsuch as TRPO in a risk-averse manner. Finally, we test the proposed approach in\ntwo simulated financial environments.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:57:06 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Bisi", "Lorenzo", ""], ["Sabbioni", "Luca", ""], ["Vittori", "Edoardo", ""], ["Papini", "Matteo", ""], ["Restelli", "Marcello", ""]]}, {"id": "1912.03194", "submitter": "Jingzhao Zhang", "authors": "Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim,\n  Sashank J Reddi, Sanjiv Kumar, Suvrit Sra", "title": "Why are Adaptive Methods Good for Attention Models?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While stochastic gradient descent (SGD) is still the \\emph{de facto}\nalgorithm in deep learning, adaptive methods like Clipped SGD/Adam have been\nobserved to outperform SGD across important tasks, such as attention models.\nThe settings under which SGD performs poorly in comparison to adaptive methods\nare not well understood yet. In this paper, we provide empirical and\ntheoretical evidence that a heavy-tailed distribution of the noise in\nstochastic gradients is one cause of SGD's poor performance. We provide the\nfirst tight upper and lower convergence bounds for adaptive gradient methods\nunder heavy-tailed noise. Further, we demonstrate how gradient clipping plays a\nkey role in addressing heavy-tailed gradient noise. Subsequently, we show how\nclipping can be applied in practice by developing an \\emph{adaptive}\ncoordinate-wise clipping algorithm (ACClip) and demonstrate its superior\nperformance on BERT pretraining and finetuning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:58:29 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:07:04 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhang", "Jingzhao", ""], ["Karimireddy", "Sai Praneeth", ""], ["Veit", "Andreas", ""], ["Kim", "Seungyeon", ""], ["Reddi", "Sashank J", ""], ["Kumar", "Sanjiv", ""], ["Sra", "Suvrit", ""]]}, {"id": "1912.03201", "submitter": "Rene Larisch", "authors": "Ren\\'e Larisch and Michael Teichmann and Fred H. Hamker", "title": "A Neural Spiking Approach Compared to Deep Feedforward Networks on\n  Stepwise Pixel Erasement", "comments": "Published in ICANN 2018: Artificial Neural Networks and Machine\n  Learning - ICANN 2018\n  https://link.springer.com/chapter/10.1007/978-3-030-01418-6_25 The final\n  authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-01418-6_25", "journal-ref": null, "doi": "10.1007/978-3-030-01418-6_25", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world scenarios, objects are often partially occluded. This requires\na robustness for object recognition against these perturbations. Convolutional\nnetworks have shown good performances in classification tasks. The learned\nconvolutional filters seem similar to receptive fields of simple cells found in\nthe primary visual cortex. Alternatively, spiking neural networks are more\nbiological plausible. We developed a two layer spiking network, trained on\nnatural scenes with a biologically plausible learning rule. It is compared to\ntwo deep convolutional neural networks using a classification task of stepwise\npixel erasement on MNIST. In comparison to these networks the spiking approach\nachieves good accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:08:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Larisch", "Ren\u00e9", ""], ["Teichmann", "Michael", ""], ["Hamker", "Fred H.", ""]]}, {"id": "1912.03207", "submitter": "Boyang Deng", "authors": "Boyang Deng, JP Lewis, Timothy Jeruzalski, Gerard Pons-Moll, Geoffrey\n  Hinton, Mohammad Norouzi, Andrea Tagliasacchi", "title": "NASA: Neural Articulated Shape Approximation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient representation of articulated objects such as human bodies is an\nimportant problem in computer vision and graphics. To efficiently simulate\ndeformation, existing approaches represent 3D objects using polygonal meshes\nand deform them using skinning techniques. This paper introduces neural\narticulated shape approximation (NASA), an alternative framework that enables\nefficient representation of articulated deformable objects using neural\nindicator functions that are conditioned on pose. Occupancy testing using NASA\nis straightforward, circumventing the complexity of meshes and the issue of\nwater-tightness. We demonstrate the effectiveness of NASA for 3D tracking\napplications, and discuss other potential extensions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:18:35 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 04:23:51 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 14:49:13 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 18:57:24 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Deng", "Boyang", ""], ["Lewis", "JP", ""], ["Jeruzalski", "Timothy", ""], ["Pons-Moll", "Gerard", ""], ["Hinton", "Geoffrey", ""], ["Norouzi", "Mohammad", ""], ["Tagliasacchi", "Andrea", ""]]}, {"id": "1912.03221", "submitter": "Martin Robert", "authors": "Martin Robert, Patrick Dallaire and Philippe Gigu\\`ere", "title": "Tree bark re-identification using a deep-learning feature descriptor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to visually re-identify objects is a fundamental capability in\nvision systems. Oftentimes, it relies on collections of visual signatures based\non descriptors, such as SIFT or SURF. However, these traditional descriptors\nwere designed for a certain domain of surface appearances and geometries\n(limited relief). Consequently, highly-textured surfaces such as tree bark pose\na challenge to them. In turn, this makes it more difficult to use trees as\nidentifiable landmarks for navigational purposes (robotics) or to track felled\nlumber along a supply chain (logistics). We thus propose to use data-driven\ndescriptors trained on bark images for tree surface re-identification. To this\neffect, we collected a large dataset containing 2,400 bark images with strong\nillumination changes, annotated by surface and with the ability to pixel-align\nthem. We used this dataset to sample from more than 2 million 64x64 pixel\npatches to train our novel local descriptors DeepBark and SqueezeBark. Our\nDeepBark method has shown a clear advantage against the hand-crafted\ndescriptors SIFT and SURF. For instance, we demonstrated that DeepBark can\nreach a mAP of 87.2% when retrieving 11 relevant bark images, i.e.\ncorresponding to the same physical surface, to a bark query against 7,900\nimages. Our work thus suggests that re-identifying tree surfaces in a\nchallenging illuminations context is possible. We also make public our dataset,\nwhich can be used to benchmark surface re-identification techniques.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:43:02 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 15:14:40 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Robert", "Martin", ""], ["Dallaire", "Patrick", ""], ["Gigu\u00e8re", "Philippe", ""]]}, {"id": "1912.03223", "submitter": "Mahya Ameryan", "authors": "Mahya Ameryan, Lambert Schomaker", "title": "A limited-size ensemble of homogeneous CNN/LSTMs for high-performance\n  word classification", "comments": null, "journal-ref": "Neural Computing and Applications(2021)", "doi": "10.1007/s00521-020-05612-0", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, long short-term memory neural networks (LSTMs) have been\napplied quite successfully to problems in handwritten text recognition.\nHowever, their strength is more located in handling sequences of variable\nlength than in handling geometric variability of the image patterns.\nFurthermore, the best results for LSTMs are often based on large-scale training\nof an ensemble of network instances. In this paper, an end-to-end convolutional\nLSTM Neural Network is used to handle both geometric variation and sequence\nvariability. We show that high performances can be reached on a common\nbenchmark set by using proper data augmentation for just five such networks\nusing a proper coding scheme and a proper voting scheme. The networks have\nsimilar architectures (Convolutional Neural Network (CNN): five layers,\nbidirectional LSTM (BiLSTM): three layers followed by a connectionist temporal\nclassification (CTC) processing step). The approach assumes differently-scaled\ninput images and different feature map sizes. Two datasets are used for\nevaluation of the performance of our algorithm: A standard benchmark RIMES\ndataset (French), and a historical handwritten dataset KdK (Dutch). Final\nperformance obtained for the word-recognition test of RIMES was 96.6%, a clear\nimprovement over other state-of-the-art approaches. On the KdK dataset, our\napproach also shows good results. The proposed approach is deployed in the Monk\nsearch engine for historical-handwriting collections.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:45:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Ameryan", "Mahya", ""], ["Schomaker", "Lambert", ""]]}, {"id": "1912.03227", "submitter": "Jannik Zuern", "authors": "Jannik Z\\\"urn, Wolfram Burgard, Abhinav Valada", "title": "Self-Supervised Visual Terrain Classification from Unsupervised Acoustic\n  Feature Learning", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robots operating in unknown urban environments encounter a wide range\nof complex terrains to which they must adapt their planned trajectory for safe\nand efficient navigation. Most existing approaches utilize supervised learning\nto classify terrains from either an exteroceptive or a proprioceptive sensor\nmodality. However, this requires a tremendous amount of manual labeling effort\nfor each newly encountered terrain as well as for variations of terrains caused\nby changing environmental conditions. In this work, we propose a novel terrain\nclassification framework leveraging an unsupervised proprioceptive classifier\nthat learns from vehicle-terrain interaction sounds to self-supervise an\nexteroceptive classifier for pixel-wise semantic segmentation of images. To\nthis end, we first learn a discriminative embedding space for vehicle-terrain\ninteraction sounds from triplets of audio clips formed using visual features of\nthe corresponding terrain patches and cluster the resulting embeddings. We\nsubsequently use these clusters to label the visual terrain patches by\nprojecting the traversed tracks of the robot into the camera images. Finally,\nwe use the sparsely labeled images to train our semantic segmentation network\nin a weakly supervised manner. We present extensive quantitative and\nqualitative results that demonstrate that our proprioceptive terrain classifier\nexceeds the state-of-the-art among unsupervised methods and our self-supervised\nexteroceptive semantic segmentation model achieves a comparable performance to\nsupervised learning with manually labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:54:10 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Z\u00fcrn", "Jannik", ""], ["Burgard", "Wolfram", ""], ["Valada", "Abhinav", ""]]}, {"id": "1912.03234", "submitter": "Alejandro Mottini", "authors": "Alejandro Mottini, Amber Roy Chowdhury", "title": "What Do You Mean I'm Funny? Personalizing the Joke Skill of a\n  Voice-Controlled Virtual Assistant", "comments": "Presented at the AAAI 2020 Workshop on Interactive and Conversational\n  Recommendation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A considerable part of the success experienced by Voice-controlled virtual\nassistants (VVA) is due to the emotional and personalized experience they\ndeliver, with humor being a key component in providing an engaging interaction.\nIn this paper we describe methods used to improve the joke skill of a VVA\nthrough personalization. The first method, based on traditional NLP techniques,\nis robust and scalable. The others combine self-attentional network and\nmulti-task learning to obtain better results, at the cost of added complexity.\nA significant challenge facing these systems is the lack of explicit user\nfeedback needed to provide labels for the models. Instead, we explore the use\nof two implicit feedback-based labelling strategies. All models were evaluated\non real production data. Online results show that models trained on any of the\nconsidered labels outperform a heuristic method, presenting a positive\nreal-world impact on user satisfaction. Offline results suggest that the\ndeep-learning approaches can improve the joke experience with respect to the\nother considered methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:17:39 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mottini", "Alejandro", ""], ["Chowdhury", "Amber Roy", ""]]}, {"id": "1912.03241", "submitter": "Eugene Ie", "authors": "Larry Lansing, Vihan Jain, Harsh Mehta, Haoshuo Huang, Eugene Ie", "title": "VALAN: Vision and Language Agent Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  VALAN is a lightweight and scalable software framework for deep reinforcement\nlearning based on the SEED RL architecture. The framework facilitates the\ndevelopment and evaluation of embodied agents for solving grounded language\nunderstanding tasks, such as Vision-and-Language Navigation and\nVision-and-Dialog Navigation, in photo-realistic environments, such as\nMatterport3D and Google StreetView. We have added a minimal set of abstractions\non top of SEED RL allowing us to generalize the architecture to solve a variety\nof other RL problems. In this article, we will describe VALAN's software\nabstraction and architecture, and also present an example of using VALAN to\ndesign agents for instruction-conditioned indoor navigation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:29:43 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Lansing", "Larry", ""], ["Jain", "Vihan", ""], ["Mehta", "Harsh", ""], ["Huang", "Haoshuo", ""], ["Ie", "Eugene", ""]]}, {"id": "1912.03249", "submitter": "Arno Solin", "authors": "Yuxin Hou, Ari Heljakka, Arno Solin", "title": "Gaussian Process Priors for View-Aware Inference", "comments": "Appearing in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While frame-independent predictions with deep neural networks have become the\nprominent solutions to many computer vision tasks, the potential benefits of\nutilizing correlations between frames have received less attention. Even though\nprobabilistic machine learning provides the ability to encode correlation as\nprior knowledge for inference, there is a tangible gap between the theory and\npractice of applying probabilistic methods to modern vision problems. For this,\nwe derive a principled framework to combine information coupling between camera\nposes (translation and orientation) with deep models. We proposed a novel view\nkernel that generalizes the standard periodic kernel in $\\mathrm{SO}(3)$. We\nshow how this soft-prior knowledge can aid several pose-related vision tasks\nlike novel view synthesis and predict arbitrary points in the latent space of\ngenerative models, pointing towards a range of new applications for inter-frame\nreasoning.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:41:37 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 20:02:15 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Hou", "Yuxin", ""], ["Heljakka", "Ari", ""], ["Solin", "Arno", ""]]}, {"id": "1912.03250", "submitter": "Rachel Cummings", "authors": "Uthaipon Tantipongpipat, Chris Waites, Digvijay Boob, Amaresh Ankit\n  Siva, Rachel Cummings", "title": "Differentially Private Synthetic Mixed-Type Data Generation For\n  Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the DP-auto-GAN framework for synthetic data generation, which\ncombines the low dimensional representation of autoencoders with the\nflexibility of Generative Adversarial Networks (GANs). This framework can be\nused to take in raw sensitive data and privately train a model for generating\nsynthetic data that will satisfy similar statistical properties as the original\ndata. This learned model can generate an arbitrary amount of synthetic data,\nwhich can then be freely shared due to the post-processing guarantee of\ndifferential privacy. Our framework is applicable to unlabeled mixed-type data,\nthat may include binary, categorical, and real-valued data. We implement this\nframework on both binary data (MIMIC-III) and mixed-type data (ADULT), and\ncompare its performance with existing private algorithms on metrics in\nunsupervised settings. We also introduce a new quantitative metric able to\ndetect diversity, or lack thereof, of synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:46:07 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 00:46:37 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Tantipongpipat", "Uthaipon", ""], ["Waites", "Chris", ""], ["Boob", "Digvijay", ""], ["Siva", "Amaresh Ankit", ""], ["Cummings", "Rachel", ""]]}, {"id": "1912.03263", "submitter": "Will Grathwohl", "authors": "Will Grathwohl, Kuan-Chieh Wang, J\\\"orn-Henrik Jacobsen, David\n  Duvenaud, Mohammad Norouzi, Kevin Swersky", "title": "Your Classifier is Secretly an Energy Based Model and You Should Treat\n  it Like One", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to reinterpret a standard discriminative classifier of p(y|x) as\nan energy based model for the joint distribution p(x,y). In this setting, the\nstandard class probabilities can be easily computed as well as unnormalized\nvalues of p(x) and p(x|y). Within this framework, standard discriminative\narchitectures may beused and the model can also be trained on unlabeled data.\nWe demonstrate that energy based training of the joint distribution improves\ncalibration, robustness, andout-of-distribution detection while also enabling\nour models to generate samplesrivaling the quality of recent GAN approaches. We\nimprove upon recently proposed techniques for scaling up the training of energy\nbased models and presentan approach which adds little overhead compared to\nstandard classification training. Our approach is the first to achieve\nperformance rivaling the state-of-the-artin both generative and discriminative\nlearning within one hybrid model.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:00:36 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 19:57:55 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 15:40:19 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Grathwohl", "Will", ""], ["Wang", "Kuan-Chieh", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Duvenaud", "David", ""], ["Norouzi", "Mohammad", ""], ["Swersky", "Kevin", ""]]}, {"id": "1912.03264", "submitter": "Guocheng Qian", "authors": "Guocheng Qian and Abdulellah Abualshour and Guohao Li and Ali Thabet\n  and Bernard Ghanem", "title": "PU-GCN: Point Cloud Upsampling using Graph Convolutional Networks", "comments": "Get accepted to CVPR 2021. The source code of this work is available\n  at https://github.com/guochengqian/PU-GCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of learning-based point cloud upsampling pipelines heavily\nrelies on the upsampling modules and feature extractors used therein. For the\npoint upsampling module, we propose a novel model called NodeShuffle, which\nuses a Graph Convolutional Network (GCN) to better encode local point\ninformation from point neighborhoods. NodeShuffle is versatile and can be\nincorporated into any point cloud upsampling pipeline. Extensive experiments\nshow how NodeShuffle consistently improves state-of-the-art upsampling methods.\nFor feature extraction, we also propose a new multi-scale point feature\nextractor, called Inception DenseGCN. By aggregating features at multiple\nscales, this feature extractor enables further performance gain in the final\nupsampled point clouds. We combine Inception DenseGCN with NodeShuffle into a\nnew point upsampling pipeline called PU-GCN. PU-GCN sets new state-of-art\nperformance with much fewer parameters and more efficient inference.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 13:18:19 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 09:09:54 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 15:34:38 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Qian", "Guocheng", ""], ["Abualshour", "Abdulellah", ""], ["Li", "Guohao", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1912.03277", "submitter": "Divyat Mahajan", "authors": "Divyat Mahajan, Chenhao Tan, Amit Sharma", "title": "Preserving Causal Constraints in Counterfactual Explanations for Machine\n  Learning Classifiers", "comments": "2019 NeurIPS Workshop on Do the right thing: Machine learning and\n  Causal Inference for improved decision making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To construct interpretable explanations that are consistent with the original\nML model, counterfactual examples---showing how the model's output changes with\nsmall perturbations to the input---have been proposed. This paper extends the\nwork in counterfactual explanations by addressing the challenge of feasibility\nof such examples. For explanations of ML models in critical domains such as\nhealthcare and finance, counterfactual examples are useful for an end-user only\nto the extent that perturbation of feature inputs is feasible in the real\nworld. We formulate the problem of feasibility as preserving causal\nrelationships among input features and present a method that uses (partial)\nstructural causal models to generate actionable counterfactuals. When\nfeasibility constraints cannot be easily expressed, we consider an alternative\nmechanism where people can label generated CF examples on feasibility: whether\nit is feasible to intervene and realize the candidate CF example from the\noriginal input. To learn from this labelled feasibility data, we propose a\nmodified variational auto encoder loss for generating CF examples that\noptimizes for feasibility as people interact with its output. Our experiments\non Bayesian networks and the widely used ''Adult-Income'' dataset show that our\nproposed methods can generate counterfactual explanations that better satisfy\nfeasibility constraints than existing methods.. Code repository can be accessed\nhere: \\textit{https://github.com/divyat09/cf-feasibility}\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:16:29 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 10:18:41 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 23:46:46 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mahajan", "Divyat", ""], ["Tan", "Chenhao", ""], ["Sharma", "Amit", ""]]}, {"id": "1912.03280", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco and Renato A. Krohling", "title": "Recent advances in deep learning applied to skin cancer detection", "comments": "Paper accepted in the Retrospectives Workshop @ NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer is a major public health problem around the world. Its early\ndetection is very important to increase patient prognostics. However, the lack\nof qualified professionals and medical instruments are significant issues in\nthis field. In this context, over the past few years, deep learning models\napplied to automated skin cancer detection have become a trend. In this paper,\nwe present an overview of the recent advances reported in this field as well as\na discussion about the challenges and opportunities for improvement in the\ncurrent models. In addition, we also present some important aspects regarding\nthe use of these models in smartphones and indicate future directions we\nbelieve the field will take.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:23:30 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Pacheco", "Andre G. C.", ""], ["Krohling", "Renato A.", ""]]}, {"id": "1912.03283", "submitter": "Pablo Antonio Moreno Casares", "authors": "P. A. M. Casares and M. A. Martin-Delgado", "title": "A quantum active learning algorithm for sampling against adversarial\n  attacks", "comments": "Contains an additional dequantization appendix E that does not appear\n  in the published version", "journal-ref": "New Journal of Physics, 2020", "doi": "10.1088/1367-2630/ab976f", "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks represent a serious menace for learning algorithms and\nmay compromise the security of future autonomous systems. A theorem by Khoury\nand Hadfield-Menell (KH), provides sufficient conditions to guarantee the\nrobustness of machine learning algorithms, but comes with a caveat: it is\ncrucial to know the smallest distance among the classes of the corresponding\nclassification problem. We propose a theoretical framework that allows us to\nthink of active learning as sampling the most promising new points to be\nclassified, so that the minimum distance between classes can be found and the\ntheorem KH used. Additionally, we introduce a quantum active learning algorithm\nthat makes use of such framework and whose complexity is polylogarithmic in the\ndimension of the space, $m$, and the size of the initial training data $n$,\nprovided the use of qRAMs; and polynomial in the precision, achieving an\nexponential speedup over the equivalent classical algorithm in $n$ and $m$.\nThis algorithm may be nevertheless `dequantized' reducing the advantage to\npolynomial.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 18:26:47 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 20:05:22 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 11:46:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Casares", "P. A. M.", ""], ["Martin-Delgado", "M. A.", ""]]}, {"id": "1912.03306", "submitter": "Burim Ramosaj", "authors": "Burim Ramosaj and Markus Pauly", "title": "Asymptotic Unbiasedness of the Permutation Importance Measure in Random\n  Forest Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection in sparse regression models is an important task as\napplications ranging from biomedical research to econometrics have shown.\nEspecially for higher dimensional regression problems, for which the link\nfunction between response and covariates cannot be directly detected, the\nselection of informative variables is challenging. Under these circumstances,\nthe Random Forest method is a helpful tool to predict new outcomes while\ndelivering measures for variable selection. One common approach is the usage of\nthe permutation importance. Due to its intuitive idea and flexible usage, it is\nimportant to explore circumstances, for which the permutation importance based\non Random Forest correctly indicates informative covariates. Regarding the\nlatter, we deliver theoretical guarantees for the validity of the permutation\nimportance measure under specific assumptions and prove its (asymptotic)\nunbiasedness. An extensive simulation study verifies our findings.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 19:11:32 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Ramosaj", "Burim", ""], ["Pauly", "Markus", ""]]}, {"id": "1912.03310", "submitter": "Nitish Srivastava", "authors": "Nitish Srivastava, Hanlin Goh, Ruslan Salakhutdinov", "title": "Geometric Capsule Autoencoders for 3D Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to learn object representations from 3D point clouds\nusing bundles of geometrically interpretable hidden units, which we call\ngeometric capsules. Each geometric capsule represents a visual entity, such as\nan object or a part, and consists of two components: a pose and a feature. The\npose encodes where the entity is, while the feature encodes what it is. We use\nthese capsules to construct a Geometric Capsule Autoencoder that learns to\ngroup 3D points into parts (small local surfaces), and these parts into the\nwhole object, in an unsupervised manner. Our novel Multi-View Agreement voting\nmechanism is used to discover an object's canonical pose and its pose-invariant\nfeature vector. Using the ShapeNet and ModelNet40 datasets, we analyze the\nproperties of the learned representations and show the benefits of having\nmultiple votes agree. We perform alignment and retrieval of arbitrarily rotated\nobjects -- tasks that evaluate our model's object identification and canonical\npose recovery capabilities -- and obtained insightful results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 00:10:14 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Srivastava", "Nitish", ""], ["Goh", "Hanlin", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1912.03321", "submitter": "Minxiang Ye", "authors": "Minxiang Ye, Vladimir Stankovic, Lina Stankovic, Gene Cheung", "title": "Robust Deep Graph Based Learning for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN)-based feature learning has become state of\nthe art, since given sufficient training data, CNN can significantly outperform\ntraditional methods for various classification tasks. However, feature learning\nbecomes more difficult if some training labels are noisy. With traditional\nregularization techniques, CNN often overfits to the noisy training labels,\nresulting in sub-par classification performance. In this paper, we propose a\nrobust binary classifier, based on CNNs, to learn deep metric functions, which\nare then used to construct an optimal underlying graph structure used to clean\nnoisy labels via graph Laplacian regularization (GLR). GLR is posed as a convex\nmaximum a posteriori (MAP) problem solved via convex quadratic programming\n(QP). To penalize samples around the decision boundary, we propose two\nregularized loss functions for semi-supervised learning. The binary\nclassification experiments on three datasets, varying in number and type of\nfeatures, demonstrate that given a noisy training dataset, our proposed\nnetworks outperform several state-of-the-art classifiers, including label-noise\nrobust support vector machine, CNNs with three different robust loss functions,\nmodel-based GLR, and dynamic graph CNN classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 19:11:52 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Ye", "Minxiang", ""], ["Stankovic", "Vladimir", ""], ["Stankovic", "Lina", ""], ["Cheung", "Gene", ""]]}, {"id": "1912.03330", "submitter": "Ishan Misra", "authors": "Xueting Yan and Ishan Misra and Abhinav Gupta and Deepti Ghadiyaram\n  and Dhruv Mahajan", "title": "ClusterFit: Improving Generalization of Visual Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training convolutional neural networks with weakly-supervised and\nself-supervised strategies is becoming increasingly popular for several\ncomputer vision tasks. However, due to the lack of strong discriminative\nsignals, these learned representations may overfit to the pre-training\nobjective (e.g., hashtag prediction) and not generalize well to downstream\ntasks. In this work, we present a simple strategy - ClusterFit (CF) to improve\nthe robustness of the visual representations learned during pre-training. Given\na dataset, we (a) cluster its features extracted from a pre-trained network\nusing k-means and (b) re-train a new network from scratch on this dataset using\ncluster assignments as pseudo-labels. We empirically show that clustering helps\nreduce the pre-training task-specific information from the extracted features\nthereby minimizing overfitting to the same. Our approach is extensible to\ndifferent pre-training frameworks -- weak- and self-supervised, modalities --\nimages and videos, and pre-training tasks -- object and action classification.\nThrough extensive transfer learning experiments on 11 different target datasets\nof varied vocabularies and granularities, we show that ClusterFit significantly\nimproves the representation quality compared to the state-of-the-art\nlarge-scale (millions / billions) weakly-supervised image and video models and\nself-supervised image models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 19:56:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Yan", "Xueting", ""], ["Misra", "Ishan", ""], ["Gupta", "Abhinav", ""], ["Ghadiyaram", "Deepti", ""], ["Mahajan", "Dhruv", ""]]}, {"id": "1912.03359", "submitter": "Mohamed K. Abdel-Aziz", "authors": "Mohamed K. Abdel-Aziz, Sumudu Samarakoon, Mehdi Bennis, and Walid Saad", "title": "Ultra-Reliable and Low-Latency Vehicular Communication: An Active\n  Learning Approach", "comments": "Accepted for publication in IEEE Communication Letters with 4 pages\n  and 4 figures", "journal-ref": null, "doi": "10.1109/LCOMM.2019.2956929", "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, an age of information (AoI)-aware transmission power and\nresource block (RB) allocation technique for vehicular communication networks\nis proposed. Due to the highly dynamic nature of vehicular networks, gaining a\nprior knowledge about the network dynamics, i.e., wireless channels and\ninterference, in order to allocate resources, is challenging. Therefore, to\neffectively allocate power and RBs, the proposed approach allows the network to\nactively learn its dynamics by balancing a tradeoff between minimizing the\nprobability that the vehicles' AoI exceeds a predefined threshold and\nmaximizing the knowledge about the network dynamics. In this regard, using a\nGaussian process regression (GPR) approach, an online decentralized strategy is\nproposed to actively learn the network dynamics, estimate the vehicles' future\nAoI, and proactively allocate resources. Simulation results show a significant\nimprovement in terms of AoI violation probability, compared to several\nbaselines, with a reduction of at least 50%.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 12:50:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Abdel-Aziz", "Mohamed K.", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Saad", "Walid", ""]]}, {"id": "1912.03363", "submitter": "Ankur Gandhe", "authors": "Ankur Gandhe, Ariya Rastrow", "title": "Audio-attention discriminative language model for ASR rescoring", "comments": "4 pages, 1 figure, Accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end approaches for automatic speech recognition (ASR) benefit from\ndirectly modeling the probability of the word sequence given the input audio\nstream in a single neural network. However, compared to conventional ASR\nsystems, these models typically require more data to achieve comparable\nresults. Well-known model adaptation techniques, to account for domain and\nstyle adaptation, are not easily applicable to end-to-end systems. Conventional\nHMM-based systems, on the other hand, have been optimized for various\nproduction environments and use cases. In this work, we propose to combine the\nbenefits of end-to-end approaches with a conventional system using an\nattention-based discriminative language model that learns to rescore the output\nof a first-pass ASR system. We show that learning to rescore a list of\npotential ASR outputs is much simpler than learning to generate the hypothesis.\nThe proposed model results in 8% improvement in word error rate even when the\namount of training data is a fraction of data used for training the first-pass\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 22:09:07 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:03:03 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Gandhe", "Ankur", ""], ["Rastrow", "Ariya", ""]]}, {"id": "1912.03366", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang, Philip S. Yu and Yuan Luo", "title": "Med2Meta: Learning Representations of Medical Concepts with\n  Meta-Embeddings", "comments": "9 pages", "journal-ref": "HEALTHINF 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representations of medical concepts have been used to support\ndownstream clinical tasks recently. Electronic Health Records (EHR) capture\ndifferent aspects of patients' hospital encounters and serve as a rich source\nfor augmenting clinical decision making by learning robust medical concept\nembeddings. However, the same medical concept can be recorded in different\nmodalities (e.g., clinical notes, lab results)-with each capturing salient\ninformation unique to that modality-and a holistic representation calls for\nrelevant feature ensemble from all information sources. We hypothesize that\nrepresentations learned from heterogeneous data types would lead to performance\nenhancement on various clinical informatics and predictive modeling tasks. To\nthis end, our proposed approach makes use of meta-embeddings, embeddings\naggregated from learned embeddings. Firstly, modality-specific embeddings for\neach medical concept is learned with graph autoencoders. The ensemble of all\nthe embeddings is then modeled as a meta-embedding learning problem to\nincorporate their correlating and complementary information through a joint\nreconstruction. Empirical results of our model on both quantitative and\nqualitative clinical evaluations have shown improvements over state-of-the-art\nembedding models, thus validating our hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 22:11:37 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 17:06:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""], ["Luo", "Yuan", ""]]}, {"id": "1912.03393", "submitter": "Naveen Arivazhagan", "authors": "Naveen Arivazhagan, Colin Cherry, Te I, Wolfgang Macherey, Pallavi\n  Baljekar, George Foster", "title": "Re-Translation Strategies For Long Form, Simultaneous, Spoken Language\n  Translation", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of simultaneous machine translation of long-form\nspeech content. We target a continuous speech-to-text scenario, generating\ntranslated captions for a live audio feed, such as a lecture or play-by-play\ncommentary. As this scenario allows for revisions to our incremental\ntranslations, we adopt a re-translation approach to simultaneous translation,\nwhere the source is repeatedly translated from scratch as it grows. This\napproach naturally exhibits very low latency and high final quality, but at the\ncost of incremental instability as the output is continuously refined. We\nexperiment with a pipeline of industry-grade speech recognition and translation\ntools, augmented with simple inference heuristics to improve stability. We use\nTED Talks as a source of multilingual test data, developing our techniques on\nEnglish-to-German spoken language translation. Our minimalist approach to\nsimultaneous translation allows us to easily scale our final evaluation to six\nmore target languages, dramatically improving incremental stability for all of\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 23:46:37 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 19:25:47 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Arivazhagan", "Naveen", ""], ["Cherry", "Colin", ""], ["I", "Te", ""], ["Macherey", "Wolfgang", ""], ["Baljekar", "Pallavi", ""], ["Foster", "George", ""]]}, {"id": "1912.03406", "submitter": "Malhar Jere", "authors": "Malhar Jere, Sandro Herbig, Christine Lind, Farinaz Koushanfar", "title": "Principal Component Properties of Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks for image classification have been found to be\nvulnerable to adversarial samples, which consist of sub-perceptual noise added\nto a benign image that can easily fool trained neural networks, posing a\nsignificant risk to their commercial deployment. In this work, we analyze\nadversarial samples through the lens of their contributions to the principal\ncomponents of each image, which is different than prior works in which authors\nperformed PCA on the entire dataset. We investigate a number of\nstate-of-the-art deep neural networks trained on ImageNet as well as several\nattacks for each of the networks. Our results demonstrate empirically that\nadversarial samples across several attacks have similar properties in their\ncontributions to the principal components of neural network inputs. We propose\na new metric for neural networks to measure their robustness to adversarial\nsamples, termed the (k,p) point. We utilize this metric to achieve 93.36%\naccuracy in detecting adversarial samples independent of architecture and\nattack type for models trained on ImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 01:15:40 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Jere", "Malhar", ""], ["Herbig", "Sandro", ""], ["Lind", "Christine", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "1912.03417", "submitter": "Wei Zhang", "authors": "Wei Zhang, Hao Wei, Bunyamin Sisman, Xin Luna Dong, Christos\n  Faloutsos, David Page", "title": "AutoBlock: A Hands-off Blocking Framework for Entity Matching", "comments": "In The Thirteenth ACM International Conference on Web Search and Data\n  Mining (WSDM '20), February 3-7, 2020, Houston, TX, USA. ACM, Anchorage,\n  Alaska, USA , 9 pages", "journal-ref": null, "doi": "10.1145/3336191.3371813", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity matching seeks to identify data records over one or multiple data\nsources that refer to the same real-world entity. Virtually every entity\nmatching task on large datasets requires blocking, a step that reduces the\nnumber of record pairs to be matched. However, most of the traditional blocking\nmethods are learning-free and key-based, and their successes are largely built\non laborious human effort in cleaning data and designing blocking keys.\n  In this paper, we propose AutoBlock, a novel hands-off blocking framework for\nentity matching, based on similarity-preserving representation learning and\nnearest neighbor search. Our contributions include: (a) Automation: AutoBlock\nfrees users from laborious data cleaning and blocking key tuning. (b)\nScalability: AutoBlock has a sub-quadratic total time complexity and can be\neasily deployed for millions of records. (c) Effectiveness: AutoBlock\noutperforms a wide range of competitive baselines on multiple large-scale,\nreal-world datasets, especially when datasets are dirty and/or unstructured.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 02:42:48 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Wei", ""], ["Wei", "Hao", ""], ["Sisman", "Bunyamin", ""], ["Dong", "Xin Luna", ""], ["Faloutsos", "Christos", ""], ["Page", "David", ""]]}, {"id": "1912.03418", "submitter": "Donghuan Lu", "authors": "Donghuan Lu, Morgan Heisler, Da Ma, Setareh Dabiri, Sieun Lee, Gavin\n  Weiguang Ding, Marinko V. Sarunic and Mirza Faisal Beg", "title": "Cascaded Deep Neural Networks for Retinal Layer Segmentation of Optical\n  Coherence Tomography with Fluid Presence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical coherence tomography (OCT) is a non-invasive imaging technology which\ncan provide micrometer-resolution cross-sectional images of the inner\nstructures of the eye. It is widely used for the diagnosis of ophthalmic\ndiseases with retinal alteration, such as layer deformation and fluid\naccumulation. In this paper, a novel framework was proposed to segment retinal\nlayers with fluid presence. The main contribution of this study is two folds:\n1) we developed a cascaded network framework to incorporate the prior\nstructural knowledge; 2) we proposed a novel deep neural network based on U-Net\nand fully convolutional network, termed LF-UNet. Cross validation experiments\nproved that the proposed LF-UNet has superior performance comparing with the\nstate-of-the-art methods, and incorporating the relative distance map\nstructural prior information could further improve the performance regardless\nthe network.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 02:45:36 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lu", "Donghuan", ""], ["Heisler", "Morgan", ""], ["Ma", "Da", ""], ["Dabiri", "Setareh", ""], ["Lee", "Sieun", ""], ["Ding", "Gavin Weiguang", ""], ["Sarunic", "Marinko V.", ""], ["Beg", "Mirza Faisal", ""]]}, {"id": "1912.03426", "submitter": "Rares Ambrus", "authors": "Jiexiong Tang, Rares Ambrus, Vitor Guizilini, Sudeep Pillai, Hanme\n  Kim, Patric Jensfelt, Adrien Gaidon", "title": "Self-Supervised 3D Keypoint Learning for Ego-motion Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and matching robust viewpoint-invariant keypoints is critical for\nvisual SLAM and Structure-from-Motion. State-of-the-art learning-based methods\ngenerate training samples via homography adaptation to create 2D synthetic\nviews with known keypoint matches from a single image. This approach, however,\ndoes not generalize to non-planar 3D scenes with illumination variations\ncommonly seen in real-world videos. In this work, we propose self-supervised\nlearning of depth-aware keypoints directly from unlabeled videos. We jointly\nlearn keypoint and depth estimation networks by combining appearance and\ngeometric matching via a differentiable structure-from-motion module based on\nProcrustean residual pose correction. We describe how our self-supervised\nkeypoints can be integrated into state-of-the-art visual odometry frameworks\nfor robust and accurate ego-motion estimation of autonomous vehicles in\nreal-world conditions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 03:44:28 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 19:32:56 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 04:14:23 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tang", "Jiexiong", ""], ["Ambrus", "Rares", ""], ["Guizilini", "Vitor", ""], ["Pillai", "Sudeep", ""], ["Kim", "Hanme", ""], ["Jensfelt", "Patric", ""], ["Gaidon", "Adrien", ""]]}, {"id": "1912.03430", "submitter": "Boyang Li", "authors": "Adam Noack, Isaac Ahern, Dejing Dou, Boyang Li", "title": "An Empirical Study on the Relation between Network Interpretability and\n  Adversarial Robustness", "comments": "Accepted by the journal Springer Nature Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have had many successes, but they suffer from two\nmajor issues: (1) a vulnerability to adversarial examples and (2) a tendency to\nelude human interpretation. Interestingly, recent empirical and theoretical\nevidence suggests these two seemingly disparate issues are actually connected.\nIn particular, robust models tend to provide more interpretable gradients than\nnon-robust models. However, whether this relationship works in the opposite\ndirection remains obscure. With this paper, we seek empirical answers to the\nfollowing question: can models acquire adversarial robustness when they are\ntrained to have interpretable gradients? We introduce a theoretically inspired\ntechnique called Interpretation Regularization (IR), which encourages a model's\ngradients to (1) match the direction of interpretable target salience maps and\n(2) have small magnitude. To assess model performance and tease apart factors\nthat contribute to adversarial robustness, we conduct extensive experiments on\nMNIST and CIFAR-10 with both $\\ell_2$ and $\\ell_\\infty$ attacks. We demonstrate\nthat training the networks to have interpretable gradients improves their\nrobustness to adversarial perturbations. Applying the network interpretation\ntechnique SmoothGrad yields additional performance gains, especially in\ncross-norm attacks and under heavy perturbations. The results indicate that the\ninterpretability of the model gradients is a crucial factor for adversarial\nrobustness. Code for the experiments can be found at\nhttps://github.com/a1noack/interp_regularization.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 03:54:58 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 17:16:02 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 18:05:00 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 05:49:36 GMT"}, {"version": "v5", "created": "Tue, 10 Nov 2020 16:35:50 GMT"}, {"version": "v6", "created": "Fri, 4 Dec 2020 03:00:58 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Noack", "Adam", ""], ["Ahern", "Isaac", ""], ["Dou", "Dejing", ""], ["Li", "Boyang", ""]]}, {"id": "1912.03433", "submitter": "Aniket Pramanik", "authors": "Aniket Pramanik, Hemant Aggarwal and Mathews Jacob", "title": "Deep Generalization of Structured Low-Rank Algorithms (Deep-SLR)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured low-rank (SLR) algorithms, which exploit annihilation relations\nbetween the Fourier samples of a signal resulting from different properties, is\na powerful image reconstruction framework in several applications. This scheme\nrelies on low-rank matrix completion to estimate the annihilation relations\nfrom the measurements. The main challenge with this strategy is the high\ncomputational complexity of matrix completion. We introduce a deep learning\n(DL) approach to significantly reduce the computational complexity.\nSpecifically, we use a convolutional neural network (CNN)-based filterbank that\nis trained to estimate the annihilation relations from imperfect (under-sampled\nand noisy) k-space measurements of Magnetic Resonance Imaging (MRI). The main\nreason for the computational efficiency is the pre-learning of the parameters\nof the non-linear CNN from exemplar data, compared to SLR schemes that learn\nthe linear filterbank parameters from the dataset itself. Experimental\ncomparisons show that the proposed scheme can enable calibration-less parallel\nMRI; it can offer performance similar to SLR schemes while reducing the runtime\nby around three orders of magnitude. Unlike pre-calibrated and self-calibrated\napproaches, the proposed uncalibrated approach is insensitive to motion errors\nand affords higher acceleration. The proposed scheme also incorporates image\ndomain priors that are complementary, thus significantly improving the\nperformance over that of SLR schemes.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 04:05:52 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 15:01:14 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 18:59:29 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Pramanik", "Aniket", ""], ["Aggarwal", "Hemant", ""], ["Jacob", "Mathews", ""]]}, {"id": "1912.03437", "submitter": "Md Khairul Islam", "authors": "Md. Khairul Islam, Toufique Ahmed, Fahim Ahmed, Dr. Anindya Iqbal", "title": "Accepted or Abandoned? Predicting the Fate of Code Changes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mature Open-Source Software (OSS), as well as commercial, organizations\nhave adopted peer code review as an integral part of the development process to\nensure the quality of the product. Of particular interest are code changes that\nend up \"abandoned,\" either because they are rejected, or (more commonly)\nbecause they are never accepted at all (at least not through the review tool).\nSeveral factors such as resource allocation, job environment, and efficiency\nmismatch between the author and the reviewer may cause a code change to be\nabandoned even after months of efforts from the developers and the reviewers.\nPredicting the review outcome of such code changes can ease the prioritization\nof tasks and the utilization of limited resources by saving time spent on\nlow-quality code changes. In this paper, we conducted a comprehensive study to\npredict whether a code change is merged or abandoned and applied various\nwell-known supervised machine learning algorithms. We propose PredCR, a Random\nForest based model that predicts the review outcome of a code change with 0.91\nf-measure at the beginning of the code change on the test set. Also, it\nimproves predictions of abandoned changes by 27\\%-103\\% and merged changes by\n5\\%-11\\%. Our model accurately classifies 93\\% of the top 25\\% code changes\n(with average 196 days duration) that go longest without being merged. PredCR\ncan also adapt to the changes in feature values at different stages of the\nreview process although it achieves very high performance at the very early\nstage (within 10\\% of the review process). This way, prediction quality for a\nparticular code change can improve as the code review progresses. We also\nconducted a study to find out the properties of an ideal training set for our\ntool. We found that training with the instances from the same projects ensures\n9\\%-25\\% performance increase.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 04:38:48 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Islam", "Md. Khairul", ""], ["Ahmed", "Toufique", ""], ["Ahmed", "Fahim", ""], ["Iqbal", "Dr. Anindya", ""]]}, {"id": "1912.03440", "submitter": "Yongshun Gong", "authors": "Yongshun Gong, Zhibin Li, Jian Zhang, Wei Liu and Jinfeng Yi", "title": "Potential Passenger Flow Prediction: A Novel Study for Urban\n  Transportation Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, practical applications for passenger flow prediction have brought\nmany benefits to urban transportation development. With the development of\nurbanization, a real-world demand from transportation managers is to construct\na new metro station in one city area that never planned before. Authorities are\ninterested in the picture of the future volume of commuters before constructing\na new station, and estimate how would it affect other areas. In this paper,\nthis specific problem is termed as potential passenger flow (PPF) prediction,\nwhich is a novel and important study connected with urban computing and\nintelligent transportation systems. For example, an accurate PPF predictor can\nprovide invaluable knowledge to designers, such as the advice of station scales\nand influences on other areas, etc. To address this problem, we propose a\nmulti-view localized correlation learning method. The core idea of our strategy\nis to learn the passenger flow correlations between the target areas and their\nlocalized areas with adaptive-weight. To improve the prediction accuracy, other\ndomain knowledge is involved via a multi-view learning process. We conduct\nintensive experiments to evaluate the effectiveness of our method with\nreal-world official transportation datasets. The results demonstrate that our\nmethod can achieve excellent performance compared with other available\nbaselines. Besides, our method can provide an effective solution to the\ncold-start problem in the recommender system as well, which proved by its\noutperformed experimental results.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 05:11:19 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Gong", "Yongshun", ""], ["Li", "Zhibin", ""], ["Zhang", "Jian", ""], ["Liu", "Wei", ""], ["Yi", "Jinfeng", ""]]}, {"id": "1912.03442", "submitter": "Behnoosh Parsa", "authors": "Behnoosh Parsa, Athma Narayanan, Behzad Dariush", "title": "Spatio-Temporal Pyramid Graph Convolutions for Human Action Recognition\n  and Postural Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognition of human actions and associated interactions with objects and the\nenvironment is an important problem in computer vision due to its potential\napplications in a variety of domains. The most versatile methods can generalize\nto various environments and deal with cluttered backgrounds, occlusions, and\nviewpoint variations. Among them, methods based on graph convolutional networks\nthat extract features from the skeleton have demonstrated promising\nperformance. In this paper, we propose a novel Spatio-Temporal Pyramid Graph\nConvolutional Network (ST-PGN) for online action recognition for ergonomic risk\nassessment that enables the use of features from all levels of the skeleton\nfeature hierarchy. The proposed algorithm outperforms state-of-art action\nrecognition algorithms tested on two public benchmark datasets typically used\nfor postural assessment (TUM and UW-IOM). We also introduce a pipeline to\nenhance postural assessment methods with online action recognition techniques.\nFinally, the proposed algorithm is integrated with a traditional ergonomic risk\nindex (REBA) to demonstrate the potential value for assessment of\nmusculoskeletal disorders in occupational safety.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 05:16:31 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Parsa", "Behnoosh", ""], ["Narayanan", "Athma", ""], ["Dariush", "Behzad", ""]]}, {"id": "1912.03444", "submitter": "Kelechi Ogueji", "authors": "Kelechi Ogueji and Orevaoghene Ahia", "title": "PidginUNMT: Unsupervised Neural Machine Translation from West African\n  Pidgin to English", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 800 languages are spoken across West Africa. Despite the obvious\ndiversity among people who speak these languages, one language significantly\nunifies them all - West African Pidgin English. There are at least 80 million\nspeakers of West African Pidgin English. However, there is no known natural\nlanguage processing (NLP) work on this language. In this work, we perform the\nfirst NLP work on the most popular variant of the language, providing three\nmajor contributions. First, the provision of a Pidgin corpus of over 56000\nsentences, which is the largest we know of. Secondly, the training of the first\never cross-lingual embedding between Pidgin and English. This aligned embedding\nwill be helpful in the performance of various downstream tasks between English\nand Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translation\nmodel between Pidgin and English which achieves BLEU scores of 7.93 from Pidgin\nto English, and 5.18 from English to Pidgin. In all, this work greatly reduces\nthe barrier of entry for future NLP works on West African Pidgin English.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 05:30:09 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Ogueji", "Kelechi", ""], ["Ahia", "Orevaoghene", ""]]}, {"id": "1912.03449", "submitter": "Ruisen Luo", "authors": "Miao Du, Qin Yu, Shaomin Fei, Chen Wang, Xiaofeng Gong, and Ruisen Luo", "title": "Fully Dense Neural Network for the Automatic Modulation Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we mainly use various convolution neural network (CNN) structures\nto extract features from radio data or spectrogram in AMR. Based on expert\nexperience and spectrograms, they not only increase the difficulty of\npreprocessing, but also consume a lot of memory. In order to directly use\nin-phase and quadrature (IQ) data obtained by the receiver and enhance the\nefficiency of network extraction features to improve the recognition rate of\nmodulation mode, this paper proposes a new network structure called Fully Dense\nNeural Network (FDNN). This network uses residual blocks to extract features,\ndense connect to reduce model size, and adds attentions mechanism to\nrecalibrate. Experiments on RML2016.10a show that this network has a higher\nrecognition rate and lower model complexity. And it shows that the FDNN model\nwith dense connections can not only extract features effectively but also\ngreatly reduce model parameters, which also provides a significant contribution\nfor the application of deep learning to the intelligent radio system.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 06:48:38 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Du", "Miao", ""], ["Yu", "Qin", ""], ["Fei", "Shaomin", ""], ["Wang", "Chen", ""], ["Gong", "Xiaofeng", ""], ["Luo", "Ruisen", ""]]}, {"id": "1912.03452", "submitter": "Yingshi Chen", "authors": "Yingshi Chen, Jinfeng Zhu", "title": "A novel guided deep learning algorithm to design low-cost SPP films", "comments": "9 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.app-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of surface plasmon polaritons (SPP) films is an ill-posed inverse\nproblem. There are many-to-one correspondence between the structures and user\nneeds. We present a novel guided deep learning algorithm to find optimal\nsolutions (with both high accuracy and low cost). To achieve this goal, we use\nlow cost sample replacement algorithm in training process. The deep CNN would\ngradually learn better model from samples with lower cost. We have successfully\napplied this algorithm to the design of low-cost SPP films. Our model learned\nto replace precious metals with ordinary metals to reduce cost. So the the cost\nof predicted structure is much lower than standard deep CNN. And the average\nrelative error of spectrum is less than 10%. The source codes are available at\nhttps://github.com/closest-git/MetaLab.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 07:26:00 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 02:21:07 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Chen", "Yingshi", ""], ["Zhu", "Jinfeng", ""]]}, {"id": "1912.03460", "submitter": "Bolin Gao", "authors": "Bolin Gao, Lacra Pavel", "title": "Continuous-time Discounted Mirror-Descent Dynamics in Monotone Concave\n  Games", "comments": "8 pages, 9 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": "IEEE Transactions on Automatic Control, vol 66 (11), 2021", "doi": "10.1109/TAC.2020.3045094", "report-no": null, "categories": "math.OC cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider concave continuous-kernel games characterized by\nmonotonicity properties and propose discounted mirror descent-type dynamics. We\nintroduce two classes of dynamics whereby the associated mirror map is\nconstructed based on a strongly convex or a Legendre regularizer. Depending on\nthe properties of the regularizer we show that these new dynamics can converge\nasymptotically in concave games with monotone (negative) pseudo-gradient.\nFurthermore, we show that when the regularizer enjoys strong convexity, the\nresulting dynamics can converge even in games with hypo-monotone (negative)\npseudo-gradient, which corresponds to a shortage of monotonicity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 08:04:21 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gao", "Bolin", ""], ["Pavel", "Lacra", ""]]}, {"id": "1912.03463", "submitter": "Erdem Varol", "authors": "Erdem Varol, Amin Nejatbakhsh, Conor McGrory", "title": "Temporal Wasserstein non-negative matrix factorization for non-rigid\n  motion segmentation and spatiotemporal deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV cs.LG eess.IV q-bio.QM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Motion segmentation for natural images commonly relies on dense optic flow to\nyield point trajectories which can be grouped into clusters through various\nmeans including spectral clustering or minimum cost multicuts. However, in\nbiological imaging scenarios, such as fluorescence microscopy or calcium\nimaging, where the signal to noise ratio is compromised and intensity\nfluctuations occur, optical flow may be difficult to approximate. To this end,\nwe propose an alternative paradigm for motion segmentation based on optimal\ntransport which models the video frames as time-varying mass represented as\nhistograms. Thus, we cast motion segmentation as a temporal non-linear matrix\nfactorization problem with Wasserstein metric loss. The dictionary elements of\nthis factorization yield segmentation of motion into coherent objects while the\nloading coefficients allow for time-varying intensity signal of the moving\nobjects to be captured. We demonstrate the use of the proposed paradigm on a\nsimulated multielectrode drift scenario, as well as calcium indicating\nfluorescence microscopy videos of the nematode Caenorhabditis elegans (C.\nelegans). The latter application has the added utility of extracting neural\nactivity of the animal in freely conducted behavior.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 08:30:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Varol", "Erdem", ""], ["Nejatbakhsh", "Amin", ""], ["McGrory", "Conor", ""]]}, {"id": "1912.03467", "submitter": "Mohamed Karim Belaid", "authors": "Mohamed Karim Belaid", "title": "Comparison of Neuronal Attention Models", "comments": null, "journal-ref": "Data Science Seminar, 2019, Uni Passau", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent models for image processing are using the Convolutional neural network\n(CNN) which requires a pixel per pixel analysis of the input image. This method\nworks well. However, it is time-consuming if we have large images. To increase\nthe performance, by improving the training time or the accuracy, we need a\nsize-independent method. As a solution, we can add a Neuronal Attention model\n(NAM). The power of this new approach is that it can efficiently choose several\nsmall regions from the initial image to focus on. The purpose of this paper is\nto explain and also test each of the NAM's parameters.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 09:00:18 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Belaid", "Mohamed Karim", ""]]}, {"id": "1912.03485", "submitter": "Hema Venkata Krishna Giri Narra", "authors": "Krishna Giri Narra, Zhifeng Lin, Yongqin Wang, Keshav Balasubramaniam,\n  Murali Annavaram", "title": "Privacy-Preserving Inference in Machine Learning Services Using Trusted\n  Execution Environments", "comments": "13 pages, Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents Origami, which provides privacy-preserving inference for\nlarge deep neural network (DNN) models through a combination of enclave\nexecution, cryptographic blinding, interspersed with accelerator-based\ncomputation. Origami partitions the ML model into multiple partitions. The\nfirst partition receives the encrypted user input within an SGX enclave. The\nenclave decrypts the input and then applies cryptographic blinding to the input\ndata and the model parameters. Cryptographic blinding is a technique that adds\nnoise to obfuscate data. Origami sends the obfuscated data for computation to\nan untrusted GPU/CPU. The blinding and de-blinding factors are kept private by\nthe SGX enclave, thereby preventing any adversary from denoising the data, when\nthe computation is offloaded to a GPU/CPU. The computed output is returned to\nthe enclave, which decodes the computation on noisy data using the unblinding\nfactors privately stored within SGX. This process may be repeated for each DNN\nlayer, as has been done in prior work Slalom.\n  However, the overhead of blinding and unblinding the data is a limiting\nfactor to scalability. Origami relies on the empirical observation that the\nfeature maps after the first several layers can not be used, even by a powerful\nconditional GAN adversary to reconstruct input. Hence, Origami dynamically\nswitches to executing the rest of the DNN layers directly on an accelerator\nwithout needing any further cryptographic blinding intervention to preserve\nprivacy. We empirically demonstrate that using Origami, a conditional GAN\nadversary, even with an unlimited inference budget, cannot reconstruct the\ninput. We implement and demonstrate the performance gains of Origami using the\nVGG-16 and VGG-19 models. Compared to running the entire VGG-19 model within\nSGX, Origami inference improves the performance of private inference from 11x\nwhile using Slalom to 15.1x.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 10:27:33 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Narra", "Krishna Giri", ""], ["Lin", "Zhifeng", ""], ["Wang", "Yongqin", ""], ["Balasubramaniam", "Keshav", ""], ["Annavaram", "Murali", ""]]}, {"id": "1912.03488", "submitter": "Bhanu Garg Mr.", "authors": "Bhanu Garg and Naresh Manwani", "title": "Robust Deep Ordinal Regression Under Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-world data is often susceptible to label noise, which might\nconstrict the effectiveness of the existing state of the art algorithms for\nordinal regression. Existing works on ordinal regression do not take label\nnoise into account. We propose a theoretically grounded approach for class\nconditional label noise in ordinal regression problems. We present a deep\nlearning implementation of two commonly used loss functions for ordinal\nregression that is both - 1) robust to label noise, and 2) rank consistent for\na good ranking rule. We verify these properties of the algorithm empirically\nand show robustness to label noise on real data and rank consistency. To the\nbest of our knowledge, this is the first approach for robust ordinal regression\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 10:39:45 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 17:47:59 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Garg", "Bhanu", ""], ["Manwani", "Naresh", ""]]}, {"id": "1912.03500", "submitter": "V\\'it Musil", "authors": "Michal Rol\\'inek, V\\'it Musil, Anselm Paulus, Marin Vlastelica,\n  Claudio Michaelis, and Georg Martius", "title": "Optimizing Rank-based Metrics with Blackbox Differentiation", "comments": "CVPR 2020 conference paper (oral). The first two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank-based metrics are some of the most widely used criteria for performance\nevaluation of computer vision models. Despite years of effort, direct\noptimization for these metrics remains a challenge due to their\nnon-differentiable and non-decomposable nature. We present an efficient,\ntheoretically sound, and general method for differentiating rank-based metrics\nwith mini-batch gradient descent. In addition, we address optimization\ninstability and sparsity of the supervision signal that both arise from using\nrank-based metrics as optimization targets. Resulting losses based on recall\nand Average Precision are applied to image retrieval and object detection\ntasks. We obtain performance that is competitive with state-of-the-art on\nstandard image retrieval datasets and consistently improve performance of near\nstate-of-the-art object detectors. The code is available at\nhttps://github.com/martius-lab/blackbox-backprop\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 13:21:54 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 10:25:53 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Rol\u00ednek", "Michal", ""], ["Musil", "V\u00edt", ""], ["Paulus", "Anselm", ""], ["Vlastelica", "Marin", ""], ["Michaelis", "Claudio", ""], ["Martius", "Georg", ""]]}, {"id": "1912.03509", "submitter": "Sascha Rosbach", "authors": "Sascha Rosbach, Vinit James, Simon Gro{\\ss}johann, Silviu Homoceanu,\n  Xing Li and Stefan Roth", "title": "Driving Style Encoder: Situational Reward Adaptation for General-Purpose\n  Planning in Automated Driving", "comments": "To appear in Proceedings of the IEEE International Conference on\n  Robotics and Automation (ICRA), Paris, France, June 2020 (Virtual\n  Conference). Accepted version. Corrected figure font", "journal-ref": "IEEE International Conference on Robotics and Automation (ICRA),\n  Paris, France, 2020, pp. 6419-6425", "doi": "10.1109/ICRA40945.2020.9196778", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General-purpose planning algorithms for automated driving combine mission,\nbehavior, and local motion planning. Such planning algorithms map features of\nthe environment and driving kinematics into complex reward functions. To\nachieve this, planning experts often rely on linear reward functions. The\nspecification and tuning of these reward functions is a tedious process and\nrequires significant experience. Moreover, a manually designed linear reward\nfunction does not generalize across different driving situations. In this work,\nwe propose a deep learning approach based on inverse reinforcement learning\nthat generates situation-dependent reward functions. Our neural network\nprovides a mapping between features and actions of sampled driving policies of\na model-predictive control-based planner and predicts reward functions for\nupcoming planning cycles. In our evaluation, we compare the driving style of\nreward functions predicted by our deep network against clustered and linear\nreward functions. Our proposed deep learning approach outperforms clustered\nlinear reward functions and is at par with linear reward functions with\na-priori knowledge about the situation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:30:22 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 12:10:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Rosbach", "Sascha", ""], ["James", "Vinit", ""], ["Gro\u00dfjohann", "Simon", ""], ["Homoceanu", "Silviu", ""], ["Li", "Xing", ""], ["Roth", "Stefan", ""]]}, {"id": "1912.03513", "submitter": "Warren Powell", "authors": "Warren B Powell", "title": "From Reinforcement Learning to Optimal Control: A unified framework for\n  sequential decisions", "comments": "47 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are over 15 distinct communities that work in the general area of\nsequential decisions and information, often referred to as decisions under\nuncertainty or stochastic optimization. We focus on two of the most important\nfields: stochastic optimal control, with its roots in deterministic optimal\ncontrol, and reinforcement learning, with its roots in Markov decision\nprocesses. Building on prior work, we describe a unified framework that covers\nall 15 different communities, and note the strong parallels with the modeling\nframework of stochastic optimal control. By contrast, we make the case that the\nmodeling framework of reinforcement learning, inherited from discrete Markov\ndecision processes, is quite limited. Our framework (and that of stochastic\ncontrol) is based on the core problem of optimizing over policies. We describe\nfour classes of policies that we claim are universal, and show that each of\nthese two fields have, in their own way, evolved to include examples of each of\nthese four classes.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:50:37 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 14:20:17 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Powell", "Warren B", ""]]}, {"id": "1912.03517", "submitter": "Jean Tarbouriech", "authors": "Jean Tarbouriech, Evrard Garcelon, Michal Valko, Matteo Pirotta,\n  Alessandro Lazaric", "title": "No-Regret Exploration in Goal-Oriented Reinforcement Learning", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many popular reinforcement learning problems (e.g., navigation in a maze,\nsome Atari games, mountain car) are instances of the episodic setting under its\nstochastic shortest path (SSP) formulation, where an agent has to achieve a\ngoal state while minimizing the cumulative cost. Despite the popularity of this\nsetting, the exploration-exploitation dilemma has been sparsely studied in\ngeneral SSP problems, with most of the theoretical literature focusing on\ndifferent problems (i.e., fixed-horizon and infinite-horizon) or making the\nrestrictive loop-free SSP assumption (i.e., no state can be visited twice\nduring an episode). In this paper, we study the general SSP problem with no\nassumption on its dynamics (some policies may actually never reach the goal).\nWe introduce UC-SSP, the first no-regret algorithm in this setting, and prove a\nregret bound scaling as $\\displaystyle \\widetilde{\\mathcal{O}}( D S \\sqrt{ A D\nK})$ after $K$ episodes for any unknown SSP with $S$ states, $A$ actions,\npositive costs and SSP-diameter $D$, defined as the smallest expected hitting\ntime from any starting state to the goal. We achieve this result by crafting a\nnovel stopping rule, such that UC-SSP may interrupt the current policy if it is\ntaking too long to achieve the goal and switch to alternative policies that are\ndesigned to rapidly terminate the episode.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 15:19:22 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 18:23:10 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 11:46:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Tarbouriech", "Jean", ""], ["Garcelon", "Evrard", ""], ["Valko", "Michal", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "1912.03538", "submitter": "Sara Beery", "authors": "Sara Beery, Guanhang Wu, Vivek Rathod, Ronny Votel, Jonathan Huang", "title": "Context R-CNN: Long Term Temporal Context for Per-Camera Object\n  Detection", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In static monitoring cameras, useful contextual information can stretch far\nbeyond the few seconds typical video understanding models might see: subjects\nmay exhibit similar behavior over multiple days, and background objects remain\nstatic. Due to power and storage constraints, sampling frequencies are low,\noften no faster than one frame per second, and sometimes are irregular due to\nthe use of a motion trigger. In order to perform well in this setting, models\nmust be robust to irregular sampling rates. In this paper we propose a method\nthat leverages temporal context from the unlabeled frames of a novel camera to\nimprove performance at that camera. Specifically, we propose an attention-based\napproach that allows our model, Context R-CNN, to index into a long term memory\nbank constructed on a per-camera basis and aggregate contextual features from\nother frames to boost object detection performance on the current frame.\n  We apply Context R-CNN to two settings: (1) species detection using camera\ntraps, and (2) vehicle detection in traffic cameras, showing in both settings\nthat Context R-CNN leads to performance gains over strong baselines. Moreover,\nwe show that increasing the contextual time horizon leads to improved results.\nWhen applied to camera trap data from the Snapshot Serengeti dataset, Context\nR-CNN with context from up to a month of images outperforms a single-frame\nbaseline by 17.9% mAP, and outperforms S3D (a 3d convolution based baseline) by\n11.2% mAP.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 17:53:48 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 21:52:33 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 15:09:17 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Beery", "Sara", ""], ["Wu", "Guanhang", ""], ["Rathod", "Vivek", ""], ["Votel", "Ronny", ""], ["Huang", "Jonathan", ""]]}, {"id": "1912.03549", "submitter": "Juho Timonen", "authors": "Juho Timonen, Henrik Mannerstr\\\"om, Aki Vehtari and Harri\n  L\\\"ahdesm\\\"aki", "title": "lgpr: An interpretable nonparametric method for inferring covariate\n  effects from longitudinal data", "comments": "Contains main manuscript and supplementary material. Tables S1-S3 are\n  in ancillary files", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal study designs are indispensable for studying disease\nprogression. Inferring covariate effects from longitudinal data, however,\nrequires interpretable methods that can model complicated covariance structures\nand detect nonlinear effects of both categorical and continuous covariates, as\nwell as their interactions. Detecting disease effects is hindered by the fact\nthat they often occur rapidly near the disease initiation time, and this time\npoint cannot be exactly observed. An additional challenge is that the effect\nmagnitude can be heterogeneous over the subjects. We present lgpr, a widely\napplicable and interpretable method for nonparametric analysis of longitudinal\ndata using additive Gaussian processes. We demonstrate that it outperforms\nprevious approaches in identifying the relevant categorical and continuous\ncovariates in various settings. Furthermore, it implements important novel\nfeatures, including the ability to account for the heterogeneity of covariate\neffects, their temporal uncertainty, and appropriate observation models for\ndifferent types of biomedical data. The lgpr tool is implemented as a\ncomprehensive and user-friendly R-package. lgpr is available at\njtimonen.github.io/lgpr-usage with documentation, tutorials, test data, and\ncode for reproducing the experiments of this paper.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 19:36:33 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 10:36:10 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Timonen", "Juho", ""], ["Mannerstr\u00f6m", "Henrik", ""], ["Vehtari", "Aki", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1912.03553", "submitter": "Spencer Frazier", "authors": "Spencer Frazier, Md Sultan Al Nahian, Mark Riedl, Brent Harrison", "title": "Learning Norms from Stories: A Prior for Value Aligned Agents", "comments": "AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value alignment is a property of an intelligent agent indicating that it can\nonly pursue goals and activities that are beneficial to humans. Traditional\napproaches to value alignment use imitation learning or preference learning to\ninfer the values of humans by observing their behavior. We introduce a\ncomplementary technique in which a value aligned prior is learned from\nnaturally occurring stories which encode societal norms. Training data is\nsourced from the childrens educational comic strip, Goofus and Gallant. In this\nwork, we train multiple machine learning models to classify natural language\ndescriptions of situations found in the comic strip as normative or non\nnormative by identifying if they align with the main characters behavior. We\nalso report the models performance when transferring to two unrelated tasks\nwith little to no additional training on the new task.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 20:12:43 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Frazier", "Spencer", ""], ["Nahian", "Md Sultan Al", ""], ["Riedl", "Mark", ""], ["Harrison", "Brent", ""]]}, {"id": "1912.03558", "submitter": "Jiachen Yang", "authors": "Jiachen Yang, Igor Borovikov, Hongyuan Zha", "title": "Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill\n  Discovery", "comments": "Published at International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human players in professional team sports achieve high level coordination by\ndynamically choosing complementary skills and executing primitive actions to\nperform these skills. As a step toward creating intelligent agents with this\ncapability for fully cooperative multi-agent settings, we propose a two-level\nhierarchical multi-agent reinforcement learning (MARL) algorithm with\nunsupervised skill discovery. Agents learn useful and distinct skills at the\nlow level via independent Q-learning, while they learn to select complementary\nlatent skill variables at the high level via centralized multi-agent training\nwith an extrinsic team reward. The set of low-level skills emerges from an\nintrinsic reward that solely promotes the decodability of latent skill\nvariables from the trajectory of a low-level skill, without the need for\nhand-crafted rewards for each skill. For scalable decentralized execution, each\nagent independently chooses latent skill variables and primitive actions based\non local observations. Our overall method enables the use of general\ncooperative MARL algorithms for training high level policies and single-agent\nRL for training low level skills. Experiments on a stochastic high dimensional\nteam game show the emergence of useful skills and cooperative team play. The\ninterpretability of the learned skills show the promise of the proposed method\nfor achieving human-AI cooperation in team sports games.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 20:41:32 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:30:45 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 03:00:47 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Yang", "Jiachen", ""], ["Borovikov", "Igor", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1912.03573", "submitter": "Lixiang Zhang", "authors": "Lixiang Zhang, Lin Lin, Jia Li", "title": "Deep Variable-Block Chain with Adaptive Variable Selection", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architectures of deep neural networks (DNN) rely heavily on the\nunderlying grid structure of variables, for instance, the lattice of pixels in\nan image. For general high dimensional data with variables not associated with\na grid, the multi-layer perceptron and deep brief network are often used.\nHowever, it is frequently observed that those networks do not perform\ncompetitively and they are not helpful for identifying important variables. In\nthis paper, we propose a framework that imposes on blocks of variables a chain\nstructure obtained by step-wise greedy search so that the DNN architecture can\nleverage the constructed grid. We call this new neural network Deep\nVariable-Block Chain (DVC). Because the variable blocks are used for\nclassification in a sequential manner, we further develop the capacity of\nselecting variables adaptively according to a number of regions trained by a\ndecision tree. Our experiments show that DVC outperforms other generic DNNs and\nother strong classifiers. Moreover, DVC can achieve high accuracy at much\nreduced dimensionality and sometimes reveals drastically different sets of\nrelevant variables for different regions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 23:02:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Lixiang", ""], ["Lin", "Lin", ""], ["Li", "Jia", ""]]}, {"id": "1912.03579", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen and David Duvenaud", "title": "Neural Networks with Cheap Differential Operators", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradients of neural networks can be computed efficiently for any\narchitecture, but some applications require differential operators with higher\ntime complexity. We describe a family of restricted neural network\narchitectures that allow efficient computation of a family of differential\noperators involving dimension-wise derivatives, used in cases such as computing\nthe divergence. Our proposed architecture has a Jacobian matrix composed of\ndiagonal and hollow (non-diagonal) components. We can then modify the backward\ncomputation graph to extract dimension-wise derivatives efficiently with\nautomatic differentiation. We demonstrate these cheap differential operators\nfor solving root-finding subproblems in implicit ODE solvers, exact density\nevaluation for continuous normalizing flows, and evaluating the Fokker--Planck\nequation for training stochastic differential equation models.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 00:08:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""]]}, {"id": "1912.03582", "submitter": "Vatsal Sharan", "authors": "Parikshit Gopalan, Vatsal Sharan, Udi Wieder", "title": "PIDForest: Anomaly Detection via Partial Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting anomalies in a large dataset. We propose\na framework called Partial Identification which captures the intuition that\nanomalies are easy to distinguish from the overwhelming majority of points by\nrelatively few attribute values. Formalizing this intuition, we propose a\ngeometric anomaly measure for a point that we call PIDScore, which measures the\nminimum density of data points over all subcubes containing the point. We\npresent PIDForest: a random forest based algorithm that finds anomalies based\non this definition. We show that it performs favorably in comparison to several\npopular anomaly detection methods, across a broad range of benchmarks.\nPIDForest also provides a succinct explanation for why a point is labelled\nanomalous, by providing a set of features and ranges for them which are\nrelatively uncommon in the dataset.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 00:43:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Gopalan", "Parikshit", ""], ["Sharan", "Vatsal", ""], ["Wieder", "Udi", ""]]}, {"id": "1912.03585", "submitter": "Souvick Ghosh", "authors": "Souvick Ghosh and Satanu Ghosh", "title": "Exploring the Ideal Depth of Neural Network when Predicting Question\n  Deletion on Community Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Community Question Answering (CQA) has emerged as a popular\nplatform for knowledge curation and archival. An interesting aspect of question\nanswering is that it combines aspects from natural language processing,\ninformation retrieval, and machine learning. In this paper, we have explored\nhow the depth of the neural network influences the accuracy of prediction of\ndeleted questions in question-answering forums. We have used different shallow\nand deep models for prediction and analyzed the relationships between number of\nhidden layers, accuracy, and computational time. The results suggest that while\ndeep networks perform better than shallow networks in modeling complex\nnon-linear functions, increasing the depth may not always produce desired\nresults. We observe that the performance of the deep neural network suffers\nsignificantly due to vanishing gradients when large number of hidden layers are\npresent. Constantly increasing the depth of the model increases accuracy\ninitially, after which the accuracy plateaus, and finally drops. Adding each\nlayer is also expensive in terms of the time required to train the model. This\nresearch is situated in the domain of neural information retrieval and\ncontributes towards building a theory on how deep neural networks can be\nefficiently and accurately used for predicting question deletion. We predict\ndeleted questions with more than 90\\% accuracy using two to ten hidden layers,\nwith less accurate results for shallower and deeper architectures.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 01:06:16 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Ghosh", "Souvick", ""], ["Ghosh", "Satanu", ""]]}, {"id": "1912.03587", "submitter": "Qun Liu", "authors": "Qun Liu, Subhashis Hazarika, John M. Patchett, James Paul Ahrens, Ayan\n  Biswas", "title": "Deep Learning-Based Feature-Aware Data Modeling for Complex Physics\n  Simulations", "comments": "Accepted as a research poster at the International Conference for\n  High Performance Computing, Networking, Storage, and Analysis (SC19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data modeling and reduction for in situ is important. Feature-driven methods\nfor in situ data analysis and reduction are a priority for future exascale\nmachines as there are currently very few such methods. We investigate a\ndeep-learning based workflow that targets in situ data processing using\nautoencoders. We propose a Residual Autoencoder integrated Residual in Residual\nDense Block (RRDB) to obtain better performance. Our proposed framework\ncompressed our test data into 66 KB from 2.1 MB per 3D volume timestep.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 01:14:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Liu", "Qun", ""], ["Hazarika", "Subhashis", ""], ["Patchett", "John M.", ""], ["Ahrens", "James Paul", ""], ["Biswas", "Ayan", ""]]}, {"id": "1912.03589", "submitter": "Xiao Lu", "authors": "Guangxia Lia, Yulong Shena, Peilin Zhaob, Xiao Lu, Jia Liu, Yangyang\n  Liu, Steven C. H. Hoi", "title": "Detecting Cyberattacks in Industrial Control Systems Using Online\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial control systems are critical to the operation of industrial\nfacilities, especially for critical infrastructures, such as refineries, power\ngrids, and transportation systems. Similar to other information systems, a\nsignificant threat to industrial control systems is the attack from\ncyberspace---the offensive maneuvers launched by \"anonymous\" in the digital\nworld that target computer-based assets with the goal of compromising a\nsystem's functions or probing for information. Owing to the importance of\nindustrial control systems, and the possibly devastating consequences of being\nattacked, significant endeavors have been attempted to secure industrial\ncontrol systems from cyberattacks. Among them are intrusion detection systems\nthat serve as the first line of defense by monitoring and reporting potentially\nmalicious activities. Classical machine-learning-based intrusion detection\nmethods usually generate prediction models by learning modest-sized training\nsamples all at once. Such approach is not always applicable to industrial\ncontrol systems, as industrial control systems must process continuous control\ncommands with limited computational resources in a nonstop way. To satisfy such\nrequirements, we propose using online learning to learn prediction models from\nthe controlling data stream. We introduce several state-of-the-art online\nlearning algorithms categorically, and illustrate their efficacies on two\ntypically used testbeds---power system and gas pipeline. Further, we explore a\nnew cost-sensitive online learning algorithm to solve the class-imbalance\nproblem that is pervasive in industrial intrusion detection systems. Our\nexperimental results indicate that the proposed algorithm can achieve an\noverall improvement in the detection rate of cyberattacks in industrial control\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 01:29:37 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lia", "Guangxia", ""], ["Shena", "Yulong", ""], ["Zhaob", "Peilin", ""], ["Lu", "Xiao", ""], ["Liu", "Jia", ""], ["Liu", "Yangyang", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "1912.03606", "submitter": "John Zech", "authors": "John R. Zech, Jessica Zosa Forde, Michael L. Littman", "title": "Individual predictions matter: Assessing the effect of data ordering in\n  training fine-tuned CNNs for medical imaging", "comments": "J.Z. and J.F. contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reproduced the results of CheXNet with fixed hyperparameters and 50\ndifferent random seeds to identify 14 finding in chest radiographs (x-rays).\nBecause CheXNet fine-tunes a pre-trained DenseNet, the random seed affects the\nordering of the batches of training data but not the initialized model weights.\nWe found substantial variability in predictions for the same radiograph across\nmodel runs (mean ln[(maximum probability)/(minimum probability)] 2.45,\ncoefficient of variation 0.543). This individual radiograph-level variability\nwas not fully reflected in the variability of AUC on a large test set.\nAveraging predictions from 10 models reduced variability by nearly 70% (mean\ncoefficient of variation from 0.543 to 0.169, t-test 15.96, p-value < 0.0001).\nWe encourage researchers to be aware of the potential variability of CNNs and\nensemble predictions from multiple models to minimize the effect this\nvariability may have on the care of individual patients when these models are\ndeployed clinically.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 03:18:18 GMT"}], "update_date": "2019-12-28", "authors_parsed": [["Zech", "John R.", ""], ["Forde", "Jessica Zosa", ""], ["Littman", "Michael L.", ""]]}, {"id": "1912.03609", "submitter": "Yi Xiang Marcus Tan", "authors": "Yi Xiang Marcus Tan, Yuval Elovici, Alexander Binder", "title": "Exploring the Back Alleys: Analysing The Robustness of Alternative\n  Neural Network Architectures against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate to what extent alternative variants of Artificial Neural\nNetworks (ANNs) are susceptible to adversarial attacks. We analyse the\nadversarial robustness of conventional, stochastic ANNs and Spiking Neural\nNetworks (SNNs) in the raw image space, across three different datasets. Our\nexperiments reveal that stochastic ANN variants are almost equally as\nsusceptible as conventional ANNs when faced with simple iterative\ngradient-based attacks in the white-box setting. However we observe, that in\nblack-box settings, stochastic ANNs are more robust than conventional ANNs,\nwhen faced with boundary attacks, transferability and surrogate attacks.\nConsequently, we propose improved attacks and defence mechanisms for stochastic\nANNs in black-box settings. When performing surrogate-based black-box attacks,\none can employ stochastic models as surrogates to observe higher attack success\non both stochastic and deterministic targets. This success can be further\nimproved with our proposed Variance Mimicking (VM) surrogate training method,\nagainst stochastic targets. Finally, adopting a defender's perspective, we\ninvestigate the plausibility of employing stochastic switching of model\nmixtures as a viable hardening mechanism. We observe that such a scheme does\nprovide a partial hardening.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 03:47:06 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:15:59 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 06:41:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Tan", "Yi Xiang Marcus", ""], ["Elovici", "Yuval", ""], ["Binder", "Alexander", ""]]}, {"id": "1912.03618", "submitter": "Aman Sinha", "authors": "Justin Norden, Matthew O'Kelly, Aman Sinha", "title": "Efficient Black-box Assessment of Autonomous Vehicle Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While autonomous vehicle (AV) technology has shown substantial progress, we\nstill lack tools for rigorous and scalable testing. Real-world testing, the\n$\\textit{de-facto}$ evaluation method, is dangerous to the public. Moreover,\ndue to the rare nature of failures, billions of miles of driving are needed to\nstatistically validate performance claims. Thus, the industry has largely\nturned to simulation to evaluate AV systems. However, having a simulation stack\nalone is not a solution. A simulation testing framework needs to prioritize\nwhich scenarios to run, learn how the chosen scenarios provide coverage of\nfailure modes, and rank failure scenarios in order of importance. We implement\na simulation testing framework that evaluates an entire modern AV system as a\nblack box. This framework estimates the probability of accidents under a base\ndistribution governing standard traffic behavior. In order to accelerate\nrare-event probability evaluation, we efficiently learn to identify and rank\nfailure scenarios via adaptive importance-sampling methods. Using this\nframework, we conduct the first independent evaluation of a full-stack\ncommercial AV system, Comma AI's OpenPilot.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 05:12:17 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:56:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Norden", "Justin", ""], ["O'Kelly", "Matthew", ""], ["Sinha", "Aman", ""]]}, {"id": "1912.03624", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Sunabha Chatterjee, Piyush Rai", "title": "Bayesian Structure Adaptation for Continual Learning", "comments": "17 pages, 16 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning is a learning paradigm where learning systems are trained\nwith sequential or streaming tasks. Two notable directions among the recent\nadvances in continual learning with neural networks are ($i$) variational Bayes\nbased regularization by learning priors from previous tasks, and, ($ii$)\nlearning the structure of deep networks to adapt to new tasks. So far, these\ntwo approaches have been orthogonal. We present a novel Bayesian approach to\ncontinual learning based on learning the structure of deep neural networks,\naddressing the shortcomings of both these approaches. The proposed model learns\nthe deep structure for each task by learning which weights to be used, and\nsupports inter-task transfer through the overlapping of different sparse\nsubsets of weights learned by different tasks. Experimental results on\nsupervised and unsupervised benchmarks shows that our model performs comparably\nor better than recent advances in continual learning setting.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 06:40:44 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 16:34:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Kumar", "Abhishek", ""], ["Chatterjee", "Sunabha", ""], ["Rai", "Piyush", ""]]}, {"id": "1912.03629", "submitter": "Francis Williams", "authors": "Francis Williams, Daniele Panozzo, Kwang Moo Yi, Andrea Tagliasacchi", "title": "VoronoiNet: General Functional Approximators with Local Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voronoi diagrams are highly compact representations that are used in various\nGraphics applications. In this work, we show how to embed a differentiable\nversion of it -- via a novel deep architecture -- into a generative deep\nnetwork. By doing so, we achieve a highly compact latent embedding that is able\nto provide much more detailed reconstructions, both in 2D and 3D, for various\nshapes. In this tech report, we introduce our representation and present a set\nof preliminary results comparing it with recently proposed implicit occupancy\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 07:12:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Williams", "Francis", ""], ["Panozzo", "Daniele", ""], ["Yi", "Kwang Moo", ""], ["Tagliasacchi", "Andrea", ""]]}, {"id": "1912.03634", "submitter": "Ali Ghofrani", "authors": "Ali Ghofrani, Rahil Mahdian Toroghi", "title": "Capsule-Based Persian/Arabic Robust Handwritten Digit Recognition Using\n  EM Routing", "comments": "5 pages, 10 figures, 4th International Conference on Pattern\n  Recognition and Image Analysis (IPRIA2019), IEEE", "journal-ref": null, "doi": "10.1109/PRIA.2019.8785981", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of handwritten digit recognition has been\naddressed. However, the underlying language is Persian/Arabic, and the system\nwith which this task is a capsule network (CapsNet) has recently emerged as a\nmore advanced architecture than its ancestor, namely CNN (Convolutional Neural\nNetwork). The training of the architecture is performed using the Hoda dataset,\nwhich has been provided for Persian/Arabic handwritten digits. The output of\nthe system clearly outperforms the results achieved by its ancestors, as well\nas other previously presented recognition algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 07:58:26 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 20:00:22 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Ghofrani", "Ali", ""], ["Toroghi", "Rahil Mahdian", ""]]}, {"id": "1912.03652", "submitter": "Johannes Schneider", "authors": "Johannes Schneider", "title": "Human-to-AI Coach: Improving Human Inputs to AI Systems", "comments": null, "journal-ref": "Symposium on Intelligent Data Analysis 2020, Konstanz", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans increasingly interact with Artificial intelligence(AI) systems. AI\nsystems are optimized for objectives such as minimum computation or minimum\nerror rate in recognizing and interpreting inputs from humans. In contrast,\ninputs created by humans are often treated as a given. We investigate how\ninputs of humans can be altered to reduce misinterpretation by the AI system\nand to improve efficiency of input generation for the human while altered\ninputs should remain as similar as possible to the original inputs. These\nobjectives result in trade-offs that are analyzed for a deep learning system\nclassifying handwritten digits. To create examples that serve as demonstrations\nfor humans to improve, we develop a model based on a conditional convolutional\nautoencoder (CCAE). Our quantitative and qualitative evaluation shows that in\nmany occasions the generated proposals lead to lower error rates, require less\neffort to create and differ only modestly from the original samples.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 10:43:43 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 21:33:52 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schneider", "Johannes", ""]]}, {"id": "1912.03656", "submitter": "Maurits Bleeker", "authors": "Maurits Bleeker and Maarten de Rijke", "title": "Bidirectional Scene Text Recognition with a Single Decoder", "comments": "8 pages. In 24th European Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene Text Recognition (STR) is the problem of recognizing the correct word\nor character sequence in a cropped word image. To obtain more robust output\nsequences, the notion of bidirectional STR has been introduced. So far,\nbidirectional STRs have been implemented by using two separate decoders; one\nfor left-to-right decoding and one for right-to-left. Having two separate\ndecoders for almost the same task with the same output space is undesirable\nfrom a computational and optimization point of view. We introduce the\nbidirectional Scene Text Transformer (Bi-STET), a novel bidirectional STR\nmethod with a single decoder for bidirectional text decoding. With its single\ndecoder, Bi-STET outperforms methods that apply bidirectional decoding by using\ntwo separate decoders while also being more efficient than those methods,\nFurthermore, we achieve or beat state-of-the-art (SOTA) methods on all STR\nbenchmarks with Bi-STET. Finally, we provide analyses and insights into the\nperformance of Bi-STET.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 11:20:35 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:44:34 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bleeker", "Maurits", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1912.03668", "submitter": "Haihui Pan", "authors": "Zhifang Liao, Haihui Pan, Qi Zeng, Xiaoping Fan, Yan Zhang, Song Yu", "title": "Short-term Load Forecasting with Dense Average Network", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important part of the power system, power load forecasting directly\naffects the national economy. The data shows that improving the load\nforecasting accuracy by 0.01% can save millions of dollars for the power\nindustry. Therefore, improving the accuracy of power load forecasting has\nalways been the pursuing goals for a power system. Based on this goal, this\npaper proposes a novel connection, the dense average connection, in which the\noutputs of all preceding layers are averaged as the input of the next layer in\na feed-forward fashion. Based on dense average connection , we construct the\ndense average network for power load forecasting. The predictions of the\nproposed model for two public datasets are better than those of existing\nmethods. On this basis, we use the ensemble method to further improve the\naccuracy of the model. To verify the reliability of the model predictions, the\nrobustness is analyzed and verified by adding input disturbances. The\nexperimental results show that the proposed model is effective and robust for\npower load forecasting.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 12:19:07 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 11:14:22 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 03:51:18 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liao", "Zhifang", ""], ["Pan", "Haihui", ""], ["Zeng", "Qi", ""], ["Fan", "Xiaoping", ""], ["Zhang", "Yan", ""], ["Yu", "Song", ""]]}, {"id": "1912.03673", "submitter": "Matthias Rottmann", "authors": "Matthias Rottmann, Kira Maag, Robin Chan, Fabian H\\\"uger, Peter\n  Schlicht, Hanno Gottschalk", "title": "Detection of False Positive and False Negative Samples in Semantic\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning methods have outperformed other methods in\nimage recognition. This has fostered imagination of potential application of\ndeep learning technology including safety relevant applications like the\ninterpretation of medical images or autonomous driving. The passage from\nassistance of a human decision maker to ever more automated systems however\nincreases the need to properly handle the failure modes of deep learning\nmodules. In this contribution, we review a set of techniques for the\nself-monitoring of machine-learning algorithms based on uncertainty\nquantification. In particular, we apply this to the task of semantic\nsegmentation, where the machine learning algorithm decomposes an image\naccording to semantic categories. We discuss false positive and false negative\nerror modes at instance-level and review techniques for the detection of such\nerrors that have been recently proposed by the authors. We also give an outlook\non future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 13:04:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Rottmann", "Matthias", ""], ["Maag", "Kira", ""], ["Chan", "Robin", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1912.03685", "submitter": "Haishan Wu", "authors": "Xin Hou, Biao Wang, Wanqi Hu, Lei Yin, Haishan Wu", "title": "SolarNet: A Deep Learning Framework to Map Solar Power Plants In China\n  From Satellite Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Renewable energy such as solar power is critical to fight the ever more\nserious climate change. China is the world leading installer of solar panel and\nnumerous solar power plants were built. In this paper, we proposed a deep\nlearning framework named SolarNet which is designed to perform semantic\nsegmentation on large scale satellite imagery data to detect solar farms.\nSolarNet has successfully mapped 439 solar farms in China, covering near 2000\nsquare kilometers, equivalent to the size of whole Shenzhen city or two and a\nhalf of New York city. To the best of our knowledge, it is the first time that\nwe used deep learning to reveal the locations and sizes of solar farms in\nChina, which could provide insights for solar power companies, market analysts\nand the government.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 14:19:47 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 15:27:33 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Hou", "Xin", ""], ["Wang", "Biao", ""], ["Hu", "Wanqi", ""], ["Yin", "Lei", ""], ["Wu", "Haishan", ""]]}, {"id": "1912.03699", "submitter": "Ying Jin", "authors": "Ying Jin, Ximei Wang, Mingsheng Long, Jianmin Wang", "title": "Minimum Class Confusion for Versatile Domain Adaptation", "comments": "Accepted by ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a variety of Domain Adaptation (DA) scenarios subject to label sets\nand domain configurations, including closed-set and partial-set DA, as well as\nmulti-source and multi-target DA. It is notable that existing DA methods are\ngenerally designed only for a specific scenario, and may underperform for\nscenarios they are not tailored to. To this end, this paper studies Versatile\nDomain Adaptation (VDA), where one method can handle several different DA\nscenarios without any modification. Towards this goal, a more general inductive\nbias other than the domain alignment should be explored. We delve into a\nmissing piece of existing methods: class confusion, the tendency that a\nclassifier confuses the predictions between the correct and ambiguous classes\nfor target examples, which is common in different DA scenarios. We uncover that\nreducing such pairwise class confusion leads to significant transfer gains.\nWith this insight, we propose a general loss function: Minimum Class Confusion\n(MCC). It can be characterized as (1) a non-adversarial DA method without\nexplicitly deploying domain alignment, enjoying faster convergence speed; (2) a\nversatile approach that can handle four existing scenarios: Closed-Set,\nPartial-Set, Multi-Source, and Multi-Target DA, outperforming the\nstate-of-the-art methods in these scenarios, especially on one of the largest\nand hardest datasets to date (7.3% on DomainNet). Its versatility is further\njustified by two scenarios proposed in this paper: Multi-Source Partial DA and\nMulti-Target Partial DA. In addition, it can also be used as a general\nregularizer that is orthogonal and complementary to a variety of existing DA\nmethods, accelerating convergence and pushing these readily competitive methods\nto stronger ones. Code is available at\nhttps://github.com/thuml/Versatile-Domain-Adaptation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 15:31:14 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 12:41:22 GMT"}, {"version": "v3", "created": "Mon, 10 Aug 2020 15:49:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Jin", "Ying", ""], ["Wang", "Ximei", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""]]}, {"id": "1912.03700", "submitter": "Dibyendu Das", "authors": "Dibyendu Das, Shahid Asghar Ahmad, Kumar Venkataramanan", "title": "Deep Learning-based Hybrid Graph-Coloring Algorithm for Register\n  Allocation", "comments": "11 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Register allocation, which is a crucial phase of a good optimizing compiler,\nrelies on graph coloring. Hence, an efficient graph coloring algorithm is of\nparamount importance. In this work we try to learn a good heuristic for\ncoloring interference graphs that are used in the register allocation phase. We\naim to handle moderate sized interference graphs which have 100 nodes or less.\nFor such graphs we can get the optimal allocation of colors to the nodes. Such\noptimal coloring is then used to train our Deep Learning network which is based\non several layers of LSTM that output a color for each node of the graph.\nHowever, the current network may allocate the same color to the nodes connected\nby an edge resulting in an invalid coloring of the interference graph. Since it\nis difficult to encode constraints in an LSTM to avoid invalid coloring, we\naugment our deep learning network with a color correction phase that runs after\nthe colors have been allocated by the network. Thus, our algorithm is hybrid in\nnature consisting of a mix of a deep learning algorithm followed by a more\ntraditional correction phase. We have trained our network using several\nthousand random graphs of varying sparsity. On application of our hybrid\nalgorithm to various popular graphs found in literature we see that our\nalgorithm does very well when compared to the optimal coloring of these graphs.\nWe have also run our algorithm against LLVMs popular greedy register allocator\nfor several SPEC CPU 2017 benchmarks and notice that the hybrid algorithm\nperforms on par or better than such a well-tuned allocator for most of these\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 15:36:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Das", "Dibyendu", ""], ["Ahmad", "Shahid Asghar", ""], ["Venkataramanan", "Kumar", ""]]}, {"id": "1912.03702", "submitter": "Yi Zhong", "authors": "Yi Zhong, Xueyu Chen, Yu Zhao, Xiaoming Chen, Tingfang Gao, Zuquan\n  Weng", "title": "Graph-augmented Convolutional Networks on Drug-Drug Interactions\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end model to predict drug-drug interactions (DDIs) by\nemploying graph-augmented convolutional networks. And this is implemented by\ncombining graph CNN with an attentive pooling network to extract structural\nrelations between drug pairs and make DDI predictions. The experiment results\nsuggest a desirable performance achieving ROC at 0.988, F1-score at 0.956, and\nAUPR at 0.986. Besides, the model can tell how the two DDI drugs interact\nstructurally by varying colored atoms. And this may be helpful for drug design\nduring drug discovery.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 15:43:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhong", "Yi", ""], ["Chen", "Xueyu", ""], ["Zhao", "Yu", ""], ["Chen", "Xiaoming", ""], ["Gao", "Tingfang", ""], ["Weng", "Zuquan", ""]]}, {"id": "1912.03703", "submitter": "Bhagya Hettige", "authors": "Bhagya Hettige, Yuan-Fang Li, Weiqing Wang, Suong Le and Wray Buntine", "title": "$\\mathtt{MedGraph:}$ Structural and Temporal Representation Learning of\n  Electronic Medical Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical record (EMR) data contains historical sequences of visits\nof patients, and each visit contains rich information, such as patient\ndemographics, hospital utilisation and medical codes, including diagnosis,\nprocedure and medication codes. Most existing EMR embedding methods capture\nvisit-code associations by constructing input visit representations as binary\nvectors with a static vocabulary of medical codes. With this limited\nrepresentation, they fail in encapsulating rich attribute information of visits\n(demographics and utilisation information) and/or codes (e.g., medical code\ndescriptions). Furthermore, current work considers visits of the same patient\nas discrete-time events and ignores time gaps between them. However, the time\ngaps between visits depict dynamics of the patient's medical history inducing\nvarying influences on future visits. To address these limitations, we present\n$\\mathtt{MedGraph}$, a supervised EMR embedding method that captures two types\nof information: (1) the visit-code associations in an attributed bipartite\ngraph, and (2) the temporal sequencing of visits through a point process.\n$\\mathtt{MedGraph}$ produces Gaussian embeddings for visits and codes to model\nthe uncertainty. We evaluate the performance of $\\mathtt{MedGraph}$ through an\nextensive experimental study and show that $\\mathtt{MedGraph}$ outperforms\nstate-of-the-art EMR embedding methods in several medical risk prediction\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 15:43:52 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 01:15:43 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 02:06:31 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Hettige", "Bhagya", ""], ["Li", "Yuan-Fang", ""], ["Wang", "Weiqing", ""], ["Le", "Suong", ""], ["Buntine", "Wray", ""]]}, {"id": "1912.03716", "submitter": "Yunbo Wang", "authors": "Zhiyu Yao, Yunbo Wang, Xingqiang Du, Mingsheng Long, Jianmin Wang", "title": "Adversarial Pyramid Network for Video Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new research problem of video domain generalization\n(video DG) where most state-of-the-art action recognition networks degenerate\ndue to the lack of exposure to the target domains of divergent distributions.\nWhile recent advances in video understanding focus on capturing the temporal\nrelations of the long-term video context, we observe that the global temporal\nfeatures are less generalizable in the video DG settings. The reason is that\nvideos from other unseen domains may have unexpected absence, misalignment, or\nscale transformation of the temporal relations, which is known as the temporal\ndomain shift. Therefore, the video DG is even more challenging than the image\nDG, which is also under-explored, because of the entanglement of the spatial\nand temporal domain shifts.\n  This finding has led us to view the key to video DG as how to effectively\nlearn the local-relation features of different time scales that are more\ngeneralizable, and how to exploit them along with the global-relation features\nto maintain the discriminability. This paper presents the Adversarial Pyramid\nNetwork (APN), which captures the local-relation, global-relation, and\nmultilayer cross-relation features progressively. This pyramid network not only\nimproves the feature transferability from the view of representation learning,\nbut also enhances the diversity and quality of the new data points that can\nbridge different domains when it is integrated with an improved version of the\nimage DG adversarial data augmentation method. We construct four video DG\nbenchmarks: UCF-HMDB, Something-Something, PKU-MMD, and NTU, in which the\nsource and target domains are divided according to different datasets,\ndifferent consequences of actions, or different camera views. The APN\nconsistently outperforms previous action recognition models over all\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 17:13:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Yao", "Zhiyu", ""], ["Wang", "Yunbo", ""], ["Du", "Xingqiang", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""]]}, {"id": "1912.03718", "submitter": "Amartansh Dubey", "authors": "Samruddhi Deshmukh, Amartansh Dubey", "title": "Improved Covariance Matrix Estimator using Shrinkage Transformation and\n  Random Matrix Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in multivariate analysis is the estimation of\npopulation covariance matrix from sample covariance matrix (SCM). Most recent\ncovariance matrix estimators use either shrinkage transformations or asymptotic\nresults from Random Matrix Theory (RMT). Shrinkage techniques help in pulling\nextreme correlation values towards certain target values whereas tools from RMT\nhelp in removing noisy eigenvalues of SCM. Both of these techniques use\ndifferent approaches to achieve a similar goal which is to remove noisy\ncorrelations and add structure to SCM to overcome the bias-variance trade-off.\nIn this paper, we first critically evaluate the pros and cons of these two\ntechniques and then propose an improved estimator which exploits the advantages\nof both by taking an optimally weighted convex combination of covariance\nmatrices estimated by an improved shrinkage transformation and a RMT based\nfilter. It is a generalized estimator which can adapt to changing sampling\nnoise conditions in various datasets by performing hyperparameter optimization.\nWe show the effectiveness of this estimator on the problem of designing a\nfinancial portfolio with minimum risk. We have chosen this problem because the\ncomplex properties of stock market data provide extreme conditions to test the\nrobustness of a covariance estimator. Using data from four of the world's\nlargest stock exchanges, we show that our proposed estimator outperforms\nexisting estimators in minimizing the out-of-sample risk of the portfolio and\nhence predicts population statistics more precisely. Since covariance analysis\nis a crucial statistical tool, this estimator can be used in a wide range of\nmachine learning, signal processing and high dimensional pattern recognition\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 17:15:58 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Deshmukh", "Samruddhi", ""], ["Dubey", "Amartansh", ""]]}, {"id": "1912.03720", "submitter": "Wei Zhang", "authors": "Wei Zhang, Chao Dong, Jianhua Yin, Jianyong Wang", "title": "Attentive Representation Learning with Adversarial Training for Short\n  Text Clustering", "comments": "14pages, to appear in IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text clustering has far-reaching effects on semantic analysis, showing\nits importance for multiple applications such as corpus summarization and\ninformation retrieval. However, it inevitably encounters the severe sparsity of\nshort text representations, making the previous clustering approaches still far\nfrom satisfactory. In this paper, we present a novel attentive representation\nlearning model for shot text clustering, wherein cluster-level attention is\nproposed to capture the correlations between text representations and cluster\nrepresentations. Relying on this, the representation learning and clustering\nfor short texts are seamlessly integrated into a unified model. To further\nensure robust model training for short texts, we apply adversarial training to\nthe unsupervised clustering setting, by injecting perturbations into the\ncluster representations. The model parameters and perturbations are optimized\nalternately through a minimax game. Extensive experiments on four real-world\nshort text datasets demonstrate the superiority of the proposed model over\nseveral strong competitors, verifying that robust adversarial training yields\nsubstantial performance gains.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 17:22:07 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 01:18:30 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Zhang", "Wei", ""], ["Dong", "Chao", ""], ["Yin", "Jianhua", ""], ["Wang", "Jianyong", ""]]}, {"id": "1912.03735", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei and Xin Liu", "title": "Security of Deep Learning Methodologies: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the plethora of studies about security vulnerabilities and defenses\nof deep learning models, security aspects of deep learning methodologies, such\nas transfer learning, have been rarely studied. In this article, we highlight\nthe security challenges and research opportunities of these methodologies,\nfocusing on vulnerabilities and attacks unique to them.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:23:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Liu", "Xin", ""]]}, {"id": "1912.03747", "submitter": "\\'Oscar Gil Viyuela", "authors": "\\'Oscar Gil Viyuela and Alberto Sanfeliu", "title": "Effects of a Social Force Model reward in Robot Navigation based on Deep\n  Reinforcement Learning", "comments": "This is a preprint. This paper has been accepted to the fourth\n  Iberian Robotics Conference (Robot 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-36150-1_18", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper is proposed an inclusion of the Social Force Model (SFM) into a\nconcrete Deep Reinforcement Learning (RL) framework for robot navigation. These\ntypes of techniques have demonstrated to be useful to deal with different types\nof environments to achieve a goal. In Deep RL, a description of the world to\ndescribe the states and a reward adapted to the environment are crucial\nelements to get the desire behaviour and achieve a high performance. For this\nreason, this work adds a dense reward function based on SFM and uses the forces\nin the states like an additional description. Furthermore, obstacles are added\nto improve the behaviour of works that only consider moving agents. This SFM\ninclusion can offer a better description of the obstacles for the navigation.\nSeveral simulations have been done to check the effects of these modifications\nin the average performance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 19:43:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Viyuela", "\u00d3scar Gil", ""], ["Sanfeliu", "Alberto", ""]]}, {"id": "1912.03760", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui, Radu Tudor Ionescu", "title": "Convolutional Neural Networks for User Identificationbased on Motion\n  Sensors Represented as Image", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep learning approach for smartphone user\nidentification based on analyzing motion signals recorded by the accelerometer\nand the gyroscope, during a single tap gesture performed by the user on the\nscreen. We transform the discrete 3-axis signals from the motion sensors into a\ngray-scale image representation which is provided as input to a convolutional\nneural network (CNN) that is pre-trained for multi-class user classification.\nIn the pre-training stage, we benefit from different users and multiple samples\nper user. After pre-training, we use our CNN as feature extractor, generating\nan embedding associated to each single tap on the screen. The resulting\nembeddings are used to train a Support Vector Machines (SVM) model in a\nfew-shot user identification setting, i.e. requiring only 20 taps on the screen\nduring the registration phase. We compare our identification system based on\nCNN features with two baseline systems, one that employs handcrafted features\nand another that employs recurrent neural network (RNN) features. All systems\nare based on the same classifier, namely SVM. To pre-train the CNN and the RNN\nmodels for multi-class user classification, we use a different set of users\nthan the set used for few-shot user identification, ensuring a realistic\nscenario. The empirical results demonstrate that our CNN model yields a top\naccuracy of 89.75% in multi-class user classification and a top accuracy of\n96.72% in few-shot user identification. In conclusion, we believe that our\nsystem is ready for practical use, having a better generalization capacity than\nboth baselines.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 21:04:43 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:05:12 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1912.03761", "submitter": "Weicheng Zhu", "authors": "Weicheng Zhu, Narges Razavian", "title": "Variationally Regularized Graph-based Representation Learning for\n  Electronic Health Records", "comments": null, "journal-ref": null, "doi": "10.1145/3450439.3451855", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHR) are high-dimensional data with implicit\nconnections among thousands of medical concepts. These connections, for\ninstance, the co-occurrence of diseases and lab-disease correlations can be\ninformative when only a subset of these variables is documented by the\nclinician. A feasible approach to improving the representation learning of EHR\ndata is to associate relevant medical concepts and utilize these connections.\nExisting medical ontologies can be the reference for EHR structures, but they\nplace numerous constraints on the data source. Recent progress on graph neural\nnetworks (GNN) enables end-to-end learning of topological structures for\nnon-grid or non-sequential data. However, there are problems to be addressed on\nhow to learn the medical graph adaptively and how to understand the effect of\nthe medical graph on representation learning. In this paper, we propose a\nvariationally regularized encoder-decoder graph network that achieves more\nrobustness in graph structure learning by regularizing node representations.\nOur model outperforms the existing graph and non-graph based methods in various\nEHR predictive tasks based on both public data and real-world clinical data.\nBesides the improvements in empirical experiment performances, we provide an\ninterpretation of the effect of variational regularization compared to standard\ngraph neural network, using singular value analysis.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 21:06:38 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 04:11:09 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Zhu", "Weicheng", ""], ["Razavian", "Narges", ""]]}, {"id": "1912.03769", "submitter": "Arunkumar Bagavathi", "authors": "Arunkumar Bagavathi, Siddharth Krishnan, Sanjay Subrahmanyan, and S.\n  L. Narasimhan", "title": "ragamAI: A Network Based Recommender System to Arrange a Indian\n  Classical Music Concert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  South Indian classical music (Carnatic music) is best consumed through live\nconcerts. A carnatic recital requires meticulous planning accounting for\nseveral parameters like the performers' repertoire, composition variety,\nmusical versatility, thematic structure, the recital's arrangement, etc. to\nensure that the audience have a comprehensive listening experience. In this\nwork, we present ragamAI a novel machine learning framework that utilizes the\ntonic nuances and musical structures in the carnatic music to generate a\nconcert recital that melodically captures the entire range in an octave.\nUtilizing the underlying idea of playlist and session-based recommender models,\nthe proposed model studies the mathematical structure present in past concerts\nand recommends relevant items for the playlist/concert. ragamAI ensembles\nrecommendations given by multiple models to learn user idea and past preference\nof sequences in concerts to extract recommendations. Our experiments on a vast\ncollection of concert show that our model performs 25%-50% better than baseline\nmodels. ragamAI's applications are two-fold. 1) it will assist musicians to\ncustomize their performance with the necessary variety required to sustain the\ninterest of the audience for the entirety of the concert 2) it will generate\ncarefully curated lists of south Indian classical music so that the listener\ncan discover the wide range of melody that the musical system can offer.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 21:39:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bagavathi", "Arunkumar", ""], ["Krishnan", "Siddharth", ""], ["Subrahmanyan", "Sanjay", ""], ["Narasimhan", "S. L.", ""]]}, {"id": "1912.03771", "submitter": "Anton Osokin", "authors": "Irina Saparina and Anton Osokin", "title": "Cost-Sensitive Training for Autoregressive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training autoregressive models to better predict under the test metric,\ninstead of maximizing the likelihood, has been reported to be beneficial in\nseveral use cases but brings additional complications, which prevent wider\nadoption. In this paper, we follow the learning-to-search approach (Daum\\'e III\net al., 2009; Leblond et al., 2018) and investigate its several components.\nFirst, we propose a way to construct a reference policy based on an alignment\nbetween the model output and ground truth. Our reference policy is optimal when\napplied to the Kendall-tau distance between permutations (appear in the task of\nword ordering) and helps when working with the METEOR score for machine\ntranslation. Second, we observe that the learning-to-search approach benefits\nfrom choosing the costs related to the test metrics. Finally, we study the\neffect of different learning objectives and find that the standard KL loss only\nlearns several high-probability tokens and can be replaced with ranking\nobjectives that target these tokens explicitly.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 21:57:56 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Saparina", "Irina", ""], ["Osokin", "Anton", ""]]}, {"id": "1912.03785", "submitter": "Jerome Friedman", "authors": "Jerome H. Friedman", "title": "Contrast Trees and Distribution Boosting", "comments": "18 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often machine learning methods are applied and results reported in cases\nwhere there is little to no information concerning accuracy of the output.\nSimply because a computer program returns a result does not insure its\nvalidity. If decisions are to be made based on such results it is important to\nhave some notion of their veracity. Contrast trees represent a new approach for\nassessing the accuracy of many types of machine learning estimates that are not\namenable to standard (cross) validation methods. In situations where\ninaccuracies are detected boosted contrast trees can often improve performance.\nA special case, distribution boosting, provides an assumption free method for\nestimating the full probability distribution of an outcome variable given any\nset of joint input predictor variable values.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 23:30:25 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Friedman", "Jerome H.", ""]]}, {"id": "1912.03787", "submitter": "Austin Dill", "authors": "Austin Dill, Chun-Liang Li, Songwei Ge, Eunsu Kang", "title": "Getting Topology and Point Cloud Generation to Mesh", "comments": "Sets & Partitions Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore the idea that effective generative models for point\nclouds under the autoencoding framework must acknowledge the relationship\nbetween a continuous surface, a discretized mesh, and a set of points sampled\nfrom the surface. This view motivates a generative model that works by\nprogressively deforming a uniform sphere until it approximates the goal point\ncloud. We review the underlying concepts leading to this conclusion from\ncomputer graphics and topology in differential geometry, and model the\ngeneration process as deformation via deep neural network parameterization.\nFinally, we show that this view of the problem produces a model that can\ngenerate quality meshes efficiently.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 23:36:04 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Dill", "Austin", ""], ["Li", "Chun-Liang", ""], ["Ge", "Songwei", ""], ["Kang", "Eunsu", ""]]}, {"id": "1912.03789", "submitter": "Rishu Garg", "authors": "Saumil Maheshwari, Rohit Verma, Anupam Shukla, Ritu Tiwari and Rishu\n  Garg", "title": "Feature Engineering Combined with 1 D Convolutional Neural Network for\n  Improved Mortality Prediction", "comments": "Being a short term project, this paper is not exhaustive", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intensive care units (ICUs) are responsible for generating a wealth of\nuseful data in the form of Electronic Health Record (EHR). This data allows for\nthe development of a prediction tool with perfect knowledge backing. We aimed\nto build a mortality prediction model on 2012 Physionet Challenge mortality\nprediction database of 4000 patients admitted in ICU. The challenges in the\ndataset, such as high dimensionality, imbalanced distribution, and missing\nvalues were tackled with analytical methods and tools via feature engineering\nand new variable construction. The objective of the research is to utilize the\nrelations among the clinical variables and construct new variables which would\nestablish the effectiveness of 1-Dimensional Convolutional Neural Network (1- D\nCNN) with constructed features. Its performance with the traditional machine\nlearning algorithms like XGBoost classifier, Support Vector Machine (SVM),\nK-Neighbours Classifier (K-NN), and Random Forest Classifier (RF) is compared\nfor Area Under Curve (AUC). The investigation reveals the best AUC of 0.848\nusing 1-D CNN model.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 23:52:58 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 10:27:23 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Maheshwari", "Saumil", ""], ["Verma", "Rohit", ""], ["Shukla", "Anupam", ""], ["Tiwari", "Ritu", ""], ["Garg", "Rishu", ""]]}, {"id": "1912.03790", "submitter": "Giovanni Apruzzese", "authors": "Giovanni Apruzzese, Mauro Andreolini, Michele Colajanni, Mirco\n  Marchetti", "title": "Hardening Random Forest Cyber Detectors Against Adversarial Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/TETCI.2019.2961157", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are effective in several applications, but they\nare not as much successful when applied to intrusion detection in cyber\nsecurity. Due to the high sensitivity to their training data, cyber detectors\nbased on machine learning are vulnerable to targeted adversarial attacks that\ninvolve the perturbation of initial samples. Existing defenses assume\nunrealistic scenarios; their results are underwhelming in non-adversarial\nsettings; or they can be applied only to machine learning algorithms that\nperform poorly for cyber security. We present an original methodology for\ncountering adversarial perturbations targeting intrusion detection systems\nbased on random forests. As a practical application, we integrate the proposed\ndefense method in a cyber detector analyzing network traffic. The experimental\nresults on millions of labelled network flows show that the new detector has a\ntwofold value: it outperforms state-of-the-art detectors that are subject to\nadversarial attacks; it exhibits robust results both in adversarial and\nnon-adversarial scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 00:02:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Apruzzese", "Giovanni", ""], ["Andreolini", "Mauro", ""], ["Colajanni", "Michele", ""], ["Marchetti", "Mirco", ""]]}, {"id": "1912.03798", "submitter": "Rishu Garg", "authors": "Rishu Garg, Saumil Maheshwari, Anupam Shukla", "title": "Decision Support System for Detection and Classification of Skin Cancer\n  using CNN", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin Cancer is one of the most deathful of all the cancers. It is bound to\nspread to different parts of the body on the off chance that it is not analyzed\nand treated at the beginning time. It is mostly because of the abnormal growth\nof skin cells, often develops when the body is exposed to sunlight. The\nDetection Furthermore, the characterization of skin malignant growth in the\nbeginning time is a costly and challenging procedure. It is classified where it\ndevelops and its cell type. High Precision and recall are required for the\nclassification of lesions. The paper aims to use MNIST HAM-10000 dataset\ncontaining dermoscopy images. The objective is to propose a system that detects\nskin cancer and classifies it in different classes by using the Convolution\nNeural Network. The diagnosing methodology uses Image processing and deep\nlearning model. The dermoscopy image of skin cancer taken, undergone various\ntechniques to remove the noise and picture resolution. The image count is also\nincreased by using various image augmentation techniques. In the end, the\nTransfer Learning method is used to increase the classification accuracy of the\nimages further. Our CNN model gave a weighted average Precision of 0.88, a\nweighted Recall average of 0.74, and a weighted f1-score of 0.77. The transfer\nlearning approach applied using ResNet model yielded an accuracy of 90.51%\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 00:49:24 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Garg", "Rishu", ""], ["Maheshwari", "Saumil", ""], ["Shukla", "Anupam", ""]]}, {"id": "1912.03802", "submitter": "Candice Schumann", "authors": "Candice Schumann, Zhi Lang, Nicholas Mattei, John P. Dickerson", "title": "Group Fairness in Bandit Arm Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel formulation of group fairness in the contextual\nmulti-armed bandit (CMAB) setting. In the CMAB setting a sequential decision\nmaker must at each time step choose an arm to pull from a finite set of arms\nafter observing some context for each of the potential arm pulls. In our model\narms are partitioned into two or more sensitive groups based on some protected\nfeature (e.g., age, race, or socio-economic status). Despite the fact that\nthere may be differences in expected payout between the groups, we may wish to\nensure some form of fairness between picking arms from the various groups. In\nthis work we explore two definitions of fairness: equal group probability,\nwherein the probability of pulling an arm from any of the protected groups is\nthe same; and proportional parity, wherein the probability of choosing an arm\nfrom a particular group is proportional to the size of that group. We provide a\nnovel algorithm that can accommodate these notions of fairness for an arbitrary\nnumber of groups, and provide bounds on the regret for our algorithm. We then\nvalidate our algorithm using synthetic data as well as two real-world datasets\nfor intervention settings wherein we want to allocate resources fairly across\nprotected groups.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 01:02:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:26:41 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Schumann", "Candice", ""], ["Lang", "Zhi", ""], ["Mattei", "Nicholas", ""], ["Dickerson", "John P.", ""]]}, {"id": "1912.03817", "submitter": "Varun Chandrasekaran", "authors": "Lucas Bourtoule, Varun Chandrasekaran, Christopher A. Choquette-Choo,\n  Hengrui Jia, Adelin Travers, Baiwu Zhang, David Lie and Nicolas Papernot", "title": "Machine Unlearning", "comments": "Published in IEEE S&P 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Once users have shared their data online, it is generally difficult for them\nto revoke access and ask for the data to be deleted. Machine learning (ML)\nexacerbates this problem because any model trained with said data may have\nmemorized it, putting users at risk of a successful privacy attack exposing\ntheir information. Yet, having models unlearn is notoriously difficult. We\nintroduce SISA training, a framework that expedites the unlearning process by\nstrategically limiting the influence of a data point in the training procedure.\nWhile our framework is applicable to any learning algorithm, it is designed to\nachieve the largest improvements for stateful algorithms like stochastic\ngradient descent for deep neural networks. SISA training reduces the\ncomputational overhead associated with unlearning, even in the worst-case\nsetting where unlearning requests are made uniformly across the training set.\nIn some cases, the service provider may have a prior on the distribution of\nunlearning requests that will be issued by users. We may take this prior into\naccount to partition and order data accordingly, and further decrease overhead\nfrom unlearning. Our evaluation spans several datasets from different domains,\nwith corresponding motivations for unlearning. Under no distributional\nassumptions, for simple learning tasks, we observe that SISA training improves\ntime to unlearn points from the Purchase dataset by 4.63x, and 2.45x for the\nSVHN dataset, over retraining from scratch. SISA training also provides a\nspeed-up of 1.36x in retraining for complex learning tasks such as ImageNet\nclassification; aided by transfer learning, this results in a small degradation\nin accuracy. Our work contributes to practical data governance in machine\nunlearning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:16:53 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 20:09:45 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 05:39:28 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bourtoule", "Lucas", ""], ["Chandrasekaran", "Varun", ""], ["Choquette-Choo", "Christopher A.", ""], ["Jia", "Hengrui", ""], ["Travers", "Adelin", ""], ["Zhang", "Baiwu", ""], ["Lie", "David", ""], ["Papernot", "Nicolas", ""]]}, {"id": "1912.03820", "submitter": "Mingzhang Yin", "authors": "Mingzhang Yin, George Tucker, Mingyuan Zhou, Sergey Levine, Chelsea\n  Finn", "title": "Meta-Learning without Memorization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn new concepts with small amounts of data is a critical\naspect of intelligence that has proven challenging for deep learning methods.\nMeta-learning has emerged as a promising technique for leveraging data from\nprevious tasks to enable efficient learning of new tasks. However, most\nmeta-learning algorithms implicitly require that the meta-training tasks be\nmutually-exclusive, such that no single model can solve all of the tasks at\nonce. For example, when creating tasks for few-shot image classification, prior\nwork uses a per-task random assignment of image classes to N-way classification\nlabels. If this is not done, the meta-learner can ignore the task training data\nand learn a single model that performs all of the meta-training tasks\nzero-shot, but does not adapt effectively to new image classes. This\nrequirement means that the user must take great care in designing the tasks,\nfor example by shuffling labels or removing task identifying information from\nthe inputs. In some domains, this makes meta-learning entirely inapplicable. In\nthis paper, we address this challenge by designing a meta-regularization\nobjective using information theory that places precedence on data-driven\nadaptation. This causes the meta-learner to decide what must be learned from\nthe task training data and what should be inferred from the task testing input.\nBy doing so, our algorithm can successfully use data from\nnon-mutually-exclusive tasks to efficiently adapt to novel tasks. We\ndemonstrate its applicability to both contextual and gradient-based\nmeta-learning algorithms, and apply it in practical settings where applying\nstandard meta-learning has been difficult. Our approach substantially\noutperforms standard meta-learning algorithms in these settings.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:30:46 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 19:49:41 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 22:33:53 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yin", "Mingzhang", ""], ["Tucker", "George", ""], ["Zhou", "Mingyuan", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1912.03821", "submitter": "Kaiqing Zhang", "authors": "Kaiqing Zhang, Zhuoran Yang, Tamer Ba\\c{s}ar", "title": "Decentralized Multi-Agent Reinforcement Learning with Networked Agents:\n  Recent Advances", "comments": "This is a invited submission to a Special Issue of the Journal of\n  Frontiers of Information Technology & Electronic Engineering (FITEE). Most of\n  the contents are based on the Sec. 4 in our recent overview arXiv:1911.10635,\n  with focus on the setting of decentralized MARL with networked agents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has long been a significant and\neverlasting research topic in both machine learning and control. With the\nrecent development of (single-agent) deep RL, there is a resurgence of\ninterests in developing new MARL algorithms, especially those that are backed\nby theoretical analysis. In this paper, we review some recent advances a\nsub-area of this topic: decentralized MARL with networked agents. Specifically,\nmultiple agents perform sequential decision-making in a common environment,\nwithout the coordination of any central controller. Instead, the agents are\nallowed to exchange information with their neighbors over a communication\nnetwork. Such a setting finds broad applications in the control and operation\nof robots, unmanned vehicles, mobile sensor networks, and smart grid. This\nreview is built upon several our research endeavors in this direction, together\nwith some progresses made by other researchers along the line. We hope this\nreview to inspire the devotion of more research efforts to this exciting yet\nchallenging area.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:33:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "1912.03832", "submitter": "Tapas Nayak", "authors": "Tapas Nayak and Hwee Tou Ng", "title": "Effective Attention Modeling for Neural Relation Extraction", "comments": "Accepted at CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction is the task of determining the relation between two\nentities in a sentence. Distantly-supervised models are popular for this task.\nHowever, sentences can be long and two entities can be located far from each\nother in a sentence. The pieces of evidence supporting the presence of a\nrelation between two entities may not be very direct, since the entities may be\nconnected via some indirect links such as a third entity or via co-reference.\nRelation extraction in such scenarios becomes more challenging as we need to\ncapture the long-distance interactions among the entities and other words in\nthe sentence. Also, the words in a sentence do not contribute equally in\nidentifying the relation between the two entities. To address this issue, we\npropose a novel and effective attention model which incorporates syntactic\ninformation of the sentence and a multi-factor attention mechanism. Experiments\non the New York Times corpus show that our proposed model outperforms prior\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 03:38:16 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nayak", "Tapas", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1912.03845", "submitter": "Giorgio Giannone", "authors": "Giorgio Giannone, Saeed Saremi, Jonathan Masci, Christian Osendorfer", "title": "No Representation without Transformation", "comments": "Preprint. Accepted at BDL and PGR workshops at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of variational autoencoders to represent\ntransformations explicitly in the latent space. In the family of hierarchical\ngraphical models that emerges, the latent space is populated by higher order\nobjects that are inferred jointly with the latent representations they act on.\nTo explicitly demonstrate the effect of these higher order objects, we show\nthat the inferred latent transformations reflect interpretable properties in\nthe observation space. Furthermore, the model is structured in such a way that\nin the absence of transformations, we can run inference and obtain generative\ncapabilities comparable with standard variational autoencoders. Finally,\nutilizing the trained encoder, we outperform the baselines by a wide margin on\na challenging out-of-distribution classification task.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:46:06 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 15:18:39 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Giannone", "Giorgio", ""], ["Saremi", "Saeed", ""], ["Masci", "Jonathan", ""], ["Osendorfer", "Christian", ""]]}, {"id": "1912.03851", "submitter": "Ujwal Padam Tewari", "authors": "Ujwal Padam Tewari, Vishal Bidawatka, Varsha Raveendran, Vinay\n  Sudhakaran, Shreedhar Kodate Shreeshail, Jayanth Prakash Kulkarni", "title": "Intelligent Coordination among Multiple Traffic Intersections Using\n  Multi-Agent Reinforcement Learning", "comments": "Accepted in the NeurIPS 2019 Deep RL Workshop :\n  https://sites.google.com/view/deep-rl-workshop-neurips-2019/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Asynchronous Advantage Actor Critic (A3C) for implementing an AI agent\nin the controllers that optimize flow of traffic across a single intersection\nand then extend it to multiple intersections by considering a multi-agent\nsetting. We explore three different methodologies to address the multi-agent\nproblem - (1) use of asynchronous property of A3C to control multiple\nintersections using a single agent (2) utilise self/competitive play among\nindependent agents across multiple intersections and (3) ingest a global reward\nfunction among agents to introduce cooperative behavior between intersections.\nWe observe that (1) & (2) leads to a reduction in traffic congestion.\nAdditionally the use of (3) with (1) & (2) led to a further reduction in\ncongestion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 04:54:31 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 12:53:18 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 15:58:24 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 14:21:09 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tewari", "Ujwal Padam", ""], ["Bidawatka", "Vishal", ""], ["Raveendran", "Varsha", ""], ["Sudhakaran", "Vinay", ""], ["Shreeshail", "Shreedhar Kodate", ""], ["Kulkarni", "Jayanth Prakash", ""]]}, {"id": "1912.03877", "submitter": "Xu Shibing", "authors": "Shibing Xu, Zishu Gao and Guojun Xie", "title": "Bi-Semantic Reconstructing Generative Network for Zero-shot Learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent methods of zero-shot learning (ZSL) attempt to utilize generative\nmodel to generate the unseen visual samples from semantic descriptions and\nrandom noise. Therefore, the ZSL problem becomes a traditional supervised\nclassification problem. However, most of the existing methods based on the\ngenerative model only focus on the quality of synthesized samples at the\ntraining stage, and ignore the importance of the zero-shot recognition stage.\nIn this paper, we consider both the above two points and propose a novel\napproach. Specially, we select the Generative Adversarial Network (GAN) as our\ngenerative model. In order to improve the quality of synthesized samples,\nconsidering the internal relation of the semantic description in the semantic\nspace as well as the fact that the seen and unseen visual information belong to\ndifferent domains, we propose a bi-semantic reconstructing (BSR) component\nwhich contain two different semantic reconstructing regressors to lead the\ntraining of GAN. Since the semantic descriptions are available during the\ntraining stage, to further improve the ability of classifier, we combine the\nvisual samples and semantic descriptions to train a classifier. At the\nrecognition stage, we naturally utilize the BSR component to transfer the\nvisual features and semantic descriptions, and concatenate them for\nclassification. Experimental results show that our method outperforms the state\nof the art on several ZSL benchmark datasets with significant improvements.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 07:12:18 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 07:48:36 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2020 16:47:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Xu", "Shibing", ""], ["Gao", "Zishu", ""], ["Xie", "Guojun", ""]]}, {"id": "1912.03884", "submitter": "Chao-I Tuan", "authors": "Chao-I Tuan, Yuan-Kuei Wu, Hung-yi Lee, Yu Tsao", "title": "MITAS: A Compressed Time-Domain Audio Separation Network with Parameter\n  Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning methods have brought substantial advancements in speech\nseparation (SS). Nevertheless, it remains challenging to deploy\ndeep-learning-based models on edge devices. Thus, identifying an effective way\nto compress these large models without hurting SS performance has become an\nimportant research topic. Recently, TasNet and Conv-TasNet have been proposed.\nThey achieved state-of-the-art results on several standardized SS tasks.\nMoreover, their low latency natures make them definitely suitable for real-time\non-device applications. In this study, we propose two parameter-sharing schemes\nto lower the memory consumption on TasNet and Conv-TasNet. Accordingly, we\nderive a novel so-called MiTAS (Mini TasNet). Our experimental results first\nconfirmed the robustness of our MiTAS on two types of perturbations in mixed\naudio. We also designed a series of ablation experiments to analyze the\nrelation between SS performance and the amount of parameters in the model. The\nresults show that MiTAS is able to reduce the model size by a factor of four\nwhile maintaining comparable SS performance with improved stability as compared\nto TasNet and Conv-TasNet. This suggests that MiTAS is more suitable for\nreal-time low latency applications.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 07:44:32 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Tuan", "Chao-I", ""], ["Wu", "Yuan-Kuei", ""], ["Lee", "Hung-yi", ""], ["Tsao", "Yu", ""]]}, {"id": "1912.03891", "submitter": "Petros Maragos", "authors": "Petros Maragos and Emmanouil Theodosis", "title": "Tropical Geometry and Piecewise-Linear Approximation of Curves and\n  Surfaces on Weighted Lattices", "comments": "39 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tropical Geometry and Mathematical Morphology share the same max-plus and\nmin-plus semiring arithmetic and matrix algebra. In this chapter we summarize\nsome of their main ideas and common (geometric and algebraic) structure,\ngeneralize and extend both of them using weighted lattices and a max-$\\star$\nalgebra with an arbitrary binary operation $\\star$ that distributes over max,\nand outline applications to geometry, machine learning, and optimization.\nFurther, we generalize tropical geometrical objects using weighted lattices.\nFinally, we provide the optimal solution of max-$\\star$ equations using\nmorphological adjunctions that are projections on weighted lattices, and apply\nit to optimal piecewise-linear regression for fitting max-$\\star$ tropical\ncurves and surfaces to arbitrary data that constitute polygonal or polyhedral\nshape approximations. This also includes an efficient algorithm for solving the\nconvex regression problem of data fitting with max-affine functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 08:06:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Maragos", "Petros", ""], ["Theodosis", "Emmanouil", ""]]}, {"id": "1912.03896", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis, Riyasat Ohib, Sergey Plis, Vamsi Potluru", "title": "Grouped sparse projection", "comments": "21 pages, 12 figures; affiliation corrected, grant added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As evident from deep learning, very large models bring improvements in\ntraining dynamics and representation power. Yet, smaller models have benefits\nof energy efficiency and interpretability. To get the benefits from both ends\nof the spectrum we often encourage sparsity in the model. Unfortunately, most\nexisting approaches do not have a controllable way to request a desired value\nof sparsity in an interpretable parameter. In this paper, we design a new\nsparse projection method for a set of vectors in order to achieve a desired\naverage level of sparsity which is measured using the ratio of the $\\ell_1$ and\n$\\ell_2$ norms. Most existing methods project each vector individuality trying\nto achieve a target sparsity, hence the user has to choose a sparsity level for\neach vector (e.g., impose that all vectors have the same sparsity). Instead, we\nproject all vectors together to achieve an average target sparsity, where the\nsparsity levels of the vectors is automatically tuned. We also propose a\ngeneralization of this projection using a new notion of weighted sparsity\nmeasured using the ratio of a weighted $\\ell_1$ and the $\\ell_2$ norms. These\nprojections can be used in particular to sparsify the columns of a matrix,\nwhich we use to compute sparse nonnegative matrix factorization and to learn\nsparse deep networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 08:24:29 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 09:18:13 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Gillis", "Nicolas", ""], ["Ohib", "Riyasat", ""], ["Plis", "Sergey", ""], ["Potluru", "Vamsi", ""]]}, {"id": "1912.03905", "submitter": "Prabhat Nagarajan", "authors": "Yasuhiro Fujita, Prabhat Nagarajan, Toshiki Kataoka, Takahiro Ishikawa", "title": "ChainerRL: A Deep Reinforcement Learning Library", "comments": "Journal of Machine Learning Research", "journal-ref": "Journal of Machine Learning Research 22(77) (2021) 1-14;", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce ChainerRL, an open-source deep reinforcement\nlearning (DRL) library built using Python and the Chainer deep learning\nframework. ChainerRL implements a comprehensive set of DRL algorithms and\ntechniques drawn from state-of-the-art research in the field. To foster\nreproducible research, and for instructional purposes, ChainerRL provides\nscripts that closely replicate the original papers' experimental settings and\nreproduce published benchmark results for several algorithms. Lastly, ChainerRL\noffers a visualization tool that enables the qualitative inspection of trained\nagents. The ChainerRL source code can be found on GitHub:\nhttps://github.com/chainer/chainerrl.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 08:59:15 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:24:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Fujita", "Yasuhiro", ""], ["Nagarajan", "Prabhat", ""], ["Kataoka", "Toshiki", ""], ["Ishikawa", "Takahiro", ""]]}, {"id": "1912.03915", "submitter": "Eduardo Hugo Sanchez", "authors": "Eduardo Hugo Sanchez (IRIT), Mathieu Serrurier (IRIT), Mathias Ortner", "title": "Learning Disentangled Representations via Mutual Information Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of learning disentangled\nrepresentations. Given a pair of images sharing some attributes, we aim to\ncreate a low-dimensional representation which is split into two parts: a shared\nrepresentation that captures the common information between the images and an\nexclusive representation that contains the specific information of each image.\nTo address this issue, we propose a model based on mutual information\nestimation without relying on image reconstruction or image generation. Mutual\ninformation maximization is performed to capture the attributes of data in the\nshared and exclusive representations while we minimize the mutual information\nbetween the shared and exclusive representation to enforce representation\ndisentanglement. We show that these representations are useful to perform\ndownstream tasks such as image classification and image retrieval based on the\nshared or exclusive component. Moreover, classification results show that our\nmodel outperforms the state-of-the-art model based on VAE/GAN approaches in\nrepresentation disentanglement.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:31:08 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sanchez", "Eduardo Hugo", "", "IRIT"], ["Serrurier", "Mathieu", "", "IRIT"], ["Ortner", "Mathias", ""]]}, {"id": "1912.03918", "submitter": "Uddeshya Upadhyay", "authors": "Uddeshya Upadhyay, Nikunj Shah, Sucheta Ravikanti, Mayanka Medhe", "title": "Transformer Based Reinforcement Learning For Games", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent times have witnessed sharp improvements in reinforcement learning\ntasks using deep reinforcement learning techniques like Deep Q Networks, Policy\nGradients, Actor Critic methods which are based on deep learning based models\nand back-propagation of gradients to train such models. An active area of\nresearch in reinforcement learning is about training agents to play complex\nvideo games, which so far has been something accomplished only by human\nintelligence. Some state of the art performances in video game playing using\ndeep reinforcement learning are obtained by processing the sequence of frames\nfrom video games, passing them through a convolutional network to obtain\nfeatures and then using recurrent neural networks to figure out the action\nleading to optimal rewards. The recurrent neural network will learn to extract\nthe meaningful signal out of the sequence of such features. In this work, we\npropose a method utilizing a transformer network which have recently replaced\nRNNs in Natural Language Processing (NLP), and perform experiments to compare\nwith existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:35:48 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Upadhyay", "Uddeshya", ""], ["Shah", "Nikunj", ""], ["Ravikanti", "Sucheta", ""], ["Medhe", "Mayanka", ""]]}, {"id": "1912.03927", "submitter": "Hugo Cui", "authors": "Hugo Cui, Luca Saglietti, Lenka Zdeborov\\'a", "title": "Large deviations for the perceptron model and consequences for active\n  learning", "comments": "25 pages, 7 figures", "journal-ref": "Proceedings of The First Mathematical and Scientific Machine\n  Learning Conference, PMLR 107:390-430, 2020", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a branch of machine learning that deals with problems\nwhere unlabeled data is abundant yet obtaining labels is expensive. The\nlearning algorithm has the possibility of querying a limited number of samples\nto obtain the corresponding labels, subsequently used for supervised learning.\nIn this work, we consider the task of choosing the subset of samples to be\nlabeled from a fixed finite pool of samples. We assume the pool of samples to\nbe a random matrix and the ground truth labels to be generated by a\nsingle-layer teacher random neural network. We employ replica methods to\nanalyze the large deviations for the accuracy achieved after supervised\nlearning on a subset of the original pool. These large deviations then provide\noptimal achievable performance boundaries for any active learning algorithm. We\nshow that the optimal learning performance can be efficiently approached by\nsimple message-passing active learning algorithms. We also provide a comparison\nwith the performance of some other popular active learning strategies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:50:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Cui", "Hugo", ""], ["Saglietti", "Luca", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1912.03937", "submitter": "Johannes M\\\"uller", "authors": "Johannes M\\\"uller, Marius Zeinhofer", "title": "Deep Ritz revisited", "comments": "10 pages, work in progress, corrected typos in the second version", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, progress has been made in the application of neural networks to the\nnumerical analysis of partial differential equations (PDEs). In the latter the\nvariational formulation of the Poisson problem is used in order to obtain an\nobjective function - a regularised Dirichlet energy - that was used for the\noptimisation of some neural networks. In this notes we use the notion of\n$\\Gamma$-convergence to show that ReLU networks of growing architecture that\nare trained with respect to suitably regularised Dirichlet energies converge to\nthe true solution of the Poisson problem. We discuss how this approach\ngeneralises to arbitrary variational problems under certain universality\nassumptions of neural networks and see that this covers some nonlinear\nstationary PDEs like the $p$-Laplace.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:59:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 19:25:16 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["M\u00fcller", "Johannes", ""], ["Zeinhofer", "Marius", ""]]}, {"id": "1912.03959", "submitter": "Eli (Omid) David", "authors": "Itay Mosafi, Eli David, Nathan S. Netanyahu", "title": "Stealing Knowledge from Protected Deep Neural Networks Using Composite\n  Unlabeled Data", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN), pages\n  1-8, Budapest, Hungary, July 2019", "doi": "10.1109/IJCNN.2019.8851798", "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As state-of-the-art deep neural networks are deployed at the core of more\nadvanced Al-based products and services, the incentive for copying them (i.e.,\ntheir intellectual properties) by rival adversaries is expected to increase\nconsiderably over time. The best way to extract or steal knowledge from such\nnetworks is by querying them using a large dataset of random samples and\nrecording their output, followed by training a student network to mimic these\noutputs, without making any assumption about the original networks. The most\neffective way to protect against such a mimicking attack is to provide only the\nclassification result, without confidence values associated with the softmax\nlayer.In this paper, we present a novel method for generating composite images\nfor attacking a mentor neural network using a student model. Our method assumes\nno information regarding the mentor's training dataset, architecture, or\nweights. Further assuming no information regarding the mentor's softmax output\nvalues, our method successfully mimics the given neural network and steals all\nof its knowledge. We also demonstrate that our student network (which copies\nthe mentor) is impervious to watermarking protection methods, and thus would\nnot be detected as a stolen model.Our results imply, essentially, that all\ncurrent neural networks are vulnerable to mimicking attacks, even if they do\nnot divulge anything but the most basic required output, and that the student\nmodel which mimics them cannot be easily detected and singled out as a stolen\ncopy using currently available techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 10:57:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Mosafi", "Itay", ""], ["David", "Eli", ""], ["Netanyahu", "Nathan S.", ""]]}, {"id": "1912.03960", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee,\n  Lovekesh Vig, Gautam Shroff", "title": "MetaCI: Meta-Learning for Causal Inference in a Heterogeneous Population", "comments": "10 pages, 4 figures, Accepted in CausalML Workshop - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing inference on data obtained through observational studies is\nbecoming extremely relevant due to the widespread availability of data in\nfields such as healthcare, education, retail, etc. Furthermore, this data is\naccrued from multiple homogeneous subgroups of a heterogeneous population, and\nhence, generalizing the inference mechanism over such data is essential. We\npropose the MetaCI framework with the goal of answering counterfactual\nquestions in the context of causal inference (CI), where the factual\nobservations are obtained from several homogeneous subgroups. While the CI\nnetwork is designed to generalize from factual to counterfactual distribution\nin order to tackle covariate shift, MetaCI employs the meta-learning paradigm\nto tackle the shift in data distributions between training and test phase due\nto the presence of heterogeneity in the population, and due to drifts in the\ntarget distribution, also known as concept shift. We benchmark the performance\nof the MetaCI algorithm using the mean absolute percentage error over the\naverage treatment effect as the metric, and demonstrate that meta\ninitialization has significant gains compared to randomly initialized networks,\nand other methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 11:01:09 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:40:02 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 05:06:05 GMT"}, {"version": "v4", "created": "Fri, 1 May 2020 05:15:55 GMT"}, {"version": "v5", "created": "Fri, 18 Dec 2020 11:02:08 GMT"}, {"version": "v6", "created": "Wed, 17 Feb 2021 15:19:37 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Sharma", "Ankit", ""], ["Gupta", "Garima", ""], ["Prasad", "Ranjitha", ""], ["Chatterjee", "Arnab", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1912.03978", "submitter": "Tan Nguyen", "authors": "Tan M. Nguyen, Animesh Garg, Richard G. Baraniuk, Anima Anandkumar", "title": "InfoCNF: An Efficient Conditional Continuous Normalizing Flow with\n  Adaptive Solvers", "comments": "17 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Normalizing Flows (CNFs) have emerged as promising deep generative\nmodels for a wide range of tasks thanks to their invertibility and exact\nlikelihood estimation. However, conditioning CNFs on signals of interest for\nconditional image generation and downstream predictive tasks is inefficient due\nto the high-dimensional latent code generated by the model, which needs to be\nof the same size as the input data. In this paper, we propose InfoCNF, an\nefficient conditional CNF that partitions the latent space into a\nclass-specific supervised code and an unsupervised code that shared among all\nclasses for efficient use of labeled information. Since the partitioning\nstrategy (slightly) increases the number of function evaluations (NFEs),\nInfoCNF also employs gating networks to learn the error tolerances of its\nordinary differential equation (ODE) solvers for better speed and performance.\nWe show empirically that InfoCNF improves the test accuracy over the baseline\nwhile yielding comparable likelihood scores and reducing the NFEs on CIFAR10.\nFurthermore, applying the same partitioning strategy in InfoCNF on time-series\ndata helps improve extrapolation performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 11:37:22 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nguyen", "Tan M.", ""], ["Garg", "Animesh", ""], ["Baraniuk", "Richard G.", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1912.03980", "submitter": "Francois Lanusse", "authors": "Francois Lanusse, Peter Melchior, Fred Moolekamp", "title": "Hybrid Physical-Deep Learning Model for Astronomical Inverse Problems", "comments": "8 pages, accepted submission to the NeurIPS 2019 Machine Learning and\n  the Physical Sciences Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian machine learning architecture that combines a\nphysically motivated parametrization and an analytic error model for the\nlikelihood with a deep generative model providing a powerful data-driven prior\nfor complex signals. This combination yields an interpretable and\ndifferentiable generative model, allows the incorporation of prior knowledge,\nand can be utilized for observations with different data quality without having\nto retrain the deep network. We demonstrate our approach with an example of\nastronomical source separation in current imaging data, yielding a physical and\ninterpretable model of astronomical scenes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 11:46:56 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Lanusse", "Francois", ""], ["Melchior", "Peter", ""], ["Moolekamp", "Fred", ""]]}, {"id": "1912.03984", "submitter": "Shouvik Mani", "authors": "Shouvik Mani, Mehdi Maasoumy, Sina Pakazad, Henrik Ohlsson", "title": "Expert-guided Regularization via Distance Metric Learning", "comments": null, "journal-ref": "Learning with Rich Experience (LIRE) Workshop, NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional prediction is a challenging problem setting for traditional\nstatistical models. Although regularization improves model performance in high\ndimensions, it does not sufficiently leverage knowledge on feature importances\nheld by domain experts. As an alternative to standard regularization\ntechniques, we propose Distance Metric Learning Regularization (DMLreg), an\napproach for eliciting prior knowledge from domain experts and integrating that\nknowledge into a regularized linear model. First, we learn a Mahalanobis\ndistance metric between observations from pairwise similarity comparisons\nprovided by an expert. Then, we use the learned distance metric to place prior\ndistributions on coefficients in a linear model. Through experimental results\non a simulated high-dimensional prediction problem, we show that DMLreg leads\nto improvements in model performance when the domain expert is knowledgeable.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 12:05:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Mani", "Shouvik", ""], ["Maasoumy", "Mehdi", ""], ["Pakazad", "Sina", ""], ["Ohlsson", "Henrik", ""]]}, {"id": "1912.03991", "submitter": "Chenying Liu", "authors": "Chenying Liu and Jun Li and Lin He and Antonio J. Plaza and Shutao Li\n  and Bo Li", "title": "Naive Gabor Networks for Hyperspectral Image Classification", "comments": "This paper has been accepted by IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many convolutional neural network (CNN) methods have been designed\nfor hyperspectral image (HSI) classification since CNNs are able to produce\ngood representations of data, which greatly benefits from a huge number of\nparameters. However, solving such a high-dimensional optimization problem often\nrequires a large amount of training samples in order to avoid overfitting.\nAdditionally, it is a typical non-convex problem affected by many local minima\nand flat regions. To address these problems, in this paper, we introduce naive\nGabor Networks or Gabor-Nets which, for the first time in the literature,\ndesign and learn CNN kernels strictly in the form of Gabor filters, aiming to\nreduce the number of involved parameters and constrain the solution space, and\nhence improve the performances of CNNs. Specifically, we develop an innovative\nphase-induced Gabor kernel, which is trickily designed to perform the Gabor\nfeature learning via a linear combination of local low-frequency and\nhigh-frequency components of data controlled by the kernel phase. With the\nphase-induced Gabor kernel, the proposed Gabor-Nets gains the ability to\nautomatically adapt to the local harmonic characteristics of the HSI data and\nthus yields more representative harmonic features. Also, this kernel can\nfulfill the traditional complex-valued Gabor filtering in a real-valued manner,\nhence making Gabor-Nets easily perform in a usual CNN thread. We evaluated our\nnewly developed Gabor-Nets on three well-known HSIs, suggesting that our\nproposed Gabor-Nets can significantly improve the performance of CNNs,\nparticularly with a small training set.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 12:16:48 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 06:21:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liu", "Chenying", ""], ["Li", "Jun", ""], ["He", "Lin", ""], ["Plaza", "Antonio J.", ""], ["Li", "Shutao", ""], ["Li", "Bo", ""]]}, {"id": "1912.04002", "submitter": "J. Fernando Hernandez-Garcia", "authors": "J. Fernando Hernandez-Garcia and Richard S. Sutton", "title": "Learning Sparse Representations Incrementally in Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse representations have been shown to be useful in deep reinforcement\nlearning for mitigating catastrophic interference and improving the performance\nof agents in terms of cumulative reward. Previous results were based on a two\nstep process were the representation was learned offline and the action-value\nfunction was learned online afterwards. In this paper, we investigate if it is\npossible to learn a sparse representation and the action-value function\nsimultaneously and incrementally. We investigate this question by employing\nseveral regularization techniques and observing how they affect sparsity of the\nrepresentation learned by a DQN agent in two different benchmark domains. Our\nresults show that with appropriate regularization it is possible to increase\nthe sparsity of the representations learned by DQN agents. Moreover, we found\nthat learning sparse representations also resulted in improved performance in\nterms of cumulative reward. Finally, we found that the performance of the\nagents that learned a sparse representation was more robust to the size of the\nexperience replay buffer. This last finding supports the long standing\nhypothesis that the overlap in representations learned by deep neural networks\nis the leading cause of catastrophic interference.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 12:41:17 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hernandez-Garcia", "J. Fernando", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1912.04009", "submitter": "Alexandre Miot", "authors": "Alexandre Miot and Gilles Drigout", "title": "An empirical study of neural networks for trend detection in time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting structure in noisy time series is a difficult task. One intuitive\nfeature is the notion of trend. From theoretical hints and using simulated time\nseries, we empirically investigate the efficiency of standard recurrent neural\nnetworks (RNNs) to detect trends. We show the overall superiority and\nversatility of certain standard RNNs structures over various other estimators.\nThese RNNs could be used as basic blocks to build more complex time series\ntrend estimators.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 13:01:58 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 17:34:37 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Miot", "Alexandre", ""], ["Drigout", "Gilles", ""]]}, {"id": "1912.04022", "submitter": "J\\\"org Schl\\\"otterer", "authors": "Christian Reiser and J\\\"org Schl\\\"otterer and Michael Granitzer", "title": "Parallel Total Variation Distance Estimation with Neural Networks for\n  Merging Over-Clusterings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the initial situation where a dataset has been over-partitioned\ninto $k$ clusters and seek a domain independent way to merge those initial\nclusters. We identify the total variation distance (TVD) as suitable for this\ngoal. By exploiting the relation of the TVD to the Bayes accuracy we show how\nneural networks can be used to estimate TVDs between all pairs of clusters in\nparallel. Crucially, the needed memory space is decreased by reducing the\nrequired number of output neurons from $k^2$ to $k$. On realistically obtained\nover-clusterings of ImageNet subsets it is demonstrated that our TVD estimates\nlead to better merge decisions than those obtained by relying on\nstate-of-the-art unsupervised representations. Further the generality of the\napproach is verified by evaluating it on a a point cloud dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 13:25:14 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Reiser", "Christian", ""], ["Schl\u00f6tterer", "J\u00f6rg", ""], ["Granitzer", "Michael", ""]]}, {"id": "1912.04030", "submitter": "F. Rodrigo P. Cavalcanti", "authors": "Mateus P. Mota, Daniel C. Araujo, Francisco Hugo Costa Neto, Andre L.\n  F. de Almeida, F. Rodrigo P. Cavalcanti", "title": "Adaptive Modulation and Coding based on Reinforcement Learning for 5G\n  Networks", "comments": "Accepted for presentation at the IEEE GLOBECOM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a self-exploratory reinforcement learning (RL) framework, based on\nthe Q-learning algorithm, that enables the base station (BS) to choose a\nsuitable modulation and coding scheme (MCS) that maximizes the spectral\nefficiency while maintaining a low block error rate (BLER). In this framework,\nthe BS chooses the MCS based on the channel quality indicator (CQI) reported by\nthe user equipment (UE). A transmission is made with the chosen MCS and the\nresults of this transmission are converted by the BS into rewards that the BS\nuses to learn the suitable mapping from CQI to MCS. Comparing with a\nconventional fixed look-up table and the outer loop link adaptation, the\nproposed framework achieves superior performance in terms of spectral\nefficiency and BLER.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 23:25:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Mota", "Mateus P.", ""], ["Araujo", "Daniel C.", ""], ["Neto", "Francisco Hugo Costa", ""], ["de Almeida", "Andre L. F.", ""], ["Cavalcanti", "F. Rodrigo P.", ""]]}, {"id": "1912.04042", "submitter": "John Duchi", "authors": "Hilal Asi and John Duchi and Omid Javidbakht", "title": "Element Level Differential Privacy: The Right Granularity of Privacy", "comments": "34 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy (DP) provides strong guarantees on the risk of\ncompromising a user's data in statistical learning applications, though these\nstrong protections make learning challenging and may be too stringent for some\nuse cases. To address this, we propose element level differential privacy,\nwhich extends differential privacy to provide protection against leaking\ninformation about any particular \"element\" a user has, allowing better utility\nand more robust results than classical DP. By carefully choosing these\n\"elements,\" it is possible to provide privacy protections at a desired\ngranularity. We provide definitions, associated privacy guarantees, and\nanalysis to identify the tradeoffs with the new definition; we also develop\nseveral private estimation and learning methodologies, providing careful\nexamples for item frequency and M-estimation (empirical risk minimization) with\nconcomitant privacy and utility analysis. We complement our theoretical and\nmethodological advances with several real-world applications, estimating\nhistograms and fitting several large-scale prediction models, including deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 23:05:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Asi", "Hilal", ""], ["Duchi", "John", ""], ["Javidbakht", "Omid", ""]]}, {"id": "1912.04061", "submitter": "Amritanshu Agrawal", "authors": "Amritanshu Agrawal, Xueqi Yang, Rishabh Agrawal, Rahul Yedida, Xipeng\n  Shen, Tim Menzies", "title": "Simpler Hyperparameter Optimization for Software Analytics: Why, How,\n  When?", "comments": "15 pages", "journal-ref": "Transactions on Software Engineering, 2021", "doi": "10.1109/TSE.2021.3073242", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we make software analytics simpler and faster? One method is to match\nthe complexity of analysis to the intrinsic complexity of the data being\nexplored. For example, hyperparameter optimizers find the control settings for\ndata miners that improve the predictions generated via software analytics.\nSometimes, very fast hyperparameter optimization can be achieved by\n\"DODGE-ing\"; i.e. simply steering way from settings that lead to similar\nconclusions. But when is it wise to use that simple approach and when must we\nuse more complex (and much slower) optimizers?} To answer this, we applied\nhyperparameter optimization to 120 SE data sets that explored bad smell\ndetection, predicting Github issue close time, bug report analysis, defect\nprediction, and dozens of other non-SE problems. We find that the simple DODGE\nworks best for data sets with low \"intrinsic dimensionality\" (u ~ 3) and very\npoorly for higher-dimensional data (u > 8). Nearly all the SE data seen here\nwas intrinsically low-dimensional, indicating that DODGE is applicable for many\nSE analytics tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:10:40 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 15:46:19 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 23:04:25 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 14:28:07 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 14:29:22 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Agrawal", "Amritanshu", ""], ["Yang", "Xueqi", ""], ["Agrawal", "Rishabh", ""], ["Yedida", "Rahul", ""], ["Shen", "Xipeng", ""], ["Menzies", "Tim", ""]]}, {"id": "1912.04063", "submitter": "Takayuki Osa", "authors": "Takayuki Osa and Shuhei Ikemoto", "title": "Goal-Conditioned Variational Autoencoder Trajectory Primitives with\n  Continuous and Discrete Latent Codes", "comments": "8 pages, SN Computer Science", "journal-ref": null, "doi": "10.1007/s42979-020-00324-7", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation learning is an intuitive approach for teaching motion to robotic\nsystems. Although previous studies have proposed various methods to model\ndemonstrated movement primitives, one of the limitations of existing methods is\nthat the shape of the trajectories are encoded in high dimensional space. The\nhigh dimensionality of the trajectory representation can be a bottleneck in the\nsubsequent process such as planning a sequence of primitive motions. We address\nthis problem by learning the latent space of the robot trajectory. If the\nlatent variable of the trajectories can be learned, it can be used to tune the\ntrajectory in an intuitive manner even when the user is not an expert. We\npropose a framework for modeling demonstrated trajectories with a neural\nnetwork that learns the low-dimensional latent space. Our neural network\nstructure is built on the variational autoencoder (VAE) with discrete and\ncontinuous latent variables. We extend the structure of the existing VAE to\nobtain the decoder that is conditioned on the goal position of the trajectory\nfor generalization to different goal positions. Although the inference\nperformed by VAE is not accurate, the positioning error at the generalized goal\nposition can be reduced to less than 1~mm by incorporating the projection onto\nthe solution space. To cope with requirement of the massive training data, we\nuse a trajectory augmentation technique inspired by the data augmentation\ncommonly used in the computer vision community. In the proposed framework, the\nlatent variables that encodes the multiple types of trajectories are learned in\nan unsupervised manner, although existing methods usually require label\ninformation to model diverse behaviors. The learned decoder can be used as a\nmotion planner in which the user can specify the goal position and the\ntrajectory types by setting the latent variables.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:12:37 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 07:06:05 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Osa", "Takayuki", ""], ["Ikemoto", "Shuhei", ""]]}, {"id": "1912.04066", "submitter": "Wei Xiao", "authors": "Wei Xiao and Calin A. Belta and Christos G. Cassandras", "title": "Feasibility-Guided Learning for Robust Control in Constrained Optimal\n  Control Problems", "comments": "8 pages, submitted to L-CSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal control problems with constraints ensuring safety and convergence to\ndesired states can be mapped onto a sequence of real time optimization problems\nthrough the use of Control Barrier Functions (CBFs) and Control Lyapunov\nFunctions (CLFs). One of the main challenges in these approaches is ensuring\nthe feasibility of the resulting quadratic programs (QPs) if the system is\naffine in controls. The recently proposed penalty method has the potential to\nimprove the existence of feasible solutions to such problems. In this paper, we\nfurther improve the feasibility robustness (i.e., feasibility maintenance in\nthe presence of time-varying and unknown unsafe sets) through the definition of\na High Order CBF (HOCBF) that works for arbitrary relative degree constraints;\nthis is achieved by a proposed feasibility-guided learning approach.\nSpecifically, we apply machine learning techniques to classify the parameter\nspace of a HOCBF into feasible and infeasible sets, and get a differentiable\nclassifier that is then added to the learning process. The proposed\nfeasibility-guided learning approach is compared with the gradient-descent\nmethod on a robot control problem. The simulation results show an improved\nability of the feasibility-guided learning approach over the gradient-decent\nmethod to determine the optimal parameters in the definition of a HOCBF for the\nfeasibility robustness, as well as show the potential of the CBF method for\nrobot safe navigation in an unknown environment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 10:06:59 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Xiao", "Wei", ""], ["Belta", "Calin A.", ""], ["Cassandras", "Christos G.", ""]]}, {"id": "1912.04067", "submitter": "Andreas Krug", "authors": "Andreas Krug, Sebastian Stober", "title": "Visualizing Deep Neural Networks for Speech Recognition with Learned\n  Topographic Filter Maps", "comments": "Accepted for 2019 ACL Workshop BlackboxNLP: Analyzing and\n  Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uninformative ordering of artificial neurons in Deep Neural Networks\ncomplicates visualizing activations in deeper layers. This is one reason why\nthe internal structure of such models is very unintuitive. In neuroscience,\nactivity of real brains can be visualized by highlighting active regions.\nInspired by those techniques, we train a convolutional speech recognition\nmodel, where filters are arranged in a 2D grid and neighboring filters are\nsimilar to each other. We show, how those topographic filter maps visualize\nartificial neuron activations more intuitively. Moreover, we investigate,\nwhether this causes phoneme-responsive neurons to be grouped in certain regions\nof the topographic map.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 10:31:29 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Krug", "Andreas", ""], ["Stober", "Sebastian", ""]]}, {"id": "1912.04075", "submitter": "Gabrielle Ras", "authors": "Gabri\\\"elle Ras, Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u, Marcel A. J. van\n  Gerven", "title": "Temporal Factorization of 3D Convolutional Kernels", "comments": "8 pages, 3 figures, Proceedings of BNAIC/BENELEARN 2019 conference", "journal-ref": "Proceedings of the 31st Benelux Conference on Artificial\n  Intelligence (BNAIC 2019) and the 28th Belgian Dutch Conference on Machine\n  Learning (Benelearn 2019), Brussels, Belgium, November 6-8, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  3D convolutional neural networks are difficult to train because they are\nparameter-expensive and data-hungry. To solve these problems we propose a\nsimple technique for learning 3D convolutional kernels efficiently requiring\nless training data. We achieve this by factorizing the 3D kernel along the\ntemporal dimension, reducing the number of parameters and making training from\ndata more efficient. Additionally we introduce a novel dataset called\nVideo-MNIST to demonstrate the performance of our method. Our method\nsignificantly outperforms the conventional 3D convolution in the low data\nregime (1 to 5 videos per class). Finally, our model achieves competitive\nresults in the high data regime (>10 videos per class) using up to 45% fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:21:00 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Ras", "Gabri\u00eblle", ""], ["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1912.04099", "submitter": "Qiaosheng Zhang", "authors": "Qiaosheng Zhang, Vincent Y. F. Tan, and Changho Suh", "title": "Community Detection and Matrix Completion with Social and Item\n  Similarity Graphs", "comments": "To appear in the IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.IR cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a binary rating matrix as well as\nclusters of users and items based on a partially observed matrix together with\nside-information in the form of social and item similarity graphs. These two\ngraphs are both generated according to the celebrated stochastic block model\n(SBM). We develop lower and upper bounds on sample complexity that match for\nvarious scenarios. Our information-theoretic results quantify the benefits of\nthe availability of the social and item similarity graphs. Further analysis\nreveals that under certain scenarios, the social and item similarity graphs\nproduce an interesting synergistic effect. This means that observing two graphs\nis strictly better than observing just one in terms of reducing the sample\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 15:27:56 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 06:16:39 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Zhang", "Qiaosheng", ""], ["Tan", "Vincent Y. F.", ""], ["Suh", "Changho", ""]]}, {"id": "1912.04106", "submitter": "Stavros Vologiannidis", "authors": "Polychronis Charitidis, Stavros Doropoulos, Stavros Vologiannidis,\n  Ioannis Papastergiou, Sophia Karakeva", "title": "Towards countering hate speech against journalists on social media", "comments": null, "journal-ref": null, "doi": "10.1016/j.osnem.2020.100071", "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The damaging effects of hate speech on social media are evident during the\nlast few years, and several organizations, researchers and social media\nplatforms tried to harness them in various ways. Despite these efforts, social\nmedia users are still affected by hate speech. The problem is even more\napparent to social groups that promote public discourse, such as journalists.\nIn this work, we focus on countering hate speech that is targeted to\njournalistic social media accounts. To accomplish this, a group of journalists\nassembled a definition of hate speech, taking into account the journalistic\npoint of view and the types of hate speech that are usually targeted against\njournalists. We then compile a large pool of tweets referring to\njournalism-related accounts in multiple languages. In order to annotate the\npool of unlabeled tweets according to the definition, we follow a concise\nannotation strategy that involves active learning annotation stages. The\noutcome of this paper is a novel, publicly available collection of Twitter\ndatasets in five different languages. Additionally, we experiment with\nstate-of-the-art deep learning architectures for hate speech detection and use\nour annotated datasets to train and evaluate them. Finally, we propose an\nensemble detection model that outperforms all individual models.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 07:51:23 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 19:55:34 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Charitidis", "Polychronis", ""], ["Doropoulos", "Stavros", ""], ["Vologiannidis", "Stavros", ""], ["Papastergiou", "Ioannis", ""], ["Karakeva", "Sophia", ""]]}, {"id": "1912.04107", "submitter": "Radu Tudor Ionescu", "authors": "S\\'ebastien D\\'ejean, Radu Tudor Ionescu, Josiane Mothe, Md Zia Ullah", "title": "Forward and Backward Feature Selection for Query Performance Prediction", "comments": "Accepted at SAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of query performance prediction (QPP) is to automatically estimate\nthe effectiveness of a search result for any given query, without relevance\njudgements. Post-retrieval features have been shown to be more effective for\nthis task while being more expensive to compute than pre-retrieval features.\nCombining multiple post-retrieval features is even more effective, but\nstate-of-the-art QPP methods are impossible to interpret because of the\nblack-box nature of the employed machine learning models. However,\ninterpretation is useful for understanding the predictive model and providing\nmore answers about its behavior. Moreover, combining many post-retrieval\nfeatures is not applicable to real-world cases, since the query running time is\nof utter importance. In this paper, we investigate a new framework for feature\nselection in which the trained model explains well the prediction. We introduce\na step-wise (forward and backward) model selection approach where different\nsubsets of query features are used to fit different models from which the\nsystem selects the best one. We evaluate our approach on four TREC collections\nusing standard QPP features. We also develop two QPP features to address the\nissue of query-drift in the query feedback setting. We found that: (1) our\nmodel based on a limited number of selected features is as good as more complex\nmodels for QPP and better than non-selective models; (2) our model is more\nefficient than complex models during inference time since it requires fewer\nfeatures; (3) the predictive model is readable and understandable; and (4) one\nof our new QPP features is consistently selected across different collections,\nproving its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:19:16 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["D\u00e9jean", "S\u00e9bastien", ""], ["Ionescu", "Radu Tudor", ""], ["Mothe", "Josiane", ""], ["Ullah", "Md Zia", ""]]}, {"id": "1912.04108", "submitter": "Liang Zhao", "authors": "Liang Zhao, Yang Wang, Daxiang Dong, Hao Tian", "title": "Learning to Recommend via Meta Parameter Partition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose to solve an important problem in recommendation --\nuser cold start, based on meta leaning method. Previous meta learning\napproaches finetune all parameters for each new user, which is both computing\nand storage expensive. In contrast, we divide model parameters into fixed and\nadaptive parts and develop a two-stage meta learning algorithm to learn them\nseparately. The fixed part, capturing user invariant features, is shared by all\nusers and is learned during offline meta learning stage. The adaptive part,\ncapturing user specific features, is learned during online meta learning stage.\nBy decoupling user invariant parameters from user dependent parameters, the\nproposed approach is more efficient and storage cheaper than previous methods.\nIt also has potential to deal with catastrophic forgetting while continually\nadapting for streaming coming users.\n  Experiments on production data demonstrates that the proposed method\nconverges faster and to a better performance than baseline methods.\nMeta-training without online meta model finetuning increases the AUC from\n72.24% to 74.72% (2.48% absolute improvement). Online meta training achieves a\nfurther gain of 2.46\\% absolute improvement comparing with offline meta\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 05:58:31 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Liang", ""], ["Wang", "Yang", ""], ["Dong", "Daxiang", ""], ["Tian", "Hao", ""]]}, {"id": "1912.04109", "submitter": "Yangjun Xu", "authors": "Liang Chen and Yangjun Xu and Fenfang Xie and Min Huang and Zibin\n  Zheng", "title": "Data Poisoning Attacks on Neighborhood-based Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, collaborative filtering recommender systems have been widely\ndeployed in many commercial companies to make profit. Neighbourhood-based\ncollaborative filtering is common and effective. To date, despite its\neffectiveness, there has been little effort to explore their robustness and the\nimpact of data poisoning attacks on their performance. Can the\nneighbourhood-based recommender systems be easily fooled? To this end, we shed\nlight on the robustness of neighbourhood-based recommender systems and propose\na novel data poisoning attack framework encoding the purpose of attack and\nconstraint against them. We firstly illustrate how to calculate the optimal\ndata poisoning attack, namely UNAttack. We inject a few well-designed fake\nusers into the recommender systems such that target items will be recommended\nto as many normal users as possible. Extensive experiments are conducted on\nthree real-world datasets to validate the effectiveness and the transferability\nof our proposed method. Besides, some interesting phenomenons can be found. For\nexample, 1) neighbourhood-based recommender systems with Euclidean\nDistance-based similarity have strong robustness. 2) the fake users can be\ntransferred to attack the state-of-the-art collaborative filtering recommender\nsystems such as Neural Collaborative Filtering and Bayesian Personalized\nRanking Matrix Factorization.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 15:34:58 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Chen", "Liang", ""], ["Xu", "Yangjun", ""], ["Xie", "Fenfang", ""], ["Huang", "Min", ""], ["Zheng", "Zibin", ""]]}, {"id": "1912.04116", "submitter": "Cailey Kerley", "authors": "Cailey I. Kerley, Kurt G. Schilling, Justin Blaber, Beth Miller, Allen\n  Newton, Adam W. Anderson, Bennett A. Landman, and Tonia S. Rex", "title": "MRI correlates of chronic symptoms in mild traumatic brain injury", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Veterans with mild traumatic brain injury (mTBI) have reported auditory and\nvisual dysfunction that persists beyond the acute incident. The etiology behind\nthese symptoms is difficult to characterize with current clinical imaging.\nThese functional deficits may be caused by shear injury or micro-bleeds, which\ncan be detected with special imaging modalities. We explore these hypotheses in\na pilot study of multi-parametric MRI. We extract over 1,000 imaging and\nclinical metrics and project them to a low-dimensional space, where we can\ndiscriminate between healthy controls and patients with mTBI. We also show\ncorrelations between the metric representations and patient symptoms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:30:51 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:46:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kerley", "Cailey I.", ""], ["Schilling", "Kurt G.", ""], ["Blaber", "Justin", ""], ["Miller", "Beth", ""], ["Newton", "Allen", ""], ["Anderson", "Adam W.", ""], ["Landman", "Bennett A.", ""], ["Rex", "Tonia S.", ""]]}, {"id": "1912.04132", "submitter": "Kostadin Cvejoski", "authors": "Kostadin Cvejoski, Ramses J. Sanchez, Bogdan Georgiev, Jannis\n  Schuecker, Christian Bauckhage, Cesar Ojeda", "title": "Recurrent Point Processes for Dynamic Review Models", "comments": "Presented at the AAAI 2020 Workshop on Interactive and Conversational\n  Recommendation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent progress in recommender system research has shown the importance of\nincluding temporal representations to improve interpretability and performance.\nHere, we incorporate temporal representations in continuous time via recurrent\npoint process for a dynamical model of reviews. Our goal is to characterize how\nchanges in perception, user interest and seasonal effects affect review text.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 15:42:01 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 16:15:31 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Cvejoski", "Kostadin", ""], ["Sanchez", "Ramses J.", ""], ["Georgiev", "Bogdan", ""], ["Schuecker", "Jannis", ""], ["Bauckhage", "Christian", ""], ["Ojeda", "Cesar", ""]]}, {"id": "1912.04136", "submitter": "Akshay Krishnamurthy", "authors": "Yining Wang, Ruosong Wang, Simon S. Du, Akshay Krishnamurthy", "title": "Optimism in Reinforcement Learning with Generalized Linear Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new provably efficient algorithm for episodic reinforcement\nlearning with generalized linear function approximation. We analyze the\nalgorithm under a new expressivity assumption that we call \"optimistic\nclosure,\" which is strictly weaker than assumptions from prior analyses for the\nlinear setting. With optimistic closure, we prove that our algorithm enjoys a\nregret bound of $\\tilde{O}(\\sqrt{d^3 T})$ where $d$ is the dimensionality of\nthe state-action features and $T$ is the number of episodes. This is the first\nstatistically and computationally efficient algorithm for reinforcement\nlearning with generalized linear functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 15:47:27 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wang", "Yining", ""], ["Wang", "Ruosong", ""], ["Du", "Simon S.", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "1912.04138", "submitter": "Adi Szeskin", "authors": "Adi Szeskin, Lev Faivishevsky, Ashwin K Muppalla, Amitai Armon and Tom\n  Hope", "title": "A Weak Supervision Approach to Detecting Visual Anomalies for Automated\n  Testing of Graphics Units", "comments": "Accepted to NeurIPS 2019 Machine Learning for Systems Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning system for testing graphics units by detecting\nnovel visual corruptions in videos. Unlike previous work in which manual\ntagging was required to collect labeled training data, our weak supervision\nmethod is fully automatic and needs no human labelling. This is achieved by\nreproducing driver bugs that increase the probability of generating\ncorruptions, and by making use of ideas and methods from the Multiple Instance\nLearning (MIL) setting. In our experiments, we significantly outperform\nunsupervised methods such as GAN-based models and discover novel corruptions\nundetected by baselines, while adhering to strict requirements on accuracy and\nefficiency of our real-time system.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 15:48:34 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Szeskin", "Adi", ""], ["Faivishevsky", "Lev", ""], ["Muppalla", "Ashwin K", ""], ["Armon", "Amitai", ""], ["Hope", "Tom", ""]]}, {"id": "1912.04154", "submitter": "Yingzhou Li", "authors": "Zhongshu Xu, Yingzhou Li, Xiuyuan Cheng", "title": "Butterfly-Net2: Simplified Butterfly-Net and Fourier Transform\n  Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured CNN designed using the prior information of problems potentially\nimproves efficiency over conventional CNNs in various tasks in solving PDEs and\ninverse problems in signal processing. This paper introduces BNet2, a\nsimplified Butterfly-Net and inline with the conventional CNN. Moreover, a\nFourier transform initialization is proposed for both BNet2 and CNN with\nguaranteed approximation power to represent the Fourier transform operator.\nExperimentally, BNet2 and the Fourier transform initialization strategy are\ntested on various tasks, including approximating Fourier transform operator,\nend-to-end solvers of linear and nonlinear PDEs, and denoising and deblurring\nof 1D signals. On all tasks, under the same initialization, BNet2 achieves\nsimilar accuracy as CNN but has fewer parameters. And Fourier transform\ninitialized BNet2 and CNN consistently improve the training and testing\naccuracy over the randomly initialized CNN.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 16:25:32 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 19:54:13 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 17:54:29 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Xu", "Zhongshu", ""], ["Li", "Yingzhou", ""], ["Cheng", "Xiuyuan", ""]]}, {"id": "1912.04158", "submitter": "Philipp Henzler", "authors": "Philipp Henzler, Niloy J. Mitra, Tobias Ritschel", "title": "Learning a Neural 3D Texture Space from 2D Exemplars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative model of 2D and 3D natural textures with diversity,\nvisual fidelity and at high computational efficiency. This is enabled by a\nfamily of methods that extend ideas from classic stochastic procedural\ntexturing (Perlin noise) to learned, deep, non-linearities. The key idea is a\nhard-coded, tunable and differentiable step that feeds multiple transformed\nrandom 2D or 3D fields into an MLP that can be sampled over infinite domains.\nOur model encodes all exemplars from a diverse set of textures without a need\nto be re-trained for each exemplar. Applications include texture interpolation,\nand learning 3D textures from 2D exemplars.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 16:35:17 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 18:26:48 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Henzler", "Philipp", ""], ["Mitra", "Niloy J.", ""], ["Ritschel", "Tobias", ""]]}, {"id": "1912.04161", "submitter": "Hanten Chang", "authors": "Hanten Chang and Katsuya Futagami", "title": "Reinforcement Learning with Convolutional Reservoir Computing", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.08040", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning models have achieved great success,\nmastering complex tasks such as Go and other games with higher scores than\nhuman players. Many of these models store considerable data on the tasks and\nachieve high performance by extracting visual and time-series features using\nconvolutional neural networks (CNNs) and recurrent neural networks,\nrespectively. However, these networks have very high computational costs\nbecause they need to be trained by repeatedly using the stored data. In this\nstudy, we propose a novel practical approach called reinforcement learning with\nconvolutional reservoir computing (RCRC) model. The RCRC model uses a fixed\nrandom-weight CNN and a reservoir computing model to extract visual and\ntime-series features. Using these extracted features, it decides actions with\nan evolution strategy method. Thereby, the RCRC model has several desirable\nfeatures: (1) there is no need to train the feature extractor, (2) there is no\nneed to store training data, (3) it can take a wide range of actions, and (4)\nthere is only a single task-dependent weight parameter to be trained.\nFurthermore, we show the RCRC model can solve multiple reinforcement learning\ntasks with a completely identical feature extractor.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 19:59:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Chang", "Hanten", ""], ["Futagami", "Katsuya", ""]]}, {"id": "1912.04174", "submitter": "Harry Clifford MSci DPhil", "authors": "Geoffroy Dubourg-Felonneau, Omar Darwish, Christopher Parsons, Dami\n  Rebergen, John W Cassidy, Nirmesh Patel, Harry W Clifford", "title": "Deep Bayesian Recurrent Neural Networks for Somatic Variant Calling in\n  Cancer", "comments": "Bayesian Deep Learning Workshop at NeurIPS 2019. arXiv admin note:\n  text overlap with arXiv:1912.02065", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging field of precision oncology relies on the accurate pinpointing\nof alterations in the molecular profile of a tumor to provide personalized\ntargeted treatments. Current methodologies in the field commonly include the\napplication of next generation sequencing technologies to a tumor sample,\nfollowed by the identification of mutations in the DNA known as somatic\nvariants. The differentiation of these variants from sequencing error poses a\nclassic classification problem, which has traditionally been approached with\nBayesian statistics, and more recently with supervised machine learning methods\nsuch as neural networks. Although these methods provide greater accuracy,\nclassic neural networks lack the ability to indicate the confidence of a\nvariant call. In this paper, we explore the performance of deep Bayesian neural\nnetworks on next generation sequencing data, and their ability to give\nprobability estimates for somatic variant calls. In addition to demonstrating\nsimilar performance in comparison to standard neural networks, we show that the\nresultant output probabilities make these better suited to the disparate and\nhighly-variable sequencing data-sets these models are likely to encounter in\nthe real world. We aim to deliver algorithms to oncologists for which model\ncertainty better reflects accuracy, for improved clinical application. By\nmoving away from point estimates to reliable confidence intervals, we expect\nthe resultant clinical and treatment decisions to be more robust and more\ninformed by the underlying reality of the tumor molecular profile.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 16:01:15 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Dubourg-Felonneau", "Geoffroy", ""], ["Darwish", "Omar", ""], ["Parsons", "Christopher", ""], ["Rebergen", "Dami", ""], ["Cassidy", "John W", ""], ["Patel", "Nirmesh", ""], ["Clifford", "Harry W", ""]]}, {"id": "1912.04177", "submitter": "Ainesh Bakshi", "authors": "Ainesh Bakshi, Nadiia Chepurko and David P. Woodruff", "title": "Robust and Sample Optimal Algorithms for PSD Low-Rank Approximation", "comments": "minor edits in technical overview", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Musco and Woodruff (FOCS, 2017) showed that given an $n \\times n$\npositive semidefinite (PSD) matrix $A$, it is possible to compute a\n$(1+\\epsilon)$-approximate relative-error low-rank approximation to $A$ by\nquerying $O(nk/\\epsilon^{2.5})$ entries of $A$ in time $O(nk/\\epsilon^{2.5} +n\nk^{\\omega-1}/\\epsilon^{2(\\omega-1)})$. They also showed that any relative-error\nlow-rank approximation algorithm must query $\\Omega(nk/\\epsilon)$ entries of\n$A$, this gap has since remained open. Our main result is to resolve this\nquestion by obtaining an optimal algorithm that queries $O(nk/\\epsilon)$\nentries of $A$ and outputs a relative-error low-rank approximation in\n$O(n(k/\\epsilon)^{\\omega-1})$ time. Note, our running time improves that of\nMusco and Woodruff, and matches the information-theoretic lower bound if the\nmatrix-multiplication exponent $\\omega$ is $2$.\n  We then extend our techniques to negative-type distance matrices. Bakshi and\nWoodruff (NeurIPS, 2018) showed a bi-criteria, relative-error low-rank\napproximation which queries $O(nk/\\epsilon^{2.5})$ entries and outputs a\nrank-$(k+4)$ matrix. We show that the bi-criteria guarantee is not necessary\nand obtain an $O(nk/\\epsilon)$ query algorithm, which is optimal. Our algorithm\napplies to all distance matrices that arise from metrics satisfying\nnegative-type inequalities, including $\\ell_1, \\ell_2,$ spherical metrics and\nhypermetrics.\n  Next, we introduce a new robust low-rank approximation model which captures\nPSD matrices that have been corrupted with noise. While a sample complexity\nlower bound precludes sublinear algorithms for arbitrary PSD matrices, we\nprovide the first sublinear time and query algorithms when the corruption on\nthe diagonal entries is bounded. As a special case, we show sample-optimal\nsublinear time algorithms for low-rank approximation of correlation matrices\ncorrupted by noise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 16:52:12 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 20:11:03 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 03:12:59 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 02:09:36 GMT"}, {"version": "v5", "created": "Tue, 15 Jun 2021 17:18:36 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Chepurko", "Nadiia", ""], ["Woodruff", "David P.", ""]]}, {"id": "1912.04194", "submitter": "Ali Sharifara", "authors": "Razieh Tavakoli, Ali Sharifara, Mohammad Najafi", "title": "Prediction of Sewer Pipe Deterioration Using Random Forest\n  Classification", "comments": "This submission has been removed by arXiv administrators due to\n  copyright infringement and inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wastewater infrastructure systems deteriorate over time due to a combination\nof physical and chemical factors. Failure of this significant infrastructure\ncould affect important social, environmental, and economic impacts.\nFurthermore, recognizing the optimized timeline for inspection of sewer\npipelines are challenging tasks for the utility managers and other authorities.\nRegular examination of sewer networks is not cost-effective due to limited time\nand high cost of assessment technologies and a large inventory of pipes. To\navoid such obstacles, various researchers endeavored to improve infrastructure\ncondition assessment methodologies to maintain sewer pipe systems at the\ndesired condition. Sewer condition prediction models are developed to provide a\nframework to forecast the future condition of pipes to schedule inspection\nfrequencies. The main goal of this study is to develop a predictive model for\nwastewater pipes using random forest classification. Predictive models can\neffectively predict sewer pipe condition and can increase the certainty level\nof the predictive results and decrease uncertainty in the current condition of\nwastewater pipes. The developed random forest classification model has achieved\na stratified test set false negative rate, the false positive rate, and an\nexcellent area under the ROC curve of 0.81 in a case study application for the\nCity of LA, California. An area under the ROC curve > 0.80 indicates the\ndeveloped model is an \"excellent\" choice for predicting the condition of\nindividual pipes in a sewer network. The deterioration models can be used in\nthe industry to improve the inspection timeline and maintenance planning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 17:17:43 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Tavakoli", "Razieh", ""], ["Sharifara", "Ali", ""], ["Najafi", "Mohammad", ""]]}, {"id": "1912.04201", "submitter": "Aaron Havens", "authors": "Aaron Havens, Yi Ouyang, Prabhat Nagarajan, Yasuhiro Fujita", "title": "Learning Latent State Spaces for Planning through Reward Prediction", "comments": "Deep RL Workshop, Neurips 2019, Vancouver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning methods typically learn models for\nhigh-dimensional state spaces by aiming to reconstruct and predict the original\nobservations. However, drawing inspiration from model-free reinforcement\nlearning, we propose learning a latent dynamics model directly from rewards. In\nthis work, we introduce a model-based planning framework which learns a latent\nreward prediction model and then plans in the latent state-space. The latent\nrepresentation is learned exclusively from multi-step reward prediction which\nwe show to be the only necessary information for successful planning. With this\nframework, we are able to benefit from the concise model-free representation,\nwhile still enjoying the data-efficiency of model-based algorithms. We\ndemonstrate our framework in multi-pendulum and multi-cheetah environments\nwhere several pendulums or cheetahs are shown to the agent but only one of\nwhich produces rewards. In these environments, it is important for the agent to\nconstruct a concise latent representation to filter out irrelevant\nobservations. We find that our method can successfully learn an accurate latent\nreward prediction model in the presence of the irrelevant information while\nexisting model-based methods fail. Planning in the learned latent state-space\nshows strong performance and high sample efficiency over model-free and\nmodel-based baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 17:32:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Havens", "Aaron", ""], ["Ouyang", "Yi", ""], ["Nagarajan", "Prabhat", ""], ["Fujita", "Yasuhiro", ""]]}, {"id": "1912.04211", "submitter": "ANtoine Marot", "authors": "Antoine Marot, Benjamin Donnot, Camilo Romero, Luca Veyrin-Forrer,\n  Marvin Lerousseau, Balthazar Donon, Isabelle Guyon", "title": "Learning to run a power network challenge for training topology\n  controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For power grid operations, a large body of research focuses on using\ngeneration redispatching, load shedding or demand side management\nflexibilities. However, a less costly and potentially more flexible option\nwould be grid topology reconfiguration, as already partially exploited by\nCoreso (European RSC) and RTE (French TSO) operations. Beyond previous work on\nbranch switching, bus reconfigurations are a broader class of action and could\nprovide some substantial benefits to route electricity and optimize the grid\ncapacity to keep it within safety margins. Because of its non-linear and\ncombinatorial nature, no existing optimal power flow solver can yet tackle this\nproblem. We here propose a new framework to learn topology controllers through\nimitation and reinforcement learning. We present the design and the results of\nthe first \"Learning to Run a Power Network\" challenge released with this\nframework. We finally develop a method providing performance upper-bounds\n(oracle), which highlights remaining unsolved challenges and suggests future\ndirections of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:35:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Marot", "Antoine", ""], ["Donnot", "Benjamin", ""], ["Romero", "Camilo", ""], ["Veyrin-Forrer", "Luca", ""], ["Lerousseau", "Marvin", ""], ["Donon", "Balthazar", ""], ["Guyon", "Isabelle", ""]]}, {"id": "1912.04212", "submitter": "Hwan Goh", "authors": "Hwan Goh, Sheroze Sheriffdeen, Jonathan Wittmer, Tan Bui-Thanh", "title": "Solving Bayesian Inverse Problems via Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the field of machine learning has made phenomenal progress\nin the pursuit of simulating real-world data generation processes. One notable\nexample of such success is the variational autoencoder (VAE). In this work,\nwith a small shift in perspective, we leverage and adapt VAEs for a different\npurpose: uncertainty quantification in scientific inverse problems. We\nintroduce UQ-VAE: a flexible, adaptive, hybrid data/model-informed framework\nfor training neural networks capable of rapid modelling of the posterior\ndistribution representing the unknown parameter of interest. Specifically, from\ndivergence-based variational inference, our framework is derived such that most\nof the information usually present in scientific inverse problems is fully\nutilized in the training procedure. Additionally, this framework includes an\nadjustable hyperparameter that allows selection of the notion of distance\nbetween the posterior model and the target distribution. This introduces more\nflexibility in controlling how optimization directs the learning of the\nposterior model. Further, this framework possesses an inherent adaptive\noptimization property that emerges through the learning of the posterior\nuncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:33:32 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 02:09:13 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 20:44:37 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 16:51:16 GMT"}, {"version": "v5", "created": "Sat, 12 Dec 2020 02:39:05 GMT"}, {"version": "v6", "created": "Sun, 28 Feb 2021 22:44:52 GMT"}, {"version": "v7", "created": "Sun, 7 Mar 2021 06:42:51 GMT"}, {"version": "v8", "created": "Wed, 5 May 2021 02:22:11 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Goh", "Hwan", ""], ["Sheriffdeen", "Sheroze", ""], ["Wittmer", "Jonathan", ""], ["Bui-Thanh", "Tan", ""]]}, {"id": "1912.04216", "submitter": "Ilya Kavalerov", "authors": "Ilya Kavalerov, Wojciech Czaja, Rama Chellappa", "title": "cGANs with Multi-Hinge Loss", "comments": "Accepted to Winter Conference on Applications of Computer Vision\n  (WACV) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to incorporate class conditional information into\nthe critic of GANs via a multi-class generalization of the commonly used Hinge\nloss that is compatible with both supervised and semi-supervised settings. We\nstudy the compromise between training a state of the art generator and an\naccurate classifier simultaneously, and propose a way to use our algorithm to\nmeasure the degree to which a generator and critic are class conditional. We\nshow the trade-off between a generator-critic pair respecting class\nconditioning inputs and generating the highest quality images. With our\nmulti-hinge loss modification we are able to improve Inception Scores and\nFrechet Inception Distance on the Imagenet dataset. We make our tensorflow code\navailable at https://github.com/ilyakava/gan.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 17:51:50 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 21:01:27 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kavalerov", "Ilya", ""], ["Czaja", "Wojciech", ""], ["Chellappa", "Rama", ""]]}, {"id": "1912.04217", "submitter": "Tom White", "authors": "Tom White", "title": "Shared Visual Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents abstract art created by neural networks and broadly\nrecognizable across various computer vision systems. The existence of abstract\nforms that trigger specific labels independent of neural architecture or\ntraining set suggests convolutional neural networks build shared visual\nrepresentations for the categories they understand. Computer vision classifiers\nencountering these drawings often respond with strong responses for specific\nlabels - in extreme cases stronger than all examples from the validation set.\nBy surveying human subjects we confirm that these abstract artworks are also\nbroadly recognizable by people, suggesting visual representations triggered by\nthese drawings are shared across human and computer vision systems.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:51:02 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["White", "Tom", ""]]}, {"id": "1912.04218", "submitter": "Hideaki Hayashi D.Eng.", "authors": "Hideaki Hayashi, Taro Shibanoki and Toshio Tsuji", "title": "A Neural Network Based on the Johnson $S_\\mathrm{U}$ Translation System\n  and Related Application to Electromyogram Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromyogram (EMG) classification is a key technique in EMG-based control\nsystems. The existing EMG classification methods do not consider the\ncharacteristics of EMG features that the distribution has skewness and\nkurtosis, causing drawbacks such as the requirement of hyperparameter tuning.\nIn this paper, we propose a neural network based on the Johnson $S_\\mathrm{U}$\ntranslation system that is capable of representing distributions with skewness\nand kurtosis. The Johnson system is a normalizing translation that transforms\nnon-normal data to a normal distribution, thereby enabling the representation\nof a wide range of distributions. In this study, a discriminative model based\non the multivariate Johnson $S_\\mathrm{U}$ translation system is transformed\ninto a linear combination of coefficients and input vectors using\nlog-linearization. This is then incorporated into a neural network structure,\nthereby allowing the calculation of the posterior probability of the input\nvectors for each class and the determination of model parameters as weight\ncoefficients of the network. The uniqueness of convergence of the network\nlearning is theoretically guaranteed. In the experiments, the suitability of\nthe proposed network for distributions including skewness and kurtosis is\nevaluated using artificially generated data. Its applicability for real\nbiological data is also evaluated via an EMG classification experiment. The\nresults show that the proposed network achieves high classification performance\nwithout the need for hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 10:28:37 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hayashi", "Hideaki", ""], ["Shibanoki", "Taro", ""], ["Tsuji", "Toshio", ""]]}, {"id": "1912.04226", "submitter": "Allan Jabri", "authors": "Allan Jabri, Kyle Hsu, Ben Eysenbach, Abhishek Gupta, Sergey Levine,\n  Chelsea Finn", "title": "Unsupervised Curricula for Visual Meta-Reinforcement Learning", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principle, meta-reinforcement learning algorithms leverage experience\nacross many tasks to learn fast reinforcement learning (RL) strategies that\ntransfer to similar tasks. However, current meta-RL approaches rely on\nmanually-defined distributions of training tasks, and hand-crafting these task\ndistributions can be challenging and time-consuming. Can \"useful\" pre-training\ntasks be discovered in an unsupervised manner? We develop an unsupervised\nalgorithm for inducing an adaptive meta-training task distribution, i.e. an\nautomatic curriculum, by modeling unsupervised interaction in a visual\nenvironment. The task distribution is scaffolded by a parametric density model\nof the meta-learner's trajectory distribution. We formulate unsupervised\nmeta-RL as information maximization between a latent task variable and the\nmeta-learner's data distribution, and describe a practical instantiation which\nalternates between integration of recent experience into the task distribution\nand meta-learning of the updated tasks. Repeating this procedure leads to\niterative reorganization such that the curriculum adapts as the meta-learner's\ndata distribution shifts. In particular, we show how discriminative clustering\nfor visual representation can support trajectory-level task acquisition and\nexploration in domains with pixel observations, avoiding pitfalls of\nalternatives. In experiments on vision-based navigation and manipulation\ndomains, we show that the algorithm allows for unsupervised meta-learning that\ntransfers to downstream tasks specified by hand-crafted reward functions and\nserves as pre-training for more efficient supervised meta-learning of test task\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:05:05 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Jabri", "Allan", ""], ["Hsu", "Kyle", ""], ["Eysenbach", "Ben", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1912.04228", "submitter": "Casey Meehan", "authors": "Casey Meehan, Kamalika Chaudhuri", "title": "Location Trace Privacy Under Conditional Priors", "comments": "Included in NeurIPS 2019 PriML workshop\n  https://priml-workshop.github.io/priml2019/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing meaningful privacy to users of location based services is\nparticularly challenging when multiple locations are revealed in a short period\nof time. This is primarily due to the tremendous degree of dependence that can\nbe anticipated between points. We propose a R\\'enyi differentially private\nframework for bounding expected privacy loss for conditionally dependent data.\nAdditionally, we demonstrate an algorithm for achieving this privacy under\nGaussian process conditional priors. This framework both exemplifies why\nconditionally dependent data is so challenging to protect and offers a strategy\nfor preserving privacy to within a fixed radius for every user location in a\ntrace.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:12:39 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Meehan", "Casey", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "1912.04242", "submitter": "Jacobo Roa-Vicens", "authors": "Jacobo Roa-Vicens, Yuanbo Wang, Virgile Mison, Yarin Gal, Ricardo\n  Silva", "title": "Adversarial recovery of agent rewards from latent spaces of the limit\n  order book", "comments": "Published as a workshop paper on NeurIPS 2019 Workshop on Robust AI\n  in Financial Services. 33rd Conference on Neural Information Processing\n  Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning has proved its ability to explain state-action\ntrajectories of expert agents by recovering their underlying reward functions\nin increasingly challenging environments. Recent advances in adversarial\nlearning have allowed extending inverse RL to applications with non-stationary\nenvironment dynamics unknown to the agents, arbitrary structures of reward\nfunctions and improved handling of the ambiguities inherent to the ill-posed\nnature of inverse RL. This is particularly relevant in real time applications\non stochastic environments involving risk, like volatile financial markets.\nMoreover, recent work on simulation of complex environments enable learning\nalgorithms to engage with real market data through simulations of its latent\nspace representations, avoiding a costly exploration of the original\nenvironment. In this paper, we explore whether adversarial inverse RL\nalgorithms can be adapted and trained within such latent space simulations from\nreal market data, while maintaining their ability to recover agent rewards\nrobust to variations in the underlying dynamics, and transfer them to new\nregimes of the original environment.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:32:12 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Roa-Vicens", "Jacobo", ""], ["Wang", "Yuanbo", ""], ["Mison", "Virgile", ""], ["Gal", "Yarin", ""], ["Silva", "Ricardo", ""]]}, {"id": "1912.04251", "submitter": "Naoufel Werghi Dr.", "authors": "Taimur Hassan, Salman H. Khan, Samet Akcay, Mohammed Bennamoun,\n  Naoufel Werghi", "title": "Cascaded Structure Tensor Framework for Robust Identification of Heavily\n  Occluded Baggage Items from Multi-Vendor X-ray Scans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades, luggage scanning has globally become one of the\nprime aviation security concerns. Manual screening of the baggage items is a\ncumbersome, subjective and inefficient process. Hence, many researchers have\ndeveloped Xray imagery-based autonomous systems to address these shortcomings.\nHowever, to the best of our knowledge, there is no framework, up to now, that\ncan recognize heavily occluded and cluttered baggage items from multi-vendor\nX-ray scans. This paper presents a cascaded structure tensor framework which\ncan automatically extract and recognize suspicious items irrespective of their\nposition and orientation in the multi-vendor X-ray scans. The proposed\nframework is unique, as it intelligently extracts each object by iteratively\npicking contour based transitional information from different orientations and\nuses only a single feedforward convolutional neural network for the\nrecognition. The proposed framework has been rigorously tested on publicly\navailable GDXray and SIXray datasets containing a total of 1,067,381 X-ray\nscans where it significantly outperformed the state-of-the-art solutions by\nachieving the mean average precision score of 0.9343 and 0.9595 for extracting\nand recognizing suspicious items from GDXray and SIXray scans, respectively.\nFurthermore, the proposed framework has achieved 15.78% better time\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:40:47 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 05:28:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hassan", "Taimur", ""], ["Khan", "Salman H.", ""], ["Akcay", "Samet", ""], ["Bennamoun", "Mohammed", ""], ["Werghi", "Naoufel", ""]]}, {"id": "1912.04252", "submitter": "Chris Anderson", "authors": "Chris Anderson, Jacob Klein, Heygaan Rajakumar, Colin Judge, Laurent K\n  Beland", "title": "Automated Classification of Helium Ingress in Irradiated X-750", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imaging nanoscale features using transmission electron microscopy is key to\npredicting and assessing the mechanical behavior of structural materials in\nnuclear reactors. Analyzing these micrographs is often a tedious and labour\nintensive manual process. It is a prime candidate for automation. Here, a\nregion-based convolutional neural network is adapted to detect helium bubbles\nin micrographs of neutron-irradiated Inconel X-750 reactor spacer springs. We\ndemonstrate that this neural network produces analyses of similar accuracy and\nreproducibility to that produced by humans. Further, we show this method as\nbeing four orders of magnitude faster than manual analysis allowing for\ngeneration of significant quantities of data. The proposed method can be used\nwith micrographs of different Fresnel contrasts and magnification levels.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:43:50 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:56:02 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Anderson", "Chris", ""], ["Klein", "Jacob", ""], ["Rajakumar", "Heygaan", ""], ["Judge", "Colin", ""], ["Beland", "Laurent K", ""]]}, {"id": "1912.04261", "submitter": "Jonas Ismael Liechti", "authors": "Jonas I. Liechti and Sebastian Bonhoeffer", "title": "A time resolved clustering method revealing longterm structures and\n  their short-term internal dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The last decades have not only been characterized by an explosive growth of\ndata, but also an increasing appreciation of data as a valuable resource. Their\nvalue comes with the ability to extract meaningful patterns that are of\neconomic, societal or scientific relevance. A particular challenge is the\nidentification of patterns across time, including those that might only become\napparent when the temporal dimension is taken into account. Here, we present a\nnovel method that aims to achieve this by detecting dynamic clusters, i.e.\nstructural elements that can be present over prolonged durations. It is based\non an adaptive identification of majority overlaps between groups at different\ntime points and accommodates the transient decompositions in otherwise\npersistent dynamic clusters. Our method enables the detection of persistent\nstructural elements with internal dynamics and can be applied to any\nclassifiable data, ranging from social contact networks to arbitrary sets of\ntime stamped feature vectors. It represents a unique tool to study systems with\nnon-trivial temporal dynamics and has a broad applicability to scientific,\nsocietal and economic data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:54:54 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 20:38:46 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Liechti", "Jonas I.", ""], ["Bonhoeffer", "Sebastian", ""]]}, {"id": "1912.04265", "submitter": "Jeffrey Negrea", "authors": "Jeffrey Negrea, Gintare Karolina Dziugaite, Daniel M. Roy", "title": "In Defense of Uniform Convergence: Generalization via derandomization\n  with an application to interpolating predictors", "comments": "14 pages before references and appendices. 35 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to study the generalization error of a learned predictor $\\hat h$\nin terms of that of a surrogate (potentially randomized) predictor that is\ncoupled to $\\hat h$ and designed to trade empirical risk for control of\ngeneralization error. In the case where $\\hat h$ interpolates the data, it is\ninteresting to consider theoretical surrogate classifiers that are partially\nderandomized or rerandomized, e.g., fit to the training data but with modified\nlabel noise. We also show that replacing $\\hat h$ by its conditional\ndistribution with respect to an arbitrary $\\sigma$-field is a convenient way to\nderandomize. We study two examples, inspired by the work of Nagarajan and\nKolter (2019) and Bartlett et al. (2019), where the learned classifier $\\hat h$\ninterpolates the training data with high probability, has small risk, and, yet,\ndoes not belong to a nonrandom class with a tight uniform bound on two-sided\ngeneralization error. At the same time, we bound the risk of $\\hat h$ in terms\nof surrogates constructed by conditioning and denoising, respectively, and\nshown to belong to nonrandom classes with uniformly small generalization error.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:57:41 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 18:55:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Negrea", "Jeffrey", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1912.04278", "submitter": "Huidong Xie", "authors": "Huidong Xie, Hongming Shan, Wenxiang Cong, Chi Liu, Xiaohua Zhang,\n  Shaohua Liu, Ruola Ning, Ge Wang", "title": "Deep Efficient End-to-end Reconstruction (DEER) Network for Few-view\n  Breast CT Image Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3033795", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breast CT provides image volumes with isotropic resolution in high contrast,\nenabling detection of small calcification (down to a few hundred microns in\nsize) and subtle density differences. Since breast is sensitive to x-ray\nradiation, dose reduction of breast CT is an important topic, and for this\npurpose, few-view scanning is a main approach. In this article, we propose a\nDeep Efficient End-to-end Reconstruction (DEER) network for few-view breast CT\nimage reconstruction. The major merits of our network include high dose\nefficiency, excellent image quality, and low model complexity. By the design,\nthe proposed network can learn the reconstruction process with as few as O(N)\nparameters, where N is the side length of an image to be reconstructed, which\nrepresents orders of magnitude improvements relative to the state-of-the-art\ndeep-learning-based reconstruction methods that map raw data to tomographic\nimages directly. Also, validated on a cone-beam breast CT dataset prepared by\nKoning Corporation on a commercial scanner, our method demonstrates a\ncompetitive performance over the state-of-the-art reconstruction networks in\nterms of image quality. The source code of this paper is available at:\nhttps://github.com/HuidongXie/DEER.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 02:44:24 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 11:35:10 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 21:00:05 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Xie", "Huidong", ""], ["Shan", "Hongming", ""], ["Cong", "Wenxiang", ""], ["Liu", "Chi", ""], ["Zhang", "Xiaohua", ""], ["Liu", "Shaohua", ""], ["Ning", "Ruola", ""], ["Wang", "Ge", ""]]}, {"id": "1912.04321", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh and Seyed Mohammad Asghari", "title": "Learning to Code: Coded Caching via Deep Reinforcement Learning", "comments": "Presented at the 2019 Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a system comprising a file library and a network with a server\nand multiple users equipped with cache memories. The system operates in two\nphases: a prefetching phase, where users load their caches with parts of\ncontents from the library, and a delivery phase, where users request files from\nthe library and the server needs to send the uncached parts of the requested\nfiles to the users. For the case where the users' caches are arbitrarily\nloaded, we propose an algorithm based on deep reinforcement learning to\nminimize the delay of delivering requested contents to the users in the\ndelivery phase. Simulation results demonstrate that our proposed deep\nreinforcement learning agent learns a coded delivery strategy for sending the\nrequests to the users, which slightly outperforms the state-of-the-art\nperformance in terms of delivery delay, while drastically reducing the\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 19:05:41 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Asghari", "Seyed Mohammad", ""]]}, {"id": "1912.04345", "submitter": "Carl Poelking", "authors": "Carl Poelking, Yehia Amar, Alexei Lapkin, Lucy Colwell", "title": "Noisy, sparse, nonlinear: Navigating the Bermuda Triangle of physical\n  inference with deep filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the microscopic interactions that determine molecular reactivity\nposes a challenge across the physical sciences. Even a basic understanding of\nthe underlying reaction mechanisms can substantially accelerate materials and\ncompound design, including the development of new catalysts or drugs. Given the\ndifficulties routinely faced by both experimental and theoretical\ninvestigations that aim to improve our mechanistic understanding of a reaction,\nrecent advances have focused on data-driven routes to derive structure-property\nrelationships directly from high-throughput screens. However, even these\nhigh-quality, high-volume data are noisy, sparse and biased -- placing them in\na regime where machine-learning is extremely challenging. Here we show that a\nstatistical approach based on deep filtering of nonlinear feature networks\nresults in physicochemical models that are more robust, transparent and\ngeneralize better than standard machine-learning architectures. Using diligent\ndescriptor design and data post-processing, we exemplify the approach using\nboth literature and fresh data on asymmetric catalytic hydrogenation,\nPalladium-catalyzed cross-coupling reactions, and drug-drug synergy. We\nillustrate how the sparse models uncovered by the filtering help us formulate\nphysicochemical reaction ``pharmacophores'', investigate experimental bias and\nderive strategies for mechanism detection and classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:57:07 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Poelking", "Carl", ""], ["Amar", "Yehia", ""], ["Lapkin", "Alexei", ""], ["Colwell", "Lucy", ""]]}, {"id": "1912.04357", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir", "title": "DeepMUSIC: Multiple Signal Classification via Deep Learning", "comments": "To appear in IEEE Sensors Letters, 5 pages, 5 figures", "journal-ref": null, "doi": "10.1109/LSENS.2020.2980384", "report-no": null, "categories": "eess.SP cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter introduces a deep learning (DL) framework for\ndirection-of-arrival (DOA) estimation. Previous works in DL context mostly\nconsider a single or two target scenario which is a strong limitation in\npractice. Hence, in this work, we propose a DL framework for multiple signal\nclassification (DeepMUSIC). We design multiple deep convolutional neural\nnetworks (CNNs), each of which is dedicated to a subregion of the angular\nspectrum. In particular, each CNN is fed with the array covariance matrix and\nit learns the MUSIC spectra of the corresponding angular subregion. We have\nshown, through simulations, that the proposed DeepMUSIC framework has superior\nestimation accuracy and exhibits less computational complexity in comparison\nwith both DL and non-DL based techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 20:18:59 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 20:16:37 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 10:30:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Elbir", "Ahmet M.", ""]]}, {"id": "1912.04368", "submitter": "Murphy Yuezhen Niu", "authors": "Murphy Yuezhen Niu, Vadim Smelyanskyi, Paul Klimov, Sergio Boixo, Rami\n  Barends, Julian Kelly, Yu Chen, Kunal Arya, Brian Burkett, Dave Bacon, Zijun\n  Chen, Ben Chiaro, Roberto Collins, Andrew Dunsworth, Brooks Foxen, Austin\n  Fowler, Craig Gidney, Marissa Giustina, Rob Graff, Trent Huang, Evan Jeffrey,\n  David Landhuis, Erik Lucero, Anthony Megrant, Josh Mutus, Xiao Mi, Ofer\n  Naaman, Matthew Neeley, Charles Neill, Chris Quintana, Pedram Roushan, John\n  M. Martinis, Hartmut Neven", "title": "Learning Non-Markovian Quantum Noise from Moir\\'{e}-Enhanced Swap\n  Spectroscopy with Deep Evolutionary Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-level-system (TLS) defects in amorphous dielectrics are a major source of\nnoise and decoherence in solid-state qubits. Gate-dependent non-Markovian\nerrors caused by TLS-qubit coupling are detrimental to fault-tolerant quantum\ncomputation and have not been rigorously treated in the existing literature. In\nthis work, we derive the non-Markovian dynamics between TLS and qubits during a\nSWAP-like two-qubit gate and the associated average gate fidelity for\nfrequency-tunable Transmon qubits. This gate dependent error model facilitates\nusing qubits as sensors to simultaneously learn practical imperfections in both\nthe qubit's environment and control waveforms. We combine the-state-of-art\nmachine learning algorithm with Moir\\'{e}-enhanced swap spectroscopy to achieve\nrobust learning using noisy experimental data. Deep neural networks are used to\nrepresent the functional map from experimental data to TLS parameters and are\ntrained through an evolutionary algorithm. Our method achieves the highest\nlearning efficiency and robustness against experimental imperfections to-date,\nrepresenting an important step towards in-situ quantum control optimization\nover environmental and control defects.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 20:47:20 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Niu", "Murphy Yuezhen", ""], ["Smelyanskyi", "Vadim", ""], ["Klimov", "Paul", ""], ["Boixo", "Sergio", ""], ["Barends", "Rami", ""], ["Kelly", "Julian", ""], ["Chen", "Yu", ""], ["Arya", "Kunal", ""], ["Burkett", "Brian", ""], ["Bacon", "Dave", ""], ["Chen", "Zijun", ""], ["Chiaro", "Ben", ""], ["Collins", "Roberto", ""], ["Dunsworth", "Andrew", ""], ["Foxen", "Brooks", ""], ["Fowler", "Austin", ""], ["Gidney", "Craig", ""], ["Giustina", "Marissa", ""], ["Graff", "Rob", ""], ["Huang", "Trent", ""], ["Jeffrey", "Evan", ""], ["Landhuis", "David", ""], ["Lucero", "Erik", ""], ["Megrant", "Anthony", ""], ["Mutus", "Josh", ""], ["Mi", "Xiao", ""], ["Naaman", "Ofer", ""], ["Neeley", "Matthew", ""], ["Neill", "Charles", ""], ["Quintana", "Chris", ""], ["Roushan", "Pedram", ""], ["Martinis", "John M.", ""], ["Neven", "Hartmut", ""]]}, {"id": "1912.04370", "submitter": "Aparna Balagopalan", "authors": "Aparna Balagopalan, Jekaterina Novikova, Matthew B. A. McDermott, Bret\n  Nestor, Tristan Naumann, Marzyeh Ghassemi", "title": "Cross-Language Aphasia Detection using Optimal Transport Domain\n  Adaptation", "comments": "Accepted to ML4H at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-language speech datasets are scarce and often have small sample sizes\nin the medical domain. Robust transfer of linguistic features across languages\ncould improve rates of early diagnosis and therapy for speakers of low-resource\nlanguages when detecting health conditions from speech. We utilize\nout-of-domain, unpaired, single-speaker, healthy speech data for training\nmultiple Optimal Transport (OT) domain adaptation systems. We learn mappings\nfrom other languages to English and detect aphasia from linguistic\ncharacteristics of speech, and show that OT domain adaptation improves aphasia\ndetection over unilingual baselines for French (6% increased F1) and Mandarin\n(5% increased F1). Further, we show that adding aphasic data to the domain\nadaptation system significantly increases performance for both French and\nMandarin, increasing the F1 scores further (10% and 8% increase in F1 scores\nfor French and Mandarin, respectively, over unilingual baselines).\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 19:48:54 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Novikova", "Jekaterina", ""], ["McDermott", "Matthew B. A.", ""], ["Nestor", "Bret", ""], ["Naumann", "Tristan", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1912.04378", "submitter": "Ioannis Panageas", "authors": "Vaggos Chatziafratis and Sai Ganesh Nagarajan and Ioannis Panageas and\n  Xiao Wang", "title": "Depth-Width Trade-offs for ReLU Networks via Sharkovsky's Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the representational power of Deep Neural Networks (DNNs) and\nhow their structural properties (e.g., depth, width, type of activation unit)\naffect the functions they can compute, has been an important yet challenging\nquestion in deep learning and approximation theory. In a seminal paper,\nTelgarsky highlighted the benefits of depth by presenting a family of functions\n(based on simple triangular waves) for which DNNs achieve zero classification\nerror, whereas shallow networks with fewer than exponentially many nodes incur\nconstant error. Even though Telgarsky's work reveals the limitations of shallow\nneural networks, it does not inform us on why these functions are difficult to\nrepresent and in fact he states it as a tantalizing open question to\ncharacterize those functions that cannot be well-approximated by smaller\ndepths.\n  In this work, we point to a new connection between DNNs expressivity and\nSharkovsky's Theorem from dynamical systems, that enables us to characterize\nthe depth-width trade-offs of ReLU networks for representing functions based on\nthe presence of generalized notion of fixed points, called periodic points (a\nfixed point is a point of period 1). Motivated by our observation that the\ntriangle waves used in Telgarsky's work contain points of period 3 - a period\nthat is special in that it implies chaotic behavior based on the celebrated\nresult by Li-Yorke - we proceed to give general lower bounds for the width\nneeded to represent periodic functions as a function of the depth. Technically,\nthe crux of our approach is based on an eigenvalue analysis of the dynamical\nsystem associated with such functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 21:11:02 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Nagarajan", "Sai Ganesh", ""], ["Panageas", "Ioannis", ""], ["Wang", "Xiao", ""]]}, {"id": "1912.04381", "submitter": "Dolly Agarwal", "authors": "Dolly Agarwal, Jayant Gupchup, Nishant Baghel", "title": "A Dataset for measuring reading levels in India at scale", "comments": "5 pages, 3 figures, 3 Tables, Paper accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CY cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One out of four children in India are leaving grade eight without basic\nreading skills. Measuring the reading levels in a vast country like India poses\nsignificant hurdles. Recent advances in machine learning opens up the\npossibility of automating this task. However, the datasets of children's speech\nare not only rare but are primarily in English. To solve this assessment\nproblem and advance deep learning research in regional Indian languages, we\npresent the ASER dataset of children in the age group of 6-14. The dataset\nconsists of 5,301 subjects generating 81,330 labeled audio clips in Hindi,\nMarathi and English. These labels represent expert opinions on the child's\nability to read at a specified level. Using this dataset, we built a simple\nASR-based classifier. Early results indicate that we can achieve a prediction\naccuracy of 86% for the English language. Considering the ASER survey spans\nhalf a million subjects, this dataset can grow to those scales.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:06:22 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:57:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Agarwal", "Dolly", ""], ["Gupchup", "Jayant", ""], ["Baghel", "Nishant", ""]]}, {"id": "1912.04391", "submitter": "Harrison Nguyen", "authors": "Harrison Nguyen, Simon Luo, Fabio Ramos", "title": "Semi-supervised Learning Approach to Generate Neuroimaging Modalities\n  with Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic Resonance Imaging (MRI) of the brain can come in the form of\ndifferent modalities such as T1-weighted and Fluid Attenuated Inversion\nRecovery (FLAIR) which has been used to investigate a wide range of\nneurological disorders. Current state-of-the-art models for brain tissue\nsegmentation and disease classification require multiple modalities for\ntraining and inference. However, the acquisition of all of these modalities are\nexpensive, time-consuming, inconvenient and the required modalities are often\nnot available. As a result, these datasets contain large amounts of\n\\emph{unpaired} data, where examples in the dataset do not contain all\nmodalities. On the other hand, there is smaller fraction of examples that\ncontain all modalities (\\emph{paired} data) and furthermore each modality is\nhigh dimensional when compared to number of datapoints. In this work, we\ndevelop a method to address these issues with semi-supervised learning in\ntranslating between two neuroimaging modalities. Our proposed model,\nSemi-Supervised Adversarial CycleGAN (SSA-CGAN), uses an adversarial loss to\nlearn from \\emph{unpaired} data points, cycle loss to enforce consistent\nreconstructions of the mappings and another adversarial loss to take advantage\nof \\emph{paired} data points. Our experiments demonstrate that our proposed\nframework produces an improvement in reconstruction error and reduced variance\nfor the pairwise translation of multiple modalities and is more robust to\nthermal noise when compared to existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 21:53:27 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Nguyen", "Harrison", ""], ["Luo", "Simon", ""], ["Ramos", "Fabio", ""]]}, {"id": "1912.04418", "submitter": "Jakub Mare\\v{c}ek", "authors": "Albert Akhriev and Jakub Marecek", "title": "Deep Autoencoders with Value-at-Risk Thresholding for Unsupervised\n  Anomaly Detection", "comments": null, "journal-ref": "IEEE International Symposium on Multimedia 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world monitoring and surveillance applications require non-trivial\nanomaly detection to be run in the streaming model. We consider an\nincremental-learning approach, wherein a deep-autoencoding (DAE) model of what\nis normal is trained and used to detect anomalies at the same time. In the\ndetection of anomalies, we utilise a novel thresholding mechanism, based on\nvalue at risk (VaR). We compare the resulting convolutional neural network\n(CNN) against a number of subspace methods, and present results on\nchangedetection net.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 23:14:05 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Akhriev", "Albert", ""], ["Marecek", "Jakub", ""]]}, {"id": "1912.04423", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Rodrigo Alves Lima, Bruno Padilha, Joao Eduardo\n  Ferreira, Calton Pu", "title": "Robust, Extensible, and Fast: Teamed Classifiers for Vehicle Tracking\n  and Vehicle Re-ID in Multi-Camera Networks", "comments": null, "journal-ref": "2019 IEEE Conference on Cognitive Machine Intelligence", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As camera networks have become more ubiquitous over the past decade, the\nresearch interest in video management has shifted to analytics on multi-camera\nnetworks. This includes performing tasks such as object detection, attribute\nidentification, and vehicle/person tracking across different cameras without\noverlap. Current frameworks for management are designed for multi-camera\nnetworks in a closed dataset environment where there is limited variability in\ncameras and characteristics of the surveillance environment are well known.\nFurthermore, current frameworks are designed for offline analytics with\nguidance from human operators for forensic applications. This paper presents a\nteamed classifier framework for video analytics in heterogeneous many-camera\nnetworks with adversarial conditions such as multi-scale, multi-resolution\ncameras capturing the environment with varying occlusion, blur, and\norientations. We describe an implementation for vehicle tracking and vehicle\nre-identification (re-id), where we implement a zero-shot learning (ZSL) system\nthat performs automated tracking of all vehicles all the time. Our evaluations\non VeRi-776 and Cars196 show the teamed classifier framework is robust to\nadversarial conditions, extensible to changing video characteristics such as\nnew vehicle types/brands and new cameras, and offers real-time performance\ncompared to current offline video analytics approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 23:34:33 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 13:54:53 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Suprem", "Abhijit", ""], ["Lima", "Rodrigo Alves", ""], ["Padilha", "Bruno", ""], ["Ferreira", "Joao Eduardo", ""], ["Pu", "Calton", ""]]}, {"id": "1912.04427", "submitter": "Pedro Savarese", "authors": "Pedro Savarese and Hugo Silva and Michael Maire", "title": "Winning the Lottery with Continuous Sparsification", "comments": "Published as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for efficient, sparse deep neural network models is most\nprominently performed by pruning: training a dense, overparameterized network\nand removing parameters, usually via following a manually-crafted heuristic.\nAdditionally, the recent Lottery Ticket Hypothesis conjectures that, for a\ntypically-sized neural network, it is possible to find small sub-networks\nwhich, when trained from scratch on a comparable budget, match the performance\nof the original dense counterpart. We revisit fundamental aspects of pruning\nalgorithms, pointing out missing ingredients in previous approaches, and\ndevelop a method, Continuous Sparsification, which searches for sparse networks\nbased on a novel approximation of an intractable $\\ell_0$ regularization. We\ncompare against dominant heuristic-based methods on pruning as well as ticket\nsearch -- finding sparse subnetworks that can be successfully re-trained from\nan early iterate. Empirical results show that we surpass the state-of-the-art\nfor both objectives, across models and datasets, including VGG trained on\nCIFAR-10 and ResNet-50 trained on ImageNet. In addition to setting a new\nstandard for pruning, Continuous Sparsification also offers fast parallel\nticket search, opening doors to new applications of the Lottery Ticket\nHypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 00:30:34 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 00:55:36 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 23:58:27 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 11:53:22 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Savarese", "Pedro", ""], ["Silva", "Hugo", ""], ["Maire", "Michael", ""]]}, {"id": "1912.04439", "submitter": "Joonas J\\\"alk\\\"o", "authors": "Joonas J\\\"alk\\\"o, Eemil Lagerspetz, Jari Haukka, Sasu Tarkoma, Antti\n  Honkela, Samuel Kaski", "title": "Privacy-preserving data sharing via probabilistic modelling", "comments": null, "journal-ref": null, "doi": "10.1016/j.patter.2021.100271", "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy allows quantifying privacy loss resulting from accessing\nsensitive personal data. Repeated accesses to underlying data incur increasing\nloss. Releasing data as privacy-preserving synthetic data would avoid this\nlimitation, but would leave open the problem of designing what kind of\nsynthetic data. We propose formulating the problem of private data release\nthrough probabilistic modelling. This approach transforms the problem of\ndesigning the synthetic data into choosing a model for the data, allowing also\nincluding prior knowledge, which improves the quality of the synthetic data. We\ndemonstrate empirically, in an epidemiological study, that statistical\ndiscoveries can be reliably reproduced from the synthetic data. We expect the\nmethod to have broad use in creating high-quality anonymized data twins of key\ndata sets for research.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 01:21:32 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:09:43 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 07:39:45 GMT"}, {"version": "v4", "created": "Mon, 1 Mar 2021 09:26:54 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["J\u00e4lk\u00f6", "Joonas", ""], ["Lagerspetz", "Eemil", ""], ["Haukka", "Jari", ""], ["Tarkoma", "Sasu", ""], ["Honkela", "Antti", ""], ["Kaski", "Samuel", ""]]}, {"id": "1912.04443", "submitter": "Marvin Zhang", "authors": "Laura Smith, Nikita Dhawan, Marvin Zhang, Pieter Abbeel, Sergey Levine", "title": "AVID: Learning Multi-Stage Tasks via Pixel-Level Translation of Human\n  Videos", "comments": "Robotics: Science and Systems (RSS) 2020 camera ready submission.\n  Project website: https://sites.google.com/view/rss20avid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic reinforcement learning (RL) holds the promise of enabling robots to\nlearn complex behaviors through experience. However, realizing this promise for\nlong-horizon tasks in the real world requires mechanisms to reduce human burden\nin terms of defining the task and scaffolding the learning process. In this\npaper, we study how these challenges can be alleviated with an automated\nrobotic learning framework, in which multi-stage tasks are defined simply by\nproviding videos of a human demonstrator and then learned autonomously by the\nrobot from raw image observations. A central challenge in imitating human\nvideos is the difference in appearance between the human and robot, which\ntypically requires manual correspondence. We instead take an automated approach\nand perform pixel-level image translation via CycleGAN to convert the human\ndemonstration into a video of a robot, which can then be used to construct a\nreward function for a model-based RL algorithm. The robot then learns the task\none stage at a time, automatically learning how to reset each stage to retry it\nmultiple times without human-provided resets. This makes the learning process\nlargely automatic, from intuitive task specification via a video to automated\ntraining with minimal human intervention. We demonstrate that our approach is\ncapable of learning complex tasks, such as operating a coffee machine, directly\nfrom raw image observations, requiring only 20 minutes to provide human\ndemonstrations and about 180 minutes of robot interaction.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 01:36:18 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 04:29:36 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 20:16:28 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Smith", "Laura", ""], ["Dhawan", "Nikita", ""], ["Zhang", "Marvin", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.04453", "submitter": "Rishu Garg", "authors": "Rishu Garg, Rekh Ram Janghel, Yogesh Rathore", "title": "Enhancing Learnability of classification algorithms using simple data\n  preprocessing in fMRI scans of Alzheimer's disease", "comments": "8 Pages, 6 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's Disease (AD) is the most common type of dementia. In all leading\ncountries, it is one of the primary reasons of death in senior citizens.\nCurrently, it is diagnosed by calculating the MSME score and by the manual\nstudy of MRI Scan. Also, different machine learning methods are utilized for\nautomatic diagnosis but existing has some limitations in terms of accuracy. In\nthis paper, we have proposed some novel preprocessing techniques that have\nsignificantly increased the accuracy and at the same time decreased the\ntraining time of various classification algorithms. First, we have converted\nthe ADNI dataset which was in 4D format into 2D form. We have also mitigated\nthe computation costs by reducing the parameters of the input dataset while\npreserving important and relevant data. We have achieved this by using\ndifferent preprocessing steps like grayscale image conversion, Histogram\nequalization and selective clipping of dataset. We observed a highest accuracy\nof 97.52% and a sensitivity of 97.6% in our testing dataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 02:12:54 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Garg", "Rishu", ""], ["Janghel", "Rekh Ram", ""], ["Rathore", "Yogesh", ""]]}, {"id": "1912.04471", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra and Nick Craswell", "title": "Duet at TREC 2019 Deep Learning Track", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report discusses three submissions based on the Duet architecture to the\nDeep Learning track at TREC 2019. For the document retrieval task, we adapt the\nDuet model to ingest a \"multiple field\" view of documents---we refer to the new\narchitecture as Duet with Multiple Fields (DuetMF). A second submission\ncombines the DuetMF model with other neural and traditional relevance\nestimators in a learning-to-rank framework and achieves improved performance\nover the DuetMF baseline. For the passage retrieval task, we submit a single\nrun based on an ensemble of eight Duet models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:23:05 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Craswell", "Nick", ""]]}, {"id": "1912.04472", "submitter": "Daniel Brown", "authors": "Daniel S. Brown and Scott Niekum", "title": "Deep Bayesian Reward Learning from Preferences", "comments": "Workshop on Safety and Robustness in Decision Making at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inverse reinforcement learning (IRL) methods are ideal for safe\nimitation learning, as they allow a learning agent to reason about reward\nuncertainty and the safety of a learned policy. However, Bayesian IRL is\ncomputationally intractable for high-dimensional problems because each sample\nfrom the posterior requires solving an entire Markov Decision Process (MDP).\nWhile there exist non-Bayesian deep IRL methods, these methods typically infer\npoint estimates of reward functions, precluding rigorous safety and uncertainty\nanalysis. We propose Bayesian Reward Extrapolation (B-REX), a highly efficient,\npreference-based Bayesian reward learning algorithm that scales to\nhigh-dimensional, visual control tasks. Our approach uses successor feature\nrepresentations and preferences over demonstrations to efficiently generate\nsamples from the posterior distribution over the demonstrator's reward function\nwithout requiring an MDP solver. Using samples from the posterior, we\ndemonstrate how to calculate high-confidence bounds on policy performance in\nthe imitation learning setting, in which the ground-truth reward function is\nunknown. We evaluate our proposed approach on the task of learning to play\nAtari games via imitation learning from pixel inputs, with no access to the\ngame score. We demonstrate that B-REX learns imitation policies that are\ncompetitive with a state-of-the-art deep imitation learning method that only\nlearns a point estimate of the reward function. Furthermore, we demonstrate\nthat samples from the posterior generated via B-REX can be used to compute\nhigh-confidence performance bounds for a variety of evaluation policies. We\nshow that high-confidence performance bounds are useful for accurately ranking\ndifferent evaluation policies when the reward function is unknown. We also\ndemonstrate that high-confidence performance bounds may be useful for detecting\nreward hacking.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:29:51 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Brown", "Daniel S.", ""], ["Niekum", "Scott", ""]]}, {"id": "1912.04481", "submitter": "Yuan Yao", "authors": "Sam Likun Xi, Yuan Yao, Kshitij Bhardwaj, Paul Whatmough, Gu-Yeon Wei,\n  David Brooks", "title": "SMAUG: End-to-End Full-Stack Simulation Infrastructure for Deep Learning\n  Workloads", "comments": "14 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been tremendous advances in hardware acceleration\nof deep neural networks. However, most of the research has focused on\noptimizing accelerator microarchitecture for higher performance and energy\nefficiency on a per-layer basis. We find that for overall single-batch\ninference latency, the accelerator may only make up 25-40%, with the rest spent\non data movement and in the deep learning software framework. Thus far, it has\nbeen very difficult to study end-to-end DNN performance during early stage\ndesign (before RTL is available) because there are no existing DNN frameworks\nthat support end-to-end simulation with easy custom hardware accelerator\nintegration. To address this gap in research infrastructure, we present SMAUG,\nthe first DNN framework that is purpose-built for simulation of end-to-end deep\nlearning applications. SMAUG offers researchers a wide range of capabilities\nfor evaluating DNN workloads, from diverse network topologies to easy\naccelerator modeling and SoC integration. To demonstrate the power and value of\nSMAUG, we present case studies that show how we can optimize overall\nperformance and energy efficiency for up to 1.8-5x speedup over a baseline\nsystem, without changing any part of the accelerator microarchitecture, as well\nas show how SMAUG can tune an SoC for a camera-powered deep learning pipeline.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 03:46:59 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 15:18:02 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Xi", "Sam Likun", ""], ["Yao", "Yuan", ""], ["Bhardwaj", "Kshitij", ""], ["Whatmough", "Paul", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""]]}, {"id": "1912.04487", "submitter": "Ruohan Gao", "authors": "Ruohan Gao, Tae-Hyun Oh, Kristen Grauman, Lorenzo Torresani", "title": "Listen to Look: Action Recognition by Previewing Audio", "comments": "Appears in CVPR 2020; Project page:\n  http://vision.cs.utexas.edu/projects/listen_to_look/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the face of the video data deluge, today's expensive clip-level\nclassifiers are increasingly impractical. We propose a framework for efficient\naction recognition in untrimmed video that uses audio as a preview mechanism to\neliminate both short-term and long-term visual redundancies. First, we devise\nan ImgAud2Vid framework that hallucinates clip-level features by distilling\nfrom lighter modalities---a single frame and its accompanying audio---reducing\nshort-term temporal redundancy for efficient clip-level recognition. Second,\nbuilding on ImgAud2Vid, we further propose ImgAud-Skimming, an attention-based\nlong short-term memory network that iteratively selects useful moments in\nuntrimmed videos, reducing long-term temporal redundancy for efficient\nvideo-level recognition. Extensive experiments on four action recognition\ndatasets demonstrate that our method achieves the state-of-the-art in terms of\nboth recognition accuracy and speed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 04:15:24 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 02:06:18 GMT"}, {"version": "v3", "created": "Sat, 28 Mar 2020 04:53:38 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Gao", "Ruohan", ""], ["Oh", "Tae-Hyun", ""], ["Grauman", "Kristen", ""], ["Torresani", "Lorenzo", ""]]}, {"id": "1912.04497", "submitter": "Kirthi Shankar Sivamani", "authors": "Kirthi Shankar Sivamani", "title": "Feature Losses for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has made tremendous advances in computer vision tasks such as\nimage classification. However, recent studies have shown that deep learning\nmodels are vulnerable to specifically crafted adversarial inputs that are\nquasi-imperceptible to humans. In this work, we propose a novel approach to\ndefending adversarial attacks. We employ an input processing technique based on\ndenoising autoencoders as a defense. It has been shown that the input\nperturbations grow and accumulate as noise in feature maps while propagating\nthrough a convolutional neural network (CNN). We exploit the noisy feature maps\nby using an additional subnetwork to extract image feature maps and train an\nauto-encoder on perceptual losses of these feature maps. This technique\nachieves close to state-of-the-art results on defending MNIST and CIFAR10\ndatasets, but more importantly, shows a new way of employing a defense that\ncannot be trivially trained end-to-end by the attacker. Empirical results\ndemonstrate the effectiveness of this approach on the MNIST and CIFAR10\ndatasets on simple as well as iterative LP attacks. Our method can be applied\nas a preprocessing technique to any off the shelf CNN.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 04:58:45 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Sivamani", "Kirthi Shankar", ""]]}, {"id": "1912.04508", "submitter": "Mohammed Amer", "authors": "Mohammed Amer, Tom\\'as Maul", "title": "Reducing Catastrophic Forgetting in Modular Neural Networks by Dynamic\n  Information Balancing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning is a very important step toward realizing robust autonomous\nartificial agents. Neural networks are the main engine of deep learning, which\nis the current state-of-the-art technique in formulating adaptive artificial\nintelligent systems. However, neural networks suffer from catastrophic\nforgetting when stressed with the challenge of continual learning. We\ninvestigate how to exploit modular topology in neural networks in order to\ndynamically balance the information load between different modules by routing\ninputs based on the information content in each module so that information\ninterference is minimized. Our dynamic information balancing (DIB) technique\nadapts a reinforcement learning technique to guide the routing of different\ninputs based on a reward signal derived from a measure of the information load\nin each module. Our empirical results show that DIB combined with elastic\nweight consolidation (EWC) regularization outperforms models with similar\ncapacity and EWC regularization across different task formulations and\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 05:41:44 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Amer", "Mohammed", ""], ["Maul", "Tom\u00e1s", ""]]}, {"id": "1912.04511", "submitter": "Quanquan Gu", "authors": "Pan Xu and Quanquan Gu", "title": "A Finite-Time Analysis of Q-Learning with Neural Network Function\n  Approximation", "comments": "22 pages, 1 table. This version simplifies the proof and improves the\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning with neural network function approximation (neural Q-learning for\nshort) is among the most prevalent deep reinforcement learning algorithms.\nDespite its empirical success, the non-asymptotic convergence rate of neural\nQ-learning remains virtually unknown. In this paper, we present a finite-time\nanalysis of a neural Q-learning algorithm, where the data are generated from a\nMarkov decision process and the action-value function is approximated by a deep\nReLU neural network. We prove that neural Q-learning finds the optimal policy\nwith $O(1/\\sqrt{T})$ convergence rate if the neural function approximator is\nsufficiently overparameterized, where $T$ is the number of iterations. To our\nbest knowledge, our result is the first finite-time analysis of neural\nQ-learning under non-i.i.d. data assumption.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 05:52:32 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:31:07 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Xu", "Pan", ""], ["Gu", "Quanquan", ""]]}, {"id": "1912.04521", "submitter": "Yige Zhang", "authors": "Yige Zhang, Aaron Yi Ding, Jorg Ott, Mingxuan Yuan, Jia Zeng, Kun\n  Zhang, Weixiong Rao", "title": "Transfer Learning-Based Outdoor Position Recovery with Telco Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telecommunication (Telco) outdoor position recovery aims to localize outdoor\nmobile devices by leveraging measurement report (MR) data. Unfortunately, Telco\nposition recovery requires sufficient amount of MR samples across different\nareas and suffers from high data collection cost. For an area with scarce MR\nsamples, it is hard to achieve good accuracy. In this paper, by leveraging the\nrecently developed transfer learning techniques, we design a novel Telco\nposition recovery framework, called TLoc, to transfer good models in the\ncarefully selected source domains (those fine-grained small subareas) to a\ntarget one which originally suffers from poor localization accuracy.\nSpecifically, TLoc introduces three dedicated components: 1) a new coordinate\nspace to divide an area of interest into smaller domains, 2) a similarity\nmeasurement to select best source domains, and 3) an adaptation of an existing\ntransfer learning approach. To the best of our knowledge, TLoc is the first\nframework that demonstrates the efficacy of applying transfer learning in the\nTelco outdoor position recovery. To exemplify, on the 2G GSM and 4G LTE MR\ndatasets in Shanghai, TLoc outperforms a nontransfer approach by 27.58% and\n26.12% less median errors, and further leads to 47.77% and 49.22% less median\nerrors than a recent fingerprinting approach NBL.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:09:50 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Zhang", "Yige", ""], ["Ding", "Aaron Yi", ""], ["Ott", "Jorg", ""], ["Yuan", "Mingxuan", ""], ["Zeng", "Jia", ""], ["Zhang", "Kun", ""], ["Rao", "Weixiong", ""]]}, {"id": "1912.04527", "submitter": "Francesca Baldini", "authors": "Francesca Baldini, Animashree Anandkumar, and Richard M. Murray", "title": "Learning Pose Estimation for UAV Autonomous Navigation andLanding Using\n  Visual-Inertial Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new learning approach for autonomous navigation\nand landing of an Unmanned-Aerial-Vehicle (UAV). We develop a multimodal fusion\nof deep neural architectures for visual-inertial odometry. We train the model\nin an end-to-end fashion to estimate the current vehicle pose from streams of\nvisual and inertial measurements. We first evaluate the accuracy of our\nestimation by comparing the prediction of the model to traditional algorithms\non the publicly available EuRoC MAV dataset. The results illustrate a $25 \\%$\nimprovement in estimation accuracy over the baseline. Finally, we integrate the\narchitecture in the closed-loop flight control system of Airsim - a plugin\nsimulator for Unreal Engine - and we provide simulation results for autonomous\nnavigation and landing.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:37:30 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:18:55 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Baldini", "Francesca", ""], ["Anandkumar", "Animashree", ""], ["Murray", "Richard M.", ""]]}, {"id": "1912.04530", "submitter": "Kan Li PhD", "authors": "Kan Li and Jose C. Principe", "title": "No-Trick (Treat) Kernel Adaptive Filtering using Deterministic Features", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods form a powerful, versatile, and theoretically-grounded\nunifying framework to solve nonlinear problems in signal processing and machine\nlearning. The standard approach relies on the kernel trick to perform pairwise\nevaluations of a kernel function, which leads to scalability issues for large\ndatasets due to its linear and superlinear growth with respect to the training\ndata. A popular approach to tackle this problem, known as random Fourier\nfeatures (RFFs), samples from a distribution to obtain the data-independent\nbasis of a higher finite-dimensional feature space, where its dot product\napproximates the kernel function. Recently, deterministic, rather than random\nconstruction has been shown to outperform RFFs, by approximating the kernel in\nthe frequency domain using Gaussian quadrature. In this paper, we view the dot\nproduct of these explicit mappings not as an approximation, but as an\nequivalent positive-definite kernel that induces a new finite-dimensional\nreproducing kernel Hilbert space (RKHS). This opens the door to no-trick (NT)\nonline kernel adaptive filtering (KAF) that is scalable and robust. Random\nfeatures are prone to large variances in performance, especially for smaller\ndimensions. Here, we focus on deterministic feature-map construction based on\npolynomial-exact solutions and show their superiority over random\nconstructions. Without loss of generality, we apply this approach to classical\nadaptive filtering algorithms and validate the methodology to show that\ndeterministic features are faster to generate and outperform state-of-the-art\nkernel methods based on random Fourier features.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:39:59 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Li", "Kan", ""], ["Principe", "Jose C.", ""]]}, {"id": "1912.04533", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Feynman Liang and Michael W. Mahoney", "title": "Exact expressions for double descent and implicit regularization via\n  surrogate random design", "comments": "Minor typo corrections and clarifications; moved the proofs into the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Double descent refers to the phase transition that is exhibited by the\ngeneralization error of unregularized learning models when varying the ratio\nbetween the number of parameters and the number of training samples. The recent\nsuccess of highly over-parameterized machine learning models such as deep\nneural networks has motivated a theoretical analysis of the double descent\nphenomenon in classical models such as linear regression which can also\ngeneralize well in the over-parameterized regime. We provide the first exact\nnon-asymptotic expressions for double descent of the minimum norm linear\nestimator. Our approach involves constructing a special determinantal point\nprocess which we call surrogate random design, to replace the standard i.i.d.\ndesign of the training sample. This surrogate design admits exact expressions\nfor the mean squared error of the estimator while preserving the key properties\nof the standard design. We also establish an exact implicit regularization\nresult for over-parameterized training samples. In particular, we show that,\nfor the surrogate design, the implicit bias of the unregularized minimum norm\nestimator precisely corresponds to solving a ridge-regularized least squares\nproblem on the population distribution. In our analysis we introduce a new\nmathematical tool of independent interest: the class of random matrices for\nwhich determinant commutes with expectation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:49:46 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 00:36:41 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 17:03:42 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Liang", "Feynman", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1912.04538", "submitter": "Zhikai Chen", "authors": "Zhikai Chen, Lingxi Xie, Shanmin Pang, Yong He, Qi Tian", "title": "Appending Adversarial Frames for Universal Video Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been many efforts in attacking image classification models with\nadversarial perturbations, but the same topic on video classification has not\nyet been thoroughly studied. This paper presents a novel idea of video-based\nattack, which appends a few dummy frames (e.g., containing the texts of `thanks\nfor watching') to a video clip and then adds adversarial perturbations only on\nthese new frames. Our approach enjoys three major benefits, namely, a high\nsuccess rate, a low perceptibility, and a strong ability in transferring across\ndifferent networks. These benefits mostly come from the common dummy frame\nwhich pushes all samples towards the boundary of classification. On the other\nhand, such attacks are easily to be concealed since most people would not\nnotice the abnormality behind the perturbed video clips. We perform experiments\non two popular datasets with six state-of-the-art video classification models,\nand demonstrate the effectiveness of our approach in the scenario of universal\nvideo attacks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:54:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Chen", "Zhikai", ""], ["Xie", "Lingxi", ""], ["Pang", "Shanmin", ""], ["He", "Yong", ""], ["Tian", "Qi", ""]]}, {"id": "1912.04549", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz and Rahat Masum", "title": "Expansion of Cyber Attack Data From Unbalanced Datasets Using Generative\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques help to understand patterns of a dataset to\ncreate a defense mechanism against cyber attacks. However, it is difficult to\nconstruct a theoretical model due to the imbalances in the dataset for\ndiscriminating attacks from the overall dataset. Multilayer Perceptron (MLP)\ntechnique will provide improvement in accuracy and increase the performance of\ndetecting the attack and benign data from a balanced dataset. We have worked on\nthe UGR'16 dataset publicly available for this work. Data wrangling has been\ndone due to prepare test set from in the original set. We fed the neural\nnetwork classifier larger input to the neural network in an increasing manner\n(i.e. 10000, 50000, 1 million) to see the distribution of features over the\naccuracy. We have implemented a GAN model that can produce samples of different\nattack labels (e.g. blacklist, anomaly spam, ssh scan). We have been able to\ngenerate as many samples as necessary based on the data sample we have taken\nfrom the UGR'16. We have tested the accuracy of our model with the imbalance\ndataset initially and then with the increasing the attack samples and found\nimprovement of classification performance for the latter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 07:33:17 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Yilmaz", "Ibrahim", ""], ["Masum", "Rahat", ""]]}, {"id": "1912.04556", "submitter": "Ahmad ALAbadleh", "authors": "Ahmad Abadleh", "title": "Accurate Entrance Position Detection Based on Wi-Fi and GPS Signals\n  Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at detecting an accurate position of the main entrance of the\nbuildings. The proposed approach relies on the fact that the GPS signals drop\nsignificantly when the user enters a building. Moreover, as most of the public\nbuildings provide Wi-Fi services, the Wi-Fi received signal strength (RSS) can\nbe utilized in order to detect the entrance of the buildings. The rationale\nbehind this paper is that the GPS signals decrease as the user gets close to\nthe main entrance and the Wi-Fi signal increases as the user approaches the\nmain entrance. Several real experiments have been conducted in order to\nguarantee the feasibility of the proposed approach. The experiment results have\nshown an interesting result and the accuracy of the whole system was one meter\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 08:02:19 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Abadleh", "Ahmad", ""]]}, {"id": "1912.04563", "submitter": "Jyoti Islam", "authors": "Jyoti Islam, Yanqing Zhang", "title": "Understanding 3D CNN Behavior for Alzheimer's Disease Diagnosis from\n  Brain PET Scan", "comments": "Science Meets Engineering of Deep Learning (SEDL) Workshop at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent days, Convolutional Neural Networks (CNN) have demonstrated\nimpressive performance in medical image analysis. However, there is a lack of\nclear understanding of why and how the Convolutional Neural Network performs so\nwell for image analysis task. How CNN analyzes an image and discriminates among\nsamples of different classes are usually considered as non-transparent. As a\nresult, it becomes difficult to apply CNN based approaches in clinical\nprocedures and automated disease diagnosis systems. In this paper, we consider\nthis issue and work on visualizing and understanding the decision of\nConvolutional Neural Network for Alzheimer's Disease (AD) Diagnosis. We develop\na 3D deep convolutional neural network for AD diagnosis using brain PET scans\nand propose using five visualizations techniques - Sensitivity Analysis\n(Backpropagation), Guided Backpropagation, Occlusion, Brain Area Occlusion, and\nLayer-wise Relevance Propagation (LRP) to understand the decision of the CNN by\nhighlighting the relevant areas in the PET data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 08:17:22 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 03:35:41 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Islam", "Jyoti", ""], ["Zhang", "Yanqing", ""]]}, {"id": "1912.04564", "submitter": "Sankalan Pal Chowdhury", "authors": "Arnab Kumar Mondal, Sankalan Pal Chowdhury, Aravind Jayendran, Parag\n  Singla, Himanshu Asnani, Prathosh AP", "title": "MaskAAE: Latent space optimization for Adversarial Auto-Encoders", "comments": "To be presented at UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of neural generative models is dominated by the highly successful\nGenerative Adversarial Networks (GANs) despite their challenges, such as\ntraining instability and mode collapse. Auto-Encoders (AE) with regularized\nlatent space provide an alternative framework for generative models, albeit\ntheir performance levels have not reached that of GANs. In this work, we\nhypothesise that the dimensionality of the AE model's latent space has a\ncritical effect on the quality of generated data. Under the assumption that\nnature generates data by sampling from a \"true\" generative latent space\nfollowed by a deterministic function, we show that the optimal performance is\nobtained when the dimensionality of the latent space of the AE-model matches\nwith that of the \"true\" generative latent space. Further, we propose an\nalgorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the\ndimensionality of the latent space of an adversarial auto encoder is brought\ncloser to that of the \"true\" generative latent space, via a procedure to mask\nthe spurious latent dimensions. We demonstrate through experiments on synthetic\nand several real-world datasets that the proposed formulation yields betterment\nin the generation quality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 08:18:13 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 11:26:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Chowdhury", "Sankalan Pal", ""], ["Jayendran", "Aravind", ""], ["Singla", "Parag", ""], ["Asnani", "Himanshu", ""], ["AP", "Prathosh", ""]]}, {"id": "1912.04635", "submitter": "Alessandro Betti", "authors": "Alessandro Betti and Marco Gori", "title": "Backprop Diffusion is Biologically Plausible", "comments": "9 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1907.05106", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Backpropagation algorithm relies on the abstraction of using a neural\nmodel that gets rid of the notion of time, since the input is mapped\ninstantaneously to the output. In this paper, we claim that this abstraction of\nignoring time, along with the abrupt input changes that occur when feeding the\ntraining set, are in fact the reasons why, in some papers, Backprop biological\nplausibility is regarded as an arguable issue. We show that as soon as a deep\nfeedforward network operates with neurons with time-delayed response, the\nbackprop weight update turns out to be the basic equation of a biologically\nplausible diffusion process based on forward-backward waves. We also show that\nsuch a process very well approximates the gradient for inputs that are not too\nfast with respect to the depth of the network. These remarks somewhat disclose\nthe diffusion process behind the backprop equation and leads us to interpret\nthe corresponding algorithm as a degeneration of a more general diffusion\nprocess that takes place also in neural networks with cyclic connections.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 10:50:15 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 10:04:48 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1912.04639", "submitter": "Gustavo Penha", "authors": "Gustavo Penha, Alexandru Balan and Claudia Hauff", "title": "Introducing MANtIS: a novel Multi-Domain Information Seeking Dialogues\n  Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational search is an approach to information retrieval (IR), where\nusers engage in a dialogue with an agent in order to satisfy their information\nneeds. Previous conceptual work described properties and actions a good agent\nshould exhibit. Unlike them, we present a novel conceptual model defined in\nterms of conversational goals, which enables us to reason about current\nresearch practices in conversational search. Based on the literature, we elicit\nhow existing tasks and test collections from the fields of IR, natural language\nprocessing (NLP) and dialogue systems (DS) fit into this model. We describe a\nset of characteristics that an ideal conversational search dataset should have.\nLastly, we introduce MANtIS (the code and dataset are available at\nhttps://guzpenha.github.io/MANtIS/), a large-scale dataset containing\nmulti-domain and grounded information seeking dialogues that fulfill all of our\ndataset desiderata. We provide baseline results for the conversation response\nranking and user intent prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 10:59:47 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Penha", "Gustavo", ""], ["Balan", "Alexandru", ""], ["Hauff", "Claudia", ""]]}, {"id": "1912.04643", "submitter": "Pablo Laiz Trece\\~no PhD Student", "authors": "Pablo Laiz, Jordi Vitri\\`a, Hagen Wenzek, Carolina Malagelada,\n  Fernando Azpiroz, Santi Segu\\'i", "title": "WCE Polyp Detection with Triplet based Embeddings", "comments": "19 pages, 13 figures, 9 tables, Accepted in Computerized Medical\n  Imaging and Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless capsule endoscopy is a medical procedure used to visualize the\nentire gastrointestinal tract and to diagnose intestinal conditions, such as\npolyps or bleeding. Current analyses are performed by manually inspecting\nnearly each one of the frames of the video, a tedious and error-prone task.\nAutomatic image analysis methods can be used to reduce the time needed for\nphysicians to evaluate a capsule endoscopy video, however these methods are\nstill in a research phase. In this paper we focus on computer-aided polyp\ndetection in capsule endoscopy images. This is a challenging problem because of\nthe diversity of polyp appearance, the imbalanced dataset structure and the\nscarcity of data. We have developed a new polyp computer-aided decision system\nthat combines a deep convolutional neural network and metric learning. The key\npoint of the method is the use of the triplet loss function with the aim of\nimproving feature extraction from the images when having small dataset. The\ntriplet loss function allows to train robust detectors by forcing images from\nthe same category to be represented by similar embedding vectors while ensuring\nthat images from different categories are represented by dissimilar vectors.\nEmpirical results show a meaningful increase of AUC values compared to baseline\nmethods. A good performance is not the only requirement when considering the\nadoption of this technology to clinical practice. Trust and explainability of\ndecisions are as important as performance. With this purpose, we also provide a\nmethod to generate visual explanations of the outcome of our polyp detector.\nThese explanations can be used to build a physician's trust in the system and\nalso to convey information about the inner working of the method to the\ndesigner for debugging purposes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 11:08:45 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 10:44:08 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 11:51:38 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Laiz", "Pablo", ""], ["Vitri\u00e0", "Jordi", ""], ["Wenzek", "Hagen", ""], ["Malagelada", "Carolina", ""], ["Azpiroz", "Fernando", ""], ["Segu\u00ed", "Santi", ""]]}, {"id": "1912.04672", "submitter": "Konstantin Ushenin", "authors": "Marat Bogdanov, Salim Baigildin, Aygul Fabarisova, Konstantin Ushenin,\n  Olga Solovyova", "title": "Effects of lead position, cardiac rhythm variation and drug-induced QT\n  prolongation on performance of machine learning methods for ECG processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning shows great performance in various problems of\nelectrocardiography (ECG) signal analysis. However, collecting a dataset for\nbiomedical engineering is a very difficult task. Any dataset for ECG processing\ncontains from 100 to 10,000 times fewer cases than datasets for image or text\nanalysis. This issue is especially important because of physiological phenomena\nthat can significantly change the morphology of heartbeats in ECG signals. In\nthis preliminary study, we analyze the effects of lead choice from the standard\nECG recordings, variation of ECG during 24-hours, and the effects of\nQT-prolongation agents on the performance of machine learning methods for ECG\nprocessing. We choose the problem of subject identification for analysis,\nbecause this problem may be solved for almost any available dataset of ECG\ndata. In a discussion, we compare our findings with observations from other\nworks that use machine learning for ECG processing with different problem\nstatements. Our results show the importance of training dataset enrichment with\nECG signals acquired in specific physiological conditions for obtaining good\nperformance of ECG processing for real applications.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 12:59:21 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 19:44:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bogdanov", "Marat", ""], ["Baigildin", "Salim", ""], ["Fabarisova", "Aygul", ""], ["Ushenin", "Konstantin", ""], ["Solovyova", "Olga", ""]]}, {"id": "1912.04684", "submitter": "Martin Klauco", "authors": "Karol Ki\\v{s}, Martin Klau\\v{c}o", "title": "Neural Network Based Explicit MPC for Chemical Reactor Control", "comments": "Preprint submitted to Acta Chimica Slovaca, ISSN: 1339-3065", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show the implementation of deep neural networks applied in\nprocess control. In our approach, we based the training of the neural network\non model predictive control. Model predictive control is popular for its\nability to be tuned by the weighting matrices and by the fact that it respects\nthe constraints. We present the neural network that can approximate the\nbehavior of the MPC in the way of mimicking the control input trajectory while\nthe constraints on states and control input remain unimpaired of the value of\nthe weighting matrices. This approach is demonstrated in a simulation case\nstudy involving a continuous stirred tank reactor, where multi-component\nchemical reaction takes place.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 13:44:48 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Ki\u0161", "Karol", ""], ["Klau\u010do", "Martin", ""]]}, {"id": "1912.04690", "submitter": "Angshul Majumdar Dr.", "authors": "Vanika Singhal and Angshul Majumdar", "title": "Reconstructing Multi-echo Magnetic Resonance Images via Structured Deep\n  Dictionary Learning", "comments": "Final version accepted at Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-echo magnetic resonance (MR) images are acquired by changing the echo\ntimes (for T2 weighted) or relaxation times (for T1 weighted) of scans. The\nresulting (multi-echo) images are usually used for quantitative MR imaging.\nAcquiring MR images is a slow process and acquiring multi scans of the same\ncross section for multi-echo imaging is even slower. In order to accelerate the\nscan, compressed sensing (CS) based techniques have been advocating partial\nK-space (Fourier domain) scans; the resulting images are reconstructed via\nstructured CS algorithms. In recent times, it has been shown that instead of\nusing off-the-shelf CS, better results can be obtained by adaptive\nreconstruction algorithms based on structured dictionary learning. In this\nwork, we show that the reconstruction results can be further improved by using\nstructured deep dictionaries. Experimental results on real datasets show that\nby using our proposed technique the scan-time can be cut by half compared to\nthe state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 14:01:17 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Singhal", "Vanika", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.04695", "submitter": "Zhuo Wang", "authors": "Zhuo Wang, Wei Zhang, Ning Liu, Jianyong Wang", "title": "Transparent Classification with Multilayer Logical Perceptrons and\n  Random Binarization", "comments": "AAAI-20 (oral presentation); source codes added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models with transparent inner structure and high classification performance\nare required to reduce potential risk and provide trust for users in domains\nlike health care, finance, security, etc. However, existing models are hard to\nsimultaneously satisfy the above two properties. In this paper, we propose a\nnew hierarchical rule-based model for classification tasks, named Concept Rule\nSets (CRS), which has both a strong expressive ability and a transparent inner\nstructure. To address the challenge of efficiently learning the\nnon-differentiable CRS model, we propose a novel neural network architecture,\nMultilayer Logical Perceptron (MLLP), which is a continuous version of CRS.\nUsing MLLP and the Random Binarization (RB) method we proposed, we can search\nthe discrete solution of CRS in continuous space using gradient descent and\nensure the discrete CRS acts almost the same as the corresponding continuous\nMLLP. Experiments on 12 public data sets show that CRS outperforms the\nstate-of-the-art approaches and the complexity of the learned CRS is close to\nthe simple decision tree. Source code is available at\nhttps://github.com/12wang3/mllp.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 14:13:09 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 07:45:01 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Zhuo", ""], ["Zhang", "Wei", ""], ["Liu", "Ning", ""], ["Wang", "Jianyong", ""]]}, {"id": "1912.04696", "submitter": "Dominik Kowald PhD", "authors": "Dominik Kowald and Markus Schedl and Elisabeth Lex", "title": "The Unfairness of Popularity Bias in Music Recommendation: A\n  Reproducibility Study", "comments": "ECIR 2020 reproducibility track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that recommender systems are typically biased towards\npopular items, which leads to less popular items being underrepresented in\nrecommendations. The recent work of Abdollahpouri et al. in the context of\nmovie recommendations has shown that this popularity bias leads to unfair\ntreatment of both long-tail items as well as users with little interest in\npopular items. In this paper, we reproduce the analyses of Abdollahpouri et al.\nin the context of music recommendation. Specifically, we investigate three user\ngroups from the LastFM music platform that are categorized based on how much\ntheir listening preferences deviate from the most popular music among all\nLastFM users in the dataset: (i) low-mainstream users, (ii) medium-mainstream\nusers, and (iii) high-mainstream users. In line with Abdollahpouri et al., we\nfind that state-of-the-art recommendation algorithms favor popular items also\nin the music domain. However, their proposed Group Average Popularity metric\nyields different results for LastFM than for the movie domain, presumably due\nto the larger number of available items (i.e., music artists) in the LastFM\ndataset we use. Finally, we compare the accuracy results of the recommendation\nalgorithms for the three user groups and find that the low-mainstreaminess\ngroup significantly receives the worst recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 14:13:50 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 09:31:58 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Kowald", "Dominik", ""], ["Schedl", "Markus", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1912.04734", "submitter": "Angshul Majumdar Dr.", "authors": "Jyoti Maggu, Angshul Majumdar and Emilie Chouzenoux", "title": "Transformed Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering assumes that the data is sepa-rable into separate\nsubspaces. Such a simple as-sumption, does not always hold. We assume that,\neven if the raw data is not separable into subspac-es, one can learn a\nrepresentation (transform coef-ficients) such that the learnt representation is\nsep-arable into subspaces. To achieve the intended goal, we embed subspace\nclustering techniques (locally linear manifold clustering, sparse sub-space\nclustering and low rank representation) into transform learning. The entire\nformulation is jointly learnt; giving rise to a new class of meth-ods called\ntransformed subspace clustering (TSC). In order to account for non-linearity,\nker-nelized extensions of TSC are also proposed. To test the performance of the\nproposed techniques, benchmarking is performed on image clustering and document\nclustering datasets. Comparison with state-of-the-art clustering techniques\nshows that our formulation improves upon them.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 14:57:14 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""], ["Chouzenoux", "Emilie", ""]]}, {"id": "1912.04738", "submitter": "Hanyuan Hang", "authors": "Hanyuan Hang, Zhouchen Lin, Xiaoyu Liu, Hongwei Wen", "title": "Histogram Transform Ensembles for Large-scale Regression", "comments": "arXiv admin note: text overlap with arXiv:1911.11581", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for large-scale regression problems named\nhistogram transform ensembles (HTE), composed of random rotations, stretchings,\nand translations. First of all, we investigate the theoretical properties of\nHTE when the regression function lies in the H\\\"{o}lder space $C^{k,\\alpha}$,\n$k \\in \\mathbb{N}_0$, $\\alpha \\in (0,1]$. In the case that $k=0, 1$, we adopt\nthe constant regressors and develop the na\\\"{i}ve histogram transforms (NHT).\nWithin the space $C^{0,\\alpha}$, although almost optimal convergence rates can\nbe derived for both single and ensemble NHT, we fail to show the benefits of\nensembles over single estimators theoretically. In contrast, in the subspace\n$C^{1,\\alpha}$, we prove that if $d \\geq 2(1+\\alpha)/\\alpha$, the lower bound\nof the convergence rates for single NHT turns out to be worse than the upper\nbound of the convergence rates for ensemble NHT. In the other case when $k \\geq\n2$, the NHT may no longer be appropriate in predicting smoother regression\nfunctions. Instead, we apply kernel histogram transforms (KHT) equipped with\nsmoother regressors such as support vector machines (SVMs), and it turns out\nthat both single and ensemble KHT enjoy almost optimal convergence rates. Then\nwe validate the above theoretical results by numerical experiments. On the one\nhand, simulations are conducted to elucidate that ensemble NHT outperform\nsingle NHT. On the other hand, the effects of bin sizes on accuracy of both NHT\nand KHT also accord with theoretical analysis. Last but not least, in the\nreal-data experiments, comparisons between the ensemble KHT, equipped with\nadaptive histogram transforms, and other state-of-the-art large-scale\nregression estimators verify the effectiveness and accuracy of our algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 16:39:02 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Hang", "Hanyuan", ""], ["Lin", "Zhouchen", ""], ["Liu", "Xiaoyu", ""], ["Wen", "Hongwei", ""]]}, {"id": "1912.04747", "submitter": "Amir Farzad", "authors": "Amir Farzad and T. Aaron Gulliver", "title": "Oversampling Log Messages Using a Sequence Generative Adversarial\n  Network for Anomaly Detection and Classification", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": "International Conference on Artificial Intelligence and Machine\n  Learning, 10 (2020), 163-175", "doi": "10.5121/csit.2020.100515", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with imbalanced data is one of the main challenges in machine/deep\nlearning algorithms for classification. This issue is more important with log\nmessage data as it is typically very imbalanced and negative logs are rare. In\nthis paper, a model is proposed to generate text log messages using a SeqGAN\nnetwork. Then features are extracted using an Autoencoder and anomaly detection\nis done using a GRU network. The proposed model is evaluated with two\nimbalanced log data sets, namely BGL and Openstack. Results are presented which\nshow that oversampling and balancing data increases the accuracy of anomaly\ndetection and classification.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 08:00:52 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 05:54:07 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Farzad", "Amir", ""], ["Gulliver", "T. Aaron", ""]]}, {"id": "1912.04748", "submitter": "Nikesh Bajaj", "authors": "Nikesh Bajaj, Tracy Goodluck Constance, Marvin Rajwadi, Julie Wall,\n  Mansour Moniri, Cornelius Glackin, Nigel Cannings, Chris Woodruff, James\n  Laird", "title": "Fraud detection in telephone conversations for financial services using\n  linguistic features", "comments": "Published - 33rd Conference on Neural Information Processing Systems\n  (NeurIPS 2019), AI for Social Good Workshop, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detecting the elements of deception in a conversation is one of the most\nchallenging problems for the AI community. It becomes even more difficult to\ndesign a transparent system, which is fully explainable and satisfies the need\nfor financial and legal services to be deployed. This paper presents an\napproach for fraud detection in transcribed telephone conversations using\nlinguistic features. The proposed approach exploits the syntactic and semantic\ninformation of the transcription to extract both the linguistic markers and the\nsentiment of the customer's response. We demonstrate the results on real-world\nfinancial services data using simple, robust and explainable classifiers such\nas Naive Bayes, Decision Tree, Nearest Neighbours, and Support Vector Machines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:07:48 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Bajaj", "Nikesh", ""], ["Constance", "Tracy Goodluck", ""], ["Rajwadi", "Marvin", ""], ["Wall", "Julie", ""], ["Moniri", "Mansour", ""], ["Glackin", "Cornelius", ""], ["Cannings", "Nigel", ""], ["Woodruff", "Chris", ""], ["Laird", "James", ""]]}, {"id": "1912.04754", "submitter": "Angshul Majumdar Dr.", "authors": "Aanchal Mongia, Neha Jhamb, Emilie Chouzenoux and Angshul Majumdar", "title": "Deep Latent Factor Model for Collaborative Filtering", "comments": "This is an initial draft of the accepted paper at Elsevier Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models have been used widely in collaborative filtering based\nrecommender systems. In recent years, deep learning has been successful in\nsolving a wide variety of machine learning problems. Motivated by the success\nof deep learning, we propose a deeper version of latent factor model.\nExperiments on benchmark datasets shows that our proposed technique\nsignificantly outperforms all state-of-the-art collaborative filtering\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:16:06 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Mongia", "Aanchal", ""], ["Jhamb", "Neha", ""], ["Chouzenoux", "Emilie", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.04783", "submitter": "Xavier Boix", "authors": "Stephen Casper, Xavier Boix, Vanessa D'Amario, Ling Guo, Martin\n  Schrimpf, Kasper Vinken, Gabriel Kreiman", "title": "Frivolous Units: Wider Networks Are Not Really That Wide", "comments": null, "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A remarkable characteristic of overparameterized deep neural networks (DNNs)\nis that their accuracy does not degrade when the network's width is increased.\nRecent evidence suggests that developing compressible representations is key\nfor adjusting the complexity of large networks to the learning task at hand.\nHowever, these compressible representations are poorly understood. A promising\nstrand of research inspired from biology is understanding representations at\nthe unit level as it offers a more granular and intuitive interpretation of the\nneural mechanisms. In order to better understand what facilitates increases in\nwidth without decreases in accuracy, we ask: Are there mechanisms at the unit\nlevel by which networks control their effective complexity as their width is\nincreased? If so, how do these depend on the architecture, dataset, and\ntraining parameters? We identify two distinct types of \"frivolous\" units that\nproliferate when the network's width is increased: prunable units which can be\ndropped out of the network without significant change to the output and\nredundant units whose activities can be expressed as a linear combination of\nothers. These units imply complexity constraints as the function the network\nrepresents could be expressed by a network without them. We also identify how\nthe development of these units can be influenced by architecture and a number\nof training factors. Together, these results help to explain why the accuracy\nof DNNs does not degrade when width is increased and highlight the importance\nof frivolous units toward understanding implicit regularization in DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:53:45 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 19:41:16 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 16:20:23 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 02:56:07 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 23:42:59 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Casper", "Stephen", ""], ["Boix", "Xavier", ""], ["D'Amario", "Vanessa", ""], ["Guo", "Ling", ""], ["Schrimpf", "Martin", ""], ["Vinken", "Kasper", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1912.04784", "submitter": "Taiyang Zhao", "authors": "Taiyang Zhao", "title": "A Novel Topology for End-to-end Temporal Classification and Segmentation\n  with Recurrent Neural Network", "comments": "4 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist temporal classification (CTC) has matured as an alignment free\nto sequence transduction and shows competitive for end-to-end speech\nrecognition. In the CTC topology, the blank symbol occupies more than half of\nthe state trellis, which results the spike phenomenon of the non-blank symbols.\nFor classification task, the spikes work quite well, but as to the segmentation\ntask it does not provide boundaries information. In this paper, a novel\ntopology is introduced to combine the temporal classification and segmentation\nability in one framework.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:53:59 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Zhao", "Taiyang", ""]]}, {"id": "1912.04786", "submitter": "Javier Hernandez-Ortega", "authors": "Javier Hernandez-Ortega, Roberto Daza, Aythami Morales, Julian\n  Fierrez, Javier Ortega-Garcia", "title": "edBB: Biometrics and Behavior for Assessing Remote Education", "comments": "Preprint of the paper presented to the Workshop on Artificial\n  Intelligence for Education (AI4EDU) of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a platform for student monitoring in remote education consisting\nof a collection of sensors and software that capture biometric and behavioral\ndata. We define a collection of tasks to acquire behavioral data that can be\nuseful for facing the existing challenges in automatic student monitoring\nduring remote evaluation. Additionally, we release an initial database\nincluding data from 20 different users completing these tasks with a set of\nbasic sensors: webcam, microphone, mouse, and keyboard; and also from more\nadvanced sensors: NIR camera, smartwatch, additional RGB cameras, and an EEG\nband. Information from the computer (e.g. system logs, MAC, IP, or web browsing\nhistory) is also stored. During each acquisition session each user completed\nthree different types of tasks generating data of different nature: mouse and\nkeystroke dynamics, face data, and audio data among others. The tasks have been\ndesigned with two main goals in mind: i) analyse the capacity of such biometric\nand behavioral data for detecting anomalies during remote evaluation, and ii)\nstudy the capability of these data, i.e. EEG, ECG, or NIR video, for estimating\nother information about the users such as their attention level, the presence\nof stress, or their pulse rate.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:55:11 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Hernandez-Ortega", "Javier", ""], ["Daza", "Roberto", ""], ["Morales", "Aythami", ""], ["Fierrez", "Julian", ""], ["Ortega-Garcia", "Javier", ""]]}, {"id": "1912.04792", "submitter": "Chen Liu", "authors": "Chen Liu, Mathieu Salzmann, Sabine S\\\"usstrunk", "title": "Training Provably Robust Models by Polyhedral Envelope Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training certifiable neural networks enables one to obtain models with\nrobustness guarantees against adversarial attacks. In this work, we introduce a\nframework to bound the adversary-free region in the neighborhood of the input\ndata by a polyhedral envelope, which yields finer-grained certified robustness.\nWe further introduce polyhedral envelope regularization (PER) to encourage\nlarger polyhedral envelopes and thus improve the provable robustness of the\nmodels. We demonstrate the flexibility and effectiveness of our framework on\nstandard benchmarks; it applies to networks of different architectures and\ngeneral activation functions. Compared with the state-of-the-art methods, PER\nhas very little computational overhead and better robustness guarantees without\nover-regularizing the model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 16:05:20 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 20:46:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Liu", "Chen", ""], ["Salzmann", "Mathieu", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "1912.04822", "submitter": "Jocelyn Sunseri", "authors": "Jocelyn Sunseri and David Ryan Koes", "title": "libmolgrid: GPU Accelerated Molecular Gridding for Deep Learning\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many ways to represent a molecule as input to a machine learning\nmodel and each is associated with loss and retention of certain kinds of\ninformation. In the interest of preserving three-dimensional spatial\ninformation, including bond angles and torsions, we have developed libmolgrid,\na general-purpose library for representing three-dimensional molecules using\nmultidimensional arrays. This library also provides functionality for composing\nbatches of data suited to machine learning workflows, including data\naugmentation, class balancing, and example stratification according to a\nregression variable or data subgroup, and it further supports temporal and\nspatial recurrences over that data to facilitate work with recurrent neural\nnetworks, dynamical data, and size extensive modeling. It was designed for\nseamless integration with popular deep learning frameworks, including Caffe,\nPyTorch, and Keras, providing good performance by leveraging graphical\nprocessing units (GPUs) for computationally-intensive tasks and efficient\nmemory usage through the use of memory views over preallocated buffers.\nlibmolgrid is a free and open source project that is actively supported,\nserving the growing need in the molecular modeling community for tools that\nstreamline the process of data ingestion, representation construction, and\nprincipled machine learning model development.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:03:56 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Sunseri", "Jocelyn", ""], ["Koes", "David Ryan", ""]]}, {"id": "1912.04825", "submitter": "Samuel Kim", "authors": "Samuel Kim, Peter Y. Lu, Srijon Mukherjee, Michael Gilbert, Li Jing,\n  Vladimir \\v{C}eperi\\'c, and Marin Solja\\v{c}i\\'c", "title": "Integration of Neural Network-Based Symbolic Regression in Deep Learning\n  for Scientific Discovery", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic regression is a powerful technique that can discover analytical\nequations that describe data, which can lead to explainable models and\ngeneralizability outside of the training data set. In contrast, neural networks\nhave achieved amazing levels of accuracy on image recognition and natural\nlanguage processing tasks, but are often seen as black-box models that are\ndifficult to interpret and typically extrapolate poorly. Here we use a neural\nnetwork-based architecture for symbolic regression called the Equation Learner\n(EQL) network and integrate it with other deep learning architectures such that\nthe whole system can be trained end-to-end through backpropagation. To\ndemonstrate the power of such systems, we study their performance on several\nsubstantially different tasks. First, we show that the neural network can\nperform symbolic regression and learn the form of several functions. Next, we\npresent an MNIST arithmetic task where a separate part of the neural network\nextracts the digits. Finally, we demonstrate prediction of dynamical systems\nwhere an unknown parameter is extracted through an encoder. We find that the\nEQL-based architecture can extrapolate quite well outside of the training data\nset compared to a standard neural network-based architecture, paving the way\nfor deep learning to be applied in scientific exploration and discovery.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:07:52 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 18:40:43 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kim", "Samuel", ""], ["Lu", "Peter Y.", ""], ["Mukherjee", "Srijon", ""], ["Gilbert", "Michael", ""], ["Jing", "Li", ""], ["\u010ceperi\u0107", "Vladimir", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "1912.04832", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Jonathan Jakob, Fabian Hinder, Michael Biehl,\n  Peter Tino, Barbara Hammer", "title": "Feature Relevance Determination for Ordinal Regression in the Context of\n  Feature Redundancies and Privileged Information", "comments": "Preprint accepted at Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2019.12.133", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning technologies have led to increasingly powerful\nmodels in particular in the context of big data. Yet, many application\nscenarios demand for robustly interpretable models rather than optimum model\naccuracy; as an example, this is the case if potential biomarkers or causal\nfactors should be discovered based on a set of given measurements. In this\ncontribution, we focus on feature selection paradigms, which enable us to\nuncover relevant factors of a given regularity based on a sparse model. We\nfocus on the important specific setting of linear ordinal regression, i.e.\\\ndata have to be ranked into one of a finite number of ordered categories by a\nlinear projection. Unlike previous work, we consider the case that features are\npotentially redundant, such that no unique minimum set of relevant features\nexists. We aim for an identification of all strongly and all weakly relevant\nfeatures as well as their type of relevance (strong or weak); we achieve this\ngoal by determining feature relevance bounds, which correspond to the minimum\nand maximum feature relevance, respectively, if searched over all equivalent\nmodels. In addition, we discuss how this setting enables us to substitute some\nof the features, e.g.\\ due to their semantics, and how to extend the framework\nof feature relevance intervals to the setting of privileged information, i.e.\\\npotentially relevant information is available for training purposes only, but\ncannot be used for the prediction itself.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:20:18 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["Jakob", "Jonathan", ""], ["Hinder", "Fabian", ""], ["Biehl", "Michael", ""], ["Tino", "Peter", ""], ["Hammer", "Barbara", ""]]}, {"id": "1912.04836", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Bowen Du, Hongkai Wen, Sen Wang, Andrew Markham,\n  Ivan Martinovic, Yiran Shen and Niki Trigoni", "title": "Snoopy: Sniffing Your Smartwatch Passwords via Deep Sequence Learning", "comments": "27 pages. Originally published at ACM UbiComp 2018. This version\n  corrects some errors in the original version and add the pointer to released\n  code & dataset", "journal-ref": null, "doi": "10.1145/3161196", "report-no": null, "categories": "cs.HC cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demand for smartwatches has taken off in recent years with new models which\ncan run independently from smartphones and provide more useful features,\nbecoming first-class mobile platforms. One can access online banking or even\nmake payments on a smartwatch without a paired phone. This makes smartwatches\nmore attractive and vulnerable to malicious attacks, which to date have been\nlargely overlooked. In this paper, we demonstrate Snoopy, a password extraction\nand inference system which is able to accurately infer passwords entered on\nAndroid/Apple watches within 20 attempts, just by eavesdropping on motion\nsensors. Snoopy uses a uniform framework to extract the segments of motion data\nwhen passwords are entered, and uses novel deep neural networks to infer the\nactual passwords. We evaluate the proposed Snoopy system in the real-world with\ndata from 362 participants and show that our system offers a 3-fold improvement\nin the accuracy of inferring passwords compared to the state-of-the-art,\nwithout consuming excessive energy or computational resources. We also show\nthat Snoopy is very resilient to user and device heterogeneity: it can be\ntrained on crowd-sourced motion data (e.g. via Amazon Mechanical Turk), and\nthen used to attack passwords from a new user, even if they are wearing a\ndifferent model. This paper shows that, in the wrong hands, Snoopy can\npotentially cause serious leaks of sensitive information. By raising awareness,\nwe invite the community and manufacturers to revisit the risks of continuous\nmotion sensing on smart wearable devices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:25:40 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 10:24:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Du", "Bowen", ""], ["Wen", "Hongkai", ""], ["Wang", "Sen", ""], ["Markham", "Andrew", ""], ["Martinovic", "Ivan", ""], ["Shen", "Yiran", ""], ["Trigoni", "Niki", ""]]}, {"id": "1912.04838", "submitter": "Pei Sun", "authors": "Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard,\n  Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin\n  Caine, Vijay Vasudevan, Wei Han, Jiquan Ngiam, Hang Zhao, Aleksei Timofeev,\n  Scott Ettinger, Maxim Krivokon, Amy Gao, Aditya Joshi, Sheng Zhao, Shuyang\n  Cheng, Yu Zhang, Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov", "title": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research community has increasing interest in autonomous driving\nresearch, despite the resource intensity of obtaining representative real world\ndata. Existing self-driving datasets are limited in the scale and variation of\nthe environments they capture, even though generalization within and between\noperating regions is crucial to the overall viability of the technology. In an\neffort to help align the research community's contributions with real-world\nself-driving problems, we introduce a new large scale, high quality, diverse\ndataset. Our new dataset consists of 1150 scenes that each span 20 seconds,\nconsisting of well synchronized and calibrated high quality LiDAR and camera\ndata captured across a range of urban and suburban geographies. It is 15x more\ndiverse than the largest camera+LiDAR dataset available based on our proposed\ndiversity metric. We exhaustively annotated this data with 2D (camera image)\nand 3D (LiDAR) bounding boxes, with consistent identifiers across frames.\nFinally, we provide strong baselines for 2D as well as 3D detection and\ntracking tasks. We further study the effects of dataset size and generalization\nacross geographies on 3D detection methods. Find data, code and more up-to-date\ninformation at http://www.waymo.com/open.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:28:55 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 17:51:21 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 19:21:41 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 00:42:38 GMT"}, {"version": "v5", "created": "Wed, 18 Dec 2019 01:41:49 GMT"}, {"version": "v6", "created": "Mon, 30 Mar 2020 03:22:30 GMT"}, {"version": "v7", "created": "Tue, 12 May 2020 23:28:05 GMT"}], "update_date": "2020-05-24", "authors_parsed": [["Sun", "Pei", ""], ["Kretzschmar", "Henrik", ""], ["Dotiwalla", "Xerxes", ""], ["Chouard", "Aurelien", ""], ["Patnaik", "Vijaysai", ""], ["Tsui", "Paul", ""], ["Guo", "James", ""], ["Zhou", "Yin", ""], ["Chai", "Yuning", ""], ["Caine", "Benjamin", ""], ["Vasudevan", "Vijay", ""], ["Han", "Wei", ""], ["Ngiam", "Jiquan", ""], ["Zhao", "Hang", ""], ["Timofeev", "Aleksei", ""], ["Ettinger", "Scott", ""], ["Krivokon", "Maxim", ""], ["Gao", "Amy", ""], ["Joshi", "Aditya", ""], ["Zhao", "Sheng", ""], ["Cheng", "Shuyang", ""], ["Zhang", "Yu", ""], ["Shlens", "Jonathon", ""], ["Chen", "Zhifeng", ""], ["Anguelov", "Dragomir", ""]]}, {"id": "1912.04844", "submitter": "Priyanka Khante", "authors": "Priyanka Khante and Mai Lee Chang and Domingo Martinez, Kaya de\n  Barbaro, Edison Thomaz", "title": "Quantifying the Chaos Level of Infants' Environment via Unsupervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic environments vary dramatically within the home setting. They can be\na source of comfort and tranquility or chaos that can lead to less optimal\ncognitive development in children. Research to date has only subjectively\nmeasured household chaos. In this work, we use three unsupervised machine\nlearning techniques to quantify household chaos in infants' homes. These\nunsupervised techniques include hierarchical clustering using K-Means,\nclustering using self-organizing map (SOM) and deep learning. We evaluated\nthese techniques using data from 9 participants which is a total of 197 hours.\nResults show that these techniques are promising to quantify household chaos.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:34:31 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Khante", "Priyanka", ""], ["Chang", "Mai Lee", ""], ["Martinez", "Domingo", ""], ["de Barbaro", "Kaya", ""], ["Thomaz", "Edison", ""]]}, {"id": "1912.04845", "submitter": "Stefan Oehmcke", "authors": "Vinnie Ko, Stefan Oehmcke, Fabian Gieseke", "title": "Magnitude and Uncertainty Pruning Criterion for Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have achieved dramatic improvements in recent years and\ndepict the state-of-the-art methods for many real-world tasks nowadays. One\ndrawback is, however, that many of these models are overparameterized, which\nmakes them both computationally and memory intensive. Furthermore,\noverparameterization can also lead to undesired overfitting side-effects.\nInspired by recently proposed magnitude-based pruning schemes and the Wald test\nfrom the field of statistics, we introduce a novel magnitude and uncertainty\n(M&U) pruning criterion that helps to lessen such shortcomings. One important\nadvantage of our M&U pruning criterion is that it is scale-invariant, a\nphenomenon that the magnitude-based pruning criterion suffers from. In\naddition, we present a ``pseudo bootstrap'' scheme, which can efficiently\nestimate the uncertainty of the weights by using their update information\nduring training. Our experimental evaluation, which is based on various neural\nnetwork architectures and datasets, shows that our new criterion leads to more\ncompressed models compared to models that are solely based on magnitude-based\npruning criteria, with, at the same time, less loss in predictive power.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:35:23 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Ko", "Vinnie", ""], ["Oehmcke", "Stefan", ""], ["Gieseke", "Fabian", ""]]}, {"id": "1912.04853", "submitter": "Brandon Carter", "authors": "Angie Boggust, Brandon Carter, Arvind Satyanarayan", "title": "Embedding Comparator: Visualizing Differences in Global Structure and\n  Local Neighborhoods via Small Multiples", "comments": "Equal contribution by first two authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings mapping high-dimensional discrete input to lower-dimensional\ncontinuous vector spaces have been widely adopted in machine learning\napplications as a way to capture domain semantics. Interviewing 13 embedding\nusers across disciplines, we find comparing embeddings is a key task for\ndeployment or downstream analysis but unfolds in a tedious fashion that poorly\nsupports systematic exploration. In response, we present the Embedding\nComparator, an interactive system that presents a global comparison of\nembedding spaces alongside fine-grained inspection of local neighborhoods. It\nsystematically surfaces points of comparison by computing the similarity of the\n$k$-nearest neighbors of every embedded object between a pair of spaces.\nThrough case studies, we demonstrate our system rapidly reveals insights, such\nas semantic changes following fine-tuning, language changes over time, and\ndifferences between seemingly similar models. In evaluations with 15\nparticipants, we find our system accelerates comparisons by shifting from\nlaborious manual specification to browsing and manipulating visualizations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:46:43 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 21:28:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Boggust", "Angie", ""], ["Carter", "Brandon", ""], ["Satyanarayan", "Arvind", ""]]}, {"id": "1912.04859", "submitter": "Anudit Nagar", "authors": "Anudit Nagar", "title": "Privacy-Preserving Blockchain Based Federated Learning with Differential\n  Data Sharing", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the modern world where data is becoming one of the most valuable assets,\nrobust data privacy policies rooted in the fundamental infrastructure of\nnetworks and applications are becoming an even bigger necessity to secure\nsensitive user data. In due course with the ever-evolving nature of newer\nstatistical techniques infringing user privacy, machine learning models with\nalgorithms built with respect for user privacy can offer a dynamically adaptive\nsolution to preserve user privacy against the exponentially increasing\nmultidimensional relationships that datasets create. Using these privacy aware\nML Models at the core of a Federated Learning Ecosystem can enable the entire\nnetwork to learn from data in a decentralized manner. By harnessing the\never-increasing computational power of mobile devices, increasing network\nreliability and IoT devices revolutionizing the smart devices industry, and\ncombining it with a secure and scalable, global learning session backed by a\nblockchain network with the ability to ensure on-device privacy, we allow any\nInternet enabled device to participate and contribute data to a global privacy\npreserving, data sharing network with blockchain technology even allowing the\nnetwork to reward quality work. This network architecture can also be built on\ntop of existing blockchain networks like Ethereum and Hyperledger, this lets\neven small startups build enterprise ready decentralized solutions allowing\nanyone to learn from data across different departments of a company, all the\nway to thousands of devices participating in a global synchronized learning\nnetwork.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:58:10 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Nagar", "Anudit", ""]]}, {"id": "1912.04862", "submitter": "Mamikon Gulian", "authors": "Eric C. Cyr, Mamikon A. Gulian, Ravi G. Patel, Mauro Perego, and\n  Nathaniel A. Trask", "title": "Robust Training and Initialization of Deep Neural Networks: An Adaptive\n  Basis Viewpoint", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the gap between theoretical optimal approximation rates of deep\nneural networks (DNNs) and the accuracy realized in practice, we seek to\nimprove the training of DNNs. The adoption of an adaptive basis viewpoint of\nDNNs leads to novel initializations and a hybrid least squares/gradient descent\noptimizer. We provide analysis of these techniques and illustrate via numerical\nexamples dramatic increases in accuracy and convergence rate for benchmarks\ncharacterizing scientific applications where DNNs are currently used, including\nregression problems and physics-informed neural networks for the solution of\npartial differential equations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:04:03 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Cyr", "Eric C.", ""], ["Gulian", "Mamikon A.", ""], ["Patel", "Ravi G.", ""], ["Perego", "Mauro", ""], ["Trask", "Nathaniel A.", ""]]}, {"id": "1912.04871", "submitter": "Brenden Petersen", "authors": "Brenden K. Petersen, Mikel Landajuela Larma, T. Nathan Mundhenk,\n  Claudio P. Santiago, Soo K. Kim, Joanne T. Kim", "title": "Deep symbolic regression: Recovering mathematical expressions from data\n  via risk-seeking policy gradients", "comments": "Published at International Conference on Learning Representations,\n  2021", "journal-ref": "International Conference on Learning Representations, 2021", "doi": null, "report-no": "LLNL-CONF-790457", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the underlying mathematical expressions describing a dataset is a\ncore challenge for artificial intelligence. This is the problem of\n$\\textit{symbolic regression}$. Despite recent advances in training neural\nnetworks to solve complex tasks, deep learning approaches to symbolic\nregression are underexplored. We propose a framework that leverages deep\nlearning for symbolic regression via a simple idea: use a large model to search\nthe space of small models. Specifically, we use a recurrent neural network to\nemit a distribution over tractable mathematical expressions and employ a novel\nrisk-seeking policy gradient to train the network to generate better-fitting\nexpressions. Our algorithm outperforms several baseline methods (including\nEureqa, the gold standard for symbolic regression) in its ability to exactly\nrecover symbolic expressions on a series of benchmark problems, both with and\nwithout added noise. More broadly, our contributions include a framework that\ncan be applied to optimize hierarchical, variable-length objects under a\nblack-box performance metric, with the ability to incorporate constraints in\nsitu, and a risk-seeking policy gradient formulation that optimizes for\nbest-case performance instead of expected performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:25:48 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 17:16:24 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 04:00:32 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 22:29:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Petersen", "Brenden K.", ""], ["Larma", "Mikel Landajuela", ""], ["Mundhenk", "T. Nathan", ""], ["Santiago", "Claudio P.", ""], ["Kim", "Soo K.", ""], ["Kim", "Joanne T.", ""]]}, {"id": "1912.04884", "submitter": "Benjie Wang", "authors": "Benjie Wang, Stefan Webb, Tom Rainforth", "title": "Statistically Robust Neural Network Classification", "comments": "minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been much interest in quantifying the robustness of neural\nnetwork classifiers through adversarial risk metrics. However, for problems\nwhere test-time corruptions occur in a probabilistic manner, rather than being\ngenerated by an explicit adversary, adversarial metrics typically do not\nprovide an accurate or reliable indicator of robustness. To address this, we\nintroduce a statistically robust risk (SRR) framework which measures robustness\nin expectation over both network inputs and a corruption distribution. Unlike\nmany adversarial risk metrics, which typically require separate applications on\na point-by-point basis, the SRR can easily be directly estimated for an entire\nnetwork and used as a training objective in a stochastic gradient scheme.\nFurthermore, we show both theoretically and empirically that it can scale to\nhigher-dimensional networks by providing superior generalization performance\ncompared with comparable adversarial risks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:47:35 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 01:30:46 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wang", "Benjie", ""], ["Webb", "Stefan", ""], ["Rainforth", "Tom", ""]]}, {"id": "1912.04896", "submitter": "Damith Senanayake PhD", "authors": "Damith Senanayake, Wei Wang, Shalin H. Naik, Saman Halgamuge", "title": "Self Organizing Nebulous Growths for Robust and Incremental Data\n  Visualization", "comments": "in IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3023941.", "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-parametric dimensionality reduction techniques, such as t-SNE and UMAP,\nare proficient in providing visualizations for datasets of fixed sizes.\nHowever, they cannot incrementally map and insert new data points into an\nalready provided data visualization. We present Self-Organizing Nebulous\nGrowths (SONG), a parametric nonlinear dimensionality reduction technique that\nsupports incremental data visualization, i.e., incremental addition of new data\nwhile preserving the structure of the existing visualization. In addition, SONG\nis capable of handling new data increments, no matter whether they are similar\nor heterogeneous to the already observed data distribution. We test SONG on a\nvariety of real and simulated datasets. The results show that SONG is superior\nto Parametric t-SNE, t-SNE and UMAP in incremental data visualization.\nSpecifically, for heterogeneous increments, SONG improves over Parametric t-SNE\nby 14.98 % on the Fashion MNIST dataset and 49.73% on the MNIST dataset\nregarding the cluster quality measured by the Adjusted Mutual Information\nscores. On similar or homogeneous increments, the improvements are 8.36% and\n42.26% respectively. Furthermore, even when the above datasets are presented\nall at once, SONG performs better or comparable to UMAP, and superior to t-SNE.\nWe also demonstrate that the algorithmic foundations of SONG render it more\ntolerant to noise compared to UMAP and t-SNE, thus providing greater utility\nfor data with high variance, high mixing of clusters, or noise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 22:11:51 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 21:59:58 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 01:18:23 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Senanayake", "Damith", ""], ["Wang", "Wei", ""], ["Naik", "Shalin H.", ""], ["Halgamuge", "Saman", ""]]}, {"id": "1912.04958", "submitter": "Samuli Laine", "authors": "Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko\n  Lehtinen, Timo Aila", "title": "Analyzing and Improving the Image Quality of StyleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The style-based GAN architecture (StyleGAN) yields state-of-the-art results\nin data-driven unconditional generative image modeling. We expose and analyze\nseveral of its characteristic artifacts, and propose changes in both model\narchitecture and training methods to address them. In particular, we redesign\nthe generator normalization, revisit progressive growing, and regularize the\ngenerator to encourage good conditioning in the mapping from latent codes to\nimages. In addition to improving image quality, this path length regularizer\nyields the additional benefit that the generator becomes significantly easier\nto invert. This makes it possible to reliably attribute a generated image to a\nparticular network. We furthermore visualize how well the generator utilizes\nits output resolution, and identify a capacity problem, motivating us to train\nlarger models for additional quality improvements. Overall, our improved model\nredefines the state of the art in unconditional image modeling, both in terms\nof existing distribution quality metrics as well as perceived image quality.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 11:44:01 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 17:21:07 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Karras", "Tero", ""], ["Laine", "Samuli", ""], ["Aittala", "Miika", ""], ["Hellsten", "Janne", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "1912.04964", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "Before we can find a model, we must forget about perfection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With Reinforcement Learning we assume that a model of the world does exist.\nWe assume furthermore that the model in question is perfect (i.e. it describes\nthe world completely and unambiguously). This article will demonstrate that it\ndoes not make sense to search for the perfect model because this model is too\ncomplicated and practically impossible to find. We will show that we should\nabandon the pursuit of perfection and pursue Event-Driven (ED) models instead.\nThese models are generalization of Markov Decision Process (MDP) models. This\ngeneralization is essential because nothing can be found without it. Rather\nthan a single MDP, we will aim to find a raft of neat simple ED models each one\ndescribing a simple dependency or property. In other words, we will replace the\nsearch for a singular and complex perfect model with a search for a large\nnumber of simple models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:20:34 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1912.04968", "submitter": "David Ahmedt-Aristizabal", "authors": "David Ahmedt-Aristizabal, Tharindu Fernando, Simon Denman, Lars\n  Petersson, Matthew J. Aburn, Clinton Fookes", "title": "Neural Memory Networks for Seizure Type Classification", "comments": "Proceedings of the IEEE International Conference of Engineering in\n  Medicine and Biology Society. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of seizure type is a key step in the clinical process for\nevaluating an individual who presents with seizures. It determines the course\nof clinical diagnosis and treatment, and its impact stretches beyond the\nclinical domain to epilepsy research and the development of novel therapies.\nAutomated identification of seizure type may facilitate understanding of the\ndisease, and seizure detection and prediction has been the focus of recent\nresearch that has sought to exploit the benefits of machine learning and deep\nlearning architectures. Nevertheless, there is not yet a definitive solution\nfor automating the classification of seizure type, a task that must currently\nbe performed by an expert epileptologist. Inspired by recent advances in neural\nmemory networks (NMNs), we introduce a novel approach for the classification of\nseizure type using electrophysiological data. We first explore the performance\nof traditional deep learning techniques which use convolutional and recurrent\nneural networks, and enhance these architectures by using external memory\nmodules with trainable neural plasticity. We show that our model achieves a\nstate-of-the-art weighted F1 score of 0.945 for seizure type classification on\nthe TUH EEG Seizure Corpus with the IBM TUSZ preprocessed data. This work\nhighlights the potential of neural memory networks to support the field of\nepilepsy research, along with biomedical research and signal analysis more\nbroadly.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:27:40 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 02:04:44 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ahmedt-Aristizabal", "David", ""], ["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Petersson", "Lars", ""], ["Aburn", "Matthew J.", ""], ["Fookes", "Clinton", ""]]}, {"id": "1912.04973", "submitter": "Debasmit Das", "authors": "Debasmit Das and C. S. George Lee", "title": "A Two-Stage Approach to Few-Shot Learning for Image Recognition", "comments": "To Appear in IEEE Transactions on Image Processing", "journal-ref": null, "doi": "10.1109/TIP.2019.2959254", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a multi-layer neural network structure for few-shot image\nrecognition of novel categories. The proposed multi-layer neural network\narchitecture encodes transferable knowledge extracted from a large annotated\ndataset of base categories. This architecture is then applied to novel\ncategories containing only a few samples. The transfer of knowledge is carried\nout at the feature-extraction and the classification levels distributed across\nthe two training stages. In the first-training stage, we introduce the relative\nfeature to capture the structure of the data as well as obtain a\nlow-dimensional discriminative space. Secondly, we account for the variable\nvariance of different categories by using a network to predict the variance of\neach class. Classification is then performed by computing the Mahalanobis\ndistance to the mean-class representation in contrast to previous approaches\nthat used the Euclidean distance. In the second-training stage, a\ncategory-agnostic mapping is learned from the mean-sample representation to its\ncorresponding class-prototype representation. This is because the mean-sample\nrepresentation may not accurately represent the novel category prototype.\nFinally, we evaluate the proposed network structure on four standard few-shot\nimage recognition datasets, where our proposed few-shot learning system\nproduces competitive performance compared to previous work. We also extensively\nstudied and analyzed the contribution of each component of our proposed\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:45:35 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "1912.04977", "submitter": "Peter Kairouz", "authors": "Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur\\'elien Bellet,\n  Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham\n  Cormode, Rachel Cummings, Rafael G.L. D'Oliveira, Hubert Eichner, Salim El\n  Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri\\`a Gasc\\'on, Badih\n  Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie\n  He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi,\n  Gauri Joshi, Mikhail Khodak, Jakub Kone\\v{c}n\\'y, Aleksandra Korolova,\n  Farinaz Koushanfar, Sanmi Koyejo, Tancr\\`ede Lepoint, Yang Liu, Prateek\n  Mittal, Mehryar Mohri, Richard Nock, Ayfer \\\"Ozg\\\"ur, Rasmus Pagh, Mariana\n  Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song,\n  Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram\\`er,\n  Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu,\n  Han Yu, Sen Zhao", "title": "Advances and Open Problems in Federated Learning", "comments": "Published in Foundations and Trends in Machine Learning Vol 4 Issue\n  1. See: https://www.nowpublishers.com/article/Details/MAL-083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a machine learning setting where many clients\n(e.g. mobile devices or whole organizations) collaboratively train a model\nunder the orchestration of a central server (e.g. service provider), while\nkeeping the training data decentralized. FL embodies the principles of focused\ndata collection and minimization, and can mitigate many of the systemic privacy\nrisks and costs resulting from traditional, centralized machine learning and\ndata science approaches. Motivated by the explosive growth in FL research, this\npaper discusses recent advances and presents an extensive collection of open\nproblems and challenges.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:55:41 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 06:20:24 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 03:03:49 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Kairouz", "Peter", ""], ["McMahan", "H. Brendan", ""], ["Avent", "Brendan", ""], ["Bellet", "Aur\u00e9lien", ""], ["Bennis", "Mehdi", ""], ["Bhagoji", "Arjun Nitin", ""], ["Bonawitz", "Kallista", ""], ["Charles", "Zachary", ""], ["Cormode", "Graham", ""], ["Cummings", "Rachel", ""], ["D'Oliveira", "Rafael G. L.", ""], ["Eichner", "Hubert", ""], ["Rouayheb", "Salim El", ""], ["Evans", "David", ""], ["Gardner", "Josh", ""], ["Garrett", "Zachary", ""], ["Gasc\u00f3n", "Adri\u00e0", ""], ["Ghazi", "Badih", ""], ["Gibbons", "Phillip B.", ""], ["Gruteser", "Marco", ""], ["Harchaoui", "Zaid", ""], ["He", "Chaoyang", ""], ["He", "Lie", ""], ["Huo", "Zhouyuan", ""], ["Hutchinson", "Ben", ""], ["Hsu", "Justin", ""], ["Jaggi", "Martin", ""], ["Javidi", "Tara", ""], ["Joshi", "Gauri", ""], ["Khodak", "Mikhail", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Korolova", "Aleksandra", ""], ["Koushanfar", "Farinaz", ""], ["Koyejo", "Sanmi", ""], ["Lepoint", "Tancr\u00e8de", ""], ["Liu", "Yang", ""], ["Mittal", "Prateek", ""], ["Mohri", "Mehryar", ""], ["Nock", "Richard", ""], ["\u00d6zg\u00fcr", "Ayfer", ""], ["Pagh", "Rasmus", ""], ["Raykova", "Mariana", ""], ["Qi", "Hang", ""], ["Ramage", "Daniel", ""], ["Raskar", "Ramesh", ""], ["Song", "Dawn", ""], ["Song", "Weikang", ""], ["Stich", "Sebastian U.", ""], ["Sun", "Ziteng", ""], ["Suresh", "Ananda Theertha", ""], ["Tram\u00e8r", "Florian", ""], ["Vepakomma", "Praneeth", ""], ["Wang", "Jianyu", ""], ["Xiong", "Li", ""], ["Xu", "Zheng", ""], ["Yang", "Qiang", ""], ["Yu", "Felix X.", ""], ["Yu", "Han", ""], ["Zhao", "Sen", ""]]}, {"id": "1912.04981", "submitter": "Tobias Uelwer", "authors": "Tobias Uelwer, Alexander Oberstra{\\ss}, Stefan Harmeling", "title": "Phase Retrieval Using Conditional Generative Adversarial Networks", "comments": "Accepted at the 25th International Conference on Pattern Recognition\n  2020 (ICPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the application of conditional generative\nadversarial networks to solve various phase retrieval problems. We show that\nincluding knowledge of the measurement process at training time leads to an\noptimization at test time that is more robust to initialization than existing\napproaches involving generative models. In addition, conditioning the generator\nnetwork on the measurements enables us to achieve much more detailed results.\nWe empirically demonstrate that these advantages provide meaningful solutions\nto the Fourier and the compressive phase retrieval problem and that our method\noutperforms well-established projection-based methods as well as existing\nmethods that are based on neural networks. Like other deep learning methods,\nour approach is very robust to noise and can therefore be very useful for\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 21:03:59 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 07:37:49 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Uelwer", "Tobias", ""], ["Oberstra\u00df", "Alexander", ""], ["Harmeling", "Stefan", ""]]}, {"id": "1912.04994", "submitter": "Changlong Wu", "authors": "Changlong Wu, Narayana Prasad Santhanam", "title": "Almost Uniform Sampling From Neural Networks", "comments": "Submitted to 54th Annual Conference on Information Sciences and\n  Systems (CISS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a length $n$ sample from $\\mathbb{R}^d$ and a neural network with a\nfixed architecture with $W$ weights, $k$ neurons, linear threshold activation\nfunctions, and binary outputs on each neuron, we study the problem of uniformly\nsampling from all possible labelings on the sample corresponding to different\nchoices of weights. We provide an algorithm that runs in time polynomial both\nin $n$ and $W$ such that any labeling appears with probability at least\n$\\left(\\frac{W}{2ekn}\\right)^W$ for $W<n$. For a single neuron, we also provide\na random walk based algorithm that samples exactly uniformly.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 21:40:34 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wu", "Changlong", ""], ["Santhanam", "Narayana Prasad", ""]]}, {"id": "1912.05007", "submitter": "Alexander Ziller", "authors": "Alexander Ziller, Julius Hansjakob, Vitalii Rusinov, Daniel Z\\\"ugner,\n  Peter Vogel, Stephan G\\\"unnemann", "title": "Oktoberfest Food Dataset", "comments": "Dataset publication of Oktoberfest Food Dataset. 4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We release a realistic, diverse, and challenging dataset for object detection\non images. The data was recorded at a beer tent in Germany and consists of 15\ndifferent categories of food and drink items. We created more than 2,500 object\nannotations by hand for 1,110 images captured by a video camera above the\ncheckout. We further make available the remaining 600GB of (unlabeled) data\ncontaining days of footage. Additionally, we provide our trained models as a\nbenchmark. Possible applications include automated checkout systems which could\nsignificantly speed up the process.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 09:28:59 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ziller", "Alexander", ""], ["Hansjakob", "Julius", ""], ["Rusinov", "Vitalii", ""], ["Z\u00fcgner", "Daniel", ""], ["Vogel", "Peter", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "1912.05014", "submitter": "Sayan Nag", "authors": "Mayukh Bhattacharyya, Sayan Nag", "title": "Hybrid Style Siamese Network: Incorporating style loss in complementary\n  apparels retrieval", "comments": "Paper Accepted in the Third Workshop on Computer Vision for Fashion,\n  Art and Design, CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image Retrieval grows to be an integral part of fashion e-commerce ecosystem\nas it keeps expanding in multitudes. Other than the retrieval of visually\nsimilar items, the retrieval of visually compatible or complementary items is\nalso an important aspect of it. Normal Siamese Networks tend to work well on\ncomplementary items retrieval. But it fails to identify low level style\nfeatures which make items compatible in human eyes. These low level style\nfeatures are captured to a large extent in techniques used in neural style\ntransfer. This paper proposes a mechanism of utilising those methods in this\nretrieval task and capturing the low level style features through a hybrid\nsiamese network coupled with a hybrid loss. The experimental results indicate\nthat the proposed method outperforms traditional siamese networks in retrieval\ntasks for complementary items.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 05:56:50 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 23:48:47 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bhattacharyya", "Mayukh", ""], ["Nag", "Sayan", ""]]}, {"id": "1912.05019", "submitter": "Emmanuel Iarussi", "authors": "Pablo Navarro, Jos\\'e Ignacio Orlando, Claudio Delrieux, and Emmanuel\n  Iarussi", "title": "SketchZooms: Deep multi-view descriptors for matching line drawings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding point-wise correspondences between images is a long-standing problem\nin image analysis. This becomes particularly challenging for sketch images, due\nto the varying nature of human drawing style, projection distortions and\nviewport changes. In this paper we present the first attempt to obtain a\nlearned descriptor for dense registration in line drawings. Based on recent\ndeep learning techniques for corresponding photographs, we designed descriptors\nto locally match image pairs where the object of interest belongs to the same\nsemantic category, yet still differ drastically in shape, form, and projection\nangle. To this end, we have specifically crafted a data set of synthetic\nsketches using non-photorealistic rendering over a large collection of\npart-based registered 3D models. After training, a neural network generates\ndescriptors for every pixel in an input image, which are shown to generalize\ncorrectly in unseen sketches hand-drawn by humans. We evaluate our method\nagainst a baseline of correspondences data collected from expert designers, in\naddition to comparisons with other descriptors that have been proven effective\nin sketches. Code, data and further resources will be publicly released by the\ntime of publication.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 14:31:33 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 19:50:29 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Navarro", "Pablo", ""], ["Orlando", "Jos\u00e9 Ignacio", ""], ["Delrieux", "Claudio", ""], ["Iarussi", "Emmanuel", ""]]}, {"id": "1912.05021", "submitter": "Xiao Yang", "authors": "Xiao Yang, Fangyun Wei, Hongyang Zhang, Jun Zhu", "title": "Design and Interpretation of Universal Adversarial Patches in Face\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider universal adversarial patches for faces -- small visual elements\nwhose addition to a face image reliably destroys the performance of face\ndetectors. Unlike previous work that mostly focused on the algorithmic design\nof adversarial examples in terms of improving the success rate as an attacker,\nin this work we show an interpretation of such patches that can prevent the\nstate-of-the-art face detectors from detecting the real faces. We investigate a\nphenomenon: patches designed to suppress real face detection appear face-like.\nThis phenomenon holds generally across different initialization, locations,\nscales of patches, backbones, and state-of-the-art face detection frameworks.\nWe propose new optimization-based approaches to automatic design of universal\nadversarial patches for varying goals of the attack, including scenarios in\nwhich true positives are suppressed without introducing false positives. Our\nproposed algorithms perform well on real-world datasets, deceiving\nstate-of-the-art face detectors in terms of multiple precision/recall metrics\nand transferability.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 12:43:56 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:00:41 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 09:37:37 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Yang", "Xiao", ""], ["Wei", "Fangyun", ""], ["Zhang", "Hongyang", ""], ["Zhu", "Jun", ""]]}, {"id": "1912.05026", "submitter": "Stefan Oehmcke", "authors": "Stefan Oehmcke, Christoffer Thrys{\\o}e, Andreas Borgstad, Marcos\n  Antonio Vaz Salles, Martin Brandt, Fabian Gieseke", "title": "Detecting Hardly Visible Roads in Low-Resolution Satellite Time Series\n  Data", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive amounts of satellite data have been gathered over time, holding the\npotential to unveil a spatiotemporal chronicle of the surface of Earth. These\ndata allow scientists to investigate various important issues, such as land use\nchanges, on a global scale. However, not all land-use phenomena are equally\nvisible on satellite imagery. In particular, the creation of an inventory of\nthe planet's road infrastructure remains a challenge, despite being crucial to\nanalyze urbanization patterns and their impact. Towards this end, this work\nadvances data-driven approaches for the automatic identification of roads based\non open satellite data. Given the typical resolutions of these historical\nsatellite data, we observe that there is inherent variation in the visibility\nof different road types. Based on this observation, we propose two deep\nlearning frameworks that extend state-of-the-art deep learning methods by\nformalizing road detection as an ordinal classification task. In contrast to\nrelated schemes, one of the two models also resorts to satellite time series\ndata that are potentially affected by missing data and cloud occlusion. Taking\nthese time series data into account eliminates the need to manually curate\ndatasets of high-quality image tiles, substantially simplifying the application\nof such models on a global scale. We evaluate our approaches on a dataset that\nis based on Sentinel~2 satellite imagery and OpenStreetMap vector data. Our\nresults indicate that the proposed models can successfully identify large and\nmedium-sized roads. We also discuss opportunities and challenges related to the\ndetection of roads and other infrastructure on a global scale.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:40:43 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Oehmcke", "Stefan", ""], ["Thrys\u00f8e", "Christoffer", ""], ["Borgstad", "Andreas", ""], ["Salles", "Marcos Antonio Vaz", ""], ["Brandt", "Martin", ""], ["Gieseke", "Fabian", ""]]}, {"id": "1912.05027", "submitter": "Xianzhi Du", "authors": "Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Golnaz Ghiasi, Mingxing Tan,\n  Yin Cui, Quoc V. Le, Xiaodan Song", "title": "SpineNet: Learning Scale-Permuted Backbone for Recognition and\n  Localization", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks typically encode an input image into a series\nof intermediate features with decreasing resolutions. While this structure is\nsuited to classification tasks, it does not perform well for tasks requiring\nsimultaneous recognition and localization (e.g., object detection). The\nencoder-decoder architectures are proposed to resolve this by applying a\ndecoder network onto a backbone model designed for classification tasks. In\nthis paper, we argue encoder-decoder architecture is ineffective in generating\nstrong multi-scale features because of the scale-decreased backbone. We propose\nSpineNet, a backbone with scale-permuted intermediate features and cross-scale\nconnections that is learned on an object detection task by Neural Architecture\nSearch. Using similar building blocks, SpineNet models outperform ResNet-FPN\nmodels by ~3% AP at various scales while using 10-20% fewer FLOPs. In\nparticular, SpineNet-190 achieves 52.5% AP with a MaskR-CNN detector and\nachieves 52.1% AP with a RetinaNet detector on COCO for a single model without\ntest-time augmentation, significantly outperforms prior art of detectors.\nSpineNet can transfer to classification tasks, achieving 5% top-1 accuracy\nimprovement on a challenging iNaturalist fine-grained dataset. Code is at:\nhttps://github.com/tensorflow/tpu/tree/master/models/official/detection.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:13:42 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 18:24:21 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 16:37:15 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Du", "Xianzhi", ""], ["Lin", "Tsung-Yi", ""], ["Jin", "Pengchong", ""], ["Ghiasi", "Golnaz", ""], ["Tan", "Mingxing", ""], ["Cui", "Yin", ""], ["Le", "Quoc V.", ""], ["Song", "Xiaodan", ""]]}, {"id": "1912.05028", "submitter": "Gunjan Aggarwal", "authors": "Gunjan Aggarwal, Abhishek Sinha", "title": "cFineGAN: Unsupervised multi-conditional fine-grained image generation", "comments": "Accepted at NeurIPS Workshop on Machine Learning for Creativity and\n  Design 3.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised multi-conditional image generation pipeline:\ncFineGAN, that can generate an image conditioned on two input images such that\nthe generated image preserves the texture of one and the shape of the other\ninput. To achieve this goal, we extend upon the recently proposed work of\nFineGAN \\citep{singh2018finegan} and make use of standard as well as\nshape-biased pre-trained ImageNet models. We demonstrate both qualitatively as\nwell as quantitatively the benefit of using the shape-biased network. We\npresent our image generation result across three benchmark datasets-\nCUB-200-2011, Stanford Dogs and UT Zappos50k.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 04:16:08 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Aggarwal", "Gunjan", ""], ["Sinha", "Abhishek", ""]]}, {"id": "1912.05029", "submitter": "Luca Erculiani Mr", "authors": "Luca Erculiani and Fausto Giunchiglia and Andrea Passerini", "title": "Continual egocentric object recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework capable of tackilng the problem of continual object\nrecognition in a setting which resembles that under whichhumans see and learn.\nThis setting has a set of unique characteristics:it assumes an egocentric\npoint-of-view bound to the needs of a singleperson, which implies a relatively\nlow diversity of data and a coldstart with no data; it requires to operate in\nan open world, where newobjects can be encounteredat any time; supervision is\nscarce and hasto be solicited to the user, and completelyunsupervised\nrecognitionof new objects should be possible. Note that this setting differs\nfromthe one addressed in the open world recognition literature, where\nsupervised feedback is always requested to be able to incorporate newobjects.\nWe propose a first solution to this problem in the form ofa memory-based\nincremental framework that is capable of storinginformation of each and any\nobject it encounters, while using the supervision of the user to learn to\ndiscriminate between known and unknown objects. Our approach is based on four\nmain features: the useof time and space persistence (i.e., the appearance of\nobjects changesrelatively slowly), the use of similarity as the main driving\nprinciplefor object recognition and novelty detection, the progressive\nintroduction of new objects in a developmental fashion and the\nselectiveelicitation of user feedback in an online active learning fashion.\nExperimental results show the feasibility of open world, generic\nobjectrecognition, the ability to recognize, memorize and re-identify\nnewobjects even in complete absence of user supervision, and the utilityof\npersistence and incrementality in boosting performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 12:10:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 15:22:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Erculiani", "Luca", ""], ["Giunchiglia", "Fausto", ""], ["Passerini", "Andrea", ""]]}, {"id": "1912.05031", "submitter": "Abraham Nunes", "authors": "Abraham Nunes, Martin Alda, Timothy Bardouille, and Thomas Trappenberg", "title": "Representational R\\'enyi heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A discrete system's heterogeneity is measured by the R\\'enyi heterogeneity\nfamily of indices (also known as Hill numbers or Hannah--Kay indices), whose\nunits are {the numbers equivalent}. Unfortunately, numbers equivalent\nheterogeneity measures for non-categorical data require {a priori} (A)\ncategorical partitioning and (B) pairwise distance measurement on the\nobservable data space, thereby precluding application to problems with\nill-defined categories or where semantically relevant features must be learned\nas abstractions from some data. We thus introduce representational R\\'enyi\nheterogeneity (RRH), which transforms an observable domain onto a latent space\nupon which the R\\'enyi heterogeneity is both tractable and semantically\nrelevant. This method requires neither {a priori} binning nor definition of a\ndistance function on the observable space. We show that RRH can generalize\nexisting biodiversity and economic equality indices. Compared with existing\nindices on a beta-mixture distribution, we show that RRH responds more\nappropriately to changes in mixture component separation and weighting.\nFinally, we demonstrate the measurement of RRH in a set of natural images, with\nrespect to abstract representations learned by a deep neural network. The RRH\napproach will further enable heterogeneity measurement in disciplines whose\ndata do not easily conform to the assumptions of existing indices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:22:54 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 16:42:12 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 15:09:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nunes", "Abraham", ""], ["Alda", "Martin", ""], ["Bardouille", "Timothy", ""], ["Trappenberg", "Thomas", ""]]}, {"id": "1912.05032", "submitter": "Ilya Kostrikov", "authors": "Ilya Kostrikov, Ofir Nachum, Jonathan Tompson", "title": "Imitation Learning via Off-Policy Distribution Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When performing imitation learning from expert demonstrations, distribution\nmatching is a popular approach, in which one alternates between estimating\ndistribution ratios and then using these ratios as rewards in a standard\nreinforcement learning (RL) algorithm. Traditionally, estimation of the\ndistribution ratio requires on-policy data, which has caused previous work to\neither be exorbitantly data-inefficient or alter the original objective in a\nmanner that can drastically change its optimum. In this work, we show how the\noriginal distribution ratio estimation objective may be transformed in a\nprincipled manner to yield a completely off-policy objective. In addition to\nthe data-efficiency that this provides, we are able to show that this objective\nalso renders the use of a separate RL optimization unnecessary.Rather, an\nimitation policy may be learned directly from this objective without the use of\nexplicit rewards. We call the resulting algorithm ValueDICE and evaluate it on\na suite of popular imitation learning benchmarks, finding that it can achieve\nstate-of-the-art sample efficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:31:09 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Kostrikov", "Ilya", ""], ["Nachum", "Ofir", ""], ["Tompson", "Jonathan", ""]]}, {"id": "1912.05034", "submitter": "Joonas P\\\"a\\\"akk\\\"onen", "authors": "Joonas P\\\"a\\\"akk\\\"onen", "title": "Fenton-Wilkinson Order Statistics and German Tanks: A Case Study of an\n  Orienteering Relay Race", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal regression falls between discrete-valued classification and\ncontinuous-valued regression. Ordinal target variables can be associated with\nranked random variables. These random variables are known as order statistics\nand they are closely related to ordinal regression. However, the challenge of\nusing order statistics for ordinal regression prediction is finding a suitable\nparent distribution. In this work, we provide a case study of a real-world\norienteering relay race by viewing it as a random process. For this process, we\nshow that accurate order statistical ordinal regression predictions of final\nteam rankings, or places, can be obtained by assuming a lognormal distribution\nof individual leg times. Moreover, we apply Fenton-Wilkinson approximations to\nintermediate changeover times alongside an estimator for the total number of\nteams as in the notorious German tank problem. The purpose of this work is, in\npart, to spark interest in studying the applicability of order statistics in\nordinal regression problems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:37:55 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["P\u00e4\u00e4kk\u00f6nen", "Joonas", ""]]}, {"id": "1912.05035", "submitter": "Luisa Polania", "authors": "Maria Ximena Bastidas Rodriguez, Adrien Gruson, Luisa F. Polania, Shin\n  Fujieda, Flavio Prieto Ortiz, Kohei Takayama, Toshiya Hachisuka", "title": "Deep Adaptive Wavelet Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though convolutional neural networks have become the method of choice in\nmany fields of computer vision, they still lack interpretability and are\nusually designed manually in a cumbersome trial-and-error process. This paper\naims at overcoming those limitations by proposing a deep neural network, which\nis designed in a systematic fashion and is interpretable, by integrating\nmultiresolution analysis at the core of the deep neural network design. By\nusing the lifting scheme, it is possible to generate a wavelet representation\nand design a network capable of learning wavelet coefficients in an end-to-end\nform. Compared to state-of-the-art architectures, the proposed model requires\nless hyper-parameter tuning and achieves competitive accuracy in image\nclassification tasks\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 22:43:16 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Rodriguez", "Maria Ximena Bastidas", ""], ["Gruson", "Adrien", ""], ["Polania", "Luisa F.", ""], ["Fujieda", "Shin", ""], ["Ortiz", "Flavio Prieto", ""], ["Takayama", "Kohei", ""], ["Hachisuka", "Toshiya", ""]]}, {"id": "1912.05045", "submitter": "James Bagrow", "authors": "Abigail Hotaling and James P. Bagrow", "title": "Efficient crowdsourcing of crowd-generated microtasks", "comments": "12 pages, 5 figures", "journal-ref": "PLoS ONE 15(12): e0244245, 2020", "doi": "10.1371/journal.pone.0244245", "report-no": null, "categories": "cs.HC cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing members of the crowd to propose novel microtasks for one another is\nan effective way to combine the efficiencies of traditional microtask work with\nthe inventiveness and hypothesis generation potential of human workers.\nHowever, microtask proposal leads to a growing set of tasks that may overwhelm\nlimited crowdsourcer resources. Crowdsourcers can employ methods to utilize\ntheir resources efficiently, but algorithmic approaches to efficient\ncrowdsourcing generally require a fixed task set of known size. In this paper,\nwe introduce *cost forecasting* as a means for a crowdsourcer to use efficient\ncrowdsourcing algorithms with a growing set of microtasks. Cost forecasting\nallows the crowdsourcer to decide between eliciting new tasks from the crowd or\nreceiving responses to existing tasks based on whether or not new tasks will\ncost less to complete than existing tasks, efficiently balancing resources as\ncrowdsourcing occurs. Experiments with real and synthetic crowdsourcing data\nshow that cost forecasting leads to improved accuracy. Accuracy and efficiency\ngains for crowd-generated microtasks hold the promise to further leverage the\ncreativity and wisdom of the crowd, with applications such as generating more\ninformative and diverse training data for machine learning applications and\nimproving the performance of user-generated content and question-answering\nplatforms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 23:23:54 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 19:24:17 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hotaling", "Abigail", ""], ["Bagrow", "James P.", ""]]}, {"id": "1912.05066", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Ronghuo Zheng, Yuezhang Li, Katia Sycara", "title": "Event Outcome Prediction using Sentiment Analysis and Crowd Wisdom in\n  Microblog Feeds", "comments": "9 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis of microblog feeds has attracted considerable interest in\nrecent times. Most of the current work focuses on tweet sentiment\nclassification. But not much work has been done to explore how reliable the\nopinions of the mass (crowd wisdom) in social network microblogs such as\ntwitter are in predicting outcomes of certain events such as election debates.\nIn this work, we investigate whether crowd wisdom is useful in predicting such\noutcomes and whether their opinions are influenced by the experts in the field.\nWe work in the domain of multi-label classification to perform sentiment\nclassification of tweets and obtain the opinion of the crowd. This learnt\nsentiment is then used to predict outcomes of events such as: US Presidential\nDebate winners, Grammy Award winners, Super Bowl Winners. We find that in most\nof the cases, the wisdom of the crowd does indeed match with that of the\nexperts, and in cases where they don't (particularly in the case of debates),\nwe see that the crowd's opinion is actually influenced by that of the experts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 00:30:24 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Zheng", "Ronghuo", ""], ["Li", "Yuezhang", ""], ["Sycara", "Katia", ""]]}, {"id": "1912.05067", "submitter": "Sanja \\v{S}\\'cepanovi\\'c", "authors": "Sanja \\v{S}\\'cepanovi\\'c, Oleg Antropov, Pekka Laurila, Yrj\\\"o Rauste,\n  Vladimir Ignatenko, Jaan Praks", "title": "Wide-Area Land Cover Mapping with Sentinel-1 Imagery using Deep Learning\n  Semantic Segmentation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land cover mapping is essential to monitoring the environment and\nunderstanding the effects of human activities on it. The automatic approaches\nto land cover mapping (i.e., image segmentation) mostly used traditional\nmachine learning that requires heuristic feature design. On natural images,\ndeep learning has outperformed traditional machine learning approaches for\nimage segmentation. On remote sensing images, recent studies demonstrate\nsuccessful applications of specific deep learning models to small-scale land\ncover mapping tasks (e.g., to classify wetland complexes). However, it is not\nreadily clear which of the existing models are the best candidates for which\nremote sensing task. In this study, we answer that question for mapping the\nfundamental land cover classes using satellite radar data. We took Sentinel-1\nC-band SAR images available at no cost to users as representative data. CORINE\nland cover map was used as a reference, and the models were trained to\ndistinguish between the 5 major CORINE classes. We selected seven among the\nstate-of-the-art semantic segmentation models so that they cover a diverse set\nof approaches: U-Net, DeepLabV3+, PSPNet, BiSeNet, SegNet, FC-DenseNet, and\nFRRN-B. The models were pre-trained on the ImageNet dataset and further\nfine-tuned in this study. All the models demonstrated solid performance with\noverall accuracy between 87.9% and 93.1%, and with good to a very good\nagreement (kappa statistic between 0.75 and 0.86). The two best models were\nFC-DenseNet and SegNet, with the latter having a much smaller inference time.\nOverall, our results indicate that the semantic segmentation models are\nsuitable for efficient wide-area mapping using satellite SAR imagery and also\nprovide baseline accuracy against which the newly proposed models should be\nevaluated.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 00:38:37 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:33:54 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 21:32:17 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 14:05:35 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["\u0160\u0107epanovi\u0107", "Sanja", ""], ["Antropov", "Oleg", ""], ["Laurila", "Pekka", ""], ["Rauste", "Yrj\u00f6", ""], ["Ignatenko", "Vladimir", ""], ["Praks", "Jaan", ""]]}, {"id": "1912.05074", "submitter": "Zongwei Zhou", "authors": "Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, Jianming\n  Liang", "title": "UNet++: Redesigning Skip Connections to Exploit Multiscale Features in\n  Image Segmentation", "comments": "Journal of IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art models for medical image segmentation are variants of\nU-Net and fully convolutional networks (FCN). Despite their success, these\nmodels have two limitations: (1) their optimal depth is apriori unknown,\nrequiring extensive architecture search or inefficient ensemble of models of\nvarying depths; and (2) their skip connections impose an unnecessarily\nrestrictive fusion scheme, forcing aggregation only at the same-scale feature\nmaps of the encoder and decoder sub-networks. To overcome these two\nlimitations, we propose UNet++, a new neural architecture for semantic and\ninstance segmentation, by (1) alleviating the unknown network depth with an\nefficient ensemble of U-Nets of varying depths, which partially share an\nencoder and co-learn simultaneously using deep supervision; (2) redesigning\nskip connections to aggregate features of varying semantic scales at the\ndecoder sub-networks, leading to a highly flexible feature fusion scheme; and\n(3) devising a pruning scheme to accelerate the inference speed of UNet++. We\nhave evaluated UNet++ using six different medical image segmentation datasets,\ncovering multiple imaging modalities such as computed tomography (CT), magnetic\nresonance imaging (MRI), and electron microscopy (EM), and demonstrating that\n(1) UNet++ consistently outperforms the baseline models for the task of\nsemantic segmentation across different datasets and backbone architectures; (2)\nUNet++ enhances segmentation quality of varying-size objects -- an improvement\nover the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design)\noutperforms the original Mask R-CNN for the task of instance segmentation; and\n(4) pruned UNet++ models achieve significant speedup while showing only modest\nperformance degradation. Our implementation and pre-trained models are\navailable at https://github.com/MrGiovanni/UNetPlusPlus.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 01:26:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 23:15:28 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Zhou", "Zongwei", ""], ["Siddiquee", "Md Mahfuzur Rahman", ""], ["Tajbakhsh", "Nima", ""], ["Liang", "Jianming", ""]]}, {"id": "1912.05075", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman", "title": "Multimodal Generative Models for Compositional Representation Learning", "comments": "24 pages content; 7 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks become more adept at traditional tasks, many of the\nmost exciting new challenges concern multimodality---observations that combine\ndiverse types, such as image and text. In this paper, we introduce a family of\nmultimodal deep generative models derived from variational bounds on the\nevidence (data marginal likelihood). As part of our derivation we find that\nmany previous multimodal variational autoencoders used objectives that do not\ncorrectly bound the joint marginal likelihood across modalities. We further\ngeneralize our objective to work with several types of deep generative model\n(VAE, GAN, and flow-based), and allow use of different model types for\ndifferent modalities. We benchmark our models across many image, label, and\ntext datasets, and find that our multimodal VAEs excel with and without weak\nsupervision. Additional improvements come from use of GAN image models with VAE\nlanguage models. Finally, we investigate the effect of language on learned\nimage representations through a variety of downstream tasks, such as\ncompositionally, bounding box prediction, and visual relation prediction. We\nfind evidence that these image representations are more abstract and\ncompositional than equivalent representations learned from only visual data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 01:43:56 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""]]}, {"id": "1912.05078", "submitter": "E Zhenqian", "authors": "E Zhenqian and Gao Weiguo", "title": "An Improving Framework of regularization for Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have achieved remarkable success relying on the\ndeveloping high computation capability of GPUs and large-scale datasets with\nincreasing network depth and width in image recognition, object detection and\nmany other applications. However, due to the expensive computation and\nintensive memory, researchers have concentrated on designing compression\nmethods in recent years. In this paper, we briefly summarize the existing\nadvanced techniques that are useful in model compression at first. After that,\nwe give a detailed description on group lasso regularization and its variants.\nMore importantly, we propose an improving framework of partial regularization\nbased on the relationship between neurons and connections of adjacent layers.\nIt is reasonable and feasible with the help of permutation property of neural\nnetwork . Experiment results show that partial regularization methods brings\nimprovements such as higher classification accuracy in both training and\ntesting stages on multiple datasets. Since our regularizers contain the\ncomputation of less parameters, it shows competitive performances in terms of\nthe total running time of experiments. Finally, we analysed the results and\ndraw a conclusion that the optimal network structure must exist and depend on\nthe input data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 01:59:20 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 06:44:41 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhenqian", "E", ""], ["Weiguo", "Gao", ""]]}, {"id": "1912.05079", "submitter": "James Stevenson", "authors": "James M. Stevenson, Leif D. Jacobson, Yutong Zhao, Chuanjie Wu, Jon\n  Maple, Karl Leswing, Edward Harder, Robert Abel", "title": "Schr\\\"odinger-ANI: An Eight-Element Neural Network Interaction Potential\n  with Greatly Expanded Coverage of Druglike Chemical Space", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a neural network potential energy function for use in drug\ndiscovery, with chemical element support extended from 41% to 94% of druglike\nmolecules based on ChEMBL. We expand on the work of Smith et al., with their\nhighly accurate network for the elements H, C, N, O, creating a network for H,\nC, N, O, S, F, Cl, P. We focus particularly on the calculation of relative\nconformer energies, for which we show that our new potential energy function\nhas an RMSE of 0.70 kcal/mol for prospective druglike molecule conformers,\nsubstantially better than the previous state of the art. The speed and accuracy\nof this model could greatly accelerate the parameterization of protein-ligand\nbinding free energy calculations for novel druglike molecules.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:16:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Stevenson", "James M.", ""], ["Jacobson", "Leif D.", ""], ["Zhao", "Yutong", ""], ["Wu", "Chuanjie", ""], ["Maple", "Jon", ""], ["Leswing", "Karl", ""], ["Harder", "Edward", ""], ["Abel", "Robert", ""]]}, {"id": "1912.05081", "submitter": "Ziwei Li", "authors": "Ziwei Li and Sai Ravela", "title": "Neural Networks as Geometric Chaotic Maps", "comments": "in IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3087497", "report-no": null, "categories": "cs.LG math.DS nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of artificial neural networks as models of chaotic dynamics has been\nrapidly expanding. Still, a theoretical understanding of how neural networks\nlearn chaos is lacking. Here, we employ a geometric perspective to show that\nneural networks can efficiently model chaotic dynamics by becoming structurally\nchaotic themselves. We first confirm neural network's efficiency in emulating\nchaos by showing that a parsimonious neural network trained only on few data\npoints can reconstruct strange attractors, extrapolate outside training data\nboundaries, and accurately predict local divergence rates. We then posit that\nthe trained network's map comprises sequential geometric stretching, rotation,\nand compression operations. These geometric operations indicate topological\nmixing and chaos, explaining why neural networks are naturally suitable to\nemulate chaotic dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 02:00:53 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 20:12:05 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 22:29:30 GMT"}, {"version": "v4", "created": "Thu, 1 Jul 2021 04:40:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Ziwei", ""], ["Ravela", "Sai", ""]]}, {"id": "1912.05094", "submitter": "Arman Afrasiyabi", "authors": "Arman Afrasiyabi, Jean-Fran\\c{c}ois Lalonde, Christian Gagn\\'e", "title": "Associative Alignment for Few-shot Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot image classification aims at training a model from only a few\nexamples for each of the \"novel\" classes. This paper proposes the idea of\nassociative alignment for leveraging part of the base data by aligning the\nnovel training instances to the closely related ones in the base training set.\nThis expands the size of the effective novel training set by adding extra\n\"related base\" instances to the few novel ones, thereby allowing a constructive\nfine-tuning. We propose two associative alignment strategies: 1) a\nmetric-learning loss for minimizing the distance between related base samples\nand the centroid of novel instances in the feature space, and 2) a conditional\nadversarial alignment loss based on the Wasserstein distance. Experiments on\nfour standard datasets and three backbones demonstrate that combining our\ncentroid-based alignment loss results in absolute accuracy improvements of\n4.4%, 1.2%, and 6.2% in 5-shot learning over the state of the art for object\nrecognition, fine-grained classification, and cross-domain adaptation,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:14:48 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 09:25:00 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 16:09:17 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Afrasiyabi", "Arman", ""], ["Lalonde", "Jean-Fran\u00e7ois", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "1912.05098", "submitter": "Michael Kellman", "authors": "Michael Kellman, Jon Tamir, Emrah Boston, Michael Lustig, Laura Waller", "title": "Memory-efficient Learning for Large-scale Computational Imaging --\n  NeurIPS deep inverse workshop", "comments": "5 pages, 2 figures, presented at NeurIPS 2019 Deep Inverse workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational imaging systems jointly design computation and hardware to\nretrieve information which is not traditionally accessible with standard\nimaging systems. Recently, critical aspects such as experimental design and\nimage priors are optimized through deep neural networks formed by the unrolled\niterations of classical physics-based reconstructions (termed physics-based\nnetworks). However, for real-world large-scale systems, computing gradients via\nbackpropagation restricts learning due to memory limitations of graphical\nprocessing units. In this work, we propose a memory-efficient learning\nprocedure that exploits the reversibility of the network's layers to enable\ndata-driven design for large-scale computational imaging. We demonstrate our\nmethods practicality on two large-scale systems: super-resolution optical\nmicroscopy and multi-channel magnetic resonance imaging.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:19:48 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 20:42:39 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kellman", "Michael", ""], ["Tamir", "Jon", ""], ["Boston", "Emrah", ""], ["Lustig", "Michael", ""], ["Waller", "Laura", ""]]}, {"id": "1912.05100", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "Explainability Fact Sheets: A Framework for Systematic Assessment of\n  Explainable Approaches", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27-30, 2020, Barcelona, Spain", "journal-ref": null, "doi": "10.1145/3351095.3372870", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations in Machine Learning come in many forms, but a consensus\nregarding their desired properties is yet to emerge. In this paper we introduce\na taxonomy and a set of descriptors that can be used to characterise and\nsystematically assess explainable systems along five key dimensions:\nfunctional, operational, usability, safety and validation. In order to design a\ncomprehensive and representative taxonomy and associated descriptors we\nsurveyed the eXplainable Artificial Intelligence literature, extracting the\ncriteria and desiderata that other authors have proposed or implicitly used in\ntheir research. The survey includes papers introducing new explainability\nalgorithms to see what criteria are used to guide their development and how\nthese algorithms are evaluated, as well as papers proposing such criteria from\nboth computer science and social science perspectives. This novel framework\nallows to systematically compare and contrast explainability approaches, not\njust to better understand their capabilities but also to identify discrepancies\nbetween their theoretical qualities and properties of their implementations. We\ndeveloped an operationalisation of the framework in the form of Explainability\nFact Sheets, which enable researchers and practitioners alike to quickly grasp\ncapabilities and limitations of a particular explainable method. When used as a\nWork Sheet, our taxonomy can guide the development of new explainability\napproaches by aiding in their critical evaluation along the five proposed\ndimensions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:21:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "1912.05103", "submitter": "Armin Aligholian", "authors": "Armin Aligholian, Alireza Shahsavari, Ed Cortez, Emma Stewart, Hamed\n  Mohsenian-Rad", "title": "Event Detection in Micro-PMU Data: A Generative Adversarial Network\n  Scoring Method", "comments": null, "journal-ref": null, "doi": "10.1109/PESGM41954.2020.9281560", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new data-driven method is proposed to detect events in the data streams\nfrom distribution-level phasor measurement units, a.k.a., micro-PMUs. The\nproposed method is developed by constructing unsupervised deep learning anomaly\ndetection models; thus, providing event detection algorithms that require no or\nminimal human knowledge. First, we develop the core components of our approach\nbased on a Generative Adversarial Network (GAN) model. We refer to this method\nas the basic method. It uses the same features that are often used in the\nliterature to detect events in micro-PMU data. Next, we propose a second\nmethod, which we refer to as the enhanced method, which is enforced with\nadditional feature analysis. Both methods can detect point signatures on single\nfeatures and also group signatures on multiple features. This capability can\naddress the unbalanced nature of power distribution circuits. The proposed\nmethods are evaluated using real-world micro-PMU data. We show that both\nmethods highly outperform a state-of-the-art statistical method in terms of the\nevent detection accuracy. The enhanced method also outperforms the basic\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:33:14 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 16:19:49 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Aligholian", "Armin", ""], ["Shahsavari", "Alireza", ""], ["Cortez", "Ed", ""], ["Stewart", "Emma", ""], ["Mohsenian-Rad", "Hamed", ""]]}, {"id": "1912.05104", "submitter": "Riashat Islam", "authors": "Riashat Islam, Raihan Seraj, Pierre-Luc Bacon, Doina Precup", "title": "Entropy Regularization with Discounted Future State Distribution in\n  Policy Gradient Methods", "comments": "In Submission; Appeared at NeurIPS 2019 Optimization Foundations of\n  Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradient theorem is defined based on an objective with respect to\nthe initial distribution over states. In the discounted case, this results in\npolicies that are optimal for one distribution over initial states, but may not\nbe uniformly optimal for others, no matter where the agent starts from.\nFurthermore, to obtain unbiased gradient estimates, the starting point of the\npolicy gradient estimator requires sampling states from a normalized discounted\nweighting of states. However, the difficulty of estimating the normalized\ndiscounted weighting of states, or the stationary state distribution, is quite\nwell-known. Additionally, the large sample complexity of policy gradient\nmethods is often attributed to insufficient exploration, and to remedy this, it\nis often assumed that the restart distribution provides sufficient exploration\nin these algorithms. In this work, we propose exploration in policy gradient\nmethods based on maximizing entropy of the discounted future state\ndistribution. The key contribution of our work includes providing a practically\nfeasible algorithm to estimate the normalized discounted weighting of states,\ni.e, the \\textit{discounted future state distribution}. We propose that\nexploration can be achieved by entropy regularization with the discounted state\ndistribution in policy gradients, where a metric for maximal coverage of the\nstate space can be based on the entropy of the induced state distribution. The\nproposed approach can be considered as a three time-scale algorithm and under\nsome mild technical conditions, we prove its convergence to a locally optimal\npolicy. Experimentally, we demonstrate usefulness of regularization with the\ndiscounted future state distribution in terms of increased state space coverage\nand faster learning on a range of complex tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:40:46 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Islam", "Riashat", ""], ["Seraj", "Raihan", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""]]}, {"id": "1912.05109", "submitter": "Riashat Islam", "authors": "Riashat Islam, Raihan Seraj, Samin Yeasar Arnob, Doina Precup", "title": "Doubly Robust Off-Policy Actor-Critic Algorithms for Reinforcement\n  Learning", "comments": "In Submission; Appeared at NeurIPS 2019 Workshop on Safety and\n  Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy critic evaluation in several variants of\nvalue-based off-policy actor-critic algorithms. Off-policy actor-critic\nalgorithms require an off-policy critic evaluation step, to estimate the value\nof the new policy after every policy gradient update. Despite enormous success\nof off-policy policy gradients on control tasks, existing general methods\nsuffer from high variance and instability, partly because the policy\nimprovement depends on gradient of the estimated value function. In this work,\nwe present a new way of off-policy policy evaluation in actor-critic, based on\nthe doubly robust estimators. We extend the doubly robust estimator from\noff-policy policy evaluation (OPE) to actor-critic algorithms that consist of a\nreward estimator performance model. We find that doubly robust estimation of\nthe critic can significantly improve performance in continuous control tasks.\nFurthermore, in cases where the reward function is stochastic that can lead to\nhigh variance, doubly robust critic estimation can improve performance under\ncorrupted, stochastic reward signals, indicating its usefulness for robust and\nsafe reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 04:21:47 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Islam", "Riashat", ""], ["Seraj", "Raihan", ""], ["Arnob", "Samin Yeasar", ""], ["Precup", "Doina", ""]]}, {"id": "1912.05122", "submitter": "Jiezhu Cheng", "authors": "Jiezhu Cheng, Kaizhu Huang, Zibin Zheng", "title": "Towards Better Forecasting by Fusing Near and Distant Future Visions", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series forecasting is an important yet challenging problem\nin machine learning. Most existing approaches only forecast the series value of\none future moment, ignoring the interactions between predictions of future\nmoments with different temporal distance. Such a deficiency probably prevents\nthe model from getting enough information about the future, thus limiting the\nforecasting accuracy. To address this problem, we propose Multi-Level Construal\nNeural Network (MLCNN), a novel multi-task deep learning framework. Inspired by\nthe Construal Level Theory of psychology, this model aims to improve the\npredictive performance by fusing forecasting information (i.e., future visions)\nof different future time. We first use the Convolution Neural Network to\nextract multi-level abstract representations of the raw data for near and\ndistant future predictions. We then model the interplay between multiple\npredictive tasks and fuse their future visions through a modified\nEncoder-Decoder architecture. Finally, we combine traditional Autoregression\nmodel with the neural network to solve the scale insensitive problem.\nExperiments on three real-world datasets show that our method achieves\nstatistically significant improvements compared to the most state-of-the-art\nbaseline methods, with average 4.59% reduction on RMSE metric and average 6.87%\nreduction on MAE metric.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 05:32:24 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Cheng", "Jiezhu", ""], ["Huang", "Kaizhu", ""], ["Zheng", "Zibin", ""]]}, {"id": "1912.05124", "submitter": "Xi Chen", "authors": "Xi Chen, Shouyi Yin, Dandan Song, Peng Ouyang, Leibo Liu, Shaojun Wei", "title": "Small-footprint Keyword Spotting with Graph Convolutional Network", "comments": "Accepted by the IEEE Automatic Speech Recognition and Understanding\n  Workshop(ASRU 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep neural networks, it remains challenging\nto achieve high precision keyword spotting task (KWS) on resource-constrained\ndevices. In this study, we propose a novel context-aware and compact\narchitecture for keyword spotting task. Based on residual connection and\nbottleneck structure, we design a compact and efficient network for KWS task.\nTo leverage the long range dependencies and global context of the convolutional\nfeature maps, the graph convolutional network is introduced to encode the\nnon-local relations. By evaluated on the Google Speech Command Dataset, the\nproposed method achieves state-of-the-art performance and outperforms the prior\nworks by a large margin with lower computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 05:44:04 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Chen", "Xi", ""], ["Yin", "Shouyi", ""], ["Song", "Dandan", ""], ["Ouyang", "Peng", ""], ["Liu", "Leibo", ""], ["Wei", "Shaojun", ""]]}, {"id": "1912.05127", "submitter": "Weishun Zhong", "authors": "Harshvardhan Sikka, Weishun Zhong, Jun Yin, Cengiz Pehlevan", "title": "A Closer Look at Disentangling in $\\beta$-VAE", "comments": "Presented at the 53rd Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many data analysis tasks, it is beneficial to learn representations where\neach dimension is statistically independent and thus disentangled from the\nothers. If data generating factors are also statistically independent,\ndisentangled representations can be formed by Bayesian inference of latent\nvariables. We examine a generalization of the Variational Autoencoder (VAE),\n$\\beta$-VAE, for learning such representations using variational inference.\n$\\beta$-VAE enforces conditional independence of its bottleneck neurons\ncontrolled by its hyperparameter $\\beta$. This condition is in general not\ncompatible with the statistical independence of latents. By providing\nanalytical and numerical arguments, we show that this incompatibility leads to\na non-monotonic inference performance in $\\beta$-VAE with a finite optimal\n$\\beta$.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 05:51:25 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Sikka", "Harshvardhan", ""], ["Zhong", "Weishun", ""], ["Yin", "Jun", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "1912.05128", "submitter": "Riashat Islam", "authors": "Riashat Islam, Zafarali Ahmed, Doina Precup", "title": "Marginalized State Distribution Entropy Regularization in Policy\n  Optimization", "comments": "In Submission; Appeared at NeurIPS 2019 Deep Reinforcement Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy regularization is used to get improved optimization performance in\nreinforcement learning tasks. A common form of regularization is to maximize\npolicy entropy to avoid premature convergence and lead to more stochastic\npolicies for exploration through action space. However, this does not ensure\nexploration in the state space. In this work, we instead consider the\ndistribution of discounted weighting of states, and propose to maximize the\nentropy of a lower bound approximation to the weighting of a state, based on\nlatent space state representation. We propose entropy regularization based on\nthe marginal state distribution, to encourage the policy to have a more uniform\ndistribution over the state space for exploration. Our approach based on\nmarginal state distribution achieves superior state space coverage on complex\ngridworld domains, that translate into empirical gains in sparse reward 3D maze\nnavigation and continuous control domains compared to entropy regularization\nwith stochastic policies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 05:55:32 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Islam", "Riashat", ""], ["Ahmed", "Zafarali", ""], ["Precup", "Doina", ""]]}, {"id": "1912.05137", "submitter": "Yaniv Blumenfeld", "authors": "Yaniv Blumenfeld, Dar Gilboa, Daniel Soudry", "title": "Is Feature Diversity Necessary in Neural Network Initialization?", "comments": "This paper has been substantially modified, updated, and expanded\n  with additional content (arXiv:2007.01038). To avoid confusion, we are\n  withdrawing the old version of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard practice in training neural networks involves initializing the\nweights in an independent fashion. The results of recent work suggest that\nfeature \"diversity\" at initialization plays an important role in training the\nnetwork. However, other initialization schemes with reduced feature diversity\nhave also been shown to be viable. In this work, we conduct a series of\nexperiments aimed at elucidating the importance of feature diversity at\ninitialization. We show that a complete lack of diversity is harmful to\ntraining, but its effects can be counteracted by a relatively small addition of\nnoise - even the noise in standard non-deterministic GPU computations is\nsufficient. Furthermore, we construct a deep convolutional network with\nidentical features at initialization and almost all of the weights initialized\nat 0 that can be trained to reach accuracy matching its standard-initialized\ncounterpart.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 06:36:46 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 04:01:03 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 05:30:32 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Blumenfeld", "Yaniv", ""], ["Gilboa", "Dar", ""], ["Soudry", "Daniel", ""]]}, {"id": "1912.05140", "submitter": "Sambaran Bandyopadhyay", "authors": "Sambaran Bandyopadhyay, Anirban Biswas, M. N. Murty, Ramasuri\n  Narayanam", "title": "Beyond Node Embedding: A Direct Unsupervised Edge Representation\n  Framework for Homogeneous Networks", "comments": "8 pages, Under review to some conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning has traditionally been used to find lower\ndimensional vector representations of the nodes in a network. However, there\nare very important edge driven mining tasks of interest to the classical\nnetwork analysis community, which have mostly been unexplored in the network\nembedding space. For applications such as link prediction in homogeneous\nnetworks, vector representation (i.e., embedding) of an edge is derived\nheuristically just by using simple aggregations of the embeddings of the end\nvertices of the edge. Clearly, this method of deriving edge embedding is\nsuboptimal and there is a need for a dedicated unsupervised approach for\nembedding edges by leveraging edge properties of the network.\n  Towards this end, we propose a novel concept of converting a network to its\nweighted line graph which is ideally suited to find the embedding of edges of\nthe original network. We further derive a novel algorithm to embed the line\ngraph, by introducing the concept of collective homophily. To the best of our\nknowledge, this is the first direct unsupervised approach for edge embedding in\nhomogeneous information networks, without relying on the node embeddings. We\nvalidate the edge embeddings on three downstream edge mining tasks. Our\nproposed optimization framework for edge embedding also generates a set of node\nembeddings, which are not just the aggregation of edges. Further experimental\nanalysis shows the connection of our framework to the concept of node\ncentrality.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:04:27 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Bandyopadhyay", "Sambaran", ""], ["Biswas", "Anirban", ""], ["Murty", "M. N.", ""], ["Narayanam", "Ramasuri", ""]]}, {"id": "1912.05146", "submitter": "Laurent Schmalen", "authors": "Boris Karanov, Mathieu Chagnon, Vahid Aref, Domani\\c{c} Lavery, Polina\n  Bayvel, Laurent Schmalen", "title": "Concept and Experimental Demonstration of Optical IM/DD End-to-End\n  System Optimization using a Generative Model", "comments": "accepted for publication at OFC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an experimental end-to-end transceiver optimization via deep\nlearning using a generative adversarial network to approximate the test-bed\nchannel. Previously, optimization was only possible through a prior assumption\nof an explicit simplified channel model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:28:11 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 19:25:38 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Karanov", "Boris", ""], ["Chagnon", "Mathieu", ""], ["Aref", "Vahid", ""], ["Lavery", "Domani\u00e7", ""], ["Bayvel", "Polina", ""], ["Schmalen", "Laurent", ""]]}, {"id": "1912.05153", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Nhat Ho, Martin J. Wainwright, Peter L. Bartlett, Michael\n  I. Jordan", "title": "Sampling for Bayesian Mixture Models: MCMC with Polynomial-Time Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling from the power posterior distribution in\nBayesian Gaussian mixture models, a robust version of the classical posterior.\nThis power posterior is known to be non-log-concave and multi-modal, which\nleads to exponential mixing times for some standard MCMC algorithms. We\nintroduce and study the Reflected Metropolis-Hastings Random Walk (RMRW)\nalgorithm for sampling. For symmetric two-component Gaussian mixtures, we prove\nthat its mixing time is bounded as $d^{1.5}(d + \\Vert \\theta_{0}\n\\Vert^2)^{4.5}$ as long as the sample size $n$ is of the order $d (d + \\Vert\n\\theta_{0} \\Vert^2)$. Notably, this result requires no conditions on the\nseparation of the two means. En route to proving this bound, we establish some\nnew results of possible independent interest that allow for combining\nPoincar\\'{e} inequalities for conditional and marginal densities.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:48:49 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mou", "Wenlong", ""], ["Ho", "Nhat", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1912.05156", "submitter": "Lambert Schomaker", "authors": "Lambert Schomaker", "title": "Lifelong learning for text retrieval and recognition in historical\n  handwritten document collections", "comments": "To appear as chapter in book: Handwritten Historical Document\n  Analysis, Recognition, and Retrieval -- State of the Art and Future Trends,\n  in the book series: Series in Machine Perception and Artificial Intelligence\n  World Scientific, ISSN (print): 1793-0839 Original version deposited at\n  Zenodo: https://zenodo.org/record/2346885#.XfCfsq5ytpg on December 17, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides an overview of the problems that need to be dealt with\nwhen constructing a lifelong-learning retrieval, recognition and indexing\nengine for large historical document collections in multiple scripts and\nlanguages, the Monk system. This application is highly variable over time,\nsince the continuous labeling by end users changes the concept of what a\n'ground truth' constitutes. Although current advances in deep learning provide\na huge potential in this application domain, the scale of the problem, i.e.,\nmore than 520 hugely diverse books, documents and manuscripts precludes the\ncurrent meticulous and painstaking human effort which is required in designing\nand developing successful deep-learning systems. The ball-park principle is\nintroduced, which describes the evolution from the sparsely-labeled stage that\ncan only be addressed by traditional methods or nearest-neighbor methods on\nembedded vectors of pre-trained neural networks, up to the other end of the\nspectrum where massive labeling allows reliable training of deep-learning\nmethods. Contents: Introduction, Expectation management, Deep learning, The\nball-park principle, Technical realization, Work flow, Quality and quantity of\nmaterial, Industrialization and scalability, Human effort, Algorithms, Object\nof recognition, Processing pipeline, Performance,Compositionality, Conclusion.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:56:31 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Schomaker", "Lambert", ""]]}, {"id": "1912.05158", "submitter": "Chieh-Fang Teng", "authors": "Chun-Hsiang Chen, Chieh-Fang Teng, and An-Yeu Wu", "title": "Low-Complexity LSTM-Assisted Bit-Flipping Algorithm for Successive\n  Cancellation List Polar Decoder", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polar codes have attracted much attention in the past decade due to their\ncapacity-achieving performance. The higher decoding capacity is required for 5G\nand beyond 5G (B5G). Although the cyclic redundancy check (CRC)- assisted\nsuccessive cancellation list bit-flipping (CA-SCLF) decoders have been\ndeveloped to obtain a better performance, the solution to error bit correction\n(bit-flipping) problem is still imperfect and hard to design. In this work, we\nleverage the expert knowledge in communication systems and adopt deep learning\n(DL) technique to obtain the better solution. A low-complexity long short-term\nmemory network (LSTM)-assisted CA-SCLF decoder is proposed to further improve\nthe performance of conventional CA-SCLF and avoid complexity and memory\noverhead. Our test results show that we can effectively improve the BLER\nperformance by 0.11dB compared to prior work and reduce the complexity and\nmemory overhead by over 30% of the network.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:58:47 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Chen", "Chun-Hsiang", ""], ["Teng", "Chieh-Fang", ""], ["Wu", "An-Yeu", ""]]}, {"id": "1912.05159", "submitter": "Huibing Wang", "authors": "Guangqi Jiang, Huibing Wang, Jinjia Peng, Dongyan Chen, Xianping Fu", "title": "Graph-based Multi-view Binary Learning for Image Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing techniques, also known as binary code learning, have recently gained\nincreasing attention in large-scale data analysis and storage. Generally, most\nexisting hash clustering methods are single-view ones, which lack complete\nstructure or complementary information from multiple views. For cluster tasks,\nabundant prior researches mainly focus on learning discrete hash code while few\nworks take original data structure into consideration. To address these\nproblems, we propose a novel binary code algorithm for clustering, which adopts\ngraph embedding to preserve the original data structure, called (Graph-based\nMulti-view Binary Learning) GMBL in this paper. GMBL mainly focuses on encoding\nthe information of multiple views into a compact binary code, which explores\ncomplementary information from multiple views. In particular, in order to\nmaintain the graph-based structure of the original data, we adopt a Laplacian\nmatrix to preserve the local linear relationship of the data and map it to the\nHamming space. Considering different views have distinctive contributions to\nthe final clustering results, GMBL adopts a strategy of automatically assign\nweights for each view to better guide the clustering. Finally, An alternating\niterative optimization method is adopted to optimize discrete binary codes\ndirectly instead of relaxing the binary constraint in two steps. Experiments on\nfive public datasets demonstrate the superiority of our proposed method\ncompared with previous approaches in terms of clustering performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:04:56 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Jiang", "Guangqi", ""], ["Wang", "Huibing", ""], ["Peng", "Jinjia", ""], ["Chen", "Dongyan", ""], ["Fu", "Xianping", ""]]}, {"id": "1912.05160", "submitter": "Amirhossein Esmaili", "authors": "Amirhossein Esmaili, Massoud Pedram", "title": "Energy-aware Scheduling of Jobs in Heterogeneous Cluster Systems Using\n  Deep Reinforcement Learning", "comments": "Accepted in International Symposium on Quality Electronic Design\n  (ISQED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy consumption is one of the most critical concerns in designing\ncomputing devices, ranging from portable embedded systems to computer cluster\nsystems. Furthermore, in the past decade, cluster systems have increasingly\nrisen as popular platforms to run computing-intensive real-time applications in\nwhich the performance is of great importance. However, due to different\ncharacteristics of real-time workloads, developing general job scheduling\nsolutions that efficiently address both energy consumption and performance in\nreal-time cluster systems is a challenging problem. In this paper, inspired by\nrecent advances in applying deep reinforcement learning for resource management\nproblems, we present the Deep-EAS scheduler that learns efficient energy-aware\nscheduling strategies for workloads with different characteristics without\ninitially knowing anything about the scheduling task at hand. Results show that\nDeep-EAS converges quickly, and performs better compared to standard\nmanually-tuned heuristics, especially in heavy load conditions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:07:50 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Esmaili", "Amirhossein", ""], ["Pedram", "Massoud", ""]]}, {"id": "1912.05170", "submitter": "G\\\"orkem Algan", "authors": "G\\\"orkem Algan, Ilkay Ulusoy", "title": "Image Classification with Deep Learning in the Presence of Noisy Labels:\n  A Survey", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2021.106771", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Image classification systems recently made a giant leap with the advancement\nof deep neural networks. However, these systems require an excessive amount of\nlabeled data to be adequately trained. Gathering a correctly annotated dataset\nis not always feasible due to several factors, such as the expensiveness of the\nlabeling process or difficulty of correctly classifying data, even for the\nexperts. Because of these practical challenges, label noise is a common problem\nin real-world datasets, and numerous methods to train deep neural networks with\nlabel noise are proposed in the literature. Although deep neural networks are\nknown to be relatively robust to label noise, their tendency to overfit data\nmakes them vulnerable to memorizing even random noise. Therefore, it is crucial\nto consider the existence of label noise and develop counter algorithms to fade\naway its adverse effects to train deep neural networks efficiently. Even though\nan extensive survey of machine learning techniques under label noise exists,\nthe literature lacks a comprehensive survey of methodologies centered\nexplicitly around deep learning in the presence of noisy labels. This paper\naims to present these algorithms while categorizing them into one of the two\nsubgroups: noise model based and noise model free methods. Algorithms in the\nfirst group aim to estimate the noise structure and use this information to\navoid the adverse effects of noisy labels. Differently, methods in the second\ngroup try to come up with inherently noise robust algorithms by using\napproaches like robust losses, regularizers or other learning paradigms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:26:57 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:56:01 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 08:50:51 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Algan", "G\u00f6rkem", ""], ["Ulusoy", "Ilkay", ""]]}, {"id": "1912.05179", "submitter": "Yermek Kapushev", "authors": "Yermek Kapushev, Ivan Oseledets, Evgeny Burnaev", "title": "Tensor Completion via Gaussian Process Based Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the tensor completion problem representing the\nsolution in the tensor train (TT) format. It is assumed that tensor is\nhigh-dimensional, and tensor values are generated by an unknown smooth\nfunction. The assumption allows us to develop an efficient initialization\nscheme based on Gaussian Process Regression and TT-cross approximation\ntechnique. The proposed approach can be used in conjunction with any\noptimization algorithm that is usually utilized in tensor completion problems.\nWe empirically justify that in this case the reconstruction error improves\ncompared to the tensor completion with random initialization. As an additional\nbenefit, our technique automatically selects rank thanks to using the TT-cross\napproximation technique.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:52:36 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 19:17:56 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 12:18:07 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kapushev", "Yermek", ""], ["Oseledets", "Ivan", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1912.05184", "submitter": "Amir Abdi", "authors": "Amir H. Abdi, Purang Abolmaesumi, Sidney Fels", "title": "Variational Learning with Disentanglement-PyTorch", "comments": "Disentanglement Challenge - 33rd Conference on Neural Information\n  Processing Systems (NeurIPS) - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of disentangled representations is an open problem in\nmachine learning. The Disentanglement-PyTorch library is developed to\nfacilitate research, implementation, and testing of new variational algorithms.\nIn this modular library, neural architectures, dimensionality of the latent\nspace, and the training algorithms are fully decoupled, allowing for\nindependent and consistent experiments across variational methods. The library\nhandles the training scheduling, logging, and visualizations of reconstructions\nand latent space traversals. It also evaluates the encodings based on various\ndisentanglement metrics. The library, so far, includes implementations of the\nfollowing unsupervised algorithms VAE, Beta-VAE, Factor-VAE, DIP-I-VAE,\nDIP-II-VAE, Info-VAE, and Beta-TCVAE, as well as conditional approaches such as\nCVAE and IFCVAE. The library is compatible with the Disentanglement Challenge\nof NeurIPS 2019, hosted on AICrowd, and achieved the 3rd rank in both the first\nand second stages of the challenge.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 09:02:58 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Abdi", "Amir H.", ""], ["Abolmaesumi", "Purang", ""], ["Fels", "Sidney", ""]]}, {"id": "1912.05198", "submitter": "Angshul Majumdar Dr.", "authors": "Megha Gupta and Angshul Majumdar", "title": "Recurrent Transform Learning", "comments": "A slightly different version has been accepted at Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work is to improve the accuracy of building demand\nforecasting. This is a more challenging task than grid level forecasting. For\nthe said purpose, we develop a new technique called recurrent transform\nlearning (RTL). Two versions are proposed. The first one (RTL) is unsupervised;\nthis is used as a feature extraction tool that is further fed into a regression\nmodel. The second formulation embeds regression into the RTL framework leading\nto regressing recurrent transform learning (R2TL). Forecasting experiments have\nbeen carried out on three popular publicly available datasets. Both of our\nproposed techniques yield results superior to the state-of-the-art like long\nshort term memory network, echo state network and sparse coding regression.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 09:29:57 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Gupta", "Megha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.05234", "submitter": "Artjoms Sinkarovs PhD", "authors": "Artjoms \\v{S}inkarovs, Hans-Nikolai Vie{\\ss}mann, Sven-Bodo Scholz", "title": "Array Languages Make Neural Networks Fast", "comments": null, "journal-ref": null, "doi": "10.1145/3460944.3464312", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning frameworks are complex: they are typically organised\nin multiple layers each of which is written in a different language and they\ndepend on a number of external libraries, but at their core they mainly consist\nof tensor operations. As array-oriented languages provide perfect abstractions\nto implement tensor operations, we consider a minimalistic machine learning\nframework that is shallowly embedded in an array-oriented language and we study\nits productivity and performance. We do this by implementing a state of the art\nConvolutional Neural Network (CNN) and compare it against implementations in\nTensorFlow and PyTorch --- two state of the art industrial-strength frameworks.\nIt turns out that our implementation is 2 and 3 times faster, even after\nfine-tuning the TensorFlow and PyTorch to our hardware --- a 64-core\nGPU-accelerated machine. The size of all three CNN specifications is the same,\nabout 150 lines of code. Our mini framework is 150 lines of highly reusable\nhardware-agnostic code that does not depend on external libraries. The compiler\nfor a host array language automatically generates parallel code for a chosen\narchitecture. The key to such a balance between performance and portability\nlies in the design of the array language; in particular, the ability to express\nrank-polymorphic operations concisely, yet being able to do optimisations\nacross them. This design builds on very few assumptions, and it is readily\ntransferable to other contexts offering a clean approach to high-performance\nmachine learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:17:51 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["\u0160inkarovs", "Artjoms", ""], ["Vie\u00dfmann", "Hans-Nikolai", ""], ["Scholz", "Sven-Bodo", ""]]}, {"id": "1912.05238", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Cigdem Turan, Sophie Jentzsch, Constantin\n  Rothkopf and Kristian Kersting", "title": "BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout \"right\" and \"wrong\" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:27:06 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Schramowski", "Patrick", ""], ["Turan", "Cigdem", ""], ["Jentzsch", "Sophie", ""], ["Rothkopf", "Constantin", ""], ["Kersting", "Kristian", ""]]}, {"id": "1912.05239", "submitter": "Stefano Nolfi", "authors": "Paolo Pagliuca, Nicola Milano, and Stefano Nolfi", "title": "Efficacy of Modern Neuro-Evolutionary Strategies for Continuous Control\n  Optimization", "comments": "17 pages, 5 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the efficacy of modern neuro-evolutionary strategies for\ncontinuous control optimization. Overall, the results collected on a wide\nvariety of qualitatively different benchmark problems indicate that these\nmethods are generally effective and scale well with respect to the number of\nparameters and the complexity of the problem. Moreover, they are relatively\nrobust with respect to the setting of hyper-parameters. The comparison of the\nmost promising methods indicates that the OpenAI-ES algorithm outperforms or\nequals the other algorithms on all considered problems. Moreover, we\ndemonstrate how the reward functions optimized for reinforcement learning\nmethods are not necessarily effective for evolutionary strategies and vice\nversa. This finding can lead to reconsideration of the relative efficacy of the\ntwo classes of algorithm since it implies that the comparisons performed to\ndate are biased toward one or the other class.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:29:12 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 09:50:08 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Pagliuca", "Paolo", ""], ["Milano", "Nicola", ""], ["Nolfi", "Stefano", ""]]}, {"id": "1912.05255", "submitter": "Sumit Darak Dr", "authors": "Shivam Chandhok, Himani Joshi, A V Subramanyam and Sumit J. Darak", "title": "Novel Deep Learning Framework for Wideband Spectrum Characterization at\n  Sub-Nyquist Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction of spectrum-sharing in 5G and subsequent generation networks\ndemand base-station(s) with the capability to characterize the wideband\nspectrum spanned over licensed, shared and unlicensed non-contiguous frequency\nbands. Spectrum characterization involves the identification of vacant bands\nalong with center frequency and parameters (energy, modulation, etc.) of\noccupied bands. Such characterization at Nyquist sampling is area and\npower-hungry due to the need for high-speed digitization. Though sub-Nyquist\nsampling (SNS) offers an excellent alternative when the spectrum is sparse, it\nsuffers from poor performance at low signal to noise ratio (SNR) and demands\ncareful design and integration of digital reconstruction, tunable channelizer\nand characterization algorithms. In this paper, we propose a novel\ndeep-learning framework via a single unified pipeline to accomplish two tasks:\n1)~Reconstruct the signal directly from sub-Nyquist samples, and 2)~Wideband\nspectrum characterization. The proposed approach eliminates the need for\ncomplex signal conditioning between reconstruction and characterization and\ndoes not need complex tunable channelizers. We extensively compare the\nperformance of our framework for a wide range of modulation schemes, SNR and\nchannel conditions. We show that the proposed framework outperforms existing\nSNS based approaches and characterization performance approaches to Nyquist\nsampling-based framework with an increase in SNR. Easy to design and integrate\nalong with a single unified deep learning framework make the proposed\narchitecture a good candidate for reconfigurable platforms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 12:22:02 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 06:53:35 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Chandhok", "Shivam", ""], ["Joshi", "Himani", ""], ["Subramanyam", "A V", ""], ["Darak", "Sumit J.", ""]]}, {"id": "1912.05274", "submitter": "G\\\"ozde G\\\"ul \\c{S}ahin", "authors": "G\\\"ozde G\\\"ul \\c{S}ahin and Iryna Gurevych", "title": "Two Birds with One Stone: Investigating Invertible Neural Networks for\n  Inverse Problems in Morphology", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most problems in natural language processing can be approximated as inverse\nproblems such as analysis and generation at variety of levels from\nmorphological (e.g., cat+Plural <-> cats) to semantic (e.g., (call + 1 2) <->\n\"Calculate one plus two.\"). Although the tasks in both directions are closely\nrelated, general approach in the field has been to design separate models\nspecific for each task. However, having one shared model for both tasks, would\nhelp the researchers exploit the common knowledge among these problems with\nreduced time and memory requirements. We investigate a specific class of neural\nnetworks, called Invertible Neural Networks (INNs) (Ardizzone et al. 2019) that\nenable simultaneous optimization in both directions, hence allow addressing of\ninverse problems via a single model. In this study, we investigate INNs on\nmorphological problems casted as inverse problems. We apply INNs to various\nmorphological tasks with varying ambiguity and show that they provide\ncompetitive performance in both directions. We show that they are able to\nrecover the morphological input parameters, i.e., predicting the lemma (e.g.,\ncat) or the morphological tags (e.g., Plural) when run in the reverse\ndirection, without any significant performance drop in the forward direction,\ni.e., predicting the surface form (e.g., cats).\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 12:50:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1912.05283", "submitter": "Nicolas Michael M\\\"uller", "authors": "Nicolas Michael M\\\"uller, Karla Markert", "title": "Identifying Mislabeled Instances in Classification Datasets", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN),\n  Budapest, Hungary, 2019", "doi": "10.1109/IJCNN.2019.8851920", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key requirement for supervised machine learning is labeled training data,\nwhich is created by annotating unlabeled data with the appropriate class.\nBecause this process can in many cases not be done by machines, labeling needs\nto be performed by human domain experts. This process tends to be expensive\nboth in time and money, and is prone to errors. Additionally, reviewing an\nentire labeled dataset manually is often prohibitively costly, so many real\nworld datasets contain mislabeled instances.\n  To address this issue, we present in this paper a non-parametric end-to-end\npipeline to find mislabeled instances in numerical, image and natural language\ndatasets. We evaluate our system quantitatively by adding a small number of\nlabel noise to 29 datasets, and show that we find mislabeled instances with an\naverage precision of more than 0.84 when reviewing our system's top 1\\%\nrecommendation. We then apply our system to publicly available datasets and\nfind mislabeled instances in CIFAR-100, Fashion-MNIST, and others. Finally, we\npublish the code and an applicable implementation of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 13:18:39 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["M\u00fcller", "Nicolas Michael", ""], ["Markert", "Karla", ""]]}, {"id": "1912.05288", "submitter": "Sungbin Choi", "authors": "Sungbin Choi", "title": "Traffic map prediction using UNet based deep convolutional neural\n  network", "comments": "NeuralIPS 2019 Traffic4cast Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our UNet based deep convolutional neural network\napproach on the Traffic4cast challenge 2019. Challenges task is to predict\nfuture traffic flow volume, heading and speed on high resolution whole city\nmap. We used UNet based deep convolutional neural network to train predictive\nmodel for the short term traffic forecast. On each convolution block, layers\nare densely connected with subsequent layers like a DenseNet. Trained and\nevaluated on the real world data set collected from three distinct cities in\nthe world, our method achieved best performance in this challenge.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 00:25:44 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Choi", "Sungbin", ""]]}, {"id": "1912.05304", "submitter": "Hangyu Mao", "authors": "Hangyu Mao, Zhengchao Zhang, Zhen Xiao, Zhibo Gong, Yan Ni", "title": "Learning Agent Communication under Limited Bandwidth by Message Pruning", "comments": "accepted as a regular paper with poster presentation @ AAAI20. arXiv\n  admin note: text overlap with arXiv:1903.05561", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a crucial factor for the big multi-agent world to stay\norganized and productive. Recently, Deep Reinforcement Learning (DRL) has been\napplied to learn the communication strategy and the control policy for multiple\nagents. However, the practical \\emph{\\textbf{limited bandwidth}} in multi-agent\ncommunication has been largely ignored by the existing DRL methods.\nSpecifically, many methods keep sending messages incessantly, which consumes\ntoo much bandwidth. As a result, they are inapplicable to multi-agent systems\nwith limited bandwidth. To handle this problem, we propose a gating mechanism\nto adaptively prune less beneficial messages. We evaluate the gating mechanism\non several tasks. Experiments demonstrate that it can prune a lot of messages\nwith little impact on performance. In fact, the performance may be greatly\nimproved by pruning redundant messages. Moreover, the proposed gating mechanism\nis applicable to several previous methods, equipping them the ability to\naddress bandwidth restricted settings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 02:41:36 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mao", "Hangyu", ""], ["Zhang", "Zhengchao", ""], ["Xiao", "Zhen", ""], ["Gong", "Zhibo", ""], ["Ni", "Yan", ""]]}, {"id": "1912.05308", "submitter": "Mehrdad Valipour", "authors": "Mehrdad Valipour, En-Shiun Annie Lee, Jaime R. Jamacaro, and Carolina\n  Bessega", "title": "Unsupervised Transfer Learning via BERT Neuron Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advancements in language representation models such as BERT have led\nto a rapid improvement in numerous natural language processing tasks. However,\nlanguage models usually consist of a few hundred million trainable parameters\nwith embedding space distributed across multiple layers, thus making them\nchallenging to be fine-tuned for a specific task or to be transferred to a new\ndomain. To determine whether there are task-specific neurons that can be\nexploited for unsupervised transfer learning, we introduce a method for\nselecting the most important neurons to solve a specific classification task.\nThis algorithm is further extended to multi-source transfer learning by\ncomputing the importance of neurons for several single-source transfer learning\nscenarios between different subsets of data sources. Besides, a task-specific\nfingerprint for each data source is obtained based on the percentage of the\nselected neurons in each layer. We perform extensive experiments in\nunsupervised transfer learning for sentiment analysis, natural language\ninference and sentence similarity, and compare our results with the existing\nliterature and baselines. Significantly, we found that the source and target\ndata sources with higher degrees of similarity between their task-specific\nfingerprints demonstrate a better transferability property. We conclude that\nour method can lead to better performance using just a few hundred\ntask-specific and interpretable neurons.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 16:08:26 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Valipour", "Mehrdad", ""], ["Lee", "En-Shiun Annie", ""], ["Jamacaro", "Jaime R.", ""], ["Bessega", "Carolina", ""]]}, {"id": "1912.05313", "submitter": "Tinghao Zhang", "authors": "Tinghao Zhang, Jing Luo, Ping Chen, Jie Liu", "title": "Flow Rate Control in Smart District Heating Systems Using Deep\n  Reinforcement Learning", "comments": "Submitted to Information Processing in Sensor Networks (IPSN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At high latitudes, many cities adopt a centralized heating system to improve\nthe energy generation efficiency and to reduce pollution. In multi-tier\nsystems, so-called district heating, there are a few efficient approaches for\nthe flow rate control during the heating process. In this paper, we describe\nthe theoretical methods to solve this problem by deep reinforcement learning\nand propose a cloud-based heating control system for implementation. A\nreal-world case study shows the effectiveness and practicability of the\nproposed system controlled by humans, and the simulated experiments for deep\nreinforcement learning show about 1985.01 gigajoules of heat quantity and\n42276.45 tons of water are saved per hour compared with manual control.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 17:55:51 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zhang", "Tinghao", ""], ["Luo", "Jing", ""], ["Chen", "Ping", ""], ["Liu", "Jie", ""]]}, {"id": "1912.05317", "submitter": "Jovita Lukasik", "authors": "David Friede, Jovita Lukasik, Heiner Stuckenschmidt, Margret Keuper", "title": "A Variational-Sequential Graph Autoencoder for Neural Architecture\n  Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision research, the process of automating architecture\nengineering, Neural Architecture Search (NAS), has gained substantial interest.\nIn the past, NAS was hardly accessible to researchers without access to\nlarge-scale compute systems, due to very long compute times for the recurrent\nsearch and evaluation of new candidate architectures. The NAS-Bench-101 dataset\nfacilitates a paradigm change towards classical methods such as supervised\nlearning to evaluate neural architectures. In this paper, we propose a graph\nencoder built upon Graph Neural Networks (GNN). We demonstrate the\neffectiveness of the proposed encoder on NAS performance prediction for seen\narchitecture types as well an unseen ones (i.e., zero shot prediction). We also\nprovide a new variational-sequential graph autoencoder (VS-GAE) based on the\nproposed graph encoder. The VS-GAE is specialized on encoding and decoding\ngraphs of varying length utilizing GNNs. Experiments on different sampling\nmethods show that the embedding space learned by our VS-GAE increases the\nstability on the accuracy prediction task.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:02:07 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 09:50:48 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Friede", "David", ""], ["Lukasik", "Jovita", ""], ["Stuckenschmidt", "Heiner", ""], ["Keuper", "Margret", ""]]}, {"id": "1912.05328", "submitter": "Bo Zhou", "authors": "Bo Zhou, Hongsheng Zeng, Fan Wang, Yunxiang Li, Hao Tian", "title": "Efficient and Robust Reinforcement Learning with Uncertainty-based Value\n  Expansion", "comments": "1st place in NeurIPS 2019: Learn to Move - Walk Around competition\n  and best paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By integrating dynamics models into model-free reinforcement learning (RL)\nmethods, model-based value expansion (MVE) algorithms have shown a significant\nadvantage in sample efficiency as well as value estimation. However, these\nmethods suffer from higher function approximation errors than model-free\nmethods in stochastic environments due to a lack of modeling the environmental\nrandomness. As a result, their performance lags behind the best model-free\nalgorithms in some challenging scenarios. In this paper, we propose a novel\nHybrid-RL method that builds on MVE, namely the Risk Averse Value Expansion\n(RAVE). With imaginative rollouts generated by an ensemble of probabilistic\ndynamics models, we further introduce the aversion of risks by seeking the\nlower confidence bound of the estimation. Experiments on a range of challenging\nenvironments show that by modeling the uncertainty completely, RAVE\nsubstantially enhances the robustness of previous model-based methods, and\nyields state-of-the-art performance. With this technique, our solution gets the\nfirst place in NeurIPS 2019: Learn to Move.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 09:56:14 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Zhou", "Bo", ""], ["Zeng", "Hongsheng", ""], ["Wang", "Fan", ""], ["Li", "Yunxiang", ""], ["Tian", "Hao", ""]]}, {"id": "1912.05345", "submitter": "Girmaw Abebe Tadesse", "authors": "Girmaw Abebe Tadesse, Tingting Zhu, Nhan Le Nguyen Thanh, Nguyen Thanh\n  Hung, Ha Thi Hai Duong, Truong Huu Khanh, Pham Van Quang, Duc Duong Tran,\n  LamMinh Yen, H Rogier Van Doorn, Nguyen Van Hao, John Prince, Hamza Javed,\n  DaniKiyasseh, Le Van Tan, Louise Thwaites, and David A. Clifton", "title": "Severity Detection Tool for Patients with Infectious Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand, foot and mouth disease (HFMD) and tetanus are serious infectious\ndiseases in low and middle income countries. Tetanus in particular has a high\nmortality rate and its treatment is resource-demanding. Furthermore, HFMD often\naffects a large number of infants and young children. As a result, its\ntreatment consumes enormous healthcare resources, especially when outbreaks\noccur. Autonomic nervous system dysfunction (ANSD) is the main cause of death\nfor both HFMD and tetanus patients. However, early detection of ANSD is a\ndifficult and challenging problem. In this paper, we aim to provide a\nproof-of-principle to detect the ANSD level automatically by applying machine\nlearning techniques to physiological patient data, such as electrocardiogram\n(ECG) and photoplethysmogram (PPG) waveforms, which can be collected using\nlow-cost wearable sensors. Efficient features are extracted that encode\nvariations in the waveforms in the time and frequency domains. A support vector\nmachine is employed to classify the ANSD levels. The proposed approach is\nvalidated on multiple datasets of HFMD and tetanus patients in Vietnam. Results\nshow that encouraging performance is achieved in classifying ANSD levels.\nMoreover, the proposed features are simple, more generalisable and outperformed\nthe standard heart rate variability (HRV) analysis. The proposed approach would\nfacilitate both the diagnosis and treatment of infectious diseases in low and\nmiddle income countries, and thereby improve overall patient care.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 09:51:37 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Tadesse", "Girmaw Abebe", ""], ["Zhu", "Tingting", ""], ["Thanh", "Nhan Le Nguyen", ""], ["Hung", "Nguyen Thanh", ""], ["Duong", "Ha Thi Hai", ""], ["Khanh", "Truong Huu", ""], ["Van Quang", "Pham", ""], ["Tran", "Duc Duong", ""], ["Yen", "LamMinh", ""], ["Van Doorn", "H Rogier", ""], ["Van Hao", "Nguyen", ""], ["Prince", "John", ""], ["Javed", "Hamza", ""], ["DaniKiyasseh", "", ""], ["Van Tan", "Le", ""], ["Thwaites", "Louise", ""], ["Clifton", "David A.", ""]]}, {"id": "1912.05372", "submitter": "Hang Le", "authors": "Hang Le and Lo\\\"ic Vial and Jibril Frej and Vincent Segonne and\n  Maximin Coavoux and Benjamin Lecouteux and Alexandre Allauzen and Beno\\^it\n  Crabb\\'e and Laurent Besacier and Didier Schwab", "title": "FlauBERT: Unsupervised Language Model Pre-training for French", "comments": "Accepted to LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models have become a key step to achieve state-of-the art results in\nmany different Natural Language Processing (NLP) tasks. Leveraging the huge\namount of unlabeled texts nowadays available, they provide an efficient way to\npre-train continuous word representations that can be fine-tuned for a\ndownstream task, along with their contextualization at the sentence level. This\nhas been widely demonstrated for English using contextualized representations\n(Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al.,\n2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and\nshare FlauBERT, a model learned on a very large and heterogeneous French\ncorpus. Models of different sizes are trained using the new CNRS (French\nNational Centre for Scientific Research) Jean Zay supercomputer. We apply our\nFrench language models to diverse NLP tasks (text classification, paraphrasing,\nnatural language inference, parsing, word sense disambiguation) and show that\nmost of the time they outperform other pre-training approaches. Different\nversions of FlauBERT as well as a unified evaluation protocol for the\ndownstream tasks, called FLUE (French Language Understanding Evaluation), are\nshared to the research community for further reproducible experiments in French\nNLP.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:59:32 GMT"}, {"version": "v2", "created": "Sat, 14 Dec 2019 18:57:02 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 23:22:38 GMT"}, {"version": "v4", "created": "Thu, 12 Mar 2020 23:58:56 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Le", "Hang", ""], ["Vial", "Lo\u00efc", ""], ["Frej", "Jibril", ""], ["Segonne", "Vincent", ""], ["Coavoux", "Maximin", ""], ["Lecouteux", "Benjamin", ""], ["Allauzen", "Alexandre", ""], ["Crabb\u00e9", "Beno\u00eet", ""], ["Besacier", "Laurent", ""], ["Schwab", "Didier", ""]]}, {"id": "1912.05375", "submitter": "Vaishakhi Mayya", "authors": "Vaishakhi Mayya, Galen Reeves", "title": "Mutual Information in Community Detection with Covariate Information and\n  Correlated Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community detection when there is covariate\ninformation about the node labels and one observes multiple correlated\nnetworks. We provide an asymptotic upper bound on the per-node mutual\ninformation as well as a heuristic analysis of a multivariate performance\nmeasure called the MMSE matrix. These results show that the combined effects of\nseemingly very different types of information can be characterized explicitly\nin terms of formulas involving low-dimensional estimation problems in additive\nGaussian noise. Our analysis is supported by numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 15:10:30 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Mayya", "Vaishakhi", ""], ["Reeves", "Galen", ""]]}, {"id": "1912.05391", "submitter": "Hong Huy Nguyen", "authors": "Huy H. Nguyen, Minoru Kuribayashi, Junichi Yamagishi, Isao Echizen", "title": "Detecting and Correcting Adversarial Images Using Image Processing\n  Operations", "comments": "Fixing incorrect results by removing the CNN detector part", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved excellent performance on several\ntasks and have been widely applied in both academia and industry. However, DNNs\nare vulnerable to adversarial machine learning attacks, in which noise is added\nto the input to change the network output. We have devised an\nimage-processing-based method to detect adversarial images based on our\nobservation that adversarial noise is reduced after applying these operations\nwhile the normal images almost remain unaffected. In addition to detection,\nthis method can be used to restore the adversarial images' original labels,\nwhich is crucial to restoring the normal functionalities of DNN-based systems.\nTesting using an adversarial machine learning database we created for\ngenerating several types of attack using images from the ImageNet Large Scale\nVisual Recognition Challenge database demonstrated the efficiency of our\nproposed method for both detection and correction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 15:32:45 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 11:05:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nguyen", "Huy H.", ""], ["Kuribayashi", "Minoru", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1912.05393", "submitter": "Martijn Wezel Van", "authors": "M.J.A. van Wezel, L.J. Hamburger, Y. Napolean", "title": "Fine-grained Classification of Rowing teams", "comments": "7 pages, NCCV 2019, 6 figures, deep learning, attention learning,\n  CNN, rowing boat, team detector, club detector, data set, dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fine-grained classification tasks such as identifying different breeds of dog\nare quite challenging as visual differences between categories is quite small\nand can be easily overwhelmed by external factors such as object pose,\nlighting, etc. This work focuses on the specific case of classifying rowing\nteams from various associations. Currently, the photos are taken at rowing\ncompetitions and are manually classified by a small set of members, in what is\na painstaking process. To alleviate this, Deep learning models can be utilised\nas a faster method to classify the images. Recent studies show that localising\nthe manually defined parts, and modelling based on these parts, improves on\nvanilla convolution models, so this work also investigates the detection of\nclothing attributes. The networks were trained and tested on a partially\nlabelled data set mainly consisting of rowers from multiple associations. This\npaper resulted in the classification of up to ten rowing associations by using\ndeep learning networks the smaller VGG network achieved 90.1\\% accuracy whereas\nResNet was limited to 87.20\\%. Adding attention to the ResNet resulted into a\ndrop of performance as only 78.10\\% was achieved.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 15:36:25 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["van Wezel", "M. J. A.", ""], ["Hamburger", "L. J.", ""], ["Napolean", "Y.", ""]]}, {"id": "1912.05396", "submitter": "Aiham Taleb", "authors": "Aiham Taleb, Christoph Lippert, Tassilo Klein, and Moin Nabi", "title": "Multimodal Self-Supervised Learning for Medical Image Analysis", "comments": "NeurIPS 2019 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning approaches leverage unlabeled samples to acquire\ngeneric knowledge about different concepts, hence allowing for\nannotation-efficient downstream task learning. In this paper, we propose a\nnovel self-supervised method that leverages multiple imaging modalities. We\nintroduce the multimodal puzzle task, which facilitates rich representation\nlearning from multiple image modalities. The learned representations allow for\nsubsequent fine-tuning on different downstream tasks. To achieve that, we learn\na modality-agnostic feature embedding by confusing image modalities at the\ndata-level. Together with the Sinkhorn operator, with which we formulate the\npuzzle solving optimization as permutation matrix inference instead of\nclassification, they allow for efficient solving of multimodal puzzles with\nvarying levels of complexity. In addition, we also propose to utilize\ncross-modal generation techniques for multimodal data augmentation used for\ntraining self-supervised tasks. In other words, we exploit synthetic images for\nself-supervised pretraining, instead of downstream tasks directly, in order to\ncircumvent quality issues associated with synthetic images, while improving\ndata-efficiency and representations quality. Our experimental results, which\nassess the gains in downstream performance and data-efficiency, show that\nsolving our multimodal puzzles yields better semantic representations, compared\nto treating each modality independently. Our results also highlight the\nbenefits of exploiting synthetic images for self-supervised pretraining. We\nshowcase our approach on four downstream tasks: Brain tumor segmentation and\nsurvival days prediction using four MRI modalities, Prostate segmentation using\ntwo MRI modalities, and Liver segmentation using unregistered CT and MRI\nmodalities. We outperform many previous solutions, and achieve results\ncompetitive to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 15:44:00 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 23:39:07 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Taleb", "Aiham", ""], ["Lippert", "Christoph", ""], ["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1912.05416", "submitter": "Xiaolong Ma", "authors": "Geng Yuan, Xiaolong Ma, Sheng Lin, Zhengang Li, Caiwen Ding", "title": "A SOT-MRAM-based Processing-In-Memory Engine for Highly Compressed DNN\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.DC cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computing wall and data movement challenges of deep neural networks\n(DNNs) have exposed the limitations of conventional CMOS-based DNN\naccelerators. Furthermore, the deep structure and large model size will make\nDNNs prohibitive to embedded systems and IoT devices, where low power\nconsumption are required. To address these challenges, spin orbit torque\nmagnetic random-access memory (SOT-MRAM) and SOT-MRAM based\nProcessing-In-Memory (PIM) engines have been used to reduce the power\nconsumption of DNNs since SOT-MRAM has the characteristic of near-zero standby\npower, high density, none-volatile. However, the drawbacks of SOT-MRAM based\nPIM engines such as high writing latency and requiring low bit-width data\ndecrease its popularity as a favorable energy efficient DNN accelerator. To\nmitigate these drawbacks, we propose an ultra energy efficient framework by\nusing model compression techniques including weight pruning and quantization\nfrom the software level considering the architecture of SOT-MRAM PIM. And we\nincorporate the alternating direction method of multipliers (ADMM) into the\ntraining phase to further guarantee the solution feasibility and satisfy\nSOT-MRAM hardware constraints. Thus, the footprint and power consumption of\nSOT-MRAM PIM can be reduced, while increasing the overall system throughput at\nthe meantime, making our proposed ADMM-based SOT-MRAM PIM more energy\nefficiency and suitable for embedded systems or IoT devices. Our experimental\nresults show the accuracy and compression rate of our proposed framework is\nconsistently outperforming the reference works, while the efficiency (area \\&\npower) and throughput of SOT-MRAM PIM engine is significantly improved.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 22:03:26 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Li", "Zhengang", ""], ["Ding", "Caiwen", ""]]}, {"id": "1912.05421", "submitter": "David Demeter", "authors": "David Demeter and Doug Downey", "title": "Just Add Functions: A Neural-Symbolic Language Model", "comments": "Preprint of paper accepted for AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network language models (NNLMs) have achieved ever-improving accuracy\ndue to more sophisticated architectures and increasing amounts of training\ndata. However, the inductive bias of these models (formed by the distributional\nhypothesis of language), while ideally suited to modeling most running text,\nresults in key limitations for today's models. In particular, the models often\nstruggle to learn certain spatial, temporal, or quantitative relationships,\nwhich are commonplace in text and are second-nature for human readers. Yet, in\nmany cases, these relationships can be encoded with simple mathematical or\nlogical expressions. How can we augment today's neural models with such\nencodings?\n  In this paper, we propose a general methodology to enhance the inductive bias\nof NNLMs by incorporating simple functions into a neural architecture to form a\nhierarchical neural-symbolic language model (NSLM). These functions explicitly\nencode symbolic deterministic relationships to form probability distributions\nover words. We explore the effectiveness of this approach on numbers and\ngeographic locations, and show that NSLMs significantly reduce perplexity in\nsmall-corpus language modeling, and that the performance improvement persists\nfor rare tokens even on much larger corpora. The approach is simple and\ngeneral, and we discuss how it can be applied to other word classes beyond\nnumbers and geography.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:27:07 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Demeter", "David", ""], ["Downey", "Doug", ""]]}, {"id": "1912.05440", "submitter": "Andrew Simpson", "authors": "Shuyang Du, Haoli Guo, Andrew Simpson", "title": "Self-Driving Car Steering Angle Prediction Based on Image Recognition", "comments": "9 pages 13 figures. Paper originally from CS231n (Stanford) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving vehicles have expanded dramatically over the last few years.\nUdacity has release a dataset containing, among other data, a set of images\nwith the steering angle captured during driving. The Udacity challenge aimed to\npredict steering angle based on only the provided images. We explore two\ndifferent models to perform high quality prediction of steering angles based on\nimages using different deep learning techniques including Transfer Learning, 3D\nCNN, LSTM and ResNet. If the Udacity challenge was still ongoing, both of our\nmodels would have placed in the top ten of all entries.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:44:25 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Du", "Shuyang", ""], ["Guo", "Haoli", ""], ["Simpson", "Andrew", ""]]}, {"id": "1912.05452", "submitter": "Amin Karimi", "authors": "Amin Karimi Monsefi, Rana Bakhtiyarzade", "title": "Solving the Reaction-Diffusion equation based on analytical methods and\n  deep learning algorithm; the Case study of sulfate attack to concrete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reaction-diffusion equation is one of the cornerstones equations in\napplied science and engineering. In the present study, a deep neural network\nhas been trained in order to predict the solution of the equation with\ndifferent coefficients using the numerical solution of this equation and the\nutility of deep learning. Analytical solution of the Reaction-Diffusion\nequation also has been conducted by taking advantage of the Danckwerts method.\nThe accuracy of deep learning results was compared with the analytical\nsolutions. In order to decrease the learning time and to find out similar\nequations solutions, such as pure diffusion and pure reaction, dimensional\nanalysis technique has been performed. It was demonstrated that deep learning\ncan accurately estimate the Partial Differential Equations solutionin the case\nof the reaction-diffusion equation with a constant coefficient.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 12:41:53 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Monsefi", "Amin Karimi", ""], ["Bakhtiyarzade", "Rana", ""]]}, {"id": "1912.05453", "submitter": "Krishn Bera", "authors": "Krishn Bera, Yash Mandilwar and Bapi Raju", "title": "Value-of-Information based Arbitration between Model-based and\n  Model-free Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There have been numerous attempts in explaining the general learning\nbehaviours using model-based and model-free methods. While the model-based\ncontrol is flexible yet computationally expensive in planning, the model-free\ncontrol is quick but inflexible. The model-based control is therefore immune\nfrom reward devaluation and contingency degradation. Multiple arbitration\nschemes have been suggested to achieve the data efficiency and computational\nefficiency of model-based and model-free control respectively. In this context,\nwe propose a quantitative 'value of information' based arbitration between both\nthe controllers in order to establish a general computational framework for\nskill learning. The interacting model-based and model-free reinforcement\nlearning processes are arbitrated using an uncertainty-based value of\ninformation. We further show that our algorithm performs better than Q-learning\nas well as Q-learning with experience replay.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 07:26:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Bera", "Krishn", ""], ["Mandilwar", "Yash", ""], ["Raju", "Bapi", ""]]}, {"id": "1912.05457", "submitter": "Zhiyong Cui", "authors": "Zhiyong Cui, Longfei Lin, Ziyuan Pu, Yinhai Wang", "title": "Graph Markov Network for Traffic Forecasting with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting is a classical task for traffic management and it plays\nan important role in intelligent transportation systems. However, since traffic\ndata are mostly collected by traffic sensors or probe vehicles, sensor failures\nand the lack of probe vehicles will inevitably result in missing values in the\ncollected raw data for some specific links in the traffic network. Although\nmissing values can be imputed, existing data imputation methods normally need\nlong-term historical traffic state data. As for short-term traffic forecasting,\nespecially under edge computing and online prediction scenarios, traffic\nforecasting models with the capability of handling missing values are needed.\nIn this study, we consider the traffic network as a graph and define the\ntransition between network-wide traffic states at consecutive time steps as a\ngraph Markov process. In this way, missing traffic states can be inferred step\nby step and the spatial-temporal relationships among the roadway links can be\nIncorporated. Based on the graph Markov process, we propose a new neural\nnetwork architecture for spatial-temporal data forecasting, i.e. the graph\nMarkov network (GMN). By incorporating the spectral graph convolution\noperation, we also propose a spectral graph Markov network (SGMN). The proposed\nmodels are compared with baseline models and tested on three real-world traffic\nstate datasets with various missing rates. Experimental results show that the\nproposed GMN and SGMN can achieve superior prediction performance in terms of\nboth accuracy and efficiency. Besides, the proposed models' parameters,\nweights, and predicted results are comprehensively analyzed and visualized.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 09:42:33 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Cui", "Zhiyong", ""], ["Lin", "Longfei", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "1912.05458", "submitter": "Mohsen Ghassemi Parsa", "authors": "Mohsen Ghassemi Parsa, Hadi Zare, Mehdi Ghatee", "title": "Unsupervised Feature Selection based on Adaptive Similarity Learning and\n  Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection methods have an important role on the readability of data\nand the reduction of complexity of learning algorithms. In recent years, a\nvariety of efforts are investigated on feature selection problems based on\nunsupervised viewpoint due to the laborious labeling task on large datasets. In\nthis paper, we propose a novel approach on unsupervised feature selection\ninitiated from the subspace clustering to preserve the similarities by\nrepresentation learning of low dimensional subspaces among the samples. A\nself-expressive model is employed to implicitly learn the cluster similarities\nin an adaptive manner. The proposed method not only maintains the sample\nsimilarities through subspace clustering, but it also captures the\ndiscriminative information based on a regularized regression model. In line\nwith the convergence analysis of the proposed method, the experimental results\non benchmark datasets demonstrate the effectiveness of our approach as compared\nwith the state of the art methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 16:10:48 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Parsa", "Mohsen Ghassemi", ""], ["Zare", "Hadi", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "1912.05459", "submitter": "Christian Etmann", "authors": "Christian Etmann, Maximilian Schmidt, Jens Behrmann, Tobias Boskamp,\n  Lena Hauberg-Lotte, Annette Peter, Rita Casadonte, J\\\"org Kriegsmann, Peter\n  Maass", "title": "Deep Relevance Regularization: Interpretable and Robust Tumor Typing of\n  Imaging Mass Spectrometry Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have recently been established as a viable classification\nmethod for imaging mass spectrometry data for tumor typing. For\nmulti-laboratory scenarios however, certain confounding factors may strongly\nimpede their performance. In this work, we introduce Deep Relevance\nRegularization, a method of restricting what the neural network can focus on\nduring classification, in order to improve the classification performance. We\ndemonstrate how Deep Relevance Regularization robustifies neural networks\nagainst confounding factors on a challenging inter-lab dataset consisting of\nbreast and ovarian carcinoma. We further show that this makes the relevance map\n-- a way of visualizing the discriminative parts of the mass spectrum --\nsparser, thereby making the classifier easier to interpret\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:45:55 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Etmann", "Christian", ""], ["Schmidt", "Maximilian", ""], ["Behrmann", "Jens", ""], ["Boskamp", "Tobias", ""], ["Hauberg-Lotte", "Lena", ""], ["Peter", "Annette", ""], ["Casadonte", "Rita", ""], ["Kriegsmann", "J\u00f6rg", ""], ["Maass", "Peter", ""]]}, {"id": "1912.05467", "submitter": "Xun Wang Dr", "authors": "Rumeng Li, Xun Wang, Hong Yu", "title": "MetaMT,a MetaLearning Method Leveraging Multiple Domain Data for Low\n  Resource Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating training data leads to robust neural models for MT.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:05:18 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Li", "Rumeng", ""], ["Wang", "Xun", ""], ["Yu", "Hong", ""]]}, {"id": "1912.05472", "submitter": "Gianluca Maguolo", "authors": "Gianluca Maguolo, Michelangelo Paci, Loris Nanni, Ludovico Bonan", "title": "Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio data augmentation is a key step in training deep neural networks for\nsolving audio classification tasks. In this paper, we introduce Audiogmenter, a\nnovel audio data augmentation library in MATLAB. We provide 15 different\naugmentation algorithms for raw audio data and 8 for spectrograms. We\nefficiently implemented several augmentation techniques whose usefulness has\nbeen extensively proved in the literature. To the best of our knowledge, this\nis the largest MATLAB audio data augmentation library freely available. We\nvalidate the efficiency of our algorithms evaluating them on the ESC-50\ndataset. The toolbox and its documentation can be downloaded at\nhttps://github.com/LorisNanni/Audiogmenter.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:07:28 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 08:45:10 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 03:58:50 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Maguolo", "Gianluca", ""], ["Paci", "Michelangelo", ""], ["Nanni", "Loris", ""], ["Bonan", "Ludovico", ""]]}, {"id": "1912.05480", "submitter": "Kerstin Hammernik", "authors": "Jo Schlemper, Chen Qin, Jinming Duan, Ronald M. Summers, Kerstin\n  Hammernik", "title": "$\\Sigma$-net: Ensembled Iterative Deep Neural Networks for Accelerated\n  Parallel MR Image Reconstruction", "comments": "fastMRI challenge submission (team: holykspace)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore an ensembled $\\Sigma$-net for fast parallel MR imaging, including\nparallel coil networks, which perform implicit coil weighting, and sensitivity\nnetworks, involving explicit sensitivity maps. The networks in $\\Sigma$-net are\ntrained in a supervised way, including content and GAN losses, and with various\nways of data consistency, i.e., proximal mappings, gradient descent and\nvariable splitting. A semi-supervised finetuning scheme allows us to adapt to\nthe k-space data at test time, which, however, decreases the quantitative\nmetrics, although generating the visually most textured and sharp images. For\nthis challenge, we focused on robust and high SSIM scores, which we achieved by\nensembling all models to a $\\Sigma$-net.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:23:58 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Schlemper", "Jo", ""], ["Qin", "Chen", ""], ["Duan", "Jinming", ""], ["Summers", "Ronald M.", ""], ["Hammernik", "Kerstin", ""]]}, {"id": "1912.05492", "submitter": "Masataro Asai", "authors": "Masataro Asai", "title": "Neural-Symbolic Descriptive Action Model from Images: The Search for\n  STRIPS", "comments": "Technical Report; not going to be submitted to the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on Neural-Symbolic systems that learn the discrete planning model\nfrom images has opened a promising direction for expanding the scope of\nAutomated Planning and Scheduling to the raw, noisy data. However, previous\nwork only partially addressed this problem, utilizing the black-box neural\nmodel as the successor generator. In this work, we propose Double-Stage Action\nModel Acquisition (DSAMA), a system that obtains a descriptive PDDL action\nmodel with explicit preconditions and effects over the propositional variables\nunsupervized-learned from images. DSAMA trains a set of Random Forest\nrule-based classifiers and compiles them into logical formulae in PDDL. While\nwe obtained a competitively accurate PDDL model compared to a black-box model,\nwe observed that the resulting PDDL is too large and complex for the\nstate-of-the-art standard planners such as Fast Downward primarily due to the\nPDDL-SAS+ translator bottleneck. From this negative result, we argue that this\ntranslator bottleneck cannot be addressed just by using a different, existing\nrule-based learning method, and we point to the potential future directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:45:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Asai", "Masataro", ""]]}, {"id": "1912.05500", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Junhyuk Oh, Matteo Hessel, Zhongwen Xu, Manuel Kroiss,\n  Hado van Hasselt, David Silver, Satinder Singh", "title": "What Can Learned Intrinsic Rewards Capture?", "comments": "ICML 2020. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of a reinforcement learning agent is to behave so as to\nmaximise the sum of a suitable scalar function of state: the reward. These\nrewards are typically given and immutable. In this paper, we instead consider\nthe proposition that the reward function itself can be a good locus of learned\nknowledge. To investigate this, we propose a scalable meta-gradient framework\nfor learning useful intrinsic reward functions across multiple lifetimes of\nexperience. Through several proof-of-concept experiments, we show that it is\nfeasible to learn and capture knowledge about long-term exploration and\nexploitation into a reward function. Furthermore, we show that unlike policy\ntransfer methods that capture \"how\" the agent should behave, the learned reward\nfunctions can generalise to other kinds of agents and to changes in the\ndynamics of the environment by capturing \"what\" the agent should strive to do.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:00:05 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 02:17:29 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 21:16:59 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zheng", "Zeyu", ""], ["Oh", "Junhyuk", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Kroiss", "Manuel", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}, {"id": "1912.05509", "submitter": "Elsa Cazelles", "authors": "Elsa Cazelles, Arnaud Robert, Felipe Tobar", "title": "The Wasserstein-Fourier Distance for Stationary Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Wasserstein-Fourier (WF) distance to measure the\n(dis)similarity between time series by quantifying the displacement of their\nenergy across frequencies. The WF distance operates by calculating the\nWasserstein distance between the (normalised) power spectral densities (NPSD)\nof time series. Yet this rationale has been considered in the past, we fill a\ngap in the open literature providing a formal introduction of this distance,\ntogether with its main properties from the joint perspective of Fourier\nanalysis and optimal transport. As the main aim of this work is to validate WF\nas a general-purpose metric for time series, we illustrate its applicability on\nthree broad contexts. First, we rely on WF to implement a PCA-like\ndimensionality reduction for NPSDs which allows for meaningful visualisation\nand pattern recognition applications. Second, we show that the geometry induced\nby WF on the space of NPSDs admits a geodesic interpolant between time series,\nthus enabling data augmentation on the spectral domain, by averaging the\ndynamic content of two signals. Third, we implement WF for time series\nclassification using parametric/non-parametric classifiers and compare it to\nother classical metrics. Supported on theoretical results, as well as synthetic\nillustrations and experiments on real-world data, this work establishes WF as a\nmeaningful and capable resource pertinent to general distance-based\napplications of time series.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:17:12 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 10:24:24 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Cazelles", "Elsa", ""], ["Robert", "Arnaud", ""], ["Tobar", "Felipe", ""]]}, {"id": "1912.05510", "submitter": "Glen Berseth", "authors": "Glen Berseth, Daniel Geng, Coline Devin, Nicholas Rhinehart, Chelsea\n  Finn, Dinesh Jayaraman, Sergey Levine", "title": "SMiRL: Surprise Minimizing Reinforcement Learning in Unstable\n  Environments", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every living organism struggles against disruptive environmental forces to\ncarve out and maintain an orderly niche. We propose that such a struggle to\nachieve and preserve order might offer a principle for the emergence of useful\nbehaviors in artificial agents. We formalize this idea into an unsupervised\nreinforcement learning method called surprise minimizing reinforcement learning\n(SMiRL). SMiRL alternates between learning a density model to evaluate the\nsurprise of a stimulus, and improving the policy to seek more predictable\nstimuli. The policy seeks out stable and repeatable situations that counteract\nthe environment's prevailing sources of entropy. This might include avoiding\nother hostile agents, or finding a stable, balanced pose for a bipedal robot in\nthe face of disturbance forces. We demonstrate that our surprise minimizing\nagents can successfully play Tetris, Doom, control a humanoid to avoid falls,\nand navigate to escape enemies in a maze without any task-specific reward\nsupervision. We further show that SMiRL can be used together with standard task\nrewards to accelerate reward-driven learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:19:11 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:10:36 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:44:48 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 02:58:22 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Berseth", "Glen", ""], ["Geng", "Daniel", ""], ["Devin", "Coline", ""], ["Rhinehart", "Nicholas", ""], ["Finn", "Chelsea", ""], ["Jayaraman", "Dinesh", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.05511", "submitter": "Hanna Wallach", "authors": "Abigail Z. Jacobs and Hanna Wallach", "title": "Measurement and Fairness", "comments": "11 pages, 1 figure. To be published in the proceedings of the ACM\n  Conference on Fairness, Accountability, and Transparency (FAccT '21)", "journal-ref": null, "doi": "10.1145/3442188.3445901", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose measurement modeling from the quantitative social sciences as a\nframework for understanding fairness in computational systems. Computational\nsystems often involve unobservable theoretical constructs, such as\nsocioeconomic status, teacher effectiveness, and risk of recidivism. Such\nconstructs cannot be measured directly and must instead be inferred from\nmeasurements of observable properties (and other unobservable theoretical\nconstructs) thought to be related to them -- i.e., operationalized via a\nmeasurement model. This process, which necessarily involves making assumptions,\nintroduces the potential for mismatches between the theoretical understanding\nof the construct purported to be measured and its operationalization. We argue\nthat many of the harms discussed in the literature on fairness in computational\nsystems are direct results of such mismatches. We show how some of these harms\ncould have been anticipated and, in some cases, mitigated if viewed through the\nlens of measurement modeling. To do this, we contribute fairness-oriented\nconceptualizations of construct reliability and construct validity that unite\ntraditions from political science, education, and psychology and provide a set\nof tools for making explicit and testing assumptions about constructs and their\noperationalizations. We then turn to fairness itself, an essentially contested\nconstruct that has different theoretical understandings in different contexts.\nWe argue that this contestedness underlies recent debates about fairness\ndefinitions: although these debates appear to be about different\noperationalizations, they are, in fact, debates about different theoretical\nunderstandings of fairness. We show how measurement modeling can provide a\nframework for getting to the core of these debates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:21:38 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 18:20:14 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 21:26:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Jacobs", "Abigail Z.", ""], ["Wallach", "Hanna", ""]]}, {"id": "1912.05525", "submitter": "Leon Lang", "authors": "Benjamin Kolb, Leon Lang, Henning Bartsch, Arwin Gansekoele, Raymond\n  Koopmanschap, Leonardo Romor, David Speck, Mathijs Mul, Elia Bruni", "title": "Learning to Request Guidance in Emergent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research into agent communication has shown that a pre-trained guide\ncan speed up the learning process of an imitation learning agent. The guide\nachieves this by providing the agent with discrete messages in an emerged\nlanguage about how to solve the task. We extend this one-directional\ncommunication by a one-bit communication channel from the learner back to the\nguide: It is able to ask the guide for help, and we limit the guidance by\npenalizing the learner for these requests. During training, the agent learns to\ncontrol this gate based on its current observation. We find that the amount of\nrequested guidance decreases over time and guidance is requested in situations\nof high uncertainty. We investigate the agent's performance in cases of open\nand closed gates and discuss potential motives for the observed gating\nbehavior.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:48:05 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Kolb", "Benjamin", ""], ["Lang", "Leon", ""], ["Bartsch", "Henning", ""], ["Gansekoele", "Arwin", ""], ["Koopmanschap", "Raymond", ""], ["Romor", "Leonardo", ""], ["Speck", "David", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1912.05533", "submitter": "Daniel Park", "authors": "Daniel S. Park, Yu Zhang, Chung-Cheng Chiu, Youzheng Chen, Bo Li,\n  William Chan, Quoc V. Le and Yonghui Wu", "title": "SpecAugment on Large Scale Datasets", "comments": "5 pages, 3 tables; submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, SpecAugment, an augmentation scheme for automatic speech\nrecognition that acts directly on the spectrogram of input utterances, has\nshown to be highly effective in enhancing the performance of end-to-end\nnetworks on public datasets. In this paper, we demonstrate its effectiveness on\ntasks with large scale datasets by investigating its application to the Google\nMultidomain Dataset (Narayanan et al., 2018). We achieve improvement across all\ntest domains by mixing raw training data augmented with SpecAugment and\nnoise-perturbed training data when training the acoustic model. We also\nintroduce a modification of SpecAugment that adapts the time mask size and/or\nmultiplicity depending on the length of the utterance, which can potentially\nbenefit large scale tasks. By using adaptive masking, we are able to further\nimprove the performance of the Listen, Attend and Spell model on LibriSpeech to\n2.2% WER on test-clean and 5.2% WER on test-other.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:58:58 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Park", "Daniel S.", ""], ["Zhang", "Yu", ""], ["Chiu", "Chung-Cheng", ""], ["Chen", "Youzheng", ""], ["Li", "Bo", ""], ["Chan", "William", ""], ["Le", "Quoc V.", ""], ["Wu", "Yonghui", ""]]}, {"id": "1912.05537", "submitter": "Kristy Choi", "authors": "Kristy Choi, Curtis Hawthorne, Ian Simon, Monica Dinculescu, Jesse\n  Engel", "title": "Encoding Musical Style with Transformer Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning high-level controls over the global\nstructure of generated sequences, particularly in the context of symbolic music\ngeneration with complex language models. In this work, we present the\nTransformer autoencoder, which aggregates encodings of the input data across\ntime to obtain a global representation of style from a given performance. We\nshow it is possible to combine this global representation with other temporally\ndistributed embeddings, enabling improved control over the separate aspects of\nperformance style and melody. Empirically, we demonstrate the effectiveness of\nour method on various music generation tasks on the MAESTRO dataset and a\nYouTube dataset with 10,000+ hours of piano performances, where we achieve\nimprovements in terms of log-likelihood and mean listening scores as compared\nto baselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:51:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 05:00:40 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Choi", "Kristy", ""], ["Hawthorne", "Curtis", ""], ["Simon", "Ian", ""], ["Dinculescu", "Monica", ""], ["Engel", "Jesse", ""]]}, {"id": "1912.05539", "submitter": "Shahin Khobahi", "authors": "Shahin Khobahi, Arindam Bose, Mojtaba Soltanalian", "title": "Deep One-bit Compressive Autoencoding", "comments": "This work have been submitted to the IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, May 2020.\n  arXiv admin note: substantial text overlap with arXiv:1911.12410", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized mathematical models play a central role in understanding and\ndesign of complex information systems. However, they often cannot take into\naccount the intricate interactions innate to such systems. On the contrary,\npurely data-driven approaches do not need explicit mathematical models for data\ngeneration and have a wider applicability at the cost of interpretability. In\nthis paper, we consider the design of a one-bit compressive autoencoder, and\npropose a novel hybrid model-based and data-driven methodology that allows us\nto not only design the sensing matrix for one-bit data acquisition, but also\nallows for learning the latent-parameters of an iterative optimization\nalgorithm specifically designed for the problem of one-bit sparse signal\nrecovery. Our results demonstrate a significant improvement compared to\nstate-of-the-art model-based algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 21:58:54 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Khobahi", "Shahin", ""], ["Bose", "Arindam", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "1912.05541", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Information-Theoretic Performance Limitations of Feedback Control:\n  Underlying Entropic Laws and Generic $\\mathcal{L}_{p}$ Bounds", "comments": "arXiv admin note: text overlap with arXiv:1912.02628", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.IT cs.LG cs.RO cs.SY math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we utilize information theory to study the fundamental\nperformance limitations of generic feedback systems, where both the controller\nand the plant may be any causal functions/mappings while the disturbance can be\nwith any distributions. More specifically, we obtain fundamental\n$\\mathcal{L}_p$ bounds on the control error, which are shown to be completely\ncharacterized by the conditional entropy of the disturbance, based upon the\nentropic laws that are inherent in any feedback systems. We also discuss the\ngenerality and implications (in, e.g., fundamental limits of learning-based\ncontrol) of the obtained bounds.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:41:07 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 16:07:04 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 16:28:18 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 21:58:47 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1912.05571", "submitter": "Iman Tabrizian", "authors": "Saeedeh Parsaeefard, Iman Tabrizian, Alberto Leon Garcia", "title": "Representation of Federated Learning via Worst-Case Robust Optimization\n  Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed learning approach where a set of\nend-user devices participate in the learning process by acting on their\nisolated local data sets. Here, we process local data sets of users where\nworst-case optimization theory is used to reformulate the FL problem where the\nimpact of local data sets in training phase is considered as an uncertain\nfunction bounded in a closed uncertainty region. This representation allows us\nto compare the performance of FL with its centralized counterpart, and to\nreplace the uncertain function with a concept of protection functions leading\nto more tractable formulation. The latter supports applying a regularization\nfactor in each user cost function in FL to reach a better performance. We\nevaluated our model using the MNIST data set versus the protection function\nparameters, e.g., regularization factors.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:02:49 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Tabrizian", "Iman", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "1912.05590", "submitter": "Hang Guo", "authors": "Hang Guo, Xun Fan, Anh Cao, Geoff Outhred, John Heidemann", "title": "Peek Inside the Closed World: Evaluating Autoencoder-Based Detection of\n  DDoS to Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-learning-based anomaly detection (ML-based AD) has been successful at\ndetecting DDoS events in the lab. However published evaluations of ML-based AD\nhave used only limited data and provided minimal insight into why it works. To\naddress limited evaluation against real-world data, we apply autoencoder, an\nexisting ML-AD model, to 57 DDoS attack events captured at 5 cloud IPs from a\nmajor cloud provider. We show that our models detect nearly all malicious flows\nfor 2 of the 4 cloud IPs under attack (at least 99.99%) and detect most\nmalicious flows (94.75% and 91.37%) for the remaining 2 IPs. Our models also\nmaintain near-zero false positives on benign flows to all 5 IPs. Our primary\ncontribution is to improve our understanding for why ML-based AD works on some\nmalicious flows but not others. We interpret our detection results with feature\nattribution and counterfactual explanation. We show that our models are better\nat detecting malicious flows with anomalies on allow-listed features (those\nwith only a few benign values) than flows with anomalies on deny-listed\nfeatures (those with mostly benign values) because our models are more likely\nto learn correct normality for allow-listed features. We then show that our\nmodels are better at detecting malicious flows with anomalies on unordered\nfeatures (that have no ordering among their values) than flows with anomalies\non ordered features because even with incomplete normality, our models could\nstill detect anomalies on unordered feature with high recall. Lastly, we\nsummarize the implications of what we learn on applying autoencoder-based AD in\nproduction: training with noisy real-world data is possible, autoencoder can\nreliably detect real-world anomalies on well-represented unordered features and\ncombinations of autoencoder-based AD and heuristic-based filters can help both.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:41:34 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 02:17:57 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 00:09:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Guo", "Hang", ""], ["Fan", "Xun", ""], ["Cao", "Anh", ""], ["Outhred", "Geoff", ""], ["Heidemann", "John", ""]]}, {"id": "1912.05612", "submitter": "Amir Mosavi Prof", "authors": "Amin Bemani, Alireza Baghban, Shahaboddin Shamshirband, Amir Mosavi,\n  Peter Csiba, Annamaria R. Varkonyi-Koczy", "title": "Applying ANN, ANFIS, and LSSVM Models for Estimation of Acid Solvent\n  Solubility in Supercritical CO$_2$", "comments": "37 pages, 9 figure", "journal-ref": null, "doi": "10.20944/preprints201906.0055.v2", "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present work, a novel and the robust computational investigation is\ncarried out to estimate solubility of different acids in supercritical carbon\ndioxide. Four different algorithms such as radial basis function artificial\nneural network, Multi-layer Perceptron (MLP) artificial neural network (ANN),\nLeast squares support vector machine (LSSVM) and adaptive neuro-fuzzy inference\nsystem (ANFIS) are developed to predict the solubility of different acids in\ncarbon dioxide based on the temperature, pressure, hydrogen number, carbon\nnumber, molecular weight, and acid dissociation constant of acid. In the\npurpose of best evaluation of proposed models, different graphical and\nstatistical analyses and also a novel sensitivity analysis are carried out. The\npresent study proposed the great manners for best acid solubility estimation in\nsupercritical carbon dioxide, which can be helpful for engineers and chemists\nto predict operational conditions in industries.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:24:50 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Bemani", "Amin", ""], ["Baghban", "Alireza", ""], ["Shamshirband", "Shahaboddin", ""], ["Mosavi", "Amir", ""], ["Csiba", "Peter", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "1912.05617", "submitter": "Jaechang Lim", "authors": "Seung Hwan Hong, Jaechang Lim, Seongok Ryu, and Woo Youn Kim", "title": "Molecular Generative Model Based On Adversarially Regularized\n  Autoencoder", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are attracting great attention as a new promising\napproach for molecular design. All models reported so far are based on either\nvariational autoencoder (VAE) or generative adversarial network (GAN). Here we\npropose a new type model based on an adversarially regularized autoencoder\n(ARAE). It basically uses latent variables like VAE, but the distribution of\nthe latent variables is obtained by adversarial training like in GAN. The\nlatter is intended to avoid both inappropriate approximation of posterior\ndistribution in VAE and difficulty in handling discrete variables in GAN. Our\nbenchmark study showed that ARAE indeed outperformed conventional models in\nterms of validity, uniqueness, and novelty per generated molecule. We also\ndemonstrated successful conditional generation of drug-like molecules with ARAE\nfor both cases of single and multiple properties control. As a potential\nreal-world application, we could generate EGFR inhibitors sharing the scaffolds\nof known active molecules while satisfying drug-like conditions simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 04:23:15 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Hong", "Seung Hwan", ""], ["Lim", "Jaechang", ""], ["Ryu", "Seongok", ""], ["Kim", "Woo Youn", ""]]}, {"id": "1912.05625", "submitter": "Seonwoo Min", "authors": "Seonwoo Min, Seunghyun Park, Siwon Kim, Hyun-Soo Choi, Sungroh Yoon", "title": "Pre-Training of Deep Bidirectional Protein Sequence Representations with\n  Structural Information", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Bridging the exponentially growing gap between the number of\nunlabeled and labeled proteins, a couple of works have adopted semi-supervised\nlearning for protein sequence modeling. They pre-train a model with a\nsubstantial amount of unlabeled data and transfer the learned representations\nto various downstream tasks. Nonetheless, the current pre-training methods\nmostly rely on a language modeling task and often show limited performances.\nTherefore, a complementary protein-specific task for pre-training is necessary\nto better capture the information contained within unlabeled protein sequences.\n  Results: In this paper, we introduce a novel pre-training scheme called PLUS,\nwhich stands for Protein sequence representations Learned Using Structural\ninformation. PLUS consists of masked language modeling and a complementary\nprotein-specific pre-training task, namely same family prediction. PLUS can be\nused to pre-train various model architectures. In this work, we mainly use PLUS\nto pre-train a recurrent neural network (RNN) and refer to the resulting model\nas PLUS-RNN. It advances state-of-the-art pre-training methods on six out of\nseven tasks, i.e., (1) three protein(-pair)-level classification, (2) two\nprotein-level regression, and (3) two amino-acid-level classification tasks.\nFurthermore, we present results from our ablation studies and interpretation\nanalyses to better understand the strengths of PLUS-RNN.\n  Availability: The codes and pre-trained models are available at\nhttps://github.com/mswzeus/PLUS/\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:12:10 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 09:06:30 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 03:58:33 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Min", "Seonwoo", ""], ["Park", "Seunghyun", ""], ["Kim", "Siwon", ""], ["Choi", "Hyun-Soo", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1912.05629", "submitter": "Raffaello Camoriano", "authors": "Raffaello Camoriano", "title": "Large-scale Kernel Methods and Applications to Lifelong Robot Learning", "comments": "Ph. D. Thesis for the Doctoral Course in Bioengineering and Robotics\n  (Curriculum in Humanoid Robotics) at Universit\\`a degli Studi di Genova, in\n  collaboration with Istituto Italiano di Tecnologia. Advisors: Prof. Giorgio\n  Metta and Prof. Lorenzo Rosasco", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size and richness of available datasets grow larger, the opportunities\nfor solving increasingly challenging problems with algorithms learning directly\nfrom data grow at the same pace. Consequently, the capability of learning\nalgorithms to work with large amounts of data has become a crucial scientific\nand technological challenge for their practical applicability. Hence, it is no\nsurprise that large-scale learning is currently drawing plenty of research\neffort in the machine learning research community. In this thesis, we focus on\nkernel methods, a theoretically sound and effective class of learning\nalgorithms yielding nonparametric estimators. Kernel methods, in their\nclassical formulations, are accurate and efficient on datasets of limited size,\nbut do not scale up in a cost-effective manner. Recent research has shown that\napproximate learning algorithms, for instance random subsampling methods like\nNystr\\\"om and random features, with time-memory-accuracy trade-off mechanisms\nare more scalable alternatives. In this thesis, we provide analyses of the\ngeneralization properties and computational requirements of several types of\nsuch approximation schemes. In particular, we expose the tight relationship\nbetween statistics and computations, with the goal of tailoring the accuracy of\nthe learning process to the available computational resources. Our results are\nsupported by experimental evidence on large-scale datasets and numerical\nsimulations. We also study how large-scale learning can be applied to enable\naccurate, efficient, and reactive lifelong learning for robotics. In\nparticular, we propose algorithms allowing robots to learn continuously from\nexperience and adapt to changes in their operational environment. The proposed\nmethods are validated on the iCub humanoid robot in addition to other\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:08:35 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Camoriano", "Raffaello", ""]]}, {"id": "1912.05636", "submitter": "Sudheer Achary", "authors": "Sudheer Achary, K L Bhanu Moorthy, Syed Ashar Javed, Nikita Shravan,\n  Vineet Gandhi, Anoop Namboodiri", "title": "CineFilter: Unsupervised Filtering for Real Time Autonomous Camera\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous camera systems are often subjected to an optimization/filtering\noperation to smoothen and stabilize the rough trajectory estimates. Most common\nfiltering techniques do reduce the irregularities in data; however, they fail\nto mimic the behavior of a human cameraman. Global filtering methods modeling\nhuman camera operators have been successful; however, they are limited to\noffline settings. In this paper, we propose two online filtering methods called\nCinefilters, which produce smooth camera trajectories that are motivated by\ncinematographic principles. The first filter (CineConvex) uses a sliding\nwindow-based convex optimization formulation, and the second (CineCNN) is a CNN\nbased encoder-decoder model. We evaluate the proposed filters in two different\nsettings, namely a basketball dataset and a stage performance dataset. Our\nmodels outperform previous methods and baselines on both quantitative and\nqualitative metrics. The CineConvex and CineCNN filters operate at about 250fps\nand 1000fps, respectively, with a minor latency (half a second), making them\napt for a variety of real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:23:59 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 19:25:24 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 11:53:39 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 10:24:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Achary", "Sudheer", ""], ["Moorthy", "K L Bhanu", ""], ["Javed", "Syed Ashar", ""], ["Shravan", "Nikita", ""], ["Gandhi", "Vineet", ""], ["Namboodiri", "Anoop", ""]]}, {"id": "1912.05637", "submitter": "Giacomo Indiveri", "authors": "Elisabetta Chicca and Giacomo Indiveri", "title": "A recipe for creating ideal hybrid memristive-CMOS neuromorphic\n  computing systems", "comments": null, "journal-ref": null, "doi": "10.1063/1.5142089", "report-no": null, "categories": "cs.ET cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of memristive device technologies has reached a level of\nmaturity to enable the design of complex and large-scale hybrid memristive-CMOS\nneural processing systems. These systems offer promising solutions for\nimplementing novel in-memory computing architectures for machine learning and\ndata analysis problems. We argue that they are also ideal building blocks for\nthe integration in neuromorphic electronic circuits suitable for ultra-low\npower brain-inspired sensory processing systems, therefore leading to the\ninnovative solutions for always-on edge-computing and Internet-of-Things (IoT)\napplications. Here we present a recipe for creating such systems based on\ndesign strategies and computing principles inspired by those used in mammalian\nbrains. We enumerate the specifications and properties of memristive devices\nrequired to support always-on learning in neuromorphic computing systems and to\nminimize their power consumption. Finally, we discuss in what cases such\nneuromorphic systems can complement conventional processing ones and highlight\nthe importance of exploiting the physics of both the memristive devices and of\nthe CMOS circuits interfaced to them.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:24:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chicca", "Elisabetta", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1912.05651", "submitter": "Erik Daxberger", "authors": "Erik Daxberger, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Bayesian Variational Autoencoders for Unsupervised Out-of-Distribution\n  Detection", "comments": "21 pages, extended version with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their successes, deep neural networks may make unreliable predictions\nwhen faced with test data drawn from a distribution different to that of the\ntraining data, constituting a major problem for AI safety. While this has\nrecently motivated the development of methods to detect such\nout-of-distribution (OoD) inputs, a robust solution is still lacking. We\npropose a new probabilistic, unsupervised approach to this problem based on a\nBayesian variational autoencoder model, which estimates a full posterior\ndistribution over the decoder parameters using stochastic gradient Markov chain\nMonte Carlo, instead of fitting a point estimate. We describe how\ninformation-theoretic measures based on this posterior can then be used to\ndetect OoD inputs both in input space and in the model's latent space. We\nempirically demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 21:37:54 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:26:18 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 07:07:28 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Daxberger", "Erik", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1912.05652", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine, Shane Legg, Jan Leike", "title": "Learning Human Objectives by Evaluating Hypothetical Behavior", "comments": "Published at International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to align agent behavior with a user's objectives in a reinforcement\nlearning setting with unknown dynamics, an unknown reward function, and unknown\nunsafe states. The user knows the rewards and unsafe states, but querying the\nuser is expensive. To address this challenge, we propose an algorithm that\nsafely and interactively learns a model of the user's reward function. We start\nwith a generative model of initial states and a forward dynamics model trained\non off-policy data. Our method uses these models to synthesize hypothetical\nbehaviors, asks the user to label the behaviors with rewards, and trains a\nneural network to predict the rewards. The key idea is to actively synthesize\nthe hypothetical behaviors from scratch by maximizing tractable proxies for the\nvalue of information, without interacting with the environment. We call this\nmethod reward query synthesis via trajectory optimization (ReQueST). We\nevaluate ReQueST with simulated users on a state-based 2D navigation task and\nthe image-based Car Racing video game. The results show that ReQueST\nsignificantly outperforms prior methods in learning reward models that transfer\nto new environments with different initial state distributions. Moreover,\nReQueST safely trains the reward model to detect unsafe states, and corrects\nreward hacking before deploying the agent.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:25:48 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 22:26:35 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Reddy", "Siddharth", ""], ["Dragan", "Anca D.", ""], ["Levine", "Sergey", ""], ["Legg", "Shane", ""], ["Leike", "Jan", ""]]}, {"id": "1912.05663", "submitter": "Stephanie Chan", "authors": "Stephanie C.Y. Chan, Samuel Fishman, John Canny, Anoop Korattikara,\n  Sergio Guadarrama", "title": "Measuring the Reliability of Reinforcement Learning Algorithms", "comments": "Accepted for publication at ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lack of reliability is a well-known issue for reinforcement learning (RL)\nalgorithms. This problem has gained increasing attention in recent years, and\nefforts to improve it have grown substantially. To aid RL researchers and\nproduction users with the evaluation and improvement of reliability, we propose\na set of metrics that quantitatively measure different aspects of reliability.\nIn this work, we focus on variability and risk, both during training and after\nlearning (on a fixed policy). We designed these metrics to be general-purpose,\nand we also designed complementary statistical tests to enable rigorous\ncomparisons on these metrics. In this paper, we first describe the desired\nproperties of the metrics and their design, the aspects of reliability that\nthey measure, and their applicability to different scenarios. We then describe\nthe statistical tests and make additional practical recommendations for\nreporting results. The metrics and accompanying statistical tools have been\nmade available as an open-source library at\nhttps://github.com/google-research/rl-reliability-metrics. We apply our metrics\nto a set of common RL algorithms and environments, compare them, and analyze\nthe results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:50:33 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 19:23:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chan", "Stephanie C. Y.", ""], ["Fishman", "Samuel", ""], ["Canny", "John", ""], ["Korattikara", "Anoop", ""], ["Guadarrama", "Sergio", ""]]}, {"id": "1912.05665", "submitter": "V\\'itor Louren\\c{c}o", "authors": "Marcio Moreno, V\\'itor Louren\\c{c}o, Sandro Rama Fiorini, Polyana\n  Costa, Rafael Brand\\~ao, Daniel Civitarese, Renato Cerqueira", "title": "Managing Machine Learning Workflow Components", "comments": "12 pages, 3 figures, to appear at the International Journal of\n  Semantic Computing, 14(2), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning Workflows (MLWfs) have become essential and a disruptive\napproach in problem-solving over several industries. However, the development\nprocess of MLWfs may be complicated, hard to achieve, time-consuming, and\nerror-prone. To handle this problem, in this paper, we introduce machine\nlearning workflow management (MLWfM) as a technique to aid the development and\nreuse of MLWfs and their components through three aspects: representation,\nexecution, and creation. More precisely, we discuss our approach to structure\nthe MLWfs' components and their metadata to aid retrieval and reuse of\ncomponents in new MLWfs. Also, we consider the execution of these components\nwithin a tool. The hybrid knowledge representation, called Hyperknowledge,\nframes our methodology, supporting the three MLWfM's aspects. To validate our\napproach, we show a practical use case in the Oil & Gas industry.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 00:44:06 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 17:20:25 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Moreno", "Marcio", ""], ["Louren\u00e7o", "V\u00edtor", ""], ["Fiorini", "Sandro Rama", ""], ["Costa", "Polyana", ""], ["Brand\u00e3o", "Rafael", ""], ["Civitarese", "Daniel", ""], ["Cerqueira", "Renato", ""]]}, {"id": "1912.05671", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael\n  Carbin", "title": "Linear Mode Connectivity and the Lottery Ticket Hypothesis", "comments": "Published in ICML 2020. This submission subsumes arXiv:1903.01611\n  (\"Stabilizing the Lottery Ticket Hypothesis\" and \"The Lottery Ticket\n  Hypothesis at Scale\")", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study whether a neural network optimizes to the same, linearly connected\nminimum under different samples of SGD noise (e.g., random data order and\naugmentation). We find that standard vision models become stable to SGD noise\nin this way early in training. From then on, the outcome of optimization is\ndetermined to a linearly connected region. We use this technique to study\niterative magnitude pruning (IMP), the procedure used by work on the lottery\nticket hypothesis to identify subnetworks that could have trained in isolation\nto full accuracy. We find that these subnetworks only reach full accuracy when\nthey are stable to SGD noise, which either occurs at initialization for\nsmall-scale settings (MNIST) or early in training for large-scale settings\n(ResNet-50 and Inception-v3 on ImageNet).\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 22:22:21 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 20:39:29 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 19:36:46 GMT"}, {"version": "v4", "created": "Sat, 18 Jul 2020 20:31:17 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Frankle", "Jonathan", ""], ["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""], ["Carbin", "Michael", ""]]}, {"id": "1912.05676", "submitter": "Tom Eccles", "authors": "Tom Eccles, Yoram Bachrach, Guy Lever, Angeliki Lazaridou, Thore\n  Graepel", "title": "Biases for Emergent Communication in Multi-agent Reinforcement Learning", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of emergent communication, in which language arises\nbecause speakers and listeners must communicate information in order to solve\ntasks. In temporally extended reinforcement learning domains, it has proved\nhard to learn such communication without centralized training of agents, due in\npart to a difficult joint exploration problem. We introduce inductive biases\nfor positive signalling and positive listening, which ease this problem. In a\nsimple one-step environment, we demonstrate how these biases ease the learning\nproblem. We also apply our methods to a more extended environment, showing that\nagents with these inductive biases achieve better performance, and analyse the\nresulting communication protocols.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 22:39:51 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Eccles", "Tom", ""], ["Bachrach", "Yoram", ""], ["Lever", "Guy", ""], ["Lazaridou", "Angeliki", ""], ["Graepel", "Thore", ""]]}, {"id": "1912.05686", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Bayesian Hyperparameter Optimization with BoTorch, GPyTorch and Ax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are full of hyperparameters, which are set manually\nbefore the learning process can start. To find the best configuration for these\nhyperparameters in such a high dimensional space, with time-consuming and\nexpensive model training / validation, is not a trivial challenge. Bayesian\noptimization is a powerful tool for the joint optimization of hyperparameters,\nefficiently trading off exploration and exploitation of the hyperparameter\nspace. In this paper, we discuss Bayesian hyperparameter optimization,\nincluding hyperparameter optimization, Bayesian optimization, and Gaussian\nprocesses. We also review BoTorch, GPyTorch and Ax, the new open-source\nframeworks that we use for Bayesian optimization, Gaussian process inference\nand adaptive experimentation, respectively. For experimentation, we apply\nBayesian hyperparameter optimization, for optimizing group weights, to weighted\ngroup pooling, which couples unsupervised tiered graph autoencoders learning\nand supervised graph prediction learning for molecular graphs. We find that Ax,\nBoTorch and GPyTorch together provide a simple-to-use but powerful framework\nfor Bayesian hyperparameter optimization, using Ax's high-level API that\nconstructs and runs a full optimization loop and returns the best\nhyperparameter configuration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:11:40 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 14:22:22 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1912.05687", "submitter": "Omid Bazgir", "authors": "Omid Bazgir, Ruibo Zhang, Saugato Rahman Dhruba, Raziur Rahman,\n  Souparno Ghosh, Ranadip Pal", "title": "REFINED (REpresentation of Features as Images with NEighborhood\n  Dependencies): A novel feature representation for Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-18197-y", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning with Convolutional Neural Networks has shown great promise in\nvarious areas of image-based classification and enhancement but is often\nunsuitable for predictive modeling involving non-image based features or\nfeatures without spatial correlations. We present a novel approach for\nrepresentation of high dimensional feature vector in a compact image form,\ntermed REFINED (REpresentation of Features as Images with NEighborhood\nDependencies), that is conducible for convolutional neural network based deep\nlearning. We consider the correlations between features to generate a compact\nrepresentation of the features in the form of a two-dimensional image using\nminimization of pairwise distances similar to multi-dimensional scaling. We\nhypothesize that this approach enables embedded feature selection and\nintegrated with Convolutional Neural Network based Deep Learning can produce\nmore accurate predictions as compared to Artificial Neural Networks, Random\nForests and Support Vector Regression. We illustrate the superior predictive\nperformance of the proposed representation, as compared to existing approaches,\nusing synthetic datasets, cell line efficacy prediction based on drug chemical\ndescriptors for NCI60 dataset and drug sensitivity prediction based on\ntranscriptomic data and chemical descriptors using GDSC dataset. Results\nillustrated on both synthetic and biological datasets shows the higher\nprediction accuracy of the proposed framework as compared to existing\nmethodologies while maintaining desirable properties in terms of bias and\nfeature extraction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:18:05 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 05:26:15 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Bazgir", "Omid", ""], ["Zhang", "Ruibo", ""], ["Dhruba", "Saugato Rahman", ""], ["Rahman", "Raziur", ""], ["Ghosh", "Souparno", ""], ["Pal", "Ranadip", ""]]}, {"id": "1912.05693", "submitter": "Hao Yan", "authors": "Ziyue Li, Nurettin Dorukhan Sergin, Hao Yan, Chen Zhang, Fugee Tsung", "title": "Tensor Completion for Weakly-dependent Data on Graph for Metro Passenger\n  Flow Prediction", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor decomposition and completion have attracted significant\ninterest from academia given the ubiquity of tensor data. However, the low-rank\nstructure is a global property, which will not be fulfilled when the data\npresents complex and weak dependencies given specific graph structures. One\nparticular application that motivates this study is the spatiotemporal data\nanalysis. As shown in the preliminary study, weakly dependencies can worsen the\nlow-rank tensor completion performance. In this paper, we propose a novel\nlow-rank CANDECOMP / PARAFAC (CP) tensor decomposition and completion framework\nby introducing the $L_{1}$-norm penalty and Graph Laplacian penalty to model\nthe weakly dependency on graph. We further propose an efficient optimization\nalgorithm based on the Block Coordinate Descent for efficient estimation. A\ncase study based on the metro passenger flow data in Hong Kong is conducted to\ndemonstrate improved performance over the regular tensor completion methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:29:25 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Li", "Ziyue", ""], ["Sergin", "Nurettin Dorukhan", ""], ["Yan", "Hao", ""], ["Zhang", "Chen", ""], ["Tsung", "Fugee", ""]]}, {"id": "1912.05695", "submitter": "Baekjin Kim", "authors": "Baekjin Kim, Ambuj Tewari", "title": "Randomized Exploration for Non-Stationary Stochastic Linear Bandits", "comments": "In Proceedings of the 36th Annual Conference on Uncertainty in\n  Artificial Intelligence, 2020. (UAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate two perturbation approaches to overcome conservatism that\noptimism based algorithms chronically suffer from in practice. The first\napproach replaces optimism with a simple randomization when using confidence\nsets. The second one adds random perturbations to its current estimate before\nmaximizing the expected reward. For non-stationary linear bandits, where each\naction is associated with a $d$-dimensional feature and the unknown parameter\nis time-varying with total variation $B_T$, we propose two randomized\nalgorithms, Discounted Randomized LinUCB (D-RandLinUCB) and Discounted Linear\nThompson Sampling (D-LinTS) via the two perturbation approaches. We highlight\nthe statistical optimality versus computational efficiency trade-off between\nthem in that the former asymptotically achieves the optimal dynamic regret\n$\\tilde{\\mathcal{O}}(d ^{2/3}B_T^{1/3} T^{2/3})$, but the latter is\noracle-efficient with an extra logarithmic factor in the number of arms\ncompared to minimax-optimal dynamic regret. In a simulation study, both\nalgorithms show outstanding performance in tackling conservatism issue that\nDiscounted LinUCB struggles with.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:34:12 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 00:33:57 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 18:40:14 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 17:04:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Kim", "Baekjin", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1912.05699", "submitter": "Alvin Chan", "authors": "Alvin Chan, Yi Tay and Yew-Soon Ong", "title": "What it Thinks is Important is Important: Robustness Transfers through\n  Input Gradients", "comments": "Accepted as Oral in CVPR 2020, Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial perturbations are imperceptible changes to input pixels that can\nchange the prediction of deep learning models. Learned weights of models robust\nto such perturbations are previously found to be transferable across different\ntasks but this applies only if the model architecture for the source and target\ntasks is the same. Input gradients characterize how small changes at each input\npixel affect the model output. Using only natural images, we show here that\ntraining a student model's input gradients to match those of a robust teacher\nmodel can gain robustness close to a strong baseline that is robustly trained\nfrom scratch. Through experiments in MNIST, CIFAR-10, CIFAR-100 and\nTiny-ImageNet, we show that our proposed method, input gradient adversarial\nmatching, can transfer robustness across different tasks and even across\ndifferent model architectures. This demonstrates that directly targeting the\nsemantics of input gradients is a feasible way towards adversarial robustness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:51:37 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 07:50:06 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 13:45:16 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chan", "Alvin", ""], ["Tay", "Yi", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "1912.05723", "submitter": "Karthikeyan K", "authors": "Karthikeyan K, Shubham Kumar Bharti, Piyush Rai", "title": "On the relationship between multitask neural networks and multitask\n  Gaussian Processes", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the effectiveness of multitask deep neural network (MTDNN), there is\na limited theoretical understanding on how the information is shared across\ndifferent tasks in MTDNN. In this work, we establish a formal connection\nbetween MTDNN with infinitely-wide hidden layers and multitask Gaussian Process\n(GP). We derive multitask GP kernels corresponding to both single-layer and\ndeep multitask Bayesian neural networks (MTBNN) and show that information among\ndifferent tasks is shared primarily due to correlation across last layer\nweights of MTBNN and shared hyper-parameters, which is contrary to the popular\nhypothesis that information is shared because of shared intermediate layer\nweights. Our construction enables using multitask GP to perform efficient\nBayesian inference for the equivalent MTDNN with infinitely-wide hidden layers.\nPrior work on the connection between deep neural networks and GP for single\ntask settings can be seen as special cases of our construction. We also present\nan adaptive multitask neural network architecture that corresponds to a\nmultitask GP with more flexible kernels, such as Linear Model of\nCoregionalization (LMC) and Cross-Coregionalization (CC) kernels. We provide\nexperimental results to further illustrate these ideas on synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 01:51:35 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["K", "Karthikeyan", ""], ["Bharti", "Shubham Kumar", ""], ["Rai", "Piyush", ""]]}, {"id": "1912.05727", "submitter": "Toru Tamaki", "authors": "Toru Tamaki, Daisuke Ogawa, Bisser Raytchev, Kazufumi Kaneda", "title": "Semantic segmentation of trajectories with improved agent models for\n  pedestrian behavior analysis", "comments": null, "journal-ref": "Advanced Robotics, Volume 33, 2019 - Issue 3-4: Special Issue on\n  Systems Science of Bio-navigation, Pages 153-168", "doi": "10.1080/01691864.2018.1554508", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method for semantic segmentation of pedestrian\ntrajectories based on pedestrian behavior models, or agents. The agents model\nthe dynamics of pedestrian movements in two-dimensional space using a linear\ndynamics model and common start and goal locations of trajectories. First,\nagent models are estimated from the trajectories obtained from image sequences.\nOur method is built on top of the Mixture model of Dynamic pedestrian Agents\n(MDA); however, the MDA's trajectory modeling and estimation are improved.\nThen, the trajectories are divided into semantically meaningful segments. The\nsubsegments of a trajectory are modeled by applying a hidden Markov model using\nthe estimated agent models. Experimental results with a real trajectory dataset\nshow the effectiveness of the proposed method as compared to the well-known\nclassical Ramer-Douglas-Peucker algorithm and also to the original MDA model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 02:04:43 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Tamaki", "Toru", ""], ["Ogawa", "Daisuke", ""], ["Raytchev", "Bisser", ""], ["Kaneda", "Kazufumi", ""]]}, {"id": "1912.05731", "submitter": "Chenye Wu", "authors": "Jingshi Cui, Haoxiang Wang, Chenye Wu, Yang Yu", "title": "Robust Data-driven Profile-based Pricing Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable an efficient electricity market, a good pricing scheme is of vital\nimportance. Among many practical schemes, customized pricing is commonly\nbelieved to be able to best exploit the flexibility in the demand side.\nHowever, due to the large volume of consumers in the electricity sector, such\ntask is simply too overwhelming. In this paper, we first compare two data\ndriven schemes: one based on load profile and the other based on user's\nmarginal system cost. Vulnerability analysis shows that the former approach may\nlead to loopholes in the electricity market while the latter one is able to\nguarantee the robustness, which yields our robust data-driven pricing scheme.\nAlthough k-means clustering is in general NP-hard, surprisingly, by exploiting\nthe structure of our problem, we design an efficient yet optimal k-means\nclustering algorithm to implement our proposed scheme.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 02:06:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Cui", "Jingshi", ""], ["Wang", "Haoxiang", ""], ["Wu", "Chenye", ""], ["Yu", "Yang", ""]]}, {"id": "1912.05737", "submitter": "Pierre Alquier", "authors": "Badr-Eddine Ch\\'erief-Abdellatif, Pierre Alquier", "title": "Finite sample properties of parametric MMD estimation: robustness to\n  misspecification and dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many works in statistics aim at designing a universal estimation procedure,\nthat is, an estimator that would converge to the best approximation of the\n(unknown) data generating distribution in a model, without any assumption on\nthis distribution. This question is of major interest, in particular because\nthe universality property leads to the robustness of the estimator. In this\npaper, we tackle the problem of universal estimation using a minimum distance\nestimator presented in Briol et al. (2019) based on the Maximum Mean\nDiscrepancy. We show that the estimator is robust to both dependence and to the\npresence of outliers in the dataset. Finally, we provide a theoretical study of\nthe stochastic gradient descent algorithm used to compute the estimator, and we\nsupport our findings with numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 02:28:13 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 20:52:14 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 02:11:15 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2020 02:00:55 GMT"}, {"version": "v5", "created": "Thu, 4 Mar 2021 08:52:02 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""], ["Alquier", "Pierre", ""]]}, {"id": "1912.05743", "submitter": "Akanksha Atrey", "authors": "Akanksha Atrey, Kaleigh Clary, David Jensen", "title": "Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps\n  for Deep Reinforcement Learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are frequently used to support explanations of the behavior of\ndeep reinforcement learning (RL) agents. However, a review of how saliency maps\nare used in practice indicates that the derived explanations are often\nunfalsifiable and can be highly subjective. We introduce an empirical approach\ngrounded in counterfactual reasoning to test the hypotheses generated from\nsaliency maps and assess the degree to which they correspond to the semantics\nof RL environments. We use Atari games, a common benchmark for deep RL, to\nevaluate three types of saliency maps. Our results show the extent to which\nexisting claims about Atari games can be evaluated and suggest that saliency\nmaps are best viewed as an exploratory tool rather than an explanatory tool.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 12:42:07 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:40:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Atrey", "Akanksha", ""], ["Clary", "Kaleigh", ""], ["Jensen", "David", ""]]}, {"id": "1912.05752", "submitter": "Ernest Davis", "authors": "Ernest Davis", "title": "The Use of Deep Learning for Symbolic Integration: A Review of (Lample\n  and Charton, 2019)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lample and Charton (2019) describe a system that uses deep learning\ntechnology to compute symbolic, indefinite integrals, and to find symbolic\nsolutions to first- and second-order ordinary differential equations, when the\nsolutions are elementary functions. They found that, over a particular test\nset, the system could find solutions more successfully than sophisticated\npackages for symbolic mathematics such as Mathematica run with a long time-out.\nThis is an impressive accomplishment, as far as it goes. However, the system\ncan handle only a quite limited subset of the problems that Mathematica deals\nwith, and the test set has significant built-in biases. Therefore the claim\nthat this outperforms Mathematica on symbolic integration needs to be very much\nqualified.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:24:36 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 20:51:10 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Davis", "Ernest", ""]]}, {"id": "1912.05753", "submitter": "Ramtin Hosseini", "authors": "Ramtin Hosseini, Neda Hassanpour, Li-Ping Liu and Soha Hassoun", "title": "Pathway-Activity Likelihood Analysis and Metabolite Annotation for\n  Untargeted Metabolomics using Probabilistic Modeling", "comments": "For more details, please visit my homepage at:\n  https://www.eecs.tufts.edu/~ramtin/", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Untargeted metabolomics comprehensively characterizes small\nmolecules and elucidates activities of biochemical pathways within a biological\nsample. Despite computational advances, interpreting collected measurements and\ndetermining their biological role remains a challenge. Results: To interpret\nmeasurements, we present an inference-based approach, termed Probabilistic\nmodeling for Untargeted Metabolomics Analysis (PUMA). Our approach captures\nmeasurements and known information about the sample under study in a generative\nmodel and uses stochastic sampling to compute posterior probability\ndistributions. PUMA predicts the likelihood of pathways being active, and then\nderives a probabilistic annotation, which assigns chemical identities to the\nmeasurements. PUMA is validated on synthetic datasets. When applied to test\ncases, the resulting pathway activities are biologically meaningful and\ndistinctly different from those obtained using statistical pathway enrichment\ntechniques. Annotation results are in agreement to those obtained using other\ntools that utilize additional information in the form of spectral signatures.\nImportantly, PUMA annotates many additional measurements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:26:37 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 04:32:32 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Hosseini", "Ramtin", ""], ["Hassanpour", "Neda", ""], ["Liu", "Li-Ping", ""], ["Hassoun", "Soha", ""]]}, {"id": "1912.05759", "submitter": "Hanchi Liu", "authors": "Bin Liu, Yuxiao Ren, Hanchi Liu, Hui Xu, Zhengfang Wang, Anthony G.\n  Cohn, and Peng Jiang", "title": "GPRInvNet: Deep Learning-Based Ground Penetrating Radar Data Inversion\n  for Tunnel Lining", "comments": "15pages,11figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A DNN architecture called GPRInvNet is proposed to tackle the challenge of\nmapping Ground Penetrating Radar (GPR) B-Scan data to complex permittivity maps\nof subsurface structure. GPRInvNet consists of a trace-to-trace encoder and a\ndecoder. It is specially designed to take account of the characteristics of GPR\ninversion when faced with complex GPR B-Scan data as well as addressing the\nspatial alignment issue between time-series B-Scan data and spatial\npermittivity maps. It fuses features from several adjacent traces on the B-Scan\ndata to enhance each trace, and then further condense the features of each\ntrace separately. The sensitive zone on the permittivity map spatially aligned\nto the enhanced trace is reconstructed accurately. GPRInvNet has been utilized\nto reconstruct the permittivity map of tunnel linings. A diverse range of\ndielectric models of tunnel lining containing complex defects has been\nreconstructed using GPRInvNet, and results demonstrate that GPRInvNet is\ncapable of effectively reconstructing complex tunnel lining defects with clear\nboundaries. Comparative results with existing baseline methods also demonstrate\nthe superiority of the GPRInvNet. To generalize GPRInvNet to real GPR data, we\nintegrated background noise patches recorded form a practical model testing\ninto synthetic GPR data to train GPRInvNet. The model testing has been\nconducted for validation, and experimental results show that GPRInvNet achieves\nsatisfactory results on real data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 03:43:09 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 03:35:45 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Liu", "Bin", ""], ["Ren", "Yuxiao", ""], ["Liu", "Hanchi", ""], ["Xu", "Hui", ""], ["Wang", "Zhengfang", ""], ["Cohn", "Anthony G.", ""], ["Jiang", "Peng", ""]]}, {"id": "1912.05779", "submitter": "Melanie F. Pradier", "authors": "Beau Coker, Melanie F. Pradier, Finale Doshi-Velez", "title": "Towards Expressive Priors for Bayesian Neural Networks: Poisson Process\n  Radial Basis Function Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Bayesian neural networks have many appealing characteristics, current\npriors do not easily allow users to specify basic properties such as expected\nlengthscale or amplitude variance. In this work, we introduce Poisson Process\nRadial Basis Function Networks, a novel prior that is able to encode amplitude\nstationarity and input-dependent lengthscale. We prove that our novel\nformulation allows for a decoupled specification of these properties, and that\nthe estimated regression function is consistent as the number of observations\ntends to infinity. We demonstrate its behavior on synthetic and real examples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 05:37:46 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Coker", "Beau", ""], ["Pradier", "Melanie F.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1912.05783", "submitter": "Dzmitry Bahdanau", "authors": "Dzmitry Bahdanau, Harm de Vries, Timothy J. O'Donnell, Shikhar Murty,\n  Philippe Beaudoin, Yoshua Bengio, Aaron Courville", "title": "CLOSURE: Assessing Systematic Generalization of CLEVR Models", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CLEVR dataset of natural-looking questions about 3D-rendered scenes has\nrecently received much attention from the research community. A number of\nmodels have been proposed for this task, many of which achieved very high\naccuracies of around 97-99%. In this work, we study how systematic the\ngeneralization of such models is, that is to which extent they are capable of\nhandling novel combinations of known linguistic constructs. To this end, we\ntest models' understanding of referring expressions based on matching object\nproperties (such as e.g. \"another cube that is the same size as the brown\ncube\") in novel contexts. Our experiments on the thereby constructed CLOSURE\nbenchmark show that state-of-the-art models often do not exhibit systematicity\nafter being trained on CLEVR. Surprisingly, we find that an explicitly\ncompositional Neural Module Network model also generalizes badly on CLOSURE,\neven when it has access to the ground-truth programs at test time. We improve\nthe NMN's systematic generalization by developing a novel Vector-NMN module\narchitecture with vector-valued inputs and outputs. Lastly, we investigate how\nmuch few-shot transfer learning can help models that are pretrained on CLEVR to\nadapt to CLOSURE. Our few-shot learning experiments contrast the adaptation\nbehavior of the models with intermediate discrete programs with that of the\nend-to-end continuous models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 05:56:53 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 23:58:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bahdanau", "Dzmitry", ""], ["de Vries", "Harm", ""], ["O'Donnell", "Timothy J.", ""], ["Murty", "Shikhar", ""], ["Beaudoin", "Philippe", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1912.05784", "submitter": "Yaoxin Wu", "authors": "Yaoxin Wu, Wen Song, Zhiguang Cao, Jie Zhang, Andrew Lim", "title": "Learning Improvement Heuristics for Solving Routing Problems", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in using deep learning to solve routing problems focus on\nconstruction heuristics, the solutions of which are still far from optimality.\nImprovement heuristics have great potential to narrow this gap by iteratively\nrefining a solution. However, classic improvement heuristics are all guided by\nhand-crafted rules which may limit their performance. In this paper, we propose\na deep reinforcement learning framework to learn the improvement heuristics for\nrouting problems. We design a self-attention based deep architecture as the\npolicy network to guide the selection of next solution. We apply our method to\ntwo important routing problems, i.e. travelling salesman problem (TSP) and\ncapacitated vehicle routing problem (CVRP). Experiments show that our method\noutperforms state-of-the-art deep learning based approaches. The learned\npolicies are more effective than the traditional hand-crafted ones, and can be\nfurther enhanced by simple diversifying strategies. Moreover, the policies\ngeneralize well to different problem sizes, initial solutions and even\nreal-world dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 05:57:58 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 14:21:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Wu", "Yaoxin", ""], ["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Lim", "Andrew", ""]]}, {"id": "1912.05796", "submitter": "Haoyu Yang", "authors": "Haoyu Yang, Wen Chen, Piyush Pathak, Frank Gennari, Ya-Chieh Lai, Bei\n  Yu", "title": "Automatic Layout Generation with Applications in Machine Learning Engine\n  Evaluation", "comments": "6 pages, submitted to 1st ACM/IEEE Workshop on Machine Learning for\n  CAD (MLCAD) for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based lithography hotspot detection has been deeply studied\nrecently, from varies feature extraction techniques to efficient learning\nmodels. It has been observed that such machine learning-based frameworks are\nproviding satisfactory metal layer hotspot prediction results on known public\nmetal layer benchmarks. In this work, we seek to evaluate how these machine\nlearning-based hotspot detectors generalize to complicated patterns. We first\nintroduce a automatic layout generation tool that can synthesize varies layout\npatterns given a set of design rules. The tool currently supports both metal\nlayer and via layer generation. As a case study, we conduct hotspot detection\non the generated via layer layouts with representative machine learning-based\nhotspot detectors, which shows that continuous study on model robustness and\ngenerality is necessary to prototype and integrate the learning engines in DFM\nflows. The source code of the layout generation tool will be available at\nhttps://github. com/phdyang007/layout-generation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 06:52:12 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yang", "Haoyu", ""], ["Chen", "Wen", ""], ["Pathak", "Piyush", ""], ["Gennari", "Frank", ""], ["Lai", "Ya-Chieh", ""], ["Yu", "Bei", ""]]}, {"id": "1912.05827", "submitter": "Giyoung Jeon", "authors": "Giyoung Jeon, Haedong Jeong and Jaesik Choi", "title": "An Efficient Explorative Sampling Considering the Generative Boundaries\n  of Deep Generative Neural Networks", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative neural networks (DGNNs) have achieved realistic and\nhigh-quality data generation. In particular, the adversarial training scheme\nhas been applied to many DGNNs and has exhibited powerful performance. Despite\nof recent advances in generative networks, identifying the image generation\nmechanism still remains challenging. In this paper, we present an explorative\nsampling algorithm to analyze generation mechanism of DGNNs. Our method\nefficiently obtains samples with identical attributes from a query image in a\nperspective of the trained model. We define generative boundaries which\ndetermine the activation of nodes in the internal layer and probe inside the\nmodel with this information. To handle a large number of boundaries, we obtain\nthe essential set of boundaries using optimization. By gathering samples within\nthe region surrounded by generative boundaries, we can empirically reveal the\ncharacteristics of the internal layers of DGNNs. We also demonstrate that our\nalgorithm can find more homogeneous, the model specific samples compared to the\nvariations of {\\epsilon}-based sampling method.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:27:46 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Jeon", "Giyoung", ""], ["Jeong", "Haedong", ""], ["Choi", "Jaesik", ""]]}, {"id": "1912.05830", "submitter": "Zhuoran Yang", "authors": "Qi Cai, Zhuoran Yang, Chi Jin, Zhaoran Wang", "title": "Provably Efficient Exploration in Policy Optimization", "comments": "We have fixed a technical issue in the first version of this paper.\n  We remark the technical assumption of the linear MDP in this version of the\n  paper is different from that in the first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While policy-based reinforcement learning (RL) achieves tremendous successes\nin practice, it is significantly less understood in theory, especially compared\nwith value-based RL. In particular, it remains elusive how to design a provably\nefficient policy optimization algorithm that incorporates exploration. To\nbridge such a gap, this paper proposes an Optimistic variant of the Proximal\nPolicy Optimization algorithm (OPPO), which follows an ``optimistic version''\nof the policy gradient direction. This paper proves that, in the problem of\nepisodic Markov decision process with linear function approximation, unknown\ntransition, and adversarial reward with full-information feedback, OPPO\nachieves $\\tilde{O}(\\sqrt{d^2 H^3 T} )$ regret. Here $d$ is the feature\ndimension, $H$ is the episode horizon, and $T$ is the total number of steps. To\nthe best of our knowledge, OPPO is the first provably efficient policy\noptimization algorithm that explores.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:40:02 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 17:38:42 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 17:38:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Cai", "Qi", ""], ["Yang", "Zhuoran", ""], ["Jin", "Chi", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1912.05831", "submitter": "Shayan Hassantabar", "authors": "Shayan Hassantabar, Xiaoliang Dai, Niraj K. Jha", "title": "STEERAGE: Synthesis of Neural Networks Using Architecture Search and\n  Grow-and-Prune Methods", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks (NNs) have been successfully deployed in many applications.\nHowever, architectural design of these models is still a challenging problem.\nMoreover, neural networks are known to have a lot of redundancy. This increases\nthe computational cost of inference and poses an obstacle to deployment on\nInternet-of-Thing sensors and edge devices. To address these challenges, we\npropose the STEERAGE synthesis methodology. It consists of two complementary\napproaches: efficient architecture search, and grow-and-prune NN synthesis. The\nfirst step, covered in a global search module, uses an accuracy predictor to\nefficiently navigate the architectural search space. The predictor is built\nusing boosted decision tree regression, iterative sampling, and efficient\nevolutionary search. The second step involves local search. By using various\ngrow-and-prune methodologies for synthesizing convolutional and feed-forward\nNNs, it reduces the network redundancy, while boosting its performance. We have\nevaluated STEERAGE performance on various datasets, including MNIST and\nCIFAR-10. On MNIST dataset, our CNN architecture achieves an error rate of\n0.66%, with 8.6x fewer parameters compared to the LeNet-5 baseline. For the\nCIFAR-10 dataset, we used the ResNet architectures as the baseline. Our\nSTEERAGE-synthesized ResNet-18 has a 2.52% accuracy improvement over the\noriginal ResNet-18, 1.74% over ResNet-101, and 0.16% over ResNet-1001, while\nhaving comparable number of parameters and FLOPs to the original ResNet-18.\nThis shows that instead of just increasing the number of layers to increase\naccuracy, an alternative is to use a better NN architecture with fewer layers.\nIn addition, STEERAGE achieves an error rate of just 3.86% with a variant of\nResNet architecture with 40 layers. To the best of our knowledge, this is the\nhighest accuracy obtained by ResNet-based architectures on the CIFAR-10\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:42:13 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Hassantabar", "Shayan", ""], ["Dai", "Xiaoliang", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1912.05833", "submitter": "Triantafyllos Kefalas", "authors": "Triantafyllos Kefalas, Konstantinos Vougioukas, Yannis Panagakis,\n  Stavros Petridis, Jean Kossaifi, Maja Pantic", "title": "Speech-driven facial animation using polynomial fusion of features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-driven facial animation involves using a speech signal to generate\nrealistic videos of talking faces. Recent deep learning approaches to facial\nsynthesis rely on extracting low-dimensional representations and concatenating\nthem, followed by a decoding step of the concatenated vector. This accounts for\nonly first-order interactions of the features and ignores higher-order\ninteractions. In this paper we propose a polynomial fusion layer that models\nthe joint representation of the encodings by a higher-order polynomial, with\nthe parameters modelled by a tensor decomposition. We demonstrate the\nsuitability of this approach through experiments on generated videos evaluated\non a range of metrics on video quality, audiovisual synchronisation and\ngeneration of blinks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:46:57 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:36:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Kefalas", "Triantafyllos", ""], ["Vougioukas", "Konstantinos", ""], ["Panagakis", "Yannis", ""], ["Petridis", "Stavros", ""], ["Kossaifi", "Jean", ""], ["Pantic", "Maja", ""]]}, {"id": "1912.05845", "submitter": "Anthony Ortiz", "authors": "Anthony Ortiz, Caleb Robinson, Dan Morris, Olac Fuentes, Christopher\n  Kiekintveld, Md Mahmudulla Hassan and Nebojsa Jojic", "title": "Local Context Normalization: Revisiting Local Normalization", "comments": "Accepted as a CVPR 2020 oral paper. arXiv admin note: text overlap\n  with arXiv:1803.08494 by other authors", "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers have been shown to improve convergence in deep neural\nnetworks, and even add useful inductive biases. In many vision applications the\nlocal spatial context of the features is important, but most common\nnormalization schemes including Group Normalization (GN), Instance\nNormalization (IN), and Layer Normalization (LN) normalize over the entire\nspatial dimension of a feature. This can wash out important signals and degrade\nperformance. For example, in applications that use satellite imagery, input\nimages can be arbitrarily large; consequently, it is nonsensical to normalize\nover the entire area. Positional Normalization (PN), on the other hand, only\nnormalizes over a single spatial position at a time. A natural compromise is to\nnormalize features by local context, while also taking into account group level\ninformation. In this paper, we propose Local Context Normalization (LCN): a\nnormalization layer where every feature is normalized based on a window around\nit and the filters in its group. We propose an algorithmic solution to make LCN\nefficient for arbitrary window sizes, even if every point in the image has a\nunique window. LCN outperforms its Batch Normalization (BN), GN, IN, and LN\ncounterparts for object detection, semantic segmentation, and instance\nsegmentation applications in several benchmark datasets, while keeping\nperformance independent of the batch size and facilitating transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 09:28:24 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 06:22:50 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 09:27:12 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ortiz", "Anthony", ""], ["Robinson", "Caleb", ""], ["Morris", "Dan", ""], ["Fuentes", "Olac", ""], ["Kiekintveld", "Christopher", ""], ["Hassan", "Md Mahmudulla", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1912.05846", "submitter": "Jonathan Heras", "authors": "\\'Angela Casado-Garc\\'ia and C\\'esar Dom\\'inguez and J\\'onathan Heras\n  and Eloy Mata and Vico Pascual", "title": "The Benefits of Close-Domain Fine-Tuning for Table Detection in Document\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A correct localisation of tables in a document is instrumental for\ndetermining their structure and extracting their contents; therefore, table\ndetection is a key step in table understanding. Nowadays, the most successful\nmethods for table detection in document images employ deep learning algorithms;\nand, particularly, a technique known as fine-tuning. In this context, such a\ntechnique exports the knowledge acquired to detect objects in natural images to\ndetect tables in document images. However, there is only a vague relation\nbetween natural and document images, and fine-tuning works better when there is\na close relation between the source and target task. In this paper, we show\nthat it is more beneficial to employ fine-tuning from a closer domain. To this\naim, we train different object detection algorithms (namely, Mask R-CNN,\nRetinaNet, SSD and YOLO) using the TableBank dataset (a dataset of images of\nacademic documents designed for table detection and recognition), and fine-tune\nthem for several heterogeneous table detection datasets. Using this approach,\nwe considerably improve the accuracy of the detection models fine-tuned from\nnatural images (in mean a 17%, and, in the best case, up to a 60%).\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 09:30:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Casado-Garc\u00eda", "\u00c1ngela", ""], ["Dom\u00ednguez", "C\u00e9sar", ""], ["Heras", "J\u00f3nathan", ""], ["Mata", "Eloy", ""], ["Pascual", "Vico", ""]]}, {"id": "1912.05879", "submitter": "Johan Medrano", "authors": "Johan Medrano, Fuchun Joseph Lin", "title": "Enabling Machine Learning Across Heterogeneous Sensor Networks with\n  Graph Autoencoders", "comments": null, "journal-ref": "Chatzigiannakis I., De Ruyter B., Mavrommati I. (eds) Ambient\n  Intelligence. AmI 2019. Lecture Notes in Computer Science, vol 11912.\n  Springer, Cham", "doi": "10.1007/978-3-030-34255-5_11", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) has been applied to enable many life-assisting\nappli-cations, such as abnormality detection and emdergency request for the\nsoli-tary elderly. However, in most cases machine learning algorithms depend on\nthe layout of the target Internet of Things (IoT) sensor network. Hence, to\ndeploy an application across Heterogeneous Sensor Networks (HSNs), i.e. sensor\nnetworks with different sensors type or layouts, it is required to repeat the\nprocess of data collection and ML algorithm training. In this paper, we\nintroduce a novel framework leveraging deep learning for graphs to enable using\nthe same activity recognition system across HSNs deployed in differ-ent smart\nhomes. Using our framework, we were able to transfer activity classifiers\ntrained with activity labels on a source HSN to a target HSN, reaching about\n75% of the baseline accuracy on the target HSN without us-ing target activity\nlabels. Moreover, our model can quickly adapt to unseen sensor layouts, which\nmakes it highly suitable for the gradual deployment of real-world ML-based\napplications. In addition, we show that our framework is resilient to\nsuboptimal graph representations of HSNs.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 11:14:12 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Medrano", "Johan", ""], ["Lin", "Fuchun Joseph", ""]]}, {"id": "1912.05881", "submitter": "Orazio Angelini", "authors": "Orazio Angelini, Alexis Moinet, Kayoko Yanagisawa, Thomas Drugman", "title": "Singing Synthesis: with a little help from my attention", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present UTACO, a singing synthesis model based on an attention-based\nsequence-to-sequence mechanism and a vocoder based on dilated causal\nconvolutions. These two classes of models have significantly affected the field\nof text-to-speech, but have never been thoroughly applied to the task of\nsinging synthesis. UTACO demonstrates that attention can be successfully\napplied to the singing synthesis field and improves naturalness over the state\nof the art. The system requires considerably less explicit modelling of voice\nfeatures such as F0 patterns, vibratos, and note and phoneme durations, than\nprevious models in the literature. Despite this, it shows a strong improvement\nin naturalness with respect to previous neural singing synthesis models. The\nmodel does not require any durations or pitch patterns as inputs, and learns to\ninsert vibrato autonomously according to the musical context. However, we\nobserve that, by completely dispensing with any explicit duration modelling it\nbecomes harder to obtain the fine control of timing needed to exactly match the\ntempo of a song.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 11:17:30 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 12:12:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Angelini", "Orazio", ""], ["Moinet", "Alexis", ""], ["Yanagisawa", "Kayoko", ""], ["Drugman", "Thomas", ""]]}, {"id": "1912.05897", "submitter": "Runhua Xu", "authors": "Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar and Heiko Ludwig", "title": "HybridAlpha: An Efficient Approach for Privacy-Preserving Federated\n  Learning", "comments": "12 pages, AISec 2019", "journal-ref": null, "doi": "10.1145/3338501.3357371", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning has emerged as a promising approach for collaborative and\nprivacy-preserving learning. Participants in a federated learning process\ncooperatively train a model by exchanging model parameters instead of the\nactual training data, which they might want to keep private. However, parameter\ninteraction and the resulting model still might disclose information about the\ntraining data used. To address these privacy concerns, several approaches have\nbeen proposed based on differential privacy and secure multiparty computation\n(SMC), among others. They often result in large communication overhead and slow\ntraining time. In this paper, we propose HybridAlpha, an approach for\nprivacy-preserving federated learning employing an SMC protocol based on\nfunctional encryption. This protocol is simple, efficient and resilient to\nparticipants dropping out. We evaluate our approach regarding the training time\nand data volume exchanged using a federated learning process to train a CNN on\nthe MNIST data set. Evaluation against existing crypto-based SMC solutions\nshows that HybridAlpha can reduce the training time by 68% and data transfer\nvolume by 92% on average while providing the same model performance and privacy\nguarantees as the existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 12:37:39 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Xu", "Runhua", ""], ["Baracaldo", "Nathalie", ""], ["Zhou", "Yi", ""], ["Anwar", "Ali", ""], ["Ludwig", "Heiko", ""]]}, {"id": "1912.05901", "submitter": "Llu\\'is Antoni Jim\\'enez Rugama", "authors": "Giuseppe Nuti and Llu\\'is Antoni Jim\\'enez Rugama and Kaspar Thommen", "title": "Adaptive Bayesian Reticulum", "comments": "23 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks and Decision Trees: two popular techniques for supervised\nlearning that are seemingly disconnected in their formulation and optimization\nmethod, have recently been combined in a single construct. The connection\npivots on assembling an artificial Neural Network with nodes that allow for a\ngate-like function to mimic a tree split, optimized using the standard approach\nof recursively applying the chain rule to update its parameters. Yet two main\nchallenges have impeded wide use of this hybrid approach: (a) the inability of\nglobal gradient ascent techniques to optimize hierarchical parameters (as\nintroduced by the gate function); and (b) the construction of the tree\nstructure, which has relied on standard decision tree algorithms to learn the\nnetwork topology or incrementally (and heuristically) searching the space at\nrandom. Here we propose a probabilistic construct that exploits the idea of a\nnode's unexplained potential (the total error channeled through the node) in\norder to decide where to expand further, mimicking the standard tree\nconstruction in a Neural Network setting, alongside a modified gradient ascent\nthat first locally optimizes an expanded node before a global optimization. The\nprobabilistic approach allows us to evaluate each new split as a ratio of\nlikelihoods that balances the statistical improvement in explaining the\nevidence against the additional model complexity --- thus providing a natural\nstopping condition. The result is a novel classification and regression\ntechnique that leverages the strength of both: a tree-structure that grows\nnaturally and is simple to interpret with the plasticity of Neural Networks\nthat allow for soft margins and slanted boundaries.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 12:54:48 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 13:36:40 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:16:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Nuti", "Giuseppe", ""], ["Rugama", "Llu\u00eds Antoni Jim\u00e9nez", ""], ["Thommen", "Kaspar", ""]]}, {"id": "1912.05903", "submitter": "Weikaixin Kong", "authors": "Weikaixin Kong, Xinyu Tu, Zhengwei Xie and Zhuo Huang", "title": "Prediction and optimization of NaV1.7 inhibitors based on machine\n  learning methods", "comments": "The evaluation of the model in the results section of this article is\n  not comprehensive enough.We will carry out further work. The article needs to\n  be polished. There are certain disadvantages to the molecular optimization\n  method. The discussion part is not deep enough, so withdraw is needed", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We used machine learning methods to predict NaV1.7 inhibitors and found the\nmodel RF-CDK that performed best on the imbalanced dataset. Using the RF-CDK\nmodel for screening drugs, we got effective compounds K1. We use the cell patch\nclamp method to verify K1. However, because the model evaluation method in this\narticle is not comprehensive enough, there is still a lot of research work to\nbe performed, such as comparison with other existing methods.\n  The target protein has multiple active sites and requires our further\nresearch. We need more detailed models to consider this biological process and\ncompare it with the current results, which is an error in this article.\n  So we want to withdraw this article.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:56:03 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 10:01:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kong", "Weikaixin", ""], ["Tu", "Xinyu", ""], ["Xie", "Zhengwei", ""], ["Huang", "Zhuo", ""]]}, {"id": "1912.05905", "submitter": "Radu Alexandru Rosu", "authors": "Radu Alexandru Rosu, Peer Sch\\\"utt, Jan Quenzel, Sven Behnke", "title": "LatticeNet: Fast Point Cloud Segmentation Using Permutohedral Lattices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have shown outstanding performance\nin the task of semantically segmenting images. However, applying the same\nmethods on 3D data still poses challenges due to the heavy memory requirements\nand the lack of structured data. Here, we propose LatticeNet, a novel approach\nfor 3D semantic segmentation, which takes as input raw point clouds. A PointNet\ndescribes the local geometry which we embed into a sparse permutohedral\nlattice. The lattice allows for fast convolutions while keeping a low memory\nfootprint. Further, we introduce DeformSlice, a novel learned data-dependent\ninterpolation for projecting lattice features back onto the point cloud. We\npresent results of 3D segmentation on various datasets where our method\nachieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 13:01:36 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 15:29:58 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 16:33:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Rosu", "Radu Alexandru", ""], ["Sch\u00fctt", "Peer", ""], ["Quenzel", "Jan", ""], ["Behnke", "Sven", ""]]}, {"id": "1912.05906", "submitter": "Felix Axel Gimeno Gil", "authors": "Xujie Si, Yujia Li, Vinod Nair, Felix Gimeno", "title": "Prioritized Unit Propagation with Periodic Resetting is (Almost) All You\n  Need for Random SAT Solving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose prioritized unit propagation with periodic resetting, which is a\nsimple but surprisingly effective algorithm for solving random SAT instances\nthat are meant to be hard. In particular, an evaluation on the Random Track of\nthe 2017 and 2018 SAT competitions shows that a basic prototype of this simple\nidea already ranks at second place in both years. We share this observation in\nthe hope that it helps the SAT community better understand the hardness of\nrandom instances used in competitions and inspire other interesting ideas on\nSAT solving.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:57:02 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Si", "Xujie", ""], ["Li", "Yujia", ""], ["Nair", "Vinod", ""], ["Gimeno", "Felix", ""]]}, {"id": "1912.05910", "submitter": "Tianfan Fu", "authors": "Tianfan Fu, Cao Xiao, Jimeng Sun", "title": "CORE: Automatic Molecule Optimization Using Copy & Refine Strategy", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule optimization is about generating molecule $Y$ with more desirable\nproperties based on an input molecule $X$. The state-of-the-art approaches\npartition the molecules into a large set of substructures $S$ and grow the new\nmolecule structure by iteratively predicting which substructure from $S$ to\nadd. However, since the set of available substructures $S$ is large, such an\niterative prediction task is often inaccurate especially for substructures that\nare infrequent in the training data. To address this challenge, we propose a\nnew generating strategy called \"Copy & Refine\" (CORE), where at each step the\ngenerator first decides whether to copy an existing substructure from input $X$\nor to generate a new substructure, then the most promising substructure will be\nadded to the new molecule. Combining together with scaffolding tree generation\nand adversarial training, CORE can significantly improve several latest\nmolecule optimization methods in various measures including drug likeness\n(QED), dopamine receptor (DRD2) and penalized LogP. We tested CORE and\nbaselines using the ZINC database and CORE obtained up to 11% and 21%\nrelatively improvement over the baselines on success rate on the complete test\nset and the subset with infrequent substructures, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 23:02:31 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Fu", "Tianfan", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "1912.05911", "submitter": "Robin Marc Schmidt", "authors": "Robin M. Schmidt", "title": "Recurrent Neural Networks (RNNs): A gentle Introduction and Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art solutions in the areas of \"Language Modelling & Generating\nText\", \"Speech Recognition\", \"Generating Image Descriptions\" or \"Video Tagging\"\nhave been using Recurrent Neural Networks as the foundation for their\napproaches. Understanding the underlying concepts is therefore of tremendous\nimportance if we want to keep up with recent or upcoming publications in those\nareas. In this work we give a short overview over some of the most important\nconcepts in the realm of Recurrent Neural Networks which enables readers to\neasily understand the fundamentals such as but not limited to \"Backpropagation\nthrough Time\" or \"Long Short-Term Memory Units\" as well as some of the more\nrecent advances like the \"Attention Mechanism\" or \"Pointer Networks\". We also\ngive recommendations for further reading regarding more complex topics where it\nis necessary.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 06:36:13 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Schmidt", "Robin M.", ""]]}, {"id": "1912.05912", "submitter": "Md. Abu Bakr Siddique", "authors": "Md. Abu Bakr Siddique, Shadman Sakib, Md. Abdur Rahman", "title": "Performance Analysis of Deep Autoencoder and NCA Dimensionality\n  Reduction Techniques with KNN, ENN and SVM Classifiers", "comments": "2nd International Conference on Innovation in Engineering and\n  Technology (ICIET)", "journal-ref": "2019 2nd International Conference on Innovation in Engineering and\n  Technology (ICIET)", "doi": "10.1109/ICIET48527.2019.9290722", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The central aim of this paper is to implement Deep Autoencoder and\nNeighborhood Components Analysis (NCA) dimensionality reduction methods in\nMatlab and to observe the application of these algorithms on nine unlike\ndatasets from UCI machine learning repository. These datasets are CNAE9,\nMovement Libras, Pima Indians diabetes, Parkinsons, Knowledge, Segmentation,\nSeeds, Mammographic Masses, and Ionosphere. First of all, the dimension of\nthese datasets has been reduced to fifty percent of their original dimension by\nselecting and extracting the most relevant and appropriate features or\nattributes using Deep Autoencoder and NCA dimensionality reduction techniques.\nAfterward, each dataset is classified applying K-Nearest Neighbors (KNN),\nExtended Nearest Neighbors (ENN) and Support Vector Machine (SVM)\nclassification algorithms. All classification algorithms are developed in the\nMatlab environment. In each classification, the training test data ratio is\nalways set to ninety percent: ten percent. Upon classification, variation\nbetween accuracies is observed and analyzed to find the degree of compatibility\nof each dimensionality reduction technique with each classifier and to evaluate\neach classifier performance on each dataset.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:47:26 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 16:20:37 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 12:44:42 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Siddique", "Md. Abu Bakr", ""], ["Sakib", "Shadman", ""], ["Rahman", "Md. Abdur", ""]]}, {"id": "1912.05913", "submitter": "Alireza Abdoli", "authors": "Alireza Abdoli, Amy C. Murillo, Alec C. Gerry, Eamonn J. Keogh", "title": "Time Series Classification: Lessons Learned in the (Literal) Field while\n  Studying Chicken Behavior", "comments": "arXiv admin note: text overlap with arXiv:1811.03149", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005596", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poultry farms are a major contributor to the human food chain. However,\naround the world, there have been growing concerns about the quality of life\nfor the livestock in poultry farms; and increasingly vocal demands for improved\nstandards of animal welfare. Recent advances in sensing technologies and\nmachine learning allow the possibility of monitoring birds, and employing the\nlessons learned to improve the welfare for all birds. This task superficially\nappears to be easy, yet, studying behavioral patterns involves collecting\nenormous amounts of data, justifying the term Big Data. Before the big data can\nbe used for analytical purposes to tease out meaningful, well-conserved\nbehavioral patterns, the collected data needs to be pre-processed. The\npre-processing refers to processes for cleansing and preparing data so that it\nis in the format ready to be analyzed by downstream algorithms, such as\nclassification and clustering algorithms. However, as we shall demonstrate,\nefficient pre-processing of chicken big data is both non-trivial and crucial\ntowards success of further analytics.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:57:47 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 19:48:04 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Abdoli", "Alireza", ""], ["Murillo", "Amy C.", ""], ["Gerry", "Alec C.", ""], ["Keogh", "Eamonn J.", ""]]}, {"id": "1912.05915", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Some observations concerning Off Training Set (OTS) error", "comments": "Technical Report, Australian National University, August 1999", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A form of generalisation error known as Off Training Set (OTS) error was\nrecently introduced in [Wolpert, 1996b], along with a theorem showing that\nsmall training set error does not guarantee small OTS error, unless assumptions\nare made about the target function. Here it is shown that the applicability of\nthis theorem is limited to models in which the distribution generating training\ndata has no overlap with the distribution generating test data. It is argued\nthat such a scenario is of limited relevance to machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:01:10 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "1912.05916", "submitter": "Konno Tomohiko", "authors": "Tomohiko Konno", "title": "Deep-Learning Estimation of Band Gap with the Reading-Periodic-Table\n  Method and Periodic Convolution Layer", "comments": "11 pages for body", "journal-ref": "Journal of the Physical Society of Japan (2020)", "doi": "10.7566/JPSJ.89.124006", "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We verified that the deep learning method named reading periodic table\nintroduced by ref. Deep Learning Model for Finding New Superconductors, which\nutilizes deep learning to read the periodic table and the laws of the elements,\nis applicable not only for superconductors, for which the method was originally\napplied but also for other problems of materials by demonstrating band gap\nestimations. We then extended the method to learn the laws better by directly\nlearning the cylindrical periodicity between the right- and left-most columns\nin the periodic table at the learning representation level, that is, by\nconsidering the left- and right-most columns to be adjacent to each other.\nThus, while the original method handles the table as is, the extended method\ntreats the periodic table as if its two edges are connected. This is achieved\nusing novel layers named periodic convolution layers, which can handle inputs\nexhibiting periodicity and may be applied to other problems related to computer\nvision, time series, and so on for data that possess some periodicity. In the\nreading periodic table method, no material feature or descriptor is required as\ninput. We demonstrated two types of deep learning estimation: methods to\nestimate the existence of a bandgap, and methods to estimate the value of the\nbandgap given when the existence of the bandgap in the materials is known.\nFinally, we discuss the limitations of the dataset and model evaluation method.\nWe may be unable to distinguish good models based on the random train-test\nsplit scheme; thus, we must prepare an appropriate dataset where the training\nand test data are temporally separate. The code and data are open.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 14:45:11 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 09:09:28 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 07:27:30 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 09:05:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Konno", "Tomohiko", ""]]}, {"id": "1912.05920", "submitter": "Xuewen Yao", "authors": "Xuewen Yao, Dong He, Tiancheng Jing, Kaya de Barbaro", "title": "Measuring Mother-Infant Emotions By Audio Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been suggested in developmental psychology literature that the\ncommunication of affect between mothers and their infants correlates with the\nsocioemotional and cognitive development of infants. In this study, we obtained\nday-long audio recordings of 10 mother-infant pairs in order to study their\naffect communication in speech with a focus on mother's speech. In order to\nbuild a model for speech emotion detection, we used the Ryerson Audio-Visual\nDatabase of Emotional Speech and Song (RAVDESS) and trained a Convolutional\nNeural Nets model which is able to classify 6 different emotions at 70%\naccuracy. We applied our model to mother's speech and found the dominant\nemotions were angry and sad, which were not true. Based on our own\nobservations, we concluded that emotional speech databases made with the help\nof actors cannot generalize well to real-life settings, suggesting an active\nlearning or unsupervised approach in the future.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:49:35 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yao", "Xuewen", ""], ["He", "Dong", ""], ["Jing", "Tiancheng", ""], ["de Barbaro", "Kaya", ""]]}, {"id": "1912.05934", "submitter": "Supreetha B S", "authors": "Supreetha B.S, Narayan Shenoy and Prabhakar Nayak", "title": "Lion Algorithm- Optimized Long Short-Term Memory Network for Groundwater\n  Level Forecasting in Udupi District, India", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Groundwater is a precious natural resource. Groundwater level (GWL)\nforecasting is crucial in the field of water resource management. Measurement\nof GWL from observation-wells is the principle source of information about the\naquifer and is critical to its evaluation. Most part of the Udupi district of\nKarnataka State in India consists of geological formations: lateritic terrain\nand gneissic complex. Due to the topographical ruggedness and inconsistency in\nrainfall, the GWL in Udupi region is declining continually and most of the open\nwells are drying-up during the summer. Hence, the current research aimed at\ndeveloping a groundwater level forecasting model by using hybrid Long\nShort-term Memory-Lion Algorithm (LSTM-LA). The historical GWL and rainfall\ndata from an observation well from Udupi district, located in Karnataka state,\nIndia, were used to develop the model. The prediction accuracy of the hybrid\nLSTM-LA model was better than that of the Feedforward Neural network (FFNN) and\nthe isolated LSTM models. The hybrid LSTM-LA based forecasting model is\npromising for a larger dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 09:51:47 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["S", "Supreetha B.", ""], ["Shenoy", "Narayan", ""], ["Nayak", "Prabhakar", ""]]}, {"id": "1912.05944", "submitter": "Yifan Gao", "authors": "Yifan Gao, Vicente A. Gonzalez, Tak Wing Yiu, and Guillermo\n  Cabrera-Guerrerod", "title": "Non-linearity identification for construction workers'\n  personality-safety behaviour predictive relationship using neural network and\n  linear regression modelling", "comments": "The manuscript is currently undergoing a major revision as some\n  contents in its current form are not scientifically rigorous and can be\n  misleading to potential readers. Thus, we apply for withdrawal of the\n  manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of workers' safety behaviour can help identify vulnerable\nworkers who intend to undertake unsafe behaviours and be useful in the design\nof management practices to minimise the occurrence of accidents. The latest\nliterature has evidenced that there is within-population diversity that leads\npeople's intended safety behaviours in the workplace, which are found to vary\namong individuals as a function of their personality traits. In this study, an\ninnovative forecasting model, which employs neural network algorithms, is\ndeveloped to numerically simulate the predictive relationship between\nconstruction workers' personality traits and their intended safety behaviour.\nThe data-driven nature of neural network enabled a reliable estimate of the\nrelationship, which allowed this research to find that a nonlinear effect\nexists in the relationship. This research has practical implications. The\nneural network developed is shown to have highly satisfactory prediction\naccuracy and is thereby potentially useful for assisting project\ndecision-makers to assess how prone workers are to carry out unsafe behaviours\nin the workplace.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:51:56 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:06:27 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 13:05:32 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Gao", "Yifan", ""], ["Gonzalez", "Vicente A.", ""], ["Yiu", "Tak Wing", ""], ["Cabrera-Guerrerod", "Guillermo", ""]]}, {"id": "1912.05945", "submitter": "Behzad Asadi", "authors": "Behzad Asadi, Vijay Varadharajan", "title": "Towards a Robust Classifier: An MDL-Based Method for Generating\n  Adversarial Examples", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.03751", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of adversarial examples in machine learning where an\nadversary tries to misguide a classifier by making functionality-preserving\nmodifications to original samples. We assume a black-box scenario where the\nadversary has access to only the feature set, and the final hard-decision\noutput of the classifier. We propose a method to generate adversarial examples\nusing the minimum description length (MDL) principle. Our final aim is to\nimprove the robustness of the classifier by considering generated examples in\nrebuilding the classifier. We evaluate our method for the application of static\nmalware detection in portable executable (PE) files. We consider API calls of\nPE files as their distinguishing features where the feature vector is a binary\nvector representing the presence-absence of API calls. In our method, we first\ncreate a dataset of benign samples by querying the target classifier. We next\nconstruct a code table of frequent patterns for the compression of this dataset\nusing the MDL principle. We finally generate an adversarial example\ncorresponding to a malware sample by selecting and adding a pattern from the\nbenign code table to the malware sample. The selected pattern is the one that\nminimizes the length of the compressed adversarial example given the code\ntable. This modification preserves the functionalities of the original malware\nsample as all original API calls are kept, and only some new API calls are\nadded. Considering a neural network, we show that the evasion rate is 78.24\npercent for adversarial examples compared to 8.16 percent for original malware\nsamples. This shows the effectiveness of our method in generating examples that\nneed to be considered in rebuilding the classifier.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:42:41 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Asadi", "Behzad", ""], ["Varadharajan", "Vijay", ""]]}, {"id": "1912.05946", "submitter": "Ahmed Baruwa", "authors": "Ahmed Baruwa, Mojeed Abisiga, Ibrahim Gbadegesin, Afeez Fakunle", "title": "Leveraging End-to-End Speech Recognition with Neural Architecture Search", "comments": null, "journal-ref": "IJSER, vol 10, Issue 11, 2019, pp 1113-1119", "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks (DNNs) have been demonstrated to outperform many\ntraditional machine learning algorithms in Automatic Speech Recognition (ASR).\nIn this paper, we show that a large improvement in the accuracy of deep speech\nmodels can be achieved with effective Neural Architecture Optimization at a\nvery low computational cost. Phone recognition tests with the popular\nLibriSpeech and TIMIT benchmarks proved this fact by displaying the ability to\ndiscover and train novel candidate models within a few hours (less than a day)\nmany times faster than the attention-based seq2seq models. Our method achieves\ntest error of 7% Word Error Rate (WER) on the LibriSpeech corpus and 13% Phone\nError Rate (PER) on the TIMIT corpus, on par with state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:15:58 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Baruwa", "Ahmed", ""], ["Abisiga", "Mojeed", ""], ["Gbadegesin", "Ibrahim", ""], ["Fakunle", "Afeez", ""]]}, {"id": "1912.05957", "submitter": "Hamid Mohammadi", "authors": "Hamid Mohammadi, Seyed Hossein Khasteh", "title": "Text as Environment: A Deep Reinforcement Learning Text Readability\n  Assessment Model", "comments": "8 pages, 2 figures, 6 equations, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the readability of a text can significantly facilitate the precise\nexpression of information in a written form. The formulation of text\nreadability assessment demands the identification of meaningful properties of\nthe text and correct conversion of features to the right readability level.\nSophisticated features and models are being used to evaluate the\ncomprehensibility of texts accurately. Still, these models are challenging to\nimplement, heavily language-dependent, and do not perform well on short texts.\nDeep reinforcement learning models are demonstrated to be helpful in further\nimprovement of state-of-the-art text readability assessment models. The main\ncontributions of the proposed approach are the automation of feature\nextraction, loosening the tight language dependency of text readability\nassessment task, and efficient use of text by finding the minimum portion of a\ntext required to assess its readability. The experiments on Weebit, Cambridge\nExams, and Persian readability datasets display the model's state-of-the-art\nprecision, efficiency, and the capability to be applied to other languages.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 13:54:09 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 15:46:55 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Mohammadi", "Hamid", ""], ["Khasteh", "Seyed Hossein", ""]]}, {"id": "1912.05958", "submitter": "Wisdom Agboh", "authors": "Wisdom Agboh, Oliver Grainger, Daniel Ruprecht, Mehmet Dogar", "title": "Parareal with a Learned Coarse Model for Robotic Manipulation", "comments": "Accepted to Computing and Visualization in Science (special issue on\n  parallel-in-time)", "journal-ref": "Computing and Visualization in Science 23(8), 2020", "doi": "10.1007/s00791-020-00327-0", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key component of many robotics model-based planning and control algorithms\nis physics predictions, that is, forecasting a sequence of states given an\ninitial state and a sequence of controls. This process is slow and a major\ncomputational bottleneck for robotics planning algorithms. Parallel-in-time\nintegration methods can help to leverage parallel computing to accelerate\nphysics predictions and thus planning. The Parareal algorithm iterates between\na coarse serial integrator and a fine parallel integrator. A key challenge is\nto devise a coarse model that is computationally cheap but accurate enough for\nParareal to converge quickly. Here, we investigate the use of a deep neural\nnetwork physics model as a coarse model for Parareal in the context of robotic\nmanipulation. In simulated experiments using the physics engine Mujoco as fine\npropagator we show that the learned coarse model leads to faster Parareal\nconvergence than a coarse physics-based model. We further show that the learned\ncoarse model allows to apply Parareal to scenarios with multiple objects, where\nthe physics-based coarse model is not applicable. Finally, we conduct\nexperiments on a real robot and show that Parareal predictions are close to\nreal-world physics predictions for robotic pushing of multiple objects. Videos\nare at https://youtu.be/wCh2o1rf-gA.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 13:54:24 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 14:29:57 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Agboh", "Wisdom", ""], ["Grainger", "Oliver", ""], ["Ruprecht", "Daniel", ""], ["Dogar", "Mehmet", ""]]}, {"id": "1912.05977", "submitter": "Menghan Wang", "authors": "Menghan Wang, Kun Zhang, Gulin Li, Keping Yang, Luo Si", "title": "Tracing the Propagation Path: A Flow Perspective of Representation\n  Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have gained significant developments in\nrepresentation learning on graphs. However, current GCNs suffer from two common\nchallenges: 1) GCNs are only effective with shallow structures; stacking\nmultiple GCN layers will lead to over-smoothing. 2) GCNs do not scale well with\nlarge, dense graphs due to the recursive neighborhood expansion. We generalize\nthe propagation strategies of current GCNs as a \\emph{\"Sink$\\to$Source\"} mode,\nwhich seems to be an underlying cause of the two challenges. To address these\nissues intrinsically, in this paper, we study the information propagation\nmechanism in a \\emph{\"Source$\\to$Sink\"} mode. We introduce a new concept\n\"information flow path\" that explicitly defines where information originates\nand how it diffuses. Then a novel framework, namely Flow Graph Network\n(FlowGN), is proposed to learn node representations. FlowGN is computationally\nefficient and flexible in propagation strategies. Moreover, FlowGN decouples\nthe layer structure from the information propagation process, removing the\ninterior constraint of applying deep structures in traditional GCNs. Further\nexperiments on public datasets demonstrate the superiority of FlowGN against\nstate-of-the-art GCNs.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 14:21:58 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Wang", "Menghan", ""], ["Zhang", "Kun", ""], ["Li", "Gulin", ""], ["Yang", "Keping", ""], ["Si", "Luo", ""]]}, {"id": "1912.06015", "submitter": "Andre Manoel", "authors": "Gaspar Rochette, Andre Manoel, Eric W. Tramel", "title": "Efficient Per-Example Gradient Computations in Convolutional Neural\n  Networks", "comments": null, "journal-ref": "Theory and Practice of Differential Privacy (TPDP) workshop at CCS\n  2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning frameworks leverage GPUs to perform massively-parallel\ncomputations over batches of many training examples efficiently. However, for\ncertain tasks, one may be interested in performing per-example computations,\nfor instance using per-example gradients to evaluate a quantity of interest\nunique to each example. One notable application comes from the field of\ndifferential privacy, where per-example gradients must be norm-bounded in order\nto limit the impact of each example on the aggregated batch gradient. In this\nwork, we discuss how per-example gradients can be efficiently computed in\nconvolutional neural networks (CNNs). We compare existing strategies by\nperforming a few steps of differentially-private training on CNNs of varying\nsizes. We also introduce a new strategy for per-example gradient calculation,\nwhich is shown to be advantageous depending on the model architecture and how\nthe model is trained. This is a first step in making differentially-private\ntraining of CNNs practical.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:10:14 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Rochette", "Gaspar", ""], ["Manoel", "Andre", ""], ["Tramel", "Eric W.", ""]]}, {"id": "1912.06032", "submitter": "Thomas Hubregtsen", "authors": "Thomas Hubregtsen, Christoph Segler, Josef Pichlmeier, Aritra Sarkar,\n  Thomas Gabor, Koen Bertels", "title": "Integration and Evaluation of Quantum Accelerators for Data-Driven User\n  Functions", "comments": "6 pages, accepted to ISQED 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computers hold great promise for accelerating computationally\nchallenging algorithms on noisy intermediate-scale quantum (NISQ) devices in\nthe upcoming years. Much attention of the current research is directed to\nalgorithmic research on artificial data that is disconnected from live systems,\nsuch as optimization of systems or training of learning algorithms. In this\npaper we investigate the integration of quantum systems into industry-grade\nsystem architectures. In this work we propose a system architecture for the\nintegration of quantum accelerators. In order to evaluate our proposed system\narchitecture we implemented various algorithms including a classical system, a\ngate-based quantum accelerator and a quantum annealer. This algorithm automates\nuser habits using data-driven functions trained on real-world data. This also\nincludes an evaluation of the quantum enhanced kernel, that previously was only\nevaluated on artificial data. In our evaluation, we showed that the\nquantum-enhanced kernel performs at least equally well to a classical\nstate-of-the-art kernel. We also showed a low reduction in accuracy and latency\nnumbers within acceptable bounds when running on the gate-based IBM quantum\naccelerator. We, therefore, conclude it is feasible to integrate NISQ-era\ndevices in industry-grade system architecture in preparation for future\nhardware improvements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:30:21 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 16:27:44 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hubregtsen", "Thomas", ""], ["Segler", "Christoph", ""], ["Pichlmeier", "Josef", ""], ["Sarkar", "Aritra", ""], ["Gabor", "Thomas", ""], ["Bertels", "Koen", ""]]}, {"id": "1912.06036", "submitter": "Pranay Sharma", "authors": "Pranay Sharma, Swatantra Kafle, Prashant Khanduri, Saikiran Bulusu,\n  Ketan Rajawat, and Pramod K. Varshney", "title": "Parallel Restarted SPIDER -- Communication Efficient Distributed\n  Nonconvex Optimization with Optimal Computation Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a distributed algorithm for stochastic smooth,\nnon-convex optimization. We assume a worker-server architecture where $N$\nnodes, each having $n$ (potentially infinite) number of samples, collaborate\nwith the help of a central server to perform the optimization task. The global\nobjective is to minimize the average of local cost functions available at\nindividual nodes. The proposed approach is a non-trivial extension of the\npopular parallel-restarted SGD algorithm, incorporating the optimal\nvariance-reduction based SPIDER gradient estimator into it. We prove\nconvergence of our algorithm to a first-order stationary solution. The proposed\napproach achieves the best known communication complexity $O(\\epsilon^{-1})$\nalong with the optimal computation complexity. For finite-sum problems (finite\n$n$), we achieve the optimal computation (IFO) complexity\n$O(\\sqrt{Nn}\\epsilon^{-1})$. For online problems ($n$ unknown or infinite), we\nachieve the optimal IFO complexity $O(\\epsilon^{-3/2})$. In both the cases, we\nmaintain the linear speedup achieved by existing methods. This is a massive\nimprovement over the $O(\\epsilon^{-2})$ IFO complexity of the existing\napproaches. Additionally, our algorithm is general enough to allow\nnon-identical distributions of data across workers, as in the recently proposed\nfederated learning paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:36:22 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 06:03:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Sharma", "Pranay", ""], ["Kafle", "Swatantra", ""], ["Khanduri", "Prashant", ""], ["Bulusu", "Saikiran", ""], ["Rajawat", "Ketan", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1912.06044", "submitter": "Mor Avi-Aharon", "authors": "Mor Avi-Aharon, Assaf Arbelle, and Tammy Riklin Raviv", "title": "Hue-Net: Intensity-based Image-to-Image Translation with Differentiable\n  Histogram Loss Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Hue-Net - a novel Deep Learning framework for Intensity-based\nImage-to-Image Translation. The key idea is a new technique termed network\naugmentation which allows a differentiable construction of intensity histograms\nfrom images. We further introduce differentiable representations of (1D) cyclic\nand joint (2D) histograms and use them for defining loss functions based on\ncyclic Earth Mover's Distance (EMD) and Mutual Information (MI). While the\nHue-Net can be applied to several image-to-image translation tasks, we choose\nto demonstrate its strength on color transfer problems, where the aim is to\npaint a source image with the colors of a different target image. Note that the\ndesired output image does not exist and therefore cannot be used for supervised\npixel-to-pixel learning. This is accomplished by using the HSV color-space and\ndefining an intensity-based loss that is built on the EMD between the cyclic\nhue histograms of the output and the target images. To enforce color-free\nsimilarity between the source and the output images, we define a semantic-based\nloss by a differentiable approximation of the MI of these images. The\nincorporation of histogram loss functions in addition to an adversarial loss\nenables the construction of semantically meaningful and realistic images.\nPromising results are presented for different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:48:55 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Avi-Aharon", "Mor", ""], ["Arbelle", "Assaf", ""], ["Raviv", "Tammy Riklin", ""]]}, {"id": "1912.06058", "submitter": "George Dasoulas", "authors": "George Dasoulas, Ludovic Dos Santos, Kevin Scaman, Aladin Virmaux", "title": "Coloring graph neural networks for node disambiguation", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that a simple coloring scheme can improve, both\ntheoretically and empirically, the expressive power of Message Passing Neural\nNetworks(MPNNs). More specifically, we introduce a graph neural network called\nColored Local Iterative Procedure (CLIP) that uses colors to disambiguate\nidentical node attributes, and show that this representation is a universal\napproximator of continuous functions on graphs with node attributes. Our method\nrelies on separability , a key topological characteristic that allows to extend\nwell-chosen neural networks into universal representations. Finally, we show\nexperimentally that CLIP is capable of capturing structural characteristics\nthat traditional MPNNs fail to distinguish,while being state-of-the-art on\nbenchmark graph classification datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:06:47 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Dasoulas", "George", ""], ["Santos", "Ludovic Dos", ""], ["Scaman", "Kevin", ""], ["Virmaux", "Aladin", ""]]}, {"id": "1912.06059", "submitter": "Petro Liashchynskyi", "authors": "Petro Liashchynskyi and Pavlo Liashchynskyi", "title": "Grid Search, Random Search, Genetic Algorithm: A Big Comparison for NAS", "comments": "11 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare the three most popular algorithms for\nhyperparameter optimization (Grid Search, Random Search, and Genetic Algorithm)\nand attempt to use them for neural architecture search (NAS). We use these\nalgorithms for building a convolutional neural network (search architecture).\nExperimental results on CIFAR-10 dataset further demonstrate the performance\ndifference between compared algorithms. The comparison results are based on the\nexecution time of the above algorithms and accuracy of the proposed models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:07:20 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Liashchynskyi", "Petro", ""], ["Liashchynskyi", "Pavlo", ""]]}, {"id": "1912.06060", "submitter": "Xiaofei Shi", "authors": "Xiaofei Shi, David P. Woodruff", "title": "Sublinear Time Numerical Linear Algebra for Structured Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to solve a number of problems in numerical linear algebra, such\nas least squares regression, $\\ell_p$-regression for any $p \\geq 1$, low rank\napproximation, and kernel regression, in time $T(A) \\poly(\\log(nd))$, where for\na given input matrix $A \\in \\mathbb{R}^{n \\times d}$, $T(A)$ is the time needed\nto compute $A\\cdot y$ for an arbitrary vector $y \\in \\mathbb{R}^d$. Since $T(A)\n\\leq O(\\nnz(A))$, where $\\nnz(A)$ denotes the number of non-zero entries of\n$A$, the time is no worse, up to polylogarithmic factors, as all of the recent\nadvances for such problems that run in input-sparsity time. However, for many\napplications, $T(A)$ can be much smaller than $\\nnz(A)$, yielding significantly\nsublinear time algorithms. For example, in the overconstrained\n$(1+\\epsilon)$-approximate polynomial interpolation problem, $A$ is a\nVandermonde matrix and $T(A) = O(n \\log n)$; in this case our running time is\n$n \\cdot \\poly(\\log n) + \\poly(d/\\epsilon)$ and we recover the results of\n\\cite{avron2013sketching} as a special case. For overconstrained\nautoregression, which is a common problem arising in dynamical systems, $T(A) =\nO(n \\log n)$, and we immediately obtain $n \\cdot \\poly(\\log n) +\n\\poly(d/\\epsilon)$ time. For kernel autoregression, we significantly improve\nthe running time of prior algorithms for general kernels. For the important\ncase of autoregression with the polynomial kernel and arbitrary target vector\n$b\\in\\mathbb{R}^n$, we obtain even faster algorithms. Our algorithms show that,\nperhaps surprisingly, most of these optimization problems do not require much\nmore time than that of a polylogarithmic number of matrix-vector\nmultiplications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:13:51 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Shi", "Xiaofei", ""], ["Woodruff", "David P.", ""]]}, {"id": "1912.06073", "submitter": "He Jia", "authors": "He Jia, Uro\\v{s} Seljak", "title": "Normalizing Constant Estimation with Gaussianized Bridge Sampling", "comments": "Accepted by AABI 2019 Proceedings", "journal-ref": "Proceedings of The 2nd Symposium on Advances in Approximate\n  Bayesian Inference, PMLR 118:1-14, 2020", "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing constant (also called partition function, Bayesian evidence, or\nmarginal likelihood) is one of the central goals of Bayesian inference, yet\nmost of the existing methods are both expensive and inaccurate. Here we develop\na new approach, starting from posterior samples obtained with a standard Markov\nChain Monte Carlo (MCMC). We apply a novel Normalizing Flow (NF) approach to\nobtain an analytic density estimator from these samples, followed by Optimal\nBridge Sampling (OBS) to obtain the normalizing constant. We compare our method\nwhich we call Gaussianized Bridge Sampling (GBS) to existing methods such as\nNested Sampling (NS) and Annealed Importance Sampling (AIS) on several\nexamples, showing our method is both significantly faster and substantially\nmore accurate than these methods, and comes with a reliable error estimation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:50:03 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Jia", "He", ""], ["Seljak", "Uro\u0161", ""]]}, {"id": "1912.06074", "submitter": "Yifan Wu", "authors": "Fan Yang, Liu Leqi, Yifan Wu, Zachary C. Lipton, Pradeep Ravikumar,\n  William W. Cohen, Tom Mitchell", "title": "Game Design for Eliciting Distinguishable Behavior", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to inferring latent psychological traits from human behavior is\nkey to developing personalized human-interacting machine learning systems.\nApproaches to infer such traits range from surveys to manually-constructed\nexperiments and games. However, these traditional games are limited because\nthey are typically designed based on heuristics. In this paper, we formulate\nthe task of designing \\emph{behavior diagnostic games} that elicit\ndistinguishable behavior as a mutual information maximization problem, which\ncan be solved by optimizing a variational lower bound. Our framework is\ninstantiated by using prospect theory to model varying player traits, and\nMarkov Decision Processes to parameterize the games. We validate our approach\nempirically, showing that our designed games can successfully distinguish among\nplayers with different traits, outperforming manually-designed ones by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:50:43 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Yang", "Fan", ""], ["Leqi", "Liu", ""], ["Wu", "Yifan", ""], ["Lipton", "Zachary C.", ""], ["Ravikumar", "Pradeep", ""], ["Cohen", "William W.", ""], ["Mitchell", "Tom", ""]]}, {"id": "1912.06075", "submitter": "Felix Denzinger", "authors": "Felix Denzinger, Michael Wels, Nishant Ravikumar, Katharina\n  Breininger, Anika Reidelsh\\\"ofer, Joachim Eckert, Michael S\\\"uhling, Axel\n  Schmermund, and Andreas Maier", "title": "Coronary Artery Plaque Characterization from CCTA Scans using Deep\n  Learning and Radiomics", "comments": "International Conference on Medical Image Computing and\n  Computer-Assisted Intervention. Springer, Cham, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32251-9_65", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing coronary artery plaque segments in coronary CT angiography scans is\nan important task to improve patient management and clinical outcomes, as it\ncan help to decide whether invasive investigation and treatment are necessary.\nIn this work, we present three machine learning approaches capable of\nperforming this task. The first approach is based on radiomics, where a plaque\nsegmentation is used to calculate various shape-, intensity- and texture-based\nfeatures under different image transformations. A second approach is based on\ndeep learning and relies on centerline extraction as sole prerequisite. In the\nthird approach, we fuse the deep learning approach with radiomic features. On\nour data the methods reached similar scores as simulated fractional flow\nreserve (FFR) measurements, which - in contrast to our methods - requires an\nexact segmentation of the whole coronary tree and often time-consuming manual\ninteraction. In literature, the performance of simulated FFR reaches an AUC\nbetween 0.79-0.93 predicting an abnormal invasive FFR that demands\nrevascularization. The radiomics approach achieves an AUC of 0.86, the deep\nlearning approach 0.84 and the combined method 0.88 for predicting the\nrevascularization decision directly. While all three proposed methods can be\ndetermined within seconds, the FFR simulation typically takes several minutes.\nProvided representative training data in sufficient quantities, we believe that\nthe presented methods can be used to create systems for fully automatic\nnon-invasive risk assessment for a variety of adverse cardiac events.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:51:09 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 11:34:47 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Denzinger", "Felix", ""], ["Wels", "Michael", ""], ["Ravikumar", "Nishant", ""], ["Breininger", "Katharina", ""], ["Reidelsh\u00f6fer", "Anika", ""], ["Eckert", "Joachim", ""], ["S\u00fchling", "Michael", ""], ["Schmermund", "Axel", ""], ["Maier", "Andreas", ""]]}, {"id": "1912.06077", "submitter": "James Horwath", "authors": "James P. Horwath, Dmitri N. Zakharov, Remi Megret, Eric A. Stach", "title": "Understanding Important Features of Deep Learning Models for\n  Transmission Electron Microscopy Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cutting edge deep learning techniques allow for image segmentation with great\nspeed and accuracy. However, application to problems in materials science is\noften difficult since these complex models may have difficultly learning\nphysical parameters. In situ electron microscopy provides a clear platform for\nutilizing automated image analysis. In this work we consider the case of\nstudying coarsening dynamics in supported nanoparticles, which is important for\nunderstanding e.g. the degradation of industrial catalysts. By systematically\nstudying dataset preparation, neural network architecture, and accuracy\nevaluation, we describe important considerations in applying deep learning to\nphysical applications, where generalizable and convincing models are required.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:52:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Horwath", "James P.", ""], ["Zakharov", "Dmitri N.", ""], ["Megret", "Remi", ""], ["Stach", "Eric A.", ""]]}, {"id": "1912.06079", "submitter": "Julian Tanke", "authors": "Julian Tanke, Andreas Weber, Juergen Gall", "title": "Human Motion Anticipation with Symbolic Label", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipating human motion depends on two factors: the past motion and the\nperson's intention. While the first factor has been extensively utilized to\nforecast short sequences of human motion, the second one remains elusive. In\nthis work we approximate a person's intention via a symbolic representation,\nfor example fine-grained action labels such as walking or sitting down.\nForecasting a symbolic representation is much easier than forecasting the full\nbody pose with its complex inter-dependencies. However, knowing the future\nactions makes forecasting human motion easier. We exploit this connection by\nfirst anticipating symbolic labels and then generate human motion, conditioned\non the human motion input sequence as well as on the forecast labels. This\nallows the model to anticipate motion changes many steps ahead and adapt the\nposes accordingly. We achieve state-of-the-art results on short-term as well as\non long-term human motion forecasting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 16:56:32 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 09:38:48 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Tanke", "Julian", ""], ["Weber", "Andreas", ""], ["Gall", "Juergen", ""]]}, {"id": "1912.06085", "submitter": "Francesco De Lellis", "authors": "Francesco De Lellis, Fabrizia Auletta, Giovanni Russo, Piero De Lellis\n  and Mario di Bernardo", "title": "Control-Tutored Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a control-tutored reinforcement learning (CTRL) algorithm. The\nidea is to enhance tabular learning algorithms so as to improve the exploration\nof the state-space, and substantially reduce learning times by leveraging some\nlimited knowledge of the plant encoded into a tutoring model-based control\nstrategy. We illustrate the benefits of our novel approach and its\neffectiveness by using the problem of controlling one or more agents to herd\nand contain within a goal region a set of target free-roving agents in the\nplane.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:14:15 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["De Lellis", "Francesco", ""], ["Auletta", "Fabrizia", ""], ["Russo", "Giovanni", ""], ["De Lellis", "Piero", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1912.06087", "submitter": "Hope Jasperson", "authors": "Hope Jasperson, David C. Bolton, Paul Johnson, Robert Guyer, Chris\n  Marone, Maarten V. de Hoop", "title": "Attention network forecasts time-to-failure in laboratory shear\n  experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rocks under stress deform by creep mechanisms that include formation and slip\non small-scale internal cracks. Intragranular cracks and slip along grain\ncontacts release energy as elastic waves termed acoustic emissions (AE). AEs\nare thought to contain predictive information that can be used for fault\nfailure forecasting. Here we present a method using unsupervised classification\nand an attention network to forecast labquakes using AE waveform features. Our\ndata were generated in a laboratory setting using a biaxial shearing device\nwith granular fault gouge intended to mimic the conditions of tectonic faults.\nHere we analyzed the temporal evolution of AEs generated throughout several\nhundred laboratory earthquake cycles. We used a Conscience Self-Organizing Map\n(CSOM) to perform topologically ordered vector quantization based on waveform\nproperties. The resulting map was used to interactively cluster AEs. We\nexamined the clusters over time to identify those with predictive ability.\nFinally, we used a variety of LSTM and attention-based networks to test the\npredictive power of the AE clusters. By tracking cumulative waveform features\nover the seismic cycle, the network is able to forecast the time-to-failure\n(TTF) of lab earthquakes. Our results show that analyzing the data to isolate\npredictive signals and using a more sophisticated network architecture are key\nto robustly forecasting labquakes. In the future, this method could be applied\non tectonic faults monitor earthquakes and augment current early warning\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:23:14 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 22:57:55 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Jasperson", "Hope", ""], ["Bolton", "David C.", ""], ["Johnson", "Paul", ""], ["Guyer", "Robert", ""], ["Marone", "Chris", ""], ["de Hoop", "Maarten V.", ""]]}, {"id": "1912.06088", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Abhishek Gupta, Ashwin Reddy, Justin Fu, Coline Devin,\n  Benjamin Eysenbach, Sergey Levine", "title": "Learning to Reach Goals via Iterated Supervised Learning", "comments": "First two authors contributed equally. Code available at\n  https://github.com/dibyaghosh/gcsl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning (RL) algorithms can be brittle and difficult\nto use, especially when learning goal-reaching behaviors from sparse rewards.\nAlthough supervised imitation learning provides a simple and stable\nalternative, it requires access to demonstrations from a human supervisor. In\nthis paper, we study RL algorithms that use imitation learning to acquire goal\nreaching policies from scratch, without the need for expert demonstrations or a\nvalue function. In lieu of demonstrations, we leverage the property that any\ntrajectory is a successful demonstration for reaching the final state in that\nsame trajectory. We propose a simple algorithm in which an agent continually\nrelabels and imitates the trajectories it generates to progressively learn\ngoal-reaching behaviors from scratch. Each iteration, the agent collects new\ntrajectories using the latest policy, and maximizes the likelihood of the\nactions along these trajectories under the goal that was actually reached, so\nas to improve the policy. We formally show that this iterated supervised\nlearning procedure optimizes a bound on the RL objective, derive performance\nbounds of the learned policy, and empirically demonstrate improved\ngoal-reaching performance and robustness over current RL algorithms in several\nbenchmark tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:26:47 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 01:42:38 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 17:22:46 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 19:49:10 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ghosh", "Dibya", ""], ["Gupta", "Abhishek", ""], ["Reddy", "Ashwin", ""], ["Fu", "Justin", ""], ["Devin", "Coline", ""], ["Eysenbach", "Benjamin", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.06095", "submitter": "Qingbiao Li", "authors": "Qingbiao Li, Fernando Gama, Alejandro Ribeiro, Amanda Prorok", "title": "Graph Neural Networks for Decentralized Multi-Robot Path Planning", "comments": "This paper has been accepted in the IEEE/RSJ International Conference\n  on Intelligent Robots and Systems (IROS) 2020. For the simulation demo, see\n  this https URL \"https://youtu.be/AGDk2RozpMQ\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective communication is key to successful, decentralized, multi-robot path\nplanning. Yet, it is far from obvious what information is crucial to the task\nat hand, and how and when it must be shared among robots. To side-step these\nissues and move beyond hand-crafted heuristics, we propose a combined model\nthat automatically synthesizes local communication and decision-making policies\nfor robots navigating in constrained workspaces. Our architecture is composed\nof a convolutional neural network (CNN) that extracts adequate features from\nlocal observations, and a graph neural network (GNN) that communicates these\nfeatures among robots. We train the model to imitate an expert algorithm, and\nuse the resulting model online in decentralized planning involving only local\ncommunication and local observations. We evaluate our method in simulations {by\nnavigating teams of robots to their destinations in 2D} cluttered workspaces.\nWe measure the success rates and sum of costs over the planned paths. The\nresults show a performance close to that of our expert algorithm, demonstrating\nthe validity of our approach. In particular, we show our model's capability to\ngeneralize to previously unseen cases (involving larger environments and larger\nrobot teams).\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:48:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 13:04:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Li", "Qingbiao", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""], ["Prorok", "Amanda", ""]]}, {"id": "1912.06101", "submitter": "Carlos Purves", "authors": "Carlos Purves, C\\u{a}t\\u{a}lina Cangea, Petar Veli\\v{c}kovi\\'c", "title": "The PlayStation Reinforcement Learning Environment (PSXLE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new benchmark environment for evaluating Reinforcement Learning\n(RL) algorithms: the PlayStation Learning Environment (PSXLE), a PlayStation\nemulator modified to expose a simple control API that enables rich game-state\nrepresentations. We argue that the PlayStation serves as a suitable progression\nfor agent evaluation and propose a framework for such an evaluation. We build\nan action-driven abstraction for a PlayStation game with support for the OpenAI\nGym interface and demonstrate its use by running OpenAI Baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:59:52 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Purves", "Carlos", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "1912.06102", "submitter": "Vijay Rengarajan", "authors": "Vijay Rengarajan, Shuo Zhao, Ruiwen Zhen, John Glotzbach, Hamid\n  Sheikh, Aswin C. Sankaranarayanan", "title": "Photosequencing of Motion Blur using Short and Long Exposures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photosequencing aims to transform a motion blurred image to a sequence of\nsharp images. This problem is challenging due to the inherent ambiguities in\ntemporal ordering as well as the recovery of lost spatial textures due to blur.\nAdopting a computational photography approach, we propose to capture two short\nexposure images, along with the original blurred long exposure image to aid in\nthe aforementioned challenges. Post-capture, we recover the sharp photosequence\nusing a novel blur decomposition strategy that recursively splits the long\nexposure image into smaller exposure intervals. We validate the approach by\ncapturing a variety of scenes with interesting motions using machine vision\ncameras programmed to capture short and long exposure sequences. Our\nexperimental results show that the proposed method resolves both fast and fine\nmotions better than prior works.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:23:14 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Rengarajan", "Vijay", ""], ["Zhao", "Shuo", ""], ["Zhen", "Ruiwen", ""], ["Glotzbach", "John", ""], ["Sheikh", "Hamid", ""], ["Sankaranarayanan", "Aswin C.", ""]]}, {"id": "1912.06111", "submitter": "Weihao Kong", "authors": "Weihao Kong and Gregory Valiant and Emma Brunskill", "title": "Sublinear Optimal Policy Value Estimation in Contextual Bandits", "comments": "Extended to the mixture of Gaussians setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the expected reward of the optimal policy\nin the stochastic disjoint linear bandit setting. We prove that for certain\nsettings it is possible to obtain an accurate estimate of the optimal policy\nvalue even with a number of samples that is sublinear in the number that would\nbe required to \\emph{find} a policy that realizes a value close to this optima.\nWe establish nearly matching information theoretic lower bounds, showing that\nour algorithm achieves near optimal estimation error. Finally, we demonstrate\nthe effectiveness of our algorithm on joke recommendation and cancer inhibition\ndosage selection problems using real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:20:11 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 22:43:40 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kong", "Weihao", ""], ["Valiant", "Gregory", ""], ["Brunskill", "Emma", ""]]}, {"id": "1912.06112", "submitter": "Hao Tang", "authors": "Hao Tang, Hong Liu, Nicu Sebe", "title": "Unified Generative Adversarial Networks for Controllable Image-to-Image\n  Translation", "comments": "Accepted to TIP, an extended version of a paper published in ACM MM\n  2018. arXiv admin note: substantial text overlap with arXiv:1808.04859", "journal-ref": null, "doi": "10.1109/TIP.2020.3021789", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified Generative Adversarial Network (GAN) for controllable\nimage-to-image translation, i.e., transferring an image from a source to a\ntarget domain guided by controllable structures. In addition to conditioning on\na reference image, we show how the model can generate images conditioned on\ncontrollable structures, e.g., class labels, object keypoints, human skeletons,\nand scene semantic maps. The proposed model consists of a single generator and\na discriminator taking a conditional image and the target controllable\nstructure as input. In this way, the conditional image can provide appearance\ninformation and the controllable structure can provide the structure\ninformation for generating the target result. Moreover, our model learns the\nimage-to-image mapping through three novel losses, i.e., color loss,\ncontrollable structure guided cycle-consistency loss, and controllable\nstructure guided self-content preserving loss. Also, we present the Fr\\'echet\nResNet Distance (FRD) to evaluate the quality of the generated images.\nExperiments on two challenging image translation tasks, i.e., hand\ngesture-to-gesture translation and cross-view image translation, show that our\nmodel generates convincing results, and significantly outperforms other\nstate-of-the-art methods on both tasks. Meanwhile, the proposed framework is a\nunified solution, thus it can be applied to solving other controllable\nstructure guided image translation tasks such as landmark guided facial\nexpression translation and keypoint guided person image generation. To the best\nof our knowledge, we are the first to make one GAN framework work on all such\ncontrollable structure guided image translation tasks. Code is available at\nhttps://github.com/Ha0Tang/GestureGAN.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:21:30 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 11:00:42 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Tang", "Hao", ""], ["Liu", "Hong", ""], ["Sebe", "Nicu", ""]]}, {"id": "1912.06135", "submitter": "Yuyang Liu", "authors": "Yuyang Liu and Yang Cong and Gan Sun", "title": "L3DOC: Lifelong 3D Object Classification", "comments": "10 pages,17 figures, CVPR 2020 underreview", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object classification has been widely-applied into both academic and\nindustrial scenarios. However, most state-of-the-art algorithms are facing with\na fixed 3D object classification task set, which cannot well tackle the new\ncoming data with incremental tasks as human ourselves. Meanwhile, the\nperformance of most state-of-the-art lifelong learning models can be\ndeteriorated easily on previously learned classification tasks, due to the\nexisting of unordered, large-scale, and irregular 3D geometry data. To address\nthis challenge, in this paper, we propose a Lifelong 3D Object Classification\n(i.e., L3DOC) framewor, which can consecutively learn new 3D object\nclassification tasks via imitating 'human learning'. Specifically, the core\nidea of our proposed L3DOC model is to factorize PointNet in a perspective of\nlifelong learning, while capturing and storing the shared point-knowledge in a\nperspective of layer-wise tensor factorization architecture. To further\ntransfer the task-specific knowledge from previous tasks to the new coming\nclassification task, a memory attention mechanism is proposed to connect the\ncurrent task with relevant previously tasks, which can effectively prevent\ncatastrophic forgetting via soft-transferring previous knowledge. To our best\nknowledge, this is the first work about using lifelong learning to handle 3D\nobject classification task without model fine-tuning or retraining.\nFurthermore, our L3DOC model can also be extended to other backbone network\n(e.g., PointNet++). To the end, comparisons on several point cloud datasets\nvalidate that our L3DOC model can reduce averaged 1.68~3.36 times parameters\nfor the overall model, without sacrificing classification accuracy of each\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 06:41:19 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 14:51:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Liu", "Yuyang", ""], ["Cong", "Yang", ""], ["Sun", "Gan", ""]]}, {"id": "1912.06137", "submitter": "Thierry Denoeux", "authors": "Thierry Denoeux", "title": "Calibrated model-based evidential clustering using bootstrapping", "comments": null, "journal-ref": "Information Sciences, Vol. 528, pages 17-45, 2020", "doi": "10.1016/j.ins.2020.04.014", "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidential clustering is an approach to clustering in which\ncluster-membership uncertainty is represented by a collection of\nDempster-Shafer mass functions forming an evidential partition. In this paper,\nwe propose to construct these mass functions by bootstrapping finite mixture\nmodels. In the first step, we compute bootstrap percentile confidence intervals\nfor all pairwise probabilities (the probabilities for any two objects to belong\nto the same class). We then construct an evidential partition such that the\npairwise belief and plausibility degrees approximate the bounds of the\nconfidence intervals. This evidential partition is calibrated, in the sense\nthat the pairwise belief-plausibility intervals contain the true probabilities\n\"most of the time\", i.e., with a probability close to the defined confidence\nlevel. This frequentist property is verified by simulation, and the practical\napplicability of the method is demonstrated using several real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 08:40:39 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:07:19 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Denoeux", "Thierry", ""]]}, {"id": "1912.06174", "submitter": "Marta Skreta", "authors": "Marta Skreta, Aryan Arbabi, Jixuan Wang, Michael Brudno", "title": "Training without training data: Improving the generalizability of\n  automated medical abbreviation disambiguation", "comments": "NeurIPS Machine Learning for Healthcare 2019 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abbreviation disambiguation is important for automated clinical note\nprocessing due to the frequent use of abbreviations in clinical settings.\nCurrent models for automated abbreviation disambiguation are restricted by the\nscarcity and imbalance of labeled training data, decreasing their\ngeneralizability to orthogonal sources. In this work we propose a novel data\naugmentation technique that utilizes information from related medical concepts,\nwhich improves our model's ability to generalize. Furthermore, we show that\nincorporating the global context information within the whole medical note (in\naddition to the traditional local context window), can significantly improve\nthe model's representation for abbreviations. We train our model on a public\ndataset (MIMIC III) and test its performance on datasets from different sources\n(CASI, i2b2). Together, these two techniques boost the accuracy of abbreviation\ndisambiguation by almost 14% on the CASI dataset and 4% on i2b2.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 19:32:41 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Skreta", "Marta", ""], ["Arbabi", "Aryan", ""], ["Wang", "Jixuan", ""], ["Brudno", "Michael", ""]]}, {"id": "1912.06190", "submitter": "Andrzej Banburski", "authors": "Tomaso Poggio, Gil Kur, Andrzej Banburski", "title": "Double descent in the condition number", "comments": "Removed parts relating to kernel regression to streamline the\n  presentation, fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In solving a system of $n$ linear equations in $d$ variables $Ax=b$, the\ncondition number of the $n,d$ matrix $A$ measures how much errors in the data\n$b$ affect the solution $x$. Estimates of this type are important in many\ninverse problems. An example is machine learning where the key task is to\nestimate an underlying function from a set of measurements at random points in\na high dimensional space and where low sensitivity to error in the data is a\nrequirement for good predictive performance. Here we discuss the simple\nobservation, which is known but surprisingly little quoted (see Theorem 4.2 in\n\\cite{Brgisser:2013:CGN:2526261}): when the columns of $A$ are random vectors,\nthe condition number of $A$ is highest if $d=n$, that is when the inverse of\n$A$ exists. An overdetermined system ($n>d$) as well as an underdetermined\nsystem ($n<d$), for which the pseudoinverse must be used instead of the\ninverse, typically have significantly better, that is lower, condition numbers.\nThus the condition number of $A$ plotted as function of $d$ shows a double\ndescent behavior with a peak at $d=n$.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:16:11 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:46:25 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 04:29:37 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Poggio", "Tomaso", ""], ["Kur", "Gil", ""], ["Banburski", "Andrzej", ""]]}, {"id": "1912.06193", "submitter": "Nicholas James", "authors": "Nick James, Max Menzies, Jennifer Chan", "title": "Changes to the extreme and erratic behaviour of cryptocurrencies during\n  COVID-19", "comments": "Accepted manuscript. Numerous minor edits compared to v3. Equal\n  contribution from first two authors", "journal-ref": "Physica A: Statistical Mechanics and its Applications 565 (2021)\n  125581", "doi": "10.1016/j.physa.2020.125581", "report-no": null, "categories": "q-fin.MF cs.LG math.DS q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces new methods for analysing the extreme and erratic\nbehaviour of time series to evaluate the impact of COVID-19 on cryptocurrency\nmarket dynamics. Across 51 cryptocurrencies, we examine extreme behaviour\nthrough a study of distribution extremities, and erratic behaviour through\nstructural breaks. First, we analyse the structure of the market as a whole and\nobserve a reduction in self-similarity as a result of COVID-19, particularly\nwith respect to structural breaks in variance. Second, we compare and contrast\nthese two behaviours, and identify individual anomalous cryptocurrencies.\nTether (USDT) and TrueUSD (TUSD) are consistent outliers with respect to their\nreturns, while Holo (HOT), NEXO (NEXO), Maker (MKR) and NEM (XEM) are\nfrequently observed as anomalous with respect to both behaviours and time. Even\namong a market known as consistently volatile, this identifies individual\ncryptocurrencies that behave most irregularly in their extreme and erratic\nbehaviour and shows these were more affected during the COVID-19 market crisis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:20:57 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 05:34:03 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 13:06:19 GMT"}, {"version": "v4", "created": "Sun, 29 Nov 2020 09:21:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["James", "Nick", ""], ["Menzies", "Max", ""], ["Chan", "Jennifer", ""]]}, {"id": "1912.06199", "submitter": "Artur Andr\\'e Almeida De Macedo Oliveira", "authors": "Artur A. M. Oliveira, Nina S. T. Hirata, Roberto Hirata Jr", "title": "Greenery Segmentation In Urban Images By Deep Learning", "comments": "Supplemental material can be found at\n  http://greenery_data.arturao.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vegetation is a relevant feature in the urban scenery and its awareness can\nbe measured in an image by the Green View Index (GVI). Previous approaches to\nestimate the GVI were based upon heuristics image processing approaches and\nrecently by deep learning networks (DLN). By leveraging some recent DLN\narchitectures tuned to the image segmentation problem and exploiting a\nweighting strategy in the loss function (LF) we improved previously reported\nresults in similar datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:35:15 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Oliveira", "Artur A. M.", ""], ["Hirata", "Nina S. T.", ""], ["Hirata", "Roberto", "Jr"]]}, {"id": "1912.06200", "submitter": "Christoph Klemenjak", "authors": "Christoph Klemenjak, Anthony Faustine, Stephen Makonin, Wilfried\n  Elmenreich", "title": "On Metrics to Assess the Transferability of Machine Learning Models in\n  Non-Intrusive Load Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To assess the performance of load disaggregation algorithms it is common\npractise to train a candidate algorithm on data from one or multiple households\nand subsequently apply cross-validation by evaluating the classification and\nenergy estimation performance on unseen portions of the dataset derived from\nthe same households. With an emerging discussion of transferability in\nNon-Intrusive Load Monitoring (NILM), there is a need for domain-specific\nmetrics to assess the performance of NILM algorithms on new test scenarios\nbeing unseen buildings. In this paper, we discuss several metrics to assess the\ngeneralisation ability of NILM algorithms. These metrics target different\naspects of performance evaluation in NILM and are meant to complement the\ntraditional performance evaluation approach. We demonstrate how our metrics can\nbe utilised to evaluate NILM algorithms by means of two case studies. We\nconduct our studies on several energy consumption datasets and take into\nconsideration five state-of-the-art as well as four baseline NILM solutions.\nFinally, we formulate research challenges for future work.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:43:06 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Klemenjak", "Christoph", ""], ["Faustine", "Anthony", ""], ["Makonin", "Stephen", ""], ["Elmenreich", "Wilfried", ""]]}, {"id": "1912.06202", "submitter": "Emily Diana", "authors": "Emily Diana, Michael Kearns, Seth Neel, Aaron Roth", "title": "Optimal, Truthful, and Private Securities Lending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a fundamental dynamic allocation problem motivated by the problem\nof $\\textit{securities lending}$ in financial markets, the mechanism underlying\nthe short selling of stocks. A lender would like to distribute a finite number\nof identical copies of some scarce resource to $n$ clients, each of whom has a\nprivate demand that is unknown to the lender. The lender would like to maximize\nthe usage of the resource $\\mbox{---}$ avoiding allocating more to a client\nthan her true demand $\\mbox{---}$ but is constrained to sell the resource at a\npre-specified price per unit, and thus cannot use prices to incentivize\ntruthful reporting. We first show that the Bayesian optimal algorithm for the\none-shot problem $\\mbox{---}$ which maximizes the resource's expected usage\naccording to the posterior expectation of demand, given reports $\\mbox{---}$\nactually incentivizes truthful reporting as a dominant strategy. Because true\ndemands in the securities lending problem are often sensitive information that\nthe client would like to hide from competitors, we then consider the problem\nunder the additional desideratum of (joint) differential privacy. We give an\nalgorithm, based on simple dynamics for computing market equilibria, that is\nsimultaneously private, approximately optimal, and approximately\ndominant-strategy truthful. Finally, we leverage this private algorithm to\nconstruct an approximately truthful, optimal mechanism for the extensive form\nmulti-round auction where the lender does not have access to the true joint\ndistributions between clients' requests and demands.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:45:04 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Diana", "Emily", ""], ["Kearns", "Michael", ""], ["Neel", "Seth", ""], ["Roth", "Aaron", ""]]}, {"id": "1912.06203", "submitter": "Bowen Li", "authors": "Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, Philip H. S. Torr", "title": "ManiGAN: Text-Guided Image Manipulation", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of our paper is to semantically edit parts of an image matching a\ngiven text that describes desired attributes (e.g., texture, colour, and\nbackground), while preserving other contents that are irrelevant to the text.\nTo achieve this, we propose a novel generative adversarial network (ManiGAN),\nwhich contains two key components: text-image affine combination module (ACM)\nand detail correction module (DCM). The ACM selects image regions relevant to\nthe given text and then correlates the regions with corresponding semantic\nwords for effective manipulation. Meanwhile, it encodes original image features\nto help reconstruct text-irrelevant contents. The DCM rectifies mismatched\nattributes and completes missing contents of the synthetic image. Finally, we\nsuggest a new metric for evaluating image manipulation results, in terms of\nboth the generation of new attributes and the reconstruction of text-irrelevant\ncontents. Extensive experiments on the CUB and COCO datasets demonstrate the\nsuperior performance of the proposed method. Code is available at\nhttps://github.com/mrlibw/ManiGAN.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:48:52 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:42:35 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Li", "Bowen", ""], ["Qi", "Xiaojuan", ""], ["Lukasiewicz", "Thomas", ""], ["Torr", "Philip H. S.", ""]]}, {"id": "1912.06207", "submitter": "Hidenori Tanaka", "authors": "Hidenori Tanaka, Aran Nayebi, Niru Maheswaranathan, Lane McIntosh,\n  Stephen A. Baccus, Surya Ganguli", "title": "From deep learning to mechanistic understanding in neuroscience: the\n  structure of retinal prediction", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2019", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep feedforward neural networks have achieved considerable success\nin modeling biological sensory processing, in terms of reproducing the\ninput-output map of sensory neurons. However, such models raise profound\nquestions about the very nature of explanation in neuroscience. Are we simply\nreplacing one complex system (a biological circuit) with another (a deep\nnetwork), without understanding either? Moreover, beyond neural\nrepresentations, are the deep network's computational mechanisms for generating\nneural responses the same as those in the brain? Without a systematic approach\nto extracting and understanding computational mechanisms from deep neural\nnetwork models, it can be difficult both to assess the degree of utility of\ndeep learning approaches in neuroscience, and to extract experimentally\ntestable hypotheses from deep networks. We develop such a systematic approach\nby combining dimensionality reduction and modern attribution methods for\ndetermining the relative importance of interneurons for specific visual\ncomputations. We apply this approach to deep network models of the retina,\nrevealing a conceptual understanding of how the retina acts as a predictive\nfeature extractor that signals deviations from expectations for diverse\nspatiotemporal stimuli. For each stimulus, our extracted computational\nmechanisms are consistent with prior scientific literature, and in one case\nyields a new mechanistic hypothesis. Thus overall, this work not only yields\ninsights into the computational mechanisms underlying the striking predictive\ncapabilities of the retina, but also places the framework of deep networks as\nneuroscientific models on firmer theoretical foundations, by providing a new\nroadmap to go beyond comparing neural representations to extracting and\nunderstand computational mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:54:08 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Tanaka", "Hidenori", ""], ["Nayebi", "Aran", ""], ["Maheswaranathan", "Niru", ""], ["McIntosh", "Lane", ""], ["Baccus", "Stephen A.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1912.06218", "submitter": "Chong Zhou", "authors": "Daniel Bolya, Chong Zhou, Fanyi Xiao, Yong Jae Lee", "title": "YOLACT++: Better Real-time Instance Segmentation", "comments": "Journal extension of our previous conference paper arXiv:1904.02689", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3014297", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple, fully-convolutional model for real-time (>30 fps)\ninstance segmentation that achieves competitive results on MS COCO evaluated on\na single Titan Xp, which is significantly faster than any previous\nstate-of-the-art approach. Moreover, we obtain this result after training on\nonly one GPU. We accomplish this by breaking instance segmentation into two\nparallel subtasks: (1) generating a set of prototype masks and (2) predicting\nper-instance mask coefficients. Then we produce instance masks by linearly\ncombining the prototypes with the mask coefficients. We find that because this\nprocess doesn't depend on repooling, this approach produces very high-quality\nmasks and exhibits temporal stability for free. Furthermore, we analyze the\nemergent behavior of our prototypes and show they learn to localize instances\non their own in a translation variant manner, despite being\nfully-convolutional. We also propose Fast NMS, a drop-in 12 ms faster\nreplacement for standard NMS that only has a marginal performance penalty.\nFinally, by incorporating deformable convolutions into the backbone network,\noptimizing the prediction head with better anchor scales and aspect ratios, and\nadding a novel fast mask re-scoring branch, our YOLACT++ model can achieve 34.1\nmAP on MS COCO at 33.5 fps, which is fairly close to the state-of-the-art\napproaches while still running at real-time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 18:58:03 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 03:42:52 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Bolya", "Daniel", ""], ["Zhou", "Chong", ""], ["Xiao", "Fanyi", ""], ["Lee", "Yong Jae", ""]]}, {"id": "1912.06236", "submitter": "Jie Fang", "authors": "Jie Fang, Shutao Xia, Jianwu Lin, Yong Jiang", "title": "Automatic Financial Feature Construction", "comments": "Its final version has been accepted by KDD ML in Finance 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PR q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic financial feature construction task, the state-of-the-art\ntechnic leverages reverse polish expression to represent the features, then use\ngenetic programming (GP) to conduct its evolution process. In this paper, we\npropose a new framework based on neural network, alpha discovery neural network\n(ADNN). In this work, we made several contributions. Firstly, in this task, we\nmake full use of neural network overwhelming advantage in feature extraction to\nconstruct highly informative features. Secondly, we use domain knowledge to\ndesign the object function, batch size, and sampling rules. Thirdly, we use\npre-training to replace the GP evolution process. According to neural network\nuniversal approximation theorem, pre-training can conduct a more effective and\nexplainable evolution process. Experiment shows that ADNN can remarkably\nproduce more diversified and higher informative features than GP. Besides, ADNN\ncan serve as a data augmentation algorithm. It further improves the the\nperformance of financial features constructed by GP.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 05:51:05 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 05:22:15 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 07:27:25 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 15:31:01 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Fang", "Jie", ""], ["Xia", "Shutao", ""], ["Lin", "Jianwu", ""], ["Jiang", "Yong", ""]]}, {"id": "1912.06248", "submitter": "Sayandev Mukherjee", "authors": "Sayandev Mukherjee", "title": "General Information Bottleneck Objectives and their Applications to\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view the Information Bottleneck Principle (IBP: Tishby et al., 1999;\nSchwartz-Ziv and Tishby, 2017) and Predictive Information Bottleneck Principle\n(PIBP: Still et al., 2007; Alemi, 2019) as special cases of a family of general\ninformation bottleneck objectives (IBOs). Each IBO corresponds to a particular\nconstrained optimization problem where the constraints apply to: (a) the mutual\ninformation between the training data and the learned model parameters or\nextracted representation of the data, and (b) the mutual information between\nthe learned model parameters or extracted representation of the data and the\ntest data (if any). The heuristics behind the IBP and PIBP are shown to yield\ndifferent constraints in the corresponding constrained optimization problem\nformulations. We show how other heuristics lead to a new IBO, different from\nboth the IBP and PIBP, and use the techniques from (Alemi, 2019) to derive and\noptimize a variational upper bound on the new IBO.\n  We then apply the theory of general IBOs to resolve the seeming contradiction\nbetween, on the one hand, the recommendations of IBP and PIBP to maximize the\nmutual information between the model parameters and test data, and on the\nother, recent information-theoretic results (see Xu and Raginsky, 2017)\nsuggesting that this mutual information should be minimized. The key insight is\nthat the heuristics (and thus the constraints in the constrained optimization\nproblems) of IBP and PIBP are not applicable to the scenario analyzed by (Xu\nand Raginsky, 2017) because the latter makes the additional assumption that the\nparameters of the trained model have been selected to minimize the empirical\nloss function. Aided by this insight, we formulate a new IBO that accounts for\nthis property of the parameters of the trained model, and derive and optimize a\nvariational bound on this IBO.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 22:46:58 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 22:07:33 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Mukherjee", "Sayandev", ""]]}, {"id": "1912.06255", "submitter": "Yiqiu Wang", "authors": "Yiqiu Wang, Yan Gu, Julian Shun", "title": "Theoretically-Efficient and Practical Parallel DBSCAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DBSCAN method for spatial clustering has received significant attention\ndue to its applicability in a variety of data analysis tasks. There are fast\nsequential algorithms for DBSCAN in Euclidean space that take $O(n\\log n)$ work\nfor two dimensions, sub-quadratic work for three or more dimensions, and can be\ncomputed approximately in linear work for any constant number of dimensions.\nHowever, existing parallel DBSCAN algorithms require quadratic work in the\nworst case, making them inefficient for large datasets. This paper bridges the\ngap between theory and practice of parallel DBSCAN by presenting new parallel\nalgorithms for Euclidean exact DBSCAN and approximate DBSCAN that match the\nwork bounds of their sequential counterparts, and are highly parallel\n(polylogarithmic depth). We present implementations of our algorithms along\nwith optimizations that improve their practical performance. We perform a\ncomprehensive experimental evaluation of our algorithms on a variety of\ndatasets and parameter settings. Our experiments on a 36-core machine with\nhyper-threading show that we outperform existing parallel DBSCAN\nimplementations by up to several orders of magnitude, and achieve speedups by\nup to 33x over the best sequential algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 23:09:20 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 19:41:12 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 21:10:23 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 23:55:26 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Wang", "Yiqiu", ""], ["Gu", "Yan", ""], ["Shun", "Julian", ""]]}, {"id": "1912.06262", "submitter": "Yue Zhao", "authors": "Yue Zhao and John Handley", "title": "Extracting clinical concepts from user queries", "comments": "8 pages, 4 figures. Added references. Corrected wording and typos,\n  results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical concept extraction often begins with clinical Named Entity\nRecognition (NER). Often trained on annotated clinical notes, clinical NER\nmodels tend to struggle with tagging clinical entities in user queries because\nof the structural differences between clinical notes and user queries. User\nqueries, unlike clinical notes, are often ungrammatical and incoherent. In many\ncases, user queries are compounded of multiple clinical entities, without comma\nor conjunction words separating them. By using as dataset a mixture of\nannotated clinical notes and synthesized user queries, we adapt a clinical NER\nmodel based on the BiLSTM-CRF architecture for tagging clinical entities in\nuser queries. Our contribution are the following: 1) We found that when trained\non a mixture of synthesized user queries and clinical notes, the NER model\nperforms better on both user queries and clinical notes. 2) We provide an\nend-to-end and easy-to-implement framework for clinical concept extraction from\nuser queries.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 23:18:16 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 19:10:03 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Zhao", "Yue", ""], ["Handley", "John", ""]]}, {"id": "1912.06290", "submitter": "Sean Hendryx", "authors": "Sean M. Hendryx, Andrew B. Leach, Paul D. Hein, Clayton T. Morrison", "title": "Meta-Learning Initializations for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend first-order model agnostic meta-learning algorithms (including\nFOMAML and Reptile) to image segmentation, present a novel neural network\narchitecture built for fast learning which we call EfficientLab, and leverage a\nformal definition of the test error of meta-learning algorithms to decrease\nerror on out of distribution tasks. We show state of the art results on the\nFSS-1000 dataset by meta-training EfficientLab with FOMAML and using Bayesian\noptimization to infer the optimal test-time adaptation routine hyperparameters.\nWe also construct a small benchmark dataset, FP-k, for the empirical study of\nhow meta-learning systems perform in both few- and many-shot settings. On the\nFP-k dataset, we show that meta-learned initializations provide value for\ncanonical few-shot image segmentation but their performance is quickly matched\nby conventional transfer learning with performance being equal beyond 10\nlabeled examples. Our code, meta-learned model, and the FP-k dataset are\navailable at https://github.com/ml4ai/mliis .\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 01:58:36 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 06:44:55 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 20:52:49 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 23:33:07 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Hendryx", "Sean M.", ""], ["Leach", "Andrew B.", ""], ["Hein", "Paul D.", ""], ["Morrison", "Clayton T.", ""]]}, {"id": "1912.06292", "submitter": "Aur\\'elien Bibaut", "authors": "Aur\\'elien F. Bibaut, Ivana Malenica, Nikos Vlassis, Mark J. van der\n  Laan", "title": "More Efficient Off-Policy Evaluation through Regularized Targeted\n  Learning", "comments": "We are uploading the full paper with the appendix as of 12/12/2019,\n  as we noticed that, unlike the main text, the appendix has not been made\n  available on PMLR's website. The version of the appendix in this document is\n  the same that we have been sending by email since June 2019 to readers who\n  solicited it", "journal-ref": "Proceedings of the 36th International Conference on Machine\n  Learning, PMLR 97:654-663, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy evaluation (OPE) in Reinforcement Learning\n(RL), where the aim is to estimate the performance of a new policy given\nhistorical data that may have been generated by a different policy, or\npolicies. In particular, we introduce a novel doubly-robust estimator for the\nOPE problem in RL, based on the Targeted Maximum Likelihood Estimation\nprinciple from the statistical causal inference literature. We also introduce\nseveral variance reduction techniques that lead to impressive performance gains\nin off-policy evaluation. We show empirically that our estimator uniformly wins\nover existing off-policy evaluation methods across multiple RL environments and\nvarious levels of model misspecification. Finally, we further the existing\ntheoretical analysis of estimators for the RL off-policy estimation problem by\nshowing their $O_P(1/\\sqrt{n})$ rate of convergence and characterizing their\nasymptotic distribution.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 02:04:22 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Bibaut", "Aur\u00e9lien F.", ""], ["Malenica", "Ivana", ""], ["Vlassis", "Nikos", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1912.06310", "submitter": "Shuai Han", "authors": "Shuai L\\\"u and Shuai Han and Wenbo Zhou and Junwei Zhang", "title": "Recruitment-imitation Mechanism for Evolutionary Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning, evolutionary algorithms and imitation learning are\nthree principal methods to deal with continuous control tasks. Reinforcement\nlearning is sample efficient, yet sensitive to hyper-parameters setting and\nneeds efficient exploration; Evolutionary algorithms are stable, but with low\nsample efficiency; Imitation learning is both sample efficient and stable,\nhowever it requires the guidance of expert data. In this paper, we propose\nRecruitment-imitation Mechanism (RIM) for evolutionary reinforcement learning,\na scalable framework that combines advantages of the three methods mentioned\nabove. The core of this framework is a dual-actors and single critic\nreinforcement learning agent. This agent can recruit high-fitness actors from\nthe population of evolutionary algorithms, which instructs itself to learn from\nexperience replay buffer. At the same time, low-fitness actors in the\nevolutionary population can imitate behavior patterns of the reinforcement\nlearning agent and improve their adaptability. Reinforcement and imitation\nlearners in this framework can be replaced with any off-policy actor-critic\nreinforcement learner or data-driven imitation learner. We evaluate RIM on a\nseries of benchmarks for continuous control tasks in Mujoco. The experimental\nresults show that RIM outperforms prior evolutionary or reinforcement learning\nmethods. The performance of RIM's components is significantly better than\ncomponents of previous evolutionary reinforcement learning algorithm, and the\nrecruitment using soft update enables reinforcement learning agent to learn\nfaster than that using hard update.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 03:26:14 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["L\u00fc", "Shuai", ""], ["Han", "Shuai", ""], ["Zhou", "Wenbo", ""], ["Zhang", "Junwei", ""]]}, {"id": "1912.06321", "submitter": "Joanne Truong", "authors": "Abhishek Kadian, Joanne Truong, Aaron Gokaslan, Alexander Clegg, Erik\n  Wijmans, Stefan Lee, Manolis Savva, Sonia Chernova, Dhruv Batra", "title": "Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World\n  Performance?", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters (RA-L) 2020", "doi": "10.1109/LRA.2020.3013848", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does progress in simulation translate to progress on robots? If one method\noutperforms another in simulation, how likely is that trend to hold in reality\non a robot? We examine this question for embodied PointGoal navigation,\ndeveloping engineering tools and a research paradigm for evaluating a simulator\nby its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy),\na library for seamless execution of identical code on simulated agents and\nrobots, transferring simulation-trained agents to a LoCoBot platform with a\none-line code change. Second, we investigate the sim2real predictivity of\nHabitat-Sim for PointGoal navigation. We 3D-scan a physical lab space to create\na virtualized replica, and run parallel tests of 9 different models in reality\nand simulation. We present a new metric called Sim-vs-Real Correlation\nCoefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as\nused for the CVPR19 challenge is low (0.18 for the success metric), suggesting\nthat performance differences in this simulator-based challenge do not persist\nafter physical deployment. This gap is largely due to AI agents learning to\nexploit simulator imperfections, abusing collision dynamics to 'slide' along\nwalls, leading to shortcuts through otherwise non-navigable space. Naturally,\nsuch exploits do not work in the real world. Our experiments show that it is\npossible to tune simulation parameters to improve sim2real predictivity (e.g.\nimproving $SRCC_{Succ}$ from 0.18 to 0.844), increasing confidence that\nin-simulation comparisons will translate to deployed systems in reality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 04:29:38 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 03:26:55 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Kadian", "Abhishek", ""], ["Truong", "Joanne", ""], ["Gokaslan", "Aaron", ""], ["Clegg", "Alexander", ""], ["Wijmans", "Erik", ""], ["Lee", "Stefan", ""], ["Savva", "Manolis", ""], ["Chernova", "Sonia", ""], ["Batra", "Dhruv", ""]]}, {"id": "1912.06322", "submitter": "Yoshiaki Inoue", "authors": "Yoshiaki Inoue", "title": "Queueing Analysis of GPU-Based Inference Servers with Dynamic Batching:\n  A Closed-Form Characterization", "comments": null, "journal-ref": null, "doi": "10.1016/j.peva.2020.102183", "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPU-accelerated computing is a key technology to realize high-speed inference\nservers using deep neural networks (DNNs). An important characteristic of\nGPU-based inference is that the computational efficiency, in terms of the\nprocessing speed and energy consumption, drastically increases by processing\nmultiple jobs together in a batch. In this paper, we formulate GPU-based\ninference servers as a batch service queueing model with batch-size dependent\nprocessing times. We first show that the energy efficiency of the server\nmonotonically increases with the arrival rate of inference jobs, which suggests\nthat it is energy-efficient to operate the inference server under a utilization\nlevel as high as possible within a latency requirement of inference jobs. We\nthen derive a closed-form upper bound for the mean latency, which provides a\nsimple characterization of the latency performance. Through simulation and\nnumerical experiments, we show that the exact value of the mean latency is well\napproximated by this upper bound. We further compare this upper bound with the\nlatency curve measured in real implementation of GPU-based inference servers\nand we show that the real performance curve is well explained by the derived\nsimple formula.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 04:39:16 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 03:30:02 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 02:03:16 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Inoue", "Yoshiaki", ""]]}, {"id": "1912.06332", "submitter": "Archit Rathore", "authors": "Archit Rathore, Nithin Chalapathi, Sourabh Palande, Bei Wang", "title": "TopoAct: Visually Exploring the Shape of Activations in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks such as GoogLeNet, ResNet, and BERT have achieved\nimpressive performance in tasks such as image and text classification. To\nunderstand how such performance is achieved, we probe a trained deep neural\nnetwork by studying neuron activations, i.e., combinations of neuron firings,\nat various layers of the network in response to a particular input. With a\nlarge number of inputs, we aim to obtain a global view of what neurons detect\nby studying their activations. In particular, we develop visualizations that\nshow the shape of the activation space, the organizational principle behind\nneuron activations, and the relationships of these activations within a layer.\nApplying tools from topological data analysis, we present TopoAct, a visual\nexploration system to study topological summaries of activation vectors. We\npresent exploration scenarios using TopoAct that provide valuable insights into\nlearned representations of neural networks. We expect TopoAct to give a\ntopological perspective that enriches the current toolbox of neural network\nanalysis, and to provide a basis for network architecture diagnosis and data\nanomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 06:15:08 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 05:01:41 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 23:41:17 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 06:27:22 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Rathore", "Archit", ""], ["Chalapathi", "Nithin", ""], ["Palande", "Sourabh", ""], ["Wang", "Bei", ""]]}, {"id": "1912.06342", "submitter": "Runxiong Wu", "authors": "Runxiong Wu and Xin Chen", "title": "MM Algorithms for Distance Covariance based Sufficient Dimension\n  Reduction and Sufficient Variable Selection", "comments": "26 pages, 4 figures", "journal-ref": "Computational Statistics & Data Analysis, 2021", "doi": "10.1016/j.csda.2020.107089", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sufficient dimension reduction (SDR) using distance covariance (DCOV) was\nrecently proposed as an approach to dimension-reduction problems. Compared with\nother SDR methods, it is model-free without estimating link function and does\nnot require any particular distributions on predictors (see Sheng and Yin,\n2013, 2016). However, the DCOV-based SDR method involves optimizing a nonsmooth\nand nonconvex objective function over the Stiefel manifold. To tackle the\nnumerical challenge, we novelly formulate the original objective function\nequivalently into a DC (Difference of Convex functions) program and construct\nan iterative algorithm based on the majorization-minimization (MM) principle.\nAt each step of the MM algorithm, we inexactly solve the quadratic subproblem\non the Stiefel manifold by taking one iteration of Riemannian Newton's method.\nThe algorithm can also be readily extended to sufficient variable selection\n(SVS) using distance covariance. We establish the convergence property of the\nproposed algorithm under some regularity conditions. Simulation studies show\nour algorithm drastically improves the computation efficiency and is robust\nacross various settings compared with the existing method. Supplemental\nmaterials for this article are available.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 07:08:15 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 08:50:08 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Wu", "Runxiong", ""], ["Chen", "Xin", ""]]}, {"id": "1912.06366", "submitter": "Shi Dong", "authors": "Shi Dong, Benjamin Van Roy, Zhengyuan Zhou", "title": "Provably Efficient Reinforcement Learning with Aggregated States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish that an optimistic variant of Q-learning applied to a\nfixed-horizon episodic Markov decision process with an aggregated state\nrepresentation incurs regret $\\tilde{\\mathcal{O}}(\\sqrt{H^5 M K} + \\epsilon\nHK)$, where $H$ is the horizon, $M$ is the number of aggregate states, $K$ is\nthe number of episodes, and $\\epsilon$ is the largest difference between any\npair of optimal state-action values associated with a common aggregate state.\nNotably, this regret bound does not depend on the number of states or actions\nand indicates that asymptotic per-period regret is no greater than $\\epsilon$,\nindependent of horizon. To our knowledge, this is the first such result that\napplies to reinforcement learning with nontrivial value function approximation\nwithout any restrictions on transition probabilities.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 09:10:18 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 06:05:39 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Dong", "Shi", ""], ["Van Roy", "Benjamin", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "1912.06384", "submitter": "Francesco Concas", "authors": "Francesco Concas, Julien Mineraud, Eemil Lagerspetz, Samu Varjonen,\n  Xiaoli Liu, Kai Puolam\\\"aki, Petteri Nurmi, Sasu Tarkoma", "title": "Low-Cost Outdoor Air Quality Monitoring and Sensor Calibration: A Survey\n  and Critical Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significance of air pollution and the problems associated with it are\nfueling deployments of air quality monitoring stations worldwide. The most\ncommon approach for air quality monitoring is to rely on environmental\nmonitoring stations, which unfortunately are very expensive both to acquire and\nto maintain. Hence environmental monitoring stations are typically sparsely\ndeployed, resulting in limited spatial resolution for measurements. Recently,\nlow-cost air quality sensors have emerged as an alternative that can improve\nthe granularity of monitoring. The use of low-cost air quality sensors,\nhowever, presents several challenges: they suffer from cross-sensitivities\nbetween different ambient pollutants; they can be affected by external factors,\nsuch as traffic, weather changes, and human behavior; and their accuracy\ndegrades over time. Periodic re-calibration can improve the accuracy of\nlow-cost sensors, particularly with machine-learning-based calibration, which\nhas shown great promise due to its capability to calibrate sensors in-field. In\nthis article, we survey the rapidly growing research landscape of low-cost\nsensor technologies for air quality monitoring and their calibration using\nmachine learning techniques. We also identify open research challenges and\npresent directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 10:07:10 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 10:00:14 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 08:17:48 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 17:39:21 GMT"}, {"version": "v5", "created": "Fri, 8 Jan 2021 15:12:30 GMT"}, {"version": "v6", "created": "Mon, 25 Jan 2021 13:41:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Concas", "Francesco", ""], ["Mineraud", "Julien", ""], ["Lagerspetz", "Eemil", ""], ["Varjonen", "Samu", ""], ["Liu", "Xiaoli", ""], ["Puolam\u00e4ki", "Kai", ""], ["Nurmi", "Petteri", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "1912.06385", "submitter": "Hazrat Ali", "authors": "Hazrat Ali, Feroz Karim, Junaid Javed Qureshi, Adnan Omer Abuassba,\n  Mohammad Farhad Bulbul", "title": "Seizure Prediction Using Bidirectional LSTM", "comments": "CyberDI 2019, Cyberspace Data and Intelligence, and Cyber-Living,\n  Syndrome, and Health pp 349-356", "journal-ref": null, "doi": "10.1007/978-981-15-1922-2_25", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Approximately, 50 million people in the world are affected by epilepsy. For\npatients, the anti-epileptic drugs are not always useful and these drugs may\nhave undesired side effects on a patient's health. If the seizure is predicted\nthe patients will have enough time to take preventive measures. The purpose of\nthis work is to investigate the application of bidirectional LSTM for seizure\nprediction. In this paper, we trained EEG data from canines on a double\nBidirectional LSTM layer followed by a fully connected layer. The data was\nprovided in the form of a Kaggle competition by American Epilepsy Society. The\nmain task was to classify the interictal and preictal EEG clips. Using this\nmodel, we obtained an AUC of 0.84 on the test dataset. Which shows that our\nclassifier's performance is above chance level on unseen data. The comparison\nwith the previous work shows that the use of bidirectional LSTM networks can\nachieve significantly better results than SVM and GRU networks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 10:08:45 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ali", "Hazrat", ""], ["Karim", "Feroz", ""], ["Qureshi", "Junaid Javed", ""], ["Abuassba", "Adnan Omer", ""], ["Bulbul", "Mohammad Farhad", ""]]}, {"id": "1912.06395", "submitter": "Wang Yifan", "authors": "Wang Yifan, Noam Aigerman, Vladimir G. Kim, Siddhartha Chaudhuri, Olga\n  Sorkine-Hornung", "title": "Neural Cages for Detail-Preserving 3D Deformations", "comments": "accepted for oral presentation at CVPR 2020, code available at\n  https://github.com/yifita/deep_cage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learnable representation for detail-preserving shape\ndeformation. The goal of our method is to warp a source shape to match the\ngeneral structure of a target shape, while preserving the surface details of\nthe source. Our method extends a traditional cage-based deformation technique,\nwhere the source shape is enclosed by a coarse control mesh termed \\emph{cage},\nand translations prescribed on the cage vertices are interpolated to any point\non the source mesh via special weight functions. The use of this sparse cage\nscaffolding enables preserving surface details regardless of the shape's\nintricacy and topology. Our key contribution is a novel neural network\narchitecture for predicting deformations by controlling the cage. We\nincorporate a differentiable cage-based deformation module in our architecture,\nand train our network end-to-end. Our method can be trained with common\ncollections of 3D models in an unsupervised fashion, without any cage-specific\nannotations. We demonstrate the utility of our method for synthesizing shape\nvariations and deformation transfer.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 10:25:00 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 13:33:27 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Yifan", "Wang", ""], ["Aigerman", "Noam", ""], ["Kim", "Vladimir G.", ""], ["Chaudhuri", "Siddhartha", ""], ["Sorkine-Hornung", "Olga", ""]]}, {"id": "1912.06407", "submitter": "Pedro Delicado", "authors": "Pedro Delicado and Daniel Pe\\~na", "title": "Understanding complex predictive models with Ghost Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a procedure for assigning a relevance measure to each explanatory\nvariable in a complex predictive model. We assume that we have a training set\nto fit the model and a test set to check the out of sample performance. First,\nthe individual relevance of each variable is computed by comparing the\npredictions in the test set, given by the model that includes all the variables\nwith those of another model in which the variable of interest is substituted by\nits ghost variable, defined as the prediction of this variable by using the\nrest of explanatory variables. Second, we check the joint effects among the\nvariables by using the eigenvalues of a relevance matrix that is the covariance\nmatrix of the vectors of individual effects. It is shown that in simple models,\nas linear or additive models, the proposed measures are related to standard\nmeasures of significance of the variables and in neural networks models (and in\nother algorithmic prediction models) the procedure provides information about\nthe joint and individual effects of the variables that is not usually available\nby other methods. The procedure is illustrated with simulated examples and the\nanalysis of a large real data set.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 11:06:12 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:25:06 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Delicado", "Pedro", ""], ["Pe\u00f1a", "Daniel", ""]]}, {"id": "1912.06409", "submitter": "Amir Nazemi", "authors": "Amir Nazemi, Paul Fieguth", "title": "Potential adversarial samples for white-box attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks can be highly vulnerable to small\nperturbations of their inputs, potentially a major issue or limitation on\nsystem robustness when using deep networks as classifiers. In this paper we\npropose a low-cost method to explore marginal sample data near trained\nclassifier decision boundaries, thus identifying potential adversarial samples.\nBy finding such adversarial samples it is possible to reduce the search space\nof adversarial attack algorithms while keeping a reasonable successful\nperturbation rate. In our developed strategy, the potential adversarial samples\nrepresent only 61% of the test data, but in fact cover more than 82% of the\nadversarial samples produced by iFGSM and 92% of the adversarial samples\nsuccessfully perturbed by DeepFool on CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 11:09:35 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Nazemi", "Amir", ""], ["Fieguth", "Paul", ""]]}, {"id": "1912.06415", "submitter": "Sudhakar Singh", "authors": "Pankaj Singh, Sudhakar Singh, P. K. Mishra, Rakhi Garg", "title": "RDD-Eclat: Approaches to Parallelize Eclat Algorithm on Spark RDD\n  Framework", "comments": "16 pages, 6 figures, ICCNCT 2019", "journal-ref": "ICCNCT 2019, LNDECT 44", "doi": "10.1007/978-3-030-37051-0_85", "report-no": "ICCNCT-171", "categories": "cs.DC cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initially, a number of frequent itemset mining (FIM) algorithms have been\ndesigned on the Hadoop MapReduce, a distributed big data processing framework.\nBut, due to heavy disk I/O, MapReduce is found to be inefficient for such\nhighly iterative algorithms. Therefore, Spark, a more efficient distributed\ndata processing framework, has been developed with in-memory computation and\nresilient distributed dataset (RDD) features to support the iterative\nalgorithms. On the Spark RDD framework, Apriori and FP-Growth based FIM\nalgorithms have been designed, but Eclat-based algorithm has not been explored\nyet. In this paper, RDD-Eclat, a parallel Eclat algorithm on the Spark RDD\nframework is proposed with its five variants. The proposed algorithms are\nevaluated on the various benchmark datasets, which shows that RDD-Eclat\noutperforms the Spark-based Apriori by many times. Also, the experimental\nresults show the scalability of the proposed algorithms on increasing the\nnumber of cores and size of the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 11:23:47 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Singh", "Pankaj", ""], ["Singh", "Sudhakar", ""], ["Mishra", "P. K.", ""], ["Garg", "Rakhi", ""]]}, {"id": "1912.06417", "submitter": "Felix Denzinger", "authors": "Felix Denzinger, Michael Wels, Katharina Breininger, Anika\n  Reidelsh\\\"ofer, Joachim Eckert, Michael S\\\"uhling, Axel Schmermund, Andreas\n  Maier", "title": "Deep Learning Algorithms for Coronary Artery Plaque Characterisation\n  from CCTA Scans", "comments": "Accepted at BVM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing coronary artery plaque segments with respect to their functional\nsignificance and therefore their influence to patient management in a\nnon-invasive setup is an important subject of current research. In this work we\ncompare and improve three deep learning algorithms for this task: A 3D\nrecurrent convolutional neural network (RCNN), a 2D multi-view ensemble\napproach based on texture analysis, and a newly proposed 2.5D approach. Current\nstate of the art methods utilising fluid dynamics based fractional flow reserve\n(FFR) simulation reach an AUC of up to 0.93 for the task of predicting an\nabnormal invasive FFR value. For the comparable task of predicting\nrevascularisation decision, we are able to improve the performance in terms of\nAUC of both existing approaches with the proposed modifications, specifically\nfrom 0.80 to 0.90 for the 3D-RCNN, and from 0.85 to 0.90 for the multi-view\ntexture-based ensemble. The newly proposed 2.5D approach achieves comparable\nresults with an AUC of 0.90.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 11:27:17 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Denzinger", "Felix", ""], ["Wels", "Michael", ""], ["Breininger", "Katharina", ""], ["Reidelsh\u00f6fer", "Anika", ""], ["Eckert", "Joachim", ""], ["S\u00fchling", "Michael", ""], ["Schmermund", "Axel", ""], ["Maier", "Andreas", ""]]}, {"id": "1912.06432", "submitter": "Luis Ignacio Lopera Gonz\\'alez", "authors": "Luis Ignacio Lopera Gonz\\'alez, Adrian Derungs, Oliver Amft\n  (Friedrich-Alexander University Erlangen-N\\\"urnberg, Erlangen, Germany)", "title": "A Bayesian Approach to Rule Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the increasing belief criterion in association\nrule mining. The criterion uses a recursive application of Bayes' theorem to\ncompute a rule's belief. Extracted rules are required to have their belief\nincrease with their last observation. We extend the taxonomy of association\nrule mining algorithms with a new branch for Bayesian rule mining~(BRM), which\nuses increasing belief as the rule selection criterion. In contrast, the\nwell-established frequent association rule mining~(FRM) branch relies on the\nminimum-support concept to extract rules. We derive properties of the\nincreasing belief criterion, such as the increasing belief boundary,\nno-prior-worries, and conjunctive premises. Subsequently, we implement a BRM\nalgorithm using the increasing belief criterion, and illustrate its\nfunctionality in three experiments: (1)~a proof-of-concept to illustrate BRM\nproperties, (2)~an analysis relating socioeconomic information and chemical\nexposure data, and (3)~mining behaviour routines in patients undergoing\nneurological rehabilitation. We illustrate how BRM is capable of extracting\nrare rules and does not suffer from support dilution. Furthermore, we show that\nBRM focuses on the individual event generating processes, while FRM focuses on\ntheir commonalities. We consider BRM's increasing belief as an alternative\ncriterion to thresholds on rule support, as often applied in FRM, to determine\nrule usefulness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 12:06:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 20:47:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Gonz\u00e1lez", "Luis Ignacio Lopera", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"], ["Derungs", "Adrian", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"], ["Amft", "Oliver", "", "Friedrich-Alexander University Erlangen-N\u00fcrnberg, Erlangen, Germany"]]}, {"id": "1912.06444", "submitter": "Zhao Zhang", "authors": "Yan Zhang, Zhao Zhang, Zheng Zhang, Mingbo Zhao, Li Zhang, Zhengjun\n  Zha, Meng Wang", "title": "Deep Self-representative Concept Factorization Network for\n  Representation Learning", "comments": "Accepted by SDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the unsupervised deep representation learning\nissue and technically propose a novel framework called Deep Self-representative\nConcept Factorization Network (DSCF-Net), for clustering deep features. To\nimprove the representation and clustering abilities, DSCF-Net explicitly\nconsiders discovering hidden deep semantic features, enhancing the robustness\nproper-ties of the deep factorization to noise and preserving the local\nman-ifold structures of deep features. Specifically, DSCF-Net seamlessly\nintegrates the robust deep concept factorization, deep self-expressive\nrepresentation and adaptive locality preserving feature learning into a unified\nframework. To discover hidden deep repre-sentations, DSCF-Net designs a\nhierarchical factorization architec-ture using multiple layers of linear\ntransformations, where the hierarchical representation is performed by\nformulating the prob-lem as optimizing the basis concepts in each layer to\nimprove the representation indirectly. DSCF-Net also improves the robustness by\nsubspace recovery for sparse error correction firstly and then performs the\ndeep factorization in the recovered visual subspace. To obtain\nlocality-preserving representations, we also present an adaptive deep\nself-representative weighting strategy by using the coefficient matrix as the\nadaptive reconstruction weights to keep the locality of representations.\nExtensive comparison results with several other related models show that\nDSCF-Net delivers state-of-the-art performance on several public databases.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 12:50:01 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 06:58:03 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 09:46:01 GMT"}, {"version": "v4", "created": "Sun, 29 Dec 2019 14:16:12 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Yan", ""], ["Zhang", "Zhao", ""], ["Zhang", "Zheng", ""], ["Zhao", "Mingbo", ""], ["Zhang", "Li", ""], ["Zha", "Zhengjun", ""], ["Wang", "Meng", ""]]}, {"id": "1912.06449", "submitter": "Doreen Jirak", "authors": "Doreen Jirak, David Biertimpel, Matthias Kerzel, Stefan Wermter", "title": "Solving Visual Object Ambiguities when Pointing: An Unsupervised\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Whenever we are addressing a specific object or refer to a certain spatial\nlocation, we are using referential or deictic gestures usually accompanied by\nsome verbal description. Especially pointing gestures are necessary to dissolve\nambiguities in a scene and they are of crucial importance when verbal\ncommunication may fail due to environmental conditions or when two persons\nsimply do not speak the same language. With the currently increasing advances\nof humanoid robots and their future integration in domestic domains, the\ndevelopment of gesture interfaces complementing human-robot interaction\nscenarios is of substantial interest. The implementation of an intuitive\ngesture scenario is still challenging because both the pointing intention and\nthe corresponding object have to be correctly recognized in real-time. The\ndemand increases when considering pointing gestures in a cluttered environment,\nas is the case in households. Also, humans perform pointing in many different\nways and those variations have to be captured. Research in this field often\nproposes a set of geometrical computations which do not scale well with the\nnumber of gestures and objects, use specific markers or a predefined set of\npointing directions. In this paper, we propose an unsupervised learning\napproach to model the distribution of pointing gestures using a\ngrowing-when-required (GWR) network. We introduce an interaction scenario with\na humanoid robot and define so-called ambiguity classes. Our implementation for\nthe hand and object detection is independent of any markers or skeleton models,\nthus it can be easily reproduced. Our evaluation comparing a baseline computer\nvision approach with our GWR model shows that the pointing-object association\nis well learned even in cases of ambiguities resulting from close object\nproximity.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 12:57:33 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Jirak", "Doreen", ""], ["Biertimpel", "David", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1912.06472", "submitter": "Thomas Carroll", "authors": "Thomas L. Carroll", "title": "Dimension of Reservoir Computers", "comments": "submitted to Chaos", "journal-ref": "Chaos vol. 30 issue 1 013102 2020", "doi": "10.1063/1.5128898", "report-no": null, "categories": "nlin.AO cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A reservoir computer is a complex dynamical system, often created by coupling\nnonlinear nodes in a network. The nodes are all driven by a common driving\nsignal. In this work, three dimension estimation methods, false nearest\nneighbor, covariance and Kaplan-Yorke dimensions, are used to estimate the\ndimension of the reservoir dynamical system. It is shown that the signals in\nthe reservoir system exist on a relatively low dimensional surface. Changing\nthe spectral radius of the reservoir network can increase the fractal dimension\nof the reservoir signals, leading to an increase in testing error.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 12:14:08 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Carroll", "Thomas L.", ""]]}, {"id": "1912.06497", "submitter": "Vahid Behzadan", "authors": "Ibrahim Baggili and Vahid Behzadan", "title": "Founding The Domain of AI Forensics", "comments": "Accepted for presentation at SafeAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread integration of AI in everyday and critical technologies,\nit seems inevitable to witness increasing instances of failure in AI systems.\nIn such cases, there arises a need for technical investigations that produce\nlegally acceptable and scientifically indisputable findings and conclusions on\nthe causes of such failures. Inspired by the domain of cyber forensics, this\npaper introduces the need for the establishment of AI Forensics as a new\ndiscipline under AI safety. Furthermore, we propose a taxonomy of the subfields\nunder this discipline, and present a discussion on the foundational challenges\nthat lay ahead of this new research area.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 23:39:57 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Baggili", "Ibrahim", ""], ["Behzadan", "Vahid", ""]]}, {"id": "1912.06508", "submitter": "Ching-Pei Lee", "authors": "Ching-pei Lee, Cong Han Lim, Stephen J. Wright", "title": "A Distributed Quasi-Newton Algorithm for Primal and Dual Regularized\n  Empirical Risk Minimization", "comments": "arXiv admin note: text overlap with arXiv:1803.01370", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a communication- and computation-efficient distributed\noptimization algorithm using second-order information for solving empirical\nrisk minimization (ERM) problems with a nonsmooth regularization term. Our\nalgorithm is applicable to both the primal and the dual ERM problem. Current\nsecond-order and quasi-Newton methods for this problem either do not work well\nin the distributed setting or work only for specific regularizers. Our\nalgorithm uses successive quadratic approximations of the smooth part, and we\ndescribe how to maintain an approximation of the (generalized) Hessian and\nsolve subproblems efficiently in a distributed manner. When applied to the\ndistributed dual ERM problem, unlike state of the art that takes only the\nblock-diagonal part of the Hessian, our approach is able to utilize global\ncurvature information and is thus magnitudes faster. The proposed method enjoys\nglobal linear convergence for a broad range of non-strongly convex problems\nthat includes the most commonly used ERMs, thus requiring lower communication\ncomplexity. It also converges on non-convex problems, so has the potential to\nbe used on applications such as deep learning. Computational results\ndemonstrate that our method significantly improves on communication cost and\nrunning time over the current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:25:37 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Lee", "Ching-pei", ""], ["Lim", "Cong Han", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1912.06525", "submitter": "Mustafa Coskun", "authors": "Mustafa Coskun, Abdelkader Baggag, Mehmet Koyuturk", "title": "Fast Computation of Katz Index for Efficient Processing of Link\n  Prediction Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network proximity computations are among the most common operations in\nvarious data mining applications, including link prediction and collaborative\nfiltering. A common measure of network proximity is Katz index, which has been\nshown to be among the best-performing path-based link prediction algorithms.\nWith the emergence of very large network databases, such proximity computations\nbecome an important part of query processing in these databases. Consequently,\nsignificant effort has been devoted to developing algorithms for efficient\ncomputation of Katz index between a given pair of nodes or between a query node\nand every other node in the network. Here, we present LRC-Katz, an algorithm\nbased on indexing and low-rank correction to accelerate Katz index-based\nnetwork proximity queries. Using a variety of very large real-world networks,\nwe show that LRC-Katz outperforms the fastest existing method, Conjugate\nGradient, for a wide range of parameter values. We also show that this\nacceleration in the computation of Katz index can be used to drastically\nimprove the efficiency of processing link prediction queries in very large\nnetworks. Motivated by this observation, we propose a new link prediction\nalgorithm that exploits modularity of networks that are encountered in\npractical applications. Our experimental results on the link prediction problem\nshow that our modularity based algorithm significantly outperforms the\nstate-of-the-art link prediction Katz method.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:26:38 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Coskun", "Mustafa", ""], ["Baggag", "Abdelkader", ""], ["Koyuturk", "Mehmet", ""]]}, {"id": "1912.06552", "submitter": "Daniel Heestermans Svendsen", "authors": "Daniel Heestermans Svendsen, Luca Martino, Gustau Camps-Valls", "title": "Active emulation of computer codes with Gaussian processes --\n  Application to remote sensing", "comments": "Keywords: Active learning; Gaussian process; Emulation; Design of\n  experiments; Computer code; Remote sensing; Radiative transfer model", "journal-ref": "Pattern Recognition (2019): 107103", "doi": "10.1016/j.patcog.2019.107103", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fields of science and engineering rely on running simulations with\ncomplex and computationally expensive models to understand the involved\nprocesses in the system of interest. Nevertheless, the high cost involved\nhamper reliable and exhaustive simulations. Very often such codes incorporate\nheuristics that ironically make them less tractable and transparent. This paper\nintroduces an active learning methodology for adaptively constructing surrogate\nmodels, i.e. emulators, of such costly computer codes in a multi-output\nsetting. The proposed technique is sequential and adaptive, and is based on the\noptimization of a suitable acquisition function. It aims to achieve accurate\napproximations, model tractability, as well as compact and expressive simulated\ndatasets. In order to achieve this, the proposed Active Multi-Output Gaussian\nProcess Emulator (AMOGAPE) combines the predictive capacity of Gaussian\nProcesses (GPs) with the design of an acquisition function that favors sampling\nin low density and fluctuating regions of the approximation functions.\nComparing different acquisition functions, we illustrate the promising\nperformance of the method for the construction of emulators with toy examples,\nas well as for a widely used remote sensing transfer code.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 15:16:13 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Svendsen", "Daniel Heestermans", ""], ["Martino", "Luca", ""], ["Camps-Valls", "Gustau", ""]]}, {"id": "1912.06570", "submitter": "Eli Chien", "authors": "Eli Chien, Antonia Maria Tulino, Jaime Llorca", "title": "Active learning in the geometric block model", "comments": "The conference version will appear in AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The geometric block model is a recently proposed generative model for random\ngraphs that is able to capture the inherent geometric properties of many\ncommunity detection problems, providing more accurate characterizations of\npractical community structures compared with the popular stochastic block\nmodel. Galhotra et al. recently proposed a motif-counting algorithm for\nunsupervised community detection in the geometric block model that is proved to\nbe near-optimal. They also characterized the regimes of the model parameters\nfor which the proposed algorithm can achieve exact recovery. In this work, we\ninitiate the study of active learning in the geometric block model. That is, we\nare interested in the problem of exactly recovering the community structure of\nrandom graphs following the geometric block model under arbitrary model\nparameters, by possibly querying the labels of a limited number of chosen\nnodes. We propose two active learning algorithms that combine the idea of\nmotif-counting with two different label query policies. Our main contribution\nis to show that sampling the labels of a vanishingly small fraction of nodes\n(sub-linear in the total number of nodes) is sufficient to achieve exact\nrecovery in the regimes under which the state-of-the-art unsupervised method\nfails. We validate the superior performance of our algorithms via numerical\nsimulations on both real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:41:50 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Chien", "Eli", ""], ["Tulino", "Antonia Maria", ""], ["Llorca", "Jaime", ""]]}, {"id": "1912.06606", "submitter": "Qifeng Chen", "authors": "Xuanchi Ren, Haoran Li, Zijian Huang, Qifeng Chen", "title": "Music-oriented Dance Video Synthesis with Pose Perceptual Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learning-based approach with pose perceptual loss for automatic\nmusic video generation. Our method can produce a realistic dance video that\nconforms to the beats and rhymes of almost any given music. To achieve this, we\nfirstly generate a human skeleton sequence from music and then apply the\nlearned pose-to-appearance mapping to generate the final video. In the stage of\ngenerating skeleton sequences, we utilize two discriminators to capture\ndifferent aspects of the sequence and propose a novel pose perceptual loss to\nproduce natural dances. Besides, we also provide a new cross-modal evaluation\nto evaluate the dance quality, which is able to estimate the similarity between\ntwo modalities of music and dance. Finally, a user study is conducted to\ndemonstrate that dance video synthesized by the presented approach produces\nsurprisingly realistic results. The results are shown in the supplementary\nvideo at https://youtu.be/0rMuFMZa_K4\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 17:01:21 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Ren", "Xuanchi", ""], ["Li", "Haoran", ""], ["Huang", "Zijian", ""], ["Chen", "Qifeng", ""]]}, {"id": "1912.06631", "submitter": "Angshul Majumdar Dr.", "authors": "Jyoti Maggu, Prerna Singh and Angshul Majumdar", "title": "Multi-echo Reconstruction from Partial K-space Scans via Adaptively\n  Learnt Basis", "comments": "Final version accepted at Magnetic Resonance Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi echo imaging, multiple T1/T2 weighted images of the same cross\nsection is acquired. Acquiring multiple scans is time consuming. In order to\naccelerate, compressed sensing based techniques have been proposed. In recent\ntimes, it has been observed in several areas of traditional compressed sensing,\nthat instead of using fixed basis (wavelet, DCT etc.), considerably better\nresults can be achieved by learning the basis adaptively from the data.\nMotivated by these studies, we propose to employ such adaptive learning\ntechniques to improve reconstruction of multi-echo scans. This work will be\nbased on two basis learning models synthesis (better known as dictionary\nlearning) and analysis (known as transform learning). We modify these basic\nmethods by incorporating structure of the multi echo scans. Our work shows that\nwe can indeed significantly improve multi-echo imaging over compressed sensing\nbased techniques and other unstructured adaptive sparse recovery methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:47:51 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Maggu", "Jyoti", ""], ["Singh", "Prerna", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.06638", "submitter": "James Tian", "authors": "James Yi Tian, Alexander P. Kreuzer, Pai-Hung Chen, Hans-Martin Will", "title": "WaLDORf: Wasteless Language-model Distillation On Reading-comprehension", "comments": "Added Figure, minor edits for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer based Very Large Language Models (VLLMs) like BERT, XLNet and\nRoBERTa, have recently shown tremendous performance on a large variety of\nNatural Language Understanding (NLU) tasks. However, due to their size, these\nVLLMs are extremely resource intensive and cumbersome to deploy at production\ntime. Several recent publications have looked into various ways to distil\nknowledge from a transformer based VLLM (most commonly BERT-Base) into a\nsmaller model which can run much faster at inference time. Here, we propose a\nnovel set of techniques which together produce a task-specific hybrid\nconvolutional and transformer model, WaLDORf, that achieves state-of-the-art\ninference speed while still being more accurate than previous distilled models.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 18:15:37 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:08:58 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Tian", "James Yi", ""], ["Kreuzer", "Alexander P.", ""], ["Chen", "Pai-Hung", ""], ["Will", "Hans-Martin", ""]]}, {"id": "1912.06640", "submitter": "Steven Schwarcz", "authors": "Steven Schwarcz, Peng Xu, David D'Ambrosio, Juhana Kangaspunta, Anelia\n  Angelova, Huong Phan, Navdeep Jaitly", "title": "SPIN: A High Speed, High Resolution Vision Dataset for Tracking and\n  Action Recognition in Ping Pong", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new high resolution, high frame rate stereo video dataset,\nwhich we call SPIN, for tracking and action recognition in the game of ping\npong. The corpus consists of ping pong play with three main annotation streams\nthat can be used to learn tracking and action recognition models -- tracking of\nthe ping pong ball and poses of humans in the videos and the spin of the ball\nbeing hit by humans. The training corpus consists of 53 hours of data with\nlabels derived from previous models in a semi-supervised method. The testing\ncorpus contains 1 hour of data with the same information, except that crowd\ncompute was used to obtain human annotations of the ball position, from which\nball spin has been derived. Along with the dataset we introduce several\nbaseline models that were trained on this data. The models were specifically\nchosen to be able to perform inference at the same rate as the images are\ngenerated -- specifically 150 fps. We explore the advantages of multi-task\ntraining on this data, and also show interesting properties of ping pong ball\ntrajectories that are derived from our observational data, rather than from\nprior physics models. To our knowledge this is the first large scale dataset of\nping pong; we offer it to the community as a rich dataset that can be used for\na large variety of machine learning and vision tasks such as tracking, pose\nestimation, semi-supervised and unsupervised learning and generative modeling.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 18:30:29 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Schwarcz", "Steven", ""], ["Xu", "Peng", ""], ["D'Ambrosio", "David", ""], ["Kangaspunta", "Juhana", ""], ["Angelova", "Anelia", ""], ["Phan", "Huong", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1912.06650", "submitter": "Behnam Kiani Kalejahi", "authors": "Jala Quluzada, Sabnam Maharramli", "title": "The development of blockchain technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain technology is the first successful Bitcoin Network. It enables the\nledger to become more decentralized and secure. Since it is not limited to\nbitcoin and controlled by third parties by government, corporations or banks,\nthe technology is capturing the number of industries including cryptocurrency,\ninfrastructure& hardware, financial technology, Internet&mobile and so on.\nBlockchain is used as a public ledger to verify all transactions of peer to\npeer systems and to maintain traded bitcoin spending from central authorities\nwhile transactions have been distributed by Bitcoin. Achieving high\nblockchain-based performance and privacy & security are global issues that are\ndesire to be overcome as claims show they are still significant challenges in\nmany blockchain applications. Thus, this paper provides an introduction of\nBlockchain and the process of this technology in a way of outlining blockchain\ntypes. In addition, recent advances & challenges, real economy integration and\ncurrent situations of this technology have been listed.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 07:14:18 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 13:12:50 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Quluzada", "Jala", ""], ["Maharramli", "Sabnam", ""]]}, {"id": "1912.06667", "submitter": "Naim Rashid", "authors": "Naim U. Rashid, Daniel J. Luckett, Jingxiang Chen, Michael T. Lawson,\n  Longshaokan Wang, Yunshu Zhang, Eric B. Laber, Yufeng Liu, Jen Jen Yeh,\n  Donglin Zeng, Michael R. Kosorok", "title": "High dimensional precision medicine from patient-derived xenografts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of human cancer often results in significant heterogeneity in\nresponse to treatment. Precision medicine offers potential to improve patient\noutcomes by leveraging this heterogeneity. Individualized treatment rules\n(ITRs) formalize precision medicine as maps from the patient covariate space\ninto the space of allowable treatments. The optimal ITR is that which maximizes\nthe mean of a clinical outcome in a population of interest. Patient-derived\nxenograft (PDX) studies permit the evaluation of multiple treatments within a\nsingle tumor and thus are ideally suited for estimating optimal ITRs. PDX data\nare characterized by correlated outcomes, a high-dimensional feature space, and\na large number of treatments. Existing methods for estimating optimal ITRs do\nnot take advantage of the unique structure of PDX data or handle the associated\nchallenges well. In this paper, we explore machine learning methods for\nestimating optimal ITRs from PDX data. We analyze data from a large PDX study\nto identify biomarkers that are informative for developing personalized\ntreatment recommendations in multiple cancers. We estimate optimal ITRs using\nregression-based approaches such as Q-learning and direct search methods such\nas outcome weighted learning. Finally, we implement a superlearner approach to\ncombine a set of estimated ITRs and show that the resulting ITR performs better\nthan any of the input ITRs, mitigating uncertainty regarding user choice of any\nparticular ITR estimation methodology. Our results indicate that PDX data are a\nvaluable resource for developing individualized treatment strategies in\noncology.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 19:17:27 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Rashid", "Naim U.", ""], ["Luckett", "Daniel J.", ""], ["Chen", "Jingxiang", ""], ["Lawson", "Michael T.", ""], ["Wang", "Longshaokan", ""], ["Zhang", "Yunshu", ""], ["Laber", "Eric B.", ""], ["Liu", "Yufeng", ""], ["Yeh", "Jen Jen", ""], ["Zeng", "Donglin", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "1912.06670", "submitter": "Josh Meyer", "authors": "Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael\n  Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M. Tyers, Gregor\n  Weber", "title": "Common Voice: A Massively-Multilingual Speech Corpus", "comments": "Accepted to LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Common Voice corpus is a massively-multilingual collection of transcribed\nspeech intended for speech technology research and development. Common Voice is\ndesigned for Automatic Speech Recognition purposes but can be useful in other\ndomains (e.g. language identification). To achieve scale and sustainability,\nthe Common Voice project employs crowdsourcing for both data collection and\ndata validation. The most recent release includes 29 languages, and as of\nNovember 2019 there are a total of 38 languages collecting data. Over 50,000\nindividuals have participated so far, resulting in 2,500 hours of collected\naudio. To our knowledge this is the largest audio corpus in the public domain\nfor speech recognition, both in terms of number of hours and number of\nlanguages. As an example use case for Common Voice, we present speech\nrecognition experiments using Mozilla's DeepSpeech Speech-to-Text toolkit. By\napplying transfer learning from a source English model, we find an average\nCharacter Error Rate improvement of 5.99 +/- 5.48 for twelve target languages\n(German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton,\nTatar, Chuvash, and Kabyle). For most of these languages, these are the first\never published results on end-to-end Automatic Speech Recognition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 19:22:44 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 20:37:08 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Ardila", "Rosana", ""], ["Branson", "Megan", ""], ["Davis", "Kelly", ""], ["Henretty", "Michael", ""], ["Kohler", "Michael", ""], ["Meyer", "Josh", ""], ["Morais", "Reuben", ""], ["Saunders", "Lindsay", ""], ["Tyers", "Francis M.", ""], ["Weber", "Gregor", ""]]}, {"id": "1912.06675", "submitter": "Gilmer Valdes", "authors": "Gilmer Valdes, Yannet Interian, Efstathios D. Gennatas Mark J. Van der\n  Laan", "title": "Conditional Super Learner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the Conditional Super Learner (CSL), an algorithm\nwhich selects the best model candidate from a library conditional on the\ncovariates. The CSL expands the idea of using cross-validation to select the\nbest model and merges it with meta learning. Here we propose a specific\nalgorithm that finds a local minimum to the problem posed, proof that it\nconverges at a rate faster than $O_p(n^{-1/4})$ and offers extensive empirical\nevidence that it is an excellent candidate to substitute stacking or for the\nanalysis of Hierarchical problems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 19:44:16 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Valdes", "Gilmer", ""], ["Interian", "Yannet", ""], ["Van der Laan", "Efstathios D. Gennatas Mark J.", ""]]}, {"id": "1912.06680", "submitter": "Filip Wolski", "authors": "OpenAI: Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung,\n  Przemys{\\l}aw D\\k{e}biak, Christy Dennison, David Farhi, Quirin Fischer,\n  Shariq Hashme, Chris Hesse, Rafal J\\'ozefowicz, Scott Gray, Catherine Olsson,\n  Jakub Pachocki, Michael Petrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim\n  Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever,\n  Jie Tang, Filip Wolski, Susan Zhang", "title": "Dota 2 with Large Scale Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On April 13th, 2019, OpenAI Five became the first AI system to defeat the\nworld champions at an esports game. The game of Dota 2 presents novel\nchallenges for AI systems such as long time horizons, imperfect information,\nand complex, continuous state-action spaces, all challenges which will become\nincreasingly central to more capable AI systems. OpenAI Five leveraged existing\nreinforcement learning techniques, scaled to learn from batches of\napproximately 2 million frames every 2 seconds. We developed a distributed\ntraining system and tools for continual training which allowed us to train\nOpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG),\nOpenAI Five demonstrates that self-play reinforcement learning can achieve\nsuperhuman performance on a difficult task.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 19:56:40 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["OpenAI", "", ""], [":", "", ""], ["Berner", "Christopher", ""], ["Brockman", "Greg", ""], ["Chan", "Brooke", ""], ["Cheung", "Vicki", ""], ["D\u0119biak", "Przemys\u0142aw", ""], ["Dennison", "Christy", ""], ["Farhi", "David", ""], ["Fischer", "Quirin", ""], ["Hashme", "Shariq", ""], ["Hesse", "Chris", ""], ["J\u00f3zefowicz", "Rafal", ""], ["Gray", "Scott", ""], ["Olsson", "Catherine", ""], ["Pachocki", "Jakub", ""], ["Petrov", "Michael", ""], ["Pinto", "Henrique P. d. O.", ""], ["Raiman", "Jonathan", ""], ["Salimans", "Tim", ""], ["Schlatter", "Jeremy", ""], ["Schneider", "Jonas", ""], ["Sidor", "Szymon", ""], ["Sutskever", "Ilya", ""], ["Tang", "Jie", ""], ["Wolski", "Filip", ""], ["Zhang", "Susan", ""]]}, {"id": "1912.06688", "submitter": "Joerg Zimmermann", "authors": "Kristina Enes, Hassan Errami, Moritz Wolter, Tim Krake, Bernhard\n  Eberhardt, Andreas Weber, J\\\"org Zimmermann", "title": "Unsupervised and Generic Short-Term Anticipation of Human Body Motions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various neural network based methods are capable of anticipating human body\nmotions from data for a short period of time. What these methods lack are the\ninterpretability and explainability of the network and its results. We propose\nto use Dynamic Mode Decomposition with delays to represent and anticipate human\nbody motions. Exploring the influence of the number of delays on the\nreconstruction and prediction of various motion classes, we show that the\nanticipation errors in our results are comparable or even better for very short\nanticipation times ($<0.4$ sec) to a recurrent neural network based method. We\nperceive our method as a first step towards the interpretability of the results\nby representing human body motions as linear combinations of ``factors''. In\naddition, compared to the neural network based methods large training times are\nnot needed. Actually, our methods do not even regress to any other motions than\nthe one to be anticipated and hence is of a generic nature.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 20:13:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Enes", "Kristina", ""], ["Errami", "Hassan", ""], ["Wolter", "Moritz", ""], ["Krake", "Tim", ""], ["Eberhardt", "Bernhard", ""], ["Weber", "Andreas", ""], ["Zimmermann", "J\u00f6rg", ""]]}, {"id": "1912.06689", "submitter": "Valeriy Avanesov", "authors": "Valeriy Avanesov", "title": "Data-driven confidence bands for distributed nonparametric regression", "comments": "COLT2020 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process Regression and Kernel Ridge Regression are popular\nnonparametric regression approaches. Unfortunately, they suffer from high\ncomputational complexity rendering them inapplicable to the modern massive\ndatasets. To that end a number of approximations have been suggested, some of\nthem allowing for a distributed implementation. One of them is the divide and\nconquer approach, splitting the data into a number of partitions, obtaining the\nlocal estimates and finally averaging them. In this paper we suggest a novel\ncomputationally efficient fully data-driven algorithm, quantifying uncertainty\nof this method, yielding frequentist $L_2$-confidence bands. We rigorously\ndemonstrate validity of the algorithm. Another contribution of the paper is a\nminimax-optimal high-probability bound for the averaged estimator,\ncomplementing and generalizing the known risk bounds.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 20:13:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 18:17:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Avanesov", "Valeriy", ""]]}, {"id": "1912.06708", "submitter": "Mogens Graf Plessen", "authors": "Mogens Graf Plessen", "title": "A posteriori Trading-inspired Model-free Time Series Segmentation", "comments": "9 pages, double column, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of multivariate time series segmentation this paper\nproposes a method inspired by a posteriori optimal trading. After a\nnormalization step time series are treated channel-wise as surrogate stock\nprices that can be traded optimally a posteriori in a virtual portfolio holding\neither stock or cash. Linear transaction costs are interpreted as\nhyperparameters for noise filtering. Resulting trading signals as well as\nresulting trading signals obtained on the reversed time series are used for\nunsupervised labeling, before a consensus over channels is reached that\ndetermines segmentation time instants. The method is model-free such that no\nmodel prescriptions for segments are made. Benefits of proposed approach\ninclude simplicity, computational efficiency and adaptability to a wide range\nof different shapes of time series. Performance is demonstrated on synthetic\nand real-world data, including a large-scale dataset comprising a multivariate\ntime series of dimension 1000 and length 2709. Proposed method is compared to a\npopular model-based bottom-up approach fitting piecewise affine models and to a\nrecent model-based top-down approach fitting Gaussian models, and found to be\nconsistently faster while producing more intuitive results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 06:14:03 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Plessen", "Mogens Graf", ""]]}, {"id": "1912.06719", "submitter": "Susan Zhang", "authors": "Jonathan Raiman, Susan Zhang, Christy Dennison", "title": "Neural Network Surgery with Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost to train machine learning models has been increasing exponentially,\nmaking exploration and research into the correct features and architecture a\ncostly or intractable endeavor at scale. However, using a technique named\n\"surgery\" OpenAI Five was continuously trained to play the game DotA 2 over the\ncourse of 10 months through 20 major changes in features and architecture.\nSurgery transfers trained weights from one network to another after a selection\nprocess to determine which sections of the model are unchanged and which must\nbe re-initialized. In the past, the selection process relied on heuristics,\nmanual labor, or pre-existing boundaries in the structure of the model,\nlimiting the ability to salvage experiments after modifications of the feature\nset or input reorderings.\n  We propose a solution to automatically determine which components of a neural\nnetwork model should be salvaged and which require retraining. We achieve this\nby allowing the model to operate over discrete sets of features and use\nset-based operations to determine the exact relationship between inputs and\noutputs, and how they change across tweaks in model architecture. In this\npaper, we introduce the methodology for enabling neural networks to operate on\nsets, derive two methods for detecting feature-parameter interaction maps, and\nshow their equivalence. We empirically validate that we can surgery weights\nacross feature and architecture changes to the OpenAI Five model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 21:41:39 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 17:16:00 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Raiman", "Jonathan", ""], ["Zhang", "Susan", ""], ["Dennison", "Christy", ""]]}, {"id": "1912.06721", "submitter": "Susan Zhang", "authors": "Jonathan Raiman, Susan Zhang, Filip Wolski", "title": "Long-Term Planning and Situational Awareness in OpenAI Five", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how knowledge about the world is represented within model-free\ndeep reinforcement learning methods is a major challenge given the black box\nnature of its learning process within high-dimensional observation and action\nspaces. AlphaStar and OpenAI Five have shown that agents can be trained without\nany explicit hierarchical macro-actions to reach superhuman skill in games that\nrequire taking thousands of actions before reaching the final goal. Assessing\nthe agent's plans and game understanding becomes challenging given the lack of\nhierarchy or explicit representations of macro-actions in these models, coupled\nwith the incomprehensible nature of the internal representations.\n  In this paper, we study the distributed representations learned by OpenAI\nFive to investigate how game knowledge is gradually obtained over the course of\ntraining. We also introduce a general technique for learning a model from the\nagent's hidden states to identify the formation of plans and subgoals. We show\nthat the agent can learn situational similarity across actions, and find\nevidence of planning towards accomplishing subgoals minutes before they are\nexecuted. We perform a qualitative analysis of these predictions during the\ngames against the DotA 2 world champions OG in April 2019.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 21:49:30 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Raiman", "Jonathan", ""], ["Zhang", "Susan", ""], ["Wolski", "Filip", ""]]}, {"id": "1912.06723", "submitter": "Daniel Karl I. Weidele", "authors": "Daniel Karl I. Weidele, Justin D. Weisz, Eno Oduor, Michael Muller,\n  Josh Andres, Alexander Gray, Dakuo Wang", "title": "AutoAIViz: Opening the Blackbox of Automated Artificial Intelligence\n  with Conditional Parallel Coordinates", "comments": "5 pages, 1 figure, IUI2020", "journal-ref": null, "doi": "10.1145/3377325.3377538", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) can now automate the algorithm selection,\nfeature engineering, and hyperparameter tuning steps in a machine learning\nworkflow. Commonly known as AutoML or AutoAI, these technologies aim to relieve\ndata scientists from the tedious manual work. However, today's AutoAI systems\noften present only limited to no information about the process of how they\nselect and generate model results. Thus, users often do not understand the\nprocess, neither do they trust the outputs. In this short paper, we provide a\nfirst user evaluation by 10 data scientists of an experimental system,\nAutoAIViz, that aims to visualize AutoAI's model generation process. We find\nthat the proposed system helps users to complete the data science tasks, and\nincreases their understanding, toward the goal of increasing trust in the\nAutoAI system.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 21:53:01 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 16:32:18 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 15:51:23 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Weidele", "Daniel Karl I.", ""], ["Weisz", "Justin D.", ""], ["Oduor", "Eno", ""], ["Muller", "Michael", ""], ["Andres", "Josh", ""], ["Gray", "Alexander", ""], ["Wang", "Dakuo", ""]]}, {"id": "1912.06728", "submitter": "Sheena Panthaplackel", "authors": "Sheena Panthaplackel, Milos Gligoric, Raymond J. Mooney, Junyi Jessy\n  Li", "title": "Associating Natural Language Comment and Source Code Entities", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comments are an integral part of software development; they are natural\nlanguage descriptions associated with source code elements. Understanding\nexplicit associations can be useful in improving code comprehensibility and\nmaintaining the consistency between code and comments. As an initial step\ntowards this larger goal, we address the task of associating entities in\nJavadoc comments with elements in Java source code. We propose an approach for\nautomatically extracting supervised data using revision histories of open\nsource projects and present a manually annotated evaluation dataset for this\ntask. We develop a binary classifier and a sequence labeling model by crafting\na rich feature set which encompasses various aspects of code, comments, and the\nrelationships between them. Experiments show that our systems outperform\nseveral baselines learning from the proposed supervision.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:06:59 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Panthaplackel", "Sheena", ""], ["Gligoric", "Milos", ""], ["Mooney", "Raymond J.", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "1912.06729", "submitter": "Alejandro Murillo-Gonz\\'alez", "authors": "Alejandro Murillo-Gonz\\'alez, Jos\\'e David Ortega Pab\\'on, Juan\n  Guillermo Paniagua, Olga Luc\\'ia Quintero Montoya", "title": "Laguerre-Gauss Preprocessing: Line Profiles as Image Features for Aerial\n  Images Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image preprocessing methodology based on Fourier analysis together with\nthe Laguerre-Gauss Spatial Filter is proposed. This is an alternative to obtain\nfeatures from aerial images that reduces the feature space significantly,\npreserving enough information for classification tasks. Experiments on a\nchallenging data set of aerial images show that it is possible to learn a\nrobust classifier from this transformed and smaller feature space using simple\nmodels, with similar performance to the complete feature space and more complex\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:21:26 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Murillo-Gonz\u00e1lez", "Alejandro", ""], ["Pab\u00f3n", "Jos\u00e9 David Ortega", ""], ["Paniagua", "Juan Guillermo", ""], ["Montoya", "Olga Luc\u00eda Quintero", ""]]}, {"id": "1912.06732", "submitter": "Tim De Ryck", "authors": "Tim De Ryck, Siddhartha Mishra, Deep Ray", "title": "On the approximation of rough functions with deep neural networks", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": "ETH - SAM report 2020-07", "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks and the ENO procedure are both efficient frameworks for\napproximating rough functions. We prove that at any order, the ENO\ninterpolation procedure can be cast as a deep ReLU neural network. This\nsurprising fact enables the transfer of several desirable properties of the ENO\nprocedure to deep neural networks, including its high-order accuracy at\napproximating Lipschitz functions. Numerical tests for the resulting neural\nnetworks show excellent performance for approximating solutions of nonlinear\nconservation laws and at data compression.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:48:36 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:27:30 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["De Ryck", "Tim", ""], ["Mishra", "Siddhartha", ""], ["Ray", "Deep", ""]]}, {"id": "1912.06733", "submitter": "Daniel Peterson", "authors": "Daniel Peterson, Pallika Kanani, Virendra J. Marathe", "title": "Private Federated Learning with Domain Adaptation", "comments": "Presented at the Workshop on Federated Learning for Data Privacy and\n  Confidentiality (in Conjunction with NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed machine learning (ML) paradigm that\nenables multiple parties to jointly re-train a shared model without sharing\ntheir data with any other parties, offering advantages in both scale and\nprivacy. We propose a framework to augment this collaborative model-building\nwith per-user domain adaptation. We show that this technique improves model\naccuracy for all users, using both real and synthetic data, and that this\nimprovement is much more pronounced when differential privacy bounds are\nimposed on the FL model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:48:43 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Peterson", "Daniel", ""], ["Kanani", "Pallika", ""], ["Marathe", "Virendra J.", ""]]}, {"id": "1912.06745", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Katia Sycara", "title": "An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text", "comments": "19 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 23:32:38 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Sycara", "Katia", ""]]}, {"id": "1912.06752", "submitter": "Jeremy Morton", "authors": "Jeremy Morton and Freddie D. Witherden and Mykel J. Kochenderfer", "title": "Parameter-Conditioned Sequential Generative Modeling of Fluid Flows", "comments": "29 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost associated with simulating fluid flows can make it\ninfeasible to run many simulations across multiple flow conditions. Building\nupon concepts from generative modeling, we introduce a new method for learning\nneural network models capable of performing efficient parameterized simulations\nof fluid flows. Evaluated on their ability to simulate both two-dimensional and\nthree-dimensional fluid flows, trained models are shown to capture local and\nglobal properties of the flow fields at a wide array of flow conditions.\nFurthermore, flow simulations generated by the trained models are shown to be\norders of magnitude faster than the corresponding computational fluid dynamics\nsimulations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 00:16:53 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Morton", "Jeremy", ""], ["Witherden", "Freddie D.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1912.06760", "submitter": "John Moberg", "authors": "John Moberg, Lennart Svensson, Juliano Pinto, Henk Wymeersch", "title": "Bayesian Linear Regression on Deep Representations", "comments": "4th workshop on Bayesian Deep Learning (NeurIPS 2019), Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple approach to obtaining uncertainty-aware neural networks for\nregression is to do Bayesian linear regression (BLR) on the representation from\nthe last hidden layer. Recent work [Riquelme et al., 2018, Azizzadenesheli et\nal., 2018] indicates that the method is promising, though it has been limited\nto homoscedastic noise. In this paper, we propose a novel variation that\nenables the method to flexibly model heteroscedastic noise. The method is\nbenchmarked against two prominent alternative methods on a set of standard\ndatasets, and finally evaluated as an uncertainty-aware model in model-based\nreinforcement learning. Our experiments indicate that the method is competitive\nwith standard ensembling, and ensembles of BLR outperforms the methods we\ncompared to.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 01:03:05 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Moberg", "John", ""], ["Svensson", "Lennart", ""], ["Pinto", "Juliano", ""], ["Wymeersch", "Henk", ""]]}, {"id": "1912.06761", "submitter": "Yannet Interian", "authors": "Miguel Romero and Yannet Interian and Timothy Solberg and Gilmer\n  Valdes", "title": "Targeted transfer learning to improve performance in small medical\n  physics datasets", "comments": null, "journal-ref": null, "doi": "10.1002/mp.14507", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of Machine Learning has produced significant advances in many\nfields. For image-based tasks, however, the use of deep learning remains\nchallenging in small datasets. In this article, we review, evaluate and compare\nthe current state-of-the-art techniques in training neural networks to\nelucidate which techniques work best for small datasets. We further propose a\npath forward for the improvement of model accuracy in medical imaging\napplications. We observed best results from one cycle training, discriminative\nlearning rates with gradual freezing and parameter modification after transfer\nlearning. We also established that when datasets are small, transfer learning\nplays an important role beyond parameter initialization by reusing previously\nlearned features. Surprisingly we observed that there is little advantage in\nusing pre-trained networks in images from another part of the body compared to\nImagenet. On the contrary, if images from the same part of the body are\navailable then transfer learning can produce a significant improvement in\nperformance with as little as 50 images in the training data.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 01:05:10 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 19:54:09 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 04:36:07 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Romero", "Miguel", ""], ["Interian", "Yannet", ""], ["Solberg", "Timothy", ""], ["Valdes", "Gilmer", ""]]}, {"id": "1912.06767", "submitter": "Likang Wu", "authors": "Likang Wu, Zhi Li, Hongke Zhao, Zhen Pan, Qi Liu, Enhong Chen", "title": "Estimating Early Fundraising Performance of Innovations via Graph-based\n  Market Environment Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well begun is half done. In the crowdfunding market, the early fundraising\nperformance of the project is a concerned issue for both creators and\nplatforms. However, estimating the early fundraising performance before the\nproject published is very challenging and still under-explored. To that end, in\nthis paper, we present a focused study on this important problem in a market\nmodeling view. Specifically, we propose a Graph-based Market Environment model\n(GME) for estimating the early fundraising performance of the target project by\nexploiting the market environment. In addition, we discriminatively model the\nmarket competition and market evolution by designing two graph-based neural\nnetwork architectures and incorporating them into the joint optimization stage.\nFinally, we conduct extensive experiments on the real-world crowdfunding data\ncollected from Indiegogo.com. The experimental results clearly demonstrate the\neffectiveness of our proposed model for modeling and estimating the early\nfundraising performance of the target project.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 02:11:50 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Wu", "Likang", ""], ["Li", "Zhi", ""], ["Zhao", "Hongke", ""], ["Pan", "Zhen", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "1912.06779", "submitter": "Hanson Wang", "authors": "Hanson Wang, Zehui Wang, Yuanyuan Ma", "title": "Predictive Precompute with Recurrent Neural Networks", "comments": null, "journal-ref": "Proceedings of the 3rd MLSys Conference, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In both mobile and web applications, speeding up user interface response\ntimes can often lead to significant improvements in user engagement. A common\ntechnique to improve responsiveness is to precompute data ahead of time for\nspecific activities. However, simply precomputing data for all user and\nactivity combinations is prohibitive at scale due to both network constraints\nand server-side computational costs. It is therefore important to accurately\npredict per-user application usage in order to minimize wasted precomputation\n(\"predictive precompute\"). In this paper, we describe the novel application of\nrecurrent neural networks (RNNs) for predictive precompute. We compare their\nperformance with traditional machine learning models, and share findings from\ntheir large-scale production use at Facebook. We demonstrate that RNN models\nimprove prediction accuracy, eliminate most feature engineering steps, and\nreduce the computational cost of serving predictions by an order of magnitude.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 03:40:38 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 04:40:47 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Hanson", ""], ["Wang", "Zehui", ""], ["Ma", "Yuanyuan", ""]]}, {"id": "1912.06785", "submitter": "Igor Gilitschenski", "authors": "Igor Gilitschenski, Guy Rosman, Arjun Gupta, Sertac Karaman, Daniela\n  Rus", "title": "Deep Context Maps: Agent Trajectory Prediction using Location-specific\n  Latent Maps", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2020.3004800", "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach for agent motion prediction in\ncluttered environments. One of the main challenges in predicting agent motion\nis accounting for location and context-specific information. Our main\ncontribution is the concept of learning context maps to improve the prediction\ntask. Context maps are a set of location-specific latent maps that are trained\nalongside the predictor. Thus, the proposed maps are capable of capturing\nlocation context beyond visual context cues (e.g. usual average speeds and\ntypical trajectories) or predefined map primitives (such as lanes and stop\nlines). We pose context map learning as a multi-task training problem and\ndescribe our map model and its incorporation into a state-of-the-art trajectory\npredictor. In extensive experiments, it is shown that use of learned maps can\nsignificantly improve predictor accuracy. Furthermore, the performance can be\nadditionally boosted by providing partial knowledge of map semantics.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 05:16:59 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 22:18:03 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Gilitschenski", "Igor", ""], ["Rosman", "Guy", ""], ["Gupta", "Arjun", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1912.06794", "submitter": "Matt Zhang", "authors": "Dawit Belayneh, Federico Carminati, Amir Farbin, Benjamin Hooberman,\n  Gulrukh Khattak, Miaoyuan Liu, Junze Liu, Dominick Olivito, Vit\\'oria Barin\n  Pacela, Maurizio Pierini, Alexander Schwing, Maria Spiropulu, Sofia\n  Vallecorsa, Jean-Roch Vlimant, Wei Wei, Matt Zhang", "title": "Calorimetry with Deep Learning: Particle Simulation and Reconstruction\n  for Collider Physics", "comments": "26 pages, 38 figures. Corrected typos and added additional references\n  in v2. Extended Acknowledgements section in v3", "journal-ref": null, "doi": "10.1140/epjc/s10052-020-8251-9", "report-no": null, "categories": "physics.ins-det cs.CV cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using detailed simulations of calorimeter showers as training data, we\ninvestigate the use of deep learning algorithms for the simulation and\nreconstruction of particles produced in high-energy physics collisions. We\ntrain neural networks on shower data at the calorimeter-cell level, and show\nsignificant improvements for simulation and reconstruction when using these\nnetworks compared to methods which rely on currently-used state-of-the-art\nalgorithms. We define two models: an end-to-end reconstruction network which\nperforms simultaneous particle identification and energy regression of\nparticles when given calorimeter shower data, and a generative network which\ncan provide reasonable modeling of calorimeter showers for different particle\ntypes at specified angles and energies. We investigate the optimization of our\nmodels with hyperparameter scans. Furthermore, we demonstrate the applicability\nof the reconstruction model to shower inputs from other detector geometries,\nspecifically ATLAS-like and CMS-like geometries. These networks can serve as\nfast and computationally light methods for particle shower simulation and\nreconstruction for current and future experiments at particle colliders.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 06:19:04 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 21:13:51 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 22:41:43 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Belayneh", "Dawit", ""], ["Carminati", "Federico", ""], ["Farbin", "Amir", ""], ["Hooberman", "Benjamin", ""], ["Khattak", "Gulrukh", ""], ["Liu", "Miaoyuan", ""], ["Liu", "Junze", ""], ["Olivito", "Dominick", ""], ["Pacela", "Vit\u00f3ria Barin", ""], ["Pierini", "Maurizio", ""], ["Schwing", "Alexander", ""], ["Spiropulu", "Maria", ""], ["Vallecorsa", "Sofia", ""], ["Vlimant", "Jean-Roch", ""], ["Wei", "Wei", ""], ["Zhang", "Matt", ""]]}, {"id": "1912.06798", "submitter": "Xun Wang", "authors": "Xun Wang, Haozhi Zhang, Weilin Huang, Matthew R. Scott", "title": "Cross-Batch Memory for Embedding Learning", "comments": "CVPR 2020 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining informative negative instances are of central importance to deep\nmetric learning (DML), however this task is intrinsically limited by mini-batch\ntraining, where only a mini-batch of instances is accessible at each iteration.\nIn this paper, we identify a \"slow drift\" phenomena by observing that the\nembedding features drift exceptionally slow even as the model parameters are\nupdating throughout the training process. This suggests that the features of\ninstances computed at preceding iterations can be used to considerably\napproximate their features extracted by the current model. We propose a\ncross-batch memory (XBM) mechanism that memorizes the embeddings of past\niterations, allowing the model to collect sufficient hard negative pairs across\nmultiple mini-batches - even over the whole dataset. Our XBM can be directly\nintegrated into a general pair-based DML framework, where the XBM augmented DML\ncan boost performance considerably. In particular, without bells and whistles,\na simple contrastive loss with our XBM can have large R@1 improvements of\n12%-22.5% on three large-scale image retrieval datasets, surpassing the most\nsophisticated state-of-the-art methods, by a large margin. Our XBM is\nconceptually simple, easy to implement - using several lines of codes, and is\nmemory efficient - with a negligible 0.2 GB extra GPU memory. Code is available\nat: https://github.com/MalongTech/research-xbm.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 07:38:53 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:09:17 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 02:54:52 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wang", "Xun", ""], ["Zhang", "Haozhi", ""], ["Huang", "Weilin", ""], ["Scott", "Matthew R.", ""]]}, {"id": "1912.06803", "submitter": "Puja Sahu", "authors": "Puja Sahu and Nandyala Hemachandra", "title": "Optimal PAC-Bayesian Posteriors for Stochastic Classifiers and their use\n  for Choice of SVM Regularization Parameter", "comments": "56 pages, 6 Figures, ACML 2019 conference paper with supplementary\n  material", "journal-ref": "Proceedings of The Eleventh Asian Conference on Machine Learning,\n  in PMLR 101:268-283 (2019)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PAC-Bayesian set up involves a stochastic classifier characterized by a\nposterior distribution on a classifier set, offers a high probability bound on\nits averaged true risk and is robust to the training sample used. For a given\nposterior, this bound captures the trade off between averaged empirical risk\nand KL-divergence based model complexity term. Our goal is to identify an\noptimal posterior with the least PAC-Bayesian bound. We consider a finite\nclassifier set and 5 distance functions: KL-divergence, its Pinsker's and a\nsixth degree polynomial approximations; linear and squared distances. Linear\ndistance based model results in a convex optimization problem. We obtain closed\nform expression for its optimal posterior. For uniform prior, this posterior\nhas full support with weights negative-exponentially proportional to number of\nmisclassifications. Squared distance and Pinsker's approximation bounds are\npossibly quasi-convex and are observed to have single local minimum. We derive\nfixed point equations (FPEs) using partial KKT system with strict positivity\nconstraints. This obviates the combinatorial search for subset support of the\noptimal posterior. For uniform prior, exponential search on a full-dimensional\nsimplex can be limited to an ordered subset of classifiers with increasing\nempirical risk values. These FPEs converge rapidly to a stationary point, even\nfor a large classifier set when a solver fails. We apply these approaches to\nSVMs generated using a finite set of SVM regularization parameter values on 9\nUCI datasets. These posteriors yield stochastic SVM classifiers with tight\nbounds. KL-divergence based bound is the tightest, but is computationally\nexpensive due to non-convexity and multiple calls to a root finding algorithm.\nOptimal posteriors for all 5 distance functions have lowest 10% test error\nvalues on most datasets, with linear distance being the easiest to obtain.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 08:21:57 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Sahu", "Puja", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "1912.06806", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, Zornitsa Kozareva, Alan Ritter, Sara Rosenthal, Veselin\n  Stoyanov, Theresa Wilson", "title": "SemEval-2013 Task 2: Sentiment Analysis in Twitter", "comments": "Sentiment analysis, microblog sentiment analysis, Twitter opinion\n  mining, SMS", "journal-ref": "SemEval-2013", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, sentiment analysis in social media has attracted a lot of\nresearch interest and has been used for a number of applications.\nUnfortunately, research has been hindered by the lack of suitable datasets,\ncomplicating the comparison between approaches. To address this issue, we have\nproposed SemEval-2013 Task 2: Sentiment Analysis in Twitter, which included two\nsubtasks: A, an expression-level subtask, and B, a message-level subtask. We\nused crowdsourcing on Amazon Mechanical Turk to label a large Twitter training\ndataset along with additional test sets of Twitter and SMS messages for both\nsubtasks. All datasets used in the evaluation are released to the research\ncommunity. The task attracted significant interest and a total of 149\nsubmissions from 44 teams. The best-performing team achieved an F1 of 88.9% and\n69% for subtasks A and B, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 08:44:18 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Nakov", "Preslav", ""], ["Kozareva", "Zornitsa", ""], ["Ritter", "Alan", ""], ["Rosenthal", "Sara", ""], ["Stoyanov", "Veselin", ""], ["Wilson", "Theresa", ""]]}, {"id": "1912.06808", "submitter": "Helin Wang", "authors": "Helin Wang, Yuexian Zou, Dading Chong, Wenwu Wang", "title": "Environmental Sound Classification with Parallel Temporal-spectral\n  Attention", "comments": "submitted to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) are one of the best-performing neural\nnetwork architectures for environmental sound classification (ESC). Recently,\ntemporal attention mechanisms have been used in CNN to capture the useful\ninformation from the relevant time frames for audio classification, especially\nfor weakly labelled data where the onset and offset times of the sound events\nare not applied. In these methods, however, the inherent spectral\ncharacteristics and variations are not explicitly exploited when obtaining the\ndeep features. In this paper, we propose a novel parallel temporal-spectral\nattention mechanism for CNN to learn discriminative sound representations,\nwhich enhances the temporal and spectral features by capturing the importance\nof different time frames and frequency bands. Parallel branches are constructed\nto allow temporal attention and spectral attention to be applied respectively\nin order to mitigate interference from the segments without the presence of\nsound events. The experiments on three environmental sound classification (ESC)\ndatasets and two acoustic scene classification (ASC) datasets show that our\nmethod improves the classification performance and also exhibits robustness to\nnoise.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 08:48:15 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 12:51:04 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 02:38:05 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Wang", "Helin", ""], ["Zou", "Yuexian", ""], ["Chong", "Dading", ""], ["Wang", "Wenwu", ""]]}, {"id": "1912.06810", "submitter": "Preslav Nakov", "authors": "Alberto Barr\\'on-Cede\\~no, Giovanni Da San Martino, Israa Jaradat,\n  Preslav Nakov", "title": "Proppy: A System to Unmask Propaganda in Online News", "comments": "propaganda, disinformation, fake news", "journal-ref": "Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI-2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 08:58:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Martino", "Giovanni Da San", ""], ["Jaradat", "Israa", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.06813", "submitter": "Wen-Chin Huang", "authors": "Wen-Chin Huang, Tomoki Hayashi, Yi-Chiao Wu, Hirokazu Kameoka, Tomoki\n  Toda", "title": "Voice Transformer Network: Sequence-to-Sequence Voice Conversion Using\n  Transformer with Text-to-Speech Pretraining", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel sequence-to-sequence (seq2seq) voice conversion (VC)\nmodel based on the Transformer architecture with text-to-speech (TTS)\npretraining. Seq2seq VC models are attractive owing to their ability to convert\nprosody. While seq2seq models based on recurrent neural networks (RNNs) and\nconvolutional neural networks (CNNs) have been successfully applied to VC, the\nuse of the Transformer network, which has shown promising results in various\nspeech processing tasks, has not yet been investigated. Nonetheless, their\ndata-hungry property and the mispronunciation of converted speech make seq2seq\nmodels far from practical. To this end, we propose a simple yet effective\npretraining technique to transfer knowledge from learned TTS models, which\nbenefit from large-scale, easily accessible TTS corpora. VC models initialized\nwith such pretrained model parameters are able to generate effective hidden\nrepresentations for high-fidelity, highly intelligible converted speech.\nExperimental results show that such a pretraining scheme can facilitate\ndata-efficient training and outperform an RNN-based seq2seq VC model in terms\nof intelligibility, naturalness, and similarity.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 09:30:52 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Huang", "Wen-Chin", ""], ["Hayashi", "Tomoki", ""], ["Wu", "Yi-Chiao", ""], ["Kameoka", "Hirokazu", ""], ["Toda", "Tomoki", ""]]}, {"id": "1912.06844", "submitter": "Mihai Suteu", "authors": "Mihai Suteu, Yike Guo", "title": "Regularizing Deep Multi-Task Networks using Orthogonal Gradients", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are a promising approach towards multi-task learning\nbecause of their capability to leverage knowledge across domains and learn\ngeneral purpose representations. Nevertheless, they can fail to live up to\nthese promises as tasks often compete for a model's limited resources,\npotentially leading to lower overall performance. In this work we tackle the\nissue of interfering tasks through a comprehensive analysis of their training,\nderived from looking at the interaction between gradients within their shared\nparameters. Our empirical results show that well-performing models have low\nvariance in the angles between task gradients and that popular regularization\nmethods implicitly reduce this measure. Based on this observation, we propose a\nnovel gradient regularization term that minimizes task interference by\nenforcing near orthogonal gradients. Updating the shared parameters using this\nproperty encourages task specific decoders to optimize different parts of the\nfeature extractor, thus reducing competition. We evaluate our method with\nclassification and regression tasks on the multiDigitMNIST, NYUv2 and SUN RGB-D\ndatasets where we obtain competitive results.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 13:35:32 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Suteu", "Mihai", ""], ["Guo", "Yike", ""]]}, {"id": "1912.06845", "submitter": "Geoffrey Wolfer", "authors": "Geoffrey Wolfer", "title": "Mixing Time Estimation in Ergodic Markov Chains from a Single Trajectory\n  with Contraction Methods", "comments": "Accepted for presentation at ALT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixing time $t_{\\mathsf{mix}}$ of an ergodic Markov chain measures the\nrate of convergence towards its stationary distribution $\\boldsymbol{\\pi}$. We\nconsider the problem of estimating $t_{\\mathsf{mix}}$ from one single\ntrajectory of $m$ observations $(X_1, . . . , X_m)$, in the case where the\ntransition kernel $\\boldsymbol{M}$ is unknown, a research program started by\nHsu et al. [2015]. The community has so far focused primarily on leveraging\nspectral methods to estimate the relaxation time $t_{\\mathsf{rel}}$ of a\nreversible Markov chain as a proxy for $t_{\\mathsf{mix}}$. Although these\ntechniques have recently been extended to tackle non-reversible chains, this\ngeneral setting remains much less understood. Our new approach based on\ncontraction methods is the first that aims at directly estimating\n$t_{\\mathsf{mix}}$ up to multiplicative small universal constants instead of\n$t_{\\mathsf{rel}}$. It does so by introducing a generalized version of\nDobrushin's contraction coefficient $\\kappa_{\\mathsf{gen}}$, which is shown to\ncontrol the mixing time regardless of reversibility. We subsequently design\nfully data-dependent high confidence intervals around $\\kappa_{\\mathsf{gen}}$\nthat generally yield better convergence guarantees and are more practical than\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 13:38:02 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Wolfer", "Geoffrey", ""]]}, {"id": "1912.06874", "submitter": "Tanmay Randhavane", "authors": "Tanmay Randhavane, Uttaran Bhattacharya, Kyra Kapsaskis, Kurt Gray,\n  Aniket Bera, Dinesh Manocha", "title": "The Liar's Walk: Detecting Deception with Gait and Gesture", "comments": "10 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven deep neural algorithm for detecting deceptive\nwalking behavior using nonverbal cues like gaits and gestures. We conducted an\nelaborate user study, where we recorded many participants performing tasks\ninvolving deceptive walking. We extract the participants' walking gaits as\nseries of 3D poses. We annotate various gestures performed by participants\nduring their tasks. Based on the gait and gesture data, we train an LSTM-based\ndeep neural network to obtain deep features. Finally, we use a combination of\npsychology-based gait, gesture, and deep features to detect deceptive walking\nwith an accuracy of 88.41%. This is an improvement of 10.6% over handcrafted\ngait and gesture features and an improvement of 4.7% and 9.2% over classifiers\nbased on the state-of-the-art emotion and action classification algorithms,\nrespectively. Additionally, we present a novel dataset, DeceptiveWalk, that\ncontains gaits and gestures with their associated deception labels. To the best\nof our knowledge, ours is the first algorithm to detect deceptive behavior\nusing non-verbal cues of gait and gesture.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:18:56 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 03:22:47 GMT"}, {"version": "v3", "created": "Sun, 29 Mar 2020 14:24:30 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Randhavane", "Tanmay", ""], ["Bhattacharya", "Uttaran", ""], ["Kapsaskis", "Kyra", ""], ["Gray", "Kurt", ""], ["Bera", "Aniket", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1912.06875", "submitter": "Yuwei Luo", "authors": "Yuwei Luo, Zhuoran Yang, Zhaoran Wang, Mladen Kolar", "title": "Natural Actor-Critic Converges Globally for Hierarchical Linear\n  Quadratic Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning has been successfully applied to a number\nof challenging problems. Despite these empirical successes, theoretical\nunderstanding of different algorithms is lacking, primarily due to the curse of\ndimensionality caused by the exponential growth of the state-action space with\nthe number of agents. We study a fundamental problem of multi-agent linear\nquadratic regulator in a setting where the agents are partially exchangeable.\nIn this setting, we develop a hierarchical actor-critic algorithm, whose\ncomputational complexity is independent of the total number of agents, and\nprove its global linear convergence to the optimal policy. As linear quadratic\nregulators are often used to approximate general dynamic systems, this paper\nprovided an important step towards better understanding of general hierarchical\nmean-field multi-agent reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:26:42 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Luo", "Yuwei", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Kolar", "Mladen", ""]]}, {"id": "1912.06876", "submitter": "Nicolas Garneau", "authors": "Nicolas Garneau, Jean-Samuel Leboeuf, Yuval Pinter and Luc Lamontagne", "title": "Attending Form and Context to Generate Specialized\n  Out-of-VocabularyWords Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new contextual-compositional neural network layer that handles\nout-of-vocabulary (OOV) words in natural language processing (NLP) tagging\ntasks. This layer consists of a model that attends to both the character\nsequence and the context in which the OOV words appear. We show that our model\nlearns to generate task-specific \\textit{and} sentence-dependent OOV word\nrepresentations without the need for pre-training on an embedding table, unlike\nprevious attempts. We insert our layer in the state-of-the-art tagging model of\n\\citet{plank2016multilingual} and thoroughly evaluate its contribution on 23\ndifferent languages on the task of jointly tagging part-of-speech and\nmorphosyntactic attributes. Our OOV handling method successfully improves\nperformances of this model on every language but one to achieve a new\nstate-of-the-art on the Universal Dependencies Dataset 1.4.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:27:57 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Garneau", "Nicolas", ""], ["Leboeuf", "Jean-Samuel", ""], ["Pinter", "Yuval", ""], ["Lamontagne", "Luc", ""]]}, {"id": "1912.06879", "submitter": "Tom Van Steenkiste", "authors": "Tom Van Steenkiste, Dirk Deschrijver, Tom Dhaene", "title": "Sensor Fusion using Backward Shortcut Connections for Sleep Apnea\n  Detection in Multi-Modal Data", "comments": "Paper presented at ML4H (Machine Learning for Health) workshop at\n  NeurIPS 2019. https://ml4health.github.io/2019/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep apnea is a common respiratory disorder characterized by breathing\npauses during the night. Consequences of untreated sleep apnea can be severe.\nStill, many people remain undiagnosed due to shortages of hospital beds and\ntrained sleep technicians. To assist in the diagnosis process, automated\ndetection methods are being developed. Recent works have demonstrated that deep\nlearning models can extract useful information from raw respiratory data and\nthat such models can be used as a robust sleep apnea detector. However, trained\nsleep technicians take into account multiple sensor signals when annotating\nsleep recordings instead of relying on a single respiratory estimate. To\nimprove the predictive performance and reliability of the models, early and\nlate sensor fusion methods are explored in this work. In addition, a novel late\nsensor fusion method is proposed which uses backward shortcut connections to\nimprove the learning of the first stages of the models. The performance of\nthese fusion methods is analyzed using CNN as well as LSTM deep learning\nbase-models. The results demonstrate a significant and consistent improvement\nin predictive performance over the single sensor methods and over the other\nexplored sensor fusion methods, by using the proposed sensor fusion method with\nbackward shortcut connections.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:55:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 15:47:03 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Van Steenkiste", "Tom", ""], ["Deschrijver", "Dirk", ""], ["Dhaene", "Tom", ""]]}, {"id": "1912.06880", "submitter": "Wenhang Bao", "authors": "Wenhang Bao, Xiao-yang Liu", "title": "Spatial Influence-aware Reinforcement Learning for Intelligent\n  Transportation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent transportation systems (ITSs) are envisioned to be crucial for\nsmart cities, which aims at improving traffic flow to improve the life quality\nof urban residents and reducing congestion to improve the efficiency of\ncommuting. However, several challenges need to be resolved before such systems\ncan be deployed, for example, conventional solutions for Markov decision\nprocess (MDP) and single-agent Reinforcement Learning (RL) algorithms suffer\nfrom poor scalability, and multi-agent systems suffer from poor communication\nand coordination. In this paper, we explore the potential of mutual information\nsharing, or in other words, spatial influence based communication, to optimize\ntraffic light control policy. First, we mathematically analyze the\ntransportation system. We conclude that the transportation system does not have\nstationary Nash Equilibrium, thereby reinforcement learning algorithms offer\nsuitable solutions. Secondly, we describe how to build a multi-agent Deep\nDeterministic Policy Gradient (DDPG) system with spatial influence and social\ngroup utility incorporated. Then we utilize the grid topology road network to\nempirically demonstrate the scalability of the new system. We demonstrate three\ntypes of directed communications to show the effect of directions of social\ninfluence on the entire network utility and individual utility. Lastly, we\ndefine \"selfish index\" and analyze the effect of it on total group utility.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:57:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bao", "Wenhang", ""], ["Liu", "Xiao-yang", ""]]}, {"id": "1912.06883", "submitter": "Reuben Binns Dr", "authors": "Reuben Binns", "title": "On the Apparent Conflict Between Individual and Group Fairness", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27--30, 2020, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A distinction has been drawn in fair machine learning research between\n`group' and `individual' fairness measures. Many technical research papers\nassume that both are important, but conflicting, and propose ways to minimise\nthe trade-offs between these measures. This paper argues that this apparent\nconflict is based on a misconception. It draws on theoretical discussions from\nwithin the fair machine learning research, and from political and legal\nphilosophy, to argue that individual and group fairness are not fundamentally\nin conflict. First, it outlines accounts of egalitarian fairness which\nencompass plausible motivations for both group and individual fairness, thereby\nsuggesting that there need be no conflict in principle. Second, it considers\nthe concept of individual justice, from legal philosophy and jurisprudence\nwhich seems similar but actually contradicts the notion of individual fairness\nas proposed in the fair machine learning literature. The conclusion is that the\napparent conflict between individual and group fairness is more of an artifact\nof the blunt application of fairness measures, rather than a matter of\nconflicting principles. In practice, this conflict may be resolved by a nuanced\nconsideration of the sources of `unfairness' in a particular deployment\ncontext, and the carefully justified application of measures to mitigate it.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 17:13:15 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Binns", "Reuben", ""]]}, {"id": "1912.06889", "submitter": "Harshavardhan Kamarthi", "authors": "Aakash Srinivasan, Harshavardhan Kamarthi, Devi Ganesan and Sutanu\n  Chakraborti", "title": "Integrating Lexical Knowledge in Word Embeddings using Sprinkling and\n  Retrofitting", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based word embeddings, such as Word2Vec and GloVe, are purely\ndata driven in that they capture the distributional information about words\nfrom the training corpus. Past works have attempted to improve these embeddings\nby incorporating semantic knowledge from lexical resources like WordNet. Some\ntechniques like retrofitting modify word embeddings in the post-processing\nstage while some others use a joint learning approach by modifying the\nobjective function of neural networks. In this paper, we discuss two novel\napproaches for incorporating semantic knowledge into word embeddings. In the\nfirst approach, we take advantage of Levy et al's work which showed that using\nSVD based methods on co-occurrence matrix provide similar performance to neural\nnetwork based embeddings. We propose a 'sprinkling' technique to add semantic\nrelations to the co-occurrence matrix directly before factorization. In the\nsecond approach, WordNet similarity scores are used to improve the retrofitting\nmethod. We evaluate the proposed methods in both intrinsic and extrinsic tasks\nand observe significant improvements over the baselines in many of the\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 17:38:46 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:19:46 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Srinivasan", "Aakash", ""], ["Kamarthi", "Harshavardhan", ""], ["Ganesan", "Devi", ""], ["Chakraborti", "Sutanu", ""]]}, {"id": "1912.06895", "submitter": "Cristian Canton Ferrer", "authors": "Hao Guo, Brian Dolhansky, Eric Hsin, Phong Dinh, Cristian Canton\n  Ferrer, Song Wang", "title": "Deep Poisoning: Towards Robust Image Data Sharing against Visual\n  Disclosure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to respectively limited training data, different entities addressing the\nsame vision task based on certain sensitive images may not train a robust deep\nnetwork. This paper introduces a new vision task where various entities share\ntask-specific image data to enlarge each other's training data volume without\nvisually disclosing sensitive contents (e.g. illegal images). Then, we present\na new structure-based training regime to enable different entities learn\ntask-specific and reconstruction-proof image representations for image data\nsharing. Specifically, each entity learns a private Deep Poisoning Module (DPM)\nand insert it to a pre-trained deep network, which is designed to perform the\nspecific vision task. The DPM deliberately poisons convolutional image features\nto prevent image reconstructions, while ensuring that the altered image data is\nfunctionally equivalent to the non-poisoned data for the specific vision task.\nGiven this equivalence, the poisoned features shared from one entity could be\nused by another entity for further model refinement. Experimental results on\nimage classification prove the efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 18:02:53 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 02:56:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guo", "Hao", ""], ["Dolhansky", "Brian", ""], ["Hsin", "Eric", ""], ["Dinh", "Phong", ""], ["Ferrer", "Cristian Canton", ""], ["Wang", "Song", ""]]}, {"id": "1912.06907", "submitter": "Mingyu Yang", "authors": "Mingyu Yang, Roger Hsiao, Gordy Carichner, Katherine Ernst, Jaechan\n  Lim, Delbert A. Green II, Inhee Lee, David Blaauw and Hun-Seok Kim", "title": "Migrating Monarch Butterfly Localization Using Multi-Sensor Fusion\n  Neural Networks", "comments": "under review for ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Details of Monarch butterfly migration from the U.S. to Mexico remain a\nmystery due to lack of a proper localization technology to accurately localize\nand track butterfly migration. In this paper, we propose a deep learning based\nbutterfly localization algorithm that can estimate a butterfly's daily location\nby analyzing a light and temperature sensor data log continuously obtained from\nan ultra-low power, mm-scale sensor attached to the butterfly. To train and\ntest the proposed neural network based multi-sensor fusion localization\nalgorithm, we collected over 1500 days of real world sensor measurement data\nwith 82 volunteers all over the U.S. The proposed algorithm exhibits a mean\nabsolute error of <1.5 degree in latitude and <0.5 degree in longitude Earth\ncoordinate, satisfying our target goal for the Monarch butterfly migration\nstudy.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 19:23:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yang", "Mingyu", ""], ["Hsiao", "Roger", ""], ["Carichner", "Gordy", ""], ["Ernst", "Katherine", ""], ["Lim", "Jaechan", ""], ["Green", "Delbert A.", "II"], ["Lee", "Inhee", ""], ["Blaauw", "David", ""], ["Kim", "Hun-Seok", ""]]}, {"id": "1912.06910", "submitter": "Tom Schaul", "authors": "Tom Schaul, Diana Borsa, David Ding, David Szepesvari, Georg\n  Ostrovski, Will Dabney, Simon Osindero", "title": "Adapting Behaviour for Learning Progress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining what experience to generate to best facilitate learning (i.e.\nexploration) is one of the distinguishing features and open challenges in\nreinforcement learning. The advent of distributed agents that interact with\nparallel instances of the environment has enabled larger scales and greater\nflexibility, but has not removed the need to tune exploration to the task,\nbecause the ideal data for the learning algorithm necessarily depends on its\nprocess of learning. We propose to dynamically adapt the data generation by\nusing a non-stationary multi-armed bandit to optimize a proxy of the learning\nprogress. The data distribution is controlled by modulating multiple parameters\nof the policy (such as stochasticity, consistency or optimism) without\nsignificant overhead. The adaptation speed of the bandit can be increased by\nexploiting the factored modulation structure. We demonstrate on a suite of\nAtari 2600 games how this unified approach produces results comparable to\nper-task tuning at a fraction of the cost.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 19:34:47 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Schaul", "Tom", ""], ["Borsa", "Diana", ""], ["Ding", "David", ""], ["Szepesvari", "David", ""], ["Ostrovski", "Georg", ""], ["Dabney", "Will", ""], ["Osindero", "Simon", ""]]}, {"id": "1912.06931", "submitter": "Hao Tang", "authors": "Hao Tang, Dan Xu, Hong Liu, Nicu Sebe", "title": "Asymmetric Generative Adversarial Networks for Image-to-Image\n  Translation", "comments": "An extended version of a paper published in ACCV2018. arXiv admin\n  note: substantial text overlap with arXiv:1901.04604", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models for unpaired image-to-image translation with\nGenerative Adversarial Networks (GANs) can learn the mapping from the source\ndomain to the target domain using a cycle-consistency loss. The intuition\nbehind these models is that if we translate from one domain to the other and\nback again we should arrive at where we started. However, existing methods\nalways adopt a symmetric network architecture to learn both forward and\nbackward cycles. Because of the task complexity and cycle input difference\nbetween the source and target image domains, the inequality in bidirectional\nforward-backward cycle translations is significant and the amount of\ninformation between two domains is different. In this paper, we analyze the\nlimitation of the existing symmetric GAN models in asymmetric translation\ntasks, and propose an AsymmetricGAN model with both translation and\nreconstruction generators of unequal sizes and different parameter-sharing\nstrategy to adapt to the asymmetric need in both unsupervised and supervised\nimage-to-image translation tasks. Moreover, the training stage of existing\nmethods has the common problem of model collapse that degrades the quality of\nthe generated images, thus we explore different optimization losses for better\ntraining of AsymmetricGAN, and thus make image-to-image translation with higher\nconsistency and better stability. Extensive experiments on both supervised and\nunsupervised generative tasks with several publicly available datasets\ndemonstrate that the proposed AsymmetricGAN achieves superior model capacity\nand better generation performance compared with existing GAN models. To the\nbest of our knowledge, we are the first to investigate the asymmetric GAN\nframework on both unsupervised and supervised image-to-image translation tasks.\nThe source code, data and trained models are available at\nhttps://github.com/Ha0Tang/AsymmetricGAN.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 21:24:41 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Tang", "Hao", ""], ["Xu", "Dan", ""], ["Liu", "Hong", ""], ["Sebe", "Nicu", ""]]}, {"id": "1912.06969", "submitter": "Aditya Cowsik", "authors": "Aditya Cowsik, John W. Clark", "title": "Breast Cancer Diagnosis by Higher-Order Probabilistic Perceptrons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two-layer neural network model that systematically includes correlations\namong input variables to arbitrary order and is designed to implement Bayes\ninference has been adapted to classify breast cancer tumors as malignant or\nbenign, assigning a probability for either outcome. The inputs to the network\nrepresent measured characteristics of cell nuclei imaged in Fine Needle\nAspiration biopsies. The present machine-learning approach to diagnosis (known\nas HOPP, for higher-order probabilistic perceptron) is tested on the\nmuch-studied, open-access Breast Cancer Wisconsin (Diagnosis) Data Set of\nWolberg et al. This set lists, for each tumor, measured physical parameters of\nthe cell nuclei of each sample. The HOPP model can identify the key factors --\ninput features and their combinations -- most relevant for reliable diagnosis.\nHOPP networks were trained on 90\\% of the examples in the Wisconsin database,\nand tested on the remaining 10\\%. Referred to ensembles of 300 networks,\nselected randomly for cross-validation, accuracy of classification for the test\nsets of up to 97\\% was readily achieved, with standard deviation around 2\\%,\ntogether with average Matthews correlation coefficients reaching 0.94\nindicating excellent predictive performance. Demonstrably, the HOPP is capable\nof matching the predictive power attained by other advanced machine-learning\nalgorithms applied to this much-studied database, over several decades.\nAnalysis shows that in this special problem, which is almost linearly\nseparable, the effects of irreducible correlations among the measured features\nof the Wisconsin database are of relatively minor importance, as the Naive\nBayes approximation can itself yield predictive accuracy approaching 95\\%. The\nadvantages of the HOPP algorithm will be more clearly revealed in application\nto more challenging machine-learning problems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 03:00:20 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Cowsik", "Aditya", ""], ["Clark", "John W.", ""]]}, {"id": "1912.06977", "submitter": "Steve Yadlowsky", "authors": "Steve Yadlowsky, Fabio Pellegrini, Federica Lionetto, Stefan Braune,\n  and Lu Tian", "title": "Estimation and Validation of Ratio-based Conditional Average Treatment\n  Effects Using Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sample sizes in randomized clinical trials are large enough to estimate\nthe average treatment effect well, they are often insufficient for estimation\nof treatment-covariate interactions critical to studying data-driven precision\nmedicine. Observational data from real world practice may play an important\nrole in alleviating this problem. One common approach in trials is to predict\nthe outcome of interest with separate regression models in each treatment arm,\nand estimate the treatment effect based on the contrast of the predictions.\nUnfortunately, this simple approach may induce spurious treatment-covariate\ninteraction in observational studies when the regression model is misspecified.\nMotivated by the need of modeling the number of relapses in multiple sclerosis\npatients, where the ratio of relapse rates is a natural choice of the treatment\neffect, we propose to estimate the conditional average treatment effect (CATE)\nas the ratio of expected potential outcomes, and derive a doubly robust\nestimator of this CATE in a semiparametric model of treatment-covariate\ninteractions. We also provide a validation procedure to check the quality of\nthe estimator on an independent sample. We conduct simulations to demonstrate\nthe finite sample performance of the proposed methods, and illustrate their\nadvantages on real data by examining the treatment effect of dimethyl fumarate\ncompared to teriflunomide in multiple sclerosis patients.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 05:13:56 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 00:48:55 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yadlowsky", "Steve", ""], ["Pellegrini", "Fabio", ""], ["Lionetto", "Federica", ""], ["Braune", "Stefan", ""], ["Tian", "Lu", ""]]}, {"id": "1912.06979", "submitter": "Jon Gillick", "authors": "Jon Gillick, David Bamman", "title": "Breaking Speech Recognizers to Imagine Lyrics", "comments": "3 pages", "journal-ref": "NeurIPS 2019 Workshop on Machine Learning for Creativity and\n  Design", "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for generating text, and in particular song lyrics,\nbased on the speech-like acoustic qualities of a given audio file. We repurpose\na vocal source separation algorithm and an acoustic model trained to recognize\nisolated speech, instead inputting instrumental music or environmental sounds.\nFeeding the \"mistakes\" of the vocal separator into the recognizer, we obtain a\ntranscription of words \\emph{imagined} to be spoken in the input audio. We\ndescribe the key components of our approach, present initial analysis, and\ndiscuss the potential of the method for machine-in-the-loop collaboration in\ncreative applications.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 05:34:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Gillick", "Jon", ""], ["Bamman", "David", ""]]}, {"id": "1912.06987", "submitter": "Lei Wu", "authors": "Weinan E, Chao Ma, Lei Wu", "title": "The Generalization Error of the Minimum-norm Solutions for\n  Over-parameterized Neural Networks", "comments": "Published version", "journal-ref": "Pure and Applied Functional Analysis, Volume 5, Number 6,\n  1145-1460, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalization properties of minimum-norm solutions for three\nover-parametrized machine learning models including the random feature model,\nthe two-layer neural network model and the residual network model. We proved\nthat for all three models, the generalization error for the minimum-norm\nsolution is comparable to the Monte Carlo rate, up to some logarithmic terms,\nas long as the models are sufficiently over-parametrized.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 06:05:14 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 15:16:12 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["E", "Weinan", ""], ["Ma", "Chao", ""], ["Wu", "Lei", ""]]}, {"id": "1912.06989", "submitter": "Jicong Fan", "authors": "Jicong Fan, Yuqian Zhang, Madeleine Udell", "title": "Polynomial Matrix Completion for Missing Data Imputation and\n  Transductive Learning", "comments": "Accepted by AAAI 2020. The supplementary material is at\n  https://github.com/jicongfan/Supplementary-material-of-conference-papers/blob/master/supp_PMC_AAAI2020.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops new methods to recover the missing entries of a high-rank\nor even full-rank matrix when the intrinsic dimension of the data is low\ncompared to the ambient dimension. Specifically, we assume that the columns of\na matrix are generated by polynomials acting on a low-dimensional intrinsic\nvariable, and wish to recover the missing entries under this assumption. We\nshow that we can identify the complete matrix of minimum intrinsic dimension by\nminimizing the rank of the matrix in a high dimensional feature space. We\ndevelop a new formulation of the resulting problem using the kernel trick\ntogether with a new relaxation of the rank objective, and propose an efficient\noptimization method. We also show how to use our methods to complete data drawn\nfrom multiple nonlinear manifolds. Comparative studies on synthetic data,\nsubspace clustering with missing data, motion capture data recovery, and\ntransductive learning verify the superiority of our methods over the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 06:39:00 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Fan", "Jicong", ""], ["Zhang", "Yuqian", ""], ["Udell", "Madeleine", ""]]}, {"id": "1912.06991", "submitter": "Amir Bahador Parsa", "authors": "Amir Bahador Parsa, Rishabh Singh Chauhan, Homa Taghipour, Sybil\n  Derrible, Abolfazl Mohammadian", "title": "Applying Deep Learning to Detect Traffic Accidents in Real Time Using\n  Spatiotemporal Sequential Data", "comments": "13 pages, 4 figures,2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accident detection is a vital part of traffic safety. Many road users suffer\nfrom traffic accidents, as well as their consequences such as delay,\ncongestion, air pollution, and so on. In this study, we utilize two advanced\ndeep learning techniques, Long Short-Term Memory (LSTM) and Gated Recurrent\nUnits (GRUs), to detect traffic accidents in Chicago. These two techniques are\nselected because they are known to perform well with sequential data (i.e.,\ntime series). The full dataset consists of 241 accident and 6,038 non-accident\ncases selected from Chicago expressway, and it includes traffic spatiotemporal\ndata, weather condition data, and congestion status data. Moreover, because the\ndataset is imbalanced (i.e., the dataset contains many more non-accident cases\nthan accident cases), Synthetic Minority Over-sampling Technique (SMOTE) is\nemployed. Overall, the two models perform significantly well, both with an Area\nUnder Curve (AUC) of 0.85. Nonetheless, the GRU model is observed to perform\nslightly better than LSTM model with respect to detection rate. The performance\nof both models is similar in terms of false alarm rate.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 06:49:43 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 20:45:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Parsa", "Amir Bahador", ""], ["Chauhan", "Rishabh Singh", ""], ["Taghipour", "Homa", ""], ["Derrible", "Sybil", ""], ["Mohammadian", "Abolfazl", ""]]}, {"id": "1912.07018", "submitter": "Adarsh Kappiyath", "authors": "Silpa V S, Adarsh K, Sumitra S, Raju K George", "title": "Disentanglement based Active Learning", "comments": "Accepted to NewinML workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Disentanglement based Active Learning (DAL), a new active learning\ntechnique based on query synthesis which leverages the concept of\ndisentanglement. Instead of requesting labels from the human oracle, our method\nautomatically labels majority of the datapoints, thus drastically reducing the\nhuman labelling budget in active learning. The proposed method uses Information\nMaximizing Generative Adversarial Nets (InfoGAN) to achieve the task where the\nactive learner provides a feedback on the generation of InfoGAN based on which\ndecision is taken about the datapoints to be queried. Results on two benchmark\ndatasets demonstrate that DAL is able to achieve nearly fully supervised\naccuracy with fairly less labelling budget compared to existing active learning\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 10:48:06 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["S", "Silpa V", ""], ["K", "Adarsh", ""], ["S", "Sumitra", ""], ["George", "Raju K", ""]]}, {"id": "1912.07044", "submitter": "Claudio Conti", "authors": "Giulia Marcucci, Davide Pierangeli, Claudio Conti", "title": "Theory of neuromorphic computing by waves: machine learning by rogue\n  waves, dispersive shocks, and solitons", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. Lett. 125, 093901 (2020)", "doi": "10.1103/PhysRevLett.125.093901", "report-no": null, "categories": "physics.optics cond-mat.quant-gas cs.LG nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study artificial neural networks with nonlinear waves as a computing\nreservoir. We discuss universality and the conditions to learn a dataset in\nterms of output channels and nonlinearity. A feed-forward three-layer model,\nwith an encoding input layer, a wave layer, and a decoding readout, behaves as\na conventional neural network in approximating mathematical functions,\nreal-world datasets, and universal Boolean gates. The rank of the transmission\nmatrix has a fundamental role in assessing the learning abilities of the wave.\nFor a given set of training points, a threshold nonlinearity for universal\ninterpolation exists. When considering the nonlinear Schroedinger equation, the\nuse of highly nonlinear regimes implies that solitons, rogue, and shock waves\ndo have a leading role in training and computing. Our results may enable the\nrealization of novel machine learning devices by using diverse physical\nsystems, as nonlinear optics, hydrodynamics, polaritonics, and Bose-Einstein\ncondensates. The application of these concepts to photonics opens the way to a\nlarge class of accelerators and new computational paradigms. In complex wave\nsystems, as multimodal fibers, integrated optical circuits, random, topological\ndevices, and metasurfaces, nonlinear waves can be employed to perform\ncomputation and solve complex combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 14:14:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Marcucci", "Giulia", ""], ["Pierangeli", "Davide", ""], ["Conti", "Claudio", ""]]}, {"id": "1912.07048", "submitter": "Alexander Korotin", "authors": "Alexander Korotin, Vladimir V'yugin, Evgeny Burnaev", "title": "Integral Mixability: a Tool for Efficient Online Aggregation of\n  Functional and Probabilistic Forecasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the setting of the online prediction with expert\nadvice to function-valued forecasts. At each step of the online game several\nexperts predict a function, and the learner has to efficiently aggregate these\nfunctional forecasts into a single forecast. We adapt basic mixable (and\nexponentially concave) loss functions to compare functional predictions and\nprove that these adaptations are also mixable (exp-concave). We call this\nphenomena integral mixability (exp-concavity). As an application of our main\nresult, we prove that various loss functions used for probabilistic forecasting\nare mixable (exp-concave). The considered losses include Sliced Continuous\nRanking Probability Score, Energy-Based Distance, Optimal Transport Costs &\nSliced Wasserstein-2 distance, Beta-2 & Kullback-Leibler divergences,\nCharacteristic function and Maximum Mean Discrepancies.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 14:25:33 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 14:04:34 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 11:52:20 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Korotin", "Alexander", ""], ["V'yugin", "Vladimir", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1912.07106", "submitter": "Runde Yang", "authors": "Runde Yang", "title": "Towards Building a Real Time Mobile Device Bird Counting System Through\n  Synthetic Data Training and Model Compression", "comments": "The paper is in a wrong format for ICML. I really need to withdraw\n  the paper to modify the content and submit it to other computer vision\n  conferences. Some sections need to be completely rewritten and I recognize\n  certain parts that are not consistent with the major theme of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting the number of birds in an open sky setting has been an challenging\nproblem due to the large number of bird flocks and the birds can overlap.\nAnother difficulty is the lack of accurate training samples since the cost of\nlabeling images of bird flocks can be extremely high and each sample picture\ncan contain thousands of birds in a high resolution image. Inspired by recent\nwork on training with synthetic data to perform crowd counting, we design a\nmechanism to generate synthetic bird dataset with precise bird count and the\ncorresponding density maps. We then train a Unet model on the synthetic dataset\nto perform density map estimation that produces the count for each input. Our\nmethod is able to achieve MSE of approximately 12.4 on real dataset. In order\nto build a scalable system for fast bird counting under storage and\ncomputational constraints, we use model compression techniques and efficient\nmodel structures to increase the inference speed and save storage cost. We are\nable to reduce storage cost from 55MB to less than 5MB for the model with\nminimum loss of accuracy. This paper describes the pipelines of building an\nefficient bird counting system.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 20:30:24 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 02:37:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Runde", ""]]}, {"id": "1912.07109", "submitter": "Yue Jiang", "authors": "Yue Jiang, Dantong Ji, Zhizhong Han, Matthias Zwicker", "title": "SDFDiff: Differentiable Rendering of Signed Distance Fields for 3D Shape\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose SDFDiff, a novel approach for image-based shape optimization using\ndifferentiable rendering of 3D shapes represented by signed distance functions\n(SDF). Compared to other representations, SDFs have the advantage that they can\nrepresent shapes with arbitrary topology, and that they guarantee watertight\nsurfaces. We apply our approach to the problem of multi-view 3D reconstruction,\nwhere we achieve high reconstruction quality and can capture complex topology\nof 3D objects. In addition, we employ a multi-resolution strategy to obtain a\nrobust optimization algorithm. We further demonstrate that our SDF-based\ndifferentiable renderer can be integrated with deep learning models, which\nopens up options for learning approaches on 3D objects without 3D supervision.\nIn particular, we apply our method to single-view 3D reconstruction and achieve\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 21:06:46 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Jiang", "Yue", ""], ["Ji", "Dantong", ""], ["Han", "Zhizhong", ""], ["Zwicker", "Matthias", ""]]}, {"id": "1912.07123", "submitter": "Antonio Quintero-Rincon", "authors": "Antonio Quintero-Rinc\\'on, Valeria Muro, Carlos D'Giano, Jorge\n  Prendes, Hadj Batatia", "title": "A novel spike-and-wave automatic detection in EEG signals", "comments": "8 pages, 3 figures", "journal-ref": "Computers (MDPI AG) 2020", "doi": "10.3390/computers9040085", "report-no": "computers9040085", "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-and-wave discharge (SWD) pattern classification in\nelectroencephalography (EEG) signals is a key problem in signal processing. It\nis particularly important to develop a SWD automatic detection method in\nlong-term EEG recordings since the task of marking the patters manually is time\nconsuming, difficult and error-prone. This paper presents a new detection\nmethod with a low computational complexity that can be easily trained if\nstandard medical protocols are respected. The detection procedure is as\nfollows: First, each EEG signal is divided into several time segments and for\neach time segment, the Morlet 1-D decomposition is applied. Then three\nparameters are extracted from the wavelet coefficients of each segment: scale\n(using a generalized Gaussian statistical model), variance and median. This is\nfollowed by a k-nearest neighbors (k-NN) classifier to detect the\nspike-and-wave pattern in each EEG channel from these three parameters. A total\nof 106 spike-and-wave and 106 non-spike-and-wave were used for training, while\n69 new annotated EEG segments from six subjects were used for classification.\nIn these circumstances, the proposed methodology achieved 100% accuracy. These\nresults generate new research opportunities for the underlying causes of the\nso-called absence epilepsy in long-term EEG recordings.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 22:42:17 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Quintero-Rinc\u00f3n", "Antonio", ""], ["Muro", "Valeria", ""], ["D'Giano", "Carlos", ""], ["Prendes", "Jorge", ""], ["Batatia", "Hadj", ""]]}, {"id": "1912.07127", "submitter": "Amirhossein Kiani", "authors": "Amirhossein Kiani, Chris Wang, Angela Xu", "title": "Sepsis World Model: A MIMIC-based OpenAI Gym \"World Model\" Simulator for\n  Sepsis Treatment", "comments": "This project was done as a class project for CS221 at Stanford\n  University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis is a life-threatening condition caused by the body's response to an\ninfection. In order to treat patients with sepsis, physicians must control\nvarying dosages of various antibiotics, fluids, and vasopressors based on a\nlarge number of variables in an emergency setting. In this project we employ a\n\"world model\" methodology to create a simulator that aims to predict the next\nstate of a patient given a current state and treatment action. In doing so, we\nhope our simulator learns from a latent and less noisy representation of the\nEHR data. Using historical sepsis patient records from the MIMIC dataset, our\nmethod creates an OpenAI Gym simulator that leverages a Variational\nAuto-Encoder and a Mixture Density Network combined with a RNN (MDN-RNN) to\nmodel the trajectory of any sepsis patient in the hospital. To reduce the\neffects of noise, we sample from a generated distribution of next steps during\nsimulation and have the option of introducing uncertainty into our simulator by\ncontrolling the \"temperature\" variable. It is worth noting that we do not have\naccess to the ground truth for the best policy because we can only evaluate\nlearned policies by real-world experimentation or expert feedback. Instead, we\naim to study our simulator model's performance by evaluating the similarity\nbetween our environment's rollouts with the real EHR data and assessing its\nviability for learning a realistic policy for sepsis treatment using Deep\nQ-Learning.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 22:50:27 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kiani", "Amirhossein", ""], ["Wang", "Chris", ""], ["Xu", "Angela", ""]]}, {"id": "1912.07145", "submitter": "Amir Gholami", "authors": "Zhewei Yao and Amir Gholami and Kurt Keutzer and Michael Mahoney", "title": "PyHessian: Neural Networks Through the Lens of the Hessian", "comments": null, "journal-ref": "IEEE BigData 2020 (and ICML Workshop 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PYHESSIAN, a new scalable framework that enables fast computation\nof Hessian (i.e., second-order derivative) information for deep neural\nnetworks. PYHESSIAN enables fast computations of the top Hessian eigenvalues,\nthe Hessian trace, and the full Hessian eigenvalue/spectral density, and it\nsupports distributed-memory execution on cloud/supercomputer systems and is\navailable as open source. This general framework can be used to analyze neural\nnetwork models, including the topology of the loss landscape (i.e., curvature\ninformation) to gain insight into the behavior of different models/optimizers.\nTo illustrate this, we analyze the effect of residual connections and Batch\nNormalization layers on the trainability of neural networks. One recent claim,\nbased on simpler first-order analysis, is that residual connections and Batch\nNormalization make the loss landscape smoother, thus making it easier for\nStochastic Gradient Descent to converge to a good solution. Our extensive\nanalysis shows new finer-scale insights, demonstrating that, while conventional\nwisdom is sometimes validated, in other cases it is simply incorrect. In\nparticular, we find that Batch Normalization does not necessarily make the loss\nlandscape smoother, especially for shallower networks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 00:55:34 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 20:56:47 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 18:43:29 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Keutzer", "Kurt", ""], ["Mahoney", "Michael", ""]]}, {"id": "1912.07146", "submitter": "Dmitriy Drusvyatskiy", "authors": "Damek Davis, Dmitriy Drusvyatskiy", "title": "Proximal methods avoid active strict saddles of weakly convex functions", "comments": "43 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a geometrically transparent strict saddle property for nonsmooth\nfunctions. This property guarantees that simple proximal algorithms on weakly\nconvex problems converge only to local minimizers, when randomly initialized.\nWe argue that the strict saddle property may be a realistic assumption in\napplications, since it provably holds for generic semi-algebraic optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 00:56:47 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 19:25:08 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""]]}, {"id": "1912.07160", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Xiaolin Huang, Zhengbao He, Chengjin Sun", "title": "DAmageNet: A Universal Adversarial Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now well known that deep neural networks (DNNs) are vulnerable to\nadversarial attack. Adversarial samples are similar to the clean ones, but are\nable to cheat the attacked DNN to produce incorrect predictions in high\nconfidence. But most of the existing adversarial attacks have high success rate\nonly when the information of the attacked DNN is well-known or could be\nestimated by massive queries. A promising way is to generate adversarial\nsamples with high transferability. By this way, we generate 96020 transferable\nadversarial samples from original ones in ImageNet. The average difference,\nmeasured by root means squared deviation, is only around 3.8 on average.\nHowever, the adversarial samples are misclassified by various models with an\nerror rate up to 90\\%. Since the images are generated independently with the\nattacked DNNs, this is essentially zero-query adversarial attack. We call the\ndataset \\emph{DAmageNet}, which is the first universal adversarial dataset that\nbeats many models trained in ImageNet. By finding the drawbacks, DAmageNet\ncould serve as a benchmark to study and improve robustness of DNNs. DAmageNet\ncould be downloaded in http://www.pami.sjtu.edu.cn/Show/56/122.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 02:11:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Chen", "Sizhe", ""], ["Huang", "Xiaolin", ""], ["He", "Zhengbao", ""], ["Sun", "Chengjin", ""]]}, {"id": "1912.07180", "submitter": "Kuang Gong", "authors": "Nuobei Xie, Kuang Gong, Ning Guo, Zhixin Qin, Zhifang Wu, Huafeng Liu,\n  Quanzheng Li", "title": "Penalized-likelihood PET Image Reconstruction Using 3D Structural\n  Convolutional Sparse Coding", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positron emission tomography (PET) is widely used for clinical diagnosis. As\nPET suffers from low resolution and high noise, numerous efforts try to\nincorporate anatomical priors into PET image reconstruction, especially with\nthe development of hybrid PET/CT and PET/MRI systems. In this work, we proposed\na novel 3D structural convolutional sparse coding (CSC) concept for\npenalized-likelihood PET image reconstruction, named 3D PET-CSC. The proposed\n3D PET-CSC takes advantage of the convolutional operation and manages to\nincorporate anatomical priors without the need of registration or supervised\ntraining. As 3D PET-CSC codes the whole 3D PET image, instead of patches, it\nalleviates the staircase artifacts commonly presented in traditional\npatch-based sparse coding methods. Moreover, we developed the residual-image\nand order-subset mechanisms to further reduce the computational cost and\naccelerate the convergence for the proposed 3D PET-CSC method. Experiments\nbased on computer simulations and clinical datasets demonstrate the superiority\nof 3D PET-CSC compared with other reference methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 03:57:55 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Xie", "Nuobei", ""], ["Gong", "Kuang", ""], ["Guo", "Ning", ""], ["Qin", "Zhixin", ""], ["Wu", "Zhifang", ""], ["Liu", "Huafeng", ""], ["Li", "Quanzheng", ""]]}, {"id": "1912.07190", "submitter": "Ryosuke Furuta", "authors": "Ryosuke Furuta, Naoto Inoue, Toshihiko Yamasaki", "title": "PixelRL: Fully Convolutional Network with Reinforcement Learning for\n  Image Processing", "comments": "To appear in IEEE Transactions on Multimedia (TMM), Special Issue on\n  Multimedia Computing with Interpretable Machine Learning. Extended version of\n  our paper in AAAI 2019 (arXiv:1811.04323)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles a new problem setting: reinforcement learning with\npixel-wise rewards (pixelRL) for image processing. After the introduction of\nthe deep Q-network, deep RL has been achieving great success. However, the\napplications of deep reinforcement learning (RL) for image processing are still\nlimited. Therefore, we extend deep RL to pixelRL for various image processing\napplications. In pixelRL, each pixel has an agent, and the agent changes the\npixel value by taking an action. We also propose an effective learning method\nfor pixelRL that significantly improves the performance by considering not only\nthe future states of the own pixel but also those of the neighbor pixels. The\nproposed method can be applied to some image processing tasks that require\npixel-wise manipulations, where deep RL has never been applied. Besides, it is\npossible to visualize what kind of operation is employed for each pixel at each\niteration, which would help us understand why and how such an operation is\nchosen. We also believe that our technology can enhance the explainability and\ninterpretability of the deep neural networks. In addition, because the\noperations executed at each pixels are visualized, we can change or modify the\noperations if necessary. We apply the proposed method to a variety of image\nprocessing tasks: image denoising, image restoration, local color enhancement,\nand saliency-driven image editing. Our experimental results demonstrate that\nthe proposed method achieves comparable or better performance, compared with\nthe state-of-the-art methods based on supervised learning. The source code is\navailable on https://github.com/rfuruta/pixelRL.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 04:42:37 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Furuta", "Ryosuke", ""], ["Inoue", "Naoto", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "1912.07197", "submitter": "Seyed Amir Hossein Hosseini", "authors": "Seyed Amir Hossein Hosseini, Burhaneddin Yaman, Steen Moeller, Mingyi\n  Hong, and Mehmet Ak\\c{c}akaya", "title": "Dense Recurrent Neural Networks for Accelerated MRI: History-Cognizant\n  Unrolling of Optimization Algorithms", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, 2020", "doi": "10.1109/JSTSP.2020.3003170", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems for accelerated MRI typically incorporate domain-specific\nknowledge about the forward encoding operator in a regularized reconstruction\nframework. Recently physics-driven deep learning (DL) methods have been\nproposed to use neural networks for data-driven regularization. These methods\nunroll iterative optimization algorithms to solve the inverse problem objective\nfunction, by alternating between domain-specific data consistency and\ndata-driven regularization via neural networks. The whole unrolled network is\nthen trained end-to-end to learn the parameters of the network. Due to\nsimplicity of data consistency updates with gradient descent steps, proximal\ngradient descent (PGD) is a common approach to unroll physics-driven DL\nreconstruction methods. However, PGD methods have slow convergence rates,\nnecessitating a higher number of unrolled iterations, leading to memory issues\nin training and slower reconstruction times in testing. Inspired by efficient\nvariants of PGD methods that use a history of the previous iterates, we propose\na history-cognizant unrolling of the optimization algorithm with dense\nconnections across iterations for improved performance. In our approach, the\ngradient descent steps are calculated at a trainable combination of the outputs\nof all the previous regularization units. We also apply this idea to unrolling\nvariable splitting methods with quadratic relaxation. Our results in\nreconstruction of the fastMRI knee dataset show that the proposed\nhistory-cognizant approach reduces residual aliasing artifacts compared to its\nconventional unrolled counterpart without requiring extra computational power\nor increasing reconstruction time.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 05:20:19 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 05:00:51 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Hosseini", "Seyed Amir Hossein", ""], ["Yaman", "Burhaneddin", ""], ["Moeller", "Steen", ""], ["Hong", "Mingyi", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "1912.07200", "submitter": "Yunhui Guo", "authors": "Yunhui Guo, Noel C. Codella, Leonid Karlinsky, James V. Codella, John\n  R. Smith, Kate Saenko, Tajana Rosing, Rogerio Feris", "title": "A Broader Study of Cross-Domain Few-Shot Learning", "comments": "ECCV 2020. Website: https://www.learning-with-limited-labels.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent progress on few-shot learning largely relies on annotated data for\nmeta-learning: base classes sampled from the same domain as the novel classes.\nHowever, in many applications, collecting data for meta-learning is infeasible\nor impossible. This leads to the cross-domain few-shot learning problem, where\nthere is a large shift between base and novel class domains. While\ninvestigations of the cross-domain few-shot scenario exist, these works are\nlimited to natural images that still contain a high degree of visual\nsimilarity. No work yet exists that examines few-shot learning across different\nimaging methods seen in real world scenarios, such as aerial and medical\nimaging. In this paper, we propose the Broader Study of Cross-Domain Few-Shot\nLearning (BSCD-FSL) benchmark, consisting of image data from a diverse\nassortment of image acquisition methods. This includes natural images, such as\ncrop disease images, but additionally those that present with an increasing\ndissimilarity to natural images, such as satellite images, dermatology images,\nand radiology images. Extensive experiments on the proposed benchmark are\nperformed to evaluate state-of-art meta-learning approaches, transfer learning\napproaches, and newer methods for cross-domain few-shot learning. The results\ndemonstrate that state-of-art meta-learning methods are surprisingly\noutperformed by earlier meta-learning approaches, and all meta-learning methods\nunderperform in relation to simple fine-tuning by 12.8% average accuracy.\nPerformance gains previously observed with methods specialized for cross-domain\nfew-shot learning vanish in this more challenging benchmark. Finally, accuracy\nof all methods tend to correlate with dataset similarity to natural images,\nverifying the value of the benchmark to better represent the diversity of data\nseen in practice and guiding future research.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 05:29:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 07:30:22 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 21:33:27 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Guo", "Yunhui", ""], ["Codella", "Noel C.", ""], ["Karlinsky", "Leonid", ""], ["Codella", "James V.", ""], ["Smith", "John R.", ""], ["Saenko", "Kate", ""], ["Rosing", "Tajana", ""], ["Feris", "Rogerio", ""]]}, {"id": "1912.07209", "submitter": "Mohammad Majdi", "authors": "Mohammad S Majdi (1), Mahesh B Keerthivasan (2 and 5), Brian K Rutt\n  (3), Natalie M Zahr (4), Jeffrey J Rodriguez (1), Manojkumar Saranathan (1\n  and 2) ((1) Department of Electrical and Computer Engineering, University of\n  Arizona, (2) Department of Medical Imaging, University of Arizona, (3)\n  Department of Radiology, Stanford University, (4) Department of Psychiatry\n  and Behavioral Sciences, Stanford University, (5) Siemens Healthcare USA)", "title": "Automated Thalamic Nuclei Segmentation Using Multi-Planar Cascaded\n  Convolutional Neural Networks", "comments": "Submitted to Magnetic Resonance Imaging. 34 pages, 6 figures , 2\n  tables, 1 supporting figures, 2 supporting tables. Magnetic Resonance Imaging\n  (2020)", "journal-ref": null, "doi": "10.1016/j.mri.2020.08.005", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cascaded multi-planar scheme with a modified residual U-Net architecture\nwas used to segment thalamic nuclei on conventional and white-matter-nulled\n(WMn) magnetization prepared rapid gradient echo (MPRAGE) data. A single\nnetwork was optimized to work with images from healthy controls and patients\nwith multiple sclerosis (MS) and essential tremor (ET), acquired at both 3T and\n7T field strengths. Dice similarity coefficient and volume similarity index\n(VSI) were used to evaluate performance. Clinical utility was demonstrated by\napplying this method to study the effect of MS on thalamic nuclei atrophy.\nSegmentation of each thalamus into twelve nuclei was achieved in under a\nminute. For 7T WMn-MPRAGE, the proposed method outperforms current\nstate-of-the-art on patients with ET with statistically significant\nimprovements in Dice for five nuclei (increase in the range of 0.05-0.18) and\nVSI for four nuclei (increase in the range of 0.05-0.19), while performing\ncomparably for healthy and MS subjects. Dice and VSI achieved using 7T\nWMn-MPRAGE data are comparable to those using 3T WMn-MPRAGE data. For\nconventional MPRAGE, the proposed method shows a statistically significant Dice\nimprovement in the range of 0.14-0.63 over FreeSurfer for all nuclei and\ndisease types. Effect of noise on network performance shows robustness to\nimages with SNR as low as half the baseline SNR. Atrophy of four thalamic\nnuclei and whole thalamus was observed for MS patients compared to healthy\ncontrol subjects, after controlling for the effect of parallel imaging,\nintracranial volume, gender, and age (p<0.004). The proposed segmentation\nmethod is fast, accurate, performs well across disease types and field\nstrengths, and shows great potential for improving our understanding of\nthalamic nuclei involvement in neurological diseases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 05:57:33 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 21:06:00 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Majdi", "Mohammad S", "", "2 and 5"], ["Keerthivasan", "Mahesh B", "", "2 and 5"], ["Rutt", "Brian K", "", "1\n  and 2"], ["Zahr", "Natalie M", "", "1\n  and 2"], ["Rodriguez", "Jeffrey J", "", "1\n  and 2"], ["Saranathan", "Manojkumar", "", "1\n  and 2"]]}, {"id": "1912.07211", "submitter": "Yukun Zhang", "authors": "Yukun Zhang, Longsheng Zhou", "title": "Fairness Assessment for Artificial Intelligence in Financial Industry", "comments": "Robust AI in FS 2019 : NeurIPS 2019 Workshop on Robust AI in\n  Financial Services: Data, Fairness, Explainability, Trustworthiness, and\n  Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Intelligence (AI) is an important driving force for the\ndevelopment and transformation of the financial industry. However, with the\nfast-evolving AI technology and application, unintentional bias, insufficient\nmodel validation, immature contingency plan and other underestimated threats\nmay expose the company to operational and reputational risks. In this paper, we\nfocus on fairness evaluation, one of the key components of AI Governance,\nthrough a quantitative lens. Statistical methods are reviewed for imbalanced\ndata treatment and bias mitigation. These methods and fairness evaluation\nmetrics are then applied to a credit card default payment example.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 06:09:39 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Zhang", "Yukun", ""], ["Zhou", "Longsheng", ""]]}, {"id": "1912.07226", "submitter": "Xiuming Liu", "authors": "Xiuming Liu, Dave Zachariah, Petre Stoica", "title": "Robust Prediction when Features are Missing", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.2988771", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictors are learned using past training data which may contain features\nthat are unavailable at the time of prediction. We develop an approach that is\nrobust against outlying missing features, based on the optimality properties of\nan oracle predictor which observes them. The robustness properties of the\napproach are demonstrated on both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 07:24:43 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 09:20:53 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 07:47:13 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Liu", "Xiuming", ""], ["Zachariah", "Dave", ""], ["Stoica", "Petre", ""]]}, {"id": "1912.07240", "submitter": "Yuchen Liu", "authors": "Yuchen Liu, Jiajun Zhang, Hao Xiong, Long Zhou, Zhongjun He, Hua Wu,\n  Haifeng Wang, and Chengqing Zong", "title": "Synchronous Speech Recognition and Speech-to-Text Translation with\n  Interactive Decoding", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-to-text translation (ST), which translates source language speech into\ntarget language text, has attracted intensive attention in recent years.\nCompared to the traditional pipeline system, the end-to-end ST model has\npotential benefits of lower latency, smaller model size, and less error\npropagation. However, it is notoriously difficult to implement such a model\nwithout transcriptions as intermediate. Existing works generally apply\nmulti-task learning to improve translation quality by jointly training\nend-to-end ST along with automatic speech recognition (ASR). However, different\ntasks in this method cannot utilize information from each other, which limits\nthe improvement. Other works propose a two-stage model where the second model\ncan use the hidden state from the first one, but its cascade manner greatly\naffects the efficiency of training and inference process. In this paper, we\npropose a novel interactive attention mechanism which enables ASR and ST to\nperform synchronously and interactively in a single model. Specifically, the\ngeneration of transcriptions and translations not only relies on its previous\noutputs but also the outputs predicted in the other task. Experiments on TED\nspeech translation corpora have shown that our proposed model can outperform\nstrong baselines on the quality of speech translation and achieve better speech\nrecognition performances as well.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:22:43 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Liu", "Yuchen", ""], ["Zhang", "Jiajun", ""], ["Xiong", "Hao", ""], ["Zhou", "Long", ""], ["He", "Zhongjun", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""], ["Zong", "Chengqing", ""]]}, {"id": "1912.07242", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran", "title": "More Data Can Hurt for Linear Regression: Sample-wise Double Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this expository note we describe a surprising phenomenon in\noverparameterized linear regression, where the dimension exceeds the number of\nsamples: there is a regime where the test risk of the estimator found by\ngradient descent increases with additional samples. In other words, more data\nactually hurts the estimator. This behavior is implicit in a recent line of\ntheoretical works analyzing \"double-descent\" phenomenon in linear models. In\nthis note, we isolate and understand this behavior in an extremely simple\nsetting: linear regression with isotropic Gaussian covariates. In particular,\nthis occurs due to an unconventional type of bias-variance tradeoff in the\noverparameterized regime: the bias decreases with more samples, but variance\nincreases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:28:26 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Nakkiran", "Preetum", ""]]}, {"id": "1912.07248", "submitter": "Chenping Hou", "authors": "Hong Tao and Chenping Hou and Yuhua Qian and Jubo Zhu and Dongyun Yi", "title": "Latent Complete Row Space Recovery for Multi-view Subspace Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2020.3010631", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view subspace clustering has been applied to applications such as image\nprocessing and video surveillance, and has attracted increasing attention. Most\nexisting methods learn view-specific self-representation matrices, and\nconstruct a combined affinity matrix from multiple views. The affinity\nconstruction process is time-consuming, and the combined affinity matrix is not\nguaranteed to reflect the whole true subspace structure. To overcome these\nissues, the Latent Complete Row Space Recovery (LCRSR) method is proposed.\nConcretely, LCRSR is based on the assumption that the multi-view observations\nare generated from an underlying latent representation, which is further\nassumed to collect the authentic samples drawn exactly from multiple subspaces.\nLCRSR is able to recover the row space of the latent representation, which not\nonly carries complete information from multiple views but also determines the\nsubspace membership under certain conditions. LCRSR does not involve the graph\nconstruction procedure and is solved with an efficient and convergent\nalgorithm, thereby being more scalable to large-scale datasets. The\neffectiveness and efficiency of LCRSR are validated by clustering various kinds\nof multi-view data and illustrated in the background subtraction task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:46:03 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tao", "Hong", ""], ["Hou", "Chenping", ""], ["Qian", "Yuhua", ""], ["Zhu", "Jubo", ""], ["Yi", "Dongyun", ""]]}, {"id": "1912.07250", "submitter": "Yi-Ting Huang", "authors": "Yi-Ting Huang, Ting-Yi Chen, Yeali S. Sun, and Meng Chang Chen", "title": "Learning Malware Representation based on Execution Sequences", "comments": "Incorrect experiment data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware analysis has been extensively investigated as the number and types of\nmalware has increased dramatically. However, most previous studies use\nend-to-end systems to detect whether a sample is malicious, or to identify its\nmalware family. In this paper, we propose a neural network framework composed\nof an embedder, an encoder, and a filter to learn malware representations from\ncharacteristic execution sequences for malware family classification. The\nembedder uses BERT and Sent2Vec, state-of-the-art embedding modules, to capture\nrelations within a single API call and among consecutive API calls in an\nexecution trace. The encoder comprises gated recurrent units (GRU) to preserve\nthe ordinal position of API calls and a self-attention mechanism for comparing\nintra-relations among different positions of API calls. The filter identifies\nrepresentative API calls to build the malware representation. We conduct broad\nexperiments to determine the influence of individual framework components. The\nresults show that the proposed framework outperforms the baselines, and also\ndemonstrates that considering Sent2Vec to learn complete API call embeddings\nand GRU to explicitly preserve ordinal information yields more information and\nthus significant improvements. Also, the proposed approach effectively\nclassifies new malicious execution traces on the basis of similarities with\npreviously collected families.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:52:40 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 02:22:17 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Huang", "Yi-Ting", ""], ["Chen", "Ting-Yi", ""], ["Sun", "Yeali S.", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1912.07254", "submitter": "Haoyu Yang", "authors": "Haoyu Yang, Wei Zhong, Yuzhe Ma, Hao Geng, Ran Chen, Wanli Chen, Bei\n  Yu", "title": "VLSI Mask Optimization: From Shallow To Deep Learning", "comments": "6 pages; accepted by 25th Asia and South Pacific Design Automation\n  Conference (ASP-DAC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  VLSI mask optimization is one of the most critical stages in\nmanufacturability aware design, which is costly due to the complicated mask\noptimization and lithography simulation. Recent researches have shown prominent\nadvantages of machine learning techniques dealing with complicated and big data\nproblems, which bring potential of dedicated machine learning solution for DFM\nproblems and facilitate the VLSI design cycle. In this paper, we focus on a\nheterogeneous OPC framework that assists mask layout optimization. Preliminary\nresults show the efficiency and effectiveness of proposed frameworks that have\nthe potential to be alternatives to existing EDA solutions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 09:11:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Yang", "Haoyu", ""], ["Zhong", "Wei", ""], ["Ma", "Yuzhe", ""], ["Geng", "Hao", ""], ["Chen", "Ran", ""], ["Chen", "Wanli", ""], ["Yu", "Bei", ""]]}, {"id": "1912.07277", "submitter": "Jingjing Zhang", "authors": "Jingjing Zhang, Osvaldo Simeone, Zoran Cvetkovic, Eugenio Abela, and\n  Mark Richardson", "title": "ITENE: Intrinsic Transfer Entropy Neural Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the directionality of information flow is instrumental in\nunderstanding, and possibly controlling, the operation of many complex systems,\nsuch as transportation, social, neural, or gene-regulatory networks. The\nstandard Transfer Entropy (TE) metric follows Granger's causality principle by\nmeasuring the Mutual Information (MI) between the past states of a source\nsignal $X$ and the future state of a target signal $Y$ while conditioning on\npast states of $Y$. Hence, the TE quantifies the improvement, as measured by\nthe log-loss, in the prediction of the target sequence $Y$ that can be accrued\nwhen, in addition to the past of $Y$, one also has available past samples from\n$X$. However, by conditioning on the past of $Y$, the TE also measures\ninformation that can be synergistically extracted by observing both the past of\n$X$ and $Y$, and not solely the past of $X$. Building on a private key\nagreement formulation, the Intrinsic TE (ITE) aims to discount such synergistic\ninformation to quantify the degree to which $X$ is \\emph{individually}\npredictive of $Y$, independent of $Y$'s past. In this paper, an estimator of\nthe ITE is proposed that is inspired by the recently proposed Mutual\nInformation Neural Estimation (MINE). The estimator is based on variational\nbound on the KL divergence, two-sample neural network classifiers, and the\npathwise estimator of Monte Carlo gradients.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 10:13:13 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 11:02:27 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhang", "Jingjing", ""], ["Simeone", "Osvaldo", ""], ["Cvetkovic", "Zoran", ""], ["Abela", "Eugenio", ""], ["Richardson", "Mark", ""]]}, {"id": "1912.07286", "submitter": "Chu Guo", "authors": "Yong Liu, Dongyang Wang, Shichuan Xue, Anqi Huang, Xiang Fu, Xiaogang\n  Qiang, Ping Xu, He-Liang Huang, Mingtang Deng, Chu Guo, Xuejun Yang, Junjie\n  Wu", "title": "Variational Quantum Circuits for Quantum State Tomography", "comments": "7 pages, 3 figures", "journal-ref": "Phys. Rev. A 101, 052316 (2020)", "doi": "10.1103/PhysRevA.101.052316", "report-no": null, "categories": "quant-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum state tomography is a key process in most quantum experiments. In\nthis work, we employ quantum machine learning for state tomography. Given an\nunknown quantum state, it can be learned by maximizing the fidelity between the\noutput of a variational quantum circuit and this state. The number of\nparameters of the variational quantum circuit grows linearly with the number of\nqubits and the circuit depth, so that only polynomial measurements are\nrequired, even for highly-entangled states. After that, a subsequent classical\ncircuit simulator is used to transform the information of the target quantum\nstate from the variational quantum circuit into a familiar format. We\ndemonstrate our method by performing numerical simulations for the tomography\nof the ground state of a one-dimensional quantum spin chain, using a\nvariational quantum circuit simulator. Our method is suitable for near-term\nquantum computing platforms, and could be used for relatively large-scale\nquantum state tomography for experimentally relevant quantum states.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 10:43:59 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 01:44:39 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Liu", "Yong", ""], ["Wang", "Dongyang", ""], ["Xue", "Shichuan", ""], ["Huang", "Anqi", ""], ["Fu", "Xiang", ""], ["Qiang", "Xiaogang", ""], ["Xu", "Ping", ""], ["Huang", "He-Liang", ""], ["Deng", "Mingtang", ""], ["Guo", "Chu", ""], ["Yang", "Xuejun", ""], ["Wu", "Junjie", ""]]}, {"id": "1912.07323", "submitter": "Joy Bose", "authors": "Kushal Singla, Joy Bose, Chetan Naik", "title": "Analysis of Software Engineering for Agile Machine Learning Projects", "comments": "5 pages, 8 figures , INDICON conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of machine learning, artificial intelligence or data science\nrelated software engineering projects using Agile methodology is increasing.\nHowever, there are very few studies on how such projects work in practice. In\nthis paper, we analyze project issues tracking data taken from Scrum (a popular\ntool for Agile) for several machine learning projects. We compare this data\nwith corresponding data from non-machine learning projects, in an attempt to\nanalyze how machine learning projects are executed differently from normal\nsoftware engineering projects. On analysis, we find that machine learning\nproject issues use different kinds of words to describe issues, have higher\nnumber of exploratory or research oriented tasks as compared to implementation\ntasks, and have a higher number of issues in the product backlog after each\nsprint, denoting that it is more difficult to estimate the duration of machine\nlearning project related tasks in advance. After analyzing this data, we\npropose a few ways in which Agile machine learning projects can be better\nlogged and executed, given their differences with normal software engineering\nprojects.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:40:26 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Singla", "Kushal", ""], ["Bose", "Joy", ""], ["Naik", "Chetan", ""]]}, {"id": "1912.07354", "submitter": "Yun Liu", "authors": "Ellery Wulczyn, David F. Steiner, Zhaoyang Xu, Apaar Sadhwani, Hongwu\n  Wang, Isabelle Flament, Craig H. Mermel, Po-Hsuan Cameron Chen, Yun Liu,\n  Martin C. Stumpe", "title": "Deep learning-based survival prediction for multiple cancer types using\n  histopathology images", "comments": null, "journal-ref": "PLOS ONE (2020)", "doi": "10.1371/journal.pone.0233678", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostic information at diagnosis has important implications for cancer\ntreatment and monitoring. Although cancer staging, histopathological\nassessment, molecular features, and clinical variables can provide useful\nprognostic insights, improving risk stratification remains an active research\narea. We developed a deep learning system (DLS) to predict disease specific\nsurvival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a\nweakly-supervised approach without pixel-level annotations, and tested three\ndifferent survival loss functions. The DLS was developed using 9,086 slides\nfrom 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In\nmultivariable Cox regression analysis of the combined cohort including all 10\ncancers, the DLS was significantly associated with disease specific survival\n(hazard ratio of 1.58, 95% CI 1.28-1.70, p<0.0001) after adjusting for cancer\ntype, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS\nremained a significant predictor of survival in 5 of 10 cancer types. Compared\nto a baseline model including stage, age, and sex, the c-index of the model\ndemonstrated an absolute 3.7% improvement (95% CI 1.0-6.5) in the combined\ncohort. Additionally, our models stratified patients within individual cancer\nstages, particularly stage II (p=0.025) and stage III (p<0.001). By developing\nand evaluating prognostic models across multiple cancer types, this work\nrepresents one of the most comprehensive studies exploring the direct\nprediction of clinical outcomes using deep learning and histopathology images.\nOur analysis demonstrates the potential for this approach to provide prognostic\ninformation in multiple cancer types, and even within specific pathologic\nstages. However, given the relatively small number of clinical events, we\nobserved wide confidence intervals, suggesting that future work will benefit\nfrom larger datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:47:36 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Wulczyn", "Ellery", ""], ["Steiner", "David F.", ""], ["Xu", "Zhaoyang", ""], ["Sadhwani", "Apaar", ""], ["Wang", "Hongwu", ""], ["Flament", "Isabelle", ""], ["Mermel", "Craig H.", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Liu", "Yun", ""], ["Stumpe", "Martin C.", ""]]}, {"id": "1912.07358", "submitter": "Angshul Majumdar Dr.", "authors": "Angshul Majumdar", "title": "Blind Denoising Autoencoder", "comments": "The final version accepted at IEEE Transactions on Neural Networks\n  and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term blind denoising refers to the fact that the basis used for denoising\nis learnt from the noisy sample itself during denoising. Dictionary learning\nand transform learning based formulations for blind denoising are well known.\nBut there has been no autoencoder based solution for the said blind denoising\napproach. So far autoencoder based denoising formulations have learnt the model\non a separate training data and have used the learnt model to denoise test\nsamples. Such a methodology fails when the test image (to denoise) is not of\nthe same kind as the models learnt with. This will be first work, where we\nlearn the autoencoder from the noisy sample while denoising. Experimental\nresults show that our proposed method performs better than dictionary learning\n(KSVD), transform learning, sparse stacked denoising autoencoder and the gold\nstandard BM3D algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:18:07 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Majumdar", "Angshul", ""]]}, {"id": "1912.07360", "submitter": "Angshul Majumdar Dr.", "authors": "Shikha Singh and Angshul Majumdar", "title": "Non-intrusive Load Monitoring via Multi-label Sparse Representation\n  based Classification", "comments": "The final version has been accepted at IEEE Transactions on Smartgrid", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work follows the approach of multi-label classification for\nnon-intrusive load monitoring (NILM). We modify the popular sparse\nrepresentation based classification (SRC) approach (developed for single label\nclassification) to solve multi-label classification problems. Results on\nbenchmark REDD and Pecan Street dataset shows significant improvement over\nstate-of-the-art techniques with small volume of training data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 09:15:32 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Singh", "Shikha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.07361", "submitter": "Zhyar Rostam Mr.", "authors": "Zhyar Rzgar K. Rostam, Sozan Abdullah Mahmood", "title": "Classification of Brainwave Signals Based on Hybrid Deep Learning and an\n  Evolutionary Algorithm", "comments": "10 pages, 6 tables, and 5 figures", "journal-ref": "JZS (2019) 21_2 35_44", "doi": "10.17656/jzs.10755", "report-no": "4_JZS_Comp_19", "categories": "eess.SP cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brainwave signals are read through Electroencephalogram (EEG) devices. These\nsignals are generated from an active brain based on brain activities and\nthoughts. The classification of brainwave signals is a challenging task due to\nits non-stationary nature. To address the issue, this paper proposes a\nConvolutional Neural Network (CNN) model to classify brainwave signals. In\norder to evaluate the performance of the proposed model a dataset is developed\nby recording brainwave signals for two conditions, which are visible and\ninvisible. In the visible mode, the human subjects focus on the color and shape\npresented. Meanwhile, in the invisible mode, the subjects think about specific\ncolors or shapes with closed eyes. A comparison has been provided between the\noriginal CNN and the proposed CNN architecture on the same dataset. The results\nshow that the proposed CNN model achieves higher classification accuracy as\ncompared to the standard CNN. The best accuracy rate achieved when the proposed\nCNN is applied on the visible color mode is 92%. In the future, improvements on\nthe proposed CNN will be able to classify raw EEG signals in an efficient way.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 07:03:14 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rostam", "Zhyar Rzgar K.", ""], ["Mahmood", "Sozan Abdullah", ""]]}, {"id": "1912.07366", "submitter": "Piyush Pandita", "authors": "Piyush Pandita, Nimish Awalgaonkar, Ilias Bilionis and Jitesh Panchal", "title": "Learning Arbitrary Quantities of Interest from Expensive Black-Box\n  Functions through Bayesian Sequential Optimal Design", "comments": "58 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating arbitrary quantities of interest (QoIs) that are non-linear\noperators of complex, expensive-to-evaluate, black-box functions is a\nchallenging problem due to missing domain knowledge and finite budgets.\nBayesian optimal design of experiments (BODE) is a family of methods that\nidentify an optimal design of experiments (DOE) under different contexts, using\nonly in a limited number of function evaluations. Under BODE methods,\nsequential design of experiments (SDOE) accomplishes this task by selecting an\noptimal sequence of experiments while using data-driven probabilistic surrogate\nmodels instead of the expensive black-box function. Probabilistic predictions\nfrom the surrogate model are used to define an information acquisition function\n(IAF) which quantifies the marginal value contributed or the expected\ninformation gained by a hypothetical experiment. The next experiment is\nselected by maximizing the IAF. A generally applicable IAF is the expected\ninformation gain (EIG) about a QoI as captured by the expectation of the\nKullback-Leibler divergence between the predictive distribution of the QoI\nafter doing a hypothetical experiment and the current predictive distribution\nabout the same QoI. We model the underlying information source as a\nfully-Bayesian, non-stationary Gaussian process (FBNSGP), and derive an\napproximation of the information gain of a hypothetical experiment about an\narbitrary QoI conditional on the hyper-parameters The EIG about the same QoI is\nestimated by sample averages to integrate over the posterior of the\nhyper-parameters and the potential experimental outcomes. We demonstrate the\nperformance of our method in four numerical examples and a practical\nengineering problem of steel wire manufacturing. The method is compared to two\nclassic SDOE methods: random sampling and uncertainty sampling.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:55:07 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Pandita", "Piyush", ""], ["Awalgaonkar", "Nimish", ""], ["Bilionis", "Ilias", ""], ["Panchal", "Jitesh", ""]]}, {"id": "1912.07367", "submitter": "Haolin Fei", "authors": "Haolin Fei and Xiaofeng Wu and Chunbo Luo", "title": "A Model-driven and Data-driven Fusion Framework for Accurate Air Quality\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air quality is closely related to public health. Health issues such as\ncardiovascular diseases and respiratory diseases, may have connection with long\nexposure to highly polluted environment. Therefore, accurate air quality\nforecasts are extremely important to those who are vulnerable. To estimate the\nvariation of several air pollution concentrations, previous researchers used\nvarious approaches, such as the Community Multiscale Air Quality model (CMAQ)\nor neural networks. Although CMAQ model considers a coverage of the historic\nair pollution data and meteorological variables, extra bias is introduced due\nto additional adjustment. In this paper, a combination of model-based strategy\nand data-driven method namely the physical-temporal collection(PTC) model is\nproposed, aiming to fix the systematic error that traditional models deliver.\nIn the data-driven part, the first components are the temporal pattern and the\nweather pattern to measure important features that contribute to the prediction\nperformance. The less relevant input variables will be removed to eliminate\nnegative weights in network training. Then, we deploy a long-short-term-memory\n(LSTM) to fetch the preliminary results, which will be further corrected by a\nneural network (NN) involving the meteorological index as well as other\npollutants concentrations. The data-set we applied for forecasting is from\nJanuary 1st, 2016 to December 31st, 2016. According to the results, our PTC\nachieves an excellent performance compared with the baseline model (CMAQ\nprediction, GRU, DNN and etc.). This joint model-based data-driven method for\nair quality prediction can be easily deployed on stations without extra\nadjustment, providing results with high-time-resolution information for\nvulnerable members to prevent heavy air pollution ahead.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 08:24:11 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Fei", "Haolin", ""], ["Wu", "Xiaofeng", ""], ["Luo", "Chunbo", ""]]}, {"id": "1912.07372", "submitter": "Michael Niemeyer", "authors": "Michael Niemeyer, Lars Mescheder, Michael Oechsle, Andreas Geiger", "title": "Differentiable Volumetric Rendering: Learning Implicit 3D\n  Representations without 3D Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based 3D reconstruction methods have shown impressive results.\nHowever, most methods require 3D supervision which is often hard to obtain for\nreal-world datasets. Recently, several works have proposed differentiable\nrendering techniques to train reconstruction models from RGB images.\nUnfortunately, these approaches are currently restricted to voxel- and\nmesh-based representations, suffering from discretization or low resolution. In\nthis work, we propose a differentiable rendering formulation for implicit shape\nand texture representations. Implicit representations have recently gained\npopularity as they represent shape and texture continuously. Our key insight is\nthat depth gradients can be derived analytically using the concept of implicit\ndifferentiation. This allows us to learn implicit shape and texture\nrepresentations directly from RGB images. We experimentally show that our\nsingle-view reconstructions rival those learned with full 3D supervision.\nMoreover, we find that our method can be used for multi-view 3D reconstruction,\ndirectly resulting in watertight meshes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 13:59:33 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 14:10:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Niemeyer", "Michael", ""], ["Mescheder", "Lars", ""], ["Oechsle", "Michael", ""], ["Geiger", "Andreas", ""]]}, {"id": "1912.07390", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Clara McCreery, Vamsi Chitters", "title": "Incrementally Improving Graph WaveNet Performance on Traffic Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a series of modifications which improve upon Graph WaveNet's\npreviously state-of-the-art performance on the METR-LA traffic prediction task.\nThe goal of this task is to predict the future speed of traffic at each sensor\nin a network using the past hour of sensor readings. Graph WaveNet (GWN) is a\nspatio-temporal graph neural network which interleaves graph convolution to\naggregate information from nearby sensors and dilated convolutions to aggregate\ninformation from the past. We improve GWN by (1) using better hyperparameters,\n(2) adding connections that allow larger gradients to flow back to the early\nconvolutional layers, and (3) pretraining on an easier short-term traffic\nprediction task. These modifications reduce the mean absolute error by .06 on\nthe METR-LA task, nearly equal to GWN's improvement over its predecessor. These\nimprovements generalize to the PEMS-BAY dataset, with similar relative\nmagnitude. We also show that ensembling separate models for short-and long-term\npredictions further improves performance. Code is available at\nhttps://github.com/sshleifer/Graph-WaveNet .\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 22:30:46 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Shleifer", "Sam", ""], ["McCreery", "Clara", ""], ["Chitters", "Vamsi", ""]]}, {"id": "1912.07394", "submitter": "Giulio Gambardella", "authors": "Giulio Gambardella, Johannes Kappauf, Michaela Blott, Christoph\n  Doehring, Martin Kumm, Peter Zipf and Kees Vissers", "title": "Efficient Error-Tolerant Quantized Neural Network Accelerators", "comments": "6 pages, 5 figures", "journal-ref": "2019 IEEE International Symposium on Defect and Fault Tolerance in\n  VLSI and Nanotechnology Systems (DFT)", "doi": "10.1109/DFT.2019.8875314", "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks are currently one of the most widely deployed machine\nlearning algorithms. In particular, Convolutional Neural Networks (CNNs), are\ngaining popularity and are evaluated for deployment in safety critical\napplications such as self driving vehicles. Modern CNNs feature enormous memory\nbandwidth and high computational needs, challenging existing hardware platforms\nto meet throughput, latency and power requirements. Functional safety and error\ntolerance need to be considered as additional requirement in safety critical\nsystems. In general, fault tolerant operation can be achieved by adding\nredundancy to the system, which is further exacerbating the computational\ndemands. Furthermore, the question arises whether pruning and quantization\nmethods for performance scaling turn out to be counterproductive with regards\nto fail safety requirements. In this work we present a methodology to evaluate\nthe impact of permanent faults affecting Quantized Neural Networks (QNNs) and\nhow to effectively decrease their effects in hardware accelerators. We use\nFPGA-based hardware accelerated error injection, in order to enable the fast\nevaluation. A detailed analysis is presented showing that QNNs containing\nconvolutional layers are by far not as robust to faults as commonly believed\nand can lead to accuracy drops of up to 10%. To circumvent that, we propose two\ndifferent methods to increase their robustness: 1) selective channel\nreplication which adds significantly less redundancy than used by the common\ntriple modular redundancy and 2) a fault-aware scheduling of processing\nelements for folded implementations\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:25:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Gambardella", "Giulio", ""], ["Kappauf", "Johannes", ""], ["Blott", "Michaela", ""], ["Doehring", "Christoph", ""], ["Kumm", "Martin", ""], ["Zipf", "Peter", ""], ["Vissers", "Kees", ""]]}, {"id": "1912.07398", "submitter": "Jacqueline Cavazos", "authors": "Jacqueline G. Cavazos, P. Jonathon Phillips, Carlos D. Castillo, Alice\n  J. O'Toole", "title": "Accuracy comparison across face recognition algorithms: Where are we on\n  measuring race bias?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous generations of face recognition algorithms differ in accuracy for\nimages of different races (race bias). Here, we present the possible underlying\nfactors (data-driven and scenario modeling) and methodological considerations\nfor assessing race bias in algorithms. We discuss data driven factors (e.g.,\nimage quality, image population statistics, and algorithm architecture), and\nscenario modeling factors that consider the role of the \"user\" of the algorithm\n(e.g., threshold decisions and demographic constraints). To illustrate how\nthese issues apply, we present data from four face recognition algorithms (a\nprevious-generation algorithm and three deep convolutional neural networks,\nDCNNs) for East Asian and Caucasian faces. First, dataset difficulty affected\nboth overall recognition accuracy and race bias, such that race bias increased\nwith item difficulty. Second, for all four algorithms, the degree of bias\nvaried depending on the identification decision threshold. To achieve equal\nfalse accept rates (FARs), East Asian faces required higher identification\nthresholds than Caucasian faces, for all algorithms. Third, demographic\nconstraints on the formulation of the distributions used in the test, impacted\nestimates of algorithm accuracy. We conclude that race bias needs to be\nmeasured for individual applications and we provide a checklist for measuring\nthis bias in face recognition algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:27:10 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 15:50:26 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Cavazos", "Jacqueline G.", ""], ["Phillips", "P. Jonathon", ""], ["Castillo", "Carlos D.", ""], ["O'Toole", "Alice J.", ""]]}, {"id": "1912.07416", "submitter": "Byung Hyung Kim", "authors": "Byung Hyung Kim, Seunghun Koh, Sejoon Huh, Sungho Jo, Sunghee Choi", "title": "Improved Explanatory Efficacy on Human Affect and Workload through\n  Interactive Process in Artificial Intelligence", "comments": null, "journal-ref": "IEEE Access, Vol.8, 2020", "doi": "10.1109/ACCESS.2020.3032056", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in the field of explainable artificial intelligence\nsystems, a concrete quantitative measure for evaluating the usability of such\nsystems is nonexistent. Ensuring the success of an explanatory interface in\ninteracting with users requires a cyclic, symbiotic relationship between human\nand artificial intelligence. We, therefore, propose explanatory efficacy, a\nnovel metric for evaluating the strength of the cyclic relationship the\ninterface exhibits. Furthermore, in a user study, we evaluated the perceived\naffect and workload and recorded the EEG signals of our participants as they\ninteracted with our custom-built, iterative explanatory interface to build\npersonalized recommendation systems. We found that systems for perceptually\ndriven iterative tasks with greater explanatory efficacy are characterized by\nstatistically significant hemispheric differences in neural signals with 62.4%\naccuracy, indicating the feasibility of neural correlates as a measure of\nexplanatory efficacy. These findings are beneficial for researchers who aim to\nstudy the circular ecosystem of the human-artificial intelligence partnership.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 14:08:49 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 01:53:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kim", "Byung Hyung", ""], ["Koh", "Seunghun", ""], ["Huh", "Sejoon", ""], ["Jo", "Sungho", ""], ["Choi", "Sunghee", ""]]}, {"id": "1912.07418", "submitter": "Huajun Wang", "authors": "Huajun Wang, Yuanhai Shao, Shenglong Zhou, Ce Zhang and Naihua Xiu", "title": "Support Vector Machine Classifier via $L_{0/1}$ Soft-Margin Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) has attracted great attentions for the last two\ndecades due to its extensive applications, and thus numerous optimization\nmodels have been proposed. To distinguish all of them, in this paper, we\nintroduce a new model equipped with an $L_{0/1}$ soft-margin loss (dubbed as\n$L_{0/1}$-SVM) which well captures the nature of the binary classification.\nMany of the existing convex/non-convex soft-margin losses can be viewed as a\nsurrogate of the $L_{0/1}$ soft-margin loss. Despite the discrete nature of\n$L_{0/1}$, we manage to establish the existence of global minimizer of the new\nmodel as well as revealing the relationship among its minimizers and\nKKT/P-stationary points. These theoretical properties allow us to take\nadvantage of the alternating direction method of multipliers. In addition, the\n$L_{0/1}$-support vector operator is introduced as a filter to prevent outliers\nfrom being support vectors during the training process. Hence, the method is\nexpected to be relatively robust. Finally, numerical experiments demonstrate\nthat our proposed method generates better performance in terms of much shorter\ncomputational time with much fewer number of support vectors when against with\nsome other leading methods in areas of SVM. When the data size gets bigger, its\nadvantage becomes more evident.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:42:30 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 13:36:15 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 03:30:28 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 14:30:46 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Wang", "Huajun", ""], ["Shao", "Yuanhai", ""], ["Zhou", "Shenglong", ""], ["Zhang", "Ce", ""], ["Xiu", "Naihua", ""]]}, {"id": "1912.07435", "submitter": "Benjamin Lu", "authors": "Benjamin Lu and Johanna Hardin", "title": "A Unified Framework for Random Forest Prediction Error Estimation", "comments": "41 pages, 8 figures, 6 tables", "journal-ref": "Journal of Machine Learning Research, 22(8):1-41, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a unified framework for random forest prediction error\nestimation based on a novel estimator of the conditional prediction error\ndistribution function. Our framework enables simple plug-in estimation of key\nprediction uncertainty metrics, including conditional mean squared prediction\nerrors, conditional biases, and conditional quantiles, for random forests and\nmany variants. Our approach is especially well-adapted for prediction interval\nestimation; we show via simulations that our proposed prediction intervals are\ncompetitive with, and in some settings outperform, existing methods. To\nestablish theoretical grounding for our framework, we prove pointwise uniform\nconsistency of a more stringent version of our estimator of the conditional\nprediction error distribution function. The estimators introduced here are\nimplemented in the R package forestError.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:11:15 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 19:22:49 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 06:32:06 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 22:15:52 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 22:05:37 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Lu", "Benjamin", ""], ["Hardin", "Johanna", ""]]}, {"id": "1912.07441", "submitter": "Joeran Beel", "authors": "Nicholas Bonello, Joeran Beel, Seamus Lawless, Jeremy Debattista", "title": "Multi-stream Data Analytics for Enhanced Performance Prediction in\n  Fantasy Football", "comments": null, "journal-ref": "27th AIAI Irish Conference on Artificial Intelligence and\n  Cognitive Science. 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fantasy Premier League (FPL) performance predictors tend to base their\nalgorithms purely on historical statistical data. The main problems with this\napproach is that external factors such as injuries, managerial decisions and\nother tournament match statistics can never be factored into the final\npredictions. In this paper, we present a new method for predicting future\nplayer performances by automatically incorporating human feedback into our\nmodel. Through statistical data analysis such as previous performances,\nupcoming fixture difficulty ratings, betting market analysis, opinions of the\ngeneral-public and experts alike via social media and web articles, we can\nimprove our understanding of who is likely to perform well in upcoming matches.\nWhen tested on the English Premier League 2018/19 season, the model\noutperformed regular statistical predictors by over 300 points, an average of\n11 points per week, ranking within the top 0.5% of players rank 30,000 out of\nover 6.5 million players.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:24:30 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bonello", "Nicholas", ""], ["Beel", "Joeran", ""], ["Lawless", "Seamus", ""], ["Debattista", "Jeremy", ""]]}, {"id": "1912.07443", "submitter": "Reza Khodayi-Mehr", "authors": "Reza Khodayi-Mehr and Michael M. Zavlanos", "title": "VarNet: Variational Neural Networks for the Solution of Partial\n  Differential Equations", "comments": "15 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new model-based unsupervised learning method,\ncalled VarNet, for the solution of partial differential equations (PDEs) using\ndeep neural networks (NNs). Particularly, we propose a novel loss function that\nrelies on the variational (integral) form of PDEs as apposed to their\ndifferential form which is commonly used in the literature. Our loss function\nis discretization-free, highly parallelizable, and more effective in capturing\nthe solution of PDEs since it employs lower-order derivatives and trains over\nmeasure non-zero regions of space-time. Given this loss function, we also\npropose an approach to optimally select the space-time samples, used to train\nthe NN, that is based on the feedback provided from the PDE residual. The\nmodels obtained using VarNet are smooth and do not require interpolation. They\nare also easily differentiable and can directly be used for control and\noptimization of PDEs. Finally, VarNet can straight-forwardly incorporate\nparametric PDE models making it a natural tool for model order reduction (MOR)\nof PDEs. We demonstrate the performance of our method through extensive\nnumerical experiments for the advection-diffusion PDE as an important\ncase-study.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:30:48 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Khodayi-Mehr", "Reza", ""], ["Zavlanos", "Michael M.", ""]]}, {"id": "1912.07447", "submitter": "Nian Xue", "authors": "Zhen Li, Hanyang Shao, Nian Xue, Liang Niu and LiangLiang Cao", "title": "Progressive Learning Algorithm for Efficient Person Re-Identification", "comments": "ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of Person Re-Identification (ReID)for\nlarge-scale applications. Recent research efforts have been devoted to building\ncomplicated part models, which introduce considerably high computational cost\nand memory consumption, inhibiting its practicability in large-scale\napplications. This paper aims to develop a novel learning strategy to find\nefficient feature embeddings while maintaining the balance of accuracy and\nmodel complexity. More specifically, we find by enhancing the classical triplet\nloss together with cross-entropy loss, our method can explore the hard examples\nand build a discriminant feature embedding yet compact enough for large-scale\napplications. Our method is carried out progressively using Bayesian\noptimization, and we call it the Progressive Learning Algorithm (PLA).\nExtensive experiments on three large-scale datasets show that our PLA is\ncomparable or better than the-state-of-the-arts. Especially, on the challenging\nMarket-1501 dataset, we achieve Rank-1=94.7\\%/mAP=89.4\\% while saving at least\n30\\% parameters than strong part models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:32:01 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 22:08:16 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Li", "Zhen", ""], ["Shao", "Hanyang", ""], ["Xue", "Nian", ""], ["Niu", "Liang", ""], ["Cao", "LiangLiang", ""]]}, {"id": "1912.07458", "submitter": "Kanil Patel", "authors": "Kanil Patel, William Beluch, Dan Zhang, Michael Pfeiffer, Bin Yang", "title": "On-manifold Adversarial Data Augmentation Improves Uncertainty\n  Calibration", "comments": "Accepted for oral at International Conference on Pattern Recognition,\n  ICPR 2020. Nominated (top 4) for Best Industry Related Paper Award (BIRPA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimates help to identify ambiguous, novel, or anomalous inputs,\nbut the reliable quantification of uncertainty has proven to be challenging for\nmodern deep networks. In order to improve uncertainty estimation, we propose\nOn-Manifold Adversarial Data Augmentation or OMADA, which specifically attempts\nto generate the most challenging examples by following an on-manifold\nadversarial attack path in the latent space of an autoencoder-based generative\nmodel that closely approximates decision boundaries between two or more\nclasses. On a variety of datasets as well as on multiple diverse network\narchitectures, OMADA consistently yields more accurate and better calibrated\nclassifiers than baseline models, and outperforms competing approaches such as\nMixup, as well as achieving similar performance to (at times better than)\npost-processing calibration methods such as temperature scaling. Variants of\nOMADA can employ different sampling schemes for ambiguous on-manifold examples\nbased on the entropy of their estimated soft labels, which exhibit specific\nstrengths for generalization, calibration of predicted uncertainty, or\ndetection of out-of-distribution inputs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:43:03 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 22:12:20 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 13:38:50 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 14:18:49 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 22:32:59 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Patel", "Kanil", ""], ["Beluch", "William", ""], ["Zhang", "Dan", ""], ["Pfeiffer", "Michael", ""], ["Yang", "Bin", ""]]}, {"id": "1912.07464", "submitter": "Shao-Bo Lin", "authors": "Charles K. Chui, Shao-Bo Lin, Bo Zhang, and Ding-Xuan Zhou", "title": "Realization of spatial sparseness by deep ReLU nets with massive data", "comments": "15pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great success of deep learning poses urgent challenges for understanding\nits working mechanism and rationality. The depth, structure, and massive size\nof the data are recognized to be three key ingredients for deep learning. Most\nof the recent theoretical studies for deep learning focus on the necessity and\nadvantages of depth and structures of neural networks. In this paper, we aim at\nrigorous verification of the importance of massive data in embodying the\nout-performance of deep learning. To approximate and learn spatially sparse and\nsmooth functions, we establish a novel sampling theorem in learning theory to\nshow the necessity of massive data. We then prove that implementing the\nclassical empirical risk minimization on some deep nets facilitates in\nrealization of the optimal learning rates derived in the sampling theorem. This\nperhaps explains why deep learning performs so well in the era of big data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:55:51 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Chui", "Charles K.", ""], ["Lin", "Shao-Bo", ""], ["Zhang", "Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "1912.07478", "submitter": "Dawei Zhu", "authors": "Dawei Zhu, Aditya Mogadala, Dietrich Klakow", "title": "Image Manipulation with Natural Language using Two-sidedAttentive\n  Conditional Generative Adversarial Network", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Altering the content of an image with photo editing tools is a tedious task\nfor an inexperienced user. Especially, when modifying the visual attributes of\na specific object in an image without affecting other constituents such as\nbackground etc. To simplify the process of image manipulation and to provide\nmore control to users, it is better to utilize a simpler interface like natural\nlanguage. Therefore, in this paper, we address the challenge of manipulating\nimages using natural language description. We propose the Two-sidEd Attentive\nconditional Generative Adversarial Network (TEA-cGAN) to generate semantically\nmanipulated images while preserving other contents such as background intact.\nTEA-cGAN uses fine-grained attention both in the generator and discriminator of\nGenerative Adversarial Network (GAN) based framework at different scales.\nExperimental results show that TEA-cGAN which generates 128x128 and 256x256\nresolution images outperforms existing methods on CUB and Oxford-102 datasets\nboth quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:21:13 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Zhu", "Dawei", ""], ["Mogadala", "Aditya", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1912.07519", "submitter": "Angshul Majumdar Dr.", "authors": "Janki Mehta and Angshul Majumdar", "title": "RODEO: Robust DE-aliasing autoencOder for Real-time Medical Image\n  Reconstruction", "comments": "Final paper accepted at Pattern Recognition. arXiv admin note: text\n  overlap with arXiv:1503.06383", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the problem of real-time dynamic medical MRI and X\nRay CT image reconstruction from parsimonious samples Fourier frequency space\nfor MRI and sinogram tomographic projections for CT. Today the de facto\nstandard for such reconstruction is compressed sensing. CS produces high\nquality images (with minimal perceptual loss, but such reconstructions are time\nconsuming, requiring solving a complex optimization problem. In this work we\npropose to learn the reconstruction from training samples using an autoencoder.\nOur work is based on the universal function approximation capacity of neural\nnetworks. The training time for the autoencoder is large, but is offline and\nhence does not affect performance during operation. During testing or\noperation, our method requires only a few matrix vector products and hence is\nsignificantly faster than CS based methods. In fact, it is fast enough for\nreal-time reconstruction the images are reconstructed as fast as they are\nacquired with only slight degradation of image quality. However, in order to\nmake the autoencoder suitable for our problem, we depart from the standard\nEuclidean norm cost function of autoencoders and use a robust l1-norm instead.\nThe ensuing problem is solved using the Split Bregman method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 12:16:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Mehta", "Janki", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.07527", "submitter": "Tianxiang Gao", "authors": "Tianxiang Gao, Songtao Lu, Jia Liu, Chris Chu", "title": "Leveraging Two Reference Functions in Block Bregman Proximal Gradient\n  Descent for Non-convex and Non-Lipschitz Problems", "comments": "Submit to TSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the applications of signal processing and data analytics, there is a wide\nclass of non-convex problems whose objective function is freed from the common\nglobal Lipschitz continuous gradient assumption (e.g., the nonnegative matrix\nfactorization (NMF) problem). Recently, this type of problem with some certain\nspecial structures has been solved by Bregman proximal gradient (BPG). This\ninspires us to propose a new Block-wise two-references Bregman proximal\ngradient (B2B) method, which adopts two reference functions so that a\nclosed-form solution in the Bregman projection is obtained. Based on the\nrelative smoothness, we prove the global convergence of the proposed algorithms\nfor various block selection rules. In particular, we establish the global\nconvergence rate of $O(\\frac{\\sqrt{s}}{\\sqrt{k}})$ for the greedy and\nrandomized block updating rule for B2B, which is $O(\\sqrt{s})$ times faster\nthan the cyclic variant, i.e., $O(\\frac{s}{\\sqrt{k}} )$, where $s$ is the\nnumber of blocks, and $k$ is the number of iterations. Multiple numerical\nresults are provided to illustrate the superiority of the proposed B2B compared\nto the state-of-the-art works in solving NMF problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 17:32:24 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Gao", "Tianxiang", ""], ["Lu", "Songtao", ""], ["Liu", "Jia", ""], ["Chu", "Chris", ""]]}, {"id": "1912.07538", "submitter": "Rakshith Shetty", "authors": "Vedika Agarwal and Rakshith Shetty and Mario Fritz", "title": "Towards Causal VQA: Revealing and Reducing Spurious Correlations by\n  Invariant and Covariant Semantic Editing", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant success in Visual Question Answering (VQA), VQA models\nhave been shown to be notoriously brittle to linguistic variations in the\nquestions. Due to deficiencies in models and datasets, today's models often\nrely on correlations rather than predictions that are causal w.r.t. data. In\nthis paper, we propose a novel way to analyze and measure the robustness of the\nstate of the art models w.r.t semantic visual variations as well as propose\nways to make models more robust against spurious correlations. Our method\nperforms automated semantic image manipulations and tests for consistency in\nmodel predictions to quantify the model robustness as well as generate\nsynthetic data to counter these problems. We perform our analysis on three\ndiverse, state of the art VQA models and diverse question types with a\nparticular focus on challenging counting questions. In addition, we show that\nmodels can be made significantly more robust against inconsistent predictions\nusing our edited data. Finally, we show that results also translate to\nreal-world error cases of state of the art models, which results in improved\noverall performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 17:45:01 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 21:22:34 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 08:58:11 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Agarwal", "Vedika", ""], ["Shetty", "Rakshith", ""], ["Fritz", "Mario", ""]]}, {"id": "1912.07544", "submitter": "John Winder", "authors": "John Winder, Stephanie Milani, Matthew Landen, Erebus Oh, Shane Parr,\n  Shawn Squire, Marie desJardins, Cynthia Matuszek", "title": "Planning with Abstract Learned Models While Learning Transferable\n  Subtasks", "comments": "Accepted at AAAI-20, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm for model-based hierarchical reinforcement learning\nto acquire self-contained transition and reward models suitable for\nprobabilistic planning at multiple levels of abstraction. We call this\nframework Planning with Abstract Learned Models (PALM). By representing\nsubtasks symbolically using a new formal structure, the lifted abstract Markov\ndecision process (L-AMDP), PALM learns models that are independent and modular.\nThrough our experiments, we show how PALM integrates planning and execution,\nfacilitating a rapid and efficient learning of abstract, hierarchical models.\nWe also demonstrate the increased potential for learned models to be\ntransferred to new and related tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 17:47:57 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 15:09:33 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Winder", "John", ""], ["Milani", "Stephanie", ""], ["Landen", "Matthew", ""], ["Oh", "Erebus", ""], ["Parr", "Shane", ""], ["Squire", "Shawn", ""], ["desJardins", "Marie", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "1912.07546", "submitter": "Prateek Raj Srivastava", "authors": "Prateek R. Srivastava, Purnamrita Sarkar, Grani A. Hanasusanto", "title": "A Robust Spectral Clustering Algorithm for Sub-Gaussian Mixture Models\n  with Outliers", "comments": "54 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering datasets in the presence of arbitrary\noutliers. Traditional clustering algorithms such as k-means and spectral\nclustering are known to perform poorly for datasets contaminated with even a\nsmall number of outliers. In this paper, we develop a provably robust spectral\nclustering algorithm that applies a simple rounding scheme to denoise a\nGaussian kernel matrix built from the data points and uses vanilla spectral\nclustering to recover the cluster labels of data points. We analyze the\nperformance of our algorithm under the assumption that the \"good\" data points\nare generated from a mixture of sub-gaussians (we term these \"inliers\"), while\nthe outlier points can come from any arbitrary probability distribution. For\nthis general class of models, we show that the misclassification error decays\nat an exponential rate in the signal-to-noise ratio, provided the number of\noutliers is a small fraction of the inlier points. Surprisingly, this derived\nerror bound matches with the best-known bound for semidefinite programs (SDPs)\nunder the same setting without outliers. We conduct extensive experiments on a\nvariety of simulated and real-world datasets to demonstrate that our algorithm\nis less sensitive to outliers compared to other state-of-the-art algorithms\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 17:48:58 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 00:47:37 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 08:32:52 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Srivastava", "Prateek R.", ""], ["Sarkar", "Purnamrita", ""], ["Hanasusanto", "Grani A.", ""]]}, {"id": "1912.07557", "submitter": "Dan Schmidt", "authors": "Dan Schmidt, Nick Moran, Jonathan S. Rosenfeld, Jonathan Rosenthal,\n  Jonathan Yedidia", "title": "Self-Play Learning Without a Reward Metric", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AlphaZero algorithm for the learning of strategy games via self-play,\nwhich has produced superhuman ability in the games of Go, chess, and shogi,\nuses a quantitative reward function for game outcomes, requiring the users of\nthe algorithm to explicitly balance different components of the reward against\neach other, such as the game winner and margin of victory. We present a\nmodification to the AlphaZero algorithm that requires only a total ordering\nover game outcomes, obviating the need to perform any quantitative balancing of\nreward components. We demonstrate that this system learns optimal play in a\ncomparable amount of time to AlphaZero on a sample game.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:11:14 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Schmidt", "Dan", ""], ["Moran", "Nick", ""], ["Rosenfeld", "Jonathan S.", ""], ["Rosenthal", "Jonathan", ""], ["Yedidia", "Jonathan", ""]]}, {"id": "1912.07559", "submitter": "Wojciech Czarnecki", "authors": "Wojciech Marian Czarnecki, Simon Osindero, Razvan Pascanu, Max\n  Jaderberg", "title": "A Deep Neural Network's Loss Surface Contains Every Low-dimensional\n  Pattern", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work \"Loss Landscape Sightseeing with Multi-Point Optimization\"\n(Skorokhodov and Burtsev, 2019) demonstrated that one can empirically find\narbitrary 2D binary patterns inside loss surfaces of popular neural networks.\nIn this paper we prove that: (i) this is a general property of deep universal\napproximators; and (ii) this property holds for arbitrary smooth patterns, for\nother dimensionalities, for every dataset, and any neural network that is\nsufficiently deep and wide. Our analysis predicts not only the existence of all\nsuch low-dimensional patterns, but also two other properties that were observed\nempirically: (i) that it is easy to find these patterns; and (ii) that they\ntransfer to other data-sets (e.g. a test-set).\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:15:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 17:40:38 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["Osindero", "Simon", ""], ["Pascanu", "Razvan", ""], ["Jaderberg", "Max", ""]]}, {"id": "1912.07561", "submitter": "Grzegorz G{\\l}uch", "authors": "Grzegorz G{\\l}uch, R\\\"udiger Urbanke", "title": "Constructing a provably adversarially-robust classifier from a high\n  accuracy one", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models with very high accuracy have been shown to be\nvulnerable to small, adversarially chosen perturbations of the input. Given\nblack-box access to a high-accuracy classifier $f$, we show how to construct a\nnew classifier $g$ that has high accuracy and is also robust to adversarial\n$\\ell_2$-bounded perturbations. Our algorithm builds upon the framework of\n\\textit{randomized smoothing} that has been recently shown to outperform all\nprevious defenses against $\\ell_2$-bounded adversaries. Using techniques like\nrandom partitions and doubling dimension, we are able to bound the adversarial\nerror of $g$ in terms of the optimum error. In this paper we focus on our\nconceptual contribution, but we do present two examples to illustrate our\nframework. We will argue that, under some assumptions, our bounds are optimal\nfor these cases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:19:59 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["G\u0142uch", "Grzegorz", ""], ["Urbanke", "R\u00fcdiger", ""]]}, {"id": "1912.07568", "submitter": "Angshul Majumdar Dr.", "authors": "Vanika Singhal, Jyoti Maggu and Angshul Majumdar", "title": "Simultaneous Detection of Multiple Appliances from Smart-meter\n  Measurements via Multi-Label Consistent Deep Dictionary Learning and Deep\n  Transform Learning", "comments": "Final paper accepted at IEEE Transactions on Smart Grid", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently there are several well-known approaches to non-intrusive appliance\nload monitoring rule based, stochastic finite state machines, neural networks\nand sparse coding. Recently several studies have proposed a new approach based\non multi label classification. Different appliances are treated as separate\nclasses, and the task is to identify the classes given the aggregate\nsmart-meter reading. Prior studies in this area have used off the shelf\nalgorithms like MLKNN and RAKEL to address this problem. In this work, we\npropose a deep learning based technique. There are hardly any studies in deep\nlearning based multi label classification; two new deep learning techniques to\nsolve the said problem are fundamental contributions of this work. These are\ndeep dictionary learning and deep transform learning. Thorough experimental\nresults on benchmark datasets show marked improvement over existing studies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:26:16 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Singhal", "Vanika", ""], ["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.07575", "submitter": "Th\\'eodore Bluche", "authors": "Theodore Bluche and Thibault Gisselbrecht", "title": "Predicting detection filters for small footprint open-vocabulary keyword\n  spotting", "comments": "Submtted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fully-neural approach to open-vocabulary keyword\nspotting, that allows the users to include a customizable voice interface to\ntheir device and that does not require task-specific data. We present a keyword\ndetection neural network weighing less than 250KB, in which the topmost layer\nperforming keyword detection is predicted by an auxiliary network, that may be\nrun offline to generate a detector for any keyword. We show that the proposed\nmodel outperforms acoustic keyword spotting baselines by a large margin on two\ntasks of detecting keywords in utterances and three tasks of detecting isolated\nspeech commands. We also propose a method to fine-tune the model when specific\ntraining data is available for some keywords, which yields a performance\nsimilar to a standard speech command neural network while keeping the ability\nof the model to be applied to new keywords.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:41:49 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:09:15 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Bluche", "Theodore", ""], ["Gisselbrecht", "Thibault", ""]]}, {"id": "1912.07589", "submitter": "Paul Bertens", "authors": "Paul Bertens, Seong-Whan Lee", "title": "Network of Evolvable Neural Units: Evolving to Learn at a Synaptic Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Deep Neural Networks have seen great success in recent years through\nvarious changes in overall architectures and optimization strategies, their\nfundamental underlying design remains largely unchanged. Computational\nneuroscience on the other hand provides more biologically realistic models of\nneural processing mechanisms, but they are still high level abstractions of the\nactual experimentally observed behaviour. Here a model is proposed that bridges\nNeuroscience, Machine Learning and Evolutionary Algorithms to evolve individual\nsoma and synaptic compartment models of neurons in a scalable manner. Instead\nof attempting to manually derive models for all the observed complexity and\ndiversity in neural processing, we propose an Evolvable Neural Unit (ENU) that\ncan approximate the function of each individual neuron and synapse. We\ndemonstrate that this type of unit can be evolved to mimic Integrate-And-Fire\nneurons and synaptic Spike-Timing-Dependent Plasticity. Additionally, by\nconstructing a new type of neural network where each synapse and neuron is such\nan evolvable neural unit, we show it is possible to evolve an agent capable of\nlearning to solve a T-maze environment task. This network independently\ndiscovers spiking dynamics and reinforcement type learning rules, opening up a\nnew path towards biologically inspired artificial intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:57:50 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bertens", "Paul", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "1912.07618", "submitter": "Arjun Gupta", "authors": "Arjun Gupta, E. A. Huerta, Zhizhen Zhao and Issam Moussa", "title": "Deep Learning for Cardiologist-level Myocardial Infarction Detection in\n  Electrocardiograms", "comments": "Accepted to the European Medical and Biological Engineering\n  Conference (EMBEC) 2020", "journal-ref": null, "doi": "10.1007/978-3-030-64610-3_40", "report-no": null, "categories": "cs.LG eess.SP physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Myocardial infarction is the leading cause of death worldwide. In this paper,\nwe design domain-inspired neural network models to detect myocardial\ninfarction. First, we study the contribution of various leads. This systematic\nanalysis, first of its kind in the literature, indicates that out of 15 ECG\nleads, data from the v6, vz, and ii leads are critical to correctly identify\nmyocardial infarction. Second, we use this finding and adapt the ConvNetQuake\nneural network model--originally designed to identify earthquakes--to attain\nstate-of-the-art classification results for myocardial infarction, achieving\n$99.43\\%$ classification accuracy on a record-wise split, and $97.83\\%$\nclassification accuracy on a patient-wise split. These two results represent\ncardiologist-level performance level for myocardial infarction detection after\nfeeding only 10 seconds of raw ECG data into our model. Third, we show that our\nmulti-ECG-channel neural network achieves cardiologist-level performance\nwithout the need of any kind of manual feature extraction or data\npre-processing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:00:03 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 05:07:12 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 16:59:49 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gupta", "Arjun", ""], ["Huerta", "E. A.", ""], ["Zhao", "Zhizhen", ""], ["Moussa", "Issam", ""]]}, {"id": "1912.07629", "submitter": "Sitan Chen", "authors": "Sitan Chen, Jerry Li, Zhao Song", "title": "Learning Mixtures of Linear Regressions in Subexponential Time via\n  Fourier Moments", "comments": "83 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a mixture of linear regressions (MLRs).\nAn MLR is specified by $k$ nonnegative mixing weights $p_1, \\ldots, p_k$\nsumming to $1$, and $k$ unknown regressors $w_1,...,w_k\\in\\mathbb{R}^d$. A\nsample from the MLR is drawn by sampling $i$ with probability $p_i$, then\noutputting $(x, y)$ where $y = \\langle x, w_i \\rangle + \\eta$, where\n$\\eta\\sim\\mathcal{N}(0,\\varsigma^2)$ for noise rate $\\varsigma$. Mixtures of\nlinear regressions are a popular generative model and have been studied\nextensively in machine learning and theoretical computer science. However, all\nprevious algorithms for learning the parameters of an MLR require running time\nand sample complexity scaling exponentially with $k$.\n  In this paper, we give the first algorithm for learning an MLR that runs in\ntime which is sub-exponential in $k$. Specifically, we give an algorithm which\nruns in time $\\widetilde{O}(d)\\cdot\\exp(\\widetilde{O}(\\sqrt{k}))$ and outputs\nthe parameters of the MLR to high accuracy, even in the presence of nontrivial\nregression noise. We demonstrate a new method that we call \"Fourier moment\ndescent\" which uses univariate density estimation and low-degree moments of the\nFourier transform of suitable univariate projections of the MLR to iteratively\nrefine our estimate of the parameters. To the best of our knowledge, these\ntechniques have never been used in the context of high dimensional distribution\nlearning, and may be of independent interest. We also show that our techniques\ncan be used to give a sub-exponential time algorithm for learning mixtures of\nhyperplanes, a natural hard instance of the subspace clustering problem.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:00:19 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Jerry", ""], ["Song", "Zhao", ""]]}, {"id": "1912.07648", "submitter": "Angelica I. Aviles-Rivero", "authors": "Jiulong Liu, Angelica I. Aviles-Rivero, Hui Ji and Carola-Bibiane\n  Sch\\\"onlieb", "title": "Rethinking Medical Image Reconstruction via Shape Prior, Going Deeper\n  and Faster: Deep Joint Indirect Registration and Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indirect image registration is a promising technique to improve image\nreconstruction quality by providing a shape prior for the reconstruction task.\nIn this paper, we propose a novel hybrid method that seeks to reconstruct high\nquality images from few measurements whilst requiring low computational cost.\nWith this purpose, our framework intertwines indirect registration and\nreconstruction tasks is a single functional. It is based on two major\nnovelties. Firstly, we introduce a model based on deep nets to solve the\nindirect registration problem, in which the inversion and registration mappings\nare recurrently connected through a fixed-point interaction based sparse\noptimisation. Secondly, we introduce specific inversion blocks, that use the\nexplicit physical forward operator, to map the acquired measurements to the\nimage reconstruction. We also introduce registration blocks based deep nets to\npredict the registration parameters and warp transformation accurately and\nefficiently. We demonstrate, through extensive numerical and visual\nexperiments, that our framework outperforms significantly classic\nreconstruction schemes and other bi-task method; this in terms of both image\nquality and computational time. Finally, we show generalisation capabilities of\nour approach by demonstrating their performance on fast Magnetic Resonance\nImaging (MRI), sparse view computed tomography (CT) and low dose CT with\nmeasurements much below the Nyquist limit.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:28:52 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Liu", "Jiulong", ""], ["Aviles-Rivero", "Angelica I.", ""], ["Ji", "Hui", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1912.07650", "submitter": "Alexander Hayes", "authors": "Alexander L. Hayes and Mayukh Das and Phillip Odom and Sriraam\n  Natarajan", "title": "User Friendly Automatic Construction of Background Knowledge: Mode\n  Construction from ER Diagrams", "comments": "8 pages. Published in Proceedings of the Knowledge Capture\n  Conference, 2017", "journal-ref": "Proceedings of the Knowledge Capture Conference (2017) 30:1-30:8", "doi": "10.1145/3148011.3148027", "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One of the key advantages of Inductive Logic Programming systems is the\nability of the domain experts to provide background knowledge as modes that\nallow for efficient search through the space of hypotheses. However, there is\nan inherent assumption that this expert should also be an ILP expert to provide\neffective modes. We relax this assumption by designing a graphical user\ninterface that allows the domain expert to interact with the system using\nEntity Relationship diagrams. These interactions are used to construct modes\nfor the learning system. We evaluate our algorithm on a probabilistic logic\nlearning system where we demonstrate that the user is able to construct\neffective background knowledge on par with the expert-encoded knowledge on five\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:30:57 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Hayes", "Alexander L.", ""], ["Das", "Mayukh", ""], ["Odom", "Phillip", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1912.07651", "submitter": "Arash Vahdat", "authors": "Arash Vahdat, Arun Mallya, Ming-Yu Liu, Jan Kautz", "title": "UNAS: Differentiable Architecture Search Meets Reinforcement Learning", "comments": "Accepted to CVPR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) aims to discover network architectures with\ndesired properties such as high accuracy or low latency. Recently,\ndifferentiable NAS (DNAS) has demonstrated promising results while maintaining\na search cost orders of magnitude lower than reinforcement learning (RL) based\nNAS. However, DNAS models can only optimize differentiable loss functions in\nsearch, and they require an accurate differentiable approximation of\nnon-differentiable criteria. In this work, we present UNAS, a unified framework\nfor NAS, that encapsulates recent DNAS and RL-based approaches under one\nframework. Our framework brings the best of both worlds, and it enables us to\nsearch for architectures with both differentiable and non-differentiable\ncriteria in one unified framework while maintaining a low search cost. Further,\nwe introduce a new objective function for search based on the generalization\ngap that prevents the selection of architectures prone to overfitting. We\npresent extensive experiments on the CIFAR-10, CIFAR-100, and ImageNet datasets\nand we perform search in two fundamentally different search spaces. We show\nthat UNAS obtains the state-of-the-art average accuracy on all three datasets\nwhen compared to the architectures searched in the DARTS space. Moreover, we\nshow that UNAS can find an efficient and accurate architecture in the\nProxylessNAS search space, that outperforms existing MobileNetV2 based\narchitectures. The source code is available at https://github.com/NVlabs/unas .\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:31:39 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 21:48:42 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Vahdat", "Arash", ""], ["Mallya", "Arun", ""], ["Liu", "Ming-Yu", ""], ["Kautz", "Jan", ""]]}, {"id": "1912.07661", "submitter": "Subhashini Venugopalan", "authors": "Subhashini Venugopalan, Arunachalam Narayanaswamy, Samuel Yang, Anton\n  Geraschenko, Scott Lipnick, Nina Makhortova, James Hawrot, Christine Marques,\n  Joao Pereira, Michael Brenner, Lee Rubin, Brian Wainger, Marc Berndl", "title": "It's easy to fool yourself: Case studies on identifying bias and\n  confounding in bio-medical datasets", "comments": "Accepted at Neurips 2019 LMRL workshop -- extended abstract track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confounding variables are a well known source of nuisance in biomedical\nstudies. They present an even greater challenge when we combine them with\nblack-box machine learning techniques that operate on raw data. This work\npresents two case studies. In one, we discovered biases arising from systematic\nerrors in the data generation process. In the other, we found a spurious source\nof signal unrelated to the prediction task at hand. In both cases, our\nprediction models performed well but under careful examination hidden\nconfounders and biases were revealed. These are cautionary tales on the limits\nof using machine learning techniques on raw data from scientific experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 18:45:25 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:46:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Venugopalan", "Subhashini", ""], ["Narayanaswamy", "Arunachalam", ""], ["Yang", "Samuel", ""], ["Geraschenko", "Anton", ""], ["Lipnick", "Scott", ""], ["Makhortova", "Nina", ""], ["Hawrot", "James", ""], ["Marques", "Christine", ""], ["Pereira", "Joao", ""], ["Brenner", "Michael", ""], ["Rubin", "Lee", ""], ["Wainger", "Brian", ""], ["Berndl", "Marc", ""]]}, {"id": "1912.07662", "submitter": "Alessio Pagani Dr", "authors": "Alessio Pagani, Abhinav Mehrotra and Mirco Musolesi", "title": "Graph Input Representations for Machine Learning Applications in Urban\n  Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and learning the characteristics of network paths has been of\nparticular interest for decades and has led to several successful applications.\nSuch analysis becomes challenging for urban networks as their size and\ncomplexity are significantly higher compared to other networks. The\nstate-of-the-art machine learning (ML) techniques allow us to detect hidden\npatterns and, thus, infer the features associated with them. However, very\nlittle is known about the impact on the performance of such predictive models\nby the use of different input representations. In this paper, we design and\nevaluate six different graph input representations (i.e., representations of\nthe network paths), by considering the network's topological and temporal\ncharacteristics, for being used as inputs for machine learning models to learn\nthe behavior of urban networks paths. The representations are validated and\nthen tested with a real-world taxi journeys dataset predicting the tips using a\nroad network of New York. Our results demonstrate that the input\nrepresentations that use temporal information help the model to achieve the\nhighest accuracy (RMSE of 1.42$).\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:28:00 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Pagani", "Alessio", ""], ["Mehrotra", "Abhinav", ""], ["Musolesi", "Mirco", ""]]}, {"id": "1912.07663", "submitter": "Haoxing Lin", "authors": "Haoxing Lin, Weijia Jia, Yiping Sun, Yongjian You", "title": "Spatial-Temporal Self-Attention Network for Flow Prediction", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow prediction (e.g., crowd flow, traffic flow) with features of\nspatial-temporal is increasingly investigated in AI research field. It is very\nchallenging due to the complicated spatial dependencies between different\nlocations and dynamic temporal dependencies among different time intervals.\nAlthough measurements of both dependencies are employed, existing methods\nsuffer from the following two problems. First, the temporal dependencies are\nmeasured either uniformly or bias against long-term dependencies, which\noverlooks the distinctive impacts of short-term and long-term temporal\ndependencies. Second, the existing methods capture spatial and temporal\ndependencies independently, which wrongly assumes that the correlations between\nthese dependencies are weak and ignores the complicated mutual influences\nbetween them. To address these issues, we propose a Spatial-Temporal\nSelf-Attention Network (ST-SAN). As the path-length of attending long-term\ndependency is shorter in the self-attention mechanism, the vanishing of\nlong-term temporal dependencies is prevented. In addition, since our model\nrelies solely on attention mechanisms, the spatial and temporal dependencies\ncan be simultaneously measured. Experimental results on real-world data\ndemonstrate that, in comparison with state-of-the-art methods, our model\nreduces the root mean square errors by 9% in inflow prediction and 4% in\noutflow prediction on Taxi-NYC data, which is very significant compared to the\nprevious improvement.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 07:42:35 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 02:02:09 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Lin", "Haoxing", ""], ["Jia", "Weijia", ""], ["Sun", "Yiping", ""], ["You", "Yongjian", ""]]}, {"id": "1912.07669", "submitter": "Burhaneddin Yaman", "authors": "Burhaneddin Yaman, Seyed Amir Hossein Hosseini, Steen Moeller, Jutta\n  Ellermann, K\\^amil U\\u{g}urbil, Mehmet Ak\\c{c}akaya", "title": "Self-Supervised Learning of Physics-Guided Reconstruction Neural\n  Networks without Fully-Sampled Reference Data", "comments": "This work is an extension of our previous work arXiv:1910.09116", "journal-ref": "Magnetic Resonance in Medicine, 2020", "doi": "10.1002/mrm.28378", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop a strategy for training a physics-guided MRI\nreconstruction neural network without a database of fully-sampled datasets.\nTheory and Methods: Self-supervised learning via data under-sampling (SSDU) for\nphysics-guided deep learning (DL) reconstruction partitions available\nmeasurements into two disjoint sets, one of which is used in the data\nconsistency units in the unrolled network and the other is used to define the\nloss for training. The proposed training without fully-sampled data is compared\nto fully-supervised training with ground-truth data, as well as conventional\ncompressed sensing and parallel imaging methods using the publicly available\nfastMRI knee database. The same physics-guided neural network is used for both\nproposed SSDU and supervised training. The SSDU training is also applied to\nprospectively 2-fold accelerated high-resolution brain datasets at different\nacceleration rates, and compared to parallel imaging. Results: Results on five\ndifferent knee sequences at acceleration rate of 4 shows that proposed\nself-supervised approach performs closely with supervised learning, while\nsignificantly outperforming conventional compressed sensing and parallel\nimaging, as characterized by quantitative metrics and a clinical reader study.\nThe results on prospectively sub-sampled brain datasets, where supervised\nlearning cannot be employed due to lack of ground-truth reference, show that\nthe proposed self-supervised approach successfully perform reconstruction at\nhigh acceleration rates (4, 6 and 8). Image readings indicate improved visual\nreconstruction quality with the proposed approach compared to parallel imaging\nat acquisition acceleration. Conclusion: The proposed SSDU approach allows\ntraining of physics-guided DL-MRI reconstruction without fully-sampled data,\nwhile achieving comparable results with supervised DL-MRI trained on\nfully-sampled data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:04:02 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 19:13:15 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Yaman", "Burhaneddin", ""], ["Hosseini", "Seyed Amir Hossein", ""], ["Moeller", "Steen", ""], ["Ellermann", "Jutta", ""], ["U\u011furbil", "K\u00e2mil", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "1912.07670", "submitter": "Youngwoon Lee", "authors": "Youngwoon Lee, Edward S. Hu, Zhengyu Yang, Joseph J. Lim", "title": "To Follow or not to Follow: Selective Imitation Learning from\n  Observations", "comments": "Published at the Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations is a useful way to transfer a skill from one\nagent to another. While most imitation learning methods aim to mimic an expert\nskill by following the demonstration step-by-step, imitating every step in the\ndemonstration often becomes infeasible when the learner and its environment are\ndifferent from the demonstration. In this paper, we propose a method that can\nimitate a demonstration composed solely of observations, which may not be\nreproducible with the current agent. Our method, dubbed selective imitation\nlearning from observations (SILO), selects reachable states in the\ndemonstration and learns how to reach the selected states. Our experiments on\nboth simulated and real robot environments show that our method reliably\nperforms a new task by following a demonstration. Videos and code are available\nat https://clvrai.com/silo .\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:05:37 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Lee", "Youngwoon", ""], ["Hu", "Edward S.", ""], ["Yang", "Zhengyu", ""], ["Lim", "Joseph J.", ""]]}, {"id": "1912.07685", "submitter": "Benedikt Boecking", "authors": "Benedikt Boecking and Artur Dubrawski", "title": "Pairwise Feedback for Data Programming", "comments": "Presented at the NeurIPS 2019 workshop on Learning with Rich\n  Experience: Integration of Learning Paradigms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scalability of the labeling process and the attainable quality of labels\nhave become limiting factors for many applications of machine learning. The\nprogrammatic creation of labeled datasets via the synthesis of noisy heuristics\nprovides a promising avenue to address this problem. We propose to improve\nmodeling of latent class variables in the programmatic creation of labeled\ndatasets by incorporating pairwise feedback into the process. We discuss the\nease with which such pairwise feedback can be obtained or generated in many\napplication domains. Our experiments show that even a small number of sources\nof pairwise feedback can substantially improve the quality of the posterior\nestimate of the latent class variable.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:24:45 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1912.07700", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab, Jaydip Sen", "title": "A Robust Predictive Model for Stock Price Prediction Using Deep Learning\n  and Natural Language Processing", "comments": "6 pages, 18 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future movement of stock prices has been a subject matter of\nmany research work. There is a gamut of literature of technical analysis of\nstock prices where the objective is to identify patterns in stock price\nmovements and derive profit from it. Improving the prediction accuracy remains\nthe single most challenge in this area of research. We propose a hybrid\napproach for stock price movement prediction using machine learning, deep\nlearning, and natural language processing. We select the NIFTY 50 index values\nof the National Stock Exchange of India, and collect its daily price movement\nover a period of three years (2015 to 2017). Based on the data of 2015 to 2017,\nwe build various predictive models using machine learning, and then use those\nmodels to predict the closing value of NIFTY 50 for the period January 2018\ntill June 2019 with a prediction horizon of one week. For predicting the price\nmovement patterns, we use a number of classification techniques, while for\npredicting the actual closing price of the stock, various regression models\nhave been used. We also build a Long and Short-Term Memory - based deep\nlearning network for predicting the closing price of the stocks and compare the\nprediction accuracies of the machine learning models with the LSTM model. We\nfurther augment the predictive model by integrating a sentiment analysis module\non twitter data to correlate the public sentiment of stock prices with the\nmarket sentiment. This has been done using twitter sentiment and previous week\nclosing values to predict stock price movement for the next week. We tested our\nproposed scheme using a cross validation method based on Self Organizing Fuzzy\nNeural Networks and found extremely interesting results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 20:50:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}, {"id": "1912.07701", "submitter": "Donatas Narbutis", "authors": "Lucia Larise Stavarache (1), Donatas Narbutis (2), Toyotaro Suzumura\n  (3), Ray Harishankar (1), Augustas \\v{Z}altauskas (2) ((1) IBM Global\n  Business Services, (2) IBM Lithuania, Client Innovation Center Baltic, (3)\n  IBM T.J. Watson Research Center)", "title": "Exploring Multi-Banking Customer-to-Customer Relations in AML Context\n  with Poincar\\'e Embeddings", "comments": "NeurIPS 2019 Workshop on Robust AI in Financial Services\n  (https://sites.google.com/view/robust-ai-in-fs-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CY cs.LG cs.SI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years money laundering schemes have grown in complexity and\nspeed of realization, affecting financial institutions and millions of\ncustomers globally. Strengthened privacy policies, along with in-country\nregulations, make it hard for banks to inner- and cross-share, and report\nsuspicious activities for the AML (Anti-Money Laundering) measures. Existing\ntopologies and models for AML analysis and information sharing are subject to\nmajor limitations, such as compliance with regulatory constraints, extended\ninfrastructure to run high-computation algorithms, data quality and span,\nproving cumbersome and costly to execute, federate, and interpret. This paper\nproposes a new topology for exploring multi-banking customer social relations\nin AML context -- customer-to-customer, customer-to-transaction, and\ntransaction-to-transaction -- using a 3D modeling topological algebra\nformulated through Poincar\\'e embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:38:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 12:31:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Stavarache", "Lucia Larise", ""], ["Narbutis", "Donatas", ""], ["Suzumura", "Toyotaro", ""], ["Harishankar", "Ray", ""], ["\u017daltauskas", "Augustas", ""]]}, {"id": "1912.07702", "submitter": "Guanghui Lan", "authors": "Guanghui Lan", "title": "Complexity of Stochastic Dual Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic dual dynamic programming is a cutting plane type algorithm for\nmulti-stage stochastic optimization originated about 30 years ago. In spite of\nits popularity in practice, there does not exist any analysis on the\nconvergence rates of this method. In this paper, we first establish the number\nof iterations, i.e., iteration complexity, required by a basic dynamic cutting\nplane method for solving relatively simple multi-stage optimization problems,\nby introducing novel mathematical tools including the saturation of search\npoints. We then refine these basic tools and establish the iteration complexity\nfor both deterministic and stochastic dual dynamic programming methods for\nsolving more general multi-stage stochastic optimization problems under the\nstandard stage-wise independence assumption. Our results indicate that the\ncomplexity of these methods mildly increases with the number of stages $T$, in\nfact linearly dependent on $T$ for discounted problems. Therefore, they are\nefficient for strategic decision making which involves a large number of\nstages, but with a relatively small number of decision variables in each stage.\nWithout explicitly discretizing the state and action spaces, these methods\nmight also be pertinent to the related reinforcement learning and stochastic\ncontrol areas.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:56:46 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 23:19:37 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2019 18:01:10 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 02:30:55 GMT"}, {"version": "v5", "created": "Sat, 5 Sep 2020 15:53:36 GMT"}, {"version": "v6", "created": "Tue, 29 Jun 2021 15:55:35 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Lan", "Guanghui", ""]]}, {"id": "1912.07721", "submitter": "David DeFazio", "authors": "David DeFazio and Arti Ramesh", "title": "Adversarial Model Extraction on Graph Neural Networks", "comments": "AAAI Workshop on Deep Learning on Graphs: Methodologies and\n  Applications (DLGMA), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the advent of deep neural networks came various methods of\nexploitation, such as fooling the classifier or contaminating its training\ndata. Another such attack is known as model extraction, where provided API\naccess to some black box neural network, the adversary extracts the underlying\nmodel. This is done by querying the model in such a way that the underlying\nneural network provides enough information to the adversary to be\nreconstructed. While several works have achieved impressive results with neural\nnetwork extraction in the propositional domain, this problem has not yet been\nconsidered over the relational domain, where data samples are no longer\nconsidered to be independent and identically distributed (iid). Graph Neural\nNetworks (GNNs) are a popular deep learning framework to perform machine\nlearning tasks over relational data. In this work, we formalize an instance of\nGNN extraction, present a solution with preliminary results, and discuss our\nassumptions and future directions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 21:54:21 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["DeFazio", "David", ""], ["Ramesh", "Arti", ""]]}, {"id": "1912.07729", "submitter": "Charlie Frogner", "authors": "Charlie Frogner, Sebastian Claici, Edward Chien, Justin Solomon", "title": "Incorporating Unlabeled Data into Distributionally Robust Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a robust alternative to empirical risk minimization called\ndistributionally robust learning (DRL), in which one learns to perform against\nan adversary who can choose the data distribution from a specified set of\ndistributions. We illustrate a problem with current DRL formulations, which\nrely on an overly broad definition of allowed distributions for the adversary,\nleading to learned classifiers that are unable to predict with any confidence.\nWe propose a solution that incorporates unlabeled data into the DRL problem to\nfurther constrain the adversary. We show that this new formulation is tractable\nfor stochastic gradient-based optimization and yields a computable guarantee on\nthe future performance of the learned classifier, analogous to -- but tighter\nthan -- guarantees from conventional DRL. We examine the performance of this\nnew formulation on 14 real datasets and find that it often yields effective\nclassifiers with nontrivial performance guarantees in situations where\nconventional DRL produces neither. Inspired by these results, we extend our DRL\nformulation to active learning with a novel, distributionally-robust version of\nthe standard model-change heuristic. Our active learning algorithm often\nachieves superior learning performance to the original heuristic on real\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 22:13:19 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 01:55:20 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Frogner", "Charlie", ""], ["Claici", "Sebastian", ""], ["Chien", "Edward", ""], ["Solomon", "Justin", ""]]}, {"id": "1912.07730", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Mason Carnahan, Co Tran, Ahmed H Tewfik", "title": "Continuous Speech Recognition using EEG and Video", "comments": "On preparation for submission to EUSIPCO 2020. arXiv admin note: text\n  overlap with arXiv:1911.11610, arXiv:1911.04261", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate whether electroencephalography (EEG) features\ncan be used to improve the performance of continuous visual speech recognition\nsystems. We implemented a connectionist temporal classification (CTC) based\nend-to-end automatic speech recognition (ASR) model for performing recognition.\nOur results demonstrate that EEG features are helpful in enhancing the\nperformance of continuous visual speech recognition systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 22:16:19 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 04:34:45 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 04:01:48 GMT"}, {"version": "v4", "created": "Tue, 24 Dec 2019 06:39:00 GMT"}, {"version": "v5", "created": "Fri, 27 Dec 2019 22:47:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Krishna", "Gautam", ""], ["Carnahan", "Mason", ""], ["Tran", "Co", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "1912.07737", "submitter": "Djordje Slijepcevic", "authors": "Djordje Slijepcevic, Fabian Horst, Sebastian Lapuschkin, Anna-Maria\n  Raberger, Matthias Zeppelzauer, Wojciech Samek, Christian Breiteneder,\n  Wolfgang I. Sch\\\"ollhorn, Brian Horsak", "title": "On the Explanation of Machine Learning Predictions in Clinical Gait\n  Analysis", "comments": "37 pages, 7 figures, 2 tables, 24 supplementary figures, 1\n  supplementary table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) is increasingly used to support decision-making in the\nhealthcare sector. While ML approaches provide promising results with regard to\ntheir classification performance, most share a central limitation, namely their\nblack-box character. Motivated by the interest to understand the functioning of\nML models, methods from the field of Explainable Artificial Intelligence (XAI)\nhave recently become important. This article investigates the usefulness of XAI\nmethods in clinical gait classification. For this purpose, predictions of\nstate-of-the-art classification methods are explained with an established XAI\nmethod, i.e., Layer-wise Relevance Propagation (LRP). We propose to evaluate\nthe obtained explanations with two complementary approaches: a statistical\nanalysis of the underlying data using Statistical Parametric Mapping and a\nqualitative evaluation by a clinical expert. A gait dataset comprising ground\nreaction force measurements from 132 patients with different lower-body gait\ndisorders and 62 healthy controls is utilized. We investigate several gait\nclassification tasks, employ multiple classification methods, and analyze the\nimpact of data normalization and different signal components for classification\nperformance and explanation quality. Our experiments show that explanations\nobtained by LRP exhibit promising statistical properties concerning inter-class\ndiscriminativity and are also in line with clinically relevant biomechanical\ngait characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 22:34:06 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:20:32 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Slijepcevic", "Djordje", ""], ["Horst", "Fabian", ""], ["Lapuschkin", "Sebastian", ""], ["Raberger", "Anna-Maria", ""], ["Zeppelzauer", "Matthias", ""], ["Samek", "Wojciech", ""], ["Breiteneder", "Christian", ""], ["Sch\u00f6llhorn", "Wolfgang I.", ""], ["Horsak", "Brian", ""]]}, {"id": "1912.07743", "submitter": "Lin Fu", "authors": "Lin Fu and Bruno De Man", "title": "A hierarchical approach to deep learning and its application to\n  tomographic reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has shown unprecedented performance for many image\nanalysis and image enhancement tasks. Yet, solving large-scale inverse problems\nlike tomographic reconstruction remains challenging for DL. These problems\ninvolve non-local and space-variant integral transforms between the input and\noutput domains, for which no efficient neural network models have been found. A\nprior attempt to solve such problems with supervised learning relied on a\nbrute-force fully connected network and applied it to reconstruction for a\n$128^4$ system matrix size. This cannot practically scale to realistic data\nsizes such as $512^4$ and $512^6$ for three-dimensional data sets. Here we\npresent a novel framework to solve such problems with deep learning by casting\nthe original problem as a continuum of intermediate representations between the\ninput and output data. The original problem is broken down into a sequence of\nsimpler transformations that can be well mapped onto an efficient hierarchical\nnetwork architecture, with exponentially fewer parameters than a generic\nnetwork would need. We applied the approach to computed tomography (CT) image\nreconstruction for a $512^4$ system matrix size. To our knowledge, this enabled\nthe first data-driven DL solver for full-size CT reconstruction without relying\non the structure of direct (analytical) or iterative (numerical) inversion\ntechniques. The proposed approach is applicable to other imaging problems such\nas emission and magnetic resonance reconstruction. More broadly, hierarchical\nDL opens the door to a new class of solvers for general inverse problems, which\ncould potentially lead to improved signal-to-noise ratio, spatial resolution\nand computational efficiency in various areas.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 22:53:14 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Fu", "Lin", ""], ["De Man", "Bruno", ""]]}, {"id": "1912.07747", "submitter": "William Hsu", "authors": "Huichen Yang, Carlos A. Aguirre, Maria F. De La Torre, Derek\n  Christensen, Luis Bobadilla, Emily Davich, Jordan Roth, Lei Luo, Yihong\n  Theis, Alice Lam, T. Yong-Jin Han, David Buttler, William H. Hsu", "title": "Pipelines for Procedural Information Extraction from Scientific\n  Literature: Towards Recipes using Machine Learning and Data Science", "comments": "15th International Conference on Document Analysis and Recognition\n  Workshops (ICDARW 2019)", "journal-ref": null, "doi": "10.1109/ICDARW.2019.10037", "report-no": "2019-1", "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a machine learning and data science pipeline for\nstructured information extraction from documents, implemented as a suite of\nopen-source tools and extensions to existing tools. It centers around a\nmethodology for extracting procedural information in the form of recipes,\nstepwise procedures for creating an artifact (in this case synthesizing a\nnanomaterial), from published scientific literature. From our overall goal of\nproducing recipes from free text, we derive the technical objectives of a\nsystem consisting of pipeline stages: document acquisition and filtering,\npayload extraction, recipe step extraction as a relationship extraction task,\nrecipe assembly, and presentation through an information retrieval interface\nwith question answering (QA) functionality. This system meets computational\ninformation and knowledge management (CIKM) requirements of metadata-driven\npayload extraction, named entity extraction, and relationship extraction from\ntext. Functional contributions described in this paper include semi-supervised\nmachine learning methods for PDF filtering and payload extraction tasks,\nfollowed by structured extraction and data transformation tasks beginning with\nsection extraction, recipe steps as information tuples, and finally assembled\nrecipes. Measurable objective criteria for extraction quality include precision\nand recall of recipe steps, ordering constraints, and QA accuracy, precision,\nand recall. Results, key novel contributions, and significant open problems\nderived from this work center around the attribution of these holistic quality\nmeasures to specific machine learning and inference stages of the pipeline,\neach with their performance measures. The desired recipes contain identified\npreconditions, material inputs, and operations, and constitute the overall\noutput generated by our computational information and knowledge management\n(CIKM) system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 23:04:03 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Yang", "Huichen", ""], ["Aguirre", "Carlos A.", ""], ["De La Torre", "Maria F.", ""], ["Christensen", "Derek", ""], ["Bobadilla", "Luis", ""], ["Davich", "Emily", ""], ["Roth", "Jordan", ""], ["Luo", "Lei", ""], ["Theis", "Yihong", ""], ["Lam", "Alice", ""], ["Han", "T. Yong-Jin", ""], ["Buttler", "David", ""], ["Hsu", "William H.", ""]]}, {"id": "1912.07748", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Bhavya Kailkhura, Timo\n  Bremer", "title": "MimicGAN: Robust Projection onto Image Manifolds with Corruption\n  Mimicking", "comments": "International Journal on Computer Vision's (IJCV) Special Issue on\n  GANs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, Generative Adversarial Networks (GANs) have\ndramatically advanced our ability to represent and parameterize\nhigh-dimensional, non-linear image manifolds. As a result, they have been\nwidely adopted across a variety of applications, ranging from challenging\ninverse problems like image completion, to problems such as anomaly detection\nand adversarial defense. A recurring theme in many of these applications is the\nnotion of projecting an image observation onto the manifold that is inferred by\nthe generator. In this context, Projected Gradient Descent (PGD) has been the\nmost popular approach, which essentially optimizes for a latent vector that\nminimizes the discrepancy between a generated image and the given observation.\nHowever, PGD is a brittle optimization technique that fails to identify the\nright projection (or latent vector) when the observation is corrupted, or\nperturbed even by a small amount. Such corruptions are common in the real\nworld, for example images in the wild come with unknown crops, rotations,\nmissing pixels, or other kinds of non-linear distributional shifts which break\ncurrent encoding methods, rendering downstream applications unusable. To\naddress this, we propose corruption mimicking -- a new robust projection\ntechnique, that utilizes a surrogate network to approximate the unknown\ncorruption directly at test time, without the need for additional supervision\nor data augmentation. The proposed method is significantly more robust than PGD\nand other competing methods under a wide variety of corruptions, thereby\nenabling a more effective use of GANs in real-world applications. More\nimportantly, we show that our approach produces state-of-the-art performance in\nseveral GAN-based applications -- anomaly detection, domain adaptation, and\nadversarial defense, that benefit from an accurate projection.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 23:14:56 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 19:18:41 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 17:21:50 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Kailkhura", "Bhavya", ""], ["Bremer", "Timo", ""]]}, {"id": "1912.07756", "submitter": "Gianluca Maguolo", "authors": "Loris Nanni, Gianluca Maguolo, Michelangelo Paci", "title": "Data augmentation approaches for improving animal audio classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present ensembles of classifiers for automated animal audio\nclassification, exploiting different data augmentation techniques for training\nConvolutional Neural Networks (CNNs). The specific animal audio classification\nproblems are i) birds and ii) cat sounds, whose datasets are freely available.\nWe train five different CNNs on the original datasets and on their versions\naugmented by four augmentation protocols, working on the raw audio signals or\ntheir representations as spectrograms. We compared our best approaches with the\nstate of the art, showing that we obtain the best recognition rate on the same\ndatasets, without ad hoc parameter optimization. Our study shows that different\nCNNs can be trained for the purpose of animal audio classification and that\ntheir fusion works better than the stand-alone classifiers. To the best of our\nknowledge this is the largest study on data augmentation for CNNs in animal\naudio classification audio datasets using the same set of classifiers and\nparameters. Our MATLAB code is available at https://github.com/LorisNanni.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 23:30:42 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 20:19:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nanni", "Loris", ""], ["Maguolo", "Gianluca", ""], ["Paci", "Michelangelo", ""]]}, {"id": "1912.07768", "submitter": "Felipe Petroski Such", "authors": "Felipe Petroski Such, Aditya Rawal, Joel Lehman, Kenneth O. Stanley,\n  Jeff Clune", "title": "Generative Teaching Networks: Accelerating Neural Architecture Search by\n  Learning to Generate Synthetic Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the intriguing question of whether we can create\nlearning algorithms that automatically generate training data, learning\nenvironments, and curricula in order to help AI agents rapidly learn. We show\nthat such algorithms are possible via Generative Teaching Networks (GTNs), a\ngeneral approach that is, in theory, applicable to supervised, unsupervised,\nand reinforcement learning, although our experiments only focus on the\nsupervised case. GTNs are deep neural networks that generate data and/or\ntraining environments that a learner (e.g. a freshly initialized neural\nnetwork) trains on for a few SGD steps before being tested on a target task. We\nthen differentiate through the entire learning process via meta-gradients to\nupdate the GTN parameters to improve performance on the target task. GTNs have\nthe beneficial property that they can theoretically generate any type of data\nor training environment, making their potential impact large. This paper\nintroduces GTNs, discusses their potential, and showcases that they can\nsubstantially accelerate learning. We also demonstrate a practical and exciting\napplication of GTNs: accelerating the evaluation of candidate architectures for\nneural architecture search (NAS), which is rate-limited by such evaluations,\nenabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art,\nfinding higher performing architectures when controlling for the search\nproposal mechanism. GTN-NAS also is competitive with the overall state of the\nart approaches, which achieve top performance while using orders of magnitude\nless computation than typical NAS methods. Speculating forward, GTNs may\nrepresent a first step toward the ambitious goal of algorithms that generate\ntheir own training data and, in doing so, open a variety of interesting new\nresearch questions and directions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 00:57:50 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Such", "Felipe Petroski", ""], ["Rawal", "Aditya", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1912.07773", "submitter": "Sonia Baee", "authors": "Sonia Baee, Erfan Pakdamanian, Inki Kim, Lu Feng, Vicente Ordonez,\n  Laura Barnes", "title": "MEDIRL: Predicting the Visual Attention of Drivers via Maximum Entropy\n  Deep Inverse Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by human visual attention, we introduce a Maximum Entropy Deep\nInverse Reinforcement Learning (MEDIRL) framework for modeling the visual\nattention allocation of drivers in imminent rear-end collisions. MEDIRL is\ncomposed of visual, driving, and attention modules. Given a front-view driving\nvideo and corresponding eye fixations from humans, the visual and driving\nmodules extract generic and driving-specific visual features, respectively.\nFinally, the attention module learns the intrinsic task-sensitive reward\nfunctions induced by eye fixation policies recorded from attentive drivers.\nMEDIRL uses the learned policies to predict visual attention allocation of\ndrivers. We also introduce EyeCar, a new driver visual attention dataset during\naccident-prone situations. We conduct comprehensive experiments and show that\nMEDIRL outperforms previous state-of-the-art methods on driving task-related\nvisual attention allocation on the following large-scale driving attention\nbenchmark datasets: DR(eye)VE, BDD-A, and DADA-2000. The code and dataset are\nprovided for reproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 01:05:26 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 00:34:35 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 00:37:03 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Baee", "Sonia", ""], ["Pakdamanian", "Erfan", ""], ["Kim", "Inki", ""], ["Feng", "Lu", ""], ["Ordonez", "Vicente", ""], ["Barnes", "Laura", ""]]}, {"id": "1912.07776", "submitter": "Zeyu Deng", "authors": "Zeyu Deng, Lihui Wang, Zixiang Kuai, Qijian Chen, Xinyu Cheng, Feng\n  Yang, Jie Yang, Yuemin Zhu", "title": "CNN-Based Invertible Wavelet Scattering for the Investigation of\n  Diffusion Properties of the In Vivo Human Heart in Diffusion Tensor Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vivo diffusion tensor imaging (DTI) is a promising technique to\ninvestigate noninvasively the fiber structures of the in vivo human heart.\nHowever, signal loss due to motions remains a persistent problem in in vivo\ncardiac DTI. We propose a novel motion-compensation method for investigating in\nvivo myocardium structures in DTI with free-breathing acquisitions. The method\nis based on an invertible Wavelet Scattering achieved by means of Convolutional\nNeural Network (WSCNN). It consists of first extracting translation-invariant\nwavelet scattering features from DW images acquired at different trigger delays\nand then mapping the fused scattering features into motion-compensated spatial\nDW images by performing an inverse wavelet scattering transform achieved using\nCNN. The results on both simulated and acquired in vivo cardiac DW images\nshowed that the proposed WSCNN method effectively compensates for\nmotion-induced signal loss and produces in vivo cardiac DW images with better\nquality and more coherent fiber structures with respect to existing methods,\nwhich makes it an interesting method for measuring correctly the diffusion\nproperties of the in vivo human heart in DTI under free breathing.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 01:26:06 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Deng", "Zeyu", ""], ["Wang", "Lihui", ""], ["Kuai", "Zixiang", ""], ["Chen", "Qijian", ""], ["Cheng", "Xinyu", ""], ["Yang", "Feng", ""], ["Yang", "Jie", ""], ["Zhu", "Yuemin", ""]]}, {"id": "1912.07777", "submitter": "Laurel Orr", "authors": "Laurel Orr, Samuel Ainsworth, Walter Cai, Kevin Jamieson, Magda\n  Balazinska, Dan Suciu", "title": "Mosaic: A Sample-Based Database System for Open World Query Processing", "comments": "CIDR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data scientists have relied on samples to analyze populations of interest for\ndecades. Recently, with the increase in the number of public data repositories,\nsample data has become easier to access. It has not, however, become easier to\nanalyze. This sample data is arbitrarily biased with an unknown sampling\nprobability, meaning data scientists must manually debias the sample with\ncustom techniques to avoid inaccurate results. In this vision paper, we propose\nMosaic, a database system that treats samples as first-class citizens and\nallows users to ask questions over populations represented by these samples.\nAnswering queries over biased samples is non-trivial as there is no existing,\nstandard technique to answer population queries when the sampling probability\nis unknown. In this paper, we show how our envisioned system solves this\nproblem by having a unique sample-based data model with extensions to the SQL\nlanguage. We propose how to perform population query answering using biased\nsamples and give preliminary results for one of our novel query answering\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 01:34:05 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 19:46:28 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 20:48:14 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Orr", "Laurel", ""], ["Ainsworth", "Samuel", ""], ["Cai", "Walter", ""], ["Jamieson", "Kevin", ""], ["Balazinska", "Magda", ""], ["Suciu", "Dan", ""]]}, {"id": "1912.07778", "submitter": "He-Feng Yin", "authors": "Wen Zhao, Xiao-Jun Wu, He-Feng Yin and Zi-Qi Li", "title": "Collaborative representation-based robust face recognition by\n  discriminative low-rank representation", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust face recognition in which both the training\nand test samples might be corrupted because of disguise and occlusion.\nPerformance of conventional subspace learning methods and recently proposed\nsparse representation based classification (SRC) might be degraded when\ncorrupted training samples are provided. In addition, sparsity based approaches\nare time-consuming due to the sparsity constraint. To alleviate the\naforementioned problems to some extent, in this paper, we propose a\ndiscriminative low-rank representation method for collaborative\nrepresentation-based (DLRR-CR) robust face recognition. DLRR-CR not only\nobtains a clean dictionary, it further forces the sub-dictionaries for distinct\nclasses to be as independent as possible by introducing a structural\nincoherence regularization term. Simultaneously, a low-rank projection matrix\ncan be learned to remove the possible corruptions in the testing samples.\nCollaborative representation based classification (CRC) method is exploited in\nour proposed method which has closed-form solution. Experimental results\nobtained on public face databases verify the effectiveness and robustness of\nour method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 01:40:04 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhao", "Wen", ""], ["Wu", "Xiao-Jun", ""], ["Yin", "He-Feng", ""], ["Li", "Zi-Qi", ""]]}, {"id": "1912.07783", "submitter": "Mahmudul Hasan", "authors": "Nowshin Tasnim, Mahmudul Hasan, Ishrak Islam", "title": "Comparisonal study of Deep Learning approaches on Retinal OCT Image", "comments": "Poster in International Conference on Innovation in Engineering and\n  Technology (ICIET) 23-24 December, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical science, the use of computer science in disease detection and\ndiagnosis is gaining popularity. Previously, the detection of disease used to\ntake a significant amount of time and was less reliable. Machine learning (ML)\ntechniques employed in recent biomedical researches are making revolutionary\nchanges by gaining higher accuracy with more concise timing. At present, it is\neven possible to automatically detect diseases from the scanned images with the\nhelp of ML. In this research, we have taken such an attempt to detect retinal\ndiseases from optical coherence tomography (OCT) X-ray images. Here, we propose\na deep learning (DL) based approach in detecting retinal diseases from OCT\nimages which can identify three conditions of the retina. Four different models\nused in this approach are compared with each other. On the test set, the\ndetection accuracy is 98.00\\% for a vanilla convolutional neural network (CNN)\nmodel, 99.07\\% for Xception model, 97.00\\% for ResNet50 model, and 99.17\\% for\nMobileNetV2 model. The MobileNetV2 model acquires the highest accuracy, and the\nclosest to the highest is the Xception model. The proposed approach has a\npotential impact on creating a tool for automatically detecting retinal\ndiseases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:09:11 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Tasnim", "Nowshin", ""], ["Hasan", "Mahmudul", ""], ["Islam", "Ishrak", ""]]}, {"id": "1912.07791", "submitter": "Xuan Zhang", "authors": "Xuan Zhang, Shaofei Qin, Yi Xu, Hongteng Xu", "title": "Quaternion Product Units for Deep Learning on 3D Rotation Groups", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel quaternion product unit (QPU) to represent data on 3D\nrotation groups. The QPU leverages quaternion algebra and the law of 3D\nrotation group, representing 3D rotation data as quaternions and merging them\nvia a weighted chain of Hamilton products. We prove that the representations\nderived by the proposed QPU can be disentangled into \"rotation-invariant\"\nfeatures and \"rotation-equivariant\" features, respectively, which supports the\nrationality and the efficiency of the QPU in theory. We design quaternion\nneural networks based on our QPUs and make our models compatible with existing\ndeep learning models. Experiments on both synthetic and real-world data show\nthat the proposed QPU is beneficial for the learning tasks requiring rotation\nrobustness.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 02:46:54 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 12:47:39 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Zhang", "Xuan", ""], ["Qin", "Shaofei", ""], ["Xu", "Yi", ""], ["Xu", "Hongteng", ""]]}, {"id": "1912.07800", "submitter": "Ethan Chi", "authors": "Bowen Jing, Ethan A. Chi, Jillian Tang", "title": "SGVAE: Sequential Graph Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models of graphs are well-known, but many existing models are\nlimited in scalability and expressivity. We present a novel sequential\ngraphical variational autoencoder operating directly on graphical\nrepresentations of data. In our model, the encoding and decoding of a graph as\nis framed as a sequential deconstruction and construction process,\nrespectively, enabling the the learning of a latent space. Experiments on a\ncycle dataset show promise, but highlight the need for a relaxation of the\ndistribution over node permutations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 03:19:47 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Jing", "Bowen", ""], ["Chi", "Ethan A.", ""], ["Tang", "Jillian", ""]]}, {"id": "1912.07812", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang and Ali Etemad", "title": "Capsule Attention for Multimodal EEG-EOG Representation Learning with\n  Application to Driver Vigilance Estimation", "comments": "Accepted by IEEE Transactions on Neural Systems and Rehabilitation\n  Engineering", "journal-ref": null, "doi": "10.1109/TNSRE.2021.3089594", "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver vigilance estimation is an important task for transportation safety.\nWearable and portable brain-computer interface devices provide a powerful means\nfor real-time monitoring of the vigilance level of drivers to help with\navoiding distracted or impaired driving. In this paper, we propose a novel\nmultimodal architecture for in-vehicle vigilance estimation from\nElectroencephalogram and Electrooculogram. To enable the system to focus on the\nmost salient parts of the learned multimodal representations, we propose an\narchitecture composed of a capsule attention mechanism following a deep Long\nShort-Term Memory (LSTM) network. Our model learns hierarchical dependencies in\nthe data through the LSTM and capsule feature representation layers. To better\nexplore the discriminative ability of the learned representations, we study the\neffect of the proposed capsule attention mechanism including the number of\ndynamic routing iterations as well as other parameters. Experiments show the\nrobustness of our method by outperforming other solutions and baseline\ntechniques, setting a new state-of-the-art. We then provide an analysis on\ndifferent frequency bands and brain regions to evaluate their suitability for\ndriver vigilance estimation. Lastly, an analysis on the role of capsule\nattention, multimodality, and robustness to noise is performed, highlighting\nthe advantages of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 04:20:08 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 19:59:07 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 16:31:51 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 16:14:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Guangyi", ""], ["Etemad", "Ali", ""]]}, {"id": "1912.07814", "submitter": "Fahimeh Bahmaninezhad", "authors": "Fahimeh Bahmaninezhad, Shi-Xiong Zhang, Yong Xu, Meng Yu, John H.L.\n  Hansen, Dong Yu", "title": "A Unified Framework for Speech Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech separation refers to extracting each individual speech source in a\ngiven mixed signal. Recent advancements in speech separation and ongoing\nresearch in this area, have made these approaches as promising techniques for\npre-processing of naturalistic audio streams. After incorporating deep learning\ntechniques into speech separation, performance on these systems is improving\nfaster. The initial solutions introduced for deep learning based speech\nseparation analyzed the speech signals into time-frequency domain with STFT;\nand then encoded mixed signals were fed into a deep neural network based\nseparator. Most recently, new methods are introduced to separate waveform of\nthe mixed signal directly without analyzing them using STFT. Here, we introduce\na unified framework to include both spectrogram and waveform separations into a\nsingle structure, while being only different in the kernel function used to\nencode and decode the data; where, both can achieve competitive performance.\nThis new framework provides flexibility; in addition, depending on the\ncharacteristics of the data, or limitations of the memory and latency can set\nthe hyper-parameters to flow in a pipeline of the framework which fits the task\nproperly. We extend single-channel speech separation into multi-channel\nframework with end-to-end training of the network while optimizing the speech\nseparation criterion (i.e., Si-SNR) directly. We emphasize on how tied kernel\nfunctions for calculating spatial features, encoder, and decoder in\nmulti-channel framework can be effective. We simulate spatialized reverberate\ndata for both WSJ0 and LibriSpeech corpora here, and while these two sets of\ndata are different in the matter of size and duration, the effect of capturing\nshorter and longer dependencies of previous/+future samples are studied in\ndetail. We report SDR, Si-SNR and PESQ to evaluate the performance of developed\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 04:21:03 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Bahmaninezhad", "Fahimeh", ""], ["Zhang", "Shi-Xiong", ""], ["Xu", "Yong", ""], ["Yu", "Meng", ""], ["Hansen", "John H. L.", ""], ["Yu", "Dong", ""]]}, {"id": "1912.07819", "submitter": "Jiantao Wu", "authors": "JT Wu and L.Wang", "title": "Angular Learning: Toward Discriminative Embedded Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The margin-based softmax loss functions greatly enhance intra-class\ncompactness and perform well on the tasks of face recognition and object\nclassification. Outperformance, however, depends on the careful hyperparameter\nselection. Moreover, the hard angle restriction also increases the risk of\noverfitting. In this paper, angular loss suggested by maximizing the angular\ngradient to promote intra-class compactness avoids overfitting. Besides, our\nmethod has only one adjustable constant for intra-class compactness control. We\ndefine three metrics to measure inter-class separability and intra-class\ncompactness. In experiments, we test our method, as well as other methods, on\nmany well-known datasets. Experimental results reveal that our method has the\nsuperiority of accuracy improvement, discriminative information, and\ntime-consumption.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 05:08:20 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Wu", "JT", ""], ["Wang", "L.", ""]]}, {"id": "1912.07820", "submitter": "Sainyam Galhotra Mr", "authors": "Sandhya Saisubramanian, Sainyam Galhotra and Shlomo Zilberstein", "title": "Balancing the Tradeoff Between Clustering Value and Interpretability", "comments": "Accepted at AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph clustering groups entities -- the vertices of a graph -- based on their\nsimilarity, typically using a complex distance function over a large number of\nfeatures. Successful integration of clustering approaches in automated\ndecision-support systems hinges on the interpretability of the resulting\nclusters. This paper addresses the problem of generating interpretable\nclusters, given features of interest that signify interpretability to an\nend-user, by optimizing interpretability in addition to common clustering\nobjectives. We propose a $\\beta$-interpretable clustering algorithm that\nensures that at least $\\beta$ fraction of nodes in each cluster share the same\nfeature value. The tunable parameter $\\beta$ is user-specified. We also present\na more efficient algorithm for scenarios with $\\beta\\!=\\!1$ and analyze the\ntheoretical guarantees of the two algorithms. Finally, we empirically\ndemonstrate the benefits of our approaches in generating interpretable clusters\nusing four real-world datasets. The interpretability of the clusters is\ncomplemented by generating simple explanations denoting the feature values of\nthe nodes in the clusters, using frequent pattern mining.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 05:08:34 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 03:24:54 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 00:17:28 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Saisubramanian", "Sandhya", ""], ["Galhotra", "Sainyam", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "1912.07829", "submitter": "Fan Zhang", "authors": "Fan Zhang, Miao Hu", "title": "Defects Mitigation in Resistive Crossbars for Analog Vector Matrix\n  Multiplication", "comments": "Proceedings of the 25th Asia and South Pacific Design Automation\n  Conference (ASP-DAC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With storage and computation happening at the same place, computing in\nresistive crossbars minimizes data movement and avoids the memory bottleneck\nissue. It leads to ultra-high energy efficiency for data-intensive\napplications. However, defects in crossbars severely affect computing accuracy.\nExisting solutions, including re-training with defects and redundant designs,\nbut they have limitations in practical implementations. In this work, we\nintroduce row shuffling and output compensation to mitigate defects without\nre-training or redundant resistive crossbars. We also analyzed the coupling\neffects of defects and circuit parasitics. Moreover, We study different\ncombinations of methods to achieve the best trade-off between cost and\nperformance. Our proposed methods could rescue up to 10% of defects in\nResNet-20 application without performance degradation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 05:49:37 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Zhang", "Fan", ""], ["Hu", "Miao", ""]]}, {"id": "1912.07832", "submitter": "Yu Chen", "authors": "Yu Chen, Lingfei Wu and Mohammed J. Zaki", "title": "Deep Iterative and Adaptive Learning for Graph Neural Networks", "comments": "6 pages. Accepted at the AAAI 2020 Workshop on Deep Learning on\n  Graphs: Methodologies and Applications (AAAI DLGMA 2020). Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end graph learning framework, namely Deep\nIterative and Adaptive Learning for Graph Neural Networks (DIAL-GNN), for\njointly learning the graph structure and graph embeddings simultaneously. We\nfirst cast the graph structure learning problem as a similarity metric learning\nproblem and leverage an adapted graph regularization for controlling\nsmoothness, connectivity and sparsity of the generated graph. We further\npropose a novel iterative method for searching for a hidden graph structure\nthat augments the initial graph structure. Our iterative method dynamically\nstops when the learned graph structure approaches close enough to the optimal\ngraph. Our extensive experiments demonstrate that the proposed DIAL-GNN model\ncan consistently outperform or match state-of-the-art baselines in terms of\nboth downstream task performance and computational time. The proposed approach\ncan cope with both transductive learning and inductive learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:02:59 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Yu", ""], ["Wu", "Lingfei", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1912.07840", "submitter": "Zihan Wang", "authors": "Karthikeyan K, Zihan Wang, Stephen Mayhew, Dan Roth", "title": "Cross-Lingual Ability of Multilingual BERT: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has exhibited the surprising cross-lingual abilities of\nmultilingual BERT (M-BERT) -- surprising since it is trained without any\ncross-lingual objective and with no aligned data. In this work, we provide a\ncomprehensive study of the contribution of different components in M-BERT to\nits cross-lingual ability. We study the impact of linguistic properties of the\nlanguages, the architecture of the model, and the learning objectives. The\nexperimental study is done in the context of three typologically different\nlanguages -- Spanish, Hindi, and Russian -- and using two conceptually\ndifferent NLP tasks, textual entailment and named entity recognition. Among our\nkey conclusions is the fact that the lexical overlap between languages plays a\nnegligible role in the cross-lingual success, while the depth of the network is\nan integral part of it. All our models and implementations can be found on our\nproject page: http://cogcomp.org/page/publication_view/900 .\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 06:53:05 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 18:48:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["K", "Karthikeyan", ""], ["Wang", "Zihan", ""], ["Mayhew", "Stephen", ""], ["Roth", "Dan", ""]]}, {"id": "1912.07850", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Lucas Liebenwein, Katharina Kramer", "title": "Machine Learning-based Estimation of Forest Carbon Stocks to increase\n  Transparency of Forest Preservation Efforts", "comments": "Published at 2019 NeurIPS Workshop on Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of companies and cities plan to become CO2-neutral,\nwhich requires them to invest in renewable energies and carbon emission\noffsetting solutions. One of the cheapest carbon offsetting solutions is\npreventing deforestation in developing nations, a major contributor in global\ngreenhouse gas emissions. However, forest preservation projects historically\ndisplay an issue of trust and transparency, which drives companies to invest in\ntransparent, but expensive air carbon capture facilities. Preservation projects\ncould conduct accurate forest inventories (tree diameter, species, height etc.)\nto transparently estimate the biomass and amount of stored carbon. However,\ncurrent rainforest inventories are too inaccurate, because they are often based\non a few expensive ground-based samples and/or low-resolution satellite\nimagery. LiDAR-based solutions, used in US forests, are accurate, but\ncost-prohibitive, and hardly-accessible in the Amazon rainforest. We propose\naccurate and cheap forest inventory analyses through Deep Learning-based\nprocessing of drone imagery. The more transparent estimation of stored carbon\nwill create higher transparency towards clients and thereby increase trust and\ninvestment into forest preservation projects.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 07:27:26 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Liebenwein", "Lucas", ""], ["Kramer", "Katharina", ""]]}, {"id": "1912.07868", "submitter": "Kevin Bui", "authors": "Kevin Bui and Fredrick Park and Shuai Zhang and Yingyong Qi and Jack\n  Xin", "title": "$\\ell_0$ Regularized Structured Sparsity Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepening and widening convolutional neural networks (CNNs) significantly\nincreases the number of trainable weight parameters by adding more\nconvolutional layers and feature maps per layer, respectively. By imposing\ninter- and intra-group sparsity onto the weights of the layers during the\ntraining process, a compressed network can be obtained with accuracy comparable\nto a dense one. In this paper, we propose a new variant of sparse group lasso\nthat blends the $\\ell_0$ norm onto the individual weight parameters and the\n$\\ell_{2,1}$ norm onto the output channels of a layer. To address the\nnon-differentiability of the $\\ell_0$ norm, we apply variable splitting\nresulting in an algorithm that consists of executing stochastic gradient\ndescent followed by hard thresholding for each iteration. Numerical experiments\nare demonstrated on LeNet-5 and wide-residual-networks for MNIST and CIFAR\n10/100, respectively. They showcase the effectiveness of our proposed method in\nattaining superior test accuracy with network sparsification on par with the\ncurrent state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 08:34:22 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Bui", "Kevin", ""], ["Park", "Fredrick", ""], ["Zhang", "Shuai", ""], ["Qi", "Yingyong", ""], ["Xin", "Jack", ""]]}, {"id": "1912.07882", "submitter": "Yiming Gu", "authors": "Donsuk Lee, Yiming Gu, Jerrick Hoang, Micol Marchetti-Bowick", "title": "Joint Interaction and Trajectory Prediction for Autonomous Driving using\n  Graph Neural Networks", "comments": "Accepted in Machine Learning for Autonomous Driving NeurIPS 2019\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to predict the future motion of vehicles in a traffic\nscene by explicitly modeling their pairwise interactions. Specifically, we\npropose a graph neural network that jointly predicts the discrete interaction\nmodes and 5-second future trajectories for all agents in the scene. Our model\ninfers an interaction graph whose nodes are agents and whose edges capture the\nlong-term interaction intents among the agents. In order to train the model to\nrecognize known modes of interaction, we introduce an auto-labeling function to\ngenerate ground truth interaction labels. Using a large-scale real-world\ndriving dataset, we demonstrate that jointly predicting the trajectories along\nwith the explicit interaction types leads to significantly lower trajectory\nerror than baseline methods. Finally, we show through simulation studies that\nthe learned interaction modes are semantically meaningful.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 09:06:31 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Lee", "Donsuk", ""], ["Gu", "Yiming", ""], ["Hoang", "Jerrick", ""], ["Marchetti-Bowick", "Micol", ""]]}, {"id": "1912.07896", "submitter": "Martin Stoll", "authors": "Martin Stoll", "title": "A literature survey of matrix methods for data science", "comments": null, "journal-ref": "GAMM Mitteilungen, 2020", "doi": "10.1002/gamm.202000013", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient numerical linear algebra is a core ingredient in many applications\nacross almost all scientific and industrial disciplines. With this survey we\nwant to illustrate that numerical linear algebra has played and is playing a\ncrucial role in enabling and improving data science computations with many new\ndevelopments being fueled by the availability of data and computing resources.\nWe highlight the role of various different factorizations and the power of\nchanging the representation of the data as well as discussing topics such as\nrandomized algorithms, functions of matrices, and high-dimensional problems. We\nbriefly touch upon the role of techniques from numerical linear algebra used\nwithin deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 09:37:36 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 12:00:51 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Stoll", "Martin", ""]]}, {"id": "1912.07902", "submitter": "Yanan Li", "authors": "Yanan Li, Shusen Yang, Xuebin Ren, Cong Zhao", "title": "Asynchronous Federated Learning with Differential Privacy for Edge\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has been showing as a promising approach in paving the\nlast mile of artificial intelligence, due to its great potential of solving the\ndata isolation problem in large scale machine learning. Particularly, with\nconsideration of the heterogeneity in practical edge computing systems,\nasynchronous edge-cloud collaboration based federated learning can further\nimprove the learning efficiency by significantly reducing the straggler effect.\nDespite no raw data sharing, the open architecture and extensive collaborations\nof asynchronous federated learning (AFL) still give some malicious participants\ngreat opportunities to infer other parties' training data, thus leading to\nserious concerns of privacy. To achieve a rigorous privacy guarantee with high\nutility, we investigate to secure asynchronous edge-cloud collaborative\nfederated learning with differential privacy, focusing on the impacts of\ndifferential privacy on model convergence of AFL. Formally, we give the first\nanalysis on the model convergence of AFL under DP and propose a multi-stage\nadjustable private algorithm (MAPA) to improve the trade-off between model\nutility and privacy by dynamically adjusting both the noise scale and the\nlearning rate. Through extensive simulations and real-world experiments with an\nedge-could testbed, we demonstrate that MAPA significantly improves both the\nmodel accuracy and convergence speed with sufficient privacy guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 09:49:38 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Li", "Yanan", ""], ["Yang", "Shusen", ""], ["Ren", "Xuebin", ""], ["Zhao", "Cong", ""]]}, {"id": "1912.07911", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Jing Chen, Haonan Sun, Keyang Xu", "title": "A Heterogeneous Graphical Model to Understand User-Level Sentiments in\n  Social Media", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media has seen a tremendous growth in the last decade and is\ncontinuing to grow at a rapid pace. With such adoption, it is increasingly\nbecoming a rich source of data for opinion mining and sentiment analysis. The\ndetection and analysis of sentiment in social media is thus a valuable topic\nand attracts a lot of research efforts. Most of the earlier efforts focus on\nsupervised learning approaches to solve this problem, which require expensive\nhuman annotations and therefore limits their practical use. In our work, we\npropose a semi-supervised approach to predict user-level sentiments for\nspecific topics. We define and utilize a heterogeneous graph built from the\nsocial networks of the users with the knowledge that connected users in social\nnetworks typically share similar sentiments. Compared with the previous works,\nwe have several novelties: (1) we incorporate the influences/authoritativeness\nof the users into the model, 2) we include comment-based and like-based\nuser-user links to the graph, 3) we superimpose multiple heterogeneous graphs\ninto one thereby allowing multiple types of links to exist between two users.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 10:29:26 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Chen", "Jing", ""], ["Sun", "Haonan", ""], ["Xu", "Keyang", ""]]}, {"id": "1912.07913", "submitter": "Anthony Nouy", "authors": "Erwan Grelier and Anthony Nouy and R\\'egis Lebrun", "title": "Learning high-dimensional probability distributions using tree tensor\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the estimation of a high-dimensional probability\ndistribution from i.i.d. samples of the distribution using model classes of\nfunctions in tree-based tensor formats, a particular case of tensor networks\nassociated with a dimension partition tree. The distribution is assumed to\nadmit a density with respect to a product measure, possibly discrete for\nhandling the case of discrete random variables.\n  After discussing the representation of classical model classes in tree-based\ntensor formats, we present learning algorithms based on empirical risk\nminimization using a $L^2$ contrast.\n  These algorithms exploit the multilinear parametrization of the formats to\nrecast the nonlinear minimization problem into a sequence of empirical risk\nminimization problems with linear models. A suitable parametrization of the\ntensor in tree-based tensor format allows to obtain a linear model with\northogonal bases, so that each problem admits an explicit expression of the\nsolution and cross-validation risk estimates. These estimations of the risk\nenable the model selection, for instance when exploiting sparsity in the\ncoefficients of the representation.\n  A strategy for the adaptation of the tensor format (dimension tree and\ntree-based ranks) is provided, which allows to discover and exploit some\nspecific structures of high-dimensional probability distributions such as\nindependence or conditional independence.\n  We illustrate the performances of the proposed algorithms for the\napproximation of classical probabilistic models (such as Gaussian distribution,\ngraphical models, Markov chain).\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 10:31:16 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:39:59 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 17:21:11 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Grelier", "Erwan", ""], ["Nouy", "Anthony", ""], ["Lebrun", "R\u00e9gis", ""]]}, {"id": "1912.07936", "submitter": "Hannes Thaller", "authors": "Hannes Thaller, Lukas Linsbauer, Rudolf Ramler, Alexander Egyed", "title": "Probabilistic Software Modeling: A Data-driven Paradigm for Software\n  Analysis", "comments": "10 pages, 7 figures, 4 tables, 64 references, closed source until\n  full publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software systems are complex, and behavioral comprehension with the\nincreasing amount of AI components challenges traditional testing and\nmaintenance strategies.The lack of tools and methodologies for behavioral\nsoftware comprehension leaves developers to testing and debugging that work in\nthe boundaries of known scenarios. We present Probabilistic Software Modeling\n(PSM), a data-driven modeling paradigm for predictive and generative methods in\nsoftware engineering. PSM analyzes a program and synthesizes a network of\nprobabilistic models that can simulate and quantify the original program's\nbehavior. The approach extracts the type, executable, and property structure of\na program and copies its topology. Each model is then optimized towards the\nobserved runtime leading to a network that reflects the system's structure and\nbehavior. The resulting network allows for the full spectrum of statistical\ninferential analysis with which rich predictive and generative applications can\nbe built. Applications range from the visualization of states, inferential\nqueries, test case generation, and anomaly detection up to the stochastic\nexecution of the modeled system. In this work, we present the modeling\nmethodologies, an empirical study of the runtime behavior of software systems,\nand a comprehensive study on PSM modeled systems. Results indicate that PSM is\na solid foundation for structural and behavioral software comprehension\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:35:41 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 10:39:48 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Thaller", "Hannes", ""], ["Linsbauer", "Lukas", ""], ["Ramler", "Rudolf", ""], ["Egyed", "Alexander", ""]]}, {"id": "1912.07938", "submitter": "Galit Shmueli", "authors": "Travis Greene and Galit Shmueli", "title": "How Personal is Machine Learning Personalization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though used extensively, the concept and process of machine learning (ML)\npersonalization have generally received little attention from academics,\npractitioners, and the general public. We describe the ML approach as relying\non the metaphor of the person as a feature vector and contrast this with\nhumanistic views of the person. In light of the recent calls by the IEEE to\nconsider the effects of ML on human well-being, we ask whether ML\npersonalization can be reconciled with these humanistic views of the person,\nwhich highlight the importance of moral and social identity. As human behavior\nincreasingly becomes digitized, analyzed, and predicted, to what extent do our\nsubsequent decisions about what to choose, buy, or do, made both by us and\nothers, reflect who we are as persons? This paper first explicates the term\npersonalization by considering ML personalization and highlights its relation\nto humanistic conceptions of the person, then proposes several dimensions for\nevaluating the degree of personalization of ML personalized scores. By doing\nso, we hope to contribute to current debate on the issues of algorithmic bias,\ntransparency, and fairness in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:37:19 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 03:39:46 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Greene", "Travis", ""], ["Shmueli", "Galit", ""]]}, {"id": "1912.07942", "submitter": "Santiago Zanella-Beguelin", "authors": "Marc Brockschmidt, Boris K\\\"opf, Olga Ohrimenko, Andrew Paverd, Victor\n  R\\\"uhle, Shruti Tople, Lukas Wutschitz, Santiago Zanella-B\\'eguelin", "title": "Analyzing Information Leakage of Updates to Natural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To continuously improve quality and reflect changes in data, machine learning\napplications have to regularly retrain and update their core models. We show\nthat a differential analysis of language model snapshots before and after an\nupdate can reveal a surprising amount of detailed information about changes in\nthe training data. We propose two new metrics---differential score and\ndifferential rank---for analyzing the leakage due to updates of natural\nlanguage models. We perform leakage analysis using these metrics across models\ntrained on several different datasets using different methods and\nconfigurations. We discuss the privacy implications of our findings, propose\nmitigation strategies and evaluate their effect.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:46:08 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 13:28:16 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:41:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Brockschmidt", "Marc", ""], ["K\u00f6pf", "Boris", ""], ["Ohrimenko", "Olga", ""], ["Paverd", "Andrew", ""], ["R\u00fchle", "Victor", ""], ["Tople", "Shruti", ""], ["Wutschitz", "Lukas", ""], ["Zanella-B\u00e9guelin", "Santiago", ""]]}, {"id": "1912.07943", "submitter": "Hazrat Ali", "authors": "Hazrat Ali, Ahsan Ullah, Talha Iqbal, Shahid Khattak", "title": "Pioneer dataset and automatic recognition of Urdu handwritten characters\n  using a deep autoencoder and convolutional neural network", "comments": "SN Applied Sciences, December 2019", "journal-ref": null, "doi": "10.1007/s42452-019-1914-1", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic recognition of Urdu handwritten digits and characters, is a\nchallenging task. It has applications in postal address reading, bank's cheque\nprocessing, and digitization and preservation of handwritten manuscripts from\nold ages. While there exists a significant work for automatic recognition of\nhandwritten English characters and other major languages of the world, the work\ndone for Urdu lan-guage is extremely insufficient. This paper has two goals.\nFirstly, we introduce a pioneer dataset for handwritten digits and characters\nof Urdu, containing samples from more than 900 individuals. Secondly, we report\nresults for automatic recog-nition of handwritten digits and characters as\nachieved by using deep auto-encoder network and convolutional neural network.\nMore specifically, we use a two-layer and a three-layer deep autoencoder\nnetwork and convolutional neural network and evaluate the two frameworks in\nterms of recognition accuracy. The proposed framework of deep autoencoder can\nsuccessfully recognize digits and characters with an accuracy of 97% for digits\nonly, 81% for characters only and 82% for both digits and characters\nsimultaneously. In comparison, the framework of convolutional neural network\nhas accuracy of 96.7% for digits only, 86.5% for characters only and 82.7% for\nboth digits and characters simultaneously. These frameworks can serve as\nbaselines for future research on Urdu handwritten text.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:49:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Ali", "Hazrat", ""], ["Ullah", "Ahsan", ""], ["Iqbal", "Talha", ""], ["Khattak", "Shahid", ""]]}, {"id": "1912.07946", "submitter": "Giuseppe Antonio Di Luna", "authors": "Fiorella Artuso, Giuseppe Antonio Di Luna, Luca Massarelli and\n  Leonardo Querzoni", "title": "In Nomine Function: Naming Functions in Stripped Binaries with Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the problem of automatically naming pieces of\nassembly code. Where by naming we mean assigning to an assembly function a\nstring of words that would likely be assigned by a human reverse engineer. We\nformally and precisely define the framework in which our investigation takes\nplace. That is we define the problem, we provide reasonable justifications for\nthe choices that we made for the design of training and the tests. We performed\nan analysis on a large real-world corpora constituted by nearly 9 millions of\nfunctions taken from more than 22k softwares. In such framework we test\nbaselines coming from the field of Natural Language Processing (e.g., Seq2Seq\nnetworks and Transformer). Interestingly, our evaluation shows promising\nresults beating the state-of-the-art and reaching good performance. We\ninvestigate the applicability of tine-tuning (i.e., taking a model already\ntrained on a large generic corpora and retraining it for a specific task). Such\ntechnique is popular and well-known in the NLP field. Our results confirm that\nfine-tuning is effective even when neural networks are applied to binaries. We\nshow that a model, pre-trained on the aforementioned corpora, when fine-tuned\nhas higher performances on specific domains (such as predicting names in system\nutilites, malware, etc).\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 11:59:41 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 16:17:59 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 09:31:56 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Artuso", "Fiorella", ""], ["Di Luna", "Giuseppe Antonio", ""], ["Massarelli", "Luca", ""], ["Querzoni", "Leonardo", ""]]}, {"id": "1912.07976", "submitter": "Heng Yang", "authors": "Heng Yang, Biqing Zeng, JianHao Yang, Youwei Song and Ruyang Xu", "title": "A Multi-task Learning Model for Chinese-oriented Aspect Polarity\n  Classification and Aspect Term Extraction", "comments": "Submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) task is a multi-grained task of\nnatural language processing and consists of two subtasks: aspect term\nextraction (ATE) and aspect polarity classification (APC). Most of the existing\nwork focuses on the subtask of aspect term polarity inferring and ignores the\nsignificance of aspect term extraction. Besides, the existing researches do not\npay attention to the research of the Chinese-oriented ABSA task. Based on the\nlocal context focus (LCF) mechanism, this paper firstly proposes a multi-task\nlearning model for Chinese-oriented aspect-based sentiment analysis, namely\nLCF-ATEPC. Compared with existing models, this model equips the capability of\nextracting aspect term and inferring aspect term polarity synchronously,\nmoreover, this model is effective to analyze both Chinese and English comments\nsimultaneously and the experiment on a multilingual mixed dataset proved its\navailability. By integrating the domain-adapted BERT model, the LCF-ATEPC model\nachieved the state-of-the-art performance of aspect term extraction and aspect\npolarity classification in four Chinese review datasets. Besides, the\nexperimental results on the most commonly used SemEval-2014 task4 Restaurant\nand Laptop datasets outperform the state-of-the-art performance on the ATE and\nAPC subtask.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 12:47:33 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 01:38:38 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 09:20:28 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yang", "Heng", ""], ["Zeng", "Biqing", ""], ["Yang", "JianHao", ""], ["Song", "Youwei", ""], ["Xu", "Ruyang", ""]]}, {"id": "1912.07991", "submitter": "Yatin Dandi", "authors": "Yatin Dandi, Aniket Das, Soumye Singhal, Vinay P. Namboodiri, Piyush\n  Rai", "title": "Jointly Trained Image and Video Generation using Residual Vectors", "comments": "Accepted in 2020 Winter Conference on Applications of Computer Vision\n  (WACV '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a modeling technique for jointly training image and\nvideo generation models by simultaneously learning to map latent variables with\na fixed prior onto real images and interpolate over images to generate videos.\nThe proposed approach models the variations in representations using residual\nvectors encoding the change at each time step over a summary vector for the\nentire video. We utilize the technique to jointly train an image generation\nmodel with a fixed prior along with a video generation model lacking\nconstraints such as disentanglement. The joint training enables the image\ngenerator to exploit temporal information while the video generation model\nlearns to flexibly share information across frames. Moreover, experimental\nresults verify our approach's compatibility with pre-training on videos or\nimages and training on datasets containing a mixture of both. A comprehensive\nset of quantitative and qualitative evaluations reveal the improvements in\nsample quality and diversity over both video generation and image generation\nbaselines. We further demonstrate the technique's capabilities of exploiting\nsimilarity in features across frames by applying it to a model based on\ndecomposing the video into motion and content. The proposed model allows minor\nvariations in content across frames while maintaining the temporal dependence\nthrough latent vectors encoding the pose or motion features.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:14:17 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Dandi", "Yatin", ""], ["Das", "Aniket", ""], ["Singhal", "Soumye", ""], ["Namboodiri", "Vinay P.", ""], ["Rai", "Piyush", ""]]}, {"id": "1912.07999", "submitter": "No\\\"elie Cherrier", "authors": "No\\\"elie Cherrier, Maxime Defurne, Jean-Philippe Poli and Franck\n  Sabati\\'e", "title": "Embedded Constrained Feature Construction for High-Energy Physics Data\n  Classification", "comments": "Accepted at the NeurIPS 2019 workshop on Machine Learning for the\n  Physical Sciences (https://ml4physicalsciences.github.io)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before any publication, data analysis of high-energy physics experiments must\nbe validated. This validation is granted only if a perfect understanding of the\ndata and the analysis process is demonstrated. Therefore, physicists prefer\nusing transparent machine learning algorithms whose performances highly rely on\nthe suitability of the provided input features. To transform the feature space,\nfeature construction aims at automatically generating new relevant features.\nWhereas most of previous works in this area perform the feature construction\nprior to the model training, we propose here a general framework to embed a\nfeature construction technique adapted to the constraints of high-energy\nphysics in the induction of tree-based models. Experiments on two high-energy\nphysics datasets confirm that a significant gain is obtained on the\nclassification scores, while limiting the number of built features. Since the\nfeatures are built to be interpretable, the whole model is transparent and\nreadable.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:30:11 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Cherrier", "No\u00eblie", ""], ["Defurne", "Maxime", ""], ["Poli", "Jean-Philippe", ""], ["Sabati\u00e9", "Franck", ""]]}, {"id": "1912.08001", "submitter": "No\\\"elie Cherrier", "authors": "Marouen Baalouch, Maxime Defurne, Jean-Philippe Poli and No\\\"elie\n  Cherrier", "title": "Sim-to-Real Domain Adaptation For High Energy Physics", "comments": "Accepted at the NeurIPS 2019 workshop on Machine Learning for the\n  Physical Sciences (https://ml4physicalsciences.github.io)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle physics or High Energy Physics (HEP) studies the elementary\nconstituents of matter and their interactions with each other. Machine Learning\n(ML) has played an important role in HEP analysis and has proven extremely\nsuccessful in this area. Usually, the ML algorithms are trained on numerical\nsimulations of the experimental setup and then applied to the real experimental\ndata. However, any discrepancy between the simulation and real data may lead to\ndramatic consequences concerning the performances of the algorithm on real\ndata. In this paper, we present an application of domain adaptation using a\nDomain Adversarial Neural Network trained on public HEP data. We demonstrate\nthe success of this approach to achieve sim-to-real transfer and ensure the\nconsistency of the ML algorithms performances on real and simulated HEP\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:37:32 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Baalouch", "Marouen", ""], ["Defurne", "Maxime", ""], ["Poli", "Jean-Philippe", ""], ["Cherrier", "No\u00eblie", ""]]}, {"id": "1912.08011", "submitter": "Xin Feng", "authors": "Xin Feng and Lei Wang", "title": "Application of Word2vec in Phoneme Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present how to hybridize a Word2vec model and an\nattention-based end-to-end speech recognition model. We build a phoneme\nrecognition system based on Listen, Attend and Spell model. And the phoneme\nrecognition model uses a word2vec model to initialize the embedding matrix for\nthe improvement of the performance, which can increase the distance among the\nphoneme vectors. At the same time, in order to solve the problem of overfitting\nin the 61 phoneme recognition model on TIMIT dataset, we propose a new training\nmethod. A 61-39 phoneme mapping comparison table is used to inverse map the\nphonemes of the dataset to generate more 61 phoneme training data. At the end\nof training, replace the dataset with a standard dataset for corrective\ntraining. Our model can achieve the best result under the TIMIT dataset which\nis 16.5% PER (Phoneme Error Rate).\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:45:13 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 12:40:45 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Feng", "Xin", ""], ["Wang", "Lei", ""]]}, {"id": "1912.08041", "submitter": "Xavier Amatriain", "authors": "Anitha Kannan, Jason Alan Fries, Eric Kramer, Jen Jen Chen, Nigam\n  Shah, Xavier Amatriain", "title": "The accuracy vs. coverage trade-off in patient-facing diagnosis models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A third of adults in America use the Internet to diagnose medical concerns,\nand online symptom checkers are increasingly part of this process. These tools\nare powered by diagnosis models similar to clinical decision support systems,\nwith the primary difference being the coverage of symptoms and diagnoses. To be\nuseful to patients and physicians, these models must have high accuracy while\ncovering a meaningful space of symptoms and diagnoses. To the best of our\nknowledge, this paper is the first in studying the trade-off between the\ncoverage of the model and its performance for diagnosis. To this end, we learn\ndiagnosis models with different coverage from EHR data. We find a 1\\% drop in\ntop-3 accuracy for every 10 diseases added to the coverage. We also observe\nthat complexity for these models does not affect performance, with linear\nmodels performing as well as neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 08:27:18 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Kannan", "Anitha", ""], ["Fries", "Jason Alan", ""], ["Kramer", "Eric", ""], ["Chen", "Jen Jen", ""], ["Shah", "Nigam", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1912.08055", "submitter": "Heramb Nemlekar", "authors": "Yifang Chen, Alex Cuellar, Haipeng Luo, Jignesh Modi, Heramb Nemlekar\n  and Stefanos Nikolaidis", "title": "Fair Contextual Multi-Armed Bandits: Theory and Experiments", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an AI system interacts with multiple users, it frequently needs to make\nallocation decisions. For instance, a virtual agent decides whom to pay\nattention to in a group setting, or a factory robot selects a worker to deliver\na part. Demonstrating fairness in decision making is essential for such systems\nto be broadly accepted. We introduce a Multi-Armed Bandit algorithm with\nfairness constraints, where fairness is defined as a minimum rate that a task\nor a resource is assigned to a user. The proposed algorithm uses contextual\ninformation about the users and the task and makes no assumptions on how the\nlosses capturing the performance of different users are generated. We provide\ntheoretical guarantees of performance and empirical results from simulation and\nan online user study. The results highlight the benefit of accounting for\ncontexts in fair decision making, especially when users perform better at some\ncontexts and worse at others.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:25:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Chen", "Yifang", ""], ["Cuellar", "Alex", ""], ["Luo", "Haipeng", ""], ["Modi", "Jignesh", ""], ["Nemlekar", "Heramb", ""], ["Nikolaidis", "Stefanos", ""]]}, {"id": "1912.08061", "submitter": "Gourav Modanwal", "authors": "Gourav Modanwal, Adithya Vellal, Maciej A. Mazurowski", "title": "Normalization of breast MRIs using Cycle-Consistent Generative\n  Adversarial Networks", "comments": "Final accepted draft in Computer Methods and Programs in Biomedicine", "journal-ref": "Computer Methods and Programs in Biomedicine, 2021", "doi": "10.1016/j.cmpb.2021.106225", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) is widely used\nto complement ultrasound examinations and x-ray mammography during the early\ndetection and diagnosis of breast cancer. However, images generated by various\nMRI scanners (e.g. GE Healthcare vs Siemens) differ both in intensity and noise\ndistribution, preventing algorithms trained on MRIs from one scanner to\ngeneralize to data from other scanners successfully. We propose a method for\nimage normalization to solve this problem. MRI normalization is challenging\nbecause it requires both normalizing intensity values and mapping between the\nnoise distributions of different scanners. We utilize a cycle-consistent\ngenerative adversarial network to learn a bidirectional mapping between MRIs\nproduced by GE Healthcare and Siemens scanners. This allows us learning the\nmapping between two different scanner types without matched data, which is not\ncommonly available. To ensure the preservation of breast shape and structures\nwithin the breast, we propose two technical innovations. First, we incorporate\na mutual information loss with the CycleGAN architecture to ensure that the\nstructure of the breast is maintained. Second, we propose a modified\ndiscriminator architecture which utilizes a smaller field-of-view to ensure the\npreservation of finer details in the breast tissue. Quantitative and\nqualitative evaluations show that the second proposed method was able to\nconsistently preserve a high level of detail in the breast structure while also\nperforming the proper intensity normalization and noise mapping. Our results\ndemonstrate that the proposed model can successfully learn a bidirectional\nmapping between MRIs produced by different vendors, potentially enabling\nimproved accuracy of downstream computational algorithms for diagnosis and\ndetection of breast cancer. All the data used in this study are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 16:04:29 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 15:58:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Modanwal", "Gourav", ""], ["Vellal", "Adithya", ""], ["Mazurowski", "Maciej A.", ""]]}, {"id": "1912.08084", "submitter": "Preslav Nakov", "authors": "Pepa Gencheva, Ivan Koychev, Llu\\'is M\\`arquez, Alberto\n  Barr\\'on-Cede\\~no, Preslav Nakov", "title": "A Context-Aware Approach for Detecting Check-Worthy Claims in Political\n  Debates", "comments": "Check-worthiness; Fact-Checking; Veracity; Neural Networks. arXiv\n  admin note: substantial text overlap with arXiv:1908.01328", "journal-ref": "RANLP-2017", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of investigative journalism, we address the problem of\nautomatically identifying which claims in a given document are most worthy and\nshould be prioritized for fact-checking. Despite its importance, this is a\nrelatively understudied problem. Thus, we create a new dataset of political\ndebates, containing statements that have been fact-checked by nine reputable\nsources, and we train machine learning models to predict which claims should be\nprioritized for fact-checking, i.e., we model the problem as a ranking task.\nUnlike previous work, which has looked primarily at sentences in isolation, in\nthis paper we focus on a rich input representation modeling the context:\nrelationship between the target statement and the larger context of the debate,\ninteraction between the opponents, and reaction by the moderator and by the\npublic. Our experiments show state-of-the-art results, outperforming a strong\nrivaling system by a margin, while also confirming the importance of the\ncontextual information.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 10:29:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Gencheva", "Pepa", ""], ["Koychev", "Ivan", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "1912.08103", "submitter": "Rodrigo A. Gonz\\'alez", "authors": "Rodrigo A. Gonz\\'alez and Cristian R. Rojas", "title": "A Finite-Sample Deviation Bound for Stable Autoregressive Processes", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study non-asymptotic deviation bounds of the least squares\nestimator in Gaussian AR($n$) processes. By relying on martingale concentration\ninequalities and a tail-bound for $\\chi^2$ distributed variables, we provide a\nconcentration bound for the sample covariance matrix of the process output.\nWith this, we present a problem-dependent finite-time bound on the deviation\nprobability of any fixed linear combination of the estimated parameters of the\nAR$(n)$ process. We discuss extensions and limitations of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 15:55:54 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:06:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Gonz\u00e1lez", "Rodrigo A.", ""], ["Rojas", "Cristian R.", ""]]}, {"id": "1912.08111", "submitter": "Geunseob Oh", "authors": "Geunseob Oh, Jean-Sebastien Valois", "title": "HCNAF: Hyper-Conditioned Neural Autoregressive Flow and its Application\n  for Probabilistic Occupancy Map Forecasting", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Hyper-Conditioned Neural Autoregressive Flow (HCNAF); a powerful\nuniversal distribution approximator designed to model arbitrarily complex\nconditional probability density functions. HCNAF consists of a neural-net based\nconditional autoregressive flow (AF) and a hyper-network that can take large\nconditions in non-autoregressive fashion and outputs the network parameters of\nthe AF. Like other flow models, HCNAF performs exact likelihood inference. We\nconduct a number of density estimation tasks on toy experiments and MNIST to\ndemonstrate the effectiveness and attributes of HCNAF, including its\ngeneralization capability over unseen conditions and expressivity. Finally, we\nshow that HCNAF scales up to complex high-dimensional prediction problems of\nthe magnitude of self-driving and that HCNAF yields a state-of-the-art\nperformance in a public self-driving dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 16:07:55 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 03:43:07 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 03:58:24 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Oh", "Geunseob", ""], ["Valois", "Jean-Sebastien", ""]]}, {"id": "1912.08112", "submitter": "Sriram Sankaranarayanan", "authors": "Yoshua Bengio, Emma Frejinger, Andrea Lodi, Rahul Patel, Sriram\n  Sankaranarayanan", "title": "A learning-based algorithm to quickly compute good primal solutions for\n  Stochastic Integer Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach using supervised learning to obtain near-optimal\nprimal solutions for two-stage stochastic integer programming (2SIP) problems\nwith constraints in the first and second stages. The goal of the algorithm is\nto predict a \"representative scenario\" (RS) for the problem such that,\ndeterministically solving the 2SIP with the random realization equal to the RS,\ngives a near-optimal solution to the original 2SIP. Predicting an RS, instead\nof directly predicting a solution ensures first-stage feasibility of the\nsolution. If the problem is known to have complete recourse, second-stage\nfeasibility is also guaranteed. For computational testing, we learn to find an\nRS for a two-stage stochastic facility location problem with integer variables\nand linear constraints in both stages and consistently provide near-optimal\nsolutions. Our computing times are very competitive with those of\ngeneral-purpose integer programming solvers to achieve a similar solution\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 16:09:54 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Bengio", "Yoshua", ""], ["Frejinger", "Emma", ""], ["Lodi", "Andrea", ""], ["Patel", "Rahul", ""], ["Sankaranarayanan", "Sriram", ""]]}, {"id": "1912.08113", "submitter": "Rushil Anirudh", "authors": "Rushil Anirudh, Jayaraman J. Thiagarajan, Peer-Timo Bremer, Brian K.\n  Spears", "title": "Improved Surrogates in Inertial Confinement Fusion with Manifold and\n  Cycle Consistencies", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become very popular in surrogate modeling because of\ntheir ability to characterize arbitrary, high dimensional functions in a data\ndriven fashion. This paper advocates for the training of surrogates that are\nconsistent with the physical manifold -- i.e., predictions are always\nphysically meaningful, and are cyclically consistent -- i.e., when the\npredictions of the surrogate, when passed through an independently trained\ninverse model give back the original input parameters. We find that these two\nconsistencies lead to surrogates that are superior in terms of predictive\nperformance, more resilient to sampling artifacts, and tend to be more data\nefficient. Using Inertial Confinement Fusion (ICF) as a test bed problem, we\nmodel a 1D semi-analytic numerical simulator and demonstrate the effectiveness\nof our approach. Code and data are available at\nhttps://github.com/rushilanirudh/macc/\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 16:14:43 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Bremer", "Peer-Timo", ""], ["Spears", "Brian K.", ""]]}, {"id": "1912.08124", "submitter": "Luca Manneschi", "authors": "Luca Manneschi, Andrew C. Lin, Eleni Vasilaki", "title": "SpaRCe: Improved Learning of Reservoir Computing Systems through Sparse\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Sparse\" neural networks, in which relatively few neurons or connections are\nactive, are common in both machine learning and neuroscience. Whereas in\nmachine learning, \"sparsity\" is related to a penalty term that leads to some\nconnecting weights becoming small or zero, in biological brains, sparsity is\noften created when high spiking thresholds prevent neuronal activity. Here we\nintroduce sparsity into a reservoir computing network via neuron-specific\nlearnable thresholds of activity, allowing neurons with low thresholds to\ncontribute to decision-making but suppressing information from neurons with\nhigh thresholds. This approach, which we term \"SpaRCe\", optimises the sparsity\nlevel of the reservoir without affecting the reservoir dynamics. The read-out\nweights and the thresholds are learned by an on-line gradient rule that\nminimises an error function on the outputs of the network. Threshold learning\noccurs by the balance of two opposing forces: reducing inter-neuronal\ncorrelations in the reservoir by deactivating redundant neurons, while\nincreasing the activity of neurons participating in correct decisions. We test\nSpaRCe on classification problems and find that threshold learning improves\nperformance compared to standard reservoir computing. SpaRCe alleviates the\nproblem of catastrophic forgetting, a problem most evident in standard echo\nstate networks and recurrent neural networks in general, due to increasing the\nnumber of task-specialised neurons that are included in the network decisions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:05:26 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 17:51:11 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 16:25:07 GMT"}, {"version": "v4", "created": "Sun, 18 Apr 2021 05:26:54 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Manneschi", "Luca", ""], ["Lin", "Andrew C.", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "1912.08136", "submitter": "Yan Luo", "authors": "Yan Luo, Yongkang Wong, Mohan S. Kankanhalli, and Qi Zhao", "title": "Direction Concentration Learning: Enhancing Congruency in Machine\n  Learning", "comments": "This is a preprint and the formal version has been published in TPAMI", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2019", "doi": "10.1109/TPAMI.2019.2963387", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the well-known challenges in computer vision tasks is the visual\ndiversity of images, which could result in an agreement or disagreement between\nthe learned knowledge and the visual content exhibited by the current\nobservation. In this work, we first define such an agreement in a concepts\nlearning process as congruency. Formally, given a particular task and\nsufficiently large dataset, the congruency issue occurs in the learning process\nwhereby the task-specific semantics in the training data are highly varying. We\npropose a Direction Concentration Learning (DCL) method to improve congruency\nin the learning process, where enhancing congruency influences the convergence\npath to be less circuitous. The experimental results show that the proposed DCL\nmethod generalizes to state-of-the-art models and optimizers, as well as\nimproves the performances of saliency prediction task, continual learning task,\nand classification task. Moreover, it helps mitigate the catastrophic\nforgetting problem in the continual learning task. The code is publicly\navailable at https://github.com/luoyan407/congruency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 16:58:04 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 01:28:05 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Luo", "Yan", ""], ["Wong", "Yongkang", ""], ["Kankanhalli", "Mohan S.", ""], ["Zhao", "Qi", ""]]}, {"id": "1912.08140", "submitter": "Yashaswi Verma", "authors": "Yashaswi Verma", "title": "An Embarrassingly Simple Baseline for eXtreme Multi-label Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of eXtreme Multi-label Learning (XML) is to design and learn a model\nthat can automatically annotate a given data point with the most relevant\nsubset of labels from an extremely large label set. Recently, many techniques\nhave been proposed for XML that achieve reasonable performance on benchmark\ndatasets. Motivated by the complexities of these methods and their subsequent\ntraining requirements, in this paper we propose a simple baseline technique for\nthis task. Precisely, we present a global feature embedding technique for XML\nthat can easily scale to very large datasets containing millions of data points\nin very high-dimensional feature space, irrespective of number of samples and\nlabels. Next we show how an ensemble of such global embeddings can be used to\nachieve further boost in prediction accuracies with only linear increase in\ntraining and prediction time. During testing, we assign the labels using a\nweighted k-nearest neighbour classifier in the embedding space. Experiments\nreveal that though conceptually simple, this technique achieves quite\ncompetitive results, and has training time of less than one minute using a\nsingle CPU core with 15.6 GB RAM even for large-scale datasets such as\nAmazon-3M.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:11:17 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Verma", "Yashaswi", ""]]}, {"id": "1912.08141", "submitter": "Martin Engqvist", "authors": "Gang Li, Jan Zrimec, Boyang Ji, Jun Geng, Johan Larsbrink, Aleksej\n  Zelezniak, Jens Nielsen, and Martin KM Engqvist", "title": "Performance of regression models as a function of experiment noise", "comments": null, "journal-ref": "Bioinformatics and Biology Insights. January 2021", "doi": "10.1177/11779322211020315", "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A challenge in developing machine learning regression models is that it is\ndifficult to know whether maximal performance has been reached on a particular\ndataset, or whether further model improvement is possible. In biology this\nproblem is particularly pronounced as sample labels (response variables) are\ntypically obtained through experiments and therefore have experiment noise\nassociated with them. Such label noise puts a fundamental limit to the\nperformance attainable by regression models. We address this challenge by\nderiving a theoretical upper bound for the coefficient of determination (R2)\nfor regression models. This theoretical upper bound depends only on the noise\nassociated with the response variable in a dataset as well as its variance. The\nupper bound estimate was validated via Monte Carlo simulations and then used as\na tool to bootstrap performance of regression models trained on biological\ndatasets, including protein sequence data, transcriptomic data, and genomic\ndata. Although we study biological datasets in this work, the new upper bound\nestimates will hold true for regression models from any research field or\napplication area where response variables have associated noise.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:13:18 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 11:12:48 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 12:08:32 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Li", "Gang", ""], ["Zrimec", "Jan", ""], ["Ji", "Boyang", ""], ["Geng", "Jun", ""], ["Larsbrink", "Johan", ""], ["Zelezniak", "Aleksej", ""], ["Nielsen", "Jens", ""], ["Engqvist", "Martin KM", ""]]}, {"id": "1912.08142", "submitter": "Daniel C. Castro", "authors": "Daniel C. Castro, Ian Walker, Ben Glocker", "title": "Causality matters in medical imaging", "comments": "20 pages, 5 figures, 4 tables", "journal-ref": "Nature Communications 11 (2020) 3673", "doi": "10.1038/s41467-020-17478-w", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses how the language of causality can shed new light on\nthe major challenges in machine learning for medical imaging: 1) data scarcity,\nwhich is the limited availability of high-quality annotations, and 2) data\nmismatch, whereby a trained algorithm may fail to generalize in clinical\npractice. Looking at these challenges through the lens of causality allows\ndecisions about data collection, annotation procedures, and learning strategies\nto be made (and scrutinized) more transparently. We discuss how causal\nrelationships between images and annotations can not only have profound effects\non the performance of predictive models, but may even dictate which learning\nstrategies should be considered in the first place. For example, we conclude\nthat semi-supervision may be unsuitable for image segmentation---one of the\npossibly surprising insights from our causal analysis, which is illustrated\nwith representative real-world examples of computer-aided diagnosis (skin\nlesion classification in dermatology) and radiotherapy (automated contouring of\ntumours). We highlight that being aware of and accounting for the causal\nrelationships in medical imaging data is important for the safe development of\nmachine learning and essential for regulation and responsible reporting. To\nfacilitate this we provide step-by-step recommendations for future studies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:15:02 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Castro", "Daniel C.", ""], ["Walker", "Ian", ""], ["Glocker", "Ben", ""]]}, {"id": "1912.08165", "submitter": "Julien Mairal", "authors": "Julien Mairal", "title": "Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for\n  Python, C++, and soon more", "comments": "http://julien.mairal.org/cyanure/welcome.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyanure is an open-source C++ software package with a Python interface. The\ngoal of Cyanure is to provide state-of-the-art solvers for learning linear\nmodels, based on stochastic variance-reduced stochastic optimization with\nacceleration mechanisms. Cyanure can handle a large variety of loss functions\n(logistic, square, squared hinge, multinomial logistic) and regularization\nfunctions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It\nprovides a simple Python API, which is very close to that of scikit-learn,\nwhich should be extended to other languages such as R or Matlab in a near\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:04:31 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 08:07:05 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mairal", "Julien", ""]]}, {"id": "1912.08177", "submitter": "Elizabeth Qian", "authors": "Elizabeth Qian, Boris Kramer, Benjamin Peherstorfer, Karen Willcox", "title": "Lift & Learn: Physics-informed machine learning for large-scale\n  nonlinear dynamical systems", "comments": null, "journal-ref": "Physica D: Nonlinear Phenomena, Volume 406, p. 132401, 2020", "doi": "10.1016/j.physd.2020.132401", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Lift & Learn, a physics-informed method for learning\nlow-dimensional models for large-scale dynamical systems. The method exploits\nknowledge of a system's governing equations to identify a coordinate\ntransformation in which the system dynamics have quadratic structure. This\ntransformation is called a lifting map because it often adds auxiliary\nvariables to the system state. The lifting map is applied to data obtained by\nevaluating a model for the original nonlinear system. This lifted data is\nprojected onto its leading principal components, and low-dimensional linear and\nquadratic matrix operators are fit to the lifted reduced data using a\nleast-squares operator inference procedure. Analysis of our method shows that\nthe Lift & Learn models are able to capture the system physics in the lifted\ncoordinates at least as accurately as traditional intrusive model reduction\napproaches. This preservation of system physics makes the Lift & Learn models\nrobust to changes in inputs. Numerical experiments on the FitzHugh-Nagumo\nneuron activation model and the compressible Euler equations demonstrate the\ngeneralizability of our model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:29:31 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 22:04:56 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 14:55:26 GMT"}, {"version": "v4", "created": "Fri, 6 Mar 2020 19:29:09 GMT"}, {"version": "v5", "created": "Thu, 26 Mar 2020 15:50:07 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Qian", "Elizabeth", ""], ["Kramer", "Boris", ""], ["Peherstorfer", "Benjamin", ""], ["Willcox", "Karen", ""]]}, {"id": "1912.08180", "submitter": "Arindam Bose", "authors": "Shahin Khobahi and Arindam Bose and Mojtaba Soltanalian", "title": "Deep Radar Waveform Design for Efficient Automotive Radar Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In radar systems, unimodular (or constant-modulus) waveform design plays an\nimportant role in achieving better clutter/interference rejection, as well as a\nmore accurate estimation of the target parameters. The design of such sequences\nhas been studied widely in the last few decades, with most design algorithms\nrequiring sophisticated a priori knowledge of environmental parameters which\nmay be difficult to obtain in real-time scenarios. In this paper, we propose a\nnovel hybrid model-driven and data-driven architecture that adapts to the ever\nchanging environment and allows for adaptive unimodular waveform design. In\nparticular, the approach lays the groundwork for developing extremely low-cost\nwaveform design and processing frameworks for radar systems deployed in\nautonomous vehicles. The proposed model-based deep architecture imitates a\nwell-known unimodular signal design algorithm in its structure, and can quickly\ninfer statistical information from the environment using the observed data. Our\nnumerical experiments portray the advantages of using the proposed method for\nefficient radar waveform design in time-varying environments.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:39:39 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:23:30 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Khobahi", "Shahin", ""], ["Bose", "Arindam", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "1912.08189", "submitter": "Przemyslaw Grabowicz", "authors": "Przemyslaw A. Grabowicz, Nicholas Perello, Kenta Takatsu", "title": "Resilience of Supervised Learning Algorithms to Discriminatory Data\n  Perturbations", "comments": "17 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination is a focal concern in supervised learning algorithms\naugmenting human decision-making. These systems are trained using historical\ndata, which may have been tainted by discrimination, and may learn biases\nagainst the protected groups. An important question is how to train models\nwithout propagating discrimination. In this study, we i) define and model\ndiscrimination as perturbations of a data-generating process and show how\ndiscrimination can be induced via attributes correlated with the protected\nattributes; ii) introduce a measure of resilience of a supervised learning\nalgorithm to potentially discriminatory data perturbations, iii) propose a\nnovel supervised learning algorithm that inhibits discrimination, and iv) show\nthat it is more resilient to discriminatory perturbations in synthetic and\nreal-world datasets than state-of-the-art learning algorithms. The proposed\nmethod can be used with general supervised learning algorithms and avoids\ninducement of discrimination, while maximizing model accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:53:23 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:50:51 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 02:40:29 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Grabowicz", "Przemyslaw A.", ""], ["Perello", "Nicholas", ""], ["Takatsu", "Kenta", ""]]}, {"id": "1912.08195", "submitter": "Luca Weihs", "authors": "Luca Weihs, Aniruddha Kembhavi, Kiana Ehsani, Sarah M Pratt, Winson\n  Han, Alvaro Herrasti, Eric Kolve, Dustin Schwenk, Roozbeh Mottaghi, Ali\n  Farhadi", "title": "Learning Generalizable Visual Representations via Interactive Gameplay", "comments": "Replaced with version accepted to ICLR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of research suggests that embodied gameplay, prevalent not\njust in human cultures but across a variety of animal species including turtles\nand ravens, is critical in developing the neural flexibility for creative\nproblem solving, decision making, and socialization. Comparatively little is\nknown regarding the impact of embodied gameplay upon artificial agents. While\nrecent work has produced agents proficient in abstract games, these\nenvironments are far removed from the real world and thus these agents can\nprovide little insight into the advantages of embodied play. Hiding games, such\nas hide-and-seek, played universally, provide a rich ground for studying the\nimpact of embodied gameplay on representation learning in the context of\nperspective taking, secret keeping, and false belief understanding. Here we are\nthe first to show that embodied adversarial reinforcement learning agents\nplaying Cache, a variant of hide-and-seek, in a high fidelity, interactive,\nenvironment, learn generalizable representations of their observations encoding\ninformation such as object permanence, free space, and containment. Moving\ncloser to biologically motivated learning strategies, our agents'\nrepresentations, enhanced by intentionality and memory, are developed through\ninteraction and play. These results serve as a model for studying how facets of\nvision develop through interaction, provide an experimental framework for\nassessing what is learned by artificial agents, and demonstrates the value of\nmoving from large, static, datasets towards experiential, interactive,\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:57:50 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 17:45:41 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 17:51:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Weihs", "Luca", ""], ["Kembhavi", "Aniruddha", ""], ["Ehsani", "Kiana", ""], ["Pratt", "Sarah M", ""], ["Han", "Winson", ""], ["Herrasti", "Alvaro", ""], ["Kolve", "Eric", ""], ["Schwenk", "Dustin", ""], ["Mottaghi", "Roozbeh", ""], ["Farhadi", "Ali", ""]]}, {"id": "1912.08198", "submitter": "Alexander Hayes", "authors": "Alexander L. Hayes", "title": "srlearn: A Python Library for Gradient-Boosted Statistical Relational\n  Models", "comments": "Ninth International Workshop on Statistical Relational AI (StarAI\n  2020). Software online at https://github.com/hayesall/srlearn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present srlearn, a Python library for boosted statistical relational\nmodels. We adapt the scikit-learn interface to this setting and provide\nexamples for how this can be used to express learning and inference problems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 20:46:32 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Hayes", "Alexander L.", ""]]}, {"id": "1912.08202", "submitter": "Hwiyoung Lee", "authors": "Hwiyoung Lee, Vic Patrangenaru", "title": "Extrinsic Kernel Ridge Regression Classifier for Planar Kendall Shape\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have had great success in Statistics and Machine Learning.\nDespite their growing popularity, however, less effort has been drawn towards\ndeveloping kernel based classification methods on Riemannian manifolds due to\ndifficulty in dealing with non-Euclidean geometry. In this paper, motivated by\nthe extrinsic framework of manifold-valued data analysis, we propose a new\npositive definite kernel on planar Kendall shape space $\\Sigma_2^k$, called\nextrinsic Veronese Whitney Gaussian kernel. We show that our approach can be\nextended to develop Gaussian kernels on any embedded manifold. Furthermore,\nkernel ridge regression classifier (KRRC) is implemented to address the shape\nclassification problem on $\\Sigma_2^k$, and their promising performances are\nillustrated through the real data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:33:58 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 06:12:27 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Lee", "Hwiyoung", ""], ["Patrangenaru", "Vic", ""]]}, {"id": "1912.08263", "submitter": "Tobias Feigl", "authors": "Felix Ott, Tobias Feigl, Christoffer L\\\"offler, and Christopher\n  Mutschler", "title": "ViPR: Visual-Odometry-aided Pose Regression for 6DoF Camera Localization", "comments": "Conf. on Computer Vision and Pattern Recognition (CVPR): Joint\n  Workshop on Long-Term Visual Localization, Visual Odometry and Geometric and\n  Learning-based SLAM 2020", "journal-ref": null, "doi": "10.1109/CVPRW50498.2020.00029", "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Odometry (VO) accumulates a positional drift in long-term robot\nnavigation tasks. Although Convolutional Neural Networks (CNNs) improve VO in\nvarious aspects, VO still suffers from moving obstacles, discontinuous\nobservation of features, and poor textures or visual information. While recent\napproaches estimate a 6DoF pose either directly from (a series of) images or by\nmerging depth maps with optical flow (OF), research that combines absolute pose\nregression with OF is limited. We propose ViPR, a novel modular architecture\nfor long-term 6DoF VO that leverages temporal information and synergies between\nabsolute pose estimates (from PoseNet-like modules) and relative pose estimates\n(from FlowNet-based modules) by combining both through recurrent layers.\nExperiments on known datasets and on our own Industry dataset show that our\nmodular design outperforms state of the art in long-term navigation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 20:29:15 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 09:25:10 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 15:20:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ott", "Felix", ""], ["Feigl", "Tobias", ""], ["L\u00f6ffler", "Christoffer", ""], ["Mutschler", "Christopher", ""]]}, {"id": "1912.08275", "submitter": "Ujjal Kr Dutta", "authors": "Ujjal Kr Dutta, Mehrtash Harandi, Chandra Sekhar Chellu", "title": "A Probabilistic approach for Learning Embeddings without Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For challenging machine learning problems such as zero-shot learning and\nfine-grained categorization, embedding learning is the machinery of choice\nbecause of its ability to learn generic notions of similarity, as opposed to\nclass-specific concepts in standard classification models. Embedding learning\naims at learning discriminative representations of data such that similar\nexamples are pulled closer, while pushing away dissimilar ones. Despite their\nexemplary performances, supervised embedding learning approaches require huge\nnumber of annotations for training. This restricts their applicability for\nlarge datasets in new applications where obtaining labels require extensive\nmanual efforts and domain knowledge. In this paper, we propose to learn an\nembedding in a completely unsupervised manner without using any class labels.\nUsing a graph-based clustering approach to obtain pseudo-labels, we form\ntriplet-based constraints following a metric learning paradigm. Our novel\nembedding learning approach uses a probabilistic notion, that intuitively\nminimizes the chances of each triplet violating a geometric constraint. Due to\nnature of the search space, we learn the parameters of our approach using\nRiemannian geometry. Our proposed approach performs competitive to\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:14:08 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Dutta", "Ujjal Kr", ""], ["Harandi", "Mehrtash", ""], ["Chellu", "Chandra Sekhar", ""]]}, {"id": "1912.08278", "submitter": "Andrea Mari", "authors": "Andrea Mari, Thomas R. Bromley, Josh Izaac, Maria Schuld, Nathan\n  Killoran", "title": "Transfer learning in hybrid classical-quantum neural networks", "comments": "Accepted in Quantum. Code available at:\n  https://github.com/XanaduAI/quantum-transfer-learning", "journal-ref": "Quantum 4, 340 (2020)", "doi": "10.22331/q-2020-10-09-340", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We extend the concept of transfer learning, widely applied in modern machine\nlearning algorithms, to the emerging context of hybrid neural networks composed\nof classical and quantum elements. We propose different implementations of\nhybrid transfer learning, but we focus mainly on the paradigm in which a\npre-trained classical network is modified and augmented by a final variational\nquantum circuit. This approach is particularly attractive in the current era of\nintermediate-scale quantum technology since it allows to optimally pre-process\nhigh dimensional data (e.g., images) with any state-of-the-art classical\nnetwork and to embed a select set of highly informative features into a quantum\nprocessor. We present several proof-of-concept examples of the convenient\napplication of quantum transfer learning for image recognition and quantum\nstate classification. We use the cross-platform software library PennyLane to\nexperimentally test a high-resolution image classifier with two different\nquantum computers, respectively provided by IBM and Rigetti.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:24:54 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 09:35:45 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Mari", "Andrea", ""], ["Bromley", "Thomas R.", ""], ["Izaac", "Josh", ""], ["Schuld", "Maria", ""], ["Killoran", "Nathan", ""]]}, {"id": "1912.08281", "submitter": "Kimmo K\\\"arkk\\\"ainen", "authors": "Kimmo K\\\"arkk\\\"ainen, Mohammad Kachuee, Orpaz Goldstein, Majid\n  Sarrafzadeh", "title": "Cost-Sensitive Feature-Value Acquisition Using Feature Relevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world machine learning problems, feature values are not readily\navailable. To make predictions, some of the missing features have to be\nacquired, which can incur a cost in money, computational time, or human time,\ndepending on the problem domain. This leads us to the problem of choosing which\nfeatures to use at the prediction time. The chosen features should increase the\nprediction accuracy for a low cost, but determining which features will do that\nis challenging. The choice should take into account the previously acquired\nfeature values as well as the feature costs. This paper proposes a novel\napproach to address this problem. The proposed approach chooses the most useful\nfeatures adaptively based on how relevant they are for the prediction task as\nwell as what the corresponding feature costs are. Our approach uses a generic\nneural network architecture, which is suitable for a wide range of problems. We\nevaluate our approach on three cost-sensitive datasets, including Yahoo!\nLearning to Rank Competition dataset as well as two health datasets. We show\nthat our approach achieves high accuracy with a lower cost than the current\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:34:36 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 01:32:21 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["K\u00e4rkk\u00e4inen", "Kimmo", ""], ["Kachuee", "Mohammad", ""], ["Goldstein", "Orpaz", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1912.08286", "submitter": "Brady Neal", "authors": "Brady Neal", "title": "On the Bias-Variance Tradeoff: Textbooks Need an Update", "comments": "MSc Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this thesis is to point out that the bias-variance tradeoff\nis not always true (e.g. in neural networks). We advocate for this lack of\nuniversality to be acknowledged in textbooks and taught in introductory courses\nthat cover the tradeoff. We first review the history of the bias-variance\ntradeoff, its prevalence in textbooks, and some of the main claims made about\nthe bias-variance tradeoff. Through extensive experiments and analysis, we show\na lack of a bias-variance tradeoff in neural networks when increasing network\nwidth. Our findings seem to contradict the claims of the landmark work by Geman\net al. (1992). Motivated by this contradiction, we revisit the experimental\nmeasurements in Geman et al. (1992). We discuss that there was never strong\nevidence for a tradeoff in neural networks when varying the number of\nparameters. We observe a similar phenomenon beyond supervised learning, with a\nset of deep reinforcement learning experiments. We argue that textbook and\nlecture revisions are in order to convey this nuanced modern understanding of\nthe bias-variance tradeoff.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:50:59 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Neal", "Brady", ""]]}, {"id": "1912.08306", "submitter": "Kaixiong Zhou", "authors": "Kaixiong Zhou, Qingquan Song, Xiao Huang, Daochen Zha, Na Zou and Xia\n  Hu", "title": "Multi-Channel Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) has been demonstrated to be effective in\nclassifying graph structures. To further improve the graph representation\nlearning ability, hierarchical GNN has been explored. It leverages the\ndifferentiable pooling to cluster nodes into fixed groups, and generates a\ncoarse-grained structure accompanied with the shrinking of the original graph.\nHowever, such clustering would discard some graph information and achieve the\nsuboptimal results. It is because the node inherently has different\ncharacteristics or roles, and two non-isomorphic graphs may have the same\ncoarse-grained structure that cannot be distinguished after pooling. To\ncompensate the loss caused by coarse-grained clustering and further advance\nGNN, we propose a multi-channel graph convolutional networks (MuchGCN). It is\nmotivated by the convolutional neural networks, at which a series of channels\nare encoded to preserve the comprehensive characteristics of the input image.\nThus, we define the specific graph convolutions to learn a series of graph\nchannels at each layer, and pool graphs iteratively to encode the hierarchical\nstructures. Experiments have been carefully carried out to demonstrate the\nsuperiority of MuchGCN over the state-of-the-art graph classification\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:05:01 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Zhou", "Kaixiong", ""], ["Song", "Qingquan", ""], ["Huang", "Xiao", ""], ["Zha", "Daochen", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "1912.08311", "submitter": "Benjamin Guedj", "authors": "Benjamin Guedj and Bhargav Srinivasa Desikan", "title": "Kernel-Based Ensemble Learning in Python", "comments": "11 pages", "journal-ref": "Information 2020, 11(2)", "doi": "10.3390/info11020063", "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new supervised learning algorithm, for classification and\nregression problems where two or more preliminary predictors are available. We\nintroduce \\texttt{KernelCobra}, a non-linear learning strategy for combining an\narbitrary number of initial predictors. \\texttt{KernelCobra} builds on the\nCOBRA algorithm introduced by \\citet{biau2016cobra}, which combined estimators\nbased on a notion of proximity of predictions on the training data. While the\nCOBRA algorithm used a binary threshold to declare which training data were\nclose and to be used, we generalize this idea by using a kernel to better\nencapsulate the proximity information. Such a smoothing kernel provides more\nrepresentative weights to each of the training points which are used to build\nthe aggregate and final predictor, and \\texttt{KernelCobra} systematically\noutperforms the COBRA algorithm. While COBRA is intended for regression,\n\\texttt{KernelCobra} deals with classification and regression.\n\\texttt{KernelCobra} is included as part of the open source Python package\n\\texttt{Pycobra} (0.2.4 and onward), introduced by \\citet{guedj2018pycobra}.\nNumerical experiments assess the performance (in terms of pure prediction and\ncomputational complexity) of \\texttt{KernelCobra} on real-life and synthetic\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:23:00 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Guedj", "Benjamin", ""], ["Desikan", "Bhargav Srinivasa", ""]]}, {"id": "1912.08320", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah\n  Tang, Jenny Huang", "title": "Garbage In, Garbage Out? Do Machine Learning Application Papers in\n  Social Computing Report Where Human-Labeled Training Data Comes From?", "comments": "18 pages, includes appendix", "journal-ref": "Proc ACM FAT* 2020", "doi": "10.1145/3351095.3372862", "report-no": null, "categories": "cs.CY cs.CL cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning projects for new application areas involve teams of\nhumans who label data for a particular purpose, from hiring crowdworkers to the\npaper's authors labeling the data themselves. Such a task is quite similar to\n(or a form of) structured content analysis, which is a longstanding methodology\nin the social sciences and humanities, with many established best practices. In\nthis paper, we investigate to what extent a sample of machine learning\napplication papers in social computing --- specifically papers from ArXiv and\ntraditional publications performing an ML classification task on Twitter data\n--- give specific details about whether such best practices were followed. Our\nteam conducted multiple rounds of structured content analysis of each paper,\nmaking determinations such as: Does the paper report who the labelers were,\nwhat their qualifications were, whether they independently labeled the same\nitems, whether inter-rater reliability metrics were disclosed, what level of\ntraining and/or instructions were given to labelers, whether compensation for\ncrowdworkers is disclosed, and if the training data is publicly available. We\nfind a wide divergence in whether such practices were followed and documented.\nMuch of machine learning research and education focuses on what is done once a\n\"gold standard\" of training data is available, but we discuss issues around the\nequally-important aspect of whether such data is reliable in the first place.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:49:19 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Yu", "Kevin", ""], ["Yang", "Yanlai", ""], ["Dai", "Mindy", ""], ["Qiu", "Jie", ""], ["Tang", "Rebekah", ""], ["Huang", "Jenny", ""]]}, {"id": "1912.08324", "submitter": "Kai Arulkumaran", "authors": "Tianhong Dai, Kai Arulkumaran, Tamara Gerbert, Samyakh Tukra, Feryal\n  Behbahani, Anil Anthony Bharath", "title": "Analysing Deep Reinforcement Learning Agents Trained with Domain\n  Randomisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has the potential to train robots to perform\ncomplex tasks in the real world without requiring accurate models of the robot\nor its environment. A practical approach is to train agents in simulation, and\nthen transfer them to the real world. One popular method for achieving\ntransferability is to use domain randomisation, which involves randomly\nperturbing various aspects of a simulated environment in order to make trained\nagents robust to the reality gap. However, less work has gone into\nunderstanding such agents - which are deployed in the real world - beyond task\nperformance. In this work we examine such agents, through qualitative and\nquantitative comparisons between agents trained with and without visual domain\nrandomisation. We train agents for Fetch and Jaco robots on a visuomotor\ncontrol task and evaluate how well they generalise using different testing\nconditions. Finally, we investigate the internals of the trained agents by\nusing a suite of interpretability techniques. Our results show that the primary\noutcome of domain randomisation is more robust, entangled representations,\naccompanied with larger weights with greater spatial structure; moreover, the\ntypes of changes are heavily influenced by the task setup and presence of\nadditional proprioceptive inputs. Additionally, we demonstrate that our domain\nrandomised agents require higher sample complexity, can overfit and more\nheavily rely on recurrent processing. Furthermore, even with an improved\nsaliency method introduced in this work, we show that qualitative studies may\nnot always correspond with quantitative measures, necessitating the combination\nof inspection tools in order to provide sufficient insights into the behaviour\nof trained agents.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 00:18:17 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 20:53:30 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Dai", "Tianhong", ""], ["Arulkumaran", "Kai", ""], ["Gerbert", "Tamara", ""], ["Tukra", "Samyakh", ""], ["Behbahani", "Feryal", ""], ["Bharath", "Anil Anthony", ""]]}, {"id": "1912.08333", "submitter": "Stephen Whitelam", "authors": "Stephen Whitelam and Isaac Tamblyn", "title": "Learning to grow: control of material self-assembly using evolutionary\n  reinforcement learning", "comments": null, "journal-ref": "Phys. Rev. E 101, 052604 (2020)", "doi": "10.1103/PhysRevE.101.052604", "report-no": null, "categories": "cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that neural networks trained by evolutionary reinforcement learning\ncan enact efficient molecular self-assembly protocols. Presented with molecular\nsimulation trajectories, networks learn to change temperature and chemical\npotential in order to promote the assembly of desired structures or choose\nbetween competing polymorphs. In the first case, networks reproduce in a\nqualitative sense the results of previously-known protocols, but faster and\nwith higher fidelity; in the second case they identify strategies previously\nunknown, from which we can extract physical insight. Networks that take as\ninput the elapsed time of the simulation or microscopic information from the\nsystem are both effective, the latter more so. The evolutionary scheme we have\nused is simple to implement and can be applied to a broad range of examples of\nexperimental self-assembly, whether or not one can monitor the experiment as it\nproceeds. Our results have been achieved with no human input beyond the\nspecification of which order parameter to promote, pointing the way to the\ndesign of synthesis protocols by artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 01:06:34 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 05:21:08 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 19:07:49 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Whitelam", "Stephen", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "1912.08335", "submitter": "Andres Masegosa R", "authors": "Andres R. Masegosa", "title": "Learning under Model Misspecification: Applications to Variational and\n  Ensemble methods", "comments": "Camera-Ready Version. NeurIPS 2020. Minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtually any model we use in machine learning to make predictions does not\nperfectly represent reality. So, most of the learning happens under model\nmisspecification. In this work, we present a novel analysis of the\ngeneralization performance of Bayesian model averaging under model\nmisspecification and i.i.d. data using a new family of second-order PAC-Bayes\nbounds. This analysis shows, in simple and intuitive terms, that Bayesian model\naveraging provides suboptimal generalization performance when the model is\nmisspecified. In consequence, we provide strong theoretical arguments showing\nthat Bayesian methods are not optimal for learning predictive models, unless\nthe model class is perfectly specified. Using novel second-order PAC-Bayes\nbounds, we derive a new family of Bayesian-like algorithms, which can be\nimplemented as variational and ensemble methods. The output of these algorithms\nis a new posterior distribution, different from the Bayesian posterior, which\ninduces a posterior predictive distribution with better generalization\nperformance. Experiments with Bayesian neural networks illustrate these\nfindings.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 01:38:58 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 09:29:53 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 12:29:11 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 11:10:41 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 10:08:28 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Masegosa", "Andres R.", ""]]}, {"id": "1912.08342", "submitter": "Orlando Romero", "authors": "Orlando Romero, Mouhacine Benosman", "title": "Finite-Time Convergence of Continuous-Time Optimization Algorithms via\n  Differential Inclusions", "comments": "Presented at workshop \"Beyond First Order Methods in Machine\n  Learning\" of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two discontinuous dynamical systems in continuous\ntime with guaranteed prescribed finite-time local convergence to strict local\nminima of a given cost function. Our approach consists of exploiting a\nLyapunov-based differential inequality for differential inclusions, which leads\nto finite-time stability and thus finite-time convergence with a provable bound\non the settling time. In particular, for exact solutions to the aforementioned\ndifferential inequality, the settling-time bound is also exact, thus achieving\nprescribed finite-time convergence. We thus construct a class of discontinuous\ndynamical systems, of second order with respect to the cost function, that\nserve as continuous-time optimization algorithms with finite-time convergence\nand prescribed convergence time. Finally, we illustrate our results on the\nRosenbrock function.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:18:04 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Romero", "Orlando", ""], ["Benosman", "Mouhacine", ""]]}, {"id": "1912.08348", "submitter": "Farzana Nasrin", "authors": "Farzana Nasrin, Christopher Oballe, David L. Boothe, and Vasileios\n  Maroulas", "title": "Bayesian Topological Learning for Brain State Classification", "comments": "7 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigation of human brain states through electroencephalograph (EEG)\nsignals is a crucial step in human-machine communications. However, classifying\nand analyzing EEG signals are challenging due to their noisy, nonlinear and\nnonstationary nature. Current methodologies for analyzing these signals often\nfall short because they have several regularity assumptions baked in. This work\nprovides an effective, flexible and noise-resilient scheme to analyze EEG by\nextracting pertinent information while abiding by the 3N (noisy, nonlinear and\nnonstationary) nature of data. We implement a topological tool, namely\npersistent homology, that tracks the evolution of topological features over\ntime intervals and incorporates individual's expectations as prior knowledge by\nmeans of a Bayesian framework to compute posterior distributions. Relying on\nthese posterior distributions, we apply Bayes factor classification to noisy\nEEG measurements. The performance of this Bayesian classification scheme is\nthen compared with other existing methods for EEG signals.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:36:03 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Nasrin", "Farzana", ""], ["Oballe", "Christopher", ""], ["Boothe", "David L.", ""], ["Maroulas", "Vasileios", ""]]}, {"id": "1912.08350", "submitter": "Makena Low", "authors": "Makena Low, Priyanka Raina", "title": "Automating Vitiligo Skin Lesion Segmentation Using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For several skin conditions such as vitiligo, accurate segmentation of\nlesions from skin images is the primary measure of disease progression and\nseverity. Existing methods for vitiligo lesion segmentation require manual\nintervention. Unfortunately, manual segmentation is time and labor-intensive,\nas well as irreproducible between physicians. We introduce a convolutional\nneural network (CNN) that quickly and robustly performs vitiligo skin lesion\nsegmentation. Our CNN has a U-Net architecture with a modified contracting\npath. We use the CNN to generate an initial segmentation of the lesion, then\nrefine it by running the watershed algorithm on high-confidence pixels. We\ntrain the network on 247 images with a variety of lesion sizes, complexity, and\nanatomical sites. The network with our modifications noticeably outperforms the\nstate-of-the-art U-Net, with a Jaccard Index (JI) score of 73.6% (compared to\n36.7%). Moreover, our method requires only a few seconds for segmentation, in\ncontrast with the previously proposed semi-autonomous watershed approach, which\nrequires 2-29 minutes per image.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 20:15:44 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Low", "Makena", ""], ["Raina", "Priyanka", ""]]}, {"id": "1912.08375", "submitter": "YeongHyeon Park", "authors": "YeongHyeon Park, Il Dong Yun, Si-Hyuck Kang", "title": "The CNN-based Coronary Occlusion Site Localization with Effective\n  Preprocessing Method", "comments": null, "journal-ref": null, "doi": "10.1002/tee.23225", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Coronary Artery Occlusion (CAO) acutely comes to human, and it highly\nthreats the human's life. When CAO detected, Percutaneous Coronary Intervention\n(PCI) should be conducted timely. Before PCI, localizing the CAO is needed\nfirstly, because the heart is covered with various arteries. We handle the\nthree kinds of CAO in this paper and our purpose is not only localization of\nCAO but also improving the localizing performance via preprocessing method. We\nimprove localization performance from a minimum of 0.150 to a maximum of 0.372\nvia our noise reduction and pulse extraction based method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 04:44:39 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 04:30:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Park", "YeongHyeon", ""], ["Yun", "Il Dong", ""], ["Kang", "Si-Hyuck", ""]]}, {"id": "1912.08394", "submitter": "Andreas W. Kempa-Liehr", "authors": "Andreas W. Kempa-Liehr and Jonty Oram and Andrew Wong and Mark Finch\n  and Thor Besier", "title": "Feature engineering workflow for activity recognition from synchronized\n  inertial measurement units", "comments": "Multi-Sensor for Action and Gesture Recognition (MAGR), ACPR 2019\n  Workshop, Auckland, New Zealand", "journal-ref": null, "doi": "10.1007/978-981-15-3651-9_20", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous availability of wearable sensors is responsible for driving\nthe Internet-of-Things but is also making an impact on sport sciences and\nprecision medicine. While human activity recognition from smartphone data or\nother types of inertial measurement units (IMU) has evolved to one of the most\nprominent daily life examples of machine learning, the underlying process of\ntime-series feature engineering still seems to be time-consuming. This lengthy\nprocess inhibits the development of IMU-based machine learning applications in\nsport science and precision medicine. This contribution discusses a feature\nengineering workflow, which automates the extraction of time-series feature on\nbased on the FRESH algorithm (FeatuRe Extraction based on Scalable Hypothesis\ntests) to identify statistically significant features from synchronized IMU\nsensors (IMeasureU Ltd, NZ). The feature engineering workflow has five main\nsteps: time-series engineering, automated time-series feature extraction,\noptimized feature extraction, fitting of a specialized classifier, and\ndeployment of optimized machine learning pipeline. The workflow is discussed\nfor the case of a user-specific running-walking classification, and the\ngeneralization to a multi-user multi-activity classification is demonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 05:51:42 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kempa-Liehr", "Andreas W.", ""], ["Oram", "Jonty", ""], ["Wong", "Andrew", ""], ["Finch", "Mark", ""], ["Besier", "Thor", ""]]}, {"id": "1912.08404", "submitter": "Weixin Zeng", "authors": "Weixin Zeng, Xiang Zhao, Jiuyang Tang, and Xuemin Lin", "title": "Collective Entity Alignment via Adaptive Features", "comments": "ICDE20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment (EA) identifies entities that refer to the same real-world\nobject but locate in different knowledge graphs (KGs), and has been harnessed\nfor KG construction and integration. When generating EA results, current\nsolutions treat entities independently and fail to take into account the\ninterdependence between entities. To fill this gap, we propose a collective EA\nframework. We first employ three representative features, i.e., structural,\nsemantic and string signals, which are adapted to capture different aspects of\nthe similarity between entities in heterogeneous KGs. In order to make\ncollective EA decisions, we formulate EA as the classical stable matching\nproblem, which is further effectively solved by deferred acceptance algorithm.\nOur proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks\nagainst state-of-the-art solutions, and the empirical results verify its\neffectiveness and superiority.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 06:25:12 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 13:50:21 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 08:49:39 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zeng", "Weixin", ""], ["Zhao", "Xiang", ""], ["Tang", "Jiuyang", ""], ["Lin", "Xuemin", ""]]}, {"id": "1912.08409", "submitter": "Burc Gokden", "authors": "Burc Gokden", "title": "CoulGAT: An Experiment on Interpretability of Graph Attention Networks", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attention mechanism inspired from definition of screened\nCoulomb potential. This attention mechanism was used to interpret the Graph\nAttention (GAT) model layers and training dataset by using a flexible and\nscalable framework (CoulGAT) developed for this purpose. Using CoulGAT, a\nforest of plain and resnet models were trained and characterized using this\nattention mechanism against CHAMPS dataset. The learnable variables of the\nattention mechanism are used to extract node-node and node-feature interactions\nto define an empirical standard model for the graph structure and hidden layer.\nThis representation of graph and hidden layers can be used as a tool to compare\ndifferent models, optimize hidden layers and extract a compact definition of\ngraph structure of the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 06:46:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Gokden", "Burc", ""]]}, {"id": "1912.08416", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Carl Edward Rasmussen", "title": "Benchmarking the Neural Linear Model for Regression", "comments": "Advances in Approximate Bayesian Inference (AABI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural linear model is a simple adaptive Bayesian linear regression\nmethod that has recently been used in a number of problems ranging from\nBayesian optimization to reinforcement learning. Despite its apparent successes\nin these settings, to the best of our knowledge there has been no systematic\nexploration of its capabilities on simple regression tasks. In this work we\ncharacterize these on the UCI datasets, a popular benchmark for Bayesian\nregression models, as well as on the recently introduced UCI \"gap\" datasets,\nwhich are better tests of out-of-distribution uncertainty. We demonstrate that\nthe neural linear model is a simple method that shows generally good\nperformance on these tasks, but at the cost of requiring good hyperparameter\ntuning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 07:23:57 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1912.08421", "submitter": "Shuang Zhang", "authors": "Shuang Zhang, Liyao Xiang, Congcong Li, Yixuan Wang, Quanshi Zhang,\n  Wei Wang and Bo Li", "title": "Learning to Prevent Leakage: Privacy-Preserving Inference in the Mobile\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powered by machine learning services in the cloud, numerous learning-driven\nmobile applications are gaining popularity in the market. As deep learning\ntasks are mostly computation-intensive, it has become a trend to process raw\ndata on devices and send the deep neural network (DNN) features to the cloud,\nwhere the features are further processed to return final results. However,\nthere is always unexpected leakage with the release of features, with which an\nadversary could infer a significant amount of information about the original\ndata. We propose a privacy-preserving reinforcement learning framework on top\nof the mobile cloud infrastructure from the perspective of DNN structures. The\nframework aims to learn a policy to modify the base DNNs to prevent information\nleakage while maintaining high inference accuracy. The policy can also be\nreadily transferred to large-size DNNs to speed up learning. Extensive\nevaluations on a variety of DNNs have shown that our framework can successfully\nfind privacy-preserving DNN structures to defend different privacy attacks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 07:42:57 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 11:55:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhang", "Shuang", ""], ["Xiang", "Liyao", ""], ["Li", "Congcong", ""], ["Wang", "Yixuan", ""], ["Zhang", "Quanshi", ""], ["Wang", "Wei", ""], ["Li", "Bo", ""]]}, {"id": "1912.08434", "submitter": "Javier Felip Leon", "authors": "Javier Felip and Nilesh Ahuja and Omesh Tickoo", "title": "Tree pyramidal adaptive importance sampling", "comments": "20 pages + 13 pages of additional result plots and evaluation details", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Tree-Pyramidal Adaptive Importance Sampling (TP-AIS), a\nnovel iterated sampling method that outperforms state-of-the-art approaches\nlike deterministic mixture population Monte Carlo (DM-PMC), mixture population\nMonte Carlo (M-PMC) and layered adaptive importance sampling (LAIS). TP-AIS\niteratively builds a proposal distribution parameterized by a tree pyramid,\nwhere each tree leaf spans a subspace that represents its importance density.\nAfter each new sample operation, a set of tree leaves are subdivided for\nimproving the approximation of the proposal distribution to the target density.\nUnlike the rest of the methods in the literature, TP-AIS is parameter free and\nrequires no tuning to achieve its best performance. We evaluate TP-AIS with\ndifferent complexity randomized target probability density functions (PDF) and\nalso analyze its application to different dimensions. The results are compared\nto state-of-the-art iterative importance sampling approaches and other baseline\nMCMC approaches using Normalized Effective Sample Size (N-ESS), Jensen-Shannon\nDivergence, and time complexity.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:05:07 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 18:55:24 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Felip", "Javier", ""], ["Ahuja", "Nilesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1912.08442", "submitter": "Xinting Huang", "authors": "Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang", "title": "MALA: Cross-Domain Dialogue Generation with Action Learning", "comments": "Update: Accepted to Proceedings of AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6306", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response generation for task-oriented dialogues involves two basic\ncomponents: dialogue planning and surface realization. These two components,\nhowever, have a discrepancy in their objectives, i.e., task completion and\nlanguage quality. To deal with such discrepancy, conditioned response\ngeneration has been introduced where the generation process is factorized into\naction decision and language generation via explicit action representations. To\nobtain action representations, recent studies learn latent actions in an\nunsupervised manner based on the utterance lexical similarity. Such an action\nlearning approach is prone to diversities of language surfaces, which may\nimpinge task completion and language quality. To address this issue, we propose\nmulti-stage adaptive latent action learning (MALA) that learns semantic latent\nactions by distinguishing the effects of utterances on dialogue progress. We\nmodel the utterance effect using the transition of dialogue states caused by\nthe utterance and develop a semantic similarity measurement that estimates\nwhether utterances have similar effects. For learning semantic actions on\ndomains without dialogue states, MsALA extends the semantic similarity\nmeasurement across domains progressively, i.e., from aligning shared actions to\nlearning domain-specific actions. Experiments using multi-domain datasets, SMD\nand MultiWOZ, show that our proposed model achieves consistent improvements\nover the baselines models in terms of both task completion and language\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:14:10 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:33:38 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Huang", "Xinting", ""], ["Qi", "Jianzhong", ""], ["Sun", "Yu", ""], ["Zhang", "Rui", ""]]}, {"id": "1912.08444", "submitter": "Yichuan Charlie Tang", "authors": "Lionel Blond\\'e, Yichuan Charlie Tang, Jian Zhang, Russ Webb", "title": "Relational Mimic for Visual Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a new method for imitation learning from video\ndemonstrations. Our method, Relational Mimic (RM), improves on previous visual\nimitation learning methods by combining generative adversarial networks and\nrelational learning. RM is flexible and can be used in conjunction with other\nrecent advances in generative adversarial imitation learning to better address\nthe need for more robust and sample-efficient approaches. In addition, we\nintroduce a new neural network architecture that improves upon the previous\nstate-of-the-art in reinforcement learning and illustrate how increasing the\nrelational reasoning capabilities of the agent enables the latter to achieve\nincreasingly higher performance in a challenging locomotion task with pixel\ninputs. Finally, we study the effects and contributions of relational learning\nin policy evaluation, policy improvement and reward learning through ablation\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:19:39 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Tang", "Yichuan Charlie", ""], ["Zhang", "Jian", ""], ["Webb", "Russ", ""]]}, {"id": "1912.08446", "submitter": "Leonit Zeynalvand", "authors": "Leonit Zeynalvand, Tie Luo, Jie Zhang", "title": "COBRA: Context-aware Bernoulli Neural Networks for Reputation Assessment", "comments": "To be published in the Proceedings of AAAI, Feb 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust and reputation management (TRM) plays an increasingly important role in\nlarge-scale online environments such as multi-agent systems (MAS) and the\nInternet of Things (IoT). One main objective of TRM is to achieve accurate\ntrust assessment of entities such as agents or IoT service providers. However,\nthis encounters an accuracy-privacy dilemma as we identify in this paper, and\nwe propose a framework called Context-aware Bernoulli Neural Network based\nReputation Assessment (COBRA) to address this challenge. COBRA encapsulates\nagent interactions or transactions, which are prone to privacy leak, in machine\nlearning models, and aggregates multiple such models using a Bernoulli neural\nnetwork to predict a trust score for an agent. COBRA preserves agent privacy\nand retains interaction contexts via the machine learning models, and achieves\nmore accurate trust prediction than a fully-connected neural network\nalternative. COBRA is also robust to security attacks by agents who inject fake\nmachine learning models; notably, it is resistant to the 51-percent attack. The\nperformance of COBRA is validated by our experiments using a real dataset, and\nby our simulations, where we also show that COBRA outperforms other\nstate-of-the-art TRM systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 08:23:34 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 04:40:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zeynalvand", "Leonit", ""], ["Luo", "Tie", ""], ["Zhang", "Jie", ""]]}, {"id": "1912.08465", "submitter": "Vincenzo Matta", "authors": "Vincenzo Matta, Augusto Santos, Ali H. Sayed", "title": "Graph Learning Under Partial Observability", "comments": "to appear in Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization, inference and learning tasks can be accomplished\nefficiently by means of decentralized processing algorithms where the network\ntopology (i.e., the graph) plays a critical role in enabling the interactions\namong neighboring nodes. There is a large body of literature examining the\neffect of the graph structure on the performance of decentralized processing\nstrategies. In this article, we examine the inverse problem and consider the\nreverse question: How much information does observing the behavior at the nodes\nof a graph convey about the underlying topology? For large-scale networks, the\ndifficulty in addressing such inverse problems is compounded by the fact that\nusually only a limited fraction of the nodes can be probed, giving rise to a\nsecond important question: Despite the presence of unobserved nodes, can\npartial observations still be sufficient to discover the graph linking the\nprobed nodes? The article surveys recent advances on this challenging learning\nproblem and related questions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:10:27 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:35:58 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 15:03:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Matta", "Vincenzo", ""], ["Santos", "Augusto", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1912.08480", "submitter": "Alexander Ulanov", "authors": "Alexander E. Ulanov, Egor S. Tiunov and A. I. Lvovsky", "title": "Quantum-inspired annealers as Boltzmann generators for machine learning\n  and statistical physics", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum simulators and processors are rapidly improving nowadays, but they\nare still not able to solve complex and multidimensional tasks of practical\nvalue. However, certain numerical algorithms inspired by the physics of real\nquantum devices prove to be efficient in application to specific problems,\nrelated, for example, to combinatorial optimization. Here we implement a\nnumerical annealer based on simulating the coherent Ising machine as a tool to\nsample from a high-dimensional Boltzmann probability distribution with the\nenergy functional defined by the classical Ising Hamiltonian. Samples provided\nby such a generator are then utilized for the partition function estimation of\nthis distribution and for the training of a general Boltzmann machine. Our\nstudy opens up a door to practical application of numerical quantum-inspired\nannealers.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:35:13 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Ulanov", "Alexander E.", ""], ["Tiunov", "Egor S.", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "1912.08495", "submitter": "Yatao A. Bian", "authors": "Yatao An Bian", "title": "Provable Non-Convex Optimization and Algorithm Validation via\n  Submodularity", "comments": "PhD thesis of Yatao (An) Bian; It is about continuous submodular\n  optimization and algorithm validation", "journal-ref": null, "doi": "10.3929/ethz-b-000386316", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodularity is one of the most well-studied properties of problem classes\nin combinatorial optimization and many applications of machine learning and\ndata mining, with strong implications for guaranteed optimization. In this\nthesis, we investigate the role of submodularity in provable non-convex\noptimization and validation of algorithms. A profound understanding which\nclasses of functions can be tractably optimized remains a central challenge for\nnon-convex optimization. By advancing the notion of submodularity to continuous\ndomains (termed \"continuous submodularity\"), we characterize a class of\ngenerally non-convex and non-concave functions -- continuous submodular\nfunctions, and derive algorithms for approximately maximizing them with strong\napproximation guarantees. Meanwhile, continuous submodularity captures a wide\nspectrum of applications, ranging from revenue maximization with general\nmarketing strategies, MAP inference for DPPs to mean field inference for\nprobabilistic log-submodular models, which renders it as a valuable domain\nknowledge in optimizing this class of objectives. Validation of algorithms is\nan information-theoretic framework to investigate the robustness of algorithms\nto fluctuations in the input/observations and their generalization ability. We\ninvestigate various algorithms for one of the paradigmatic unconstrained\nsubmodular maximization problem: MaxCut. Due to submodularity of the MaxCut\nobjective, we are able to present efficient approaches to calculate the\nalgorithmic information content of MaxCut algorithms. The results provide\ninsights into the robustness of different algorithmic techniques for MaxCut.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 10:13:38 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Bian", "Yatao An", ""]]}, {"id": "1912.08517", "submitter": "Marc Dymetman", "authors": "Tetiana Parshakova and Jean-Marc Andreoli and Marc Dymetman", "title": "Distributional Reinforcement Learning for Energy-Based Sequential Models", "comments": "OptRL workshop (Optimization Foundations for Reinforcement Learning)\n  at Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Autoregressive Models (GAMs) are a recent proposal [Parshakova et al.,\nCoNLL 2019] for exploiting global properties of sequences for data-efficient\nlearning of seq2seq models. In the first phase of training, an Energy-Based\nmodel (EBM) over sequences is derived. This EBM has high representational\npower, but is unnormalized and cannot be directly exploited for sampling. To\naddress this issue [Parshakova et al., CoNLL 2019] proposes a distillation\ntechnique, which can only be applied under limited conditions. By relating this\nproblem to Policy Gradient techniques in RL, but in a \\emph{distributional}\nrather than \\emph{optimization} perspective, we propose a general approach\napplicable to any sequential EBM. Its effectiveness is illustrated on GAM-based\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 11:05:27 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Parshakova", "Tetiana", ""], ["Andreoli", "Jean-Marc", ""], ["Dymetman", "Marc", ""]]}, {"id": "1912.08521", "submitter": "Mohammad Sadegh Aliakbarian", "authors": "Sadegh Aliakbarian, Fatemeh Sadat Saleh, Lars Petersson, Stephen\n  Gould, Mathieu Salzmann", "title": "Contextually Plausible and Diverse 3D Human Motion Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the task of diverse 3D human motion prediction, that is,\nforecasting multiple plausible future 3D poses given a sequence of observed 3D\nposes. In this context, a popular approach consists of using a Conditional\nVariational Autoencoder (CVAE). However, existing approaches that do so either\nfail to capture the diversity in human motion, or generate diverse but\nsemantically implausible continuations of the observed motion. In this paper,\nwe address both of these problems by developing a new variational framework\nthat accounts for both diversity and context of the generated future motion. To\nthis end, and in contrast to existing approaches, we condition the sampling of\nthe latent variable that acts as source of diversity on the representation of\nthe past observation, thus encouraging it to carry relevant information. Our\nexperiments demonstrate that our approach yields motions not only of higher\nquality while retaining diversity, but also that preserve the contextual\ninformation contained in the observed 3D pose sequence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 11:13:44 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 13:16:24 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 01:29:31 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 08:59:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aliakbarian", "Sadegh", ""], ["Saleh", "Fatemeh Sadat", ""], ["Petersson", "Lars", ""], ["Gould", "Stephen", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "1912.08526", "submitter": "Anastasia Borovykh", "authors": "Anastasia Borovykh", "title": "Analytic expressions for the output evolution of a deep neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology based on a Taylor expansion of the network\noutput for obtaining analytical expressions for the expected value of the\nnetwork weights and output under stochastic training. Using these analytical\nexpressions the effects of the hyperparameters and the noise variance of the\noptimization algorithm on the performance of the deep neural network are\nstudied. In the early phases of training with a small noise coefficient, the\noutput is equivalent to a linear model. In this case the network can generalize\nbetter due to the noise preventing the output from fully converging on the\ntrain data, however the noise does not result in any explicit regularization.\nIn the later training stages, when higher order approximations are required,\nthe impact of the noise becomes more significant, i.e. in a model which is\nnon-linear in the weights noise can regularize the output function resulting in\nbetter generalization as witnessed by its influence on the weight Hessian, a\ncommonly used metric for generalization capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 11:18:18 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Borovykh", "Anastasia", ""]]}, {"id": "1912.08541", "submitter": "Uehwan Kim", "authors": "In-Ug Yoon, Ue-Hwan Kim and Jong-Hwan", "title": "s-DRN: Stabilized Developmental Resonance Network", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online incremental clustering of sequentially incoming data without prior\nknowledge suffers from changing cluster numbers and tends to fall into local\nextrema according to given data order. To overcome these limitations, we\npropose a stabilized developmental resonance network (s-DRN). First, we analyze\nthe instability of the conventional choice function during the node activation\nprocess and design a scalable activation function to make clustering\nperformance stable over all input data scales. Next, we devise three criteria\nfor the node grouping algorithm: distance, intersection over union (IoU) and\nsize criteria. The proposed node grouping algorithm effectively excludes\nunnecessary clusters from incrementally created clusters, diminishes the\nperformance dependency on vigilance parameters and makes the clustering process\nrobust. To verify the performance of the proposed s-DRN model, comparative\nstudies are conducted on six real-world datasets whose statistical\ncharacteristics are distinctive. The comparative studies demonstrate the\nproposed s-DRN outperforms baselines in terms of stability and accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 11:47:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 05:06:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Yoon", "In-Ug", ""], ["Kim", "Ue-Hwan", ""], ["Jong-Hwan", "", ""]]}, {"id": "1912.08555", "submitter": "Gustavo Penha", "authors": "Gustavo Penha and Claudia Hauff", "title": "Curriculum Learning Strategies for IR: An Empirical Study on\n  Conversation Response Ranking", "comments": "Accepted for publication in the 42nd European Conference on\n  Information Retrieval (ECIR'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ranking models are traditionally trained on a series of random\nbatches, sampled uniformly from the entire training set. Curriculum learning\nhas recently been shown to improve neural models' effectiveness by sampling\nbatches non-uniformly, going from easy to difficult instances during training.\nIn the context of neural Information Retrieval (IR) curriculum learning has not\nbeen explored yet, and so it remains unclear (1) how to measure the difficulty\nof training instances and (2) how to transition from easy to difficult\ninstances during training. To address both challenges and determine whether\ncurriculum learning is beneficial for neural ranking models, we need\nlarge-scale datasets and a retrieval task that allows us to conduct a wide\nrange of experiments. For this purpose, we resort to the task of conversation\nresponse ranking: ranking responses given the conversation history. In order to\ndeal with challenge (1), we explore scoring functions to measure the difficulty\nof conversations based on different input spaces. To address challenge (2) we\nevaluate different pacing functions, which determine the velocity in which we\ngo from easy to difficult instances. We find that, overall, by just\nintelligently sorting the training data (i.e., by performing curriculum\nlearning) we can improve the retrieval effectiveness by up to 2%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 12:13:30 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Penha", "Gustavo", ""], ["Hauff", "Claudia", ""]]}, {"id": "1912.08577", "submitter": "Fang Aiqing", "authors": "Aiqing Fang and Xinbo Zhao and Jiaqi Yang and Yanning Zhang", "title": "A Cross-Modal Image Fusion Method Guided by Human Visual Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characteristics of feature selection, nonlinear combination and\nmulti-task auxiliary learning mechanism of the human visual perception system\nplay an important role in real-world scenarios, but the research of image\nfusion theory based on the characteristics of human visual perception is less.\nInspired by the characteristics of human visual perception, we propose a robust\nmulti-task auxiliary learning optimization image fusion theory. Firstly, we\ncombine channel attention model with nonlinear convolutional neural network to\nselect features and fuse nonlinear features. Then, we analyze the impact of the\nexisting image fusion loss on the image fusion quality, and establish the\nmulti-loss function model of unsupervised learning network. Secondly, aiming at\nthe multi-task auxiliary learning mechanism of human visual perception system,\nwe study the influence of multi-task auxiliary learning mechanism on image\nfusion task on the basis of single task multi-loss network model. By simulating\nthe three characteristics of human visual perception system, the fused image is\nmore consistent with the mechanism of human brain image fusion. Finally, in\norder to verify the superiority of our algorithm, we carried out experiments on\nthe combined vision system image data set, and extended our algorithm to the\ninfrared and visible image and the multi-focus image public data set for\nexperimental verification. The experimental results demonstrate the superiority\nof our fusion theory over state-of-arts in generality and robustness.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:07:20 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 10:59:55 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 00:51:11 GMT"}, {"version": "v4", "created": "Sat, 20 Jun 2020 09:43:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Fang", "Aiqing", ""], ["Zhao", "Xinbo", ""], ["Yang", "Jiaqi", ""], ["Zhang", "Yanning", ""]]}, {"id": "1912.08578", "submitter": "Adil Rasheed Professor", "authors": "Eivind Meyer, Haakon Robinson, Adil Rasheed, Omer San", "title": "Taming an autonomous surface vehicle for path following and collision\n  avoidance using deep reinforcement learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we explore the feasibility of applying proximal policy\noptimization, a state-of-the-art deep reinforcement learning algorithm for\ncontinuous control tasks, on the dual-objective problem of controlling an\nunderactuated autonomous surface vehicle to follow an a priori known path while\navoiding collisions with non-moving obstacles along the way. The artificial\nintelligent agent, which is equipped with multiple rangefinder sensors for\nobstacle detection, is trained and evaluated in a challenging, stochastically\ngenerated simulation environment based on the OpenAI gym python toolkit.\nNotably, the agent is provided with real-time insight into its own reward\nfunction, allowing it to dynamically adapt its guidance strategy. Depending on\nits strategy, which ranges from radical path-adherence to radical obstacle\navoidance, the trained agent achieves an episodic success rate between 84 and\n100%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:08:30 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Meyer", "Eivind", ""], ["Robinson", "Haakon", ""], ["Rasheed", "Adil", ""], ["San", "Omer", ""]]}, {"id": "1912.08581", "submitter": "H{\\aa}vard Kvamme", "authors": "H{\\aa}vard Kvamme and {\\O}rnulf Borgan", "title": "The Brier Score under Administrative Censoring: Problems and Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Brier score is commonly used for evaluating probability predictions. In\nsurvival analysis, with right-censored observations of the event times, this\nscore can be weighted by the inverse probability of censoring (IPCW) to retain\nits original interpretation. It is common practice to estimate the censoring\ndistribution with the Kaplan-Meier estimator, even though it assumes that the\ncensoring distribution is independent of the covariates. This paper discusses\nthe general impact of the censoring estimates on the Brier score and shows that\nthe estimation of the censoring distribution can be problematic. In particular,\nwhen the censoring times can be identified from the covariates, the IPCW score\nis no longer valid. For administratively censored data, where the potential\ncensoring times are known for all individuals, we propose an alternative\nversion of the Brier score. This administrative Brier score does not require\nestimation of the censoring distribution and is valid even if the censoring\ntimes can be identified from the covariates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:13:03 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Kvamme", "H\u00e5vard", ""], ["Borgan", "\u00d8rnulf", ""]]}, {"id": "1912.08616", "submitter": "Anton Akusok", "authors": "Anton Akusok and Emil Eirola", "title": "Comparison of Classification Methods for Very High-Dimensional Data in\n  Sparse Random Projection Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The big data trend has inspired feature-driven learning tasks, which cannot\nbe handled by conventional machine learning models. Unstructured data produces\nvery large binary matrices with millions of columns when converted to vector\nform. However, such data is often sparse, and hence can be manageable through\nthe use of sparse random projections.\n  This work studies efficient non-iterative and iterative methods suitable for\nsuch data, evaluating the results on two representative machine learning tasks\nwith millions of samples and features. An efficient Jaccard kernel is\nintroduced as an alternative to the sparse random projection. Findings indicate\nthat non-iterative methods can find larger, more accurate models than iterative\nmethods in different application scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 14:05:54 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Akusok", "Anton", ""], ["Eirola", "Emil", ""]]}, {"id": "1912.08637", "submitter": "Sreejith Kallummil", "authors": "Sreejith Kallummil, Sheetal Kalyani", "title": "Generalized Residual Ratio Thresholding", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous orthogonal matching pursuit (SOMP) and block OMP (BOMP) are two\nwidely used techniques for sparse support recovery in multiple measurement\nvector (MMV) and block sparse (BS) models respectively. For optimal\nperformance, both SOMP and BOMP require \\textit{a priori} knowledge of signal\nsparsity or noise variance. However, sparsity and noise variance are\nunavailable in most practical applications. This letter presents a novel\ntechnique called generalized residual ratio thresholding (GRRT) for operating\nSOMP and BOMP without the \\textit{a priori} knowledge of signal sparsity and\nnoise variance and derive finite sample and finite signal to noise ratio (SNR)\nguarantees for exact support recovery. Numerical simulations indicate that GRRT\nperforms similar to BOMP and SOMP with \\textit{a priori} knowledge of signal\nand noise statistics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 14:39:25 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 06:18:11 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kallummil", "Sreejith", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1912.08638", "submitter": "Anton Akusok", "authors": "Anton Akusok, Emil Eirola, Yoan Miche, Ian Oliver, Kaj-Mikael Bj\\\"ork,\n  Andrey Gritsenko, Stephen Baek and Amaury Lendasse", "title": "Incremental ELMVIS for unsupervised learning", "comments": null, "journal-ref": "Proceedings of ELM-2016 (pp. 183-193). Springer, Cham", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An incremental version of the ELMVIS+ method is proposed in this paper. It\niteratively selects a few best fitting data samples from a large pool, and adds\nthem to the model. The method keeps high speed of ELMVIS+ while allowing for\nmuch larger possible sample pools due to lower memory requirements. The\nextension is useful for reaching a better local optimum with greedy\noptimization of ELMVIS, and the data structure can be specified in\nsemi-supervised optimization. The major new application of incremental ELMVIS\nis not to visualization, but to a general dataset processing. The method is\ncapable of learning dependencies from non-organized unsupervised data -- either\nreconstructing a shuffled dataset, or learning dependencies in complex\nhigh-dimensional space. The results are interesting and promising, although\nthere is space for improvements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 14:41:05 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Akusok", "Anton", ""], ["Eirola", "Emil", ""], ["Miche", "Yoan", ""], ["Oliver", "Ian", ""], ["Bj\u00f6rk", "Kaj-Mikael", ""], ["Gritsenko", "Andrey", ""], ["Baek", "Stephen", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1912.08679", "submitter": "Xavier Rafael-Palou", "authors": "Ilaria Bonavita, Xavier Rafael-Palou, Mario Ceresa, Gemma Piella,\n  Vicent Ribas, Miguel A. Gonz\\'alez Ballester", "title": "Integration of Convolutional Neural Networks for Pulmonary Nodule\n  Malignancy Assessment in a Lung Cancer Classification Pipeline", "comments": "26 pages, 5 figures", "journal-ref": "Computer Methods and Programs in Biomedicine,\n  volume=185,number=105172, pages=1-9, year=2019, publisher=Elsevier", "doi": "10.1016/j.cmpb.2019.105172", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early identification of malignant pulmonary nodules is critical for\nbetter lung cancer prognosis and less invasive chemo or radio therapies. Nodule\nmalignancy assessment done by radiologists is extremely useful for planning a\npreventive intervention but is, unfortunately, a complex, time-consuming and\nerror-prone task. This explains the lack of large datasets containing\nradiologists malignancy characterization of nodules. In this article, we\npropose to assess nodule malignancy through 3D convolutional neural networks\nand to integrate it in an automated end-to-end existing pipeline of lung cancer\ndetection. For training and testing purposes we used independent subsets of the\nLIDC dataset. Adding the probabilities of nodules malignity in a baseline lung\ncancer pipeline improved its F1-weighted score by 14.7%, whereas integrating\nthe malignancy model itself using transfer learning outperformed the baseline\nprediction by 11.8% of F1-weighted score. Despite the limited size of the lung\ncancer datasets, integrating predictive models of nodule malignancy improves\nprediction of lung cancer.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:56:29 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Bonavita", "Ilaria", ""], ["Rafael-Palou", "Xavier", ""], ["Ceresa", "Mario", ""], ["Piella", "Gemma", ""], ["Ribas", "Vicent", ""], ["Ballester", "Miguel A. Gonz\u00e1lez", ""]]}, {"id": "1912.08722", "submitter": "Fengjiao Li", "authors": "Fengjiao Li, Yu Sang, Zhongdong Liu, Bin Li, Huasen Wu, Bo Ji", "title": "Waiting but not Aging: Optimizing Information Freshness Under the Pull\n  Model", "comments": "15 pages. arXiv admin note: substantial text overlap with\n  arXiv:1704.04848", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Age-of-Information is an important metric for investigating the\ntimeliness performance in information-update systems. In this paper, we study\nthe AoI minimization problem under a new Pull model with replication schemes,\nwhere a user proactively sends a replicated request to multiple servers to\n\"pull\" the information of interest. Interestingly, we find that under this new\nPull model, replication schemes capture a novel tradeoff between different\nvalues of the AoI across the servers (due to the random updating processes) and\ndifferent response times across the servers, which can be exploited to minimize\nthe expected AoI at the user's side. Specifically, assuming Poisson updating\nprocess for the servers and exponentially distributed response time, we derive\na closed-form formula for computing the expected AoI and obtain the optimal\nnumber of responses to wait for to minimize the expected AoI. Then, we extend\nour analysis to the setting where the user aims to maximize the AoI-based\nutility, which represents the user's satisfaction level with respect to\nfreshness of the received information. Furthermore, we consider a more\nrealistic scenario where the user has no prior knowledge of the system. In this\ncase, we reformulate the utility maximization problem as a stochastic\nMulti-Armed Bandit problem with side observations and leverage a special linear\nstructure of side observations to design learning algorithms with improved\nperformance guarantees. Finally, we conduct extensive simulations to elucidate\nour theoretical results and compare the performance of different algorithms.\nOur findings reveal that under the Pull model, waiting does not necessarily\nlead to aging; waiting for more than one response can often significantly\nreduce the AoI and improve the AoI-based utility in most scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:45:08 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 21:33:36 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 18:31:33 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Li", "Fengjiao", ""], ["Sang", "Yu", ""], ["Liu", "Zhongdong", ""], ["Li", "Bin", ""], ["Wu", "Huasen", ""], ["Ji", "Bo", ""]]}, {"id": "1912.08740", "submitter": "Marcio Ferreira Moreno", "authors": "Marcio Moreno, Daniel Civitarese, Rafael Brandao, Renato Cerqueira", "title": "Effective Integration of Symbolic and Connectionist Approaches through a\n  Hybrid Representation", "comments": "3 pages, 3 figures, accepted on NeSy'2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our position for a neuralsymbolic integration\nstrategy, arguing in favor of a hybrid representation to promote an effective\nintegration. Such description differs from others fundamentally, since its\nentities aim at representing AI models in general, allowing to describe both\nnonsymbolic and symbolic knowledge, the integration between them and their\ncorresponding processors. Moreover, the entities also support representing\nworkflows, leveraging traceability to keep track of every change applied to\nmodels and their related entities (e.g., data or concepts) throughout the\nlifecycle of the models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:10:58 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Moreno", "Marcio", ""], ["Civitarese", "Daniel", ""], ["Brandao", "Rafael", ""], ["Cerqueira", "Renato", ""]]}, {"id": "1912.08755", "submitter": "Marc-Andre Schulz", "authors": "Marc-Andre Schulz, Matt Chapman-Rounds, Manisha Verma, Danilo Bzdok,\n  Konstantinos Georgatzis", "title": "Clusters in Explanation Space: Inferring disease subtypes from model\n  explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of disease subtypes and corresponding biomarkers can\nsubstantially improve clinical diagnosis and treatment selection. Discovering\nthese subtypes in noisy, high dimensional biomedical data is often impossible\nfor humans and challenging for machines. We introduce a new approach to\nfacilitate the discovery of disease subtypes: Instead of analyzing the original\ndata, we train a diagnostic classifier (healthy vs. diseased) and extract\ninstance-wise explanations for the classifier's decisions. The distribution of\ninstances in the explanation space of our diagnostic classifier amplifies the\ndifferent reasons for belonging to the same class - resulting in a\nrepresentation that is uniquely useful for discovering latent subtypes. We\ncompare our ability to recover subtypes via cluster analysis on model\nexplanations to classical cluster analysis on the original data. In multiple\ndatasets with known ground-truth subclasses, most compellingly on UK Biobank\nbrain imaging data and transcriptome data from the Cancer Genome Atlas, we show\nthat cluster analysis on model explanations substantially outperforms the\nclassical approach. While we believe clustering in explanation space to be\nparticularly valuable for inferring disease subtypes, the method is more\ngeneral and applicable to any kind of sub-type identification.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:39:56 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 23:05:20 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Schulz", "Marc-Andre", ""], ["Chapman-Rounds", "Matt", ""], ["Verma", "Manisha", ""], ["Bzdok", "Danilo", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1912.08756", "submitter": "Jing Li", "authors": "Soroosh Khoram, Stephen J Wright, Jing Li", "title": "Interleaved Composite Quantization for High-Dimensional Similarity\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search retrieves the nearest neighbors of a query vector from a\ndataset of high-dimensional vectors. As the size of the dataset grows, the cost\nof performing the distance computations needed to implement a query can become\nprohibitive. A method often used to reduce this computational cost is\nquantization of the vector space and location-based encoding of the dataset\nvectors. These encodings can be used during query processing to find\napproximate nearest neighbors of the query point quickly. Search speed can be\nimproved by using shorter codes, but shorter codes have higher quantization\nerror, leading to degraded precision. In this work, we propose the Interleaved\nComposite Quantization (ICQ) which achieves fast similarity search without\nusing shorter codes. In ICQ, a small subset of the code is used to approximate\nthe distances, with complete codes being used only when necessary. Our method\neffectively reduces both code length and quantization error. Furthermore, ICQ\nis compatible with several recently proposed techniques for reducing\nquantization error and can be used in conjunction with these other techniques\nto improve results. We confirm these claims and show strong empirical\nperformance of ICQ using several synthetic and real-word datasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:40:56 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 01:41:50 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Khoram", "Soroosh", ""], ["Wright", "Stephen J", ""], ["Li", "Jing", ""]]}, {"id": "1912.08765", "submitter": "Muhammed Talo", "authors": "Muhammed Talo", "title": "An Automated Deep Learning Approach for Bacterial Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automated recognition and classification of bacteria species from microscopic\nimages have significant importance in clinical microbiology. Bacteria\nclassification is usually carried out manually by biologists using different\nshapes and morphologic characteristics of bacteria species. The manual taxonomy\nof bacteria types from microscopy images is time-consuming and a challenging\ntask for even experienced biologists. In this study, an automated deep learning\nbased classification approach has been proposed to classify bacterial images\ninto different categories. The ResNet-50 pre-trained CNN architecture has been\nused to classify digital bacteria images into 33 categories. The transfer\nlearning technique was employed to accelerate the training process of the\nnetwork and improve the classification performance of the network. The proposed\nmethod achieved an average classification accuracy of 99.2%. The experimental\nresults demonstrate that the proposed technique surpasses state-of-the-art\nmethods in the literature and can be used for any type of bacteria\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 20:38:31 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Talo", "Muhammed", ""]]}, {"id": "1912.08766", "submitter": "Varun Nair", "authors": "Varun Nair, Javier Fuentes Alonso, Tony Beltramelli", "title": "RealMix: Towards Realistic Semi-Supervised Deep Learning Algorithms", "comments": "Code available at https://github.com/uizard-technologies/realmix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-Supervised Learning (SSL) algorithms have shown great potential in\ntraining regimes when access to labeled data is scarce but access to unlabeled\ndata is plentiful. However, our experiments illustrate several shortcomings\nthat prior SSL algorithms suffer from. In particular, poor performance when\nunlabeled and labeled data distributions differ. To address these observations,\nwe develop RealMix, which achieves state-of-the-art results on standard\nbenchmark datasets across different labeled and unlabeled set sizes while\novercoming the aforementioned challenges. Notably, RealMix achieves an error\nrate of 9.79% on CIFAR10 with 250 labels and is the only SSL method tested able\nto surpass baseline performance when there is significant mismatch in the\nlabeled and unlabeled data distributions. RealMix demonstrates how SSL can be\nused in real world situations with limited access to both data and compute and\nguides further research in SSL with practical applicability in mind.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:03:28 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Nair", "Varun", ""], ["Alonso", "Javier Fuentes", ""], ["Beltramelli", "Tony", ""]]}, {"id": "1912.08771", "submitter": "Nick Johnston", "authors": "Nick Johnston, Elad Eban, Ariel Gordon, Johannes Ball\\'e", "title": "Computationally Efficient Neural Image Compression", "comments": "In submission to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image compression using neural networks have reached or exceeded non-neural\nmethods (such as JPEG, WebP, BPG). While these networks are state of the art in\nratedistortion performance, computational feasibility of these models remains a\nchallenge. We apply automatic network optimization techniques to reduce the\ncomputational complexity of a popular architecture used in neural image\ncompression, analyze the decoder complexity in execution runtime and explore\nthe trade-offs between two distortion metrics, rate-distortion performance and\nrun-time performance to design and research more computationally efficient\nneural image compression. We find that our method decreases the decoder\nrun-time requirements by over 50% for a stateof-the-art neural architecture.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:09:20 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Johnston", "Nick", ""], ["Eban", "Elad", ""], ["Gordon", "Ariel", ""], ["Ball\u00e9", "Johannes", ""]]}, {"id": "1912.08776", "submitter": "Byungsoo Kim", "authors": "Simon Biland, Vinicius C. Azevedo, Byungsoo Kim and Barbara\n  Solenthaler", "title": "Frequency-Aware Reconstruction of Fluid Simulations with Generative\n  Networks", "comments": "Submitted to Eurographics2020", "journal-ref": "Eurographics 2020 - Short Papers", "doi": "10.2312/egs.20201019", "report-no": null, "categories": "cs.LG cs.GR physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks were recently employed to fully reconstruct\nfluid simulation data from a set of reduced parameters. However, since\n(de-)convolutions traditionally trained with supervised L1-loss functions do\nnot discriminate between low and high frequencies in the data, the error is not\nminimized efficiently for higher bands. This directly correlates with the\nquality of the perceived results, since missing high frequency details are\neasily noticeable. In this paper, we analyze the reconstruction quality of\ngenerative networks and present a frequency-aware loss function that is able to\nfocus on specific bands of the dataset during training time. We show that our\napproach improves reconstruction quality of fluid simulation data in\nmid-frequency bands, yielding perceptually better results while requiring\ncomparable training time.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:13:22 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Biland", "Simon", ""], ["Azevedo", "Vinicius C.", ""], ["Kim", "Byungsoo", ""], ["Solenthaler", "Barbara", ""]]}, {"id": "1912.08785", "submitter": "Piotr S. Maci\\k{a}g", "authors": "Piotr S. Maci\\k{a}g (1), Marzena Kryszkiewicz (1), Robert Bembenik\n  (1), Jesus L. Lobo (2), Javier Del Ser (2 and 3) ((1) Institute of Computer\n  Science, Warsaw University of Technology, Warsaw, Poland, (2) TECNALIA Parque\n  Tecnol\\'ogico de Bizkaia, Derio, Spain, (3) University of the Basque Country\n  UPV/EHU, Bilbao, Spain)", "title": "Unsupervised Anomaly Detection in Stream Data with Online Evolving\n  Spiking Neural Networks", "comments": "52 pages", "journal-ref": "Neural Networks, Volume 139, 2021, Pages 118-139", "doi": "10.1016/j.neunet.2021.02.017", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unsupervised anomaly discovery in stream data is a research topic with many\npractical applications. However, in many cases, it is not easy to collect\nenough training data with labeled anomalies for supervised learning of an\nanomaly detector in order to deploy it later for identification of real\nanomalies in streaming data. It is thus important to design anomalies detectors\nthat can correctly detect anomalies without access to labeled training data.\nOur idea is to adapt the Online evolving Spiking Neural Network (OeSNN)\nclassifier to the anomaly detection task. As a result, we offer an Online\nevolving Spiking Neural Network for Unsupervised Anomaly Detection algorithm\n(OeSNN-UAD), which, unlike OeSNN, works in an unsupervised way and does not\nseparate output neurons into disjoint decision classes. OeSNN-UAD uses our\nproposed new two-step anomaly detection method. Also, we derive new theoretical\nproperties of neuronal model and input layer encoding of OeSNN, which enable\nmore effective and efficient detection of anomalies in our OeSNN-UAD approach.\nThe proposed OeSNN-UAD detector was experimentally compared with\nstate-of-the-art unsupervised and semi-supervised detectors of anomalies in\nstream data from the Numenta Anomaly Benchmark and Yahoo Anomaly Datasets\nrepositories. Our approach outperforms the other solutions provided in the\nliterature in the case of data streams from the Numenta Anomaly Benchmark\nrepository. Also, in the case of real data files of the Yahoo Anomaly Benchmark\nrepository, OeSNN-UAD outperforms other selected algorithms, whereas in the\ncase of Yahoo Anomaly Benchmark synthetic data files, it provides competitive\nresults to the results recently reported in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:36:01 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 20:17:42 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Maci\u0105g", "Piotr S.", "", "2 and 3"], ["Kryszkiewicz", "Marzena", "", "2 and 3"], ["Bembenik", "Robert", "", "2 and 3"], ["Lobo", "Jesus L.", "", "2 and 3"], ["Del Ser", "Javier", "", "2 and 3"]]}, {"id": "1912.08791", "submitter": "Firuz Kamalov", "authors": "Firuz Kamalov", "title": "Forecasting significant stock price changes using neural networks", "comments": null, "journal-ref": "Neural Computing and Applications (2020)", "doi": "10.1007/s00521-020-04942-3", "report-no": null, "categories": "q-fin.TR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock price prediction is a rich research topic that has attracted interest\nfrom various areas of science. The recent success of machine learning in speech\nand image recognition has prompted researchers to apply these methods to asset\nprice prediction. The majority of literature has been devoted to predicting\neither the actual asset price or the direction of price movement. In this\npaper, we study a hitherto little explored question of predicting significant\nchanges in stock price based on previous changes using machine learning\nalgorithms. We are particularly interested in the performance of neural network\nclassifiers in the given context. To this end, we construct and test three\nneural network models including multi-layer perceptron, convolutional net, and\nlong short term memory net. As benchmark models we use random forest and\nrelative strength index methods. The models are tested using 10-year daily\nstock price data of four major US public companies. Test results show that\npredicting significant changes in stock price can be accomplished with a high\ndegree of accuracy. In particular, we obtain substantially better results than\nsimilar studies that forecast the direction of price change.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:48:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kamalov", "Firuz", ""]]}, {"id": "1912.08792", "submitter": "Jing Li", "authors": "Soroosh Khoram, Jing Li", "title": "TOCO: A Framework for Compressing Neural Network Models Based on\n  Tolerance Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network compression methods have enabled deploying large models on\nemerging edge devices with little cost, by adapting already-trained models to\nthe constraints of these devices. The rapid development of AI-capable edge\ndevices with limited computation and storage requires streamlined methodologies\nthat can efficiently satisfy the constraints of different devices. In contrast,\nexisting methods often rely on heuristic and manual adjustments to maintain\naccuracy, support only coarse compression policies, or target specific device\nconstraints that limit their applicability. We address these limitations by\nproposing the TOlerance-based COmpression (TOCO) framework. TOCO uses an\nin-depth analysis of the model, to maintain the accuracy, in an active learning\nsystem. The results of the analysis are tolerances that can be used to perform\ncompression in a fine-grained manner. Finally, by decoupling compression from\nthe tolerance analysis, TOCO allows flexibility to changes in the hardware.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:45:47 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 01:40:30 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Khoram", "Soroosh", ""], ["Li", "Jing", ""]]}, {"id": "1912.08795", "submitter": "Hongxu Yin", "authors": "Hongxu Yin, Pavlo Molchanov, Zhizhong Li, Jose M. Alvarez, Arun\n  Mallya, Derek Hoiem, Niraj K. Jha and Jan Kautz", "title": "Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DeepInversion, a new method for synthesizing images from the\nimage distribution used to train a deep neural network. We 'invert' a trained\nnetwork (teacher) to synthesize class-conditional input images starting from\nrandom noise, without using any additional information about the training\ndataset. Keeping the teacher fixed, our method optimizes the input while\nregularizing the distribution of intermediate feature maps using information\nstored in the batch normalization layers of the teacher. Further, we improve\nthe diversity of synthesized images using Adaptive DeepInversion, which\nmaximizes the Jensen-Shannon divergence between the teacher and student network\nlogits. The resulting synthesized images from networks trained on the CIFAR-10\nand ImageNet datasets demonstrate high fidelity and degree of realism, and help\nenable a new breed of data-free applications - ones that do not require any\nreal images or labeled data. We demonstrate the applicability of our proposed\nmethod to three tasks of immense practical importance -- (i) data-free network\npruning, (ii) data-free knowledge transfer, and (iii) data-free continual\nlearning. Code is available at https://github.com/NVlabs/DeepInversion\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:50:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:30:21 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yin", "Hongxu", ""], ["Molchanov", "Pavlo", ""], ["Li", "Zhizhong", ""], ["Alvarez", "Jose M.", ""], ["Mallya", "Arun", ""], ["Hoiem", "Derek", ""], ["Jha", "Niraj K.", ""], ["Kautz", "Jan", ""]]}, {"id": "1912.08808", "submitter": "Artem Lutov", "authors": "Artem Lutov, Dingqi Yang and Philippe Cudr\\'e-Mauroux", "title": "Bridging the Gap between Community and Node Representations: Graph\n  Embedding via Community Detection", "comments": "IEEE BigData'19, Special Session on Information Granulation in Data\n  Science and Scalable Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph embedding has become a key component of many data mining and analysis\nsystems. Current graph embedding approaches either sample a large number of\nnode pairs from a graph to learn node embeddings via stochastic optimization or\nfactorize a high-order proximity/adjacency matrix of the graph via\ncomputationally expensive matrix factorization techniques. These approaches\ntypically require significant resources for the learning process and rely on\nmultiple parameters, which limits their applicability in practice. Moreover,\nmost of the existing graph embedding techniques operate effectively in one\nspecific metric space only (e.g., the one produced with cosine similarity), do\nnot preserve higher-order structural features of the input graph and cannot\nautomatically determine a meaningful number of embedding dimensions. Typically,\nthe produced embeddings are not easily interpretable, which complicates further\nanalyses and limits their applicability. To address these issues, we propose\nDAOR, a highly efficient and parameter-free graph embedding technique producing\nmetric space-robust, compact and interpretable embeddings without any manual\ntuning. Compared to a dozen state-of-the-art graph embedding algorithms, DAOR\nyields competitive results on both node classification (which benefits form\nhigh-order proximity) and link prediction (which relies on low-order proximity\nmostly). Unlike existing techniques, however, DAOR does not require any\nparameter tuning and improves the embeddings generation speed by several orders\nof magnitude. Our approach has hence the ambition to greatly simplify and speed\nup data analysis tasks involving graph representation learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:14:48 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Lutov", "Artem", ""], ["Yang", "Dingqi", ""], ["Cudr\u00e9-Mauroux", "Philippe", ""]]}, {"id": "1912.08809", "submitter": "Joy Bose", "authors": "Joy Bose", "title": "Field Label Prediction for Autofill in Web Browsers", "comments": "3 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic form fill is an important productivity related feature present in\nmajor web browsers, which predicts the field labels of a web form and\nautomatically fills values in a new form based on the values previously filled\nfor the same field in other forms. This feature increases the convenience and\nefficiency of users who have to fill similar information in fields in multiple\nforms. In this paper we describe a machine learning solution for predicting the\nform field labels, implemented as a web service using Azure ML Studio.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 22:55:06 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bose", "Joy", ""]]}, {"id": "1912.08812", "submitter": "Teofilo de Campos", "authors": "Frederico Guth and Teofilo Emidio de-Campos", "title": "Research Frontiers in Transfer Learning -- a systematic and bibliometric\n  review", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn from very few samples, demonstrating an outstanding\ngeneralization ability that learning algorithms are still far from reaching.\nCurrently, the most successful models demand enormous amounts of well-labeled\ndata, which are expensive and difficult to obtain, becoming one of the biggest\nobstacles to the use of machine learning in practice. This scenario shows the\nmassive potential for Transfer Learning, which aims to harness previously\nacquired knowledge to the learning of new tasks more effectively and\nefficiently. In this systematic review, we apply a quantitative method to\nselect the main contributions to the field and make use of bibliographic\ncoupling metrics to identify research frontiers. We further analyze the\nlinguistic variation between the classics of the field and the frontier and map\npromising research directions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:08:19 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Guth", "Frederico", ""], ["de-Campos", "Teofilo Emidio", ""]]}, {"id": "1912.08813", "submitter": "Jos\\'e A. Ch\\'avez Alvarez", "authors": "Jos\\'e Ch\\'avez, Rensso Mora and Edward Cayllahua-Cahuina", "title": "Ambient Lighting Generation for Flash Images with Guided Conditional\n  Adversarial Networks", "comments": "VISAPP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the challenges that low light conditions produce in images,\nphotographers tend to use the light provided by the camera flash to get better\nillumination. Nevertheless, harsh shadows and non-uniform illumination can\narise from using a camera flash, especially in low light conditions. Previous\nstudies have focused on normalizing the lighting on flash images; however, to\nthe best of our knowledge, no prior studies have examined the sideways shadows\nremoval, reconstruction of overexposed areas, and the generation of synthetic\nambient shadows or natural tone of scene objects. To provide more natural\nillumination on flash images and ensure high-frequency details, we propose a\ngenerative adversarial network in a guided conditional mode. We show that this\napproach not only generates natural illumination but also attenuates harsh\nshadows, simultaneously generating synthetic ambient shadows. Our approach\nachieves promising results on a custom FAID dataset, outperforming our baseline\nstudies. We also analyze the components of our proposal and how they affect the\noverall performance and discuss the opportunities for future work.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:58:29 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 02:44:18 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 23:25:23 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 12:33:16 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 22:12:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ch\u00e1vez", "Jos\u00e9", ""], ["Mora", "Rensso", ""], ["Cayllahua-Cahuina", "Edward", ""]]}, {"id": "1912.08830", "submitter": "Dave Zhenyu Chen", "authors": "Dave Zhenyu Chen, Angel X. Chang, Matthias Nie{\\ss}ner", "title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language", "comments": "Project page: https://daveredrum.github.io/ScanRefer/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of 3D object localization in RGB-D scans using natural\nlanguage descriptions. As input, we assume a point cloud of a scanned 3D scene\nalong with a free-form description of a specified target object. To address\nthis task, we propose ScanRefer, learning a fused descriptor from 3D object\nproposals and encoded sentence embeddings. This fused descriptor correlates\nlanguage expressions with geometric features, enabling regression of the 3D\nbounding box of a target object. We also introduce the ScanRefer dataset,\ncontaining 51,583 descriptions of 11,046 objects from 800 ScanNet scenes.\nScanRefer is the first large-scale effort to perform object localization via\nnatural language expression directly in 3D.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 19:00:49 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 21:41:53 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 09:33:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chen", "Dave Zhenyu", ""], ["Chang", "Angel X.", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "1912.08860", "submitter": "Emmanuel Kahembwe", "authors": "Emmanuel Kahembwe, Subramanian Ramamoorthy", "title": "Lower Dimensional Kernels for Video Discriminators", "comments": null, "journal-ref": "Neural.Networks 132 (2020) 506-520", "doi": "10.1016/j.neunet.2020.09.016", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an analysis of the discriminators used in Generative\nAdversarial Networks (GANs) for Video. We show that unconstrained video\ndiscriminator architectures induce a loss surface with high curvature which\nmake optimisation difficult. We also show that this curvature becomes more\nextreme as the maximal kernel dimension of video discriminators increases. With\nthese observations in hand, we propose a family of efficient Lower-Dimensional\nVideo Discriminators for GANs (LDVD GANs). The proposed family of\ndiscriminators improve the performance of video GAN models they are applied to\nand demonstrate good performance on complex and diverse datasets such as\nUCF-101. In particular, we show that they can double the performance of\nTemporal-GANs and provide for state-of-the-art performance on a single GPU.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 19:54:02 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kahembwe", "Emmanuel", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1912.08864", "submitter": "Sheroze Sheriffdeen", "authors": "Sheroze Sheriffdeen, Jean C. Ragusa, Jim E. Morel, Marvin L. Adams,\n  Tan Bui-Thanh", "title": "Accelerating PDE-constrained Inverse Solutions with Deep Learning and\n  Reduced Order Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems are pervasive mathematical methods in inferring knowledge\nfrom observational and experimental data by leveraging simulations and models.\nUnlike direct inference methods, inverse problem approaches typically require\nmany forward model solves usually governed by Partial Differential Equations\n(PDEs). This a crucial bottleneck in determining the feasibility of such\nmethods. While machine learning (ML) methods, such as deep neural networks\n(DNNs), can be employed to learn nonlinear forward models, designing a network\narchitecture that preserves accuracy while generalizing to new parameter\nregimes is a daunting task. Furthermore, due to the computation-expensive\nnature of forward models, state-of-the-art black-box ML methods would require\nan unrealistic amount of work in order to obtain an accurate surrogate model.\nOn the other hand, standard Reduced-Order Models (ROMs) accurately capture\nsupposedly important physics of the forward model in the reduced subspaces, but\notherwise could be inaccurate elsewhere. In this paper, we propose to enlarge\nthe validity of ROMs and hence improve the accuracy outside the reduced\nsubspaces by incorporating a data-driven ML technique. In particular, we focus\non a goal-oriented approach that substantially improves the accuracy of reduced\nmodels by learning the error between the forward model and the ROM outputs.\nOnce an ML-enhanced ROM is constructed it can accelerate the performance of\nsolving many-query problems in parametrized forward and inverse problems.\nNumerical results for inverse problems governed by elliptic PDEs and\nparametrized neutron transport equations will be presented to support our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 13:45:29 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Sheriffdeen", "Sheroze", ""], ["Ragusa", "Jean C.", ""], ["Morel", "Jim E.", ""], ["Adams", "Marvin L.", ""], ["Bui-Thanh", "Tan", ""]]}, {"id": "1912.08865", "submitter": "Zetong Qi", "authors": "Zetong Qi, T.J. Wilder", "title": "Adversarial VC-dimension and Sample Complexity of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks during the testing phase of neural networks pose a\nchallenge for the deployment of neural networks in security critical settings.\nThese attacks can be performed by adding noise that is imperceptible to humans\non top of the original data. By doing so, an attacker can create an adversarial\nsample, which will cause neural networks to misclassify. In this paper, we seek\nto understand the theoretical limits of what can be learned by neural networks\nin the presence of an adversary. We first defined the hypothesis space of a\nneural network, and showed the relationship between the growth number of the\nentire neural network and the growth number of each neuron. Combine that with\nthe adversarial Vapnik-Chervonenkis(VC)-dimension of halfspace classifiers, we\nconcluded the adversarial VC-dimension of the neural networks with sign\nactivation functions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:10:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Qi", "Zetong", ""], ["Wilder", "T. J.", ""]]}, {"id": "1912.08866", "submitter": "James Harrison", "authors": "James Harrison, Apoorva Sharma, Chelsea Finn, Marco Pavone", "title": "Continuous Meta-Learning without Tasks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a promising strategy for learning to efficiently learn\nwithin new tasks, using data gathered from a distribution of tasks. However,\nthe meta-learning literature thus far has focused on the task segmented\nsetting, where at train-time, offline data is assumed to be split according to\nthe underlying task, and at test-time, the algorithms are optimized to learn in\na single task. In this work, we enable the application of generic meta-learning\nalgorithms to settings where this task segmentation is unavailable, such as\ncontinual online learning with a time-varying task. We present meta-learning\nvia online changepoint analysis (MOCA), an approach which augments a\nmeta-learning algorithm with a differentiable Bayesian changepoint detection\nscheme. The framework allows both training and testing directly on time series\ndata without segmenting it into discrete tasks. We demonstrate the utility of\nthis approach on a nonlinear meta-regression benchmark as well as two\nmeta-image-classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:10:40 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 00:14:30 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Harrison", "James", ""], ["Sharma", "Apoorva", ""], ["Finn", "Chelsea", ""], ["Pavone", "Marco", ""]]}, {"id": "1912.08868", "submitter": "Rashid Mehdiyev Dr", "authors": "Rashid Mehdiyev, Jean Nava, Karan Sodhi, Saurav Acharya, Annie Ibrahim\n  Rana", "title": "Topic subject creation using unsupervised learning for topic modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the use of Non-Negative Matrix Factorization (NMF) and Latent\nDirichlet Allocation (LDA) algorithms to perform topic mining and labelling\napplied to retail customer communications in attempt to characterize the\nsubject of customers inquiries. In this paper we compare both algorithms in the\ntopic mining performance and propose methods to assign topic subject labels in\nan automated way.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:11:03 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mehdiyev", "Rashid", ""], ["Nava", "Jean", ""], ["Sodhi", "Karan", ""], ["Acharya", "Saurav", ""], ["Rana", "Annie Ibrahim", ""]]}, {"id": "1912.08869", "submitter": "Neil Dhir", "authors": "Mathias Edman and Neil Dhir", "title": "Boltzmann Exploration Expectation-Maximisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general method for fitting finite mixture models (FMM). Learning\nin a mixture model consists of finding the most likely cluster assignment for\neach data-point, as well as finding the parameters of the clusters themselves.\nIn many mixture models, this is difficult with current learning methods, where\nthe most common approach is to employ monotone learning algorithms e.g. the\nconventional expectation-maximisation algorithm. While effective, the success\nof any monotone algorithm is crucially dependant on good parameter\ninitialisation, where a common choice is $K$-means initialisation, commonly\nemployed for Gaussian mixture models.\n  For other types of mixture models, the path to good initialisation parameters\nis often unclear and may require a problem-specific solution. To this end, we\npropose a general heuristic learning algorithm that utilises Boltzmann\nexploration to assign each observation to a specific base distribution within\nthe mixture model, which we call Boltzmann exploration expectation-maximisation\n(BEEM). With BEEM, hard assignments allow straight forward parameter learning\nfor each base distribution by conditioning only on its assigned observations.\nConsequently, it can be applied to mixtures of any base distribution where\nsingle component parameter learning is tractable. The stochastic learning\nprocedure is able to escape local optima and is thus insensitive to parameter\ninitialisation. We show competitive performance on a number of synthetic\nbenchmark cases as well as on real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:15:04 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Edman", "Mathias", ""], ["Dhir", "Neil", ""]]}, {"id": "1912.08881", "submitter": "Sebastian Lapuschkin", "authors": "Seul-Ki Yeom, Philipp Seegerer, Sebastian Lapuschkin, Alexander\n  Binder, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Pruning by Explaining: A Novel Criterion for Deep Neural Network Pruning", "comments": "25 pages + 5 supplementary pages, 13 figures, 6 tables", "journal-ref": "Pattern Recognition, Volume 115, pp.107899, 2021", "doi": "10.1016/j.patcog.2021.107899", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of convolutional neural networks (CNNs) in various applications\nis accompanied by a significant increase in computation and parameter storage\ncosts. Recent efforts to reduce these overheads involve pruning and compressing\nthe weights of various layers while at the same time aiming to not sacrifice\nperformance. In this paper, we propose a novel criterion for CNN pruning\ninspired by neural network interpretability: The most relevant units, i.e.\nweights or filters, are automatically found using their relevance scores\nobtained from concepts of explainable AI (XAI). By exploring this idea, we\nconnect the lines of interpretability and model compression research. We show\nthat our proposed method can efficiently prune CNN models in transfer-learning\nsetups in which networks pre-trained on large corpora are adapted to\nspecialized tasks. The method is evaluated on a broad range of computer vision\ndatasets. Notably, our novel criterion is not only competitive or better\ncompared to state-of-the-art pruning criteria when successive retraining is\nperformed, but clearly outperforms these previous criteria in the\nresource-constrained application scenario in which the data of the task to be\ntransferred to is very scarce and one chooses to refrain from fine-tuning. Our\nmethod is able to compress the model iteratively while maintaining or even\nimproving accuracy. At the same time, it has a computational cost in the order\nof gradient computation and is comparatively simple to apply without the need\nfor tuning hyperparameters for pruning.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:42:30 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:43:54 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 11:30:15 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Yeom", "Seul-Ki", ""], ["Seegerer", "Philipp", ""], ["Lapuschkin", "Sebastian", ""], ["Binder", "Alexander", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1912.08883", "submitter": "Zhongnan Qu", "authors": "Zhongnan Qu, Zimu Zhou, Yun Cheng, Lothar Thiele", "title": "Adaptive Loss-aware Quantization for Multi-bit Networks", "comments": "To appear in CVPR 2020; Code available at\n  https://github.com/zqu1992/ALQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the compression of deep neural networks by quantizing their\nweights and activations into multiple binary bases, known as multi-bit networks\n(MBNs), which accelerate the inference and reduce the storage for the\ndeployment on low-resource mobile and embedded platforms. We propose Adaptive\nLoss-aware Quantization (ALQ), a new MBN quantization pipeline that is able to\nachieve an average bitwidth below one-bit without notable loss in inference\naccuracy. Unlike previous MBN quantization solutions that train a quantizer by\nminimizing the error to reconstruct full precision weights, ALQ directly\nminimizes the quantization-induced error on the loss function involving neither\ngradient approximation nor full precision maintenance. ALQ also exploits\nstrategies including adaptive bitwidth, smooth bitwidth reduction, and\niterative trained quantization to allow a smaller network size without loss in\naccuracy. Experiment results on popular image datasets show that ALQ\noutperforms state-of-the-art compressed networks in terms of both storage and\naccuracy. Code is available at https://github.com/zqu1992/ALQ\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:48:29 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 17:11:11 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 22:31:11 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 20:24:41 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Qu", "Zhongnan", ""], ["Zhou", "Zimu", ""], ["Cheng", "Yun", ""], ["Thiele", "Lothar", ""]]}, {"id": "1912.08905", "submitter": "Prithvijit Chakrabarty", "authors": "Prithvijit Chakrabarty, Subhransu Maji", "title": "The Spectral Bias of the Deep Image Prior", "comments": "Bayesian Deep Learning Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"deep image prior\" proposed by Ulyanov et al. is an intriguing property\nof neural nets: a convolutional encoder-decoder network can be used as a prior\nfor natural images. The network architecture implicitly introduces a bias; If\nwe train the model to map white noise to a corrupted image, this bias guides\nthe model to fit the true image before fitting the corrupted regions.\n  This paper explores why the deep image prior helps in denoising natural\nimages. We present a novel method to analyze trajectories generated by the deep\nimage prior optimization and demonstrate:\n  (i) convolution layers of the an encoder-decoder decouple the frequency\ncomponents of the image, learning each at different rates\n  (ii) the model fits lower frequencies first, making early stopping behave as\na low pass filter.\n  The experiments study an extension of Cheng et al which showed that at\ninitialization, the deep image prior is equivalent to a stationary Gaussian\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 21:51:58 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Chakrabarty", "Prithvijit", ""], ["Maji", "Subhransu", ""]]}, {"id": "1912.08910", "submitter": "Nutta Homdee", "authors": "Nutta Homdee, Mehdi Boukhechba, Yixue W. Feng, Natalie Kramer, John\n  Lach, Laura E. Barnes", "title": "Enabling Smartphone-based Estimation of Heart Rate", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous, ubiquitous monitoring through wearable sensors has the potential\nto collect useful information about users' context. Heart rate is an important\nphysiologic measure used in a wide variety of applications, such as fitness\ntracking and health monitoring. However, wearable sensors that monitor heart\nrate, such as smartwatches and electrocardiogram (ECG) patches, can have gaps\nin their data streams because of technical issues (e.g., bad wireless channels,\nbattery depletion, etc.) or user-related reasons (e.g. motion artifacts, user\ncompliance, etc.). The ability to use other available sensor data (e.g.,\nsmartphone data) to estimate missing heart rate readings is useful to cope with\nany such gaps, thus improving data quality and continuity. In this paper, we\ntest the feasibility of estimating raw heart rate using smartphone sensor data.\nUsing data generated by 12 participants in a one-week study period, we were\nable to build both personalized and generalized models using regression, SVM,\nand random forest algorithms. All three algorithms outperformed the baseline\nmoving-average interpolation method for both personalized and generalized\nsettings. Moreover, our findings suggest that personalized models outperformed\nthe generalized models, which speaks to the importance of considering personal\nphysiology, behavior, and life style in the estimation of heart rate. The\npromising results provide preliminary evidence of the feasibility of combining\nsmartphone sensor data with wearable sensor data for continuous heart rate\nmonitoring.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 22:00:19 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Homdee", "Nutta", ""], ["Boukhechba", "Mehdi", ""], ["Feng", "Yixue W.", ""], ["Kramer", "Natalie", ""], ["Lach", "John", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1912.08914", "submitter": "Istv\\'an Ketyk\\'o", "authors": "Istv\\'an Ketyk\\'o and Ferenc Kov\\'acs", "title": "On the Metrics and Adaptation Methods for Domain Divergences of\n  sEMG-based Gesture Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new metric to measure domain divergence and a new domain\nadaptation method for time-series classification. The metric belongs to the\nclass of probability distributions-based metrics, is transductive, and does not\nassume the presence of source data samples. The 2-stage method utilizes an\nimproved autoregressive, RNN-based architecture with deep/non-linear\ntransformation. We assess our metric and the performance of our model in the\ncontext of sEMG/EMG-based gesture recognition under inter-session and\ninter-subject domain shifts.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 22:12:53 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Ketyk\u00f3", "Istv\u00e1n", ""], ["Kov\u00e1cs", "Ferenc", ""]]}, {"id": "1912.08917", "submitter": "Robert Bray", "authors": "Robert L. Bray", "title": "The Multisecretary Problem with Continuous Valuations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\cite{Arlotto2019} showed that regret in the multisecretary problem is\nbounded, both in the number of job openings, $ n $, and the number of\napplicants, $ k $, provided that the applicant valuations have finite support.\nI study what happens when applicant valuations have continuous support.\nSpecifically, I show that the regret grows like $ \\log(n) $ when valuations are\ndrawn from a standard uniform distribution. So the regret, while not finite,\nstill grows very slowly. However, the mechanism is completely different in this\nsetting: the agent makes a finite number of costly mistakes in the discrete\ncase, but makes an infinite number of nearly costless mistakes in the\ncontinuous case.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:43:37 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 19:40:42 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bray", "Robert L.", ""]]}, {"id": "1912.08919", "submitter": "Michael Franklin Mbouopda", "authors": "Michael Mbouopda (LIMOS), Engelbert Mephu Nguifo (LIMOS)", "title": "Classification des S{\\'e}ries Temporelles Incertaines par Transformation\n  Shapelet", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time serie classification is used in a diverse range of domain such as\nmeteorology, medicine and physics. It aims to classify chronological data. Many\naccurate approaches have been built during the last decade and shapelet\ntransformation is one of them. However, none of these approaches does take data\nuncertainty into account. Using uncertainty propagation techiniques, we propose\na new dissimilarity measure based on euclidean distance. We also show how to\nuse this new measure to adapt shapelet transformation to uncertain time series\nclassification. An experimental assessment of our contribution is done on some\nstate of the art datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:58:19 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mbouopda", "Michael", "", "LIMOS"], ["Nguifo", "Engelbert Mephu", "", "LIMOS"]]}, {"id": "1912.08920", "submitter": "Sakshi Udeshi", "authors": "Sakshi Udeshi, Xingbin Jiang, Sudipta Chattopadhyay", "title": "Callisto: Entropy based test generation and data quality assessment for\n  Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning (ML) has seen massive progress in the last decade and as a\nresult, there is a pressing need for validating ML-based systems. To this end,\nwe propose, design and evaluate CALLISTO - a novel test generation and data\nquality assessment framework. To the best of our knowledge, CALLISTO is the\nfirst blackbox framework to leverage the uncertainty in the prediction and\nsystematically generate new test cases for ML classifiers. Our evaluation of\nCALLISTO on four real world data sets reveals thousands of errors. We also show\nthat leveraging the uncertainty in prediction can increase the number of\nerroneous test cases up to a factor of 20, as compared to when no such\nknowledge is used for testing.\n  CALLISTO has the capability to detect low quality data in the datasets that\nmay contain mislabelled data. We conduct and present an extensive user study to\nvalidate the results of CALLISTO on identifying low quality data from four\nstate-of-the-art real world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 06:20:18 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Udeshi", "Sakshi", ""], ["Jiang", "Xingbin", ""], ["Chattopadhyay", "Sudipta", ""]]}, {"id": "1912.08921", "submitter": "Diego Pinheiro", "authors": "Diego Pinheiro, Ryan Hartman, Erick Romero, Ronaldo Menezes, Martin\n  Cadeiras", "title": "Network-Based Delineation of Health Service Areas: A Comparative\n  Analysis of Community Detection Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Health Service Area (HSA) is a group of geographic regions served by\nsimilar health care facilities. The delineation of HSAs plays a pivotal role in\nthe characterization of health care services available in an area, enabling a\nbetter planning and regulation of health care services. Though Dartmouth HSAs\nhave been the standard delineation for decades, previous work has recently\nshown an improved HSA delineation using a network-based approach, in which HSAs\nare the communities extracted by the Louvain algorithm in hospital-patient\ndischarge networks. Given the existent heterogeneity of communities extracted\nby different community detection algorithms, a comparative analysis of\ncommunity detection algorithms for optimal HSA delineation is lacking. In this\nwork, we compared HSA delineations produced by community detection algorithms\nusing a large-scale dataset containing different types of hospital-patient\ndischarges spanning a 7-year period in US. Our results replicated the\nheterogeneity among community detection algorithms found in previous works, the\nimproved HSA delineation obtained by a network-based, and suggested that\nInfomap may be a more suitable community detection for HSA delineation since it\nfinds a high number of HSAs with high localization index and a low network\nconductance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 18:35:23 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Pinheiro", "Diego", ""], ["Hartman", "Ryan", ""], ["Romero", "Erick", ""], ["Menezes", "Ronaldo", ""], ["Cadeiras", "Martin", ""]]}, {"id": "1912.08922", "submitter": "Nuno Moniz", "authors": "Nuno Moniz", "title": "Real-time 2019 Portuguese Parliament Election Results Dataset", "comments": "Dataset Descriptor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents a data set describing the evolution of results in the\nPortuguese Parliamentary Elections of October 6$^{th}$ 2019. The data spans a\ntime interval of 4 hours and 25 minutes, in intervals of 5 minutes, concerning\nthe results of the 27 parties involved in the electoral event. The data set is\ntailored for predictive modelling tasks, mostly focused on numerical\nforecasting tasks. Regardless, it allows for other tasks such as ordinal\nregression or learn-to-rank.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 15:52:31 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Moniz", "Nuno", ""]]}, {"id": "1912.08925", "submitter": "Seonghyeon Lee", "authors": "Seonghyeon Lee, Chanyoung Park and Hwanjo Yu", "title": "BHIN2vec: Balancing the Type of Relation in Heterogeneous Information\n  Network", "comments": null, "journal-ref": "CIKM 2019", "doi": "10.1145/3357384.3357893", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The goal of network embedding is to transform nodes in a network to a\nlow-dimensional embedding vectors. Recently, heterogeneous network has shown to\nbe effective in representing diverse information in data. However,\nheterogeneous network embedding suffers from the imbalance issue, i.e. the size\nof relation types (or the number of edges in the network regarding the type) is\nimbalanced. In this paper, we devise a new heterogeneous network embedding\nmethod, called BHIN2vec, which considers the balance among all relation types\nin a network. We view the heterogeneous network embedding as simultaneously\nsolving multiple tasks in which each task corresponds to each relation type in\na network. After splitting the skip-gram loss into multiple losses\ncorresponding to different tasks, we propose a novel random-walk strategy to\nfocus on the tasks with high loss values by considering the relative training\nratio. Unlike previous random walk strategies, our proposed random-walk\nstrategy generates training samples according to the relative training ratio\namong different tasks, which results in a balanced training for the node\nembedding. Our extensive experiments on node classification and recommendation\ndemonstrate the superiority of BHIN2vec compared to the state-of-the-art\nmethods. Also, based on the relative training ratio, we analyze how much each\nrelation type is represented in the embedding space.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:25:44 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Lee", "Seonghyeon", ""], ["Park", "Chanyoung", ""], ["Yu", "Hwanjo", ""]]}, {"id": "1912.08926", "submitter": "Sardar Hamidian", "authors": "Sardar Hamidian and Mona T Diab", "title": "Rumor Detection and Classification for Twitter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the pervasiveness of online media data as a source of information\nverifying the validity of this information is becoming even more important yet\nquite challenging. Rumors spread a large quantity of misinformation on\nmicroblogs. In this study we address two common issues within the context of\nmicroblog social media. First we detect rumors as a type of misinformation\npropagation and next we go beyond detection to perform the task of rumor\nclassification. WE explore the problem using a standard data set. We devise\nnovel features and study their impact on the task. We experiment with various\nlevels of preprocessing as a precursor of the classification as well as\ngrouping of features. We achieve and f-measure of over 0.82 in RDC task in\nmixed rumors data set and 84 percent in a single rumor data set using a\ntwo-step classification approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:55:55 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Hamidian", "Sardar", ""], ["Diab", "Mona T", ""]]}, {"id": "1912.08927", "submitter": "Peiyuan Sun", "authors": "Peiyuan Sun", "title": "Hyperbolic Multiplex Network Embedding with Maps of Random Walk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on network embedding in hyperbolic space have proven\nsuccessful in several applications. However, nodes in real world networks tend\nto interact through several distinct channels. Simple aggregation or ignorance\nof this multiplexity will lead to misleading results. On the other hand, there\nexists redundant information between different interaction patterns between\nnodes. Recent research reveals the analogy between the community structure and\nthe hyperbolic coordinate. To learn each node's effective embedding\nrepresentation while reducing the redundancy of multiplex network, we then\npropose a unified framework combing multiplex network hyperbolic embedding and\nmultiplex community detection. The intuitive rationale is that high order node\nembedding approach is expected to alleviate the observed network's sparse and\nnoisy structure which will benefit the community detection task. On the\ncontrary, the improved community structure will also guide the node embedding\ntask. To incorporate the common features between channels while preserving\nunique features, a random walk approach which traversing in latent multiplex\nhyperbolic space is proposed to detect the community across channels and bridge\nthe connection between node embedding and community detection. The proposed\nframework is evaluated on several network tasks using different real world\ndataset. The results demonstrates that our framework is effective and\nefficiency compared with state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 10:39:08 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 17:23:06 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sun", "Peiyuan", ""]]}, {"id": "1912.08930", "submitter": "Kristijan Petrovski", "authors": "Tamara Dimitrova, Kristijan Petrovski and Ljupco Kocarev", "title": "Graphlets in Multiplex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We develop graphlet analysis for multiplex networks and discuss how this\nanalysis can be extended to multilayer and multilevel networks as well as to\ngraphs with node and/or link categorical attributes. The analysis has been\nadapted for two typical examples of multiplexes: economic trade data\nrepresented as a 957-plex network and 75 social networks each represented as a\n12-plex network. We show that wedges (open triads) occur more often in economic\ntrade networks than in social networks, indicating the tendency of a country to\nproduce/trade of a product in local structure of triads which are not closed.\nMoreover, our analysis provides evidence that the countries with small\ndiversity tend to form correlated triangles. Wedges also appear in the social\nnetworks, however the dominant graphlets in social networks are triangles\n(closed triads). If a multiplex structure indicates a strong tie, the graphlet\nanalysis provides another evidence for the concepts of strong/weak ties and\nstructural holes. In contrast to Granovetter's seminal work on the strength of\nweak ties, in which it has been documented that the wedges with only strong\nties are absent, here we show that for the analyzed 75 social networks, the\nwedges with only strong ties are not only present but also significantly\ncorrelated.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 19:11:14 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Dimitrova", "Tamara", ""], ["Petrovski", "Kristijan", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1912.08934", "submitter": "Mohammad Reza Zarei", "authors": "Mohammad Reza Zarei, Mohammad R. Moosavi", "title": "An Adaptive Similarity Measure to Tune Trust Influence in Memory-Based\n  Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the recommender systems is to provide relevant and potentially\ninteresting information to each user. This is fulfilled by utilizing the\nalready recorded tendencies of similar users or detecting items similar to\ninterested items of the user. Challenges such as data sparsity and cold start\nproblem are addressed in recent studies. Utilizing social information not only\nenhances the prediction accuracy but also tackles the data sparseness\nchallenges. In this paper, we investigate the impact of using direct and\nindirect trust information in a memory-based collaborative filtering\nrecommender system. An adaptive similarity measure is proposed and the\ncontribution of social information is tuned using two learning schemes, greedy\nand gradient-based optimization. The results of the proposed method are\ncompared with state-of-the-art memory-based and model-based CF approaches on\ntwo real-world datasets, Epinions and FilmTrust. The experiments show that our\nmethod is quite effective in designing an accurate and comprehensive\nrecommender system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 22:47:47 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zarei", "Mohammad Reza", ""], ["Moosavi", "Mohammad R.", ""]]}, {"id": "1912.08949", "submitter": "Chaopeng Shen", "authors": "Dapeng Feng, Kuai Fang, and Chaopeng Shen", "title": "Enhancing streamflow forecast and extracting insights using long-short\n  term memory networks with data integration at continental scales", "comments": null, "journal-ref": "Water Resources Research, 2020", "doi": "10.1029/2019WR026793", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent observations with varied schedules and types (moving average,\nsnapshot, or regularly spaced) can help to improve streamflow forecasts, but it\nis challenging to integrate them effectively. Based on a long short-term memory\n(LSTM) streamflow model, we tested multiple versions of a flexible procedure we\ncall data integration (DI) to leverage recent discharge measurements to improve\nforecasts. DI accepts lagged inputs either directly or through a convolutional\nneural network (CNN) unit. DI ubiquitously elevated streamflow forecast\nperformance to unseen levels, reaching a record continental-scale median\nNash-Sutcliffe Efficiency coefficient value of 0.86. Integrating moving-average\ndischarge, discharge from the last few days, or even average discharge from the\nprevious calendar month could all improve daily forecasts. Directly using\nlagged observations as inputs was comparable in performance to using the CNN\nunit. Importantly, we obtained valuable insights regarding hydrologic processes\nimpacting LSTM and DI performance. Before applying DI, the base LSTM model\nworked well in mountainous or snow-dominated regions, but less well in regions\nwith low discharge volumes (due to either low precipitation or high\nprecipitation-energy synchronicity) and large inter-annual storage variability.\nDI was most beneficial in regions with high flow autocorrelation: it greatly\nreduced baseflow bias in groundwater-dominated western basins and also improved\npeak prediction for basins with dynamical surface water storage, such as the\nPrairie Potholes or Great Lakes regions. However, even DI cannot elevate\nhigh-aridity basins with one-day flash peaks. Despite this limitation, there is\nmuch promise for a deep-learning-based forecast paradigm due to its\nperformance, automation, efficiency, and flexibility.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:44:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 19:22:43 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 12:26:30 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Feng", "Dapeng", ""], ["Fang", "Kuai", ""], ["Shen", "Chaopeng", ""]]}, {"id": "1912.08951", "submitter": "Amos Beimel", "authors": "Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheffet, Uri\n  Stemmer", "title": "The power of synergy in differential privacy: Combining a small curator\n  with local randomizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the desire to bridge the utility gap between local and trusted\ncurator models of differential privacy for practical applications, we initiate\nthe theoretical study of a hybrid model introduced by \"Blender\" [Avent et al.,\\\nUSENIX Security '17], in which differentially private protocols of n agents\nthat work in the local-model are assisted by a differentially private curator\nthat has access to the data of m additional users. We focus on the regime where\nm << n and study the new capabilities of this (m,n)-hybrid model. We show that,\ndespite the fact that the hybrid model adds no significant new capabilities for\nthe basic task of simple hypothesis-testing, there are many other tasks (under\na wide range of parameters) that can be solved in the hybrid model yet cannot\nbe solved either by the curator or by the local-users separately. Moreover, we\nexhibit additional tasks where at least one round of interaction between the\ncurator and the local-users is necessary -- namely, no hybrid model protocol\nwithout such interaction can solve these tasks. Taken together, our results\nshow that the combination of the local model with a small curator can become\npart of a promising toolkit for designing and implementing differential\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:49:11 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 17:49:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Beimel", "Amos", ""], ["Korolova", "Aleksandra", ""], ["Nissim", "Kobbi", ""], ["Sheffet", "Or", ""], ["Stemmer", "Uri", ""]]}, {"id": "1912.08956", "submitter": "Carola Doerr", "authors": "Jakob Bossek and Pascal Kerschke and Aneta Neumann and Frank Neumann\n  and Carola Doerr", "title": "One-Shot Decision-Making with and without Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot decision making is required in situations in which we can evaluate a\nfixed number of solution candidates but do not have any possibility for\nfurther, adaptive sampling. Such settings are frequently encountered in neural\nnetwork design, hyper-parameter optimization, and many simulation-based\nreal-world optimization tasks, in which evaluations are costly and time sparse.\nIt seems intuitive that well-distributed samples should be more meaningful in\none-shot decision making settings than uniform or grid-based samples, since\nthey show a better coverage of the decision space. In practice, quasi-random\ndesigns such as Latin Hypercube Samples and low-discrepancy point sets form\nindeed the state of the art, as confirmed by a number of recent studies and\ncompetitions. In this work we take a closer look into the correlation between\nthe distribution of the quasi-random designs and their performance in one-shot\ndecision making tasks, with the goal to investigate whether the assumed\ncorrelation between uniform distribution and performance can be confirmed. We\nstudy three different decision tasks: classic one-shot optimization (only the\nbest sample matters), one-shot optimization with surrogates (allowing to use\nsurrogate models for selecting a design that need not necessarily be one of the\nevaluated samples), and one-shot regression (i.e., function approximation, with\nminimization of mean squared error as objective). Our results confirm an\nadvantage of low-discrepancy designs for all three settings. The overall\ncorrelation, however, is rather weak. We complement our study by evolving\nproblem-specific samples that show significantly better performance for the\nregression task than the standard approaches based on low-discrepancy\nsequences, giving strong indication that significant performance gains over\nstate-of-the-art one-shot sampling techniques are possible.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:20:34 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 10:42:28 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Bossek", "Jakob", ""], ["Kerschke", "Pascal", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""], ["Doerr", "Carola", ""]]}, {"id": "1912.08957", "submitter": "Ruoyu Sun", "authors": "Ruoyu Sun", "title": "Optimization for deep learning: theory and algorithms", "comments": "38 pages of main body; 5 pages of appendix; 12 pages of references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When and why can a neural network be successfully trained? This article\nprovides an overview of optimization algorithms and theory for training neural\nnetworks. First, we discuss the issue of gradient explosion/vanishing and the\nmore general issue of undesirable spectrum, and then discuss practical\nsolutions including careful initialization and normalization methods. Second,\nwe review generic optimization methods used in training neural networks, such\nas SGD, adaptive gradient methods and distributed methods, and theoretical\nresults for these algorithms. Third, we review existing research on the global\nissues of neural network training, including results on bad local minima, mode\nconnectivity, lottery ticket hypothesis and infinite-width analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:23:18 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Sun", "Ruoyu", ""]]}, {"id": "1912.08974", "submitter": "Stefanie G\\\"unther", "authors": "Eric C. Cyr and Stefanie G\\\"unther and Jacob B. Schroder", "title": "Multilevel Initialization for Layer-Parallel Deep Neural Network\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates multilevel initialization strategies for training\nvery deep neural networks with a layer-parallel multigrid solver. The scheme is\nbased on the continuous interpretation of the training problem as a problem of\noptimal control, in which neural networks are represented as discretizations of\ntime-dependent ordinary differential equations. A key goal is to develop a\nmethod able to intelligently initialize the network parameters for the very\ndeep networks enabled by scalable layer-parallel training. To do this, we apply\na refinement strategy across the time domain, that is equivalent to refining in\nthe layer dimension. The resulting refinements create deep networks, with good\ninitializations for the network parameters coming from the coarser trained\nnetworks. We investigate the effectiveness of such multilevel \"nested\niteration\" strategies for network training, showing supporting numerical\nevidence of reduced run time for equivalent accuracy. In addition, we study\nwhether the initialization strategies provide a regularizing effect on the\noverall training process and reduce sensitivity to hyperparameters and\nrandomness in initial network parameters.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 01:28:41 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Cyr", "Eric C.", ""], ["G\u00fcnther", "Stefanie", ""], ["Schroder", "Jacob B.", ""]]}, {"id": "1912.08986", "submitter": "Nicholas Roberts", "authors": "Nicholas Roberts, Dian Ang Yap, Vinay Uday Prabhu", "title": "Deep Connectomics Networks: Neural Network Architectures Inspired by\n  Neuronal Networks", "comments": "Presented at the Real Neurons & Hidden Units Workshop, 33rd\n  Conference on Neural Information ProcessingSystems (NeurIPS 2019), Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interplay between inter-neuronal network topology and cognition has been\nstudied deeply by connectomics researchers and network scientists, which is\ncrucial towards understanding the remarkable efficacy of biological neural\nnetworks. Curiously, the deep learning revolution that revived neural networks\nhas not paid much attention to topological aspects. The architectures of deep\nneural networks (DNNs) do not resemble their biological counterparts in the\ntopological sense. We bridge this gap by presenting initial results of Deep\nConnectomics Networks (DCNs) as DNNs with topologies inspired by real-world\nneuronal networks. We show high classification accuracy obtained by DCNs whose\narchitecture was inspired by the biological neuronal networks of C. Elegans and\nthe mouse visual cortex.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 01:59:20 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Roberts", "Nicholas", ""], ["Yap", "Dian Ang", ""], ["Prabhu", "Vinay Uday", ""]]}, {"id": "1912.08987", "submitter": "Nicholas Roberts", "authors": "Nicholas Roberts, Vinay Uday Prabhu, Matthew McAteer", "title": "Model Weight Theft With Just Noise Inputs: The Curious Case of the\n  Petulant Attacker", "comments": "Presented at the Security and Privacy of Machine Learning Workshop,\n  36th International Conference on Machine Learning (ICML 2019), Long Beach,\n  California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the scenarios under which an attacker can claim that\n'Noise and access to the softmax layer of the model is all you need' to steal\nthe weights of a convolutional neural network whose architecture is already\nknown. We were able to achieve 96% test accuracy using the stolen MNIST model\nand 82% accuracy using the stolen KMNIST model learned using only i.i.d.\nBernoulli noise inputs. We posit that this theft-susceptibility of the weights\nis indicative of the complexity of the dataset and propose a new metric that\ncaptures the same. The goal of this dissemination is to not just showcase how\nfar knowing the architecture can take you in terms of model stealing, but to\nalso draw attention to this rather idiosyncratic weight learnability aspects of\nCNNs spurred by i.i.d. noise input. We also disseminate some initial results\nobtained with using the Ising probability distribution in lieu of the i.i.d.\nBernoulli distribution.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 01:59:59 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Roberts", "Nicholas", ""], ["Prabhu", "Vinay Uday", ""], ["McAteer", "Matthew", ""]]}, {"id": "1912.08990", "submitter": "Jo\\\"el Seytre", "authors": "Jo\\\"el Seytre, Jon Wu, Alessandro Achille", "title": "TextTubes for Detecting Curved Text in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detector for curved text in natural images. We model scene text\ninstances as tubes around their medial axes and introduce a\nparametrization-invariant loss function. We train a two-stage curved text\ndetector, and evaluate it on the curved text benchmarks CTW-1500 and\nTotal-Text. Our approach achieves state-of-the-art results or improves upon\nthem, notably for CTW-1500 by over 8 percentage points in F-score.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 02:13:08 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Seytre", "Jo\u00ebl", ""], ["Wu", "Jon", ""], ["Achille", "Alessandro", ""]]}, {"id": "1912.08998", "submitter": "Yoshihiko Suhara", "authors": "Masahiro Kazama, Yoshihiko Suhara, Andrey Bogomolov, Alex `Sandy'\n  Pentland", "title": "Understanding Human Judgments of Causality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating between causality and correlation is a major problem in\nmachine learning, and theoretical tools for determining causality are still\nbeing developed. However, people commonly make causality judgments and are\noften correct, even in unfamiliar domains. What are humans doing to make these\njudgments? This paper examines differences in human experts' and non-experts'\nability to attribute causality by comparing their performances to those of\nmachine-learning algorithms. We collected human judgments by using Amazon\nMechanical Turk (MTurk) and then divided the human subjects into two groups:\nexperts and non-experts. We also prepared expert and non-expert machine\nalgorithms based on different training of convolutional neural network (CNN)\nmodels. The results showed that human experts' judgments were similar to those\nmade by an \"expert\" CNN model trained on a large number of examples from the\ntarget domain. The human non-experts' judgments resembled the prediction\noutputs of the CNN model that was trained on only the small number of examples\nused during the MTurk instruction. We also analyzed the differences between the\nexpert and non-expert machine algorithms based on their neural representations\nto evaluate the performances, providing insight into the human experts' and\nnon-experts' cognitive abilities.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 03:08:11 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Kazama", "Masahiro", ""], ["Suhara", "Yoshihiko", ""], ["Bogomolov", "Andrey", ""], ["Pentland", "Alex `Sandy'", ""]]}, {"id": "1912.09007", "submitter": "Pedro Sequeira", "authors": "Pedro Sequeira and Melinda Gervasio", "title": "Interestingness Elements for Explainable Reinforcement Learning:\n  Understanding Agents' Capabilities and Limitations", "comments": "To appear in: Artificial Intelligence", "journal-ref": null, "doi": "10.1016/j.artint.2020.103367", "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an explainable reinforcement learning (XRL) framework that\nanalyzes an agent's history of interaction with the environment to extract\ninterestingness elements that help explain its behavior. The framework relies\non data readily available from standard RL algorithms, augmented with data that\ncan easily be collected by the agent while learning. We describe how to create\nvisual summaries of an agent's behavior in the form of short video-clips\nhighlighting key interaction moments, based on the proposed elements. We also\nreport on a user study where we evaluated the ability of humans to correctly\nperceive the aptitude of agents with different characteristics, including their\ncapabilities and limitations, given visual summaries automatically generated by\nour framework. The results show that the diversity of aspects captured by the\ndifferent interestingness elements is crucial to help humans correctly\nunderstand an agent's strengths and limitations in performing a task, and\ndetermine when it might need adjustments to improve its performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 03:46:22 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 03:25:14 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Sequeira", "Pedro", ""], ["Gervasio", "Melinda", ""]]}, {"id": "1912.09009", "submitter": "Ravdeep Pasricha", "authors": "Ravdeep Pasricha, Ekta Gujral and Evangelos E. Papalexakis", "title": "Adaptive Granularity in Tensors: A Quest for Interpretable Structure", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data collected at very frequent intervals is usually extremely sparse and has\nno structure that is exploitable by modern tensor decomposition algorithms.\nThus the utility of such tensors is low, in terms of the amount of\ninterpretable and exploitable structure that one can extract from them. In this\npaper, we introduce the problem of finding a tensor of adaptive aggregated\ngranularity that can be decomposed to reveal meaningful latent concepts\n(structures) from datasets that, in their original form, are not amenable to\ntensor analysis. Such datasets fall under the broad category of sparse point\nprocesses that evolve over space and/or time. To the best of our knowledge,\nthis is the first work that explores adaptive granularity aggregation in\ntensors. Furthermore, we formally define the problem and discuss what different\ndefinitions of \"good structure\" can be in practice, and show that optimal\nsolution is of prohibitive combinatorial complexity. Subsequently, we propose\nan efficient and effective greedy algorithm which follows a number of intuitive\ndecision criteria that locally maximize the \"goodness of structure\", resulting\nin high-quality tensors. We evaluate our method on both semi-synthetic data\nwhere ground truth is known and real datasets for which we do not have any\nground truth. In both cases, our proposed method constructs tensors that have\nvery high structure quality. Finally, our proposed method is able to discover\ndifferent natural resolutions of a multi-aspect dataset, which can lead to\nmulti-resolution analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 04:07:42 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Pasricha", "Ravdeep", ""], ["Gujral", "Ekta", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1912.09015", "submitter": "Dongmyung Shin", "authors": "Dongmyung Shin, Sooyeon Ji, Doohee Lee, Jieun Lee, Se-Hong Oh, and\n  Jongho Lee", "title": "Deep Reinforcement Learning Designed Shinnar-Le Roux RF Pulse using\n  Root-Flipping: DeepRF_SLR", "comments": "Accepted at IEEE transactions on Medical Imaging\n  (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9174664)", "journal-ref": null, "doi": "10.1109/TMI.2020.3018508", "report-no": null, "categories": "cs.LG cs.AI eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach of applying deep reinforcement learning to an RF pulse\ndesign is introduced. This method, which is referred to as DeepRF_SLR, is\ndesigned to minimize the peak amplitude or, equivalently, minimize the pulse\nduration of a multiband refocusing pulse generated by the Shinar Le-Roux (SLR)\nalgorithm. In the method, the root pattern of SLR polynomial, which determines\nthe RF pulse shape, is optimized by iterative applications of deep\nreinforcement learning and greedy tree search. When tested for the designs of\nthe multiband factors of three and seven RFs, DeepRF_SLR demonstrated improved\nperformance compared to conventional methods, generating shorter duration RF\npulses in shorter computational time. In the experiments, the RF pulse from\nDeepRF_SLR produced a slice profile similar to the minimum-phase SLR RF pulse\nand the profiles matched to that of the computer simulation. Our approach\nsuggests a new way of designing an RF by applying a machine learning algorithm,\ndemonstrating a machine-designed MRI sequence.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 04:51:57 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:20:04 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 08:46:31 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Shin", "Dongmyung", ""], ["Ji", "Sooyeon", ""], ["Lee", "Doohee", ""], ["Lee", "Jieun", ""], ["Oh", "Se-Hong", ""], ["Lee", "Jongho", ""]]}, {"id": "1912.09026", "submitter": "Kelum Gajamannage", "authors": "Kelum Gajamannage and Randy Paffenroth", "title": "Bounded Manifold Completion", "comments": "12 pages, 7 figures, submitted to Pattern Recognition Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear dimensionality reduction or, equivalently, the approximation of\nhigh-dimensional data using a low-dimensional nonlinear manifold is an active\narea of research. In this paper, we will present a thematically different\napproach to detect the existence of a low-dimensional manifold of a given\ndimension that lies within a set of bounds derived from a given point cloud. A\nmatrix representing the appropriately defined distances on a low-dimensional\nmanifold is low-rank, and our method is based on current techniques for\nrecovering a partially observed matrix from a small set of fully observed\nentries that can be implemented as a low-rank Matrix Completion (MC) problem.\nMC methods are currently used to solve challenging real-world problems, such as\nimage inpainting and recommender systems, and we leverage extent efficient\noptimization techniques that use a nuclear norm convex relaxation as a\nsurrogate for non-convex and discontinuous rank minimization. Our proposed\nmethod provides several advantages over current nonlinear dimensionality\nreduction techniques, with the two most important being theoretical guarantees\non the detection of low-dimensional embeddings and robustness to non-uniformity\nin the sampling of the manifold. We validate the performance of this approach\nusing both a theoretical analysis as well as synthetic and real-world benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 05:42:21 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Gajamannage", "Kelum", ""], ["Paffenroth", "Randy", ""]]}, {"id": "1912.09033", "submitter": "Zhongjie Yu", "authors": "Zhongjie Yu, Lin Chen, Zhongwei Cheng, Jiebo Luo", "title": "TransMatch: A Transfer-Learning Scheme for Semi-Supervised Few-Shot\n  Learning", "comments": "Accepted at CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successful application of deep learning to many visual recognition tasks\nrelies heavily on the availability of a large amount of labeled data which is\nusually expensive to obtain. The few-shot learning problem has attracted\nincreasing attention from researchers for building a robust model upon only a\nfew labeled samples. Most existing works tackle this problem under the\nmeta-learning framework by mimicking the few-shot learning task with an\nepisodic training strategy. In this paper, we propose a new transfer-learning\nframework for semi-supervised few-shot learning to fully utilize the auxiliary\ninformation from labeled base-class data and unlabeled novel-class data. The\nframework consists of three components: 1) pre-training a feature extractor on\nbase-class data; 2) using the feature extractor to initialize the classifier\nweights for the novel classes; and 3) further updating the model with a\nsemi-supervised learning method. Under the proposed framework, we develop a\nnovel method for semi-supervised few-shot learning called TransMatch by\ninstantiating the three components with Imprinting and MixMatch. Extensive\nexperiments on two popular benchmark datasets for few-shot learning,\nCUB-200-2011 and miniImageNet, demonstrate that our proposed method can\neffectively utilize the auxiliary information from labeled base-class data and\nunlabeled novel-class data to significantly improve the accuracy of few-shot\nlearning task.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 06:50:45 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 19:25:18 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Yu", "Zhongjie", ""], ["Chen", "Lin", ""], ["Cheng", "Zhongwei", ""], ["Luo", "Jiebo", ""]]}, {"id": "1912.09040", "submitter": "Zichen Zhang", "authors": "Zichen Zhang, Qingfeng Lan, Lei Ding, Yue Wang, Negar Hassanpour,\n  Russell Greiner", "title": "Reducing Selection Bias in Counterfactual Reasoning for Individual\n  Treatment Effects Estimation", "comments": "NeurIPS 2019 Workshop on \"Do the right thing\": machine learning and\n  causal inference for improved decision making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual reasoning is an important paradigm applicable in many fields,\nsuch as healthcare, economics, and education. In this work, we propose a novel\nmethod to address the issue of \\textit{selection bias}. We learn two groups of\nlatent random variables, where one group corresponds to variables that only\ncause selection bias, and the other group is relevant for outcome prediction.\nThey are learned by an auto-encoder where an additional regularized loss based\non Pearson Correlation Coefficient (PCC) encourages the de-correlation between\nthe two groups of random variables. This allows for explicitly alleviating\nselection bias by only keeping the latent variables that are relevant for\nestimating individual treatment effects. Experimental results on a synthetic\ntoy dataset and a benchmark dataset show that our algorithm is able to achieve\nstate-of-the-art performance and improve the result of its counterpart that\ndoes not explicitly model the selection bias.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 07:10:00 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhang", "Zichen", ""], ["Lan", "Qingfeng", ""], ["Ding", "Lei", ""], ["Wang", "Yue", ""], ["Hassanpour", "Negar", ""], ["Greiner", "Russell", ""]]}, {"id": "1912.09043", "submitter": "Jeonghyeon Jang", "authors": "Jeonghyeon Jang, Hoon Lee, Sangwon Hwang, Haibao Ren, Inkyu Lee", "title": "Deep Learning-based Limited Feedback Designs for MIMO Systems", "comments": "to appear in IEEE Wireless Commun. Lett", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a deep learning (DL) based limited feedback methods for\nmulti-antenna systems. Deep neural networks (DNNs) are introduced to replace an\nend-to-end limited feedback procedure including pilot-aided channel training\nprocess, channel codebook design, and beamforming vector selection. The DNNs\nare trained to yield binary feedback information as well as an efficient\nbeamforming vector which maximizes the effective channel gain. Compared to\nconventional limited feedback schemes, the proposed DL method shows an 1 dB\nsymbol error rate (SER) gain with reduced computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 07:14:17 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Jang", "Jeonghyeon", ""], ["Lee", "Hoon", ""], ["Hwang", "Sangwon", ""], ["Ren", "Haibao", ""], ["Lee", "Inkyu", ""]]}, {"id": "1912.09068", "submitter": "Diego Granziol", "authors": "Diego Granziol, Robin Ru, Stefan Zohren, Xiaowen Dong, Michael\n  Osborne, Stephen Roberts", "title": "A Maximum Entropy approach to Massive Graph Spectra", "comments": "12 pages. 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph spectral techniques for measuring graph similarity, or for learning the\ncluster number, require kernel smoothing. The choice of kernel function and\nbandwidth are typically chosen in an ad-hoc manner and heavily affect the\nresulting output. We prove that kernel smoothing biases the moments of the\nspectral density. We propose an information theoretically optimal approach to\nlearn a smooth graph spectral density, which fully respects the moment\ninformation. Our method's computational cost is linear in the number of edges,\nand hence can be applied to large networks, with millions of nodes. We apply\nour method to the problems to graph similarity and cluster number learning,\nwhere we outperform comparable iterative spectral approaches on synthetic and\nreal graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 08:48:48 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Granziol", "Diego", ""], ["Ru", "Robin", ""], ["Zohren", "Stefan", ""], ["Dong", "Xiaowen", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1912.09083", "submitter": "Anton Akusok", "authors": "Anton Akusok, Kaj-Mikael Bj\\\"ork, Leonardo Espinosa Leal, Yoan Miche,\n  Renjie Hu and Amaury Lendasse", "title": "Spiking Networks for Improved Cognitive Abilities of Edge Computing\n  Devices", "comments": null, "journal-ref": "Proceedings of the 12th ACM International Conference on PErvasive\n  Technologies Related to Assistive Environments (PETRA '19). ACM, New York,\n  NY, USA, 307-308. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This concept paper highlights a recently opened opportunity for large scale\nanalytical algorithms to be trained directly on edge devices. Such approach is\na response to the arising need of processing data generated by natural person\n(a human being), also known as personal data. Spiking Neural networks are the\ncore method behind it: suitable for a low latency energy-constrained hardware,\nenabling local training or re-training, while not taking advantage of\nscalability available in the Cloud.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:36:00 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Akusok", "Anton", ""], ["Bj\u00f6rk", "Kaj-Mikael", ""], ["Leal", "Leonardo Espinosa", ""], ["Miche", "Yoan", ""], ["Hu", "Renjie", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1912.09086", "submitter": "Alexis Bellot", "authors": "Alexis Bellot, Mihaela van der Schaar", "title": "A Bayesian Approach to Modelling Longitudinal Data in Electronic Health\n  Records", "comments": "Presented as an abstract at the Machine Learning for Health Workshop,\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing electronic health records (EHR) poses significant challenges\nbecause often few samples are available describing a patient's health and, when\navailable, their information content is highly diverse. The problem we consider\nis how to integrate sparsely sampled longitudinal data, missing measurements\ninformative of the underlying health status and fixed demographic information\nto produce estimated survival distributions updated through a patient's follow\nup. We propose a nonparametric probabilistic model that generates survival\ntrajectories from an ensemble of Bayesian trees that learns variable\ninteractions over time without specifying beforehand the longitudinal process.\nWe show performance improvements on Primary Biliary Cirrhosis patient data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:42:27 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1912.09087", "submitter": "Anton Akusok", "authors": "Anton Akusok, Emil Eirola, Kaj-Mikael Bj\\\"ork and Amaury Lendasse", "title": "Extreme Learning Tree", "comments": null, "journal-ref": "Cao J., Vong C., Miche Y., Lendasse A. (eds) Proceedings of\n  ELM-2017. ELM 2017. Proceedings in Adaptation, Learning and Optimization, vol\n  10. Springer, Cham", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a new variant of a decision tree, called an Extreme\nLearning Tree. It consists of an extremely random tree with non-linear data\ntransformation, and a linear observer that provides predictions based on the\nleaf index where the data samples fall. The proposed method outperforms linear\nmodels on a benchmark dataset, and may be a building block for a future variant\nof Random Forest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:43:11 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Akusok", "Anton", ""], ["Eirola", "Emil", ""], ["Bj\u00f6rk", "Kaj-Mikael", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1912.09090", "submitter": "Anton Akusok", "authors": "Anton Akusok, Yoan Miche, Kaj-Mikael Bj\\\"ork and Amaury Lendasse", "title": "Per-sample Prediction Intervals for Extreme Learning Machines", "comments": null, "journal-ref": "Int. J. Mach. Learn. & Cyber. (2019) 10: 991", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction intervals in supervised Machine Learning bound the region where\nthe true outputs of new samples may fall. They are necessary in the task of\nseparating reliable predictions of a trained model from near random guesses,\nminimizing the rate of False Positives, and other problem-specific tasks in\napplied Machine Learning. Many real problems have heteroscedastic stochastic\noutputs, which explains the need of input-dependent prediction intervals.\n  This paper proposes to estimate the input-dependent prediction intervals by a\nseparate Extreme Learning Machine model, using variance of its predictions as a\ncorrection term accounting for the model uncertainty. The variance is estimated\nfrom the model's linear output layer with a weighted Jackknife method. The\nmethodology is very fast, robust to heteroscedastic outputs, and handles both\nextremely large datasets and insufficient amount of training data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:50:04 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Akusok", "Anton", ""], ["Miche", "Yoan", ""], ["Bj\u00f6rk", "Kaj-Mikael", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1912.09091", "submitter": "Haifeng Li", "authors": "Jian Peng, Bo Tang, Hao Jiang, Zhuo Li, Yinjie Lei, Tao Lin, Haifeng\n  Li", "title": "Overcoming Long-term Catastrophic Forgetting through Adversarial Neural\n  Pruning and Synaptic Consolidation", "comments": "14 pages, 11 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2021", "doi": "10.1109/TNNLS.2021.3056201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks face the well-known problem of catastrophic\nforgetting. What's worse, the degradation of previously learned skills becomes\nmore severe as the task sequence increases, known as the long-term catastrophic\nforgetting. It is due to two facts: first, as the model learns more tasks, the\nintersection of the low-error parameter subspace satisfying for these tasks\nbecomes smaller or even does not exist; second, when the model learns a new\ntask, the cumulative error keeps increasing as the model tries to protect the\nparameter configuration of previous tasks from interference. Inspired by the\nmemory consolidation mechanism in mammalian brains with synaptic plasticity, we\npropose a confrontation mechanism in which Adversarial Neural Pruning and\nsynaptic Consolidation (ANPyC) is used to overcome the long-term catastrophic\nforgetting issue. The neural pruning acts as long-term depression to prune\ntask-irrelevant parameters, while the novel synaptic consolidation acts as\nlong-term potentiation to strengthen task-relevant parameters. During the\ntraining, this confrontation achieves a balance in that only crucial parameters\nremain, and non-significant parameters are freed to learn subsequent tasks.\nANPyC avoids forgetting important information and makes the model efficient to\nlearn a large number of tasks. Specifically, the neural pruning iteratively\nrelaxes the current task's parameter conditions to expand the common parameter\nsubspace of the task; the synaptic consolidation strategy, which consists of a\nstructure-aware parameter-importance measurement and an element-wise parameter\nupdating strategy, decreases the cumulative error when learning new tasks. The\nfull source code is available at https://github.com/GeoX-Lab/ANPyC.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:51:54 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 08:42:07 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 12:41:40 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Peng", "Jian", ""], ["Tang", "Bo", ""], ["Jiang", "Hao", ""], ["Li", "Zhuo", ""], ["Lei", "Yinjie", ""], ["Lin", "Tao", ""], ["Li", "Haifeng", ""]]}, {"id": "1912.09094", "submitter": "Anton Akusok", "authors": "Anton Akusok, Mirka Saarela, Tommi K\\\"arkk\\\"ainen, Kaj-Mikael Bj\\\"ork\n  and Amaury Lendasse", "title": "Mislabel Detection of Finnish Publication Ranks", "comments": null, "journal-ref": "International Conference on Extreme Learning Machine 2017 Oct 4\n  (pp. 240-248). Springer, Cham", "doi": null, "report-no": null, "categories": "cs.LG cs.DL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes to analyze a data set of Finnish ranks of academic\npublication channels with Extreme Learning Machine (ELM). The purpose is to\nintroduce and test recently proposed ELM-based mislabel detection approach with\na rich set of features characterizing a publication channel. We will compare\nthe architecture, accuracy, and, especially, the set of detected mislabels of\nthe ELM-based approach to the corresponding reference results on the reference\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 09:56:50 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Akusok", "Anton", ""], ["Saarela", "Mirka", ""], ["K\u00e4rkk\u00e4inen", "Tommi", ""], ["Bj\u00f6rk", "Kaj-Mikael", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1912.09132", "submitter": "Wei Huang", "authors": "Wei Huang, Richard Yi Da Xu, Weitao Du, Yutian Zeng, Yunce Zhao", "title": "Mean field theory for deep dropout networks: digging up gradient\n  backpropagation deeply", "comments": "20 pages, 7 figures", "journal-ref": "24th European Conference on Artificial Intelligence - ECAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the mean field theory has been applied to the study of\nneural networks and has achieved a great deal of success. The theory has been\napplied to various neural network structures, including CNNs, RNNs, Residual\nnetworks, and Batch normalization. Inevitably, recent work has also covered the\nuse of dropout. The mean field theory shows that the existence of depth scales\nthat limit the maximum depth of signal propagation and gradient\nbackpropagation. However, the gradient backpropagation is derived under the\ngradient independence assumption that weights used during feed forward are\ndrawn independently from the ones used in backpropagation. This is not how\nneural networks are trained in a real setting. Instead, the same weights used\nin a feed-forward step needs to be carried over to its corresponding\nbackpropagation. Using this realistic condition, we perform theoretical\ncomputation on linear dropout networks and a series of experiments on dropout\nnetworks. Our empirical results show an interesting phenomenon that the length\ngradients can backpropagate for a single input and a pair of inputs are\ngoverned by the same depth scale. Besides, we study the relationship between\nvariance and mean of statistical metrics of the gradient and shown an emergence\nof universality. Finally, we investigate the maximum trainable length for deep\ndropout networks through a series of experiments using MNIST and CIFAR10 and\nprovide a more precise empirical formula that describes the trainable length\nthan original work.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 11:33:34 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 06:50:24 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 08:16:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Huang", "Wei", ""], ["Da Xu", "Richard Yi", ""], ["Du", "Weitao", ""], ["Zeng", "Yutian", ""], ["Zhao", "Yunce", ""]]}, {"id": "1912.09135", "submitter": "Yujie Tang", "authors": "Yingying Li, Yujie Tang, Runyu Zhang, Na Li", "title": "Distributed Reinforcement Learning for Decentralized Linear Quadratic\n  Control: A Derivative-Free Policy Optimization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed reinforcement learning problem for\ndecentralized linear quadratic control with partial state observations and\nlocal costs. We propose a Zero-Order Distributed Policy Optimization algorithm\n(ZODPO) that learns linear local controllers in a distributed fashion,\nleveraging the ideas of policy gradient, zero-order optimization and consensus\nalgorithms. In ZODPO, each agent estimates the global cost by consensus, and\nthen conducts local policy gradient in parallel based on zero-order gradient\nestimation. ZODPO only requires limited communication and storage even in\nlarge-scale systems. Further, we investigate the nonasymptotic performance of\nZODPO and show that the sample complexity to approach a stationary point is\npolynomial with the error tolerance's inverse and the problem dimensions,\ndemonstrating the scalability of ZODPO. We also show that the controllers\ngenerated throughout ZODPO are stabilizing controllers with high probability.\nLastly, we numerically test ZODPO on multi-zone HVAC systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 11:40:08 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 21:38:36 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 06:50:43 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Li", "Yingying", ""], ["Tang", "Yujie", ""], ["Zhang", "Runyu", ""], ["Li", "Na", ""]]}, {"id": "1912.09140", "submitter": "Eyal Shulman", "authors": "Eyal Shulman, Lior Wolf", "title": "Meta Decision Trees for Explainable Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of building explainable recommendation systems that are\nbased on a per-user decision tree, with decision rules that are based on single\nattribute values. We build the trees by applying learned regression functions\nto obtain the decision rules as well as the values at the leaf nodes. The\nregression functions receive as input the embedding of the user's training set,\nas well as the embedding of the samples that arrive at the current node. The\nembedding and the regressors are learned end-to-end with a loss that encourages\nthe decision rules to be sparse. By applying our method, we obtain a\ncollaborative filtering solution that provides a direct explanation to every\nrating it provides. With regards to accuracy, it is competitive with other\nalgorithms. However, as expected, explainability comes at a cost and the\naccuracy is typically slightly lower than the state of the art result reported\nin the literature.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 11:45:01 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Shulman", "Eyal", ""], ["Wolf", "Lior", ""]]}, {"id": "1912.09147", "submitter": "Enmei Tu", "authors": "Xiao Han, Zihao Wang, Enmei Tu, Gunnam Suryanarayana, Jie Yang", "title": "Semi-Supervised Deep Learning Using Improved Unsupervised Discriminant\n  Projection", "comments": "1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning demands a huge amount of well-labeled data to train the network\nparameters. How to use the least amount of labeled data to obtain the desired\nclassification accuracy is of great practical significance, because for many\nreal-world applications (such as medical diagnosis), it is difficult to obtain\nso many labeled samples. In this paper, modify the unsupervised discriminant\nprojection algorithm from dimension reduction and apply it as a regularization\nterm to propose a new semi-supervised deep learning algorithm, which is able to\nutilize both the local and nonlocal distribution of abundant unlabeled samples\nto improve classification performance. Experiments show that given dozens of\nlabeled samples, the proposed algorithm can train a deep network to attain\nsatisfactory classification results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 11:55:12 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Han", "Xiao", ""], ["Wang", "Zihao", ""], ["Tu", "Enmei", ""], ["Suryanarayana", "Gunnam", ""], ["Yang", "Jie", ""]]}, {"id": "1912.09150", "submitter": "Jun Zhao", "authors": "Zhiying Xu, Shuyu Shi, Alex X. Liu, Jun Zhao, Lin Chen", "title": "An Adaptive and Fast Convergent Approach to Differentially Private Deep\n  Learning", "comments": "This full paper appears in the Proceedings of IEEE International\n  Conference on Computer Communications (INFOCOM), held in April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of the era of big data, deep learning has become a prevalent\nbuilding block in a variety of machine learning or data mining tasks, such as\nsignal processing, network modeling and traffic analysis, to name a few. The\nmassive user data crowdsourced plays a crucial role in the success of deep\nlearning models. However, it has been shown that user data may be inferred from\ntrained neural models and thereby exposed to potential adversaries, which\nraises information security and privacy concerns. To address this issue, recent\nstudies leverage the technique of differential privacy to design\nprivate-preserving deep learning algorithms. Albeit successful at privacy\nprotection, differential privacy degrades the performance of neural models. In\nthis paper, we develop ADADP, an adaptive and fast convergent learning\nalgorithm with a provable privacy guarantee. ADADP significantly reduces the\nprivacy cost by improving the convergence speed with an adaptive learning rate\nand mitigates the negative effect of differential privacy upon the model\naccuracy by introducing adaptive noise. The performance of ADADP is evaluated\non real-world datasets. Experiment results show that it outperforms\nstate-of-the-art differentially private approaches in terms of both privacy\ncost and model accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 12:02:58 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Liu", "Alex X.", ""], ["Zhao", "Jun", ""], ["Chen", "Lin", ""]]}, {"id": "1912.09156", "submitter": "Xingyi Duan", "authors": "Xingyi Duan, Baoxin Wang, Ziyue Wang, Wentao Ma, Yiming Cui, Dayong\n  Wu, Shijin Wang, Ting Liu, Tianxiang Huo, Zhen Hu, Heng Wang, Zhiyuan Liu", "title": "CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese Judicial\n  Reading Comprehension", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32381-3_36", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Chinese judicial reading comprehension (CJRC) dataset which\ncontains approximately 10K documents and almost 50K questions with answers. The\ndocuments come from judgment documents and the questions are annotated by law\nexperts. The CJRC dataset can help researchers extract elements by reading\ncomprehension technology. Element extraction is an important task in the legal\nfield. However, it is difficult to predefine the element types completely due\nto the diversity of document types and causes of action. By contrast, machine\nreading comprehension technology can quickly extract elements by answering\nvarious questions from the long document. We build two strong baseline models\nbased on BERT and BiDAF. The experimental results show that there is enough\nspace for improvement compared to human annotators.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 12:17:38 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Duan", "Xingyi", ""], ["Wang", "Baoxin", ""], ["Wang", "Ziyue", ""], ["Ma", "Wentao", ""], ["Cui", "Yiming", ""], ["Wu", "Dayong", ""], ["Wang", "Shijin", ""], ["Liu", "Ting", ""], ["Huo", "Tianxiang", ""], ["Hu", "Zhen", ""], ["Wang", "Heng", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1912.09236", "submitter": "Tianyu Zhang", "authors": "Tianyu Zhang, Lei Zhu, Qian Zhao, and Kilho Shin", "title": "Neural Networks Weights Quantization: Target None-retraining Ternary\n  (TNT)", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization of weights of deep neural networks (DNN) has proven to be an\neffective solution for the purpose of implementing DNNs on edge devices such as\nmobiles, ASICs and FPGAs, because they have no sufficient resources to support\ncomputation involving millions of high precision weights and\nmultiply-accumulate operations. This paper proposes a novel method to compress\nvectors of high precision weights of DNNs to ternary vectors, namely a cosine\nsimilarity based target non-retraining ternary (TNT) compression method. Our\nmethod leverages cosine similarity instead of Euclidean distances as commonly\nused in the literature and succeeds in reducing the size of the search space to\nfind optimal ternary vectors from 3N to N, where N is the dimension of target\nvectors. As a result, the computational complexity for TNT to find\ntheoretically optimal ternary vectors is only O(N log(N)). Moreover, our\nexperiments show that, when we ternarize models of DNN with high precision\nparameters, the obtained quantized models can exhibit sufficiently high\naccuracy so that re-training models is not necessary.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:24:39 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhang", "Tianyu", ""], ["Zhu", "Lei", ""], ["Zhao", "Qian", ""], ["Shin", "Kilho", ""]]}, {"id": "1912.09251", "submitter": "Khe Chai Sim", "authors": "Khe Chai Sim, Fran\\c{c}oise Beaufays, Arnaud Benard, Dhruv Guliani,\n  Andreas Kabel, Nikhil Khare, Tamar Lucassen, Petr Zadrazil, Harry Zhang, Leif\n  Johnson, Giovanni Motta, Lillian Zhou", "title": "Personalization of End-to-end Speech Recognition On Mobile Devices For\n  Named Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effectiveness of several techniques to personalize end-to-end\nspeech models and improve the recognition of proper names relevant to the user.\nThese techniques differ in the amounts of user effort required to provide\nsupervision, and are evaluated on how they impact speech recognition\nperformance. We propose using keyword-dependent precision and recall metrics to\nmeasure vocabulary acquisition performance. We evaluate the algorithms on a\ndataset that we designed to contain names of persons that are difficult to\nrecognize. Therefore, the baseline recall rate for proper names in this dataset\nis very low: 2.4%. A data synthesis approach we developed brings it to 48.6%,\nwith no need for speech input from the user. With speech input, if the user\ncorrects only the names, the name recall rate improves to 64.4%. If the user\ncorrects all the recognition errors, we achieve the best recall of 73.5%. To\neliminate the need to upload user data and store personalized models on a\nserver, we focus on performing the entire personalization workflow on a mobile\ndevice.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 21:18:53 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Sim", "Khe Chai", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Benard", "Arnaud", ""], ["Guliani", "Dhruv", ""], ["Kabel", "Andreas", ""], ["Khare", "Nikhil", ""], ["Lucassen", "Tamar", ""], ["Zadrazil", "Petr", ""], ["Zhang", "Harry", ""], ["Johnson", "Leif", ""], ["Motta", "Giovanni", ""], ["Zhou", "Lillian", ""]]}, {"id": "1912.09254", "submitter": "Jeroen Zegers", "authors": "Jeroen Zegers, Hugo Van hamme", "title": "CNN-LSTM models for Multi-Speaker Source Separation using Bayesian Hyper\n  Parameter Optimization", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there have been many deep learning approaches towards the\nmulti-speaker source separation problem. Most use Long Short-Term Memory -\nRecurrent Neural Networks (LSTM-RNN) or Convolutional Neural Networks (CNN) to\nmodel the sequential behavior of speech. In this paper we propose a novel\nnetwork for source separation using an encoder-decoder CNN and LSTM in\nparallel. Hyper parameters have to be chosen for both parts of the network and\nthey are potentially mutually dependent. Since hyper parameter grid search has\na high computational burden, random search is often preferred. However, when\nsampling a new point in the hyper parameter space, it can potentially be very\nclose to a previously evaluated point and thus give little additional\ninformation. Furthermore, random sampling is as likely to sample in a promising\narea as in an hyper space area dominated with poor performing models.\nTherefore, we use a Bayesian hyper parameter optimization technique and find\nthat the parallel CNN-LSTM outperforms the LSTM-only and CNN-only model.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:04:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zegers", "Jeroen", ""], ["Van hamme", "Hugo", ""]]}, {"id": "1912.09257", "submitter": "Nick Rossenbach", "authors": "Nick Rossenbach, Albert Zeyer, Ralf Schl\\\"uter, Hermann Ney", "title": "Generating Synthetic Audio Data for Attention-Based Speech Recognition\n  Systems", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in text-to-speech (TTS) led to the development of flexible\nmulti-speaker end-to-end TTS systems. We extend state-of-the-art\nattention-based automatic speech recognition (ASR) systems with synthetic audio\ngenerated by a TTS system trained only on the ASR corpora itself. ASR and TTS\nsystems are built separately to show that text-only data can be used to enhance\nexisting end-to-end ASR systems without the necessity of parameter or\narchitecture changes. We compare our method with language model integration of\nthe same text data and with simple data augmentation methods like SpecAugment\nand show that performance improvements are mostly independent. We achieve\nimprovements of up to 33% relative in word-error-rate (WER) over a strong\nbaseline with data-augmentation in a low-resource environment\n(LibriSpeech-100h), closing the gap to a comparable oracle experiment by more\nthan 50\\%. We also show improvements of up to 5% relative WER over our most\nrecent ASR baseline on LibriSpeech-960h.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:09:07 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 14:08:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rossenbach", "Nick", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1912.09261", "submitter": "Jeroen Zegers", "authors": "Pieter Appeltans, Jeroen Zegers, Hugo Van hamme", "title": "Practical applicability of deep neural networks for overlapping speaker\n  separation", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the applicability in realistic scenarios of two deep\nlearning based solutions to the overlapping speaker separation problem.\nFirstly, we present experiments that show that these methods are applicable for\na broad range of languages. Further experimentation indicates limited\nperformance loss for untrained languages, when these have common features with\nthe trained language(s). Secondly, it investigates how the methods deal with\nrealistic background noise and proposes some modifications to better cope with\nthese disturbances. The deep learning methods that will be examined are deep\nclustering and deep attractor networks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:13:36 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Appeltans", "Pieter", ""], ["Zegers", "Jeroen", ""], ["Van hamme", "Hugo", ""]]}, {"id": "1912.09268", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Xiaowen Chu, Bo Li", "title": "MG-WFBP: Merging Gradients Wisely for Efficient Communication in\n  Distributed Deep Learning", "comments": "Accepted by IEEE TPDS. 15 pages. arXiv admin note: substantial text\n  overlap with arXiv:1811.11141", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed synchronous stochastic gradient descent has been widely used to\ntrain deep neural networks (DNNs) on computer clusters. With the increase of\ncomputational power, network communications generally limit the system\nscalability. Wait-free backpropagation (WFBP) is a popular solution to overlap\ncommunications with computations during the training process. In this paper, we\nobserve that many DNNs have a large number of layers with only a small amount\nof data to be communicated at each layer in distributed training, which could\nmake WFBP inefficient. Based on the fact that merging some short communication\ntasks into a single one can reduce the overall communication time, we formulate\nan optimization problem to minimize the training time in pipelining\ncommunications and computations. We derive an optimal solution that can be\nsolved efficiently without affecting the training performance. We then apply\nthe solution to propose a distributed training algorithm named merged-gradient\nWFBP (MG-WFBP) and implement it in two platforms Caffe and PyTorch. Extensive\nexperiments in three GPU clusters are conducted to verify the effectiveness of\nMG-WFBP. We further exploit trace-based simulations of 4 to 2048 GPUs to\nexplore the potential scaling efficiency of MG-WFBP. Experimental results show\nthat MG-WFBP achieves much better scaling performance than existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:59:14 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 11:59:53 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""], ["Li", "Bo", ""]]}, {"id": "1912.09278", "submitter": "Kerstin Hammernik", "authors": "Kerstin Hammernik, Jo Schlemper, Chen Qin, Jinming Duan, Ronald M.\n  Summers, Daniel Rueckert", "title": "$\\Sigma$-net: Systematic Evaluation of Iterative Deep Neural Networks\n  for Fast Parallel MR Image Reconstruction", "comments": "Submitted to Magnetic Resonance in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To systematically investigate the influence of various data\nconsistency layers, (semi-)supervised learning and ensembling strategies,\ndefined in a $\\Sigma$-net, for accelerated parallel MR image reconstruction\nusing deep learning.\n  Theory and Methods: MR image reconstruction is formulated as learned unrolled\noptimization scheme with a Down-Up network as regularization and varying data\nconsistency layers. The different architectures are split into sensitivity\nnetworks, which rely on explicit coil sensitivity maps, and parallel coil\nnetworks, which learn the combination of coils implicitly. Different content\nand adversarial losses, a semi-supervised fine-tuning scheme and model\nensembling are investigated.\n  Results: Evaluated on the fastMRI multicoil validation set, architectures\ninvolving raw k-space data outperform image enhancement methods significantly.\nSemi-supervised fine-tuning adapts to new k-space data and provides, together\nwith reconstructions based on adversarial training, the visually most appealing\nresults although quantitative quality metrics are reduced. The $\\Sigma$-net\nensembles the benefits from different models and achieves similar scores\ncompared to the single state-of-the-art approaches.\n  Conclusion: This work provides an open-source framework to perform a\nsystematic wide-range comparison of state-of-the-art reconstruction approaches\nfor parallel MR image reconstruction on the fastMRI knee dataset and explores\nthe importance of data consistency. A suitable trade-off between perceptual\nimage quality and quantitative scores are achieved with the ensembled\n$\\Sigma$-net.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 16:52:39 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Hammernik", "Kerstin", ""], ["Schlemper", "Jo", ""], ["Qin", "Chen", ""], ["Duan", "Jinming", ""], ["Summers", "Ronald M.", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1912.09287", "submitter": "Minh Vu", "authors": "Minh H. Vu and Guus Grimbergen and Tufve Nyholm and Tommy L\\\"ofstedt", "title": "Evaluation of Multi-Slice Inputs to Convolutional Neural Networks for\n  Medical Image Segmentation", "comments": null, "journal-ref": null, "doi": "10.1002/mp.14391", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When using Convolutional Neural Networks (CNNs) for segmentation of organs\nand lesions in medical images, the conventional approach is to work with inputs\nand outputs either as single slice (2D) or whole volumes (3D). One common\nalternative, in this study denoted as pseudo-3D, is to use a stack of adjacent\nslices as input and produce a prediction for at least the central slice. This\napproach gives the network the possibility to capture 3D spatial information,\nwith only a minor additional computational cost. In this study, we\nsystematically evaluate the segmentation performance and computational costs of\nthis pseudo-3D approach as a function of the number of input slices, and\ncompare the results to conventional end-to-end 2D and 3D CNNs. The standard\npseudo-3D method regards the neighboring slices as multiple input image\nchannels. We additionally evaluate a simple approach where the input stack is a\nvolumetric input that is repeatably convolved in 3D to obtain a 2D feature map.\nThis 2D map is in turn fed into a standard 2D network. We conducted experiments\nusing two different CNN backbone architectures and on five diverse data sets\ncovering different anatomical regions, imaging modalities, and segmentation\ntasks. We found that while both pseudo-3D methods can process a large number of\nslices at once and still be computationally much more efficient than fully 3D\nCNNs, a significant improvement over a regular 2D CNN was only observed for one\nof the five data sets. An analysis of the structural properties of the\nsegmentation masks revealed no relations to the segmentation performance with\nrespect to the number of input slices. The conclusion is therefore that in the\ngeneral case, multi-slice inputs appear to not significantly improve\nsegmentation results over using 2D or 3D CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:26:16 GMT"}, {"version": "v2", "created": "Sun, 22 Dec 2019 19:31:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Vu", "Minh H.", ""], ["Grimbergen", "Guus", ""], ["Nyholm", "Tufve", ""], ["L\u00f6fstedt", "Tommy", ""]]}, {"id": "1912.09299", "submitter": "David Honz\\'atko", "authors": "Siavash Bigdeli, David Honz\\'atko, Sabine S\\\"usstrunk and L. Andrea\n  Dunbar", "title": "Image Restoration using Plug-and-Play CNN MAP Denoisers", "comments": "Code and models available at\n  https://github.com/DawyD/cnn-map-denoiser . Accepted for publication in\n  VISAPP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plug-and-play denoisers can be used to perform generic image restoration\ntasks independent of the degradation type. These methods build on the fact that\nthe Maximum a Posteriori (MAP) optimization can be solved using smaller\nsub-problems, including a MAP denoising optimization. We present the first\nend-to-end approach to MAP estimation for image denoising using deep neural\nnetworks. We show that our method is guaranteed to minimize the MAP denoising\nobjective, which is then used in an optimization algorithm for generic image\nrestoration. We provide theoretical analysis of our approach and show the\nquantitative performance of our method in several experiments. Our experimental\nresults show that the proposed method can achieve 70x faster performance\ncompared to the state-of-the-art, while maintaining the theoretical perspective\nof MAP.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 12:57:27 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 08:52:18 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Bigdeli", "Siavash", ""], ["Honz\u00e1tko", "David", ""], ["S\u00fcsstrunk", "Sabine", ""], ["Dunbar", "L. Andrea", ""]]}, {"id": "1912.09301", "submitter": "Caifa Zhou", "authors": "Caifa Zhou", "title": "Feature-wise change detection and robust indoor positioning using\n  RANSAC-like approach", "comments": "36 pages, 20 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprinting-based positioning, one of the promising indoor positioning\nsolutions, has been broadly explored owing to the pervasiveness of sensor-rich\nmobile devices, the prosperity of opportunistically measurable\nlocation-relevant signals and the progress of data-driven algorithms. One\ncritical challenge is to controland improve the quality of the reference\nfingerprint map (RFM), which is built at the offline stage and applied for\nonline positioning. The key concept concerningthe quality control of the RFM is\nupdating the RFM according to the newly measured data. Though varies methods\nhave been proposed for adapting the RFM, they approach the problem by\nintroducing extra-positioning schemes (e.g. PDR orUGV) and directly adjust the\nRFM without distinguishing whether critical changes have occurred. This paper\naims at proposing an extra-positioning-free solution by making full use of the\nredundancy of measurable features. Loosely inspired by random sampling\nconsensus (RANSAC), arbitrarily sampled subset of features from the online\nmeasurement are used for generating multi-resamples, which areused for\nestimating the intermediate locations. In the way of resampling, it can\nmitigate the impact of the changed features on positioning and enables to\nretrieve accurate location estimation. The users location is robustly computed\nby identifying the candidate locations from these intermediate ones using\nmodified Jaccardindex (MJI) and the feature-wise change belief is calculated\naccording to the world model of the RFM and the estimated variability of\nfeatures. In order to validate our proposed approach, two levels of\nexperimental analysis have been carried out. On the simulated dataset, the\naverage change detection accuracy is about 90%. Meanwhile, the improvement of\npositioning accuracy within 2 m is about 20% by dropping out the features that\nare detected as changed when performing positioning comparing to that of using\nall measured features for location estimation. On the long-term collected\ndataset, the average change detection accuracy is about 85%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 12:46:04 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Zhou", "Caifa", ""]]}, {"id": "1912.09303", "submitter": "Simon Msika", "authors": "Simon Msika, Alejandro Quintero, Foutse Khomh", "title": "SIGMA : Strengthening IDS with GAN and Metaheuristics Attacks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Intrusion Detection System (IDS) is a key cybersecurity tool for network\nadministrators as it identifies malicious traffic and cyberattacks. With the\nrecent successes of machine learning techniques such as deep learning, more and\nmore IDS are now using machine learning algorithms to detect attacks faster.\nHowever, these systems lack robustness when facing previously unseen types of\nattacks. With the increasing number of new attacks, especially against Internet\nof Things devices, having a robust IDS able to spot unusual and new attacks\nbecomes necessary.\n  This work explores the possibility of leveraging generative adversarial\nmodels to improve the robustness of machine learning based IDS. More\nspecifically, we propose a new method named SIGMA, that leverages adversarial\nexamples to strengthen IDS against new types of attacks. Using Generative\nAdversarial Networks (GAN) and metaheuristics, SIGMA %Our method consists in\ngenerates adversarial examples, iteratively, and uses it to retrain a machine\nlearning-based IDS, until a convergence of the detection rate (i.e. until the\ndetection system is not improving anymore). A round of improvement consists of\na generative phase, in which we use GANs and metaheuristics to generate\ninstances ; an evaluation phase in which we calculate the detection rate of\nthose newly generated attacks ; and a training phase, in which we train the IDS\nwith those attacks. We have evaluated the SIGMA method for four standard\nmachine learning classification algorithms acting as IDS, with a combination of\nGAN and a hybrid local-search and genetic algorithm, to generate new datasets\nof attacks. Our results show that SIGMA can successfully generate adversarial\nattacks against different machine learning based IDS. Also, using SIGMA, we can\nimprove the performance of an IDS to up to 100\\% after as little as two rounds\nof improvement.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 15:35:38 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Msika", "Simon", ""], ["Quintero", "Alejandro", ""], ["Khomh", "Foutse", ""]]}, {"id": "1912.09306", "submitter": "Balint Daroczy", "authors": "B\\'alint Dar\\'oczy and Rita Aleksziev and Andr\\'as Bencz\\'ur", "title": "Tangent Space Separability in Feedforward Neural Networks", "comments": "10 pages; accepted at Workshop \"Beyond First-Order Optimization\n  Methods in Machine Learning\", 33rd Conference on Neural Information\n  Processing Systems (NeurIPS 2019). arXiv admin note: substantial text overlap\n  with arXiv:1807.06630", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical neural networks are exponentially more efficient than their\ncorresponding \"shallow\" counterpart with the same expressive power, but involve\nhuge number of parameters and require tedious amounts of training. By\napproximating the tangent subspace, we suggest a sparse representation that\nenables switching to shallow networks, GradNet after a very early training\nstage. Our experiments show that the proposed approximation of the metric\nimproves and sometimes even surpasses the achievable performance of the\noriginal network significantly even after a few epochs of training the original\nfeedforward network.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:04:02 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Dar\u00f3czy", "B\u00e1lint", ""], ["Aleksziev", "Rita", ""], ["Bencz\u00far", "Andr\u00e1s", ""]]}, {"id": "1912.09318", "submitter": "Aaron Alvero", "authors": "AJ Alvero, Noah Arthurs, anthony lising antonio, Benjamin W. Domingue,\n  Ben Gebre-Medhin, Sonia Giebel, Mitchell L. Stevens", "title": "AI and Holistic Review: Informing Human Reading in College Admissions", "comments": "AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  College admissions in the United States is carried out by a human-centered\nmethod of evaluation known as holistic review, which typically involves reading\noriginal narrative essays submitted by each applicant. The legitimacy and\nfairness of holistic review, which gives human readers significant discretion\nover determining each applicant's fitness for admission, has been repeatedly\nchallenged in courtrooms and the public sphere. Using a unique corpus of\n283,676 application essays submitted to a large, selective, state university\nsystem between 2015 and 2016, we assess the extent to which applicant\ndemographic characteristics can be inferred from application essays. We find a\nrelatively interpretable classifier (logistic regression) was able to predict\ngender and household income with high levels of accuracy. Findings suggest that\ndata auditing might be useful in informing holistic review, and perhaps other\nevaluative systems, by checking potential bias in human or computational\nreadings.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:08:36 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Alvero", "AJ", ""], ["Arthurs", "Noah", ""], ["antonio", "anthony lising", ""], ["Domingue", "Benjamin W.", ""], ["Gebre-Medhin", "Ben", ""], ["Giebel", "Sonia", ""], ["Stevens", "Mitchell L.", ""]]}, {"id": "1912.09322", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "PySS3: A Python package implementing a novel text classifier with\n  visualization tools for Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently introduced text classifier, called SS3, has obtained\nstate-of-the-art performance on the CLEF's eRisk tasks. SS3 was created to deal\nwith risk detection over text streams and, therefore, not only supports\nincremental training and classification but also can visually explain its\nrationale. However, little attention has been paid to the potential use of SS3\nas a general classifier. We believe this could be due to the unavailability of\nan open-source implementation of SS3. In this work, we introduce PySS3, a\npackage that implements SS3 and also comes with visualization tools that allow\nresearchers to deploy robust, explainable, and trusty machine learning models\nfor text classification.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:01:41 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 00:31:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1912.09323", "submitter": "Artem Ryzhikov", "authors": "Artem Ryzhikov, Maxim Borisyak, Andrey Ustyuzhanin, Denis Derkach", "title": "Normalizing flows for deep anomaly detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection for complex data is a challenging task from the perspective\nof machine learning. In this work, weconsider cases with missing certain kinds\nof anomalies in the training dataset, while significant statistics for the\nnormal class isavailable. For such scenarios, conventional supervised methods\nmight suffer from the class imbalance, while unsupervised methodstend to ignore\ndifficult anomalous examples. We extend the idea of the supervised\nclassification approach for class-imbalanceddatasets by exploiting normalizing\nflows for proper Bayesian inference of the posterior probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:03:11 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Ryzhikov", "Artem", ""], ["Borisyak", "Maxim", ""], ["Ustyuzhanin", "Andrey", ""], ["Derkach", "Denis", ""]]}, {"id": "1912.09334", "submitter": "Uwe Petersohn", "authors": "Uwe Petersohn, Thomas Dedek, Sandra Zimmer, Hans Biskupski", "title": "Causal statistical modeling and calculation of distribution functions of\n  classification features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical system models provide the basis for the examination of various\nsorts of distributions. Classification distributions are a very common and\nversatile form of statistics in e.g. real economic, social, and IT systems. The\nstatistical distributions of classification features can be applied in\ndetermining the a priori probabilities in Bayesian networks. We investigate a\nstatistical model of classification distributions based on finding the critical\npoint of a specialized form of entropy. A distribution function for\nclassification features is derived, with the two parameters $n_0$, minimal\nclass, and $\\bar{N}$, average number of classes. Efficient algorithms for the\ncomputation of the class probabilities and the approximation of real frequency\ndistributions are developed and applied to examples from different domains. The\nmethod is compared to established distributions like Zipf's law. The majority\nof examples can be approximated with a sufficient quality ($3-5\\%$).\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:13:09 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Petersohn", "Uwe", ""], ["Dedek", "Thomas", ""], ["Zimmer", "Sandra", ""], ["Biskupski", "Hans", ""]]}, {"id": "1912.09336", "submitter": "Nilavra Bhattacharya", "authors": "Nilavra Bhattacharya, Danna Gurari", "title": "VizWiz Dataset Browser: A Tool for Visualizing Machine Learning Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a visualization tool to exhaustively search and browse through a\nset of large-scale machine learning datasets. Built on the top of the VizWiz\ndataset, our dataset browser tool has the potential to support and enable a\nvariety of qualitative and quantitative research, and open new directions for\nvisualizing and researching with multimodal information. The tool is publicly\navailable at https://vizwiz.org/browse.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:18:34 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bhattacharya", "Nilavra", ""], ["Gurari", "Danna", ""]]}, {"id": "1912.09351", "submitter": "Seokju Lee", "authors": "Seokju Lee, Sunghoon Im, Stephen Lin, In So Kweon", "title": "Instance-wise Depth and Motion Learning from Monocular Videos", "comments": "Project page at https://sites.google.com/site/seokjucv/home/instadm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end joint training framework that explicitly models\n6-DoF motion of multiple dynamic objects, ego-motion and depth in a monocular\ncamera setup without supervision. Our technical contributions are three-fold.\nFirst, we propose a differentiable forward rigid projection module that plays a\nkey role in our instance-wise depth and motion learning. Second, we design an\ninstance-wise photometric and geometric consistency loss that effectively\ndecomposes background and moving object regions. Lastly, we introduce a new\nauto-annotation scheme to produce video instance segmentation maps that will be\nutilized as input to our training pipeline. These proposed elements are\nvalidated in a detailed ablation study. Through extensive experiments conducted\non the KITTI dataset, our framework is shown to outperform the state-of-the-art\ndepth and motion estimation methods. Our code and dataset will be available at\nhttps://github.com/SeokjuLee/Insta-DM.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:35:30 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 11:53:52 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Lee", "Seokju", ""], ["Im", "Sunghoon", ""], ["Lin", "Stephen", ""], ["Kweon", "In So", ""]]}, {"id": "1912.09356", "submitter": "Nathan Laubeuf", "authors": "Bram-Ernst Verhoef, Nathan Laubeuf, Stefan Cosemans, Peter Debacker,\n  Ioannis Papistas, Arindam Mallik, Diederik Verkest", "title": "FQ-Conv: Fully Quantized Convolution for Efficient and Accurate\n  Inference", "comments": "12 pages, 4 Figures, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) can be made hardware-efficient by reducing the\nnumerical precision of the weights and activations of the network and by\nimproving the network's resilience to noise. However, this gain in efficiency\noften comes at the cost of significantly reduced accuracy. In this paper, we\npresent a novel approach to quantizing convolutional neural network. The\nresulting networks perform all computations in low-precision, without requiring\nhigher-precision BN and nonlinearities, while still being highly accurate. To\nachieve this result, we employ a novel quantization technique that learns to\noptimally quantize the weights and activations of the network during training.\nAdditionally, to enhance training convergence we use a new training technique,\ncalled gradual quantization. We leverage the nonlinear and normalizing behavior\nof our quantization function to effectively remove the higher-precision\nnonlinearities and BN from the network. The resulting convolutional layers are\nfully quantized to low precision, from input to output, ideal for neural\nnetwork accelerators on the edge. We demonstrate the potential of this approach\non different datasets and networks, showing that ternary-weight CNNs with\nlow-precision in- and outputs perform virtually on par with their\nfull-precision equivalents. Finally, we analyze the influence of noise on the\nweights, activations and convolution outputs (multiply-accumulate, MAC) and\npropose a strategy to improve network performance under noisy conditions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:39:45 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Verhoef", "Bram-Ernst", ""], ["Laubeuf", "Nathan", ""], ["Cosemans", "Stefan", ""], ["Debacker", "Peter", ""], ["Papistas", "Ioannis", ""], ["Mallik", "Arindam", ""], ["Verkest", "Diederik", ""]]}, {"id": "1912.09363", "submitter": "Bryan Lim", "authors": "Bryan Lim, Sercan O. Arik, Nicolas Loeff, Tomas Pfister", "title": "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-horizon forecasting problems often contain a complex mix of inputs --\nincluding static (i.e. time-invariant) covariates, known future inputs, and\nother exogenous time series that are only observed historically -- without any\nprior information on how they interact with the target. While several deep\nlearning models have been proposed for multi-step prediction, they typically\ncomprise black-box models which do not account for the full range of inputs\npresent in common scenarios. In this paper, we introduce the Temporal Fusion\nTransformer (TFT) -- a novel attention-based architecture which combines\nhigh-performance multi-horizon forecasting with interpretable insights into\ntemporal dynamics. To learn temporal relationships at different scales, the TFT\nutilizes recurrent layers for local processing and interpretable self-attention\nlayers for learning long-term dependencies. The TFT also uses specialized\ncomponents for the judicious selection of relevant features and a series of\ngating layers to suppress unnecessary components, enabling high performance in\na wide range of regimes. On a variety of real-world datasets, we demonstrate\nsignificant performance improvements over existing benchmarks, and showcase\nthree practical interpretability use-cases of TFT.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 16:45:40 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 12:45:45 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 14:17:28 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lim", "Bryan", ""], ["Arik", "Sercan O.", ""], ["Loeff", "Nicolas", ""], ["Pfister", "Tomas", ""]]}, {"id": "1912.09379", "submitter": "Benedikt Pf\\\"ulb", "authors": "Alexander Gepperth and Benedikt Pf\\\"ulb", "title": "Gradient-based training of Gaussian Mixture Models for High-Dimensional\n  Streaming Data", "comments": "17 pages, 4 figures, preprint Neural Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for efficiently training Gaussian Mixture Model (GMM)\nby Stochastic Gradient Descent (SGD) with non-stationary, high-dimensional\nstreaming data. Our training scheme does not require data-driven parameter\ninitialization (e.g., k-means) and can thus be trained based on a random\ninitialization. Furthermore, the approach allows mini-batch sizes as low as 1,\nwhich are typical for streaming-data settings. Major problems in such settings\nare undesirable local optima during early training phases and numerical\ninstabilities due to high data dimensionalities. We introduce an adaptive\nannealing procedure to address the first problem, whereas numerical\ninstabilities are eliminated by using an exponential-free approximation to the\nstandard GMM log-likelihood. Experiments on a variety of visual and non-visual\nbenchmarks show that our SGD approach can be trained completely without, for\ninstance, k-means based centroid initialization. It also compares favorably to\nan online variant of Expectation-Maximization (EM) - stochastic EM (sEM), which\nit outperforms by a large margin for very high-dimensional data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:35:39 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 15:32:05 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 16:25:30 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gepperth", "Alexander", ""], ["Pf\u00fclb", "Benedikt", ""]]}, {"id": "1912.09380", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Gabriel Gagnon-Turcotte, Angkoon Phinyomark,\n  Kyrre Glette, Erik Scheme, Fran\\c{c}ois Laviolette, and Benoit Gosselin", "title": "A Transferable Adaptive Domain Adversarial Neural Network for Virtual\n  Reality Augmented EMG-Based Gesture Recognition", "comments": "10 Pages. The last three authors shared senior authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the field of electromyography-based (EMG) gesture recognition,\ndisparities exist between the offline accuracy reported in the literature and\nthe real-time usability of a classifier. This gap mainly stems from two\nfactors: 1) The absence of a controller, making the data collected dissimilar\nto actual control. 2) The difficulty of including the four main dynamic factors\n(gesture intensity, limb position, electrode shift, and transient changes in\nthe signal), as including their permutations drastically increases the amount\nof data to be recorded. Contrarily, online datasets are limited to the exact\nEMG-based controller used to record them, necessitating the recording of a new\ndataset for each control method or variant to be tested. Consequently, this\npaper proposes a new type of dataset to serve as an intermediate between\noffline and online datasets, by recording the data using a real-time\nexperimental protocol. The protocol, performed in virtual reality, includes the\nfour main dynamic factors and uses an EMG-independent controller to guide\nmovements. This EMG-independent feedback ensures that the user is in-the-loop\nduring recording, while enabling the resulting dynamic dataset to be used as an\nEMG-based benchmark. The dataset is comprised of 20 able-bodied participants\ncompleting three to four sessions over a period of 14 to 21 days. The ability\nof the dynamic dataset to serve as a benchmark is leveraged to evaluate the\nimpact of different recalibration techniques for long-term (across-day) gesture\nrecognition, including a novel algorithm, named TADANN. TADANN consistently and\nsignificantly (p<0.05) outperforms using fine-tuning as the recalibration\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:41:56 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 14:55:11 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Gagnon-Turcotte", "Gabriel", ""], ["Phinyomark", "Angkoon", ""], ["Glette", "Kyrre", ""], ["Scheme", "Erik", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Gosselin", "Benoit", ""]]}, {"id": "1912.09382", "submitter": "Aur\\'elien Decelle", "authors": "Giancarlo Fissore, Aur\\'elien Decelle, Cyril Furtlehner, Yufei Han", "title": "Robust Multi-Output Learning with Highly Incomplete Data via Restricted\n  Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a standard multi-output classification scenario, both features and labels\nof training data are partially observed. This challenging issue is widely\nwitnessed due to sensor or database failures, crowd-sourcing and noisy\ncommunication channels in industrial data analytic services. Classic methods\nfor handling multi-output classification with incomplete supervision\ninformation usually decompose the problem into an imputation stage that\nreconstructs the missing training information, and a learning stage that builds\na classifier based on the imputed training set. These methods fail to fully\nleverage the dependencies between features and labels. In order to take full\nadvantage of these dependencies we consider a purely probabilistic setting in\nwhich the features imputation and multi-label classification problems are\njointly solved. Indeed, we show that a simple Restricted Boltzmann Machine can\nbe trained with an adapted algorithm based on mean-field equations to\nefficiently solve problems of inductive and transductive learning in which both\nfeatures and labels are missing at random. The effectiveness of the approach is\ndemonstrated empirically on various datasets, with particular focus on a\nreal-world Internet-of-Things security dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:03:27 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Fissore", "Giancarlo", ""], ["Decelle", "Aur\u00e9lien", ""], ["Furtlehner", "Cyril", ""], ["Han", "Yufei", ""]]}, {"id": "1912.09393", "submitter": "Luca Bertinetto", "authors": "Luca Bertinetto, Romain Mueller, Konstantinos Tertikas, Sina\n  Samangooei, Nicholas A. Lord", "title": "Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks", "comments": "To appear at CVPR 2020. Code available at\n  https://github.com/fiveai/making-better-mistakes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have improved image classification dramatically over the\npast decade, but have done so by focusing on performance measures that treat\nall classes other than the ground truth as equally wrong. This has led to a\nsituation in which mistakes are less likely to be made than before, but are\nequally likely to be absurd or catastrophic when they do occur. Past works have\nrecognised and tried to address this issue of mistake severity, often by using\ngraph distances in class hierarchies, but this has largely been neglected since\nthe advent of the current deep learning era in computer vision. In this paper,\nwe aim to renew interest in this problem by reviewing past approaches and\nproposing two simple modifications of the cross-entropy loss which outperform\nthe prior art under several metrics on two large datasets with complex class\nhierarchies: tieredImageNet and iNaturalist'19.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:08:51 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:19:22 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Bertinetto", "Luca", ""], ["Mueller", "Romain", ""], ["Tertikas", "Konstantinos", ""], ["Samangooei", "Sina", ""], ["Lord", "Nicholas A.", ""]]}, {"id": "1912.09395", "submitter": "Andreas Kofler", "authors": "Andreas Kofler, Markus Haltmeier, Tobias Schaeffter, Marc\n  Kachelrie{\\ss}, Marc Dewey, Christian Wald and Christoph Kolbitsch", "title": "Neural Networks-based Regularization for Large-Scale Medical Image\n  Reconstruction", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6560/ab990e", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a generalized Deep Learning-based approach for\nsolving ill-posed large-scale inverse problems occuring in medical image\nreconstruction. Recently, Deep Learning methods using iterative neural networks\nand cascaded neural networks have been reported to achieve state-of-the-art\nresults with respect to various quantitative quality measures as PSNR, NRMSE\nand SSIM across different imaging modalities. However, the fact that these\napproaches employ the forward and adjoint operators repeatedly in the network\narchitecture requires the network to process the whole images or volumes at\nonce, which for some applications is computationally infeasible. In this work,\nwe follow a different reconstruction strategy by decoupling the regularization\nof the solution from ensuring consistency with the measured data. The\nregularization is given in the form of an image prior obtained by the output of\na previously trained neural network which is used in a Tikhonov regularization\nframework. By doing so, more complex and sophisticated network architectures\ncan be used for the removal of the artefacts or noise than it is usually the\ncase in iterative networks. Due to the large scale of the considered problems\nand the resulting computational complexity of the employed networks, the priors\nare obtained by processing the images or volumes as patches or slices. We\nevaluated the method for the cases of 3D cone-beam low dose CT and undersampled\n2D radial cine MRI and compared it to a total variation-minimization-based\nreconstruction algorithm as well as to a method with regularization based on\nlearned overcomplete dictionaries. The proposed method outperformed all the\nreported methods with respect to all chosen quantitative measures and further\naccelerates the regularization step in the reconstruction by several orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:15:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 11:52:58 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Kofler", "Andreas", ""], ["Haltmeier", "Markus", ""], ["Schaeffter", "Tobias", ""], ["Kachelrie\u00df", "Marc", ""], ["Dewey", "Marc", ""], ["Wald", "Christian", ""], ["Kolbitsch", "Christoph", ""]]}, {"id": "1912.09399", "submitter": "Julian Zilly", "authors": "Julian Zilly, Lorenz Hetzel, Andrea Censi, Emilio Frazzoli", "title": "Quantifying the effect of representations on task complexity", "comments": "Workshop paper at Information Theory and Machine Learning Workshop at\n  NeurIPS'19. 13 pages (8 pages + 2 bibliography + 3 appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the influence of input data representations on learning\ncomplexity. For learning, we posit that each model implicitly uses a candidate\nmodel distribution for unexplained variations in the data, its noise model. If\nthe model distribution is not well aligned to the true distribution, then even\nrelevant variations will be treated as noise. Crucially however, the alignment\nof model and true distribution can be changed, albeit implicitly, by changing\ndata representations. \"Better\" representations can better align the model to\nthe true distribution, making it easier to approximate the input-output\nrelationship in the data without discarding useful data variations. To quantify\nthis alignment effect of data representations on the difficulty of a learning\ntask, we make use of an existing task complexity score and show its connection\nto the representation-dependent information coding length of the input.\nEmpirically we extract the necessary statistics from a linear regression\napproximation and show that these are sufficient to predict relative learning\nperformance outcomes of different data representations and neural network types\nobtained when utilizing an extensive neural network architecture search. We\nconclude that to ensure better learning outcomes, representations may need to\nbe tailored to both task and model to align with the implicit distribution of\nmodel and task.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:19:14 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Zilly", "Julian", ""], ["Hetzel", "Lorenz", ""], ["Censi", "Andrea", ""], ["Frazzoli", "Emilio", ""]]}, {"id": "1912.09405", "submitter": "Stephen Law Dr", "authors": "Andrew Elliott and Stephen Law and Chris Russell", "title": "Explaining Classifiers using Adversarial Perturbations on the Perceptual\n  Ball", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple regularization of adversarial perturbations based upon\nthe perceptual loss. While the resulting perturbations remain imperceptible to\nthe human eye, they differ from existing adversarial perturbations in that they\nare semi-sparse alterations that highlight objects and regions of interest\nwhile leaving the background unaltered. As a semantically meaningful adverse\nperturbations, it forms a bridge between counterfactual explanations and\nadversarial perturbations in the space of images. We evaluate our approach on\nseveral standard explainability benchmarks, namely, weak localization,\ninsertion deletion, and the pointing game demonstrating that perceptually\nregularized counterfactuals are an effective explanation for image-based\nclassifiers.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:25:07 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 14:55:40 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 18:50:43 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 21:51:19 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Elliott", "Andrew", ""], ["Law", "Stephen", ""], ["Russell", "Chris", ""]]}, {"id": "1912.09423", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Smon Hessner, Yao-Chong Lim, Louis-Phlippe Morency", "title": "Pseudo-Encoded Stochastic Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior inference in directed graphical models is commonly done using a\nprobabilistic encoder (a.k.a inference model) conditioned on the input. Often\nthis inference model is trained jointly with the probabilistic decoder (a.k.a\ngenerator model). If probabilistic encoder encounters complexities during\ntraining (e.g. suboptimal complxity or parameterization), then learning reaches\na suboptimal objective; a phenomena commonly called inference suboptimality. In\nVariational Inference (VI), optimizing the ELBo using Stochastic Variational\nInference (SVI) can eliminate the inference suboptimality (as demonstrated in\nthis paper), however, this solution comes at a substantial computational cost\nwhen inference needs to be done on new data points. Essentially, a long\nsequential chain of gradient updates is required to fully optimize approximate\nposteriors. In this paper, we present an approach called Pseudo-Encoded\nStochastic Variational Inference (PE-SVI), to reduce the inference complexity\nof SVI during test time. Our approach relies on finding a suitable initial\nstart point for gradient operations, which naturally reduces the required\ngradient steps. Furthermore, this initialization allows for adopting larger\nstep sizes (compared to random initialization used in SVI), which further\nreduces the inference time complexity. PE-SVI reaches the same ELBo objective\nas SVI using less than one percent of required steps, on average.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:50:18 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Zadeh", "Amir", ""], ["Hessner", "Smon", ""], ["Lim", "Yao-Chong", ""], ["Morency", "Louis-Phlippe", ""]]}, {"id": "1912.09428", "submitter": "Mrinmoy Sarkar", "authors": "Dhiman Chowdhury and Mrinmoy Sarkar", "title": "Location Forensics Analysis Using ENF Sequences Extracted from Power and\n  Audio Recordings", "comments": "5 pages, 5 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Electrical network frequency (ENF) is the signature of a power distribution\ngrid which represents the nominal frequency (50 or 60 Hz) of a power system\nnetwork. Due to load variations in a power grid, ENF sequences experience\nfluctuations. These ENF variations are inherently located in a multimedia\nsignal which is recorded close to the grid or directly from the mains power\nline. Therefore, a multimedia recording can be localized by analyzing the ENF\nsequences of that signal in absence of the concurrent power signal. In this\npaper, a novel approach to analyze location forensics using ENF sequences\nextracted from a number of power and audio recordings is proposed. The digital\nrecordings are collected from different grid locations around the world.\nPotential feature components are determined from the ENF sequences. Then, a\nmulti-class support vector machine (SVM) classification model is developed to\nvalidate the location authenticity of the recordings. The performance\nassessments affirm the efficacy of the presented work.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:15:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Chowdhury", "Dhiman", ""], ["Sarkar", "Mrinmoy", ""]]}, {"id": "1912.09445", "submitter": "S. Mohammad Mirbagheri", "authors": "S. Mohammad Mirbagheri, Howard J. Hamilton", "title": "FIBS: A Generic Framework for Classifying Interval-based Temporal\n  Sequences", "comments": "In: Big Data Analytics and Knowledge Discovery. DaWaK 2020. Springer,\n  Cham", "journal-ref": "22nd International Conference on Big Data Analytics and Knowledge\n  Discovery (DaWaK), Bratislava, Slovakia, September 14-17, 2020. Springer,\n  Cham", "doi": "10.1007/978-3-030-59065-9_24", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of classifying interval-based temporal sequences\n(IBTSs). Since common classification algorithms cannot be directly applied to\nIBTSs, the main challenge is to define a set of features that effectively\nrepresents the data such that classifiers can be applied. Most prior work\nutilizes frequent pattern mining to define a feature set based on discovered\npatterns. However, frequent pattern mining is computationally expensive and\noften discovers many irrelevant patterns. To address this shortcoming, we\npropose the FIBS framework for classifying IBTSs. FIBS extracts features\nrelevant to classification from IBTSs based on relative frequency and temporal\nrelations. To avoid selecting irrelevant features, a filter-based selection\nstrategy is incorporated into FIBS. Our empirical evaluation on eight\nreal-world datasets demonstrates the effectiveness of our methods in practice.\nThe results provide evidence that FIBS effectively represents IBTSs for\nclassification algorithms, which contributes to similar or significantly better\naccuracy compared to state-of-the-art competitors. It also suggests that the\nfeature selection strategy is beneficial to FIBS's performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 18:23:27 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 18:21:47 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Mirbagheri", "S. Mohammad", ""], ["Hamilton", "Howard J.", ""]]}, {"id": "1912.09484", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias and Warren B. Powell", "title": "Zeroth-order Stochastic Compositional Algorithms for Risk-Aware Learning", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SP eess.SY math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Free-MESSAGEp, the first zeroth-order algorithm for convex\nmean-semideviation-based risk-aware learning, which is also the first\nthree-level zeroth-order compositional stochastic optimization algorithm,\nwhatsoever. Using a non-trivial extension of Nesterov's classical results on\nGaussian smoothing, we develop the Free-MESSAGEp algorithm from first\nprinciples, and show that it essentially solves a smoothed surrogate to the\noriginal problem, the former being a uniform approximation of the latter, in a\nuseful, convenient sense. We then present a complete analysis of the\nFree-MESSAGEp algorithm, which establishes convergence in a user-tunable\nneighborhood of the optimal solutions of the original problem, as well as\nexplicit convergence rates for both convex and strongly convex costs.\nOrderwise, and for fixed problem parameters, our results demonstrate no\nsacrifice in convergence speed compared to existing first-order methods, while\nstriking a certain balance among the condition of the problem, its\ndimensionality, as well as the accuracy of the obtained results, naturally\nextending previous results in zeroth-order risk-neutral learning.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:04:15 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Powell", "Warren B.", ""]]}, {"id": "1912.09499", "submitter": "Haozhen Zhao", "authors": "Robert Keeling, Rishi Chhatwal, Nathaniel Huber-Fliflet, Jianping\n  Zhang, Fusheng Wei, Haozhen Zhao, Shi Ye, Han Qin", "title": "Empirical Comparisons of CNN with Other Learning Algorithms for Text\n  Classification in Legal Document Review", "comments": "2019 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research has shown that Convolutional Neural Networks (CNN) can be\neffectively applied to text classification as part of a predictive coding\nprotocol. That said, most research to date has been conducted on data sets with\nshort documents that do not reflect the variety of documents in real world\ndocument reviews. Using data from four actual reviews with documents of varying\nlengths, we compared CNN with other popular machine learning algorithms for\ntext classification, including Logistic Regression, Support Vector Machine, and\nRandom Forest. For each data set, classification models were trained with\ndifferent training sample sizes using different learning algorithms. These\nmodels were then evaluated using a large randomly sampled test set of\ndocuments, and the results were compared using precision and recall curves. Our\nstudy demonstrates that CNN performed well, but that there was no single\nalgorithm that performed the best across the combination of data sets and\ntraining sample sizes. These results will help advance research into the legal\nprofession's use of machine learning algorithms that maximize performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:06:47 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Keeling", "Robert", ""], ["Chhatwal", "Rishi", ""], ["Huber-Fliflet", "Nathaniel", ""], ["Zhang", "Jianping", ""], ["Wei", "Fusheng", ""], ["Zhao", "Haozhen", ""], ["Ye", "Shi", ""], ["Qin", "Han", ""]]}, {"id": "1912.09501", "submitter": "Haozhen Zhao", "authors": "Christian J. Mahoney, Jianping Zhang, Nathaniel Huber-Fliflet, Peter\n  Gronvall, Haozhen Zhao", "title": "A Framework for Explainable Text Classification in Legal Document Review", "comments": "2019 IEEE International Conference on Big Data (Big Data). arXiv\n  admin note: text overlap with arXiv:1904.01721", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies regularly spend millions of dollars producing electronically-stored\ndocuments in legal matters. Recently, parties on both sides of the 'legal\naisle' are accepting the use of machine learning techniques like text\nclassification to cull massive volumes of data and to identify responsive\ndocuments for use in these matters. While text classification is regularly used\nto reduce the discovery costs in legal matters, it also faces a peculiar\nperception challenge: amongst lawyers, this technology is sometimes looked upon\nas a \"black box\", little information provided for attorneys to understand why\ndocuments are classified as responsive. In recent years, a group of AI and ML\nresearchers have been actively researching Explainable AI, in which actions or\ndecisions are human understandable. In legal document review scenarios, a\ndocument can be identified as responsive, if one or more of its text snippets\nare deemed responsive. In these scenarios, if text classification can be used\nto locate these snippets, then attorneys could easily evaluate the model's\nclassification decision. When deployed with defined and explainable results,\ntext classification can drastically enhance overall quality and speed of the\nreview process by reducing the review time. Moreover, explainable predictive\ncoding provides lawyers with greater confidence in the results of that\nsupervised learning task. This paper describes a framework for explainable text\nclassification as a valuable tool in legal services: for enhancing the quality\nand efficiency of legal document review and for assisting in locating\nresponsive snippets within responsive documents. This framework has been\nimplemented in our legal analytics product, which has been used in hundreds of\nlegal matters. We also report our experimental results using the data from an\nactual legal matter that used this type of document review.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:07:23 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mahoney", "Christian J.", ""], ["Zhang", "Jianping", ""], ["Huber-Fliflet", "Nathaniel", ""], ["Gronvall", "Peter", ""], ["Zhao", "Haozhen", ""]]}, {"id": "1912.09508", "submitter": "Zhe Liu", "authors": "Zhe Liu, Fuchun Peng", "title": "Statistical Testing on ASR Performance via Blockwise Bootstrap", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common question being raised in automatic speech recognition (ASR)\nevaluations is how reliable is an observed word error rate (WER) improvement\ncomparing two ASR systems, where statistical hypothesis testing and confidence\ninterval (CI) can be utilized to tell whether this improvement is real or only\ndue to random chance. The bootstrap resampling method has been popular for such\nsignificance analysis which is intuitive and easy to use. However, this method\nfails in dealing with dependent data, which is prevalent in speech world - for\nexample, ASR performance on utterances from the same speaker could be\ncorrelated. In this paper we present blockwise bootstrap approach - by dividing\nevaluation utterances into nonoverlapping blocks, this method resamples these\nblocks instead of original data. We show that the resulting variance estimator\nof absolute WER difference between two ASR systems is consistent under mild\nconditions. We also demonstrate the validity of blockwise bootstrap method on\nboth synthetic and real-world speech data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:20:09 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 22:51:25 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Liu", "Zhe", ""], ["Peng", "Fuchun", ""]]}, {"id": "1912.09522", "submitter": "Siqi Liu", "authors": "Siqi Liu and Milos Hauskrecht", "title": "Event Outlier Detection in Continuous Time", "comments": "ICML 2021 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time event sequences represent discrete events occurring in\ncontinuous time. Such sequences arise frequently in real-life. Usually we\nexpect the sequences to follow some regular pattern over time. However,\nsometimes these patterns may be interrupted by unexpected absence or\noccurrences of events. Identification of these unexpected cases can be very\nimportant as they may point to abnormal situations that need human attention.\nIn this work, we study and develop methods for detecting outliers in\ncontinuous-time event sequences, including unexpected absence and unexpected\noccurrences of events. Since the patterns that event sequences tend to follow\nmay change in different contexts, we develop outlier detection methods based on\npoint processes that can take context information into account. Our methods are\nbased on Bayesian decision theory and hypothesis testing with theoretical\nguarantees. To test the performance of the methods, we conduct experiments on\nboth synthetic data and real-world clinical data and show the effectiveness of\nthe proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:53:22 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:27:53 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 15:50:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Liu", "Siqi", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "1912.09526", "submitter": "Jeremy Ash", "authors": "Jeremy R. Ash and Jacqueline M. Hughes-Oliver", "title": "Confidence Bands and Hypothesis Test Methods for Recall and Precision\n  Curves at Extremely Small Fractions with Applications to Drug Discovery", "comments": "41 pages, 7 figures, 13 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IR cs.LG q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In virtual screening for drug discovery, recall curves are used to assess the\nperformance of ranking algorithms, in which recall is a function of the\nfraction of data prioritized for experimental testing. Unfortunately,\nresearchers almost never consider the uncertainty in the estimation of the\nrecall curve when benchmarking algorithms. We confirm that a recently developed\nprocedure for estimating pointwise confidence intervals for recall curves --\nand closely related variants, such as precision curves -- can be applied to a\nvariety of simulated data sets representative of those typically encountered in\nvirtual screening. Since it is more desirable in benchmarks to present the\nuncertainty of performance over a range of testing fractions, we extend the\npointwise confidence interval procedure to allow for the estimation of\nconfidence bands for these curves. We also present hypothesis test methods to\ndetermine significant differences between the curves for competing algorithms.\nWe show these methods have high power to detect significant differences at a\nrange of small fractions typically tested, while maintaining control of type I\nerror rate. These methods enable statistically rigorous comparisons of virtual\nscreening algorithms using a metric that quantifies the aspect of performance\nthat is of primary interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:08:03 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Ash", "Jeremy R.", ""], ["Hughes-Oliver", "Jacqueline M.", ""]]}, {"id": "1912.09528", "submitter": "Nirupam Gupta", "authors": "Nirupam Gupta and Nitin H. Vaidya", "title": "Randomized Reactive Redundancy for Byzantine Fault-Tolerance in\n  Parallelized Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report considers the problem of Byzantine fault-tolerance in synchronous\nparallelized learning that is founded on the parallelized stochastic gradient\ndescent (parallelized-SGD) algorithm. The system comprises a master, and $n$\nworkers, where up to $f$ of the workers are Byzantine faulty. Byzantine workers\nneed not follow the master's instructions correctly, and might send malicious\nincorrect (or faulty) information. The identity of the Byzantine workers\nremains fixed throughout the learning process, and is unknown a priori to the\nmaster. We propose two coding schemes, a deterministic scheme and a randomized\nscheme, for guaranteeing exact fault-tolerance if $2f < n$. The coding schemes\nuse the concept of reactive redundancy for isolating Byzantine workers that\neventually send faulty information. We note that the computation efficiencies\nof the schemes compare favorably with other (deterministic or randomized)\ncoding schemes, for exact fault-tolerance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:15:28 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Gupta", "Nirupam", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1912.09529", "submitter": "Akshay Agrawal", "authors": "Akshay Agrawal, Shane Barratt, Stephen Boyd, Bartolomeo Stellato", "title": "Learning Convex Optimization Control Policies", "comments": "Authors listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many control policies used in various applications determine the input or\naction by solving a convex optimization problem that depends on the current\nstate and some parameters. Common examples of such convex optimization control\npolicies (COCPs) include the linear quadratic regulator (LQR), convex model\npredictive control (MPC), and convex control-Lyapunov or approximate dynamic\nprogramming (ADP) policies. These types of control policies are tuned by\nvarying the parameters in the optimization problem, such as the LQR weights, to\nobtain good performance, judged by application-specific metrics. Tuning is\noften done by hand, or by simple methods such as a crude grid search. In this\npaper we propose a method to automate this process, by adjusting the parameters\nusing an approximate gradient of the performance metric with respect to the\nparameters. Our method relies on recently developed methods that can\nefficiently evaluate the derivative of the solution of a convex optimization\nproblem with respect to its parameters. We illustrate our method on several\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:16:15 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Agrawal", "Akshay", ""], ["Barratt", "Shane", ""], ["Boyd", "Stephen", ""], ["Stellato", "Bartolomeo", ""]]}, {"id": "1912.09532", "submitter": "Van Nhan Nguyen", "authors": "Van Nhan Nguyen, Robert Jenssen, and Davide Roverso", "title": "LS-Net: Fast Single-Shot Line-Segment Detector", "comments": "Highlighted the paper's contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In low-altitude Unmanned Aerial Vehicle (UAV) flights, power lines are\nconsidered as one of the most threatening hazards and one of the most difficult\nobstacles to avoid. In recent years, many vision-based techniques have been\nproposed to detect power lines to facilitate self-driving UAVs and automatic\nobstacle avoidance. However, most of the proposed methods are typically based\non a common three-step approach: (i) edge detection, (ii) the Hough transform,\nand (iii) spurious line elimination based on power line constrains. These\napproaches not only are slow and inaccurate but also require a huge amount of\neffort in post-processing to distinguish between power lines and spurious\nlines. In this paper, we introduce LS-Net, a fast single-shot line-segment\ndetector, and apply it to power line detection. The LS-Net is by design fully\nconvolutional and consists of three modules: (i) a fully convolutional feature\nextractor, (ii) a classifier, and (iii) a line segment regressor. Due to the\nunavailability of large datasets with annotations of power lines, we render\nsynthetic images of power lines using the Physically Based Rendering (PBR)\napproach and propose a series of effective data augmentation techniques to\ngenerate more training data. With a customized version of the VGG-16 network as\nthe backbone, the proposed approach outperforms existing state-of-the-art\napproaches. In addition, the LS-Net can detect power lines in near real-time\n(20.4 FPS). This suggests that our proposed approach has a promising role in\nautomatic obstacle avoidance and as a valuable component of self-driving UAVs,\nespecially for automatic autonomous power line inspection.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:19:51 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:39:00 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Nguyen", "Van Nhan", ""], ["Jenssen", "Robert", ""], ["Roverso", "Davide", ""]]}, {"id": "1912.09533", "submitter": "Jeet Mohapatra", "authors": "Jeet Mohapatra, Tsui-Wei (Lily) Weng, Pin-Yu Chen, Sijia Liu and Luca\n  Daniel", "title": "Towards Verifying Robustness of Neural Networks Against Semantic\n  Perturbations", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying robustness of neural networks given a specified threat model is a\nfundamental yet challenging task. While current verification methods mainly\nfocus on the $\\ell_p$-norm threat model of the input instances, robustness\nverification against semantic adversarial attacks inducing large $\\ell_p$-norm\nperturbations, such as color shifting and lighting adjustment, are beyond their\ncapacity. To bridge this gap, we propose \\textit{Semantify-NN}, a\nmodel-agnostic and generic robustness verification approach against semantic\nperturbations for neural networks. By simply inserting our proposed\n\\textit{semantic perturbation layers} (SP-layers) to the input layer of any\ngiven model, \\textit{Semantify-NN} is model-agnostic, and any $\\ell_p$-norm\nbased verification tools can be used to verify the model robustness against\nsemantic perturbations. We illustrate the principles of designing the SP-layers\nand provide examples including semantic perturbations to image classification\nin the space of hue, saturation, lightness, brightness, contrast and rotation,\nrespectively. In addition, an efficient refinement technique is proposed to\nfurther significantly improve the semantic certificate. Experiments on various\nnetwork architectures and different datasets demonstrate the superior\nverification performance of \\textit{Semantify-NN} over $\\ell_p$-norm-based\nverification frameworks that naively convert semantic perturbation to\n$\\ell_p$-norm. The results show that \\textit{Semantify-NN} can support\nrobustness verification against a wide range of semantic perturbations.\n  Code available https://github.com/JeetMo/Semantify-NN\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:21:03 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 17:54:53 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mohapatra", "Jeet", "", "Lily"], ["Tsui-Wei", "", "", "Lily"], ["Weng", "", ""], ["Chen", "Pin-Yu", ""], ["Liu", "Sijia", ""], ["Daniel", "Luca", ""]]}, {"id": "1912.09536", "submitter": "Subru Krishnan", "authors": "Fotis Psallidas, Yiwen Zhu, Bojan Karlas, Matteo Interlandi, Avrilia\n  Floratou, Konstantinos Karanasos, Wentao Wu, Ce Zhang, Subru Krishnan, Carlo\n  Curino, Markus Weimer", "title": "Data Science through the looking glass and what we found there", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent success of machine learning (ML) has led to an explosive growth\nboth in terms of new systems and algorithms built in industry and academia, and\nnew applications built by an ever-growing community of data science (DS)\npractitioners. This quickly shifting panorama of technologies and applications\nis challenging for builders and practitioners alike to follow. In this paper,\nwe set out to capture this panorama through a wide-angle lens, by performing\nthe largest analysis of DS projects to date, focusing on questions that can\nhelp determine investments on either side. Specifically, we download and\nanalyze: (a) over 6M Python notebooks publicly available on GITHUB, (b) over 2M\nenterprise DS pipelines developed within COMPANYX, and (c) the source code and\nmetadata of over 900 releases from 12 important DS libraries. The analysis we\nperform ranges from coarse-grained statistical characterizations to analysis of\nlibrary imports, pipelines, and comparative studies across datasets and time.\nWe report a large number of measurements for our readers to interpret, and dare\nto draw a few (actionable, yet subjective) conclusions on (a) what systems\nbuilders should focus on to better serve practitioners, and (b) what\ntechnologies should practitioners bet on given current trends. We plan to\nautomate this analysis and release associated tools and results periodically.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 20:29:44 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Psallidas", "Fotis", ""], ["Zhu", "Yiwen", ""], ["Karlas", "Bojan", ""], ["Interlandi", "Matteo", ""], ["Floratou", "Avrilia", ""], ["Karanasos", "Konstantinos", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""], ["Krishnan", "Subru", ""], ["Curino", "Carlo", ""], ["Weimer", "Markus", ""]]}, {"id": "1912.09551", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro and Vinay P. Namboodiri", "title": "Deep Exemplar Networks for VQA and VQG", "comments": "This work is an extension of CVPR-2018 accepted paper\n  arXiv:1804.00298 and EMNLP-2018 accepted paper arXiv:1808.03986", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we consider the problem of solving semantic tasks such as\n`Visual Question Answering' (VQA), where one aims to answers related to an\nimage and `Visual Question Generation' (VQG), where one aims to generate a\nnatural question pertaining to an image. Solutions for VQA and VQG tasks have\nbeen proposed using variants of encoder-decoder deep learning based frameworks\nthat have shown impressive performance. Humans however often show\ngeneralization by relying on exemplar based approaches. For instance, the work\nby Tversky and Kahneman suggests that humans use exemplars when making\ncategorizations and decisions. In this work, we propose the incorporation of\nexemplar based approaches towards solving these problems. Specifically, we\nincorporate exemplar based approaches and show that an exemplar based module\ncan be incorporated in almost any of the deep learning architectures proposed\nin the literature and the addition of such a block results in improved\nperformance for solving these tasks. Thus, just as the incorporation of\nattention is now considered de facto useful for solving these tasks, similarly,\nincorporating exemplars also can be considered to improve any proposed\narchitecture for solving this task. We provide extensive empirical analysis for\nthe same through various architectures, ablations, and state of the art\ncomparisons.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 21:29:22 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Patro", "Badri N.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1912.09570", "submitter": "Erik Bollt", "authors": "Erik Bollt", "title": "Geometric Considerations of a Good Dictionary for Koopman Analysis of\n  Dynamical Systems: Cardinality, 'Primary Eigenfunction,' and Efficient\n  Representation", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation of a dynamical system in terms of simplifying modes is a\ncentral premise of reduced order modelling and a primary concern of the\nincreasingly popular DMD (dynamic mode decomposition) empirical interpretation\nof Koopman operator analysis of complex systems. In the spirit of optimal\napproximation and reduced order modelling the goal of DMD methods and variants\nare to describe the dynamical evolution as a linear evolution in an\nappropriately transformed lower rank space, as best as possible.\n  That Koopman eigenfunctions follow a linear PDE that is solvable by the\nmethod of characteristics yields several interesting relationships between\ngeometric and algebraic properties.\n  Corresponding to freedom to arbitrarily define functions on a data surface,\nfor each eigenvalue, there are infinitely many eigenfunctions emanating along\ncharacteristics. We focus on contrasting cardinality and equivalence. In\nparticular, we introduce an equivalence class, \"primary eigenfunctions,\"\nconsisting of those eigenfunctions with identical sets of level sets, that\nhelps contrast algebraic multiplicity from other geometric aspects.\n  Popularly, Koopman methods and notably dynamic mode decomposition (DMD) and\nvariants, allow data-driven study of how measurable functions evolve along\norbits. As far as we know, there has not been an in depth study regarding the\nunderlying geometry as related to an efficient representation. We present a\nconstruction that leads to functions on the data surface whose corresponding\neigenfunctions are efficient in a least squares sense. We call this\nconstruction optimal Koopman eigenfunction DMD, (oKEEDMD), and we highlight\nwith examples.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:12:17 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:25:46 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 23:05:52 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 20:18:01 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Bollt", "Erik", ""]]}, {"id": "1912.09572", "submitter": "Behnam Kiani Kalejahi", "authors": "Ulkar Ahmadova, Laman Mammadova, Behnam Kiani Kalejahi", "title": "Implementation of encryption on telemedicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the era of technology, data security is one of the most important things\nthat both individuals and companies need. Information plays a huge role in our\neveryday life and keeping it safe should be our number one priority. Nowadays\nmost of the information is transferred via the internet. One of the ways to use\nit is telemedicine. With the help of telemedicine, people can have an\nappointment at the doctors without losing their time or money. All of the\ninformation about one's health is transferred through the internet but is it\nthat safe? What techniques are used to provide the safety of our confidential\ninformation? To guarantee that the information is not changed or that in case\nit will be stolen no one can still have access to it.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 07:12:54 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 08:28:39 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ahmadova", "Ulkar", ""], ["Mammadova", "Laman", ""], ["Kalejahi", "Behnam Kiani", ""]]}, {"id": "1912.09575", "submitter": "Mustafa Coskun", "authors": "Mustafa Coskun, Burcu Bakir Gungor, Mehmet Koyuturk", "title": "Expanding Label Sets for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, Graph Convolutional Networks (GCNs) and their variants have\nbeen widely utilized in learning tasks that involve graphs. These tasks include\nrecommendation systems, node classification, among many others. In node\nclassification problem, the input is a graph in which the edges represent the\nassociation between pairs of nodes, multi-dimensional feature vectors are\nassociated with the nodes, and some of the nodes in the graph have known\nlabels. The objective is to predict the labels of the nodes that are not\nlabeled, using the nodes features, in conjunction with graph topology. While\nGCNs have been successfully applied to this problem, the caveats that they\ninherit from traditional deep learning models pose significant challenges to\nbroad utilization of GCNs in node classification. One such caveat is that\ntraining a GCN requires a large number of labeled training instances, which is\noften not the case in realistic settings. To remedy this requirement,\nstate-of-the-art methods leverage network diffusion-based approaches to\npropagate labels across the network before training GCNs. However, these\napproaches ignore the tendency of the network diffusion methods in biasing\nproximity with centrality, resulting in the propagation of labels to the nodes\nthat are well-connected in the graph. To address this problem, here we present\nan alternate approach to extrapolating node labels in GCNs in the following\nthree steps: (i) clustering of the network to identify communities, (ii) use of\nnetwork diffusion algorithms to quantify the proximity of each node to the\ncommunities, thereby obtaining a low-dimensional topological profile for each\nnode, (iii) comparing these topological profiles to identify nodes that are\nmost similar to the labeled nodes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 14:10:16 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Coskun", "Mustafa", ""], ["Gungor", "Burcu Bakir", ""], ["Koyuturk", "Mehmet", ""]]}, {"id": "1912.09579", "submitter": "Junfeng Guan", "authors": "Junfeng Guan, Sohrab Madani, Suraj Jog, Haitham Hassanieh", "title": "High Resolution Millimeter Wave Imaging For Self-Driving Cars", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed much interest in expanding the use of networking\nsignals beyond communication to sensing, localization, robotics, and autonomous\nsystems. This paper explores how we can leverage recent advances in 5G\nmillimeter wave (mmWave) technology for imaging in self-driving cars.\nSpecifically, the use of mmWave in 5G has led to the creation of compact phased\narrays with hundreds of antenna elements that can be electronically steered.\nSuch phased arrays can expand the use of mmWave beyond vehicular communications\nand simple ranging sensors to a full-fledged imaging system that enables\nself-driving cars to see through fog, smog, snow, etc. Unfortunately, using\nmmWave signals for imaging in self-driving cars is challenging due to the very\nlow resolution, the presence of fake artifacts resulting from multipath\nreflections and the absence of portions of the car due to specularity. This\npaper presents HawkEye, a system that can enable high resolution mmWave imaging\nin self driving cars. HawkEye addresses the above challenges by leveraging\nrecent advances in deep learning known as Generative Adversarial Networks\n(GANs). HawkEye introduces a GAN architecture that is customized to mmWave\nimaging and builds a system that can significantly enhance the quality of\nmmWave images for self-driving cars.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 22:27:56 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 22:35:12 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Guan", "Junfeng", ""], ["Madani", "Sohrab", ""], ["Jog", "Suraj", ""], ["Hassanieh", "Haitham", ""]]}, {"id": "1912.09588", "submitter": "Andres Potapczynski", "authors": "Andres Potapczynski, Gabriel Loaiza-Ganem, John P. Cunningham", "title": "Invertible Gaussian Reparameterization: Revisiting the Gumbel-Softmax", "comments": "Accepted at NeurIPS 2020", "journal-ref": "Published: NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gumbel-Softmax is a continuous distribution over the simplex that is\noften used as a relaxation of discrete distributions. Because it can be readily\ninterpreted and easily reparameterized, it enjoys widespread use. We propose a\nmodular and more flexible family of reparameterizable distributions where\nGaussian noise is transformed into a one-hot approximation through an\ninvertible function. This invertible function is composed of a modified softmax\nand can incorporate diverse transformations that serve different specific\npurposes. For example, the stick-breaking procedure allows us to extend the\nreparameterization trick to distributions with countably infinite support, thus\nenabling the use of our distribution along nonparametric models, or normalizing\nflows let us increase the flexibility of the distribution. Our construction\nenjoys theoretical advantages over the Gumbel-Softmax, such as closed form KL,\nand significantly outperforms it in a variety of experiments. Our code is\navailable at https://github.com/cunningham-lab/igr.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 23:11:39 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 19:35:17 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 23:07:40 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 18:26:19 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Potapczynski", "Andres", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Cunningham", "John P.", ""]]}, {"id": "1912.09592", "submitter": "Ihsan Ullah", "authors": "Ihsan Ullah, Mario Manzo, Mitul Shah, Michael Madden", "title": "Graph Convolutional Networks: analysis, improvements and results", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current era of neural networks and big data, higher dimensional data\nis processed for automation of different application areas. Graphs represent a\ncomplex data organization in which dependencies between more than one object or\nactivity occur. Due to the high dimensionality, this data creates challenges\nfor machine learning algorithms. Graph convolutional networks were introduced\nto utilize the convolutional models concepts that shows good results. In this\ncontext, we enhanced two of the existing Graph convolutional network models by\nproposing four enhancements. These changes includes: hyper parameters\noptimization, convex combination of activation functions, topological\ninformation enrichment through clustering coefficients measure, and structural\nredesign of the network through addition of dense layers. We present extensive\nresults on four state-of-art benchmark datasets. The performance is notable not\nonly in terms of lesser computational cost compared to competitors, but also\nachieved competitive results for three of the datasets and state-of-the-art for\nthe fourth dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 23:56:18 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Ullah", "Ihsan", ""], ["Manzo", "Mario", ""], ["Shah", "Mitul", ""], ["Madden", "Michael", ""]]}, {"id": "1912.09593", "submitter": "Wei Huang", "authors": "Wei Huang, Richard Yi Da Xu", "title": "Gaussian Process Latent Variable Model Factorization for Context-aware\n  Recommender Systems", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware recommender systems (CARS) have gained increasing attention due\nto their ability to utilize contextual information. Compared to traditional\nrecommender systems, CARS are, in general, able to generate more accurate\nrecommendations. Latent factors approach accounts for a large proportion of\nCARS. Recently, a non-linear Gaussian Process (GP) based factorization method\nwas proven to outperform the state-of-the-art methods in CARS. Despite its\neffectiveness, GP model-based methods can suffer from over-fitting and may not\nbe able to determine the impact of each context automatically. In order to\naddress such shortcomings, we propose a Gaussian Process Latent Variable Model\nFactorization (GPLVMF) method, where we apply an appropriate prior to the\noriginal GP model. Our work is primarily inspired by the Gaussian Process\nLatent Variable Model (GPLVM), which was a non-linear dimensionality reduction\nmethod. As a result, we improve the performance on the real datasets\nsignificantly as well as capturing the importance of each context. In addition\nto the general advantages, our method provides two main contributions regarding\nrecommender system settings: (1) addressing the influence of bias by setting a\nnon-zero mean function, and (2) utilizing real-valued contexts by fixing the\nlatent space with real values.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 23:57:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Wei", ""], ["Da Xu", "Richard Yi", ""]]}, {"id": "1912.09595", "submitter": "Johan Samir Obando Ceron", "authors": "Johan S. Obando-Ceron, Victor Romero Cano, Walter Mayor Toro", "title": "Exploiting the potential of deep reinforcement learning for\n  classification tasks in high-dimensional and unstructured data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for efficiently learning feature selection\npolicies which use less features to reach a high classification precision on\nlarge unstructured data. It uses a Deep Convolutional Autoencoder (DCAE) for\nlearning compact feature spaces, in combination with recently-proposed\nReinforcement Learning (RL) algorithms as Double DQN and Retrace.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 00:27:34 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Obando-Ceron", "Johan S.", ""], ["Cano", "Victor Romero", ""], ["Toro", "Walter Mayor", ""]]}, {"id": "1912.09600", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Sajad Darabi, Shayan Fazeli, Majid Sarrafzadeh", "title": "Group-Connected Multilayer Perceptron Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of deep learning in domains such as image, voice, and\ngraphs, there has been little progress in deep representation learning for\ndomains without a known structure between features. For instance, a tabular\ndataset of different demographic and clinical factors where the feature\ninteractions are not given as a prior. In this paper, we propose\nGroup-Connected Multilayer Perceptron (GMLP) networks to enable deep\nrepresentation learning in these domains. GMLP is based on the idea of learning\nexpressive feature combinations (groups) and exploiting them to reduce the\nnetwork complexity by defining local group-wise operations. During the training\nphase, GMLP learns a sparse feature grouping matrix using temperature annealing\nsoftmax with an added entropy loss term to encourage the sparsity. Furthermore,\nan architecture is suggested which resembles binary trees, where group-wise\noperations are followed by pooling operations to combine information; reducing\nthe number of groups as the network grows in depth. To evaluate the proposed\nmethod, we conducted experiments on different real-world datasets covering\nvarious application areas. Additionally, we provide visualizations on MNIST and\nsynthesized data. According to the results, GMLP is able to successfully learn\nand exploit expressive feature combinations and achieve state-of-the-art\nclassification performance on different datasets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 00:49:07 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:22:39 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 16:56:55 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Darabi", "Sajad", ""], ["Fazeli", "Shayan", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1912.09614", "submitter": "Alireza Abdoli", "authors": "Sara Alaee, Alireza Abdoli, Christian Shelton, Amy C. Murillo, Alec C.\n  Gerry, Eamonn Keogh", "title": "Features or Shape? Tackling the False Dichotomy of Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification is an important task in its own right, and it is\noften a precursor to further downstream analytics. To date, virtually all works\nin the literature have used either shape-based classification using a distance\nmeasure or feature-based classification after finding some suitable features\nfor the domain. It seems to be underappreciated that in many datasets it is the\ncase that some classes are best discriminated with features, while others are\nbest discriminated with shape. Thus, making the shape vs. feature choice will\ncondemn us to poor results, at least for some classes. In this work, we propose\na new model for classifying time series that allows the use of both shape and\nfeature-based measures, when warranted. Our algorithm automatically decides\nwhich approach is best for which class, and at query time chooses which\nclassifier to trust the most. We evaluate our idea on real world datasets and\ndemonstrate that our ideas produce statistically significant improvement in\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 02:24:41 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Alaee", "Sara", ""], ["Abdoli", "Alireza", ""], ["Shelton", "Christian", ""], ["Murillo", "Amy C.", ""], ["Gerry", "Alec C.", ""], ["Keogh", "Eamonn", ""]]}, {"id": "1912.09621", "submitter": "Barath Narayanan Narayanan", "authors": "Barath Narayanan Narayanan, Manawaduge Supun De Silva, Russell C.\n  Hardie, Nathan K. Kueterman, Redha Ali", "title": "Understanding Deep Neural Network Predictions for Medical Imaging\n  Applications", "comments": "20 pages, 28 Figures and 9 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-aided detection has been a research area attracting great interest\nin the past decade. Machine learning algorithms have been utilized extensively\nfor this application as they provide a valuable second opinion to the doctors.\nDespite several machine learning models being available for medical imaging\napplications, not many have been implemented in the real-world due to the\nuninterpretable nature of the decisions made by the network. In this paper, we\ninvestigate the results provided by deep neural networks for the detection of\nmalaria, diabetic retinopathy, brain tumor, and tuberculosis in different\nimaging modalities. We visualize the class activation mappings for all the\napplications in order to enhance the understanding of these networks. This type\nof visualization, along with the corresponding network performance metrics,\nwould aid the data science experts in better understanding of their models as\nwell as assisting doctors in their decision-making process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 02:57:05 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Narayanan", "Barath Narayanan", ""], ["De Silva", "Manawaduge Supun", ""], ["Hardie", "Russell C.", ""], ["Kueterman", "Nathan K.", ""], ["Ali", "Redha", ""]]}, {"id": "1912.09624", "submitter": "Can Chen", "authors": "Can Chen and Indika Rajapakse", "title": "Tensor Entropy for Uniform Hypergraphs", "comments": "12 pages, 11 figures, 1 table, IEEE Transactions on Network Science\n  and Engineering, accepted to appear", "journal-ref": null, "doi": "10.1109/TNSE.2020.3002963", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop the notion of entropy for uniform hypergraphs via\ntensor theory. We employ the probability distribution of the generalized\nsingular values, calculated from the higher-order singular value decomposition\nof the Laplacian tensors, to fit into the Shannon entropy formula. We show that\nthis tensor entropy is an extension of von Neumann entropy for graphs. In\naddition, we establish results on the lower and upper bounds of the entropy and\ndemonstrate that it is a measure of regularity for uniform hypergraphs in\nsimulated and experimental data. We exploit the tensor train decomposition in\ncomputing the proposed tensor entropy efficiently. Finally, we introduce the\nnotion of robustness for uniform hypergraphs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 03:26:45 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 21:18:57 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 18:38:48 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 18:59:37 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Chen", "Can", ""], ["Rajapakse", "Indika", ""]]}, {"id": "1912.09630", "submitter": "Sina Mohseni", "authors": "Sina Mohseni and Mandar Pitale and Vasu Singh and Zhangyang Wang", "title": "Practical Solutions for Machine Learning Safety in Autonomous Vehicles", "comments": "Accepted at Safe AI workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles rely on machine learning to solve challenging tasks in\nperception and motion planning. However, automotive software safety standards\nhave not fully evolved to address the challenges of machine learning safety\nsuch as interpretability, verification, and performance limitations. In this\npaper, we review and organize practical machine learning safety techniques that\ncan complement engineering safety for machine learning based software in\nautonomous vehicles. Our organization maps safety strategies to\nstate-of-the-art machine learning techniques in order to enhance dependability\nand safety of machine learning algorithms. We also discuss security limitations\nand user experience aspects of machine learning components in autonomous\nvehicles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 03:47:28 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mohseni", "Sina", ""], ["Pitale", "Mandar", ""], ["Singh", "Vasu", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1912.09652", "submitter": "JingKai Sioww", "authors": "JingKai Siow, Cuiyun Gao, Lingling Fan, Sen Chen, Yang Liu", "title": "CORE: Automating Review Recommendation for Code Changes", "comments": "Accepted by 27th IEEE International Conference on Software Analysis,\n  Evolution and Reengineering (SANER)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code review is a common process that is used by developers, in which a\nreviewer provides useful comments or points out defects in the submitted source\ncode changes via pull request. Code review has been widely used for both\nindustry and open-source projects due to its capacity in early defect\nidentification, project maintenance, and code improvement. With rapid updates\non project developments, code review becomes a non-trivial and labor-intensive\ntask for reviewers. Thus, an automated code review engine can be beneficial and\nuseful for project development in practice. Although there exist prior studies\non automating the code review process by adopting static analysis tools or deep\nlearning techniques, they often require external sources such as partial or\nfull source code for accurate review suggestion. In this paper, we aim at\nautomating the code review process only based on code changes and the\ncorresponding reviews but with better performance. The hinge of accurate code\nreview suggestion is to learn good representations for both code changes and\nreviews. To achieve this with limited source, we design a multi-level embedding\n(i.e., word embedding and character embedding) approach to represent the\nsemantics provided by code changes and reviews. The embeddings are then well\ntrained through a proposed attentional deep learning model, as a whole named\nCORE. We evaluate the effectiveness of CORE on code changes and reviews\ncollected from 19 popular Java projects hosted on Github. Experimental results\nshow that our model CORE can achieve significantly better performance than the\nstate-of-the-art model (DeepMem), with an increase of 131.03% in terms of\nRecall@10 and 150.69% in terms of Mean Reciprocal Rank. Qualitative general\nword analysis among project developers also demonstrates the performance of\nCORE in automating code review.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 06:14:18 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Siow", "JingKai", ""], ["Gao", "Cuiyun", ""], ["Fan", "Lingling", ""], ["Chen", "Sen", ""], ["Liu", "Yang", ""]]}, {"id": "1912.09656", "submitter": "Diego Granziol", "authors": "Diego Granziol, Xingchen Wan, Timur Garipov", "title": "Deep Curvature Suite", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MLRG Deep Curvature suite, a PyTorch-based, open-source package\nfor analysis and visualisation of neural network curvature and loss landscape.\nDespite of providing rich information into properties of neural network and\nuseful for a various designed tasks, curvature information is still not made\nsufficient use for various reasons, and our method aims to bridge this gap. We\npresent a primer, including its main practical desiderata and common\nmisconceptions, of \\textit{Lanczos algorithm}, the theoretical backbone of our\npackage, and present a series of examples based on synthetic toy examples and\nrealistic modern neural networks tested on CIFAR datasets, and show the\nsuperiority of our package against existing competing approaches for the\nsimilar purposes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 06:37:40 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 18:36:35 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Granziol", "Diego", ""], ["Wan", "Xingchen", ""], ["Garipov", "Timur", ""]]}, {"id": "1912.09666", "submitter": "Qing Jin", "authors": "Qing Jin, Linjie Yang, Zhenyu Liao", "title": "AdaBits: Neural Network Quantization with Adaptive Bit-Widths", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with adaptive configurations have gained increasing\nattention due to the instant and flexible deployment of these models on\nplatforms with different resource budgets. In this paper, we investigate a\nnovel option to achieve this goal by enabling adaptive bit-widths of weights\nand activations in the model. We first examine the benefits and challenges of\ntraining quantized model with adaptive bit-widths, and then experiment with\nseveral approaches including direct adaptation, progressive training and joint\ntraining. We discover that joint training is able to produce comparable\nperformance on the adaptive model as individual models. We further propose a\nnew technique named Switchable Clipping Level (S-CL) to further improve\nquantized models at the lowest bit-width. With our proposed techniques applied\non a bunch of models including MobileNet-V1/V2 and ResNet-50, we demonstrate\nthat bit-width of weights and activations is a new option for adaptively\nexecutable deep neural networks, offering a distinct opportunity for improved\naccuracy-efficiency trade-off as well as instant adaptation according to the\nplatform constraints in real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 07:10:23 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 19:42:05 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Jin", "Qing", ""], ["Yang", "Linjie", ""], ["Liao", "Zhenyu", ""]]}, {"id": "1912.09670", "submitter": "Faqiang Liu", "authors": "Faqiang Liu, Mingkun Xu, Guoqi Li, Jing Pei, Luping Shi, Rong Zhao", "title": "Adversarial symmetric GANs: bridging adversarial samples and adversarial\n  networks", "comments": null, "journal-ref": "Neural networks,2020", "doi": "10.1016/j.neunet.2020.10.016", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks have achieved remarkable performance on\nvarious tasks but suffer from training instability. Despite many training\nstrategies proposed to improve training stability, this issue remains as a\nchallenge. In this paper, we investigate the training instability from the\nperspective of adversarial samples and reveal that adversarial training on fake\nsamples is implemented in vanilla GANs, but adversarial training on real\nsamples has long been overlooked. Consequently, the discriminator is extremely\nvulnerable to adversarial perturbation and the gradient given by the\ndiscriminator contains non-informative adversarial noises, which hinders the\ngenerator from catching the pattern of real samples. Here, we develop\nadversarial symmetric GANs (AS-GANs) that incorporate adversarial training of\nthe discriminator on real samples into vanilla GANs, making adversarial\ntraining symmetrical. The discriminator is therefore more robust and provides\nmore informative gradient with less adversarial noise, thereby stabilizing\ntraining and accelerating convergence. The effectiveness of the AS-GANs is\nverified on image generation on CIFAR-10 , CelebA, and LSUN with varied network\narchitectures. Not only the training is more stabilized, but the FID scores of\ngenerated samples are consistently improved by a large margin compared to the\nbaseline. The bridging of adversarial samples and adversarial networks provides\na new approach to further develop adversarial networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 07:20:13 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 01:29:37 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 06:20:27 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 06:48:08 GMT"}, {"version": "v5", "created": "Sat, 14 Nov 2020 01:05:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Liu", "Faqiang", ""], ["Xu", "Mingkun", ""], ["Li", "Guoqi", ""], ["Pei", "Jing", ""], ["Shi", "Luping", ""], ["Zhao", "Rong", ""]]}, {"id": "1912.09705", "submitter": "Guodong Shi", "authors": "Deming Yuan and Alexandre Proutiere and Guodong Shi", "title": "Distributed Online Optimization with Long-Term Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed online convex optimization problems, where the\ndistributed system consists of various computing units connected through a\ntime-varying communication graph. In each time step, each computing unit\nselects a constrained vector, experiences a loss equal to an arbitrary convex\nfunction evaluated at this vector, and may communicate to its neighbors in the\ngraph. The objective is to minimize the system-wide loss accumulated over time.\nWe propose a decentralized algorithm with regret and cumulative constraint\nviolation in $\\mathcal{O}(T^{\\max\\{c,1-c\\} })$ and $\\mathcal{O}(T^{1-c/2})$,\nrespectively, for any $c\\in (0,1)$, where $T$ is the time horizon. When the\nloss functions are strongly convex, we establish improved regret and constraint\nviolation upper bounds in $\\mathcal{O}(\\log(T))$ and\n$\\mathcal{O}(\\sqrt{T\\log(T)})$. These regret scalings match those obtained by\nstate-of-the-art algorithms and fundamental limits in the corresponding\ncentralized online optimization problem (for both convex and strongly convex\nloss functions). In the case of bandit feedback, the proposed algorithms\nachieve a regret and constraint violation in $\\mathcal{O}(T^{\\max\\{c,1-c/3 \\}\n})$ and $\\mathcal{O}(T^{1-c/2})$ for any $c\\in (0,1)$. We numerically\nillustrate the performance of our algorithms for the particular case of\ndistributed online regularized linear regression problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:07:28 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Yuan", "Deming", ""], ["Proutiere", "Alexandre", ""], ["Shi", "Guodong", ""]]}, {"id": "1912.09713", "submitter": "Marc van Zee", "authors": "Daniel Keysers, Nathanael Sch\\\"arli, Nathan Scales, Hylke Buisman,\n  Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz\n  Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang, Marc van Zee, Olivier\n  Bousquet", "title": "Measuring Compositional Generalization: A Comprehensive Method on\n  Realistic Data", "comments": "Accepted for publication at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art machine learning methods exhibit limited compositional\ngeneralization. At the same time, there is a lack of realistic benchmarks that\ncomprehensively measure this ability, which makes it challenging to find and\nevaluate improvements. We introduce a novel method to systematically construct\nsuch benchmarks by maximizing compound divergence while guaranteeing a small\natom divergence between train and test sets, and we quantitatively compare this\nmethod to other approaches for creating compositional generalization\nbenchmarks. We present a large and realistic natural language question\nanswering dataset that is constructed according to this method, and we use it\nto analyze the compositional generalization ability of three machine learning\narchitectures. We find that they fail to generalize compositionally and that\nthere is a surprisingly strong negative correlation between compound divergence\nand accuracy. We also demonstrate how our method can be used to create new\ncompositionality benchmarks on top of the existing SCAN dataset, which confirms\nthese findings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:32:41 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 06:38:53 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Keysers", "Daniel", ""], ["Sch\u00e4rli", "Nathanael", ""], ["Scales", "Nathan", ""], ["Buisman", "Hylke", ""], ["Furrer", "Daniel", ""], ["Kashubin", "Sergii", ""], ["Momchev", "Nikola", ""], ["Sinopalnikov", "Danila", ""], ["Stafiniak", "Lukasz", ""], ["Tihon", "Tibor", ""], ["Tsarkov", "Dmitry", ""], ["Wang", "Xiao", ""], ["van Zee", "Marc", ""], ["Bousquet", "Olivier", ""]]}, {"id": "1912.09720", "submitter": "Ali Mottaghi", "authors": "Ali Mottaghi and Serena Yeung", "title": "Adversarial Representation Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to develop label-efficient algorithms by querying the\nmost informative samples to be labeled by an oracle. The design of efficient\ntraining methods that require fewer labels is an important research direction\nthat allows more effective use of computational and human resources for\nlabeling and training deep neural networks. In this work, we demonstrate how we\ncan use recent advances in deep generative models, to outperform the\nstate-of-the-art in achieving the highest classification accuracy using as few\nlabels as possible. Unlike previous approaches, our approach uses not only\nlabeled images to train the classifier but also unlabeled images and generated\nimages for co-training the whole model. Our experiments show that the proposed\nmethod significantly outperforms existing approaches in active learning on a\nwide range of datasets (MNIST, CIFAR-10, SVHN, CelebA, and ImageNet).\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:42:06 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Mottaghi", "Ali", ""], ["Yeung", "Serena", ""]]}, {"id": "1912.09722", "submitter": "Shujie Han", "authors": "Shujie Han, Jun Wu, Erci Xu, Cheng He, Patrick P. C. Lee, Yi Qiang,\n  Qixing Zheng, Tao Huang, Zixi Huang, Rui Li", "title": "Robust Data Preprocessing for Machine-Learning-Based Disk Failure\n  Prediction in Cloud Production Environments", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide proactive fault tolerance for modern cloud data centers, extensive\nstudies have proposed machine learning (ML) approaches to predict imminent disk\nfailures for early remedy and evaluated their approaches directly on public\ndatasets (e.g., Backblaze SMART logs). However, in real-world production\nenvironments, the data quality is imperfect (e.g., inaccurate labeling, missing\ndata samples, and complex failure types), thereby degrading the prediction\naccuracy. We present RODMAN, a robust data preprocessing pipeline that refines\ndata samples before feeding them into ML models. We start with a large-scale\ntrace-driven study of over three million disks from Alibaba Cloud's data\ncenters, and motivate the practical challenges in ML-based disk failure\nprediction. We then design RODMAN with three data preprocessing echniques,\nnamely failure-type filtering, spline-based data filling, and automated\npre-failure backtracking, that are applicable for general ML models. Evaluation\non both the Alibaba and Backblaze datasets shows that RODMAN improves the\nprediction accuracy compared to without data preprocessing under various\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:43:25 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Han", "Shujie", ""], ["Wu", "Jun", ""], ["Xu", "Erci", ""], ["He", "Cheng", ""], ["Lee", "Patrick P. C.", ""], ["Qiang", "Yi", ""], ["Zheng", "Qixing", ""], ["Huang", "Tao", ""], ["Huang", "Zixi", ""], ["Li", "Rui", ""]]}, {"id": "1912.09729", "submitter": "Deheng Ye", "authors": "Deheng Ye, Zhao Liu, Mingfei Sun, Bei Shi, Peilin Zhao, Hao Wu,\n  Hongsheng Yu, Shaojie Yang, Xipeng Wu, Qingwei Guo, Qiaobo Chen, Yinyuting\n  Yin, Hao Zhang, Tengfei Shi, Liang Wang, Qiang Fu, Wei Yang, Lanxiao Huang", "title": "Mastering Complex Control in MOBA Games with Deep Reinforcement Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning problem of complex action control in the\nMulti-player Online Battle Arena (MOBA) 1v1 games. This problem involves far\nmore complicated state and action spaces than those of traditional 1v1 games,\nsuch as Go and Atari series, which makes it very difficult to search any\npolicies with human-level performance. In this paper, we present a deep\nreinforcement learning framework to tackle this problem from the perspectives\nof both system and algorithm. Our system is of low coupling and high\nscalability, which enables efficient explorations at large scale. Our algorithm\nincludes several novel strategies, including control dependency decoupling,\naction mask, target attention, and dual-clip PPO, with which our proposed\nactor-critic network can be effectively trained in our system. Tested on the\nMOBA game Honor of Kings, our AI agent, called Tencent Solo, can defeat top\nprofessional human players in full 1v1 games.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 09:56:50 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 02:39:43 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 14:21:40 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ye", "Deheng", ""], ["Liu", "Zhao", ""], ["Sun", "Mingfei", ""], ["Shi", "Bei", ""], ["Zhao", "Peilin", ""], ["Wu", "Hao", ""], ["Yu", "Hongsheng", ""], ["Yang", "Shaojie", ""], ["Wu", "Xipeng", ""], ["Guo", "Qingwei", ""], ["Chen", "Qiaobo", ""], ["Yin", "Yinyuting", ""], ["Zhang", "Hao", ""], ["Shi", "Tengfei", ""], ["Wang", "Liang", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""], ["Huang", "Lanxiao", ""]]}, {"id": "1912.09733", "submitter": "Aliaksandr Hubin", "authors": "Aliaksandr Hubin", "title": "An adaptive simulated annealing EM algorithm for inference on\n  non-homogeneous hidden Markov models", "comments": "8 pages, 6 figures, 4 tables. Accepted version of the article\n  published in AIIPCC 2019", "journal-ref": null, "doi": "10.1145/3371425.3371641", "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-homogeneous hidden Markov models (NHHMM) are a subclass of dependent\nmixture models used for semi-supervised learning, where both transition\nprobabilities between the latent states and mean parameter of the probability\ndistribution of the responses (for a given state) depend on the set of $p$\ncovariates. A priori we do not know which (and how) covariates influence the\ntransition probabilities and the mean parameters. This induces a complex\ncombinatorial optimization problem for model selection with $4^p$ potential\nconfigurations. To address the problem, in this article we propose an adaptive\n(A) simulated annealing (SA) expectation maximization (EM) algorithm (ASA-EM)\nfor joint optimization of models and their parameters with respect to a\ncriterion of interest.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 10:03:53 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Hubin", "Aliaksandr", ""]]}, {"id": "1912.09764", "submitter": "Claudio Nordio", "authors": "Angela Rita Provenzano, Daniele Trifir\\`o, Nicola Jean, Giacomo Le\n  Pera, Maurizio Spadaccino, Luca Massaron and Claudio Nordio", "title": "An Artificial Intelligence approach to Shadow Rating", "comments": "18 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the effectiveness of modern deep learning techniques in predicting\ncredit ratings over a universe of thousands of global corporate entities\nobligations when compared to most popular, traditional machine-learning\napproaches such as linear models and tree-based classifiers. Our results show a\nadequate accuracy over different rating classes when applying categorical\nembeddings to artificial neural networks (ANN) architectures.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 11:23:32 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Provenzano", "Angela Rita", ""], ["Trifir\u00f2", "Daniele", ""], ["Jean", "Nicola", ""], ["Pera", "Giacomo Le", ""], ["Spadaccino", "Maurizio", ""], ["Massaron", "Luca", ""], ["Nordio", "Claudio", ""]]}, {"id": "1912.09784", "submitter": "Chongxuan Li", "authors": "Chongxuan Li, Kun Xu, Jiashuo Liu, Jun Zhu, Bo Zhang", "title": "Triple Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified game-theoretical framework to perform classification and\nconditional image generation given limited supervision. It is formulated as a\nthree-player minimax game consisting of a generator, a classifier and a\ndiscriminator, and therefore is referred to as Triple Generative Adversarial\nNetwork (Triple-GAN). The generator and the classifier characterize the\nconditional distributions between images and labels to perform conditional\ngeneration and classification, respectively. The discriminator solely focuses\non identifying fake image-label pairs. Under a nonparametric assumption, we\nprove the unique equilibrium of the game is that the distributions\ncharacterized by the generator and the classifier converge to the data\ndistribution. As a byproduct of the three-player mechanism, Triple-GAN is\nflexible to incorporate different semi-supervised classifiers and GAN\narchitectures. We evaluate Triple-GAN in two challenging settings, namely,\nsemi-supervised learning and the extreme low data regime. In both settings,\nTriple-GAN can achieve excellent classification results and generate meaningful\nsamples in a specific class simultaneously. In particular, using a commonly\nadopted 13-layer CNN classifier, Triple-GAN outperforms extensive\nsemi-supervised learning methods substantially on more than 10 benchmarks no\nmatter data augmentation is applied or not.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 12:17:27 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 10:09:32 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Chongxuan", ""], ["Xu", "Kun", ""], ["Liu", "Jiashuo", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1912.09789", "submitter": "Jan S. Rellermeyer", "authors": "Joost Verbraeken, Matthijs Wolting, Jonathan Katzy, Jeroen\n  Kloppenburg, Tim Verbelen and Jan S. Rellermeyer", "title": "A Survey on Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for artificial intelligence has grown significantly over the last\ndecade and this growth has been fueled by advances in machine learning\ntechniques and the ability to leverage hardware acceleration. However, in order\nto increase the quality of predictions and render machine learning solutions\nfeasible for more complex applications, a substantial amount of training data\nis required. Although small machine learning models can be trained with modest\namounts of data, the input for training larger models such as neural networks\ngrows exponentially with the number of parameters. Since the demand for\nprocessing training data has outpaced the increase in computation power of\ncomputing machinery, there is a need for distributing the machine learning\nworkload across multiple machines, and turning the centralized into a\ndistributed system. These distributed systems present new challenges, first and\nforemost the efficient parallelization of the training process and the creation\nof a coherent model. This article provides an extensive overview of the current\nstate-of-the-art in the field by outlining the challenges and opportunities of\ndistributed machine learning over conventional (centralized) machine learning,\ndiscussing the techniques used for distributed machine learning, and providing\nan overview of the systems that are available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 12:24:25 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Verbraeken", "Joost", ""], ["Wolting", "Matthijs", ""], ["Katzy", "Jonathan", ""], ["Kloppenburg", "Jeroen", ""], ["Verbelen", "Tim", ""], ["Rellermeyer", "Jan S.", ""]]}, {"id": "1912.09802", "submitter": "Markus Nagel", "authors": "Andrey Kuzmin, Markus Nagel, Saurabh Pitre, Sandeep Pendyam, Tijmen\n  Blankevoort, Max Welling", "title": "Taxonomy and Evaluation of Structured Compression of Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep neural networks in many real-world applications is\nleading to new challenges in building more efficient architectures. One\neffective way of making networks more efficient is neural network compression.\nWe provide an overview of existing neural network compression methods that can\nbe used to make neural networks more efficient by changing the architecture of\nthe network. First, we introduce a new way to categorize all published\ncompression methods, based on the amount of data and compute needed to make the\nmethods work in practice. These are three 'levels of compression solutions'.\nSecond, we provide a taxonomy of tensor factorization based and probabilistic\ncompression methods. Finally, we perform an extensive evaluation of different\ncompression techniques from the literature for models trained on ImageNet. We\nshow that SVD and probabilistic compression or pruning methods are\ncomplementary and give the best results of all the considered methods. We also\nprovide practical ways to combine them.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:11:44 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kuzmin", "Andrey", ""], ["Nagel", "Markus", ""], ["Pitre", "Saurabh", ""], ["Pendyam", "Sandeep", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "1912.09816", "submitter": "Petr Chunaev", "authors": "Petr Chunaev", "title": "Community detection in node-attributed social networks: a survey", "comments": "This is an essentially revised version of the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a fundamental problem in social network analysis\nconsisting in unsupervised dividing social actors (nodes in a social graph)\nwith certain social connections (edges in a social graph) into densely knitted\nand highly related groups with each group well separated from the others.\nClassical approaches for community detection usually deal only with network\nstructure and ignore features of its nodes (called node attributes), although\nmany real-world social networks provide additional actors' information such as\ninterests. It is believed that the attributes may clarify and enrich the\nknowledge about the actors and give sense to the communities. This belief has\nmotivated the progress in developing community detection methods that use both\nthe structure and the attributes of network (i.e. deal with a node-attributed\ngraph) to yield more informative and qualitative results.\n  During the last decade many such methods based on different ideas have\nappeared. Although there exist partial overviews of them, a recent survey is a\nnecessity as the growing number of the methods may cause repetitions in\nmethodology and uncertainty in practice.\n  In this paper we aim at describing and clarifying the overall situation in\nthe field of community detection in node-attributed social networks. Namely, we\nperform an exhaustive search of known methods and propose a classification of\nthem based on when and how structure and attributes are fused. We not only give\na description of each class but also provide general technical ideas behind\neach method in the class. Furthermore, we pay attention to available\ninformation which methods outperform others and which datasets and quality\nmeasures are used for their evaluation. Basing on the information collected, we\nmake conclusions on the current state of the field and disclose several\nproblems that seem important to be resolved in future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:35:32 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 11:01:39 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chunaev", "Petr", ""]]}, {"id": "1912.09817", "submitter": "Marharyta Aleksandrova", "authors": "Marharyta Aleksandrova and Oleg Chertov", "title": "SCR-Apriori for Mining `Sets of Contrasting Rules'", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an efficient algorithm for mining novel `Set of\nContrasting Rules'-pattern (SCR-pattern), which consists of several association\nrules. This pattern is of high interest due to the guaranteed quality of the\nrules forming it and its ability to discover useful knowledge. However,\nSCR-pattern has no efficient mining algorithm. We propose SCR-Apriori\nalgorithm, which results in the same set of SCR-patterns as the\nstate-of-the-art approache, but is less computationally expensive. We also show\nexperimentally that by incorporating the knowledge about the pattern structure\ninto Apriori algorithm, SCR-Apriori can significantly prune the search space of\nfrequent itemsets to be analysed.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:36:10 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Aleksandrova", "Marharyta", ""], ["Chertov", "Oleg", ""]]}, {"id": "1912.09818", "submitter": "Leon Sixt", "authors": "Leon Sixt, Maximilian Granz, Tim Landgraf", "title": "When Explanations Lie: Why Many Modified BP Attributions Fail", "comments": "Published in ICML 2020, Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods aim to explain a neural network's prediction by\nhighlighting the most relevant image areas. A popular approach is to\nbackpropagate (BP) a custom relevance score using modified rules, rather than\nthe gradient. We analyze an extensive set of modified BP methods: Deep Taylor\nDecomposition, Layer-wise Relevance Propagation (LRP), Excitation BP,\nPatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find\nempirically that the explanations of all mentioned methods, except for\nDeepLIFT, are independent of the parameters of later layers. We provide\ntheoretical insights for this surprising behavior and also analyze why DeepLIFT\ndoes not suffer from this limitation. Empirically, we measure how information\nof later layers is ignored by using our new metric, cosine similarity\nconvergence (CSC). The paper provides a framework to assess the faithfulness of\nnew and existing modified BP methods theoretically and empirically. For code\nsee: https://github.com/berleon/when-explanations-lie\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 13:46:31 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 07:00:17 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 17:45:40 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 16:39:10 GMT"}, {"version": "v5", "created": "Thu, 7 May 2020 19:24:58 GMT"}, {"version": "v6", "created": "Thu, 13 Aug 2020 14:12:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Sixt", "Leon", ""], ["Granz", "Maximilian", ""], ["Landgraf", "Tim", ""]]}, {"id": "1912.09831", "submitter": "Gabrielle Ras", "authors": "Gabri\\\"elle Ras, Ron Dotsch, Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u,\n  Marcel A. J. van Gerven", "title": "Background Hardly Matters: Understanding Personality Attribution in Deep\n  Residual Networks", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceived personality traits attributed to an individual do not have to\ncorrespond to their actual personality traits and may be determined in part by\nthe context in which one encounters a person. These apparent traits determine,\nto a large extent, how other people will behave towards them. Deep neural\nnetworks are increasingly being used to perform automated personality\nattribution (e.g., job interviews). It is important that we understand the\ndriving factors behind the predictions, in humans and in deep neural networks.\nThis paper explicitly studies the effect of the image background on apparent\npersonality prediction while addressing two important confounds present in\nexisting literature; overlapping data splits and including facial information\nin the background. Surprisingly, we found no evidence that background\ninformation improves model predictions for apparent personality traits. In\nfact, when background is explicitly added to the input, a decrease in\nperformance was measured across all models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:11:29 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Ras", "Gabri\u00eblle", ""], ["Dotsch", "Ron", ""], ["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1912.09848", "submitter": "Yuri G. Gordienko", "authors": "Peng Gang, Wei Zeng, Yuri Gordienko, Oleksandr Rokovyi, Oleg Alienin,\n  and Sergii Stirenko", "title": "Prediction of Physical Load Level by Machine Learning Analysis of Heart\n  Activity after Exercises", "comments": "6 pages, 8 figures, 3 tables; preprint of paper for 2019 IEEE\n  Symposium Series on Computational Intelligence (SSCI), December 6-9 2019,\n  Xiamen, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assessment of energy expenditure in real life is of great importance for\nmonitoring the current physical state of people, especially in work, sport,\nelderly care, health care, and everyday life even. This work reports about\napplication of some machine learning methods (linear regression, linear\ndiscriminant analysis, k-nearest neighbors, decision tree, random forest,\nGaussian naive Bayes, support-vector machine) for monitoring energy\nexpenditures in athletes. The classification problem was to predict the known\nlevel of the in-exercise loads (in three categories by calories) by the heart\nrate activity features measured during the short period of time (1 minute only)\nafter training, i.e by features of the post-exercise load. The results obtained\nshown that the post-exercise heart activity features preserve the information\nof the in-exercise training loads and allow us to predict their actual\nin-exercise levels. The best performance can be obtained by the random forest\nclassifier with all 8 heart rate features (micro-averaged area under curve\nvalue AUCmicro = 0.87 and macro-averaged one AUCmacro = 0.88) and the k-nearest\nneighbors classifier with 4 most important heart rate features (AUCmicro = 0.91\nand AUCmacro = 0.89). The limitations and perspectives of the ML methods used\nare outlined, and some practical advices are proposed as to their improvement\nand implementation for the better prediction of in-exercise energy\nexpenditures.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:35:49 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Gang", "Peng", ""], ["Zeng", "Wei", ""], ["Gordienko", "Yuri", ""], ["Rokovyi", "Oleksandr", ""], ["Alienin", "Oleg", ""], ["Stirenko", "Sergii", ""]]}, {"id": "1912.09855", "submitter": "Maximilian Bachl", "authors": "Alexander Hartl, Maximilian Bachl, Joachim Fabini, Tanja Zseby", "title": "Explainability and Adversarial Robustness for RNNs", "comments": "Accepted at IEEE BigDataService 2020", "journal-ref": "2020 IEEE Sixth International Conference on Big Data Computing\n  Service and Applications (BigDataService)", "doi": "10.1109/BigDataService49289.2020.00030", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) yield attractive properties for constructing\nIntrusion Detection Systems (IDSs) for network data. With the rise of\nubiquitous Machine Learning (ML) systems, malicious actors have been catching\nup quickly to find new ways to exploit ML vulnerabilities for profit. Recently\ndeveloped adversarial ML techniques focus on computer vision and their\napplicability to network traffic is not straightforward: Network packets expose\nfewer features than an image, are sequential and impose several constraints on\ntheir features.\n  We show that despite these completely different characteristics, adversarial\nsamples can be generated reliably for RNNs. To understand a classifier's\npotential for misclassification, we extend existing explainability techniques\nand propose new ones, suitable particularly for sequential data. Applying them\nshows that already the first packets of a communication flow are of crucial\nimportance and are likely to be targeted by attackers. Feature importance\nmethods show that even relatively unimportant features can be effectively\nabused to generate adversarial samples. Since traditional evaluation metrics\nsuch as accuracy are not sufficient for quantifying the adversarial threat, we\npropose the Adversarial Robustness Score (ARS) for comparing IDSs, capturing a\ncommon notion of adversarial robustness, and show that an adversarial training\nprocedure can significantly and successfully reduce the attack surface.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:47:09 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 13:23:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Hartl", "Alexander", ""], ["Bachl", "Maximilian", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "1912.09857", "submitter": "Bennet Breier", "authors": "Bennet Breier, Arno Onken", "title": "Analysis of Video Feature Learning in Two-Stream CNNs on the Example of\n  Zebrafish Swim Bout Classification", "comments": "18 pages incl. references and appendix, 16 figures, ICLR 2020\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semmelhack et al. (2014) have achieved high classification accuracy in\ndistinguishing swim bouts of zebrafish using a Support Vector Machine (SVM).\nConvolutional Neural Networks (CNNs) have reached superior performance in\nvarious image recognition tasks over SVMs, but these powerful networks remain a\nblack box. Reaching better transparency helps to build trust in their\nclassifications and makes learned features interpretable to experts. Using a\nrecently developed technique called Deep Taylor Decomposition, we generated\nheatmaps to highlight input regions of high relevance for predictions. We find\nthat our CNN makes predictions by analyzing the steadiness of the tail's trunk,\nwhich markedly differs from the manually extracted features used by Semmelhack\net al. (2014). We further uncovered that the network paid attention to\nexperimental artifacts. Removing these artifacts ensured the validity of\npredictions. After correction, our best CNN beats the SVM by 6.12%, achieving a\nclassification accuracy of 96.32%. Our work thus demonstrates the utility of AI\nexplainability for CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:51:35 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Breier", "Bennet", ""], ["Onken", "Arno", ""]]}, {"id": "1912.09859", "submitter": "Dixing Xu", "authors": "Dixing Xu, Mengyao Zheng, Linshan Jiang, Chaojie Gu, Rui Tan and Peng\n  Cheng", "title": "Lightweight and Unobtrusive Data Obfuscation at IoT Edge for Remote\n  Inference", "comments": "This paper has been accepted by IEEE Internet of Things Journal,\n  Special Issue on Artificial Intelligence Powered Edge Computing for Internet\n  of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Executing deep neural networks for inference on the server-class or cloud\nbackend based on data generated at the edge of Internet of Things is desirable\ndue primarily to the limited compute power of edge devices and the need to\nprotect the confidentiality of the inference neural networks. However, such a\nremote inference scheme incurs concerns regarding the privacy of the inference\ndata transmitted by the edge devices to the curious backend. This paper\npresents a lightweight and unobtrusive approach to obfuscate the inference data\nat the edge devices. It is lightweight in that the edge device only needs to\nexecute a small-scale neural network; it is unobtrusive in that the edge device\ndoes not need to indicate whether obfuscation is applied. Extensive evaluation\nby three case studies of free spoken digit recognition, handwritten digit\nrecognition, and American sign language recognition shows that our approach\neffectively protects the confidentiality of the raw forms of the inference data\nwhile effectively preserving the backend's inference accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:58:19 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 18:10:10 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 04:10:45 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Xu", "Dixing", ""], ["Zheng", "Mengyao", ""], ["Jiang", "Linshan", ""], ["Gu", "Chaojie", ""], ["Tan", "Rui", ""], ["Cheng", "Peng", ""]]}, {"id": "1912.09867", "submitter": "William L Hamilton", "authors": "Avishek Joey Bose, Ankit Jain, Piero Molino, and William L. Hamilton", "title": "Meta-Graph: Few Shot Link Prediction via Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of few shot link prediction on graphs. The goal is to\nlearn from a distribution over graphs so that a model is able to quickly infer\nmissing edges in a new graph after a small amount of training. We show that\ncurrent link prediction methods are generally ill-equipped to handle this task.\nThey cannot effectively transfer learned knowledge from one graph to another\nand are unable to effectively learn from sparse samples of edges. To address\nthis challenge, we introduce a new gradient-based meta learning framework,\nMeta-Graph. Our framework leverages higher-order gradients along with a learned\ngraph signature function that conditionally generates a graph neural network\ninitialization. Using a novel set of few shot link prediction benchmarks, we\nshow that Meta-Graph can learn to quickly adapt to a new graph using only a\nsmall sample of true edges, enabling not only fast adaptation but also improved\nresults at convergence.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:09:50 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 21:03:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Jain", "Ankit", ""], ["Molino", "Piero", ""], ["Hamilton", "William L.", ""]]}, {"id": "1912.09893", "submitter": "Federico Errica", "authors": "Federico Errica, Marco Podda, Davide Bacciu, Alessio Micheli", "title": "A Fair Comparison of Graph Neural Networks for Graph Classification", "comments": "Proceedings of the International Conference on Learning\n  Representations (ICLR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental reproducibility and replicability are critical topics in machine\nlearning. Authors have often raised concerns about their lack in scientific\npublications to improve the quality of the field. Recently, the graph\nrepresentation learning field has attracted the attention of a wide research\ncommunity, which resulted in a large stream of works. As such, several Graph\nNeural Network models have been developed to effectively tackle graph\nclassification. However, experimental procedures often lack rigorousness and\nare hardly reproducible. Motivated by this, we provide an overview of common\npractices that should be avoided to fairly compare with the state of the art.\nTo counter this troubling trend, we ran more than 47000 experiments in a\ncontrolled and uniform framework to re-evaluate five popular models across nine\ncommon benchmarks. Moreover, by comparing GNNs with structure-agnostic\nbaselines we provide convincing evidence that, on some datasets, structural\ninformation has not been exploited yet. We believe that this work can\ncontribute to the development of the graph learning field, by providing a much\nneeded grounding for rigorous evaluations of graph classification models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:40:50 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 13:49:46 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Errica", "Federico", ""], ["Podda", "Marco", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "1912.09899", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Xiaoyu Cao, Binghui Wang, Neil Zhenqiang Gong", "title": "Certified Robustness for Top-k Predictions against Adversarial\n  Perturbations via Randomized Smoothing", "comments": "ICLR 2020, code is available at this:\n  https://github.com/jjy1994/Certify_Topk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that classifiers are vulnerable to adversarial\nperturbations. To defend against adversarial perturbations, various certified\nrobustness results have been derived. However, existing certified robustnesses\nare limited to top-1 predictions. In many real-world applications, top-$k$\npredictions are more relevant. In this work, we aim to derive certified\nrobustness for top-$k$ predictions. In particular, our certified robustness is\nbased on randomized smoothing, which turns any classifier to a new classifier\nvia adding noise to an input example. We adopt randomized smoothing because it\nis scalable to large-scale neural networks and applicable to any classifier. We\nderive a tight robustness in $\\ell_2$ norm for top-$k$ predictions when using\nrandomized smoothing with Gaussian noise. We find that generalizing the\ncertified robustness from top-1 to top-$k$ predictions faces significant\ntechnical challenges. We also empirically evaluate our method on CIFAR10 and\nImageNet. For example, our method can obtain an ImageNet classifier with a\ncertified top-5 accuracy of 62.8\\% when the $\\ell_2$-norms of the adversarial\nperturbations are less than 0.5 (=127/255). Our code is publicly available at:\n\\url{https://github.com/jjy1994/Certify_Topk}.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:54:51 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Jia", "Jinyuan", ""], ["Cao", "Xiaoyu", ""], ["Wang", "Binghui", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "1912.09902", "submitter": "Molly O'Brien", "authors": "Molly O'Brien, William Goble, Greg Hager, Julia Bukowski", "title": "Dependable Neural Networks for Safety Critical Tasks", "comments": "8 pages, 4 figures. Accepted to AAAI EDSMLS Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks are being integrated into safety critical systems, e.g.,\nperception systems for autonomous vehicles, which require trained networks to\nperform safely in novel scenarios. It is challenging to verify neural networks\nbecause their decisions are not explainable, they cannot be exhaustively\ntested, and finite test samples cannot capture the variation across all\noperating conditions. Existing work seeks to train models robust to new\nscenarios via domain adaptation, style transfer, or few-shot learning. But\nthese techniques fail to predict how a trained model will perform when the\noperating conditions differ from the testing conditions. We propose a metric,\nMachine Learning (ML) Dependability, that measures the network's probability of\nsuccess in specified operating conditions which need not be the testing\nconditions. In addition, we propose the metrics Task Undependability and\nHarmful Undependability to distinguish network failures by their consequences.\nWe evaluate the performance of a Neural Network agent trained using\nReinforcement Learning in a simulated robot manipulation task. Our results\ndemonstrate that we can accurately predict the ML Dependability, Task\nUndependability, and Harmful Undependability for operating conditions that are\nsignificantly different from the testing conditions. Finally, we design a\nSafety Function, using harmful failures identified during testing, that reduces\nharmful failures, in one example, by a factor of 700 while maintaining a high\nprobability of success.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 16:03:10 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["O'Brien", "Molly", ""], ["Goble", "William", ""], ["Hager", "Greg", ""], ["Bukowski", "Julia", ""]]}, {"id": "1912.09925", "submitter": "Peter Richt\\'arik", "authors": "S\\'elim Chraibi and Ahmed Khaled and Dmitry Kovalev and Peter\n  Richt\\'arik and Adil Salim and Martin Tak\\'a\\v{c}", "title": "Distributed Fixed Point Methods with Compressed Iterates", "comments": "15 pages, 4 algorithms, 4 Theorems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose basic and natural assumptions under which iterative optimization\nmethods with compressed iterates can be analyzed. This problem is motivated by\nthe practice of federated learning, where a large model stored in the cloud is\ncompressed before it is sent to a mobile device, which then proceeds with\ntraining based on local data. We develop standard and variance reduced methods,\nand establish communication complexity bounds. Our algorithms are the first\ndistributed methods with compressed iterates, and the first fixed point methods\nwith compressed iterates.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 16:36:03 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Chraibi", "S\u00e9lim", ""], ["Khaled", "Ahmed", ""], ["Kovalev", "Dmitry", ""], ["Richt\u00e1rik", "Peter", ""], ["Salim", "Adil", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1912.09926", "submitter": "Yuzheng Hu", "authors": "Yuzheng Hu and Licong Lin and Shange Tang", "title": "Second-order Information in First-order Optimization Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to uncover the second-order essence of several\nfirst-order optimization methods. For Nesterov Accelerated Gradient, we\nrigorously prove that the algorithm makes use of the difference between past\nand current gradients, thus approximates the Hessian and accelerates the\ntraining. For adaptive methods, we related Adam and Adagrad to a powerful\ntechnique in computation statistics---Natural Gradient Descent. These adaptive\nmethods can in fact be treated as relaxations of NGD with only a slight\ndifference lying in the square root of the denominator in the update rules.\nSkeptical about the effect of such difference, we design a new\nalgorithm---AdaSqrt, which removes the square root in the denominator and\nscales the learning rate by sqrt(T). Surprisingly, our new algorithm is\ncomparable to various first-order methods(such as SGD and Adam) on MNIST and\neven beats Adam on CIFAR-10! This phenomenon casts doubt on the convention view\nthat the square root is crucial and training without it will lead to terrible\nperformance. As far as we have concerned, so long as the algorithm tries to\nexplore second or even higher information of the loss surface, then proper\nscaling of the learning rate alone will guarantee fast training and good\ngeneralization performance. To the best of our knowledge, this is the first\npaper that seriously considers the necessity of square root among all adaptive\nmethods. We believe that our work can shed light on the importance of\nhigher-order information and inspire the design of more powerful algorithms in\nthe future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 16:36:15 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Hu", "Yuzheng", ""], ["Lin", "Licong", ""], ["Tang", "Shange", ""]]}, {"id": "1912.09944", "submitter": "Yuchen Jin", "authors": "Wenyi Hu, Yuchen Jin, Xuqing Wu, Jiefu Chen", "title": "Progressive transfer learning for low frequency data prediction in full\n  waveform inversion", "comments": "50 pages, 21 figures, to be published in Geophysics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the purpose of effective suppression of the cycle-skipping phenomenon in\nfull waveform inversion (FWI), we developed a Deep Neural Network (DNN)\napproach to predict the absent low-frequency components by exploiting the\nimplicit relation connecting the low-frequency and high-frequency data through\nthe subsurface geological and geophysical properties. In order to solve this\nchallenging nonlinear regression problem, two novel strategies were proposed to\ndesign the DNN architecture and the learning workflow: 1) Dual Data Feed; 2)\nProgressive Transfer Learning. With the Dual Data Feed structure, both the\nhigh-frequency data and the corresponding Beat Tone data are fed into the DNN\nto relieve the burden of feature extraction, thus reducing the network\ncomplexity and the training cost. The second strategy, Progressive Transfer\nLearning, enables us to unbiasedly train the DNN using a single training\ndataset. Unlike most established deep learning approaches where the training\ndatasets are fixed, within the framework of the Progressive Transfer Learning,\nthe training dataset evolves in an iterative manner while gradually absorbing\nthe subsurface information retrieved by the physics-based inversion module,\nprogressively enhancing the prediction accuracy of the DNN and propelling the\nFWI process out of the local minima. The Progressive Transfer Learning,\nalternatingly updating the training velocity model and the DNN parameters in a\ncomplementary fashion toward convergence, saves us from being overwhelmed by\nthe otherwise tremendous amount of training data, and avoids the underfitting\nand biased sampling issues. The numerical experiments validated that, without\nany a priori geological information, the low-frequency data predicted by the\nProgressive Transfer Learning are sufficiently accurate for an FWI engine to\nproduce reliable subsurface velocity models free of cycle-skipping-induced\nartifacts.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 17:08:11 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Hu", "Wenyi", ""], ["Jin", "Yuchen", ""], ["Wu", "Xuqing", ""], ["Chen", "Jiefu", ""]]}, {"id": "1912.09953", "submitter": "James Townsend", "authors": "James Townsend, Thomas Bird, Julius Kunze, David Barber", "title": "HiLLoC: Lossless Image Compression with Hierarchical Latent Variable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make the following striking observation: fully convolutional VAE models\ntrained on 32x32 ImageNet can generalize well, not just to 64x64 but also to\nfar larger photographs, with no changes to the model. We use this property,\napplying fully convolutional models to lossless compression, demonstrating a\nmethod to scale the VAE-based 'Bits-Back with ANS' algorithm for lossless\ncompression to large color photographs, and achieving state of the art for\ncompression of full size ImageNet images. We release Craystack, an open source\nlibrary for convenient prototyping of lossless compression using probabilistic\nmodels, along with full implementations of all of our compression results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 17:20:38 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Townsend", "James", ""], ["Bird", "Thomas", ""], ["Kunze", "Julius", ""], ["Barber", "David", ""]]}, {"id": "1912.09989", "submitter": "Hai Shu", "authors": "Hai Shu, Zhe Qu", "title": "CDPA: Common and Distinctive Pattern Analysis between High-dimensional\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A representative model in integrative analysis of two high-dimensional\ncorrelated datasets is to decompose each data matrix into a low-rank common\nmatrix generated by latent factors shared across datasets, a low-rank\ndistinctive matrix corresponding to each dataset, and an additive noise matrix.\nExisting decomposition methods claim that their common matrices capture the\ncommon pattern of the two datasets. However, their so-called common pattern\nonly denotes the common latent factors but ignores the common pattern between\nthe two coefficient matrices of these common latent factors. We propose a new\nunsupervised learning method, called the common and distinctive pattern\nanalysis (CDPA), which appropriately defines the two types of data patterns by\nfurther incorporating the common and distinctive patterns of the coefficient\nmatrices. A consistent estimation approach is developed for high-dimensional\nsettings, and shows reasonably good finite-sample performance in simulations.\nOur simulation studies and real data analysis corroborate that the proposed\nCDPA can provide better characterization of common and distinctive patterns and\nthereby benefit data mining.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:21:19 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 07:01:37 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 16:44:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Shu", "Hai", ""], ["Qu", "Zhe", ""]]}, {"id": "1912.09996", "submitter": "Konrad Czechowski", "authors": "Piotr Mi{\\l}o\\'s, {\\L}ukasz Kuci\\'nski, Konrad Czechowski, Piotr\n  Kozakowski, Maciek Klimek", "title": "Uncertainty-sensitive Learning and Planning with Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reinforcement learning framework for discrete environments in\nwhich an agent makes both strategic and tactical decisions. The former\nmanifests itself through the use of value function, while the latter is powered\nby a tree search planner. These tools complement each other. The planning\nmodule performs a local \\textit{what-if} analysis, which allows to avoid\ntactical pitfalls and boost backups of the value function. The value function,\nbeing global in nature, compensates for inherent locality of the planner. In\norder to further solidify this synergy, we introduce an exploration mechanism\nwith two distinctive components: uncertainty modelling and risk measurement. To\nmodel the uncertainty we use value function ensembles, and to reflect risk we\nuse propose several functionals that summarize the implied by the ensemble. We\nshow that our method performs well on hard exploration environments: Deep-sea,\ntoy Montezuma's Revenge, and Sokoban. In all the cases, we obtain speed-up in\nlearning and boost in performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 17:58:25 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 23:00:07 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 17:47:28 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mi\u0142o\u015b", "Piotr", ""], ["Kuci\u0144ski", "\u0141ukasz", ""], ["Czechowski", "Konrad", ""], ["Kozakowski", "Piotr", ""], ["Klimek", "Maciek", ""]]}, {"id": "1912.10000", "submitter": "Luca Costabello", "authors": "Pedro Tabacof, Luca Costabello", "title": "Probability Calibration for Knowledge Graph Embedding Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding research has overlooked the problem of probability\ncalibration. We show popular embedding models are indeed uncalibrated. That\nmeans probability estimates associated to predicted triples are unreliable. We\npresent a novel method to calibrate a model when ground truth negatives are not\navailable, which is the usual case in knowledge graphs. We propose to use Platt\nscaling and isotonic regression alongside our method. Experiments on three\ndatasets with ground truth negatives show our contribution leads to\nwell-calibrated models when compared to the gold standard of using negatives.\nWe get significantly better results than the uncalibrated models from all\ncalibration methods. We show isotonic regression offers the best the\nperformance overall, not without trade-offs. We also show that calibrated\nmodels reach state-of-the-art accuracy without the need to define\nrelation-specific decision thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:31:33 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 10:38:54 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tabacof", "Pedro", ""], ["Costabello", "Luca", ""]]}, {"id": "1912.10011", "submitter": "Cl\\'ement Rebuffel", "authors": "Cl\\'ement Rebuffel and Laure Soulier and Geoffrey Scoutheeten and\n  Patrick Gallinari", "title": "A Hierarchical Model for Data-to-Text Generation", "comments": "Accepted at the 42nd European Conference on IR Research, ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcribing structured data into natural language descriptions has emerged\nas a challenging task, referred to as \"data-to-text\". These structures\ngenerally regroup multiple elements, as well as their attributes. Most attempts\nrely on translation encoder-decoder methods which linearize elements into a\nsequence. This however loses most of the structure contained in the data. In\nthis work, we propose to overpass this limitation with a hierarchical model\nthat encodes the data-structure at the element-level and the structure level.\nEvaluations on RotoWire show the effectiveness of our model w.r.t. qualitative\nand quantitative metrics.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:41:32 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Rebuffel", "Cl\u00e9ment", ""], ["Soulier", "Laure", ""], ["Scoutheeten", "Geoffrey", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1912.10013", "submitter": "Battista Biggio", "authors": "Marco Melis and Ambra Demontis and Maura Pintor and Angelo Sotgiu and\n  Battista Biggio", "title": "secml: A Python Library for Secure and Explainable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present secml, an open-source Python library for secure and explainable\nmachine learning. It implements the most popular attacks against machine\nlearning, including not only test-time evasion attacks to generate adversarial\nexamples against deep neural networks, but also training-time poisoning attacks\nagainst support vector machines and many other algorithms. These attacks enable\nevaluating the security of learning algorithms and of the corresponding\ndefenses under both white-box and black-box threat models. To this end, secml\nprovides built-in functions to compute security evaluation curves, showing how\nquickly classification performance decreases against increasing adversarial\nperturbations of the input data. secml also includes explainability methods to\nhelp understand why adversarial attacks succeed against a given model, by\nvisualizing the most influential features and training prototypes contributing\nto each decision. It is distributed under the Apache License 2.0, and hosted at\nhttps://gitlab.com/secml/secml.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:41:37 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Melis", "Marco", ""], ["Demontis", "Ambra", ""], ["Pintor", "Maura", ""], ["Sotgiu", "Angelo", ""], ["Biggio", "Battista", ""]]}, {"id": "1912.10036", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir, Kumar Vijay Mishra, M. R. Bhavani Shankar and Bj\\\"orn\n  Ottersten", "title": "A Family of Deep Learning Architectures for Channel Estimation and\n  Hybrid Beamforming in Multi-Carrier mm-Wave Massive MIMO", "comments": "15 pages and 10 figures. arXiv admin note: text overlap with\n  arXiv:1910.14240", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid analog and digital beamforming transceivers are instrumental in\naddressing the challenge of expensive hardware and high training overheads in\nthe next generation millimeter-wave (mm-Wave) massive MIMO (multiple-input\nmultiple-output) systems. However, lack of fully digital beamforming in hybrid\narchitectures and short coherence times at mm-Wave impose additional\nconstraints on the channel estimation. Prior works on addressing these\nchallenges have focused largely on narrowband channels wherein\noptimization-based or greedy algorithms were employed to derive hybrid\nbeamformers. In this paper, we introduce a deep learning (DL) approach for\nchannel estimation and hybrid beamforming for frequency-selective, wideband\nmm-Wave systems. In particular, we consider a massive MIMO Orthogonal Frequency\nDivision Multiplexing (MIMO-OFDM) system and propose three different DL\nframeworks comprising convolutional neural networks (CNNs), which accept the\nraw data of received signal as input and yield channel estimates and the hybrid\nbeamformers at the output. We also introduce both offline and online prediction\nschemes. Numerical experiments demonstrate that, compared to the current\nstate-of-the-art optimization and DL methods, our approach provides higher\nspectral efficiency, lesser computational cost and fewer number of pilot\nsignals, and higher tolerance against the deviations in the received pilot\ndata, corrupted channel matrix, and propagation environment.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 11:48:31 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 07:23:35 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 07:18:04 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 18:29:22 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Mishra", "Kumar Vijay", ""], ["Shankar", "M. R. Bhavani", ""], ["Ottersten", "Bj\u00f6rn", ""]]}, {"id": "1912.10065", "submitter": "Ethan Weinberger", "authors": "Ethan Weinberger, Joseph Janizek, Su-In Lee", "title": "Learning Deep Attribution Priors Based On Prior Knowledge", "comments": "NeurIPS 2020 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attribution methods, which explain an individual prediction made by a\nmodel as a sum of attributions for each input feature, are an essential tool\nfor understanding the behavior of complex deep learning models. However,\nensuring that models produce meaningful explanations, rather than ones that\nrely on noise, is not straightforward. Exacerbating this problem is the fact\nthat attribution methods do not provide insight as to why features are assigned\ntheir attribution values, leading to explanations that are difficult to\ninterpret. In real-world problems we often have sets of additional information\nfor each feature that are predictive of that feature's importance to the task\nat hand. Here, we propose the deep attribution prior (DAPr) framework to\nexploit such information to overcome the limitations of attribution methods.\nOur framework jointly learns a relationship between prior information and\nfeature importance, as well as biases models to have explanations that rely on\nfeatures predicted to be important. We find that our framework both results in\nnetworks that generalize better to out of sample data and admits new methods\nfor interpreting model behavior.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:17:07 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 22:53:20 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 23:02:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Weinberger", "Ethan", ""], ["Janizek", "Joseph", ""], ["Lee", "Su-In", ""]]}, {"id": "1912.10068", "submitter": "Sarah Dean", "authors": "Sarah Dean, Sarah Rich, Benjamin Recht", "title": "Recommendations and User Agency: The Reachability of\n  Collaboratively-Filtered Information", "comments": "appeared at FAccT '20", "journal-ref": null, "doi": "10.1145/3351095.3372866", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems often rely on models which are trained to maximize\naccuracy in predicting user preferences. When the systems are deployed, these\nmodels determine the availability of content and information to different\nusers. The gap between these objectives gives rise to a potential for\nunintended consequences, contributing to phenomena such as filter bubbles and\npolarization. In this work, we consider directly the information availability\nproblem through the lens of user recourse. Using ideas of reachability, we\npropose a computationally efficient audit for top-$N$ linear recommender\nmodels. Furthermore, we describe the relationship between model complexity and\nthe effort necessary for users to exert control over their recommendations. We\nuse this insight to provide a novel perspective on the user cold-start problem.\nFinally, we demonstrate these concepts with an empirical investigation of a\nstate-of-the-art model trained on a widely used movie ratings dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:23:05 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 01:23:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Dean", "Sarah", ""], ["Rich", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "1912.10070", "submitter": "Jonathan Lwowski", "authors": "Isaac Corley, Jonathan Lwowski, and Justin Hoffman", "title": "Destruction of Image Steganography using Generative Adversarial Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR cs.LG eess.IV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital image steganalysis, or the detection of image steganography, has been\nstudied in depth for years and is driven by Advanced Persistent Threat (APT)\ngroups', such as APT37 Reaper, utilization of steganographic techniques to\ntransmit additional malware to perform further post-exploitation activity on a\ncompromised host. However, many steganalysis algorithms are constrained to work\nwith only a subset of all possible images in the wild or are known to produce a\nhigh false positive rate. This results in blocking any suspected image being an\nunreasonable policy. A more feasible policy is to filter suspicious images\nprior to reception by the host machine. However, how does one optimally filter\nspecifically to obfuscate or remove image steganography while avoiding\ndegradation of visual image quality in the case that detection of the image was\na false positive? We propose the Deep Digital Steganography Purifier (DDSP), a\nGenerative Adversarial Network (GAN) which is optimized to destroy\nsteganographic content without compromising the perceptual quality of the\noriginal image. As verified by experimental results, our model is capable of\nproviding a high rate of destruction of steganographic image content while\nmaintaining a high visual quality in comparison to other state-of-the-art\nfiltering methods. Additionally, we test the transfer learning capability of\ngeneralizing to to obfuscate real malware payloads embedded into different\nimage file formats and types using an unseen steganographic algorithm and prove\nthat our model can in fact be deployed to provide adequate results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:23:32 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Corley", "Isaac", ""], ["Lwowski", "Jonathan", ""], ["Hoffman", "Justin", ""]]}, {"id": "1912.10077", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank J.\n  Reddi, Sanjiv Kumar", "title": "Are Transformers universal approximators of sequence-to-sequence\n  functions?", "comments": "23 pages, ICLR 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread adoption of Transformer models for NLP tasks, the\nexpressive power of these models is not well-understood. In this paper, we\nestablish that Transformer models are universal approximators of continuous\npermutation equivariant sequence-to-sequence functions with compact support,\nwhich is quite surprising given the amount of shared parameters in these\nmodels. Furthermore, using positional encodings, we circumvent the restriction\nof permutation equivariance, and show that Transformer models can universally\napproximate arbitrary continuous sequence-to-sequence functions on a compact\ndomain. Interestingly, our proof techniques clearly highlight the different\nroles of the self-attention and the feed-forward layers in Transformers. In\nparticular, we prove that fixed width self-attention layers can compute\ncontextual mappings of the input sequences, playing a key role in the universal\napproximation property of Transformers. Based on this insight from our\nanalysis, we consider other simpler alternatives to self-attention layers and\nempirically evaluate them.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:49:32 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 03:12:57 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yun", "Chulhee", ""], ["Bhojanapalli", "Srinadh", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1912.10080", "submitter": "Tiago Alves", "authors": "Tiago Alves, Alberto Laender, Adriano Veloso, Nivio Ziviani", "title": "Dynamic Prediction of ICU Mortality Risk Using Domain Adaptation", "comments": null, "journal-ref": "2018 IEEE International Conference on Big Data", "doi": "10.1109/BigData.2018.8621927", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early recognition of risky trajectories during an Intensive Care Unit (ICU)\nstay is one of the key steps towards improving patient survival. Learning\ntrajectories from physiological signals continuously measured during an ICU\nstay requires learning time-series features that are robust and discriminative\nacross diverse patient populations. Patients within different ICU populations\n(referred here as domains) vary by age, conditions and interventions. Thus,\nmortality prediction models using patient data from a particular ICU population\nmay perform suboptimally in other populations because the features used to\ntrain such models have different distributions across the groups. In this\npaper, we explore domain adaptation strategies in order to learn mortality\nprediction models that extract and transfer complex temporal features from\nmultivariate time-series ICU data. Features are extracted in a way that the\nstate of the patient in a certain time depends on the previous state. This\nenables dynamic predictions and creates a mortality risk space that describes\nthe risk of a patient at a particular time. Experiments based on cross-ICU\npopulations reveals that our model outperforms all considered baselines. Gains\nin terms of AUC range from 4% to 8% for early predictions when compared with a\nrecent state-of-the-art representative for ICU mortality prediction. In\nparticular, models for the Cardiac ICU population achieve AUC numbers as high\nas 0.88, showing excellent clinical utility for early mortality prediction.\nFinally, we present an explanation of factors contributing to the possible ICU\noutcomes, so that our models can be used to complement clinical reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:59:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Alves", "Tiago", ""], ["Laender", "Alberto", ""], ["Veloso", "Adriano", ""], ["Ziviani", "Nivio", ""]]}, {"id": "1912.10084", "submitter": "Nuno Henriques", "authors": "Nuno A. C. Henriques, Helder Coelho, Leonel Garcia-Marques", "title": "SensAI+Expanse Adaptation on Human Behaviour Towards Emotional Valence\n  Prediction", "comments": "Accepted as regular paper in ADAPTIVE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent, artificial or human, must be continuously adjusting its behaviour\nin order to thrive in a more or less demanding environment. An artificial agent\nwith the ability to predict human emotional valence in a geospatial and\ntemporal context requires proper adaptation to its mobile device environment\nwith resource consumption strict restrictions (e.g., power from battery). The\ndeveloped distributed system includes a mobile device embodied agent (SensAI)\nplus Cloud-expanded (Expanse) cognition and memory resources. The system is\ndesigned with several adaptive mechanisms in a best effort for the agent to\ncope with its interacting humans and to be resilient on collecting data for\nmachine learning towards prediction. These mechanisms encompass\nhomeostatic-like adjustments such as auto recovering from an unexpected failure\nin the mobile device, forgetting repeated data to save local memory, adjusting\nactions to a proper moment (e.g., notify only when human is interacting), and\nthe Expanse complementary learning algorithms' parameters with auto\nadjustments. Regarding emotional valence prediction performance, results from a\ncomparison study between state-of-the-art algorithms revealed Extreme Gradient\nBoosting on average the best model for prediction with efficient energy use,\nand explainable using feature importance inspection. Therefore, this work\ncontributes with a smartphone sensing-based system, distributed in the Cloud,\nrobust to unexpected behaviours from humans and the environment, able to\npredict emotional valence states with very good performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:11:06 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 18:00:17 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 19:43:48 GMT"}, {"version": "v4", "created": "Sat, 7 Mar 2020 20:34:04 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Henriques", "Nuno A. C.", ""], ["Coelho", "Helder", ""], ["Garcia-Marques", "Leonel", ""]]}, {"id": "1912.10086", "submitter": "Jesse Levitt", "authors": "Jesse S F Levitt, Mustafa Hajij, Radmila Sazdanovic", "title": "Big Data Approaches to Knot Theory: Understanding the Structure of the\n  Jones Polynomial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the structure and dimensionality of the Jones polynomial using\nmanifold learning techniques. Our data set consists of more than 10 million\nknots up to 17 crossings and two other special families up to 2001 crossings.\nWe introduce and describe a method for using filtrations to analyze infinite\ndata sets where representative sampling is impossible or impractical, an\nessential requirement for working with knots and the data from knot invariants.\nIn particular, this method provides a new approach for analyzing knot\ninvariants using Principal Component Analysis. Using this approach on the Jones\npolynomial data we find that it can be viewed as an approximately 3 dimensional\nmanifold, that this description is surprisingly stable with respect to the\nfiltration by the crossing number, and that the results suggest further\nstructures to be examined and understood.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:18:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Levitt", "Jesse S F", ""], ["Hajij", "Mustafa", ""], ["Sazdanovic", "Radmila", ""]]}, {"id": "1912.10087", "submitter": "Matteo Grimaldi", "authors": "Matteo Grimaldi, Valentino Peluso, Andrea Calimera", "title": "EAST: Encoding-Aware Sparse Training for Deep Memory Compression of\n  ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of Deep Convolutional Neural Networks (ConvNets) on tiny\nend-nodes with limited non-volatile memory space calls for smart compression\nstrategies capable of shrinking the footprint yet preserving predictive\naccuracy. There exist a number of strategies for this purpose, from those that\nplay with the topology of the model or the arithmetic precision, e.g. pruning\nand quantization, to those that operate a model agnostic compression, e.g.\nweight encoding. The tighter the memory constraint, the higher the probability\nthat these techniques alone cannot meet the requirement, hence more awareness\nand cooperation across different optimizations become mandatory. This work\naddresses the issue by introducing EAST, Encoding-Aware Sparse Training, a\nnovel memory-constrained training procedure that leads quantized ConvNets\ntowards deep memory compression. EAST implements an adaptive group pruning\ndesigned to maximize the compression rate of the weight encoding scheme (the\nLZ4 algorithm in this work). If compared to existing methods, EAST meets the\nmemory constraint with lower sparsity, hence ensuring higher accuracy. Results\nconducted on a state-of-the-art ConvNet (ResNet-9) deployed on a low-power\nmicrocontroller (ARM Cortex-M4) validate the proposal.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:20:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Grimaldi", "Matteo", ""], ["Peluso", "Valentino", ""], ["Calimera", "Andrea", ""]]}, {"id": "1912.10092", "submitter": "Jhonatan Souza Oliveira", "authors": "Cory J. Butz, Jhonatan S. Oliveira, Robert Peharz", "title": "Sum-Product Network Decompilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a dichotomy between classical probabilistic graphical models,\nsuch as Bayesian networks (BNs), and modern tractable models, such as\nsum-product networks (SPNs). The former generally have intractable inference,\nbut provide a high level of interpretability, while the latter admits a wide\nrange of tractable inference routines, but are typically harder to interpret.\nDue to this dichotomy, tools to convert between BNs and SPNs are desirable.\nWhile one direction -- compiling BNs into SPNs -- is well discussed in\nDarwiche's seminal work on arithmetic circuit compilation, the converse\ndirection -- decompiling SPNs into BNs -- has received surprisingly little\nattention.\n  In this paper, we fill this gap by proposing SPN2BN, an algorithm that\ndecompiles an SPN into a BN. SPN2BN has several salient features when compared\nto the only other two works decompiling SPNs. Most significantly, the BNs\nreturned by SPN2BN are minimal independence-maps that are more parsimonious\nwith respect to the introduction of latent variables. Secondly, the output BN\nproduced by SPN2BN can be precisely characterized with respect to a compiled\nBN. More specifically, a certain set of directed edges will be added to the\ninput BN, giving what we will call the moral-closure. Lastly, it is established\nthat our compilation-decompilation process is idempotent. This has practical\nsignificance as it limits the size of the decompiled SPN.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:39:28 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:52:00 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Butz", "Cory J.", ""], ["Oliveira", "Jhonatan S.", ""], ["Peharz", "Robert", ""]]}, {"id": "1912.10094", "submitter": "Rongjie Lai", "authors": "Stefan Schonsheck, Jie Chen, Rongjie Lai", "title": "Chart Auto-Encoders for Manifold Structured Data", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have made tremendous advances in image and signal\nrepresentation learning and generation. These models employ the full Euclidean\nspace or a bounded subset as the latent space, whose flat geometry, however, is\noften too simplistic to meaningfully reflect the manifold structure of the\ndata. In this work, we advocate the use of a multi-chart latent space for\nbetter data representation. Inspired by differential geometry, we propose a\n\\textbf{Chart Auto-Encoder (CAE)} and prove a universal approximation theorem\non its representation capability. We show that the training data size and the\nnetwork size scale exponentially in approximation error with an exponent\ndepending on the intrinsic dimension of the data manifold. CAE admits desirable\nmanifold properties that auto-encoders with a flat latent space fail to obey,\npredominantly proximity of data. We conduct extensive experimentation with\nsynthetic and real-life examples to demonstrate that CAE provides\nreconstruction with high fidelity, preserves proximity in the latent space, and\ngenerates new data remaining near the manifold. These experiments show that CAE\nis advantageous over existing auto-encoders and variants by preserving the\ntopology of the data manifold as well as its geometry.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:46:51 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 20:54:56 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Schonsheck", "Stefan", ""], ["Chen", "Jie", ""], ["Lai", "Rongjie", ""]]}, {"id": "1912.10095", "submitter": "Alexander Shevchenko", "authors": "Alexander Shevchenko and Marco Mondelli", "title": "Landscape Connectivity and Dropout Stability of SGD Solutions for\n  Over-parameterized Neural Networks", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of multilayer neural networks typically leads to a solution\nwith zero training error, yet the landscape can exhibit spurious local minima\nand the minima can be disconnected. In this paper, we shed light on this\nphenomenon: we show that the combination of stochastic gradient descent (SGD)\nand over-parameterization makes the landscape of multilayer neural networks\napproximately connected and thus more favorable to optimization. More\nspecifically, we prove that SGD solutions are connected via a piecewise linear\npath, and the increase in loss along this path vanishes as the number of\nneurons grows large. This result is a consequence of the fact that the\nparameters found by SGD are increasingly dropout stable as the network becomes\nwider. We show that, if we remove part of the neurons (and suitably rescale the\nremaining ones), the change in loss is independent of the total number of\nneurons, and it depends only on how many neurons are left. Our results exhibit\na mild dependence on the input dimension: they are dimension-free for two-layer\nnetworks and depend linearly on the dimension for multilayer networks. We\nvalidate our theoretical findings with numerical experiments for different\narchitectures and classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 20:49:52 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 13:26:37 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Shevchenko", "Alexander", ""], ["Mondelli", "Marco", ""]]}, {"id": "1912.10099", "submitter": "Andrew Taylor", "authors": "Andrew Taylor, Andrew Singletary, Yisong Yue, Aaron Ames", "title": "Learning for Safety-Critical Control with Control Barrier Functions", "comments": "Extended version (12 Pages), Short version submitted to Learning for\n  Dynamics & Control (L4DC) 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern nonlinear control theory seeks to endow systems with properties of\nstability and safety, and have been deployed successfully in multiple domains.\nDespite this success, model uncertainty remains a significant challenge in\nsynthesizing safe controllers, leading to degradation in the properties\nprovided by the controllers. This paper develops a machine learning framework\nutilizing Control Barrier Functions (CBFs) to reduce model uncertainty as it\nimpact the safe behavior of a system. This approach iteratively collects data\nand updates a controller, ultimately achieving safe behavior. We validate this\nmethod in simulation and experimentally on a Segway platform.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:02:14 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Taylor", "Andrew", ""], ["Singletary", "Andrew", ""], ["Yue", "Yisong", ""], ["Ames", "Aaron", ""]]}, {"id": "1912.10103", "submitter": "Luca Mocerino", "authors": "Luca Mocerino, Andrea Calimera", "title": "TentacleNet: A Pseudo-Ensemble Template for Accurate Binary\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarization is an attractive strategy for implementing lightweight Deep\nConvolutional Neural Networks (CNNs). Despite the unquestionable savings\noffered, memory footprint above all, it may induce an excessive accuracy loss\nthat prevents a widespread use. This work elaborates on this aspect introducing\nTentacleNet, a new template designed to improve the predictive performance of\nbinarized CNNs via parallelization. Inspired by the ensemble learning theory,\nit consists of a compact topology that is end-to-end trainable and organized to\nminimize memory utilization. Experimental results collected over three\nrealistic benchmarks show TentacleNet fills the gap left by classical binary\nmodels, ensuring substantial memory savings w.r.t. state-of-the-art binary\nensemble methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:18:16 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 12:37:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Mocerino", "Luca", ""], ["Calimera", "Andrea", ""]]}, {"id": "1912.10105", "submitter": "Cuneyt Gurcan Akcora", "authors": "Yitao Li and Umar Islambekov and Cuneyt Akcora and Ekaterina Smirnova\n  and Yulia R. Gel and Murat Kantarcioglu", "title": "Dissecting Ethereum Blockchain Analytics: What We Learn from Topology\n  and Geometry of Ethereum Graph", "comments": "Will appear in SIAM International Conference on Data Mining (SDM20).\n  May 7 - 9, 2020. Cincinnati, Ohio, U.S", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology and, in particular, blockchain-based cryptocurrencies\noffer us information that has never been seen before in the financial world. In\ncontrast to fiat currencies, all transactions of crypto-currencies and\ncrypto-tokens are permanently recorded on distributed ledgers and are publicly\navailable. As a result, this allows us to construct a transaction graph and to\nassess not only its organization but to glean relationships between transaction\ngraph properties and crypto price dynamics. The ultimate goal of this paper is\nto facilitate our understanding on horizons and limitations of what can be\nlearned on crypto-tokens from local topology and geometry of the Ethereum\ntransaction network whose even global network properties remain scarcely\nexplored. By introducing novel tools based on topological data analysis and\nfunctional data depth into Blockchain Data Analytics, we show that Ethereum\nnetwork (one of the most popular blockchains for creating new crypto-tokens)\ncan provide critical insights on price strikes of crypto-tokens that are\notherwise largely inaccessible with conventional data sources and traditional\nanalytic methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:18:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Li", "Yitao", ""], ["Islambekov", "Umar", ""], ["Akcora", "Cuneyt", ""], ["Smirnova", "Ekaterina", ""], ["Gel", "Yulia R.", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "1912.10107", "submitter": "Marc Bosch", "authors": "Joseph Nassar and Viveca Pavon-Harr and Marc Bosch and Ian McCulloh", "title": "Assessing Data Quality of Annotations with Krippendorff Alpha For\n  Applications in Computer Vision", "comments": "Accepted to AAAI Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current supervised deep learning frameworks rely on annotated data for\nmodeling the underlying data distribution of a given task. In particular for\ncomputer vision algorithms powered by deep learning, the quality of annotated\ndata is the most critical factor in achieving the desired algorithm\nperformance. Data annotation is, typically, a manual process where the\nannotator follows guidelines and operates in a best-guess manner. Labeling\ncriteria among annotators can show discrepancies in labeling results. This may\nimpact the algorithm inference performance. Given the popularity and widespread\nuse of deep learning among computer vision, more and more custom datasets are\nneeded to train neural networks to tackle different kinds of tasks.\nUnfortunately, there is no full understanding of the factors that affect\nannotated data quality, and how it translates into algorithm performance. In\nthis paper we studied this problem for object detection and recognition.We\nconducted several data annotation experiments to measure inter annotator\nagreement and consistency, as well as how the selection of ground truth impacts\nthe perceived algorithm performance.We propose a methodology to monitor the\nquality of annotations during the labeling of images and how it can be used to\nmeasure performance. We also show that neglecting to monitor the annotation\nprocess can result in significant loss in algorithm precision. Through these\nexperiments, we observe that knowledge of the labeling process, training data,\nand ground truth data used for algorithm evaluation are fundamental components\nto accurately assess trustworthiness of an AI system.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:23:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Nassar", "Joseph", ""], ["Pavon-Harr", "Viveca", ""], ["Bosch", "Marc", ""], ["McCulloh", "Ian", ""]]}, {"id": "1912.10113", "submitter": "In\\^es Louren\\c{c}o", "authors": "In\\^es Louren\\c{c}o, Bo Wahlberg, Rodrigo Ventura", "title": "Teaching robots to perceive time -- A reinforcement learning approach\n  (Extended version)", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time perception is the phenomenological experience of time by an individual.\nIn this paper, we study how to replicate neural mechanisms involved in time\nperception, allowing robots to take a step towards temporal cognition. Our\nframework follows a twofold biologically inspired approach. The first step\nconsists of estimating the passage of time from sensor measurements, since\nenvironmental stimuli influence the perception of time. Sensor data is modeled\nas Gaussian processes that represent the second-order statistics of the natural\nenvironment. The estimated elapsed time between two events is computed from the\nmaximum likelihood estimate of the joint distribution of the data collected\nbetween them. Moreover, exactly how time is encoded in the brain remains\nunknown, but there is strong evidence of the involvement of dopaminergic\nneurons in timing mechanisms. Since their phasic activity has a similar\nbehavior to the reward prediction error of temporal-difference learning models,\nthe latter are used to replicate this behavior. The second step of this\napproach consists therefore of applying the agent's estimate of the elapsed\ntime in a reinforcement learning problem, where a feature representation called\nMicrostimuli is used. We validate our framework by applying it to an experiment\nthat was originally conducted with mice, and conclude that a robot using this\nframework is able to reproduce the timing mechanisms of the animal's brain.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:41:38 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Louren\u00e7o", "In\u00eas", ""], ["Wahlberg", "Bo", ""], ["Ventura", "Rodrigo", ""]]}, {"id": "1912.10116", "submitter": "Vikas Dhiman", "authors": "Mohammad Javad Khojasteh, Vikas Dhiman, Massimo Franceschetti, Nikolay\n  Atanasov", "title": "Probabilistic Safety Constraints for Learned High Relative Degree System\n  Dynamics", "comments": "To appear in L4DC 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on learning a model of system dynamics online while\nsatisfying safety constraints.Our motivation is to avoid offline system\nidentification or hand-specified dynamics models and allowa system to safely\nand autonomously estimate and adapt its own model during online operation.Given\nstreaming observations of the system state, we use Bayesian learning to obtain\na distributionover the system dynamics. In turn, the distribution is used to\noptimize the system behavior andensure safety with high probability, by\nspecifying a chance constraint over a control barrier function.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 21:53:31 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 18:55:13 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 16:25:22 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Khojasteh", "Mohammad Javad", ""], ["Dhiman", "Vikas", ""], ["Franceschetti", "Massimo", ""], ["Atanasov", "Nikolay", ""]]}, {"id": "1912.10120", "submitter": "Anjian Li", "authors": "Anjian Li, Somil Bansal, Georgios Giovanis, Varun Tolani, Claire\n  Tomlin, Mo Chen", "title": "Generating Robust Supervision for Learning-Based Visual Navigation Using\n  Hamilton-Jacobi Reachability", "comments": "Learning for Dynamics and Control (L4DC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bansal et al. (2019), a novel visual navigation framework that combines\nlearning-based and model-based approaches has been proposed. Specifically, a\nConvolutional Neural Network (CNN) predicts a waypoint that is used by the\ndynamics model for planning and tracking a trajectory to the waypoint. However,\nthe CNN inevitably makes prediction errors which often lead to collisions in\ncluttered and tight spaces. In this paper, we present a novel Hamilton-Jacobi\n(HJ) reachability-based method to generate supervision for the CNN for waypoint\nprediction in an unseen environment. By modeling CNN prediction error as\n\"disturbances\" in robot's dynamics, our generated waypoints are robust to these\ndisturbances, and consequently to the prediction errors. Moreover, using\nglobally optimal HJ reachability analysis leads to predicting waypoints that\nare time-efficient and avoid greedy behavior. Through simulations and hardware\nexperiments, we demonstrate the advantages of the proposed approach on\nnavigating through cluttered, narrow indoor environments.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 22:11:11 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 18:47:10 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Li", "Anjian", ""], ["Bansal", "Somil", ""], ["Giovanis", "Georgios", ""], ["Tolani", "Varun", ""], ["Tomlin", "Claire", ""], ["Chen", "Mo", ""]]}, {"id": "1912.10127", "submitter": "Matthew Kollada", "authors": "Matthew Kollada, Qingzhu Gao, Monika S Mellem, Tathagata Banerjee,\n  William J Martin", "title": "A Generalizable Method for Automated Quality Control of Functional\n  Neuroimaging Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last twenty five years, advances in the collection and analysis of\nfMRI data have enabled new insights into the brain basis of human health and\ndisease. Individual behavioral variation can now be visualized at a neural\nlevel as patterns of connectivity among brain regions. Functional brain imaging\nis enhancing our understanding of clinical psychiatric disorders by revealing\nties between regional and network abnormalities and psychiatric symptoms.\nInitial success in this arena has recently motivated collection of larger\ndatasets which are needed to leverage fMRI to generate brain-based biomarkers\nto support development of precision medicines. Despite methodological advances\nand enhanced computational power, evaluating the quality of fMRI scans remains\na critical step in the analytical framework. Before analysis can be performed,\nexpert reviewers visually inspect raw scans and preprocessed derivatives to\ndetermine viability of the data. This Quality Control (QC) process is labor\nintensive, and the inability to automate at large scale has proven to be a\nlimiting factor in clinical neuroscience fMRI research. We present a novel\nmethod for automating the QC of fMRI scans. We train machine learning\nclassifiers using features derived from brain MR images to predict the\n\"quality\" of those images, based on the ground truth of an expert's opinion. We\nemphasize the importance of these classifiers' ability to generalize their\npredictions across data from different studies. To address this, we propose a\nnovel approach entitled \"FMRI preprocessing Log mining for Automated,\nGeneralizable Quality Control\" (FLAG-QC), in which features derived from mining\nruntime logs are used to train the classifier. We show that classifiers trained\non FLAG-QC features perform much better (AUC=0.79) than previously proposed\nfeature sets (AUC=0.56) when testing their ability to generalize across\nstudies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 22:43:52 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kollada", "Matthew", ""], ["Gao", "Qingzhu", ""], ["Mellem", "Monika S", ""], ["Banerjee", "Tathagata", ""], ["Martin", "William J", ""]]}, {"id": "1912.10136", "submitter": "Oscar Zatarain-Vera", "authors": "Oscar Zatarain-Vera", "title": "A vector-contraction inequality for Rademacher complexities using\n  $p$-stable variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Andreas Maurer in the paper \"A vector-contraction inequality for Rademacher\ncomplexities\" extended the contraction inequality for Rademacher averages to\nLipschitz functions with vector-valued domains; He did it replacing the\nRademacher variables in the bounding expression by arbitrary idd symmetric and\nsub-gaussian variables. We will see how to extend this work when we replace\nsub-gaussian variables by $p$-stable variables for $1<p<2$.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 23:05:31 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 05:45:07 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zatarain-Vera", "Oscar", ""]]}, {"id": "1912.10146", "submitter": "Sheng Li", "authors": "Sheng Li, Maxim Egorov and Mykel Kochenderfer", "title": "Optimizing Collision Avoidance in Dense Airspace using Deep\n  Reinforcement Learning", "comments": "Thirteenth USA/Europe Air Traffic Management Research and Development\n  Seminar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New methodologies will be needed to ensure the airspace remains safe and\nefficient as traffic densities rise to accommodate new unmanned operations.\nThis paper explores how unmanned free-flight traffic may operate in dense\nairspace. We develop and analyze autonomous collision avoidance systems for\naircraft operating in dense airspace where traditional collision avoidance\nsystems fail. We propose a metric for quantifying the decision burden on a\ncollision avoidance system as well as a metric for measuring the impact of the\ncollision avoidance system on airspace. We use deep reinforcement learning to\ncompute corrections for an existing collision avoidance approach to account for\ndense airspace. The results show that a corrected collision avoidance system\ncan operate more efficiently than traditional methods in dense airspace while\nmaintaining high levels of safety.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 23:31:44 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Li", "Sheng", ""], ["Egorov", "Maxim", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1912.10154", "submitter": "Yin Cui", "authors": "Yin Cui, Zeqi Gu, Dhruv Mahajan, Laurens van der Maaten, Serge\n  Belongie, Ser-Nam Lim", "title": "Measuring Dataset Granularity", "comments": "Code is available at:\n  https://github.com/richardaecn/dataset-granularity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the increasing visibility of fine-grained recognition in our field,\n\"fine-grained'' has thus far lacked a precise definition. In this work,\nbuilding upon clustering theory, we pursue a framework for measuring dataset\ngranularity. We argue that dataset granularity should depend not only on the\ndata samples and their labels, but also on the distance function we choose. We\npropose an axiomatic framework to capture desired properties for a dataset\ngranularity measure and provide examples of measures that satisfy these\nproperties. We assess each measure via experiments on datasets with\nhierarchical labels of varying granularity. When measuring granularity in\ncommonly used datasets with our measure, we find that certain datasets that are\nwidely considered fine-grained in fact contain subsets of considerable size\nthat are substantially more coarse-grained than datasets generally regarded as\ncoarse-grained. We also investigate the interplay between dataset granularity\nwith a variety of factors and find that fine-grained datasets are more\ndifficult to learn from, more difficult to transfer to, more difficult to\nperform few-shot learning with, and more vulnerable to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 00:44:52 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Cui", "Yin", ""], ["Gu", "Zeqi", ""], ["Mahajan", "Dhruv", ""], ["van der Maaten", "Laurens", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1912.10156", "submitter": "Stephen Ra", "authors": "Farhan Damani, Vishnu Sresht, Stephen Ra", "title": "Black Box Recursive Translations for Molecular Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms for generating molecular structures offer a\npromising new approach to drug discovery. We cast molecular optimization as a\ntranslation problem, where the goal is to map an input compound to a target\ncompound with improved biochemical properties. Remarkably, we observe that when\ngenerated molecules are iteratively fed back into the translator, molecular\ncompound attributes improve with each step. We show that this finding is\ninvariant to the choice of translation model, making this a \"black box\"\nalgorithm. We call this method Black Box Recursive Translation (BBRT), a new\ninference method for molecular property optimization. This simple, powerful\ntechnique operates strictly on the inputs and outputs of any translation model.\nWe obtain new state-of-the-art results for molecular property optimization\ntasks using our simple drop-in replacement with well-known sequence and\ngraph-based models. Our method provides a significant boost in performance\nrelative to its non-recursive peers with just a simple \"for\" loop. Further,\nBBRT is highly interpretable, allowing users to map the evolution of newly\ndiscovered compounds from known starting points.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 00:53:12 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Damani", "Farhan", ""], ["Sresht", "Vishnu", ""], ["Ra", "Stephen", ""]]}, {"id": "1912.10158", "submitter": "Qiyao Wang", "authors": "Qiyao Wang, Haiyan Wang, Chetan Gupta, Susumu Serita", "title": "Regularized Operating Envelope with Interpretability and\n  Implementability Constraints", "comments": "In the proceedings of the 2019 IEEE Big Data Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operating envelope is an important concept in industrial operations. Accurate\nidentification for operating envelope can be extremely beneficial to\nstakeholders as it provides a set of operational parameters that optimizes some\nkey performance indicators (KPI) such as product quality, operational safety,\nequipment efficiency, environmental impact, etc. Given the importance,\ndata-driven approaches for computing the operating envelope are gaining\npopularity. These approaches typically use classifiers such as support vector\nmachines, to set the operating envelope by learning the boundary in the\noperational parameter spaces between the manually assigned `large KPI' and\n`small KPI' groups. One challenge to these approaches is that the assignment to\nthese groups is often ad-hoc and hence arbitrary. However, a bigger challenge\nwith these approaches is that they don't take into account two key features\nthat are needed to operationalize operating envelopes: (i) interpretability of\nthe envelope by the operator and (ii) implementability of the envelope from a\npractical standpoint. In this work, we propose a new definition for operating\nenvelope which directly targets the expected magnitude of KPI (i.e., no need to\narbitrarily bin the data instances into groups) and accounts for the\ninterpretability and the implementability. We then propose a regularized `GA +\npenalty' algorithm that outputs an envelope where the user can tradeoff between\nbias and variance. The validity of our proposed algorithm is demonstrated by\ntwo sets of simulation studies and an application to a real-world challenge in\nthe mining processes of a flotation plant.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 01:03:54 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Wang", "Qiyao", ""], ["Wang", "Haiyan", ""], ["Gupta", "Chetan", ""], ["Serita", "Susumu", ""]]}, {"id": "1912.10160", "submitter": "Gaurav Kumar", "authors": "Gaurav Kumar, Rishabh Joshi, Jaspreet Singh, Promod Yenigalla", "title": "AMUSED: A Multi-Stream Vector Representation Method for Use in Natural\n  Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of building a coherent and non-monotonous conversational agent\nwith proper discourse and coverage is still an area of open research. Current\narchitectures only take care of semantic and contextual information for a given\nquery and fail to completely account for syntactic and external knowledge which\nare crucial for generating responses in a chit-chat system. To overcome this\nproblem, we propose an end to end multi-stream deep learning architecture which\nlearns unified embeddings for query-response pairs by leveraging contextual\ninformation from memory networks and syntactic information by incorporating\nGraph Convolution Networks (GCN) over their dependency parse. A stream of this\nnetwork also utilizes transfer learning by pre-training a bidirectional\ntransformer to extract semantic representation for each input sentence and\nincorporates external knowledge through the the neighborhood of the entities\nfrom a Knowledge Base (KB). We benchmark these embeddings on next sentence\nprediction task and significantly improve upon the existing techniques.\nFurthermore, we use AMUSED to represent query and responses along with its\ncontext to develop a retrieval based conversational agent which has been\nvalidated by expert linguists to have comprehensive engagement with humans.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:35:03 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kumar", "Gaurav", ""], ["Joshi", "Rishabh", ""], ["Singh", "Jaspreet", ""], ["Yenigalla", "Promod", ""]]}, {"id": "1912.10162", "submitter": "Stavros Vologiannidis", "authors": "Eleni Partalidou, Eleftherios Spyromitros-Xioufis, Stavros Doropoulos,\n  Stavros Vologiannidis, Konstantinos I. Diamantaras", "title": "Design and implementation of an open source Greek POS Tagger and Entity\n  Recognizer using spaCy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a machine learning approach to part-of-speech tagging and\nnamed entity recognition for Greek, focusing on the extraction of morphological\nfeatures and classification of tokens into a small set of classes for named\nentities. The architecture model that was used is introduced. The greek version\nof the spaCy platform was added into the source code, a feature that did not\nexist before our contribution, and was used for building the models.\nAdditionally, a part of speech tagger was trained that can detect the\nmorphology of the tokens and performs higher than the state-of-the-art results\nwhen classifying only the part of speech. For named entity recognition using\nspaCy, a model that extends the standard ENAMEX type (organization, location,\nperson) was built. Certain experiments that were conducted indicate the need\nfor flexibility in out-of-vocabulary words and there is an effort for resolving\nthis issue. Finally, the evaluation results are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 13:29:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Partalidou", "Eleni", ""], ["Spyromitros-Xioufis", "Eleftherios", ""], ["Doropoulos", "Stavros", ""], ["Vologiannidis", "Stavros", ""], ["Diamantaras", "Konstantinos I.", ""]]}, {"id": "1912.10163", "submitter": "Makoto Nakatsuji Ph. D.", "authors": "Makoto Nakatsuji", "title": "Can AI Generate Love Advice?: Toward Neural Answer Generation for\n  Non-Factoid Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods that extract answers for non-factoid questions from QA\nsites are seen as critical since they can assist users in reaching their next\ndecisions through conversations with AI systems. The current methods, however,\nhave the following two problems: (1) They can not understand the ambiguous use\nof words in the questions as word usage can strongly depend on the context. As\na result, the accuracies of their answer selections are not good enough. (2)\nThe current methods can only select from among the answers held by QA sites and\ncan not generate new ones. Thus, they can not answer the questions that are\nsomewhat different with those stored in QA sites. Our solution, Neural Answer\nConstruction Model, tackles these problems as it: (1) Incorporates the biases\nof semantics behind questions into word embeddings while also computing them\nregardless of the semantics. As a result, it can extract answers that suit the\ncontexts of words used in the question as well as following the common usage of\nwords across semantics. This improves the accuracy of answer selection. (2)\nUses biLSTM to compute the embeddings of questions as well as those of the\nsentences often used to form answers. It then simultaneously learns the optimum\ncombination of those sentences as well as the closeness between the question\nand those sentences. As a result, our model can construct an answer that\ncorresponds to the situation that underlies the question; it fills the gap\nbetween answer selection and generation and is the first model to move beyond\nthe current simple answer selection model for non-factoid QAs. Evaluations\nusing datasets created for love advice stored in the Japanese QA site, Oshiete\ngoo, indicate that our model achieves 20% higher accuracy in answer creation\nthan the strong baselines. Our model is practical and has already been applied\nto the love advice service in Oshiete goo.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 09:57:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Nakatsuji", "Makoto", ""]]}, {"id": "1912.10166", "submitter": "Zeljko Kraljevic", "authors": "Zeljko Kraljevic, Daniel Bean, Aurelie Mascio, Lukasz Roguski, Amos\n  Folarin, Angus Roberts, Rebecca Bendayan, Richard Dobson", "title": "MedCAT -- Medical Concept Annotation Tool", "comments": "Preprint, 25 pages, 5 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical documents such as Electronic Health Records (EHRs) contain a large\namount of information in an unstructured format. The data in EHRs is a hugely\nvaluable resource documenting clinical narratives and decisions, but whilst the\ntext can be easily understood by human doctors it is challenging to use in\nresearch and clinical applications. To uncover the potential of biomedical\ndocuments we need to extract and structure the information they contain. The\ntask at hand is Named Entity Recognition and Linking (NER+L). The number of\nentities, ambiguity of words, overlapping and nesting make the biomedical area\nsignificantly more difficult than many others. To overcome these difficulties,\nwe have developed the Medical Concept Annotation Tool (MedCAT), an open-source\nunsupervised approach to NER+L. MedCAT uses unsupervised machine learning to\ndisambiguate entities. It was validated on MIMIC-III (a freely accessible\ncritical care database) and MedMentions (Biomedical papers annotated with\nmentions from the Unified Medical Language System). In case of NER+L, the\ncomparison with existing tools shows that MedCAT improves the previous best\nwith only unsupervised learning (F1=0.848 vs 0.691 for disease detection;\nF1=0.710 vs. 0.222 for general concept detection). A qualitative analysis of\nthe vector embeddings learnt by MedCAT shows that it captures latent medical\nknowledge available in EHRs (MIMIC-III). Unsupervised learning can improve the\nperformance of large scale entity extraction, but it has some limitations when\nworking with only a couple of entities and a small dataset. In that case\noptions are supervised learning or active learning, both of which are supported\nin MedCAT via the MedCATtrainer extension. Our approach can detect and link\nmillions of different biomedical concepts with state-of-the-art performance,\nwhilst being lightweight, fast and easy to use.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 17:42:31 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kraljevic", "Zeljko", ""], ["Bean", "Daniel", ""], ["Mascio", "Aurelie", ""], ["Roguski", "Lukasz", ""], ["Folarin", "Amos", ""], ["Roberts", "Angus", ""], ["Bendayan", "Rebecca", ""], ["Dobson", "Richard", ""]]}, {"id": "1912.10167", "submitter": "Marco Berlot", "authors": "Marco Berlot, Evan Kaplan", "title": "Machine Translation with Cross-lingual Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning word embeddings using distributional information is a task that has\nbeen studied by many researchers, and a lot of studies are reported in the\nliterature. On the contrary, less studies were done for the case of multiple\nlanguages. The idea is to focus on a single representation for a pair of\nlanguages such that semantically similar words are closer to one another in the\ninduced representation irrespective of the language. In this way, when data are\nmissing for a particular language, classifiers from another language can be\nused.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:50:35 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 13:50:37 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Berlot", "Marco", ""], ["Kaplan", "Evan", ""]]}, {"id": "1912.10168", "submitter": "Blaine Cole", "authors": "Blaine Cole", "title": "Two Way Adversarial Unsupervised Word Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word translation is a problem in machine translation that seeks to build\nmodels that recover word level correspondence between languages. Recent\napproaches to this problem have shown that word translation models can learned\nwith very small seeding dictionaries, and even without any starting\nsupervision. In this paper we propose a method to jointly find translations\nbetween a pair of languages. Not only does our method learn translations in\nboth directions but it improves accuracy of those translations over past\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 21:21:45 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Cole", "Blaine", ""]]}, {"id": "1912.10170", "submitter": "Joeran Beel", "authors": "Dominika Tkaczyk, Andrew Collins, Joeran Beel", "title": "Na\\\"iveRole: Author-Contribution Extraction and Parsing from Biomedical\n  Manuscripts", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.01174", "journal-ref": "27th AIAI Irish Conference on Artificial Intelligence and\n  Cognitive Science, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the contributions of individual authors to scientific\npublications is important for assessing authors' achievements. Some biomedical\npublications have a short section that describes authors' roles and\ncontributions. It is usually written in natural language and hence author\ncontributions cannot be trivially extracted in a machine-readable format. In\nthis paper, we present 1) A statistical analysis of roles in author\ncontributions sections, and 2) Na\\\"iveRole, a novel approach to extract\nstructured authors' roles from author contribution sections. For the first\npart, we used co-clustering techniques, as well as Open Information Extraction,\nto semi-automatically discover the popular roles within a corpus of 2,000\ncontributions sections from PubMed Central. The discovered roles were used to\nautomatically build a training set for Na\\\"iveRole, our role extractor\napproach, based on Na\\\"ive Bayes. Na\\\"iveRole extracts roles with a\nmicro-averaged precision of 0.68, recall of 0.48 and F1 of 0.57. It is, to the\nbest of our knowledge, the first attempt to automatically extract author roles\nfrom research papers. This paper is an extended version of a previous poster\npublished at JCDL 2018.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 14:37:06 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Tkaczyk", "Dominika", ""], ["Collins", "Andrew", ""], ["Beel", "Joeran", ""]]}, {"id": "1912.10189", "submitter": "Christopher J. Cueva", "authors": "Christopher J. Cueva, Peter Y. Wang, Matthew Chin, Xue-Xin Wei", "title": "Emergence of functional and structural properties of the head direction\n  system by optimization of recurrent neural networks", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work suggests goal-driven training of neural networks can be used to\nmodel neural activity in the brain. While response properties of neurons in\nartificial neural networks bear similarities to those in the brain, the network\narchitectures are often constrained to be different. Here we ask if a neural\nnetwork can recover both neural representations and, if the architecture is\nunconstrained and optimized, the anatomical properties of neural circuits. We\ndemonstrate this in a system where the connectivity and the functional\norganization have been characterized, namely, the head direction circuits of\nthe rodent and fruit fly. We trained recurrent neural networks (RNNs) to\nestimate head direction through integration of angular velocity. We found that\nthe two distinct classes of neurons observed in the head direction system, the\nCompass neurons and the Shifter neurons, emerged naturally in artificial neural\nnetworks as a result of training. Furthermore, connectivity analysis and\nin-silico neurophysiology revealed structural and mechanistic similarities\nbetween artificial networks and the head direction system. Overall, our results\nshow that optimization of RNNs in a goal-driven task can recapitulate the\nstructure and function of biological circuits, suggesting that artificial\nneural networks can be used to study the brain at the level of both neural\nactivity and anatomical organization.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 03:51:58 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 09:06:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cueva", "Christopher J.", ""], ["Wang", "Peter Y.", ""], ["Chin", "Matthew", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "1912.10200", "submitter": "Rui Zhang", "authors": "Rui Zhang, Christian J. Walder, Edwin V. Bonilla, Marian-Andrei\n  Rizoiu, Lexing Xie", "title": "Quantile Propagation for Wasserstein-Approximate Gaussian Processes", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate inference techniques are the cornerstone of probabilistic methods\nbased on Gaussian process priors. Despite this, most work approximately\noptimizes standard divergence measures such as the Kullback-Leibler (KL)\ndivergence, which lack the basic desiderata for the task at hand, while chiefly\noffering merely technical convenience. We develop a new approximate inference\nmethod for Gaussian process models which overcomes the technical challenges\narising from abandoning these convenient divergences. Our method---dubbed\nQuantile Propagation (QP)---is similar to expectation propagation (EP) but\nminimizes the $L_2$ Wasserstein distance (WD) instead of the KL divergence. The\nWD exhibits all the required properties of a distance metric, while respecting\nthe geometry of the underlying sample space. We show that QP matches quantile\nfunctions rather than moments as in EP and has the same mean update but a\nsmaller variance update than EP, thereby alleviating EP's tendency to\nover-estimate posterior variances. Crucially, despite the significant\ncomplexity of dealing with the WD, QP has the same favorable locality property\nas EP, and thereby admits an efficient algorithm. Experiments on classification\nand Poisson regression show that QP outperforms both EP and variational Bayes.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:11:12 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 06:02:16 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 08:37:16 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhang", "Rui", ""], ["Walder", "Christian J.", ""], ["Bonilla", "Edwin V.", ""], ["Rizoiu", "Marian-Andrei", ""], ["Xie", "Lexing", ""]]}, {"id": "1912.10202", "submitter": "Songgaojun Deng", "authors": "Songgaojun Deng, Shusen Wang, Huzefa Rangwala, Lijing Wang, Yue Ning", "title": "Graph Message Passing with Cross-location Attentions for Long-term ILI\n  Prediction", "comments": "17 pages, 22 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting influenza-like illness (ILI) is of prime importance to\nepidemiologists and health-care providers. Early prediction of epidemic\noutbreaks plays a pivotal role in disease intervention and control. Most\nexisting work has either limited long-term prediction performance or lacks a\ncomprehensive ability to capture spatio-temporal dependencies in data. Accurate\nand early disease forecasting models would markedly improve both epidemic\nprevention and managing the onset of an epidemic. In this paper, we design a\ncross-location attention based graph neural network (Cola-GNN) for learning\ntime series embeddings and location aware attentions. We propose a graph\nmessage passing framework to combine learned feature embeddings and an\nattention matrix to model disease propagation over time. We compare the\nproposed method with state-of-the-art statistical approaches and deep learning\nmodels on real-world epidemic-related datasets from United States and Japan.\nThe proposed method shows strong predictive performance and leads to\ninterpretable results for long-term epidemic predictions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:28:05 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 03:47:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Deng", "Songgaojun", ""], ["Wang", "Shusen", ""], ["Rangwala", "Huzefa", ""], ["Wang", "Lijing", ""], ["Ning", "Yue", ""]]}, {"id": "1912.10204", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Carolyn Penstein Rose", "title": "A Machine Learning Framework for Authorship Identification From Texts", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship identification is a process in which the author of a text is\nidentified. Most known literary texts can easily be attributed to a certain\nauthor because they are, for example, signed. Yet sometimes we find unfinished\npieces of work or a whole bunch of manuscripts with a wide variety of possible\nauthors. In order to assess the importance of such a manuscript, it is vital to\nknow who wrote it. In this work, we aim to develop a machine learning framework\nto effectively determine authorship. We formulate the task as a single-label\nmulti-class text categorization problem and propose a supervised machine\nlearning framework incorporating stylometric features. This task is highly\ninterdisciplinary in that it takes advantage of machine learning, information\nretrieval, and natural language processing. We present an approach and a model\nwhich learns the differences in writing style between $50$ different authors\nand is able to predict the author of a new text with high accuracy. The\naccuracy is seen to increase significantly after introducing certain linguistic\nstylometric features along with text features.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:47:58 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Rose", "Carolyn Penstein", ""]]}, {"id": "1912.10206", "submitter": "James Fox", "authors": "James Fox, Sivasankaran Rajamanickam", "title": "How Robust Are Graph Neural Networks to Structural Noise?", "comments": "Accepted workshop paper at Deep Learning on Graphs: Methodologies and\n  Applications (DLGMA'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are an emerging model for learning graph\nembeddings and making predictions on graph structured data. However, robustness\nof graph neural networks is not yet well-understood. In this work, we focus on\nnode structural identity predictions, where a representative GNN model is able\nto achieve near-perfect accuracy. We also show that the same GNN model is not\nrobust to addition of structural noise, through a controlled dataset and set of\nexperiments. Finally, we show that under the right conditions, graph-augmented\ntraining is capable of significantly improving robustness to structural noise.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:56:15 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Fox", "James", ""], ["Rajamanickam", "Sivasankaran", ""]]}, {"id": "1912.10231", "submitter": "Fabio Pasqualetti", "authors": "Rajasekhar Anguluri, Abed AlRahman Al Makdah, Vaibhav Katewa, and\n  Fabio Pasqualetti", "title": "On the Robustness of Data-Driven Controllers for Linear Systems", "comments": "Submitted to 2nd L4DC Conference\n  (https://sites.google.com/berkeley.edu/l4dc/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new framework and several results to quantify the\nperformance of data-driven state-feedback controllers for linear systems\nagainst targeted perturbations of the training data. We focus on the case where\nsubsets of the training data are randomly corrupted by an adversary, and derive\nlower and upper bounds for the stability of the closed-loop system with\ncompromised controller as a function of the perturbation statistics, size of\nthe training data, sensitivity of the data-driven algorithm to perturbation of\nthe training data, and properties of the nominal closed-loop system. Our\nstability and convergence bounds are probabilistic in nature, and rely on a\nfirst-order approximation of the data-driven procedure that designs the\nstate-feedback controller, which can be computed directly using the training\ndata. We illustrate our findings via multiple numerical studies.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 09:31:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Anguluri", "Rajasekhar", ""], ["Makdah", "Abed AlRahman Al", ""], ["Katewa", "Vaibhav", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "1912.10233", "submitter": "Deli Zhao", "authors": "Deli Zhao and Jiapeng Zhu and Bo Zhang", "title": "Latent Variables on Spheres for Autoencoders in High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Auto-Encoder (VAE) has been widely applied as a fundamental\ngenerative model in machine learning. For complex samples like imagery objects\nor scenes, however, VAE suffers from the dimensional dilemma between\nreconstruction precision that needs high-dimensional latent codes and\nprobabilistic inference that favors a low-dimensional latent space. By virtue\nof high-dimensional geometry, we propose a very simple algorithm, called\nSpherical Auto-Encoder (SAE), completely different from existing VAEs to\naddress the issue. SAE is in essence the vanilla autoencoder with spherical\nnormalization on the latent space. We analyze the unique characteristics of\nrandom variables on spheres in high dimensions and argue that random variables\non spheres are agnostic to various prior distributions and data modes when the\ndimension is sufficiently high. Therefore, SAE can harness a high-dimensional\nlatent space to improve the inference precision of latent codes while maintain\nthe property of stochastic sampling from priors. The experiments on sampling\nand inference validate our theoretical analysis and the superiority of SAE.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 09:53:53 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 02:20:03 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhao", "Deli", ""], ["Zhu", "Jiapeng", ""], ["Zhang", "Bo", ""]]}, {"id": "1912.10248", "submitter": "Huaizheng Zhang", "authors": "Huaizheng Zhang, Yong Luo, Qiming Ai, Yonggang Wen", "title": "Look, Read and Feel: Benchmarking Ads Understanding with Multimodal\n  Multitask Learning", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the massive market of advertising and the sharply increasing online\nmultimedia content (such as videos), it is now fashionable to promote\nadvertisements (ads) together with the multimedia content. It is exhausted to\nfind relevant ads to match the provided content manually, and hence, some\nautomatic advertising techniques are developed. Since ads are usually hard to\nunderstand only according to its visual appearance due to the contained visual\nmetaphor, some other modalities, such as the contained texts, should be\nexploited for understanding. To further improve user experience, it is\nnecessary to understand both the topic and sentiment of the ads. This motivates\nus to develop a novel deep multimodal multitask framework to integrate multiple\nmodalities to achieve effective topic and sentiment prediction simultaneously\nfor ads understanding. In particular, our model first extracts multimodal\ninformation from ads and learn high-level and comparable representations. The\nvisual metaphor of the ad is decoded in an unsupervised manner. The obtained\nrepresentations are then fed into the proposed hierarchical multimodal\nattention modules to learn task-specific representations for final prediction.\nA multitask loss function is also designed to train both the topic and\nsentiment prediction models jointly in an end-to-end manner. We conduct\nextensive experiments on the latest and large advertisement dataset and achieve\nstate-of-the-art performance for both prediction tasks. The obtained results\ncould be utilized as a benchmark for ads understanding.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 11:19:08 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 09:37:30 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zhang", "Huaizheng", ""], ["Luo", "Yong", ""], ["Ai", "Qiming", ""], ["Wen", "Yonggang", ""]]}, {"id": "1912.10251", "submitter": "Chowdhury Rahman", "authors": "Ruhul Amin, Chowdhury Rafeed Rahman, Md. Habibur Rahman Sifat, Md\n  Nazmul Khan Liton, Md. Moshiur Rahman, Swakkhar Shatabda and Sajid Ahmed", "title": "iPromoter-BnCNN: a Novel Branched CNN Based Predictor for Identifying\n  and Classifying Sigma Promoters", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btaa609", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promoter is a short region of DNA which is responsible for initiating\ntranscription of specific genes. Development of computational tools for\nautomatic identification of promoters is in high demand. According to the\ndifference of functions, promoters can be of different types. Promoters may\nhave both intra and inter class variation and similarity in terms of consensus\nsequences. Accurate classification of various types of sigma promoters still\nremains a challenge. We present iPromoter-BnCNN for identification and accurate\nclassification of six types of promoters - sigma24, sigma28, sigma32, sigma38,\nsigma54, sigma70. It is a Convolutional Neural Network (CNN) based classifier\nwhich combines local features related to monomer nucleotide sequence, trimer\nnucleotide sequence, dimer structural properties and trimer structural\nproperties through the use of parallel branching. We conducted experiments on a\nbenchmark dataset and compared with two state-of-the-art tools to show our\nsupremacy on 5-fold cross-validation. Moreover, we tested our classifier on an\nindependent test dataset. Our proposed tool iPromoter-BnCNN web server is\nfreely available at http://103.109.52.8/iPromoter-BnCNN. The runnable source\ncode can be found at\nhttps://colab.research.google.com/drive/1yWWh7BXhsm8U4PODgPqlQRy23QGjF2DZ.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 11:59:38 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 06:51:47 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 01:20:09 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 20:44:32 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Amin", "Ruhul", ""], ["Rahman", "Chowdhury Rafeed", ""], ["Sifat", "Md. Habibur Rahman", ""], ["Liton", "Md Nazmul Khan", ""], ["Rahman", "Md. Moshiur", ""], ["Shatabda", "Swakkhar", ""], ["Ahmed", "Sajid", ""]]}, {"id": "1912.10256", "submitter": "Wenbo Hu", "authors": "Wen-Jin Fu, Xiao-Jun Wu, He-Feng Yin, Wen-Bo Hu", "title": "Research on Clustering Performance of Sparse Subspace Clustering", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sparse subspace clustering has been a valid tool to deal with\nhigh-dimensional data. There are two essential steps in the framework of sparse\nsubspace clustering. One is solving the coefficient matrix of data, and the\nother is constructing the affinity matrix from the coefficient matrix, which is\napplied to the spectral clustering. This paper investigates the factors which\naffect clustering performance from both clustering accuracy and stability of\nthe approaches based on existing algorithms. We select four methods to solve\nthe coefficient matrix and use four different ways to construct a similarity\nmatrix for each coefficient matrix. Then we compare the clustering performance\nof different combinations on three datasets. The experimental results indicate\nthat both the coefficient matrix and affinity matrix have a huge influence on\nclustering performance and how to develop a stable and valid algorithm still\nneeds to be studied.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 12:41:08 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Fu", "Wen-Jin", ""], ["Wu", "Xiao-Jun", ""], ["Yin", "He-Feng", ""], ["Hu", "Wen-Bo", ""]]}, {"id": "1912.10264", "submitter": "Hegler Tissot", "authors": "Matthew Wai Heng Chung and Hegler Tissot", "title": "Evaluating the Effectiveness of Margin Parameter when Learning Knowledge\n  Embedding Representation for Domain-specific Multi-relational Categorized\n  Data", "comments": null, "journal-ref": "StarAI 2020 9th International Workshop on Statistical Relational\n  AI", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge representation is an increasingly important technology\nthat supports a variety of machine learning related applications. However, the\nchoice of hyperparameters is seldom justified and usually relies on exhaustive\nsearch. Understanding the effect of hyperparameter combinations on embedding\nquality is crucial to avoid the inefficient process and enhance practicality of\nvector representation methods. We evaluate the effects of distinct values for\nthe margin parameter focused on translational embedding representation models\nfor multi-relational categorized data. We assess the margin influence regarding\nthe quality of embedding models by contrasting traditional link prediction task\naccuracy against a classification task. The findings provide evidence that\nlower values of margin are not rigorous enough to help with the learning\nprocess, whereas larger values produce much noise pushing the entities beyond\nto the surface of the hyperspace, thus requiring constant regularization.\nFinally, the correlation between link prediction and classification accuracy\nshows traditional validation protocol for embedding models is a weak metric to\nrepresent the quality of embedding representation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 13:24:08 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chung", "Matthew Wai Heng", ""], ["Tissot", "Hegler", ""]]}, {"id": "1912.10266", "submitter": "Patrick Michl", "authors": "Patrick Michl", "title": "Foundations of Structural Statistics: Topological Statistical Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Topological statistical theory provides the foundation for a modern\nmathematical reformulation of classical statistical theory: Structural\nStatistics emphasizes the structural assumptions that accompany distribution\nfamilies and the set of structure preserving transformations between them,\ngiven by their statistical morphisms. The resulting language is designed to\nintegrate complicated structured model spaces like deep-learning models and to\nclose the gap to topology and differential geometry. To preserve the\ncompatibility to classical statistics the language comprises corresponding\nconcepts for standard information criteria like sufficiency and completeness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 13:28:59 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 19:26:45 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 13:12:40 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Michl", "Patrick", ""]]}, {"id": "1912.10292", "submitter": "Yapeng Tian", "authors": "Yapeng Tian, Chenliang Xu, and Dingzeyu Li", "title": "Deep Audio Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are known to specialize in distilling\ncompact and robust prior from a large amount of data. We are interested in\napplying deep networks in the absence of training dataset. In this paper, we\nintroduce deep audio prior (DAP) which leverages the structure of a network and\nthe temporal information in a single audio file. Specifically, we demonstrate\nthat a randomly-initialized neural network can be used with carefully designed\naudio prior to tackle challenging audio problems such as universal blind source\nseparation, interactive audio editing, audio texture synthesis, and audio\nco-separation. To understand the robustness of the deep audio prior, we\nconstruct a benchmark dataset \\emph{Universal-150} for universal sound source\nseparation with a diverse set of sources. We show superior audio results than\nprevious work on both qualitative and quantitative evaluations. We also perform\nthorough ablation study to validate our design choices.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 16:35:54 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Tian", "Yapeng", ""], ["Xu", "Chenliang", ""], ["Li", "Dingzeyu", ""]]}, {"id": "1912.10306", "submitter": "Xiong Liu", "authors": "Xiong Liu, Yu Chen, Jay Bae, Hu Li, Joseph Johnston, Todd Sanger", "title": "Predicting Heart Failure Readmission from Clinical Notes Using Deep\n  Learning", "comments": "IEEE BIBM 2019", "journal-ref": "2019 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart failure hospitalization is a severe burden on healthcare. How to\npredict and therefore prevent readmission has been a significant challenge in\noutcomes research. To address this, we propose a deep learning approach to\npredict readmission from clinical notes. Unlike conventional methods that use\nstructured data for prediction, we leverage the unstructured clinical notes to\ntrain deep learning models based on convolutional neural networks (CNN). We\nthen use the trained models to classify and predict potentially high-risk\nadmissions/patients. For evaluation, we trained CNNs using the discharge\nsummary notes in the MIMIC III database. We also trained regular machine\nlearning models based on random forest using the same datasets. The result\nshows that deep learning models outperform the regular models in prediction\ntasks. CNN method achieves a F1 score of 0.756 in general readmission\nprediction and 0.733 in 30-day readmission prediction, while random forest only\nachieves a F1 score of 0.674 and 0.656 respectively. We also propose a\nchi-square test based method to interpret key features associated with deep\nlearning predicted readmissions. It reveals clinical insights about readmission\nembedded in the clinical notes. Collectively, our method can make the human\nevaluation process more efficient and potentially facilitate the reduction of\nreadmission rates.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 17:49:13 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Liu", "Xiong", ""], ["Chen", "Yu", ""], ["Bae", "Jay", ""], ["Li", "Hu", ""], ["Johnston", "Joseph", ""], ["Sanger", "Todd", ""]]}, {"id": "1912.10309", "submitter": "Graham Fyffe", "authors": "Graham Fyffe", "title": "There and Back Again: Unraveling the Variational Auto-Encoder", "comments": "20 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We prove that the evidence lower bound (ELBO) employed by variational\nauto-encoders (VAEs) admits non-trivial solutions having constant posterior\nvariances under certain mild conditions, removing the need to learn variances\nin the encoder. The proof follows from an unexpected journey through an array\nof topics: the closed form optimal decoder for Gaussian VAEs, a proof that the\ndecoder is always smooth, a proof that the ELBO at its stationary points is\nequal to the exact log evidence, and the posterior variance is merely part of a\nstochastic estimator of the decoder Hessian. The penalty incurred from using a\nconstant posterior variance is small under mild conditions, and otherwise\ndiscourages large variations in the decoder Hessian. From here we derive a\nsimplified formulation of the ELBO as an expectation over a batch, which we\ncall the Batch Information Lower Bound (BILBO). Despite the use of Gaussians,\nour analysis is broadly applicable -- it extends to any likelihood function\nthat induces a Riemannian metric. Regarding learned likelihoods, we show that\nthe ELBO is optimal in the limit as the likelihood variances approach zero,\nwhere it is equivalent to the change of variables formulation employed in\nnormalizing flow networks. Standard optimization procedures are unstable in\nthis limit, so we propose a bounded Gaussian likelihood that is invariant to\nthe scale of the data using a measure of the aggregate information in a batch,\nwhich we call Bounded Aggregate Information Sampling (BAGGINS). Combining the\ntwo formulations, we construct VAE networks with only half the outputs of\nordinary VAEs (no learned variances), yielding improved ELBO scores and scale\ninvariance in experiments. As we perform our analyses irrespective of any\nparticular network architecture, our reformulations may apply to any VAE\nimplementation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 18:21:22 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 22:30:22 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 07:27:37 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Fyffe", "Graham", ""]]}, {"id": "1912.10316", "submitter": "Abhishek Nan", "authors": "Abhishek Nan", "title": "Exploring TD error as a heuristic for $\\sigma$ selection in Q($\\sigma$,\n  $\\lambda$)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the landscape of TD algorithms, the Q($\\sigma$, $\\lambda$) algorithm is an\nalgorithm with the ability to perform a multistep backup in an online manner\nwhile also successfully unifying the concepts of sampling with using the\nexpectation across all actions for a state. $\\sigma \\in [0, 1]$ indicates the\nextent to which sampling is used. Selecting the value of {\\sigma} can be based\non characteristics of the current state rather than having a constant value or\nbeing time based. This report explores the viability of such a TD-error based\nscheme.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 18:53:13 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Nan", "Abhishek", ""]]}, {"id": "1912.10321", "submitter": "Ari Heljakka", "authors": "Ari Heljakka, Yuxin Hou, Juho Kannala, Arno Solin", "title": "Deep Automodulators", "comments": "To appear in Advances in Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new category of generative autoencoders called automodulators.\nThese networks can faithfully reproduce individual real-world input images like\nregular autoencoders, but also generate a fused sample from an arbitrary\ncombination of several such images, allowing instantaneous 'style-mixing' and\nother new applications. An automodulator decouples the data flow of decoder\noperations from statistical properties thereof and uses the latent vector to\nmodulate the former by the latter, with a principled approach for mutual\ndisentanglement of decoder layers. Prior work has explored similar decoder\narchitecture with GANs, but their focus has been on random sampling. A\ncorresponding autoencoder could operate on real input images. For the first\ntime, we show how to train such a general-purpose model with sharp outputs in\nhigh resolution, using novel training techniques, demonstrated on four image\ndata sets. Besides style-mixing, we show state-of-the-art results in\nautoencoder comparison, and visual image quality nearly indistinguishable from\nstate-of-the-art GANs. We expect the automodulator variants to become a useful\nbuilding block for image applications and other data domains.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 19:16:33 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 18:01:55 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 16:54:08 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 12:58:09 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Heljakka", "Ari", ""], ["Hou", "Yuxin", ""], ["Kannala", "Juho", ""], ["Solin", "Arno", ""]]}, {"id": "1912.10325", "submitter": "Arghyadip Roy", "authors": "Arghyadip Roy, Vivek Borkar, Abhay Karandikar and Prasanna Chaporkar", "title": "Online Reinforcement Learning of Optimal Threshold Policies for Markov\n  Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Process (MDP) problems can be solved using Dynamic\nProgramming (DP) methods which suffer from the curse of dimensionality and the\ncurse of modeling. To overcome these issues, Reinforcement Learning (RL)\nmethods are adopted in practice. In this paper, we aim to obtain the optimal\nadmission control policy in a system where different classes of customers are\npresent. Using DP techniques, we prove that it is optimal to admit the $i$ th\nclass of customers only upto a threshold $\\tau(i)$ which is a non-increasing\nfunction of $i$. Contrary to traditional RL algorithms which do not take into\naccount the structural properties of the optimal policy while learning, we\npropose a structure-aware learning algorithm which exploits the threshold\nstructure of the optimal policy. We prove the asymptotic convergence of the\nproposed algorithm to the optimal policy. Due to the reduction in the policy\nspace, the structure-aware learning algorithm provides remarkable improvements\nin storage and computational complexities over classical RL algorithms.\nSimulation results also establish the gain in the convergence rate of the\nproposed algorithm over other RL algorithms. The techniques presented in the\npaper can be applied to any general MDP problem covering various applications\nsuch as inventory management, financial planning and communication networking.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 19:46:55 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 01:17:59 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Roy", "Arghyadip", ""], ["Borkar", "Vivek", ""], ["Karandikar", "Abhay", ""], ["Chaporkar", "Prasanna", ""]]}, {"id": "1912.10329", "submitter": "Yanchao Sun", "authors": "Yanchao Sun and Furong Huang", "title": "Can Agents Learn by Analogy? An Inferable Model for PAC Reinforcement\n  Learning", "comments": "To be published in proceedings of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning algorithms make decisions by building and\nutilizing a model of the environment. However, none of the existing algorithms\nattempts to infer the dynamics of any state-action pair from known state-action\npairs before meeting it for sufficient times. We propose a new model-based\nmethod called Greedy Inference Model (GIM) that infers the unknown dynamics\nfrom known dynamics based on the internal spectral properties of the\nenvironment. In other words, GIM can \"learn by analogy\". We further introduce a\nnew exploration strategy which ensures that the agent rapidly and evenly visits\nunknown state-action pairs. GIM is much more computationally efficient than\nstate-of-the-art model-based algorithms, as the number of dynamic programming\noperations is independent of the environment size. Lower sample complexity\ncould also be achieved under mild conditions compared against methods without\ninferring. Experimental results demonstrate the effectiveness and efficiency of\nGIM in a variety of real-world tasks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 20:09:10 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 20:43:15 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 16:04:53 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sun", "Yanchao", ""], ["Huang", "Furong", ""]]}, {"id": "1912.10337", "submitter": "Mingyuan Zhou", "authors": "Dandan Guo, Bo Chen, Ruiying Lu, Mingyuan Zhou", "title": "Recurrent Hierarchical Topic-Guided RNN for Language Generation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To simultaneously capture syntax and global semantics from a text corpus, we\npropose a new larger-context recurrent neural network (RNN) based language\nmodel, which extracts recurrent hierarchical semantic structure via a dynamic\ndeep topic model to guide natural language generation. Moving beyond a\nconventional RNN-based language model that ignores long-range word dependencies\nand sentence order, the proposed model captures not only intra-sentence word\ndependencies, but also temporal transitions between sentences and\ninter-sentence topic dependencies. For inference, we develop a hybrid of\nstochastic-gradient Markov chain Monte Carlo and recurrent autoencoding\nvariational Bayes. Experimental results on a variety of real-world text corpora\ndemonstrate that the proposed model not only outperforms larger-context\nRNN-based language models, but also learns interpretable recurrent multilayer\ntopics and generates diverse sentences and paragraphs that are syntactically\ncorrect and semantically coherent.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 21:11:35 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 22:22:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Guo", "Dandan", ""], ["Chen", "Bo", ""], ["Lu", "Ruiying", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1912.10338", "submitter": "El Wardani Dadi Dr.", "authors": "El Wardani Dadi", "title": "Tifinagh-IRCAM Handwritten character recognition using Deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we exploit the benefits of the deep learning approach to\ndesign an efficient system of Amazigh handwritten recognition. Indeed, this\napproach has proved a greater efficiency in the various domains, especially\nrecognition tasks. However, to take full advantage of this approach it's\nnecessary to construct an adequate dataset of training and testing that\nrepresent faithfully the concerned problem. To this end, we have prepared our\ndataset of 102 writers each one contains 33 characters of IRCAM-Tifinagh.\nInspired by the MNIST database, the set of characters is size-normalized and\ncentered in a fixed-size image. The resulting is a grey level image of size\n28x28, where the black color is the non-color of the character. The number of\nimages produced after this preprocessing step is 3,366.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 21:12:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dadi", "El Wardani", ""]]}, {"id": "1912.10340", "submitter": "Jittat Fakcharoenphol", "authors": "Jittat Fakcharoenphol, Chayutpong Prompak", "title": "Bandit Multiclass Linear Classification for the Group Linear Separable\n  Case", "comments": "This work is first published in iSAI-NLP 2019, Chiang Mai, Thailand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the online multiclass linear classification under the bandit\nfeedback setting. Beygelzimer, P\\'{a}l, Sz\\\"{o}r\\'{e}nyi, Thiruvenkatachari,\nWei, and Zhang [ICML'19] considered two notions of linear separability, weak\nand strong linear separability. When examples are strongly linearly separable\nwith margin $\\gamma$, they presented an algorithm based on Multiclass\nPerceptron with mistake bound $O(K/\\gamma^2)$, where $K$ is the number of\nclasses. They employed rational kernel to deal with examples under the weakly\nlinearly separable condition, and obtained the mistake bound of $\\min(K\\cdot\n2^{\\tilde{O}(K\\log^2(1/\\gamma))},K\\cdot 2^{\\tilde{O}(\\sqrt{1/\\gamma}\\log K)})$.\nIn this paper, we refine the notion of weak linear separability to support the\nnotion of class grouping, called group weak linear separable condition. This\nsituation may arise from the fact that class structures contain inherent\ngrouping. We show that under this condition, we can also use the rational\nkernel and obtain the mistake bound of $K\\cdot 2^{\\tilde{O}(\\sqrt{1/\\gamma}\\log\nL)})$, where $L\\leq K$ represents the number of groups.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 21:17:58 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Fakcharoenphol", "Jittat", ""], ["Prompak", "Chayutpong", ""]]}, {"id": "1912.10360", "submitter": "Julian Nubert", "authors": "Julian Nubert, Johannes K\\\"ohler, Vincent Berenz, Frank Allg\\\"ower,\n  and Sebastian Trimpe", "title": "Safe and Fast Tracking on a Robot Manipulator: Robust MPC and Neural\n  Network Control", "comments": "8 pages, 4 figures,", "journal-ref": "Robotics and Automation Letters, 2020", "doi": "10.1109/LRA.2020.2975727", "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast feedback control and safety guarantees are essential in modern robotics.\nWe present an approach that achieves both by combining novel robust model\npredictive control (MPC) with function approximation via (deep) neural networks\n(NNs). The result is a new approach for complex tasks with nonlinear,\nuncertain, and constrained dynamics as are common in robotics. Specifically, we\nleverage recent results in MPC research to propose a new robust setpoint\ntracking MPC algorithm, which achieves reliable and safe tracking of a dynamic\nsetpoint while guaranteeing stability and constraint satisfaction. The\npresented robust MPC scheme constitutes a one-layer approach that unifies the\noften separated planning and control layers, by directly computing the control\ncommand based on a reference and possibly obstacle positions. As a separate\ncontribution, we show how the computation time of the MPC can be drastically\nreduced by approximating the MPC law with a NN controller. The NN is trained\nand validated from offline samples of the MPC, yielding statistical guarantees,\nand used in lieu thereof at run time. Our experiments on a state-of-the-art\nrobot manipulator are the first to show that both the proposed robust and\napproximate MPC schemes scale to real-world robotic systems.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 00:01:07 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 01:25:59 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Nubert", "Julian", ""], ["K\u00f6hler", "Johannes", ""], ["Berenz", "Vincent", ""], ["Allg\u00f6wer", "Frank", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1912.10364", "submitter": "Wei-Hong Li", "authors": "Wei-Hong Li, Chuan-Sheng Foo, Hakan Bilen", "title": "Learning to Impute: A General Framework for Semi-supervised Learning", "comments": "Semi-supervised Learning, Meta-Learning, Learning to impute", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent semi-supervised learning methods have shown to achieve comparable\nresults to their supervised counterparts while using only a small portion of\nlabels in image classification tasks thanks to their regularization strategies.\nIn this paper, we take a more direct approach for semi-supervised learning and\npropose learning to impute the labels of unlabeled samples such that a network\nachieves better generalization when it is trained on these labels. We pose the\nproblem in a learning-to-learn formulation which can easily be incorporated to\nthe state-of-the-art semi-supervised techniques and boost their performance\nespecially when the labels are limited. We demonstrate that our method is\napplicable to both classification and regression problems including image\nclassification and facial landmark detection tasks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 00:27:21 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:10:00 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 13:53:04 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Li", "Wei-Hong", ""], ["Foo", "Chuan-Sheng", ""], ["Bilen", "Hakan", ""]]}, {"id": "1912.10375", "submitter": "Boxin Wang", "authors": "Boxin Wang, Hengzhi Pei, Boyuan Pan, Qian Chen, Shuohang Wang, Bo Li", "title": "T3: Tree-Autoencoder Constrained Adversarial Text Generation for\n  Targeted Attack", "comments": "Accepted to EMNLP 2020 as a long paper. 17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against natural language processing systems, which\nperform seemingly innocuous modifications to inputs, can induce arbitrary\nmistakes to the target models. Though raised great concerns, such adversarial\nattacks can be leveraged to estimate the robustness of NLP models. Compared\nwith the adversarial example generation in continuous data domain (e.g.,\nimage), generating adversarial text that preserves the original meaning is\nchallenging since the text space is discrete and non-differentiable. To handle\nthese challenges, we propose a target-controllable adversarial attack framework\nT3, which is applicable to a range of NLP tasks. In particular, we propose a\ntree-based autoencoder to embed the discrete text data into a continuous\nrepresentation space, upon which we optimize the adversarial perturbation. A\nnovel tree-based decoder is then applied to regularize the syntactic\ncorrectness of the generated text and manipulate it on either sentence\n(T3(Sent)) or word (T3(Word)) level. We consider two most representative NLP\ntasks: sentiment analysis and question answering (QA). Extensive experimental\nresults and human studies show that T3 generated adversarial texts can\nsuccessfully manipulate the NLP models to output the targeted incorrect answer\nwithout misleading the human. Moreover, we show that the generated adversarial\ntexts have high transferability which enables the black-box attacks in\npractice. Our work sheds light on an effective and general way to examine the\nrobustness of NLP models. Our code is publicly available at\nhttps://github.com/AI-secure/T3/.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 03:02:42 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:29:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Wang", "Boxin", ""], ["Pei", "Hengzhi", ""], ["Pan", "Boyuan", ""], ["Chen", "Qian", ""], ["Wang", "Shuohang", ""], ["Li", "Bo", ""]]}, {"id": "1912.10382", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Ting Lin, Zuowei Shen", "title": "Deep Learning via Dynamical Systems: An Approximation Perspective", "comments": "Revision 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build on the dynamical systems approach to deep learning, where deep\nresidual networks are idealized as continuous-time dynamical systems, from the\napproximation perspective. In particular, we establish general sufficient\nconditions for universal approximation using continuous-time deep residual\nnetworks, which can also be understood as approximation theories in $L^p$ using\nflow maps of dynamical systems. In specific cases, rates of approximation in\nterms of the time horizon are also established. Overall, these results reveal\nthat composition function approximation through flow maps present a new\nparadigm in approximation theory and contributes to building a useful\nmathematical framework to investigate deep learning.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 04:19:33 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 03:21:43 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Qianxiao", ""], ["Lin", "Ting", ""], ["Shen", "Zuowei", ""]]}, {"id": "1912.10389", "submitter": "Eun Seo Jo", "authors": "Eun Seo Jo, Timnit Gebru", "title": "Lessons from Archives: Strategies for Collecting Sociocultural Data in\n  Machine Learning", "comments": "To be published in Conference on Fairness, Accountability, and\n  Transparency FAT* '20, January 27-30, 2020, Barcelona, Spain. ACM, New York,\n  NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3351095.3372829", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work shows that many problems in fairness, accountability,\ntransparency, and ethics in machine learning systems are rooted in decisions\nsurrounding the data collection and annotation process. In spite of its\nfundamental nature however, data collection remains an overlooked part of the\nmachine learning (ML) pipeline. In this paper, we argue that a new\nspecialization should be formed within ML that is focused on methodologies for\ndata collection and annotation: efforts that require institutional frameworks\nand procedures. Specifically for sociocultural data, parallels can be drawn\nfrom archives and libraries. Archives are the longest standing communal effort\nto gather human information and archive scholars have already developed the\nlanguage and procedures to address and discuss many challenges pertaining to\ndata collection such as consent, power, inclusivity, transparency, and ethics &\nprivacy. We discuss these five key approaches in document collection practices\nin archives that can inform data collection in sociocultural ML. By showing\ndata collection practices from another field, we encourage ML research to be\nmore cognizant and systematic in data collection and draw from\ninterdisciplinary expertise.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 05:56:55 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Jo", "Eun Seo", ""], ["Gebru", "Timnit", ""]]}, {"id": "1912.10398", "submitter": "L.A. Prashanth", "authors": "Ajay Kumar Pandey, Prashanth L.A. and Sanjay P. Bhat", "title": "Estimation of Spectral Risk Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a spectral risk measure (SRM) from\ni.i.d. samples, and propose a novel method that is based on numerical\nintegration. We show that our SRM estimate concentrates exponentially, when the\nunderlying distribution has bounded support. Further, we also consider the case\nwhen the underlying distribution is either Gaussian or exponential, and derive\na concentration bound for our estimation scheme. We validate the theoretical\nfindings on a synthetic setup, and in a vehicular traffic routing application.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 08:11:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Pandey", "Ajay Kumar", ""], ["A.", "Prashanth L.", ""], ["Bhat", "Sanjay P.", ""]]}, {"id": "1912.10402", "submitter": "Ian Manchester", "authors": "Max Revay and Ian R. Manchester", "title": "Contracting Implicit Recurrent Neural Networks: Stable Models with\n  Improved Trainability", "comments": "Conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability of recurrent models is closely linked with trainability,\ngeneralizability and in some applications, safety. Methods that train stable\nrecurrent neural networks, however, do so at a significant cost to\nexpressibility. We propose an implicit model structure that allows for a convex\nparametrization of stable models using contraction analysis of non-linear\nsystems. Using these stability conditions we propose a new approach to model\ninitialization and then provide a number of empirical results comparing the\nperformance of our proposed model set to previous stable RNNs and vanilla RNNs.\nBy carefully controlling stability in the model, we observe a significant\nincrease in the speed of training and model performance.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 09:16:05 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Revay", "Max", ""], ["Manchester", "Ian R.", ""]]}, {"id": "1912.10405", "submitter": "Boxiao Pan", "authors": "Boxiao Pan, Zhangjie Cao, Ehsan Adeli, Juan Carlos Niebles", "title": "Adversarial Cross-Domain Action Recognition with Co-Attention", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action recognition has been a widely studied topic with a heavy focus on\nsupervised learning involving sufficient labeled videos. However, the problem\nof cross-domain action recognition, where training and testing videos are drawn\nfrom different underlying distributions, remains largely under-explored.\nPrevious methods directly employ techniques for cross-domain image recognition,\nwhich tend to suffer from the severe temporal misalignment problem. This paper\nproposes a Temporal Co-attention Network (TCoN), which matches the\ndistributions of temporally aligned action features between source and target\ndomains using a novel cross-domain co-attention mechanism. Experimental results\non three cross-domain action recognition datasets demonstrate that TCoN\nimproves both previous single-domain and cross-domain methods significantly\nunder the cross-domain setting.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 09:39:15 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Pan", "Boxiao", ""], ["Cao", "Zhangjie", ""], ["Adeli", "Ehsan", ""], ["Niebles", "Juan Carlos", ""]]}, {"id": "1912.10434", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Iryna Gurevych", "title": "Analyzing Structures in the Semantic Vector Space: A Framework for\n  Decomposing Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are rich word representations, which in combination with deep\nneural networks, lead to large performance gains for many NLP tasks. However,\nword embeddings are represented by dense, real-valued vectors and they are\ntherefore not directly interpretable. Thus, computational operations based on\nthem are also not well understood. In this paper, we present an approach for\nanalyzing structures in the semantic vector space to get a better understanding\nof the underlying semantic encoding principles. We present a framework for\ndecomposing word embeddings into smaller meaningful units which we call\nsub-vectors. The framework opens up a wide range of possibilities analyzing\nphenomena in vector space semantics, as well as solving concrete NLP problems:\nWe introduce the category completion task and show that a sub-vector based\napproach is superior to supervised techniques; We present a sub-vector based\nmethod for solving the word analogy task, which substantially outperforms\ndifferent variants of the traditional vector-offset method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 09:01:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hanselowski", "Andreas", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1912.10435", "submitter": "Ankit Chadha Mr.", "authors": "Ankit Chadha and Rewa Sood", "title": "BERTQA -- Attention on Steroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we extend the Bidirectional Encoder Representations from\nTransformers (BERT) with an emphasis on directed coattention to obtain an\nimproved F1 performance on the SQUAD2.0 dataset. The Transformer architecture\non which BERT is based places hierarchical global attention on the\nconcatenation of the context and query. Our additions to the BERT architecture\naugment this attention with a more focused context to query (C2Q) and query to\ncontext (Q2C) attention via a set of modified Transformer encoder units. In\naddition, we explore adding convolution-based feature extraction within the\ncoattention architecture to add localized information to self-attention. We\nfound that coattention significantly improves the no answer F1 by 4 points in\nthe base and 1 point in the large architecture. After adding skip connections\nthe no answer F1 improved further without causing an additional loss in has\nanswer F1. The addition of localized feature extraction added to attention\nproduced an overall dev F1 of 77.03 in the base architecture. We applied our\nfindings to the large BERT model which contains twice as many layers and\nfurther used our own augmented version of the SQUAD 2.0 dataset created by back\ntranslation, which we have named SQUAD 2.Q. Finally, we performed\nhyperparameter tuning and ensembled our best models for a final F1/EM of\n82.317/79.442 (Attention on Steroids, PCE Test Leaderboard).\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 06:44:12 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chadha", "Ankit", ""], ["Sood", "Rewa", ""]]}, {"id": "1912.10438", "submitter": "Mohammad Saleh Mahdizadeh", "authors": "Mohammad Saleh Mahdizadeh, Behnam Bahrak", "title": "A Regression Framework for Predicting User's Next Location using Call\n  Detail Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of using cell phones and the increase in diversity of smart\nmobile devices, a massive volume of data is generated continuously in the\nprocess of using these devices. Among these data, Call Detail Records, CDR, is\nhighly remarkable. Since CDR contains both temporal and spatial labels,\nmobility analysis of CDR is one of the favorite subjects of study among the\nresearchers. The user next location prediction is one of the main problems in\nthe field of human mobility analysis. In this paper, we propose a data\nprocessing framework to predict user next location. We propose domain-specific\ndata processing strategies and design a deep neural network model which is\nbased on recurrent neurons and perform regression tasks. Using this prediction\nframework, the error of the prediction decreases from 74% to 55% in comparison\nto the worst and best performing traditional models. Methods, strategies, the\nframework and the results of this paper can be helpful in many applications\nsuch as urban planning and digital marketing.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 12:51:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Mahdizadeh", "Mohammad Saleh", ""], ["Bahrak", "Behnam", ""]]}, {"id": "1912.10454", "submitter": "Mostafa Mehdipour Ghazi", "authors": "Mostafa Mehdipour Ghazi, Mads Nielsen, Akshay Pai, Marc Modat, M.\n  Jorge Cardoso, Sebastien Ourselin, Lauge Sorensen", "title": "On the Initialization of Long Short-Term Memory Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-36708-4_23", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight initialization is important for faster convergence and stability of\ndeep neural networks training. In this paper, a robust initialization method is\ndeveloped to address the training instability in long short-term memory (LSTM)\nnetworks. It is based on a normalized random initialization of the network\nweights that aims at preserving the variance of the network input and output in\nthe same range. The method is applied to standard LSTMs for univariate time\nseries regression and to LSTMs robust to missing values for multivariate\ndisease progression modeling. The results show that in all cases, the proposed\ninitialization method outperforms the state-of-the-art initialization\ntechniques in terms of training convergence and generalization performance of\nthe obtained solution.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 14:19:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ghazi", "Mostafa Mehdipour", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Modat", "Marc", ""], ["Cardoso", "M. Jorge", ""], ["Ourselin", "Sebastien", ""], ["Sorensen", "Lauge", ""]]}, {"id": "1912.10481", "submitter": "Angelos Filos", "authors": "Angelos Filos, Sebastian Farquhar, Aidan N. Gomez, Tim G. J. Rudner,\n  Zachary Kenton, Lewis Smith, Milad Alizadeh, Arnoud de Kroon, Yarin Gal", "title": "A Systematic Comparison of Bayesian Deep Learning Robustness in Diabetic\n  Retinopathy Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of Bayesian deep learning (BDL) methods is challenging. We often\nseek to evaluate the methods' robustness and scalability, assessing whether new\ntools give `better' uncertainty estimates than old ones. These evaluations are\nparamount for practitioners when choosing BDL tools on-top of which they build\ntheir applications. Current popular evaluations of BDL methods, such as the UCI\nexperiments, are lacking: Methods that excel with these experiments often fail\nwhen used in application such as medical or automotive, suggesting a pertinent\nneed for new benchmarks in the field. We propose a new BDL benchmark with a\ndiverse set of tasks, inspired by a real-world medical imaging application on\n\\emph{diabetic retinopathy diagnosis}. Visual inputs (512x512 RGB images of\nretinas) are considered, where model uncertainty is used for medical\npre-screening---i.e. to refer patients to an expert when model diagnosis is\nuncertain. Methods are then ranked according to metrics derived from\nexpert-domain to reflect real-world use of model uncertainty in automated\ndiagnosis. We develop multiple tasks that fall under this application,\nincluding out-of-distribution detection and robustness to distribution shift.\nWe then perform a systematic comparison of well-tuned BDL techniques on the\nvarious tasks. From our comparison we conclude that some current techniques\nwhich solve benchmarks such as UCI `overfit' their uncertainty to the\ndataset---when evaluated on our benchmark these underperform in comparison to\nsimpler baselines. The code for the benchmark, its baselines, and a simple API\nfor evaluating new BDL tools are made available at\nhttps://github.com/oatml/bdl-benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:17:14 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Filos", "Angelos", ""], ["Farquhar", "Sebastian", ""], ["Gomez", "Aidan N.", ""], ["Rudner", "Tim G. J.", ""], ["Kenton", "Zachary", ""], ["Smith", "Lewis", ""], ["Alizadeh", "Milad", ""], ["de Kroon", "Arnoud", ""], ["Gal", "Yarin", ""]]}, {"id": "1912.10485", "submitter": "Morteza Hashemi", "authors": "Navid Naderializadeh, Morteza Hashemi", "title": "Energy-Aware Multi-Server Mobile Edge Computing: A Deep Reinforcement\n  Learning Approach", "comments": "Presented at the 2019 Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of computation offloading in a mobile edge\ncomputing architecture, where multiple energy-constrained users compete to\noffload their computational tasks to multiple servers through a shared wireless\nmedium. We propose a multi-agent deep reinforcement learning algorithm, where\neach server is equipped with an agent, observing the status of its associated\nusers and selecting the best user for offloading at each step. We consider\ncomputation time (i.e., task completion time) and system lifetime as two key\nperformance indicators, and we numerically demonstrate that our approach\noutperforms baseline algorithms in terms of the trade-off between computation\ntime and system lifetime.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:19:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Hashemi", "Morteza", ""]]}, {"id": "1912.10489", "submitter": "Tai Sing Lee", "authors": "Siming Yan, Xuyang Fang, Bowen Xiao, Harold Rockwell, Yimeng Zhang,\n  Tai Sing Lee", "title": "Recurrent Feedback Improves Feedforward Representations in Deep Neural\n  Networks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundant recurrent horizontal and feedback connections in the primate\nvisual cortex are thought to play an important role in bringing global and\nsemantic contextual information to early visual areas during perceptual\ninference, helping to resolve local ambiguity and fill in missing details. In\nthis study, we find that introducing feedback loops and horizontal recurrent\nconnections to a deep convolution neural network (VGG16) allows the network to\nbecome more robust against noise and occlusion during inference, even in the\ninitial feedforward pass. This suggests that recurrent feedback and contextual\nmodulation transform the feedforward representations of the network in a\nmeaningful and interesting way. We study the population codes of neurons in the\nnetwork, before and after learning with feedback, and find that learning with\nfeedback yielded an increase in discriminability (measured by d-prime) between\nthe different object classes in the population codes of the neurons in the\nfeedforward path, even at the earliest layer that receives feedback. We find\nthat recurrent feedback, by injecting top-down semantic meaning to the\npopulation activities, helps the network learn better feedforward paths to\nrobustly map noisy image patches to the latent representations corresponding to\nimportant visual concepts of each object class, resulting in greater robustness\nof the network against noises and occlusion as well as better fine-grained\nrecognition.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:40:19 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yan", "Siming", ""], ["Fang", "Xuyang", ""], ["Xiao", "Bowen", ""], ["Rockwell", "Harold", ""], ["Zhang", "Yimeng", ""], ["Lee", "Tai Sing", ""]]}, {"id": "1912.10490", "submitter": "Athanasios Davvetas", "authors": "Athanasios Davvetas and Iraklis A. Klampanos", "title": "Learning Improved Representations by Transferring Incomplete Evidence\n  Across Heterogeneous Tasks", "comments": "8 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring ground truth labels for unlabelled data can be a costly procedure,\nsince it often requires manual labour that is error-prone. Consequently, the\navailable amount of labelled data is increasingly reduced due to the\nlimitations of manual data labelling. It is possible to increase the amount of\nlabelled data samples by performing automated labelling or crowd-sourcing the\nannotation procedure. However, they often introduce noise or uncertainty in the\nlabelset, that leads to decreased performance of supervised deep learning\nmethods. On the other hand, weak supervision methods remain robust during noisy\nlabelsets or can be effective even with low amounts of labelled data. In this\npaper we evaluate the effectiveness of a representation learning method that\nuses external categorical evidence called \"Evidence Transfer\", against low\namount of corresponding evidence termed as incomplete evidence. Evidence\ntransfer is a robust solution against external unknown categorical evidence\nthat can introduce noise or uncertainty. In our experimental evaluation,\nevidence transfer proves to be effective and robust against different levels of\nincompleteness, for two types of incomplete evidence.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:44:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Davvetas", "Athanasios", ""], ["Klampanos", "Iraklis A.", ""]]}, {"id": "1912.10503", "submitter": "Jennifer Steeden Dr", "authors": "Jennifer A. Steeden, Michael Quail, Alexander Gotschy, Andreas\n  Hauptmann, Simon Arridge, Rodney Jones, Vivek Muthurangu", "title": "Rapid Whole-Heart CMR with Single Volume Super-resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Three-dimensional, whole heart, balanced steady state free\nprecession (WH-bSSFP) sequences provide delineation of intra-cardiac and\nvascular anatomy. However, they have long acquisition times. Here, we propose\nsignificant speed ups using a deep learning single volume super resolution\nreconstruction, to recover high resolution features from rapidly acquired low\nresolution WH-bSSFP images. Methods: A 3D residual U-Net was trained using\nsynthetic data, created from a library of high-resolution WH-bSSFP images by\nsimulating 0.5 slice resolution and 0.5 phase resolution. The trained network\nwas validated with synthetic test data, as well as prospective low-resolution\ndata. Results: Synthetic low-resolution data had significantly better image\nquality after super-resolution reconstruction. Qualitative image scores showed\nsuper-resolved images had better edge sharpness, fewer residual artefacts and\nless image distortion than low-resolution images, with similar scores to\nhigh-resolution data. Quantitative image scores showed super-resolved images\nhad significantly better edge sharpness than low-resolution or high-resolution\nimages, with significantly better signal-to-noise ratio than high-resolution\ndata. Vessel diameters measurements showed over-estimation in the\nlow-resolution measurements, compared to the high-resolution data. No\nsignificant differences and no bias was found in the super-resolution\nmeasurements. Conclusion: This paper demonstrates the potential of using a\nresidual U-Net for super-resolution reconstruction of rapidly acquired\nlow-resolution whole heart bSSFP data within a clinical setting. The resulting\nnetwork can be applied very quickly, making these techniques particularly\nappealing within busy clinical workflow. Thus, we believe that this technique\nmay help speed up whole heart CMR in clinical practice.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 18:36:18 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Steeden", "Jennifer A.", ""], ["Quail", "Michael", ""], ["Gotschy", "Alexander", ""], ["Hauptmann", "Andreas", ""], ["Arridge", "Simon", ""], ["Jones", "Rodney", ""], ["Muthurangu", "Vivek", ""]]}, {"id": "1912.10514", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci and Aliyu Garba", "title": "Tag-less Back-Translation", "comments": "29 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An effective method to generate a large number of parallel sentences for\ntraining improved neural machine translation (NMT) systems is the use of the\nback-translations of the target-side monolingual data. The standard\nback-translation method has been shown to be unable to efficiently utilize the\navailable huge amount of existing monolingual data because of the inability of\ntranslation models to differentiate between the authentic and synthetic\nparallel data during training. Tagging, or using gates, has been used to enable\ntranslation models to distinguish between synthetic and authentic data,\nimproving standard back-translation and also enabling the use of iterative\nback-translation on language pairs that underperformed using standard\nback-translation. In this work, we approach back-translation as a domain\nadaptation problem, eliminating the need for explicit tagging. In the approach\n-- \\emph{tag-less back-translation} -- the synthetic and authentic parallel\ndata are treated as out-of-domain and in-domain data respectively and, through\npre-training and fine-tuning, the translation model is shown to be able to\nlearn more efficiently from them during training. Experimental results have\nshown that the approach outperforms the standard and tagged back-translation\napproaches on low resource English-Vietnamese and English-German neural machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 19:20:10 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 09:07:53 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 15:53:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Garba", "Aliyu", ""]]}, {"id": "1912.10528", "submitter": "Stanis{\\l}aw Saganowski", "authors": "Stanis{\\l}aw Saganowski, Anna Dutkowiak, Adam Dziadek, Maciej\n  Dzie\\.zyc, Joanna Komoszy\\'nska, Weronika Michalska, Adam Polak, Micha{\\l}\n  Ujma, Przemys{\\l}aw Kazienko", "title": "Emotion Recognition Using Wearables: A Systematic Literature Review Work\n  in progress", "comments": "6 pages, accepted to the Emotion Aware 2020 workshop. Copyright 2019\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearables like smartwatches or wrist bands equipped with pervasive sensors\nenable us to monitor our physiological signals. In this study, we address the\nquestion whether they can help us to recognize our emotions in our everyday\nlife for ubiquitous computing. Using the systematic literature review, we\nidentified crucial research steps and discussed the main limitations and\nproblems in the domain.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 20:37:30 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 11:22:52 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Saganowski", "Stanis\u0142aw", ""], ["Dutkowiak", "Anna", ""], ["Dziadek", "Adam", ""], ["Dzie\u017cyc", "Maciej", ""], ["Komoszy\u0144ska", "Joanna", ""], ["Michalska", "Weronika", ""], ["Polak", "Adam", ""], ["Ujma", "Micha\u0142", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1912.10536", "submitter": "Ruocheng Guo", "authors": "Ruocheng Guo and Jundong Li and Huan Liu", "title": "Counterfactual Evaluation of Treatment Assignment Functions with\n  Networked Observational Data", "comments": "10 pages, 5 figures, Accepted to SDM'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual evaluation of novel treatment assignment functions (e.g.,\nadvertising algorithms and recommender systems) is one of the most crucial\ncausal inference problems for practitioners. Traditionally, randomized\ncontrolled trials (A/B tests) are performed to evaluate treatment assignment\nfunctions. However, such trials can be time-consuming, expensive, and even\nunethical in some cases. Therefore, offline counterfactual evaluation of\ntreatment assignment functions becomes a pressing issue because a massive\namount of observational data is available in today's big data era.\nCounterfactual evaluation requires handling the hidden confounders -- the\nunmeasured features which causally influence both the treatment assignment and\nthe outcome. To deal with the hidden confounders, most of the existing methods\nrely on the assumption of no hidden confounders. However, this assumption can\nbe untenable in the context of massive observational data. When such data comes\nwith network information, the later can be potentially useful to correct hidden\nconfounding bias. As such, we first formulate a novel problem, counterfactual\nevaluation of treatment assignment functions with networked observational data.\nThen, we investigate the following research questions: How can we utilize\nnetwork information in counterfactual evaluation? Can network information\nimprove the estimates in counterfactual evaluation? Toward answering these\nquestions, first, we propose a novel framework, \\emph{Counterfactual Network\nEvaluator} (CONE), which (1) learns partial representations of latent\nconfounders under the supervision of observed treatments and outcomes; and (2)\ncombines them for counterfactual evaluation. Then through extensive\nexperiments, we corroborate the effectiveness of CONE. The results imply that\nincorporating network information mitigates hidden confounding bias in\ncounterfactual evaluation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 21:13:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Guo", "Ruocheng", ""], ["Li", "Jundong", ""], ["Liu", "Huan", ""]]}, {"id": "1912.10546", "submitter": "Jincheng Sun", "authors": "T. Chen, J. Sun, H. Lin, Y. Liu", "title": "Hybrid Machine Learning Models of Classifying Residential Requests for\n  Smart Dispatching", "comments": "22 pages, Cyberspace Data and Intelligence, and Cyber-Living,\n  Syndrome, and Health. Springer, Singapore, 2019. 357-378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hybrid machine learning method of classifying\nresidential requests in natural language to responsible departments that\nprovide timely responses back to residents under the vision of digital\ngovernment services in smart cities. Residential requests in natural language\ndescriptions cover almost every aspect of a city's daily operation. Hence the\nresponsible departments are fine-grained to even the level of local\ncommunities. There are no specific general categories or labels for each\nrequest sample. This causes two issues for supervised classification solutions,\nnamely (1) the request sample data is unbalanced and (2) lack of specific\nlabels for training. To solve these issues, we investigate a hybrid machine\nlearning method that generates meta-class labels by means of unsupervised\nclustering algorithms; applies two-word embedding methods with three\nclassifiers (including two hierarchical classifiers and one residual\nconvolutional neural network); and selects the best performing classifier as\nthe classification result. We demonstrate our approach performing better\nclassification tasks compared to two benchmarking machine learning models,\nNaive Bayes classifier and a Multiple Layer Perceptron (MLP). In addition, the\nhierarchical classification method provides insights into the source of\nclassification errors.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 21:47:05 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chen", "T.", ""], ["Sun", "J.", ""], ["Lin", "H.", ""], ["Liu", "Y.", ""]]}, {"id": "1912.10552", "submitter": "Anahita Hosseini", "authors": "Anahita Hosseini, Tyler Davis, Majid Sarrafzadeh", "title": "Hierarchical Target-Attentive Diagnosis Prediction in Heterogeneous\n  Information Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce HTAD, a novel model for diagnosis prediction using Electronic\nHealth Records (EHR) represented as Heterogeneous Information Networks. Recent\nstudies on modeling EHR have shown success in automatically learning\nrepresentations of the clinical records in order to avoid the need for manual\nfeature selection. However, these representations are often learned and\naggregated without specificity for the different possible targets being\npredicted. Our model introduces a target-aware hierarchical attention mechanism\nthat allows it to learn to attend to the most important clinical records when\naggregating their representations for prediction of a diagnosis.\n  We evaluate our model using a publicly available benchmark dataset and\ndemonstrate that the use of target-aware attention significantly improves\nperformance compared to the current state of the art. Additionally, we propose\na method for incorporating non-categorical data into our predictions and\ndemonstrate that this technique leads to further performance improvements.\nLastly, we demonstrate that the predictions made by our proposed model are\neasily interpretable.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 22:22:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hosseini", "Anahita", ""], ["Davis", "Tyler", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1912.10557", "submitter": "Yuelong Li", "authors": "Vishal Monga, Yuelong Li and Yonina C. Eldar", "title": "Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal\n  and Image Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks provide unprecedented performance gains in many real\nworld problems in signal and image processing. Despite these gains, future\ndevelopment and practical deployment of deep networks is hindered by their\nblackbox nature, i.e., lack of interpretability, and by the need for very large\ntraining sets. An emerging technique called algorithm unrolling or unfolding\noffers promise in eliminating these issues by providing a concrete and\nsystematic connection between iterative algorithms that are used widely in\nsignal processing and deep neural networks. Unrolling methods were first\nproposed to develop fast neural network approximations for sparse coding. More\nrecently, this direction has attracted enormous attention and is rapidly\ngrowing both in theoretic investigations and practical applications. The\ngrowing popularity of unrolled deep networks is due in part to their potential\nin developing efficient, high-performance and yet interpretable network\narchitectures from reasonable size training sets. In this article, we review\nalgorithm unrolling for signal and image processing. We extensively cover\npopular techniques for algorithm unrolling in various domains of signal and\nimage processing including imaging, vision and recognition, and speech\nprocessing. By reviewing previous works, we reveal the connections between\niterative algorithms and neural networks and present recent theoretical\nresults. Finally, we provide a discussion on current limitations of unrolling\nand suggest possible future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 23:02:18 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:26:41 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 05:37:40 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Monga", "Vishal", ""], ["Li", "Yuelong", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1912.10558", "submitter": "Renuka Sindhgatta", "authors": "Renuka Sindhgatta, Chun Ouyang, Catarina Moreira", "title": "Exploring Interpretability for Predictive Process Analytics", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern predictive analytics underpinned by machine learning techniques has\nbecome a key enabler to the automation of data-driven decision making. In the\ncontext of business process management, predictive analytics has been applied\nto making predictions about the future state of an ongoing business process\ninstance, for example, when will the process instance complete and what will be\nthe outcome upon completion. Machine learning models can be trained on event\nlog data recording historical process execution to build the underlying\npredictive models. Multiple techniques have been proposed so far which encode\nthe information available in an event log and construct input features required\nto train a predictive model. While accuracy has been a dominant criterion in\nthe choice of various techniques, they are often applied as a black-box in\nbuilding predictive models. In this paper, we derive explanations using\ninterpretable machine learning techniques to compare and contrast the\nsuitability of multiple predictive models of high accuracy. The explanations\nallow us to gain an understanding of the underlying reasons for a prediction\nand highlight scenarios where accuracy alone may not be sufficient in assessing\nthe suitability of techniques used to encode event log data to features used by\na predictive model. Findings from this study motivate the need and importance\nto incorporate interpretability in predictive process analytics.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 23:09:34 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 10:42:45 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 12:09:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Sindhgatta", "Renuka", ""], ["Ouyang", "Chun", ""], ["Moreira", "Catarina", ""]]}, {"id": "1912.10559", "submitter": "Drimik Roy Chowdhury", "authors": "Drimik Roy Chowdhury, Muhammad Firmansyah Kasim", "title": "Efficient Parameter Sampling for Neural Network Construction", "comments": "Accepted for NeurIPS 2019: Machine Learning and the Physical Sciences\n  conference. Paper archived here: https://ml4physicalsciences.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG hep-ex physics.comp-ph physics.plasm-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The customizable nature of deep learning models have allowed them to be\nsuccessful predictors in various disciplines. These models are often trained\nwith respect to thousands or millions of instances for complicated problems,\nbut the gathering of such an immense collection may be infeasible and\nexpensive. However, what often occurs is the pollution of redundant information\nfrom these instances to the deep learning models. This paper outlines an\nalgorithm that dynamically selects and appends instances to a training dataset\nfrom uncertain regions of the parameter space based on differences in\npredictions from multiple convolutional neural networks (CNNs). These CNNs are\nalso simultaneously trained on this growing dataset to construct more accurate\nand knowledgable models. The methodology presented has reduced training dataset\nsizes by almost 90% and maintained predictive power in two diagnostics of high\nenergy density physics.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 23:13:50 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chowdhury", "Drimik Roy", ""], ["Kasim", "Muhammad Firmansyah", ""]]}, {"id": "1912.10564", "submitter": "Julia Stoyanovich", "authors": "Julia Stoyanovich and Armanda Lewis", "title": "Teaching Responsible Data Science: Charting New Pedagogical Territory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although numerous ethics courses are available, with many focusing\nspecifically on technology and computer ethics, pedagogical approaches employed\nin these courses rely exclusively on texts rather than on software development\nor data analysis. Technical students often consider these courses unimportant\nand a distraction from the \"real\" material. To develop instructional materials\nand methodologies that are thoughtful and engaging, we must strive for balance:\nbetween texts and coding, between critique and solution, and between\ncutting-edge research and practical applicability. Finding such balance is\nparticularly difficult in the nascent field of responsible data science (RDS),\nwhere we are only starting to understand how to interface between the\nintrinsically different methodologies of engineering and social sciences. In\nthis paper we recount a recent experience in developing and teaching an RDS\ncourse to graduate and advanced undergraduate students in data science. We then\ndive into an area that is critically important to RDS -- transparency and\ninterpretability of machine-assisted decision-making, and tie this area to the\nneeds of emerging RDS curricula. Recounting our own experience, and leveraging\nliterature on pedagogical methods in data science and beyond, we propose the\nnotion of an \"object-to-interpret-with\". We link this notion to \"nutritional\nlabels\" -- a family of interpretability tools that are gaining popularity in\nRDS research and practice. With this work we aim to contribute to the nascent\narea of RDS education, and to inspire others in the community to come together\nto develop a deeper theoretical understanding of the pedagogical needs of RDS,\nand contribute concrete educational materials and methodologies that others can\nuse. All course materials are publicly available at\nhttps://dataresponsibly.github.io/courses.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:10:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Stoyanovich", "Julia", ""], ["Lewis", "Armanda", ""]]}, {"id": "1912.10577", "submitter": "Zhihan Xiong", "authors": "Tian Tan, Zhihan Xiong, Vikranth R. Dwaracherla", "title": "Parameterized Indexed Value Function for Efficient Exploration in\n  Reinforcement Learning", "comments": "17 pages, 4 figures, Proceedings of the 34th AAAI Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that quantifying uncertainty in the action-value estimates\nis crucial for efficient exploration in reinforcement learning. Ensemble\nsampling offers a relatively computationally tractable way of doing this using\nrandomized value functions. However, it still requires a huge amount of\ncomputational resources for complex problems. In this paper, we present an\nalternative, computationally efficient way to induce exploration using index\nsampling. We use an indexed value function to represent uncertainty in our\naction-value estimates. We first present an algorithm to learn parameterized\nindexed value function through a distributional version of temporal difference\nin a tabular setting and prove its regret bound. Then, in a computational point\nof view, we propose a dual-network architecture, Parameterized Indexed Networks\n(PINs), comprising one mean network and one uncertainty network to learn the\nindexed value function. Finally, we show the efficacy of PINs through\ncomputational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 01:28:53 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 18:33:52 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Tan", "Tian", ""], ["Xiong", "Zhihan", ""], ["Dwaracherla", "Vikranth R.", ""]]}, {"id": "1912.10583", "submitter": "Thinh Thanh Doan", "authors": "Thinh T. Doan", "title": "Finite-Time Analysis and Restarting Scheme for Linear Two-Time-Scale\n  Stochastic Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by their broad applications in reinforcement learning, we study the\nlinear two-time-scale stochastic approximation, an iterative method using two\ndifferent step sizes for finding the solutions of a system of two equations.\nOur main focus is to characterize the finite-time complexity of this method\nunder time-varying step sizes and Markovian noise. In particular, we show that\nthe mean square errors of the variables generated by the method converge to\nzero at a sublinear rate $\\Ocal(k^{2/3})$, where $k$ is the number of\niterations. We then improve the performance of this method by considering the\nrestarting scheme, where we restart the algorithm after every predetermined\nnumber of iterations. We show that using this restarting method the complexity\nof the algorithm under time-varying step sizes is as good as the one using\nconstant step sizes, but still achieving an exact converge to the desired\nsolution. Moreover, the restarting scheme also helps to prevent the step sizes\nfrom getting too small, which is useful for the practical implementation of the\nlinear two-time-scale stochastic approximation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 02:00:55 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 20:06:59 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Doan", "Thinh T.", ""]]}, {"id": "1912.10597", "submitter": "Pedro Sandoval Segura", "authors": "Pedro Sandoval Segura, Julius Lauw, Daniel Bashir, Kinjal Shah, Sonia\n  Sehra, Dominique Macias, and George Montanez", "title": "The Labeling Distribution Matrix (LDM): A Tool for Estimating Machine\n  Learning Algorithm Capacity", "comments": "Accepted to 12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020), 7 pages including references", "journal-ref": null, "doi": "10.5220/0009178209800986", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm performance in supervised learning is a combination of\nmemorization, generalization, and luck. By estimating how much information an\nalgorithm can memorize from a dataset, we can set a lower bound on the amount\nof performance due to other factors such as generalization and luck. With this\ngoal in mind, we introduce the Labeling Distribution Matrix (LDM) as a tool for\nestimating the capacity of learning algorithms. The method attempts to\ncharacterize the diversity of possible outputs by an algorithm for different\ntraining datasets, using this to measure algorithm flexibility and\nresponsiveness to data. We test the method on several supervised learning\nalgorithms, and find that while the results are not conclusive, the LDM does\nallow us to gain potentially valuable insight into the prediction behavior of\nalgorithms. We also introduce the Label Recorder as an additional tool for\nestimating algorithm capacity, with more promising initial results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:07:00 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 02:35:08 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Segura", "Pedro Sandoval", ""], ["Lauw", "Julius", ""], ["Bashir", "Daniel", ""], ["Shah", "Kinjal", ""], ["Sehra", "Sonia", ""], ["Macias", "Dominique", ""], ["Montanez", "George", ""]]}, {"id": "1912.10598", "submitter": "Farbod Taymouri", "authors": "Farbod Taymouri, Marcello La Rosa, Josep Carmona", "title": "Business Process Variant Analysis based on Mutual Fingerprints of Event\n  Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing business process variants using event logs is a common use case in\nprocess mining. Existing techniques for process variant analysis detect\nstatistically-significant differences between variants at the level of\nindividual entities (such as process activities) and their relationships (e.g.\ndirectly-follows relations between activities). This may lead to a\nproliferation of differences due to the low level of granularity in which such\ndifferences are captured. This paper presents a novel approach to detect\nstatistically-significant differences between variants at the level of entire\nprocess traces (i.e. sequences of directly-follows relations). The cornerstone\nof this approach is a technique to learn a directly follows graph called mutual\nfingerprint from the event logs of the two variants. A mutual fingerprint is a\nlossless encoding of a set of traces and their duration using discrete wavelet\ntransformation. This structure facilitates the understanding of statistical\ndifferences along the control-flow and performance dimensions. The approach has\nbeen evaluated using real-life event logs against two baselines. The results\nshow that at a trace level, the baselines cannot always reveal the differences\ndiscovered by our approach, or can detect spurious differences.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:13:52 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 08:55:24 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Taymouri", "Farbod", ""], ["La Rosa", "Marcello", ""], ["Carmona", "Josep", ""]]}, {"id": "1912.10600", "submitter": "Yang Guan", "authors": "Yang Guan, Shengbo Eben Li, Jingliang Duan, Jie Li, Yangang Ren, Qi\n  Sun, Bo Cheng", "title": "Direct and indirect reinforcement learning", "comments": "Published in International Journal of Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have been successfully applied to a\nrange of challenging sequential decision making and control tasks. In this\npaper, we classify RL into direct and indirect RL according to how they seek\nthe optimal policy of the Markov decision process problem. The former solves\nthe optimal policy by directly maximizing an objective function using gradient\ndescent methods, in which the objective function is usually the expectation of\naccumulative future rewards. The latter indirectly finds the optimal policy by\nsolving the Bellman equation, which is the sufficient and necessary condition\nfrom Bellman's principle of optimality. We study policy gradient forms of\ndirect and indirect RL and show that both of them can derive the actor-critic\narchitecture and can be unified into a policy gradient with the approximate\nvalue function and the stationary state distribution, revealing the equivalence\nof direct and indirect RL. We employ a Gridworld task to verify the influence\nof different forms of policy gradient, suggesting their differences and\nrelationships experimentally. Finally, we classify current mainstream RL\nalgorithms using the direct and indirect taxonomy, together with other ones\nincluding value-based and policy-based, model-based and model-free.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 03:20:42 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:14:44 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Duan", "Jingliang", ""], ["Li", "Jie", ""], ["Ren", "Yangang", ""], ["Sun", "Qi", ""], ["Cheng", "Bo", ""]]}, {"id": "1912.10636", "submitter": "Takashi Goda", "authors": "Takashi Goda, Kei Ishikawa", "title": "Multilevel Monte Carlo estimation of log marginal likelihood", "comments": "4 pages, no figure, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we provide an unbiased multilevel Monte Carlo estimator of\nthe log marginal likelihood and discuss its application to variational Bayes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 05:44:32 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Goda", "Takashi", ""], ["Ishikawa", "Kei", ""]]}, {"id": "1912.10648", "submitter": "Xiaobai Ma Mr.", "authors": "Xiaobai Ma, Katherine Driggs-Campbell, Zongzhang Zhang, Mykel J.\n  Kochenderfer", "title": "Monte-Carlo Tree Search for Policy Optimization", "comments": "IJCAI 2019", "journal-ref": "In Proceedings of the 28th International Joint Conference on\n  Artificial Intelligence, pp. 3116-3122. AAAI Press, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient-based methods are often used for policy optimization in deep\nreinforcement learning, despite being vulnerable to local optima and saddle\npoints. Although gradient-free methods (e.g., genetic algorithms or evolution\nstrategies) help mitigate these issues, poor initialization and local optima\nare still concerns in highly nonconvex spaces. This paper presents a method for\npolicy optimization based on Monte-Carlo tree search and gradient-free\noptimization. Our method, called Monte-Carlo tree search for policy\noptimization (MCTSPO), provides a better exploration-exploitation trade-off\nthrough the use of the upper confidence bound heuristic. We demonstrate\nimproved performance on reinforcement learning tasks with deceptive or sparse\nreward functions compared to popular gradient-based and deep genetic algorithm\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:04:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ma", "Xiaobai", ""], ["Driggs-Campbell", "Katherine", ""], ["Zhang", "Zongzhang", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1912.10657", "submitter": "He-Feng Yin", "authors": "Xing Liu, Xiao-Jun Wu, Zhen Liu, He-Feng Yin", "title": "A Compared Study Between Some Subspace Based Algorithms", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technology of face recognition has made some progress in recent years.\nAfter studying the PCA, 2DPCA, R1-PCA, L1-PCA, KPCA and KECA algorithms, in\nthis paper ECA (2DECA) is proposed by extracting features in PCA (2DPCA) based\non Renyi entropy contribution. And then we conduct a study on the 2DL1-PCA and\n2DR1-PCA algorithms. On the basis of the experiments, this paper compares the\ndifference of the recognition accuracy and operational efficiency between the\nabove algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:40:51 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Liu", "Xing", ""], ["Wu", "Xiao-Jun", ""], ["Liu", "Zhen", ""], ["Yin", "He-Feng", ""]]}, {"id": "1912.10697", "submitter": "Insoon Yang", "authors": "Jeongho Kim, Insoon Yang", "title": "Hamilton-Jacobi-Bellman Equations for Q-Learning in Continuous Time", "comments": "2nd Annual Conference on Learning for Dynamics and Control (L4DC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Hamilton-Jacobi-Bellman (HJB) equations for\nQ-functions in continuous time optimal control problems with Lipschitz\ncontinuous controls. The standard Q-function used in reinforcement learning is\nshown to be the unique viscosity solution of the HJB equation. A necessary and\nsufficient condition for optimality is provided using the viscosity solution\nframework. By using the HJB equation, we develop a Q-learning method for\ncontinuous-time dynamical systems. A DQN-like algorithm is also proposed for\nhigh-dimensional state and control spaces. The performance of the proposed\nQ-learning algorithm is demonstrated using 1-, 10- and 20-dimensional dynamical\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 09:26:13 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 04:27:23 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kim", "Jeongho", ""], ["Yang", "Insoon", ""]]}, {"id": "1912.10702", "submitter": "Bin Dai", "authors": "Bin Dai, Ziyu Wang, David Wipf", "title": "The Usual Suspects? Reassessing Blame for VAE Posterior Collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In narrow asymptotic settings Gaussian VAE models of continuous data have\nbeen shown to possess global optima aligned with ground-truth distributions.\nEven so, it is well known that poor solutions whereby the latent posterior\ncollapses to an uninformative prior are sometimes obtained in practice.\nHowever, contrary to conventional wisdom that largely assigns blame for this\nphenomena on the undue influence of KL-divergence regularization, we will argue\nthat posterior collapse is, at least in part, a direct consequence of bad local\nminima inherent to the loss surface of deep autoencoder networks. In\nparticular, we prove that even small nonlinear perturbations of affine VAE\ndecoder models can produce such minima, and in deeper models, analogous minima\ncan force the VAE to behave like an aggressive truncation operator, provably\ndiscarding information along all latent dimensions in certain circumstances.\nRegardless, the underlying message here is not meant to undercut valuable\nexisting explanations of posterior collapse, but rather, to refine the\ndiscussion and elucidate alternative risk factors that may have been previously\nunderappreciated.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 09:40:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dai", "Bin", ""], ["Wang", "Ziyu", ""], ["Wipf", "David", ""]]}, {"id": "1912.10703", "submitter": "Dongqi Han", "authors": "Dongqi Han, Kenji Doya, Jun Tani", "title": "Variational Recurrent Models for Solving Partially Observable Control\n  Tasks", "comments": "Published as a conference paper at the Eighth International\n  Conference on Learning Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In partially observable (PO) environments, deep reinforcement learning (RL)\nagents often suffer from unsatisfactory performance, since two problems need to\nbe tackled together: how to extract information from the raw observations to\nsolve the task, and how to improve the policy. In this study, we propose an RL\nalgorithm for solving PO tasks. Our method comprises two parts: a variational\nrecurrent model (VRM) for modeling the environment, and an RL controller that\nhas access to both the environment and the VRM. The proposed algorithm was\ntested in two types of PO robotic control tasks, those in which either\ncoordinates or velocities were not observable and those that require long-term\nmemorization. Our experiments show that the proposed algorithm achieved better\ndata efficiency and/or learned more optimal policy than other alternative\napproaches in tasks in which unobserved states cannot be inferred from raw\nobservations in a simple manner.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 09:43:16 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 05:05:00 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Han", "Dongqi", ""], ["Doya", "Kenji", ""], ["Tani", "Jun", ""]]}, {"id": "1912.10708", "submitter": "Minoru Kusaba", "authors": "Minoru Kusaba, Chang Liu, Yukinori Koyama, Kiyoyuki Terakura, Ryo\n  Yoshida", "title": "Recreation of the Periodic Table with an Unsupervised Machine Learning\n  Algorithm", "comments": "28 pages, 14 figures, complete version of this paper is available at\n  https://www.nature.com/articles/s41598-021-81850-z (Published: 26 February\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1869, the first draft of the periodic table was published by Russian\nchemist Dmitri Mendeleev. In terms of data science, his achievement can be\nviewed as a successful example of feature embedding based on human cognition:\nchemical properties of all known elements at that time were compressed onto the\ntwo-dimensional grid system for tabular display. In this study, we seek to\nanswer the question of whether machine learning can reproduce or recreate the\nperiodic table by using observed physicochemical properties of the elements. To\nachieve this goal, we developed a periodic table generator (PTG). The PTG is an\nunsupervised machine learning algorithm based on the generative topographic\nmapping (GTM), which can automate the translation of high-dimensional data into\na tabular form with varying layouts on-demand. The PTG autonomously produced\nvarious arrangements of chemical symbols, which organized a two-dimensional\narray such as Mendeleev's periodic table or three-dimensional spiral table\naccording to the underlying periodicity in the given data. We further showed\nwhat the PTG learned from the element data and how the element features, such\nas melting point and electronegativity, are compressed to the lower-dimensional\nlatent spaces.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 10:01:51 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 21:24:40 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kusaba", "Minoru", ""], ["Liu", "Chang", ""], ["Koyama", "Yukinori", ""], ["Terakura", "Kiyoyuki", ""], ["Yoshida", "Ryo", ""]]}, {"id": "1912.10729", "submitter": "Yujing Wang", "authors": "Yujing Wang, Yaming Yang, Yiren Chen, Jing Bai, Ce Zhang, Guinan Su,\n  Xiaoyu Kou, Yunhai Tong, Mao Yang, Lidong Zhou", "title": "TextNAS: A Neural Architecture Search Space tailored for Text\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning text representation is crucial for text classification and other\nlanguage related tasks. There are a diverse set of text representation networks\nin the literature, and how to find the optimal one is a non-trivial problem.\nRecently, the emerging Neural Architecture Search (NAS) techniques have\ndemonstrated good potential to solve the problem. Nevertheless, most of the\nexisting works of NAS focus on the search algorithms and pay little attention\nto the search space. In this paper, we argue that the search space is also an\nimportant human prior to the success of NAS in different applications. Thus, we\npropose a novel search space tailored for text representation. Through\nautomatic search, the discovered network architecture outperforms\nstate-of-the-art models on various public datasets on text classification and\nnatural language inference tasks. Furthermore, some of the design principles\nfound in the automatic network agree well with human intuition.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 10:51:58 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Wang", "Yujing", ""], ["Yang", "Yaming", ""], ["Chen", "Yiren", ""], ["Bai", "Jing", ""], ["Zhang", "Ce", ""], ["Su", "Guinan", ""], ["Kou", "Xiaoyu", ""], ["Tong", "Yunhai", ""], ["Yang", "Mao", ""], ["Zhou", "Lidong", ""]]}, {"id": "1912.10730", "submitter": "Yingshi Chen", "authors": "Yingshi Chen, Jinfeng Zhu", "title": "An optical diffractive deep neural network with multiple\n  frequency-channels", "comments": "5 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffractive deep neural network (DNNet) is a novel machine learning framework\non the modulation of optical transmission. Diffractive network would get\npredictions at the speed of light. It's pure passive architecture, no\nadditional power consumption. We improved the accuracy of diffractive network\nwith optical waves at different frequency. Each layers have multiple\nfrequency-channels (optical distributions at different frequency). These\nchannels are merged at the output plane to get final output. The experiment in\nthe fasion-MNIST and EMNIST datasets showed multiple frequency-channels would\nincrease the accuracy a lot. We also give detailed analysis to show the\ndifference between DNNet and MLP. The modulation process in DNNet is actually\noptical activation function. We develop an open source package ONNet. The\nsource codes are available at https://github.com/closest-git/ONNet.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 10:54:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Chen", "Yingshi", ""], ["Zhu", "Jinfeng", ""]]}, {"id": "1912.10746", "submitter": "Hassan Eldeeb Dr.", "authors": "Hassan Eldeeb and Abdelrhman Eldallal", "title": "AutoML: Exploration v.s. Exploitation", "comments": "The paper has been rejected by EDBT conference and it needs major\n  enhancements and modifications. Therefore, it is better to be withdrawn until\n  we finish these enhancements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a machine learning (ML) pipeline in an automated way is a crucial\nand complex task as it is constrained with the available time budget and\nresources. This encouraged the research community to introduce several\nsolutions to utilize the available time and resources. A lot of work is done to\nsuggest the most promising classifiers for a given dataset using sundry of\ntechniques including meta-learning based techniques. This gives the autoML\nframework the chance to spend more time exploiting those classifiers and tuning\ntheir hyper-parameters. In this paper, we empirically study the hypothesis of\nimproving the pipeline performance by exploiting the most promising classifiers\nwithin the limited time budget. We also study the effect of increasing the time\nbudget over the pipeline performance. The empirical results across autoSKLearn,\nTPOT and ATM, show that exploiting the most promising classifiers does not\nachieve a statistically better performance than exploring the entire search\nspace. The same conclusion is also applied for long time budgets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 11:41:11 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 23:32:07 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Eldeeb", "Hassan", ""], ["Eldallal", "Abdelrhman", ""]]}, {"id": "1912.10752", "submitter": "Balaji Selvaraj", "authors": "S. Balaji, T. Kavya, Natasha Sebastian", "title": "Learn-able parameter guided Activation Functions", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we explore the concept of adding learn-able slope and mean\nshift parameters to an activation function to improve the total response\nregion. The characteristics of an activation function depend highly on the\nvalue of parameters. Making the parameters learn-able, makes the activation\nfunction more dynamic and capable to adapt as per the requirements of its\nneighboring layers. The introduced slope parameter is independent of other\nparameters in the activation function. The concept was applied to ReLU to\ndevelop Dual Line and DualParametric ReLU activation function. Evaluation on\nMNIST and CIFAR10 show that the proposed activation function Dual Line achieves\ntop-5 position for mean accuracy among 43 activation functions tested with\nLENET4, LENET5, and WideResNet architectures. This is the first time more than\n40 activation functions were analyzed on MNIST andCIFAR10 dataset at the same\ntime. The study on the distribution of positive slope parameter beta indicates\nthat the activation function adapts as per the requirements of the neighboring\nlayers. The study shows that model performance increases with the proposed\nactivation functions\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 11:54:05 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Balaji", "S.", ""], ["Kavya", "T.", ""], ["Sebastian", "Natasha", ""]]}, {"id": "1912.10762", "submitter": "Wen Song", "authors": "Wen Song, Zhiguang Cao, Jie Zhang, Andrew Lim", "title": "Learning Variable Ordering Heuristics for Solving Constraint\n  Satisfaction Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backtracking search algorithms are often used to solve the Constraint\nSatisfaction Problem (CSP). The efficiency of backtracking search depends\ngreatly on the variable ordering heuristics. Currently, the most commonly used\nheuristics are hand-crafted based on expert knowledge. In this paper, we\npropose a deep reinforcement learning based approach to automatically discover\nnew variable ordering heuristics that are better adapted for a given class of\nCSP instances. We show that directly optimizing the search cost is hard for\nbootstrapping, and propose to optimize the expected cost of reaching a leaf\nnode in the search tree. To capture the complex relations among the variables\nand constraints, we design a representation scheme based on Graph Neural\nNetwork that can process CSP instances with different sizes and constraint\narities. Experimental results on random CSP instances show that the learned\npolicies outperform classical hand-crafted heuristics in terms of minimizing\nthe search tree size, and can effectively generalize to instances that are\nlarger than those used in training.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:27:04 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 06:45:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Song", "Wen", ""], ["Cao", "Zhiguang", ""], ["Zhang", "Jie", ""], ["Lim", "Andrew", ""]]}, {"id": "1912.10764", "submitter": "S\\'ebastien Henwood", "authors": "S\\'ebastien Henwood, Fran\\c{c}ois Leduc-Primeau and Yvon Savaria", "title": "Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks", "comments": "To be presented at AICAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) depend on the storage of a large number of\nparameters, which consumes an important portion of the energy used during\ninference. This paper considers the case where the energy usage of memory\nelements can be reduced at the cost of reduced reliability. A training\nalgorithm is proposed to optimize the reliability of the storage separately for\neach layer of the network, while incurring a negligible complexity overhead\ncompared to a conventional stochastic gradient descent training. For an\nexponential energy-reliability model, the proposed training approach can\ndecrease the memory energy consumption of a DNN with binary parameters by\n3.3$\\times$ at isoaccuracy, compared to a reliable implementation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:36:51 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Henwood", "S\u00e9bastien", ""], ["Leduc-Primeau", "Fran\u00e7ois", ""], ["Savaria", "Yvon", ""]]}, {"id": "1912.10773", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Richard Bowden, Yaochu Jin, Phil Barber, Saber Fallah", "title": "A Survey of Deep Learning Applications to Autonomous Vehicle Control", "comments": "23 pages, 3 figures, Accepted in IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a controller for autonomous vehicles capable of providing adequate\nperformance in all driving scenarios is challenging due to the highly complex\nenvironment and inability to test the system in the wide variety of scenarios\nwhich it may encounter after deployment. However, deep learning methods have\nshown great promise in not only providing excellent performance for complex and\nnon-linear control problems, but also in generalising previously learned rules\nto new scenarios. For these reasons, the use of deep learning for vehicle\ncontrol is becoming increasingly popular. Although important advancements have\nbeen achieved in this field, these works have not been fully summarised. This\npaper surveys a wide range of research works reported in the literature which\naim to control a vehicle through deep learning methods. Although there exists\noverlap between control and perception, the focus of this paper is on vehicle\ncontrol, rather than the wider perception problem which includes tasks such as\nsemantic segmentation and object detection. The paper identifies the strengths\nand limitations of available deep learning methods through comparative analysis\nand discusses the research challenges in terms of computation, architecture\nselection, goal specification, generalisation, verification and validation, as\nwell as safety. Overall, this survey brings timely and topical information to a\nrapidly evolving field relevant to intelligent transportation systems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 12:50:32 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kuutti", "Sampo", ""], ["Bowden", "Richard", ""], ["Jin", "Yaochu", ""], ["Barber", "Phil", ""], ["Fallah", "Saber", ""]]}, {"id": "1912.10784", "submitter": "Jaouad Mourtada", "authors": "Jaouad Mourtada, St\\'ephane Ga\\\"iffas", "title": "An improper estimator with optimal excess risk in misspecified density\n  estimation and logistic regression", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a procedure for predictive conditional density estimation under\nlogarithmic loss, which we call SMP (Sample Minmax Predictor). This estimator\nminimizes a new general excess risk bound for supervised statistical learning.\nOn standard examples, this bound scales as $d/n$ with $d$ the model dimension\nand $n$ the sample size, and critically remains valid under model\nmisspecification. Being an improper (out-of-model) procedure, SMP improves over\nwithin-model estimators such as the maximum likelihood estimator, whose excess\nrisk degrades under misspecification. Compared to approaches reducing to the\nsequential problem, our bounds remove suboptimal $\\log n$ factors, addressing\nan open problem from Gr\\\"unwald and Kotlowski for the considered models, and\ncan handle unbounded classes. For the Gaussian linear model, the predictions\nand risk bound of SMP are governed by leverage scores of covariates, nearly\nmatching the optimal risk in the well-specified case without conditions on the\nnoise variance or approximation error of the linear model. For logistic\nregression, SMP provides a non-Bayesian approach to calibration of\nprobabilistic predictions relying on virtual samples, and can be computed by\nsolving two logistic regressions. It achieves a non-asymptotic excess risk of\n$O ( (d + B^2R^2)/n )$, where $R$ bounds the norm of features and $B$ that of\nthe comparison parameter; by contrast, no within-model estimator can achieve\nbetter rate than $\\min( {B R}/{\\sqrt{n}}, {d e^{BR}}/{n} )$ in general. This\nprovides a computationally more efficient alternative to Bayesian approaches,\nwhich require approximate posterior sampling, thereby partly answering a\nquestion by Foster et al. (2018).\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 13:11:54 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 17:04:49 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Mourtada", "Jaouad", ""], ["Ga\u00efffas", "St\u00e9phane", ""]]}, {"id": "1912.10785", "submitter": "Hao Feng", "authors": "Chi Xu, Hao Feng, Guoxin Yu, Min Yang, Xiting Wang, Xiang Ao", "title": "Discovering Protagonist of Sentiment with Aspect Reconstructed Capsule\n  Network", "comments": "7pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent existing aspect-term level sentiment analysis (ATSA) approaches\ncombined various neural network models with delicately carved attention\nmechanisms built upon given aspect and context to generate refined sentence\nrepresentations for better predictions. In these methods, aspect terms are\nalways provided in both training and testing process which may degrade\naspect-level analysis into sentence-level prediction. However, the annotated\naspect term might be unavailable in real-world scenarios which may challenge\nthe applicability of the existing methods. In this paper, we aim to improve\nATSA by discovering the potential aspect terms of the predicted sentiment\npolarity when the aspect terms of a test sentence are unknown. We access this\ngoal by proposing a capsule network based model named CAPSAR. In CAPSAR,\nsentiment categories are denoted by capsules and aspect term information is\ninjected into sentiment capsules through a sentiment-aspect reconstruction\nprocedure during the training. As a result, coherent patterns between aspects\nand sentimental expressions are encapsulated by these sentiment capsules.\nExperiments on three widely used benchmarks demonstrate these patterns have\npotential in exploring aspect terms from test sentence when only feeding the\nsentence to the model. Meanwhile, the proposed CAPSAR can clearly outperform\nSOTA methods in standard ATSA tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 13:14:40 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 01:47:29 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xu", "Chi", ""], ["Feng", "Hao", ""], ["Yu", "Guoxin", ""], ["Yang", "Min", ""], ["Wang", "Xiting", ""], ["Ao", "Xiang", ""]]}, {"id": "1912.10787", "submitter": "Austin Dill", "authors": "Austin Dill, Songwei Ge, Eunsu Kang, Chun-Liang Li, Barnabas Poczos", "title": "Learned Interpolation for 3D Generation", "comments": "Creativity and Design Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to generate novel 3D shapes with machine learning, one must allow\nfor interpolation. The typical approach for incorporating this creative process\nis to interpolate in a learned latent space so as to avoid the problem of\ngenerating unrealistic instances by exploiting the model's learned structure.\nThe process of the interpolation is supposed to form a semantically smooth\nmorphing. While this approach is sound for synthesizing realistic media such as\nlifelike portraits or new designs for everyday objects, it subjectively fails\nto directly model the unexpected, unrealistic, or creative. In this work, we\npresent a method for learning how to interpolate point clouds. By encoding\nprior knowledge about real-world objects, the intermediate forms are both\nrealistic and unlike any existing forms. We show not only how this method can\nbe used to generate \"creative\" point clouds, but how the method can also be\nleveraged to generate 3D models suitable for sculpture.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 23:44:33 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 20:12:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Dill", "Austin", ""], ["Ge", "Songwei", ""], ["Kang", "Eunsu", ""], ["Li", "Chun-Liang", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1912.10798", "submitter": "Kelly Kochanski", "authors": "Kelly Kochanski, Divya Mohan, Jenna Horrall, Barry Rountree, Ghaleb\n  Abdulla", "title": "Deep learning predictions of sand dune migration", "comments": "Workshop on Tackling climate change with machine learning at NeurIPS.\n  Vancouver, Canada, December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dry decade in the Navajo Nation has killed vegetation, dessicated soils,\nand released once-stable sand into the wind. This sand now covers one-third of\nthe Nation's land, threatening roads, gardens and hundreds of homes. Many arid\nregions have similar problems: global warming has increased dune movement\nacross farmland in Namibia and Angola, and the southwestern US. Current dune\nmodels, unfortunately, do not scale well enough to provide useful forecasts for\nthe $\\sim$5\\% of land surfaces covered by mobile sand. We test the ability of\ntwo deep learning algorithms, a GAN and a CNN, to model the motion of sand\ndunes. The models are trained on simulated data from community-standard\ncellular automaton model of sand dunes. Preliminary results show the GAN\nproducing reasonable forward predictions of dune migration at ten million times\nthe speed of the existing model.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 01:17:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Kochanski", "Kelly", ""], ["Mohan", "Divya", ""], ["Horrall", "Jenna", ""], ["Rountree", "Barry", ""], ["Abdulla", "Ghaleb", ""]]}, {"id": "1912.10799", "submitter": "Andr\\'e Neves", "authors": "Andr\\'e Neves and Carlos Dam\\'asio and Jo\\~ao Pires and Fernando Birra", "title": "Dete\\c{c}\\~ao de estruturas permanentes a partir de dados de s\\'eries\n  temporais Sentinel 1 e 2", "comments": "12 pages, in Portuguese, 7 figures, conference: INForum 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mapping structures such as settlements, roads, individual houses and any\nother types of artificial structures is of great importance for the analysis of\nurban growth, masking, image alignment and, especially in the studied use case,\nthe definition of Fuel Management Networks (FGC), which protect buildings from\nforest fires. Current cartography has a low generation frequency and their\nresolution may not be suitable for extracting small structures such as small\nsettlements or roads, which may lack forest fire protection. In this paper, we\nuse time series data, extracted from Sentinel-1 and 2 constellations, over\nSantar\\'em, Ma\\c{c}\\~ao, to explore the detection of permanent structures at a\nresolution of 10 by 10 meters. For this purpose, a XGBoost classification model\nis trained with 133 attributes extracted from the time series from all the\nbands, including normalized radiometric indices. The results show that the use\nof time series data increases the accuracy of the extraction of permanent\nstructures when compared using only static data, using multitemporal data also\nincreases the number of detected roads. In general, the final result has a\npermanent structure mapping with a higher resolution than state of the art\nsettlement maps, small structures and roads are also more accurately\nrepresented. Regarding the use case, by using our final map for the creation of\nFGC it is possible to simplify and accelerate the process of delimitation of\nthe official FGC.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:08:07 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Neves", "Andr\u00e9", ""], ["Dam\u00e1sio", "Carlos", ""], ["Pires", "Jo\u00e3o", ""], ["Birra", "Fernando", ""]]}, {"id": "1912.10801", "submitter": "Angshul Majumdar Dr.", "authors": "Vanika Singhal and Angshul Majumdar", "title": "Majorization Minimization Technique for Optimally Solving Deep\n  Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of deep dictionary learning has been recently proposed. Unlike\nshallow dictionary learning which learns single level of dictionary to\nrepresent the data, it uses multiple layers of dictionaries. So far, the\nproblem could only be solved in a greedy fashion; this was achieved by learning\na single layer of dictionary in each stage where the coefficients from the\nprevious layer acted as inputs to the subsequent layer (only the first layer\nused the training samples as inputs). This was not optimal; there was feedback\nfrom shallower to deeper layers but not the other way. This work proposes an\noptimal solution to deep dictionary learning whereby all the layers of\ndictionaries are solved simultaneously. We employ the Majorization Minimization\napproach. Experiments have been carried out on benchmark datasets; it shows\nthat optimal learning indeed improves over greedy piecemeal learning.\nComparison with other unsupervised deep learning tools (stacked denoising\nautoencoder, deep belief network, contractive autoencoder and K-sparse\nautoencoder) show that our method supersedes their performance both in accuracy\nand speed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:21:34 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Singhal", "Vanika", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.10803", "submitter": "Angshul Majumdar Dr.", "authors": "Vanika Singhal, Hemant K. Aggarwal, Snigdha Tariyal and Angshul\n  Majumdar", "title": "Discriminative Robust Deep Dictionary Learning for Hyperspectral Image\n  Classification", "comments": "Final version accepted at IEEE Transactions on Geosciences and Remote\n  Sensing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new framework for deep learning that has been\nparticularly tailored for hyperspectral image classification. We learn multiple\nlevels of dictionaries in a robust fashion. The last layer is discriminative\nthat learns a linear classifier. The training proceeds greedily, at a time a\nsingle level of dictionary is learnt and the coefficients used to train the\nnext level. The coefficients from the final level are used for classification.\nRobustness is incorporated by minimizing the absolute deviations instead of the\nmore popular Euclidean norm. The inbuilt robustness helps combat mixed noise\n(Gaussian and sparse) present in hyperspectral images. Results show that our\nproposed techniques outperforms all other deep learning methods Deep Belief\nNetwork (DBN), Stacked Autoencoder (SAE) and Convolutional Neural Network\n(CNN). The experiments have been carried out on benchmark hyperspectral imaging\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:59:25 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Singhal", "Vanika", ""], ["Aggarwal", "Hemant K.", ""], ["Tariyal", "Snigdha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.10804", "submitter": "Angshul Majumdar Dr.", "authors": "Vanika Singhal and Angshul Majumdar", "title": "Row-Sparse Discriminative Deep Dictionary Learning for Hyperspectral\n  Image Classification", "comments": "Accepted at IEEE JSTARS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies in hyperspectral imaging, biometrics and energy analytics,\nthe framework of deep dictionary learning has shown promise. Deep dictionary\nlearning outperforms other traditional deep learning tools when training data\nis limited; therefore hyperspectral imaging is one such example that benefits\nfrom this framework. Most of the prior studies were based on the unsupervised\nformulation; and in all cases, the training algorithm was greedy and hence\nsub-optimal. This is the first work that shows how to learn the deep dictionary\nlearning problem in a joint fashion. Moreover, we propose a new discriminative\npenalty to the said framework. The third contribution of this work is showing\nhow to incorporate stochastic regularization techniques into the deep\ndictionary learning framework. Experimental results on hyperspectral image\nclassification shows that the proposed technique excels over all\nstate-of-the-art deep and shallow (traditional) learning based methods\npublished in recent times.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:00:31 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Singhal", "Vanika", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.10810", "submitter": "Mehrzad Saremi", "authors": "Mehrzad Saremi and Maryam Amirmazlaghani", "title": "Reconstruction of Gene Regulatory Networks usingMultiple Datasets", "comments": "17 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Laboratory gene regulatory data for a species are sporadic.\nDespite the abundance of gene regulatory network algorithms that employ single\ndata sets, few algorithms can combine the vast but disperse sources of data and\nextract the potential information. With a motivation to compensate for this\nshortage, we developed an algorithm called GENEREF that can accumulate\ninformation from multiple types of data sets in an iterative manner, with each\niteration boosting the performance of the prediction results.\n  Results: The algorithm is examined extensively on data extracted from the\nquintuple DREAM4 networks and DREAM5's Escherichia coli and Saccharomyces\ncerevisiae networks and sub-networks. Many single-dataset and multi-dataset\nalgorithms were compared to test the performance of the algorithm. Results show\nthat GENEREF surpasses non-ensemble state-of-the-art multi-perturbation\nalgorithms on the selected networks and is competitive to present\nmultiple-dataset algorithms. Specifically, it outperforms dynGENIE3 and is on\npar with iRafNet. Also, we argued that a scoring method solely based on the\nAUPR criterion would be more trustworthy than the traditional score.\n  Availability: The Python implementation along with the data sets and results\ncan be downloaded from github.com/msaremi/GENEREF\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 22:54:59 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 19:32:05 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Saremi", "Mehrzad", ""], ["Amirmazlaghani", "Maryam", ""]]}, {"id": "1912.10815", "submitter": "Mateusz Dorobek B.S", "authors": "Mateusz Dorobek", "title": "Wykorzystanie sztucznej inteligencji do generowania tre\\'sci muzycznych", "comments": "Bachelor Thesis, in Polish", "journal-ref": null, "doi": "10.13140/RG.2.2.23824.66564", "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is presenting a method for generating short musical phrases using\na deep convolutional generative adversarial network (DCGAN). To train neural\nnetwork were used datasets of classical and jazz music MIDI recordings. Our\napproach introduces translating the MIDI data into graphical images in a piano\nroll format suitable for the network input size, using the RGB channels as\nadditional information carriers for improved performance. The network has\nlearned to generate images that are indistinguishable from the input data and,\nwhen translated back to MIDI and played back, include several musically\ninteresting rhythmic and harmonic structures. The results of the conducted\nexperiments are described and discussed, with conclusions for further work and\na short comparison with selected existing solutions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 02:48:16 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dorobek", "Mateusz", ""]]}, {"id": "1912.10819", "submitter": "Joeran Beel", "authors": "Conor O'Sullivan and Joeran Beel", "title": "Predicting the Outcome of Judicial Decisions made by the European Court\n  of Human Rights", "comments": null, "journal-ref": "27th AIAI Irish Conference on Artificial Intelligence and\n  Cognitive Science. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, machine learning models were constructed to predict whether\njudgments made by the European Court of Human Rights (ECHR) would lead to a\nviolation of an Article in the Convention on Human Rights. The problem is\nframed as a binary classification task where a judgment can lead to a\n\"violation\" or \"non-violation\" of a particular Article. Using auto-sklearn, an\nautomated algorithm selection package, models were constructed for 12 Articles\nin the Convention. To train these models, textual features were obtained from\nthe ECHR Judgment documents using N-grams, word embeddings and paragraph\nembeddings. Additional documents, from the ECHR, were incorporated into the\nmodels through the creation of a word embedding (echr2vec) and a doc2vec model.\nThe features obtained using the echr2vec embedding provided the highest\ncross-validation accuracy for 5 of the Articles. The overall test accuracy,\nacross the 12 Articles, was 68.83%. As far as we could tell, this is the first\nestimate of the accuracy of such machine learning models using a realistic test\nset. This provides an important benchmark for future work. As a baseline, a\nsimple heuristic of always predicting the most common outcome in the past was\nused. The heuristic achieved an overall test accuracy of 86.68% which is 29.7%\nhigher than the models. Again, this was seemingly the first study that included\nsuch a heuristic with which to compare model results. The higher accuracy\nachieved by the heuristic highlights the importance of including such a\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 15:42:30 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["O'Sullivan", "Conor", ""], ["Beel", "Joeran", ""]]}, {"id": "1912.10822", "submitter": "Jithin James", "authors": "Jithin James", "title": "DeepHashing using TripletLoss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing is one of the most efficient techniques for approximate nearest\nneighbour search for large scale image retrieval. Most of the techniques are\nbased on hand-engineered features and do not give optimal results all the time.\nDeep Convolutional Neural Networks have proven to generate very effective\nrepresentation of images that are used for various computer vision tasks and\ninspired by this there have been several Deep Hashing models like Wang et al.\n(2016) have been proposed. These models train on the triplet loss function\nwhich can be used to train models with superior representation capabilities.\nTaking the latest advancements in training using the triplet loss I propose new\ntechniques that help the Deep Hash-ing models train more faster and\nefficiently. Experiment result1show that using the more efficient techniques\nfor training on the triplet loss, we have obtained a 5%percent improvement in\nour model compared to the original work of Wang et al.(2016). Using a larger\nmodel and more training data we can drastically improve the performance using\nthe techniques we propose\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:17:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["James", "Jithin", ""]]}, {"id": "1912.10824", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Matko Bo\\v{s}njak, Tim Rockt\\\"aschel, Sebastian\n  Riedel, Edward Grefenstette", "title": "Differentiable Reasoning on Large Knowledge Bases and Natural Language", "comments": "Accepted at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning with knowledge expressed in natural language and Knowledge Bases\n(KBs) is a major challenge for Artificial Intelligence, with applications in\nmachine reading, dialogue, and question answering. General neural architectures\nthat jointly learn representations and transformations of text are very\ndata-inefficient, and it is hard to analyse their reasoning process. These\nissues are addressed by end-to-end differentiable reasoning systems such as\nNeural Theorem Provers (NTPs), although they can only be used with small-scale\nsymbolic KBs. In this paper we first propose Greedy NTPs (GNTPs), an extension\nto NTPs addressing their complexity and scalability limitations, thus making\nthem applicable to real-world datasets. This result is achieved by dynamically\nconstructing the computation graph of NTPs and including only the most\npromising proof paths during inference, thus obtaining orders of magnitude more\nefficient models. Then, we propose a novel approach for jointly reasoning over\nKBs and textual mentions, by embedding logic facts and natural language\nsentences in a shared embedding space. We show that GNTPs perform on par with\nNTPs at a fraction of their cost while achieving competitive link prediction\nresults on large datasets, providing explanations for predictions, and inducing\ninterpretable models. Source code, datasets, and supplementary material are\navailable online at https://github.com/uclnlp/gntp.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:01:54 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Minervini", "Pasquale", ""], ["Bo\u0161njak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1912.10828", "submitter": "Ana Paula Appel", "authors": "Ana Paula Appel, Victor Oliveira, Bruno Lima, Gabriel Louzada\n  Malfatti, Vagner Figueredo de Santana, Rogerio de Paula", "title": "Optimize Cash Collection: Use Machine learning to Predicting Invoice\n  Payment", "comments": "10 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting invoice payment is valuable in multiple industries and supports\ndecision-making processes in most financial workflows. However, the challenge\nin this realm involves dealing with complex data and the lack of data related\nto decisions-making processes not registered in the accounts receivable system.\nThis work presents a prototype developed as a solution devised during a\npartnership with a multinational bank to support collectors in predicting\ninvoices payment. The proposed prototype reached up to 77\\% of accuracy, which\nimproved the prioritization of customers and supported the daily work of\ncollectors. With the presented results, one expects to support researchers\ndealing with the problem of invoice payment prediction to get insights and\nexamples of how to tackle issues present in real data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:10:00 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Appel", "Ana Paula", ""], ["Oliveira", "Victor", ""], ["Lima", "Bruno", ""], ["Malfatti", "Gabriel Louzada", ""], ["de Santana", "Vagner Figueredo", ""], ["de Paula", "Rogerio", ""]]}, {"id": "1912.10829", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Y. Berger-Wolf", "title": "Variable-lag Granger Causality for Time Series Analysis", "comments": "This paper will be appeared in the proceeding of 2019 IEEE\n  International Conference on Data Science and Advanced Analytics (DSAA). The R\n  package is available at https://github.com/DarkEyes/VLTimeSeriesCausality", "journal-ref": "Proceedings of 2019 IEEE International Conference on Data Science\n  and Advanced Analytics (DSAA)", "doi": "10.1109/DSAA.2019.00016", "report-no": null, "categories": "cs.LG econ.EM q-bio.QM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a fundamental technique for causal inference in time\nseries data, commonly used in the social and biological sciences. Typical\noperationalizations of Granger causality make a strong assumption that every\ntime point of the effect time series is influenced by a combination of other\ntime series with a fixed time delay. However, the assumption of the fixed time\ndelay does not hold in many applications, such as collective behavior,\nfinancial markets, and many natural phenomena. To address this issue, we\ndevelop variable-lag Granger causality, a generalization of Granger causality\nthat relaxes the assumption of the fixed time delay and allows causes to\ninfluence effects with arbitrary time delays. In addition, we propose a method\nfor inferring variable-lag Granger causality relations. We demonstrate our\napproach on an application for studying coordinated collective behavior and\nshow that it performs better than several existing methods in both simulated\nand real-world datasets. Our approach can be applied in any domain of time\nseries analysis.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 23:38:48 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Zheleva", "Elena", ""], ["Berger-Wolf", "Tanya Y.", ""]]}, {"id": "1912.10832", "submitter": "Xiaoqing Yang", "authors": "Huiting Hong, Hantao Guo, Yucheng Lin, Xiaoqing Yang, Zang Li, Jieping\n  Ye", "title": "An Attention-based Graph Neural Network for Heterogeneous Structural\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on graph representation learning of heterogeneous\ninformation network (HIN), in which various types of vertices are connected by\nvarious types of relations. Most of the existing methods conducted on HIN\nrevise homogeneous graph embedding models via meta-paths to learn\nlow-dimensional vector space of HIN. In this paper, we propose a novel\nHeterogeneous Graph Structural Attention Neural Network (HetSANN) to directly\nencode structural information of HIN without meta-path and achieve more\ninformative representations. With this method, domain experts will not be\nneeded to design meta-path schemes and the heterogeneous information can be\nprocessed automatically by our proposed model. Specifically, we implicitly\nrepresent heterogeneous information using the following two methods: 1) we\nmodel the transformation between heterogeneous vertices through a projection in\nlow-dimensional entity spaces; 2) afterwards, we apply the graph neural network\nto aggregate multi-relational information of projected neighborhood by means of\nattention mechanism. We also present three extensions of HetSANN, i.e.,\nvoices-sharing product attention for the pairwise relationships in HIN,\ncycle-consistency loss to retain the transformation between heterogeneous\nentity spaces, and multi-task learning with full use of information. The\nexperiments conducted on three public datasets demonstrate that our proposed\nmodels achieve significant and consistent improvements compared to\nstate-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 06:20:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hong", "Huiting", ""], ["Guo", "Hantao", ""], ["Lin", "Yucheng", ""], ["Yang", "Xiaoqing", ""], ["Li", "Zang", ""], ["Ye", "Jieping", ""]]}, {"id": "1912.10833", "submitter": "Ziwen He", "authors": "Ziwen He, Wei Wang, Xinsheng Xuan, Jing Dong, Tieniu Tan", "title": "A New Ensemble Method for Concessively Targeted Multi-model Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that deep learning models are vulnerable to adversarial\nexamples crafted by maliciously adding perturbations to original inputs. There\nare two types of attacks: targeted attack and non-targeted attack, and most\nresearchers often pay more attention to the targeted adversarial examples.\nHowever, targeted attack has a low success rate, especially when aiming at a\nrobust model or under a black-box attack protocol. In this case, non-targeted\nattack is the last chance to disable AI systems. Thus, in this paper, we\npropose a new attack mechanism which performs the non-targeted attack when the\ntargeted attack fails. Besides, we aim to generate a single adversarial sample\nfor different deployed models of the same task, e.g. image classification\nmodels. Hence, for this practical application, we focus on attacking ensemble\nmodels by dividing them into two groups: easy-to-attack and robust models. We\nalternately attack these two groups of models in the non-targeted or targeted\nmanner. We name it a bagging and stacking ensemble (BAST) attack. The BAST\nattack can generate an adversarial sample that fails multiple models\nsimultaneously. Some of the models classify the adversarial sample as a target\nlabel, and other models which are not attacked successfully may give wrong\nlabels at least. The experimental results show that the proposed BAST attack\noutperforms the state-of-the-art attack methods on the new defined criterion\nthat considers both targeted and non-targeted attack performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 10:56:36 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["He", "Ziwen", ""], ["Wang", "Wei", ""], ["Xuan", "Xinsheng", ""], ["Dong", "Jing", ""], ["Tan", "Tieniu", ""]]}, {"id": "1912.10834", "submitter": "Stefano Teso", "authors": "Stefano Teso", "title": "Does Symbolic Knowledge Prevent Adversarial Fooling?", "comments": "Short position paper. Accepted at the Ninth International Workshop on\n  Statistical Relational AI (StarIA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguments in favor of injecting symbolic knowledge into neural architectures\nabound. When done right, constraining a sub-symbolic model can substantially\nimprove its performance and sample complexity and prevent it from predicting\ninvalid configurations. Focusing on deep probabilistic (logical) graphical\nmodels -- i.e., constrained joint distributions whose parameters are determined\n(in part) by neural nets based on low-level inputs -- we draw attention to an\nelementary but unintended consequence of symbolic knowledge: that the resulting\nconstraints can propagate the negative effects of adversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 11:50:33 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Teso", "Stefano", ""]]}, {"id": "1912.10836", "submitter": "Aykut \\c{C}ay{\\i}r", "authors": "Aykut \\c{C}ay{\\i}r, U\\u{g}ur \\\"Unal and Hasan Da\\u{g}", "title": "Random CapsNet Forest Model for Imbalanced Malware Type Classification\n  Task", "comments": "30 pages, 10 figures, typos are corrected, references are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Behavior of a malware varies with respect to malware types. Therefore,knowing\ntype of a malware affects strategies of system protection softwares. Many\nmalware type classification models empowered by machine and deep learning\nachieve superior accuracies to predict malware types.Machine learning based\nmodels need to do heavy feature engineering and feature engineering is\ndominantly effecting performance of models.On the other hand, deep learning\nbased models require less feature engineering than machine learning based\nmodels. However, traditional deep learning architectures and components cause\nvery complex and data sensitive models. Capsule network architecture minimizes\nthis complexity and data sensitivity unlike classical convolutional neural\nnetwork architectures. This paper proposes an ensemble capsule network model\nbased on bootstrap aggregating technique. The proposed method are tested on two\nmalware datasets, whose the-state-of-the-art results are well-known.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 06:40:40 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:51:31 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 19:56:53 GMT"}, {"version": "v4", "created": "Sun, 23 Aug 2020 20:21:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["\u00c7ay\u0131r", "Aykut", ""], ["\u00dcnal", "U\u011fur", ""], ["Da\u011f", "Hasan", ""]]}, {"id": "1912.10837", "submitter": "Siming Bayer", "authors": "Siming Bayer, Xia Zhong, Weilin Fu, Nishant Ravikumar, Andreas Maier", "title": "Analyzing an Imitation Learning Network for Fundus Image Registration\n  Using a Divide-and-Conquer Approach", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparison of microvascular circulation on fundoscopic images is a\nnon-invasive clinical indication for the diagnosis and monitoring of diseases,\nsuch as diabetes and hypertensions. The differences between intra-patient\nimages can be assessed quantitatively by registering serial acquisitions. Due\nto the variability of the images (i.e. contrast, luminosity) and the anatomical\nchanges of the retina, the registration of fundus images remains a challenging\ntask. Recently, several deep learning approaches have been proposed to register\nfundus images in an end-to-end fashion, achieving remarkable results. However,\nthe results are difficult to interpret and analyze. In this work, we propose an\nimitation learning framework for the registration of 2D color funduscopic\nimages for a wide range of applications such as disease monitoring, image\nstitching and super-resolution. We follow a divide-and-conquer approach to\nimprove the interpretability of the proposed network, and analyze both the\ninfluence of the input image and the hyperparameters on the registration\nresult. The results show that the proposed registration network reduces the\ninitial target registration error up to 95\\%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 15:01:49 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Bayer", "Siming", ""], ["Zhong", "Xia", ""], ["Fu", "Weilin", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""]]}, {"id": "1912.10840", "submitter": "Yoeri Boink", "authors": "Yoeri E. Boink, Christoph Brune", "title": "Learned SVD: solving inverse problems via hybrid autoencoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our world is full of physics-driven data where effective mappings between\ndata manifolds are desired. There is an increasing demand for understanding\ncombined model-based and data-driven methods. We propose a nonlinear, learned\nsingular value decomposition (L-SVD), which combines autoencoders that\nsimultaneously learn and connect latent codes for desired signals and given\nmeasurements. We provide a convergence analysis for a specifically structured\nL-SVD that acts as a regularisation method. In a more general setting, we\ninvestigate the topic of model reduction via data dimensionality reduction to\nobtain a regularised inversion. We present a promising direction for solving\ninverse problems in cases where the underlying physics are not fully understood\nor have very complex behaviour. We show that the building blocks of learned\ninversion maps can be obtained automatically, with improved performance upon\nclassical methods and better interpretability than black-box methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 12:29:12 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 09:18:39 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 12:55:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Boink", "Yoeri E.", ""], ["Brune", "Christoph", ""]]}, {"id": "1912.10846", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Kyubum Lee, Shankai Yan, Sun Kim, Chih-Hsuan Wei, and\n  Zhiyong Lu", "title": "BioConceptVec: creating and evaluating literature-based biomedical\n  concept embeddings on a large scale", "comments": "33 pages, 6 figures, 7 tables, accepted by PLOS Computational Biology", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007617", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the semantics of related biological concepts, such as genes and\nmutations, is of significant importance to many research tasks in computational\nbiology such as protein-protein interaction detection, gene-drug association\nprediction, and biomedical literature-based discovery. Here, we propose to\nleverage state-of-the-art text mining tools and machine learning models to\nlearn the semantics via vector representations (aka. embeddings) of over\n400,000 biological concepts mentioned in the entire PubMed abstracts. Our\nlearned embeddings, namely BioConceptVec, can capture related concepts based on\ntheir surrounding contextual information in the literature, which is beyond\nexact term match or co-occurrence-based methods. BioConceptVec has been\nthoroughly evaluated in multiple bioinformatics tasks consisting of over 25\nmillion instances from nine different biological datasets. The evaluation\nresults demonstrate that BioConceptVec has better performance than existing\nmethods in all tasks. Finally, BioConceptVec is made freely available to the\nresearch community and general public via\nhttps://github.com/ncbi-nlp/BioConceptVec.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 14:46:46 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Chen", "Qingyu", ""], ["Lee", "Kyubum", ""], ["Yan", "Shankai", ""], ["Kim", "Sun", ""], ["Wei", "Chih-Hsuan", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1912.10847", "submitter": "Preeti Sah", "authors": "Preeti Sah and Ernest Fokou\\'e", "title": "What do Asian Religions Have in Common? An Unsupervised Text Analytics\n  Exploration", "comments": "18 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main source of various religious teachings is their sacred texts which\nvary from religion to religion based on different factors like the geographical\nlocation or time of the birth of a particular religion. Despite these\ndifferences, there could be similarities between the sacred texts based on what\nlessons it teaches to its followers. This paper attempts to find the similarity\nusing text mining techniques. The corpus consisting of Asian (Tao Te Ching,\nBuddhism, Yogasutra, Upanishad) and non-Asian (four Bible texts) is used to\nexplore findings of similarity measures like Euclidean, Manhattan, Jaccard and\nCosine on raw Document Term Frequency [DTM], normalized DTM which reveals\nsimilarity based on word usage. The performance of Supervised learning\nalgorithms like K-Nearest Neighbor [KNN], Support Vector Machine [SVM] and\nRandom Forest is measured based on its accuracy to predict correct scared text\nfor any given chapter in the corpus. The K-means clustering visualizations on\nEuclidean distances of raw DTM reveals that there exists a pattern of\nsimilarity among these sacred texts with Upanishads and Tao Te Ching is the\nmost similar text in the corpus.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 18:28:29 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Sah", "Preeti", ""], ["Fokou\u00e9", "Ernest", ""]]}, {"id": "1912.10850", "submitter": "Karanbir Chahal", "authors": "Fabian Ruffy, Karanbir Chahal", "title": "The State of Knowledge Distillation for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey various knowledge distillation (KD) strategies for simple\nclassification tasks and implement a set of techniques that claim\nstate-of-the-art accuracy. Our experiments using standardized model\narchitectures, fixed compute budgets, and consistent training schedules\nindicate that many of these distillation results are hard to reproduce. This is\nespecially apparent with methods using some form of feature distillation.\nFurther examination reveals a lack of generalizability where these techniques\nmay only succeed for specific architectures and training settings. We observe\nthat appropriately tuned classical distillation in combination with a data\naugmentation training scheme gives an orthogonal improvement over other\ntechniques. We validate this approach and open-source our code.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 04:01:18 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ruffy", "Fabian", ""], ["Chahal", "Karanbir", ""]]}, {"id": "1912.10852", "submitter": "Ta-Chun Su", "authors": "Ta-Chun Su, Guan-Ying Chen", "title": "ET-USB: Transformer-Based Sequential Behavior Modeling for Inbound\n  Customer Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models with attention mechanisms have achieved exceptional\nresults for many tasks, including language tasks and recommendation systems.\nWhereas previous studies have emphasized allocation of phone agents, we focused\non inbound call prediction for customer service. A common method of analyzing\nuser history behaviors is to extract all types of aggregated feature over time,\nbut that method may fail to detect users' behavioral sequences. Therefore, we\ncreated a new approach, ET-USB, that incorporates users' sequential and\nnonsequential features; we apply the powerful Transformer encoder, a\nself-attention network model, to capture the information underlying user\nbehavior sequences. ET-USB is helpful in various business scenarios at Cathay\nFinancial Holdings. We conducted experiments to test the proposed network\nstructure's ability to process various dimensions of behavior data; the results\nsuggest that ET-USB delivers results superior to those of delivered by other\ndeep-learning models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 10:00:11 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 10:05:28 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 08:46:32 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Su", "Ta-Chun", ""], ["Chen", "Guan-Ying", ""]]}, {"id": "1912.10857", "submitter": "Yusen Wu", "authors": "Yusen Wu, Chao-hua Yu, Sujuan Qin, Qiaoyan Wen, and Fei Gao", "title": "Bayesian machine learning for Boltzmann machine in quantum-enhanced\n  feature spaces", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian learning is ubiquitous for implementing classification and\nregression tasks, however, it is accompanied by computationally intractable\nlimitations when the feature spaces become extremely large. Aiming to solve\nthis problem, we develop a quantum bayesian learning framework of the\nrestricted Boltzmann machine in the quantum-enhanced feature spaces. Our\nframework provides the encoding phase to map the real data and Boltzmann weight\nonto the quantum feature spaces and the training phase to learn an optimal\ninference function. Specifically, the training phase provides a physical\nquantity to measure the posterior distribution in quantum feature spaces, and\nthis measure is utilized to design the quantum maximum a posterior (QMAP)\nalgorithm and the quantum predictive distribution estimator (QPDE). It is shown\nthat both quantum algorithms achieve exponential speed-up over their classical\ncounterparts. Furthermore, it is interesting to note that our framework can\nfigure out the classical bayesian learning tasks, i.e. processing the classical\ndata and outputting corresponding classical labels. And a simulation, which is\nperformed on an open-source software framework for quantum computing,\nillustrates that our algorithms show almost the same classification performance\ncompared to their classical counterparts. Noting that the proposed quantum\nalgorithms utilize the shallow circuit, our work is expected to be implemented\non the noisy intermediate-scale quantum (NISQ) devices, and is one of the\npromising candidates to achieve quantum supremacy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 16:38:19 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Wu", "Yusen", ""], ["Yu", "Chao-hua", ""], ["Qin", "Sujuan", ""], ["Wen", "Qiaoyan", ""], ["Gao", "Fei", ""]]}, {"id": "1912.10858", "submitter": "Xuan-Hong Dang", "authors": "Xuan-Hong Dang, Syed Yousaf Shah, Petros Zerfos", "title": "\"The Squawk Bot\": Joint Learning of Time Series and Text Data Modalities\n  for Automated Financial Information Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal analysis that uses numerical time series and textual corpora as\ninput data sources is becoming a promising approach, especially in the\nfinancial industry. However, the main focus of such analysis has been on\nachieving high prediction accuracy while little effort has been spent on the\nimportant task of understanding the association between the two data\nmodalities. Performance on the time series hence receives little explanation\nthough human-understandable textual information is available. In this work, we\naddress the problem of given a numerical time series, and a general corpus of\ntextual stories collected in the same period of the time series, the task is to\ntimely discover a succinct set of textual stories associated with that time\nseries. Towards this goal, we propose a novel multi-modal neural model called\nMSIN that jointly learns both numerical time series and categorical text\narticles in order to unearth the association between them. Through multiple\nsteps of data interrelation between the two data modalities, MSIN learns to\nfocus on a small subset of text articles that best align with the performance\nin the time series. This succinct set is timely discovered and presented as\nrecommended documents, acting as automated information filtering, for the given\ntime series. We empirically evaluate the performance of our model on\ndiscovering relevant news articles for two stock time series from Apple and\nGoogle companies, along with the daily news articles collected from the Thomson\nReuters over a period of seven consecutive years. The experimental results\ndemonstrate that MSIN achieves up to 84.9% and 87.2% in recalling the ground\ntruth articles respectively to the two examined time series, far more superior\nto state-of-the-art algorithms that rely on conventional attention mechanism in\ndeep learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:37:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dang", "Xuan-Hong", ""], ["Shah", "Syed Yousaf", ""], ["Zerfos", "Petros", ""]]}, {"id": "1912.10872", "submitter": "Ari Frankel", "authors": "Ari Frankel, Reese Jones, Laura Swiler", "title": "Tensor Basis Gaussian Process Models of Hyperelastic Materials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop Gaussian process regression (GPR) models of\nhyperelastic material behavior. First, we consider the direct approach of\nmodeling the components of the Cauchy stress tensor as a function of the\ncomponents of the Finger stretch tensor in a Gaussian process. We then consider\nan improvement on this approach that embeds rotational invariance of the\nstress-stretch constitutive relation in the GPR representation. This approach\nrequires fewer training examples and achieves higher accuracy while maintaining\ninvariance to rotations exactly. Finally, we consider an approach that recovers\nthe strain-energy density function and derives the stress tensor from this\npotential. Although the error of this model for predicting the stress tensor is\nhigher, the strain-energy density is recovered with high accuracy from limited\ntraining data. The approaches presented here are examples of physics-informed\nmachine learning. They go beyond purely data-driven approaches by embedding the\nphysical system constraints directly into the Gaussian process representation\nof materials models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 14:32:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Frankel", "Ari", ""], ["Jones", "Reese", ""], ["Swiler", "Laura", ""]]}, {"id": "1912.10891", "submitter": "Xinyang Gu", "authors": "Jingbin Liu, Shuai Liu, Xinyang Gu", "title": "Soft Q Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q Network (DQN) is a very successful algorithm, yet the inherent problem\nof reinforcement learning, i.e. the exploit-explore balance, remains. In this\nwork, we introduce entropy regularization into DQN and propose SQN. We find\nthat the backup equation of soft Q learning can enjoy the corrective feedback\nif we view the soft backup as policy improvement in the form of Q, instead of\npolicy evaluation. We show that Soft Q Learning with Corrective Feedback\n(SQL-CF) underlies the on-plicy nature of SQL and the equivalence of SQL and\nSoft Policy Gradient (SPG). With these insights, we propose an on-policy\nversion of deep Q learning algorithm, i.e. Q On-Policy (QOP). We experiment\nwith QOP on a self-play environment called Google Research Football (GRF). The\nQOP algorithm exhibits great stability and efficiency in training GRF agents.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:55:40 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:12:57 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Jingbin", ""], ["Liu", "Shuai", ""], ["Gu", "Xinyang", ""]]}, {"id": "1912.10900", "submitter": "Lukas Hewing", "authors": "Lukas Hewing and Elena Arcari and Lukas P. Fr\\\"ohlich and Melanie N.\n  Zeilinger", "title": "On Simulation and Trajectory Prediction with Gaussian Process Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Established techniques for simulation and prediction with Gaussian process\n(GP) dynamics often implicitly make use of an independence assumption on\nsuccessive function evaluations of the dynamics model. This can result in\nsignificant error and underestimation of the prediction uncertainty,\npotentially leading to failures in safety-critical applications. This paper\ndiscusses methods that explicitly take the correlation of successive function\nevaluations into account. We first describe two sampling-based techniques; one\napproach provides samples of the true trajectory distribution, suitable for\n`ground truth' simulations, while the other draws function samples from basis\nfunction approximations of the GP. Second, we propose a linearization-based\ntechnique that directly provides approximations of the trajectory distribution,\ntaking correlations explicitly into account. We demonstrate the procedures in\nsimple numerical examples, contrasting the results with established methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 15:00:48 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 08:50:53 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 07:39:23 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hewing", "Lukas", ""], ["Arcari", "Elena", ""], ["Fr\u00f6hlich", "Lukas P.", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "1912.10903", "submitter": "Thomas Bonald", "authors": "Nathan de Lara (IP Paris, DIG, INFRES, LINCS), Thomas Bonald (DIG,\n  INFRES, IP Paris, LINCS)", "title": "Spectral embedding of regularized block models", "comments": null, "journal-ref": "ICLR, 2020, Addis Abeba, Ethiopia", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral embedding is a popular technique for the representation of graph\ndata. Several regularization techniques have been proposed to improve the\nquality of the embedding with respect to downstream tasks like clustering. In\nthis paper, we explain on a simple block model the impact of the complete graph\nregularization, whereby a constant is added to all entries of the adjacency\nmatrix. Specifically, we show that the regularization forces the spectral\nembedding to focus on the largest blocks, making the representation less\nsensitive to noise or outliers. We illustrate these results on both on both\nsynthetic and real data, showing how regularization improves standard\nclustering scores.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 15:06:54 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["de Lara", "Nathan", "", "IP Paris, DIG, INFRES, LINCS"], ["Bonald", "Thomas", "", "DIG,\n  INFRES, IP Paris, LINCS"]]}, {"id": "1912.10917", "submitter": "Wuyang Chen", "authors": "Wuyang Chen, Xinyu Gong, Xianming Liu, Qian Zhang, Yuan Li, Zhangyang\n  Wang", "title": "FasterSeg: Searching for Faster Real-time Semantic Segmentation", "comments": "ICLR 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FasterSeg, an automatically designed semantic segmentation network\nwith not only state-of-the-art performance but also faster speed than current\nmethods. Utilizing neural architecture search (NAS), FasterSeg is discovered\nfrom a novel and broader search space integrating multi-resolution branches,\nthat has been recently found to be vital in manually designed segmentation\nmodels. To better calibrate the balance between the goals of high accuracy and\nlow latency, we propose a decoupled and fine-grained latency regularization,\nthat effectively overcomes our observed phenomenons that the searched networks\nare prone to \"collapsing\" to low-latency yet poor-accuracy models. Moreover, we\nseamlessly extend FasterSeg to a new collaborative search (co-searching)\nframework, simultaneously searching for a teacher and a student network in the\nsame single run. The teacher-student distillation further boosts the student\nmodel's accuracy. Experiments on popular segmentation benchmarks demonstrate\nthe competency of FasterSeg. For example, FasterSeg can run over 30% faster\nthan the closest manually designed competitor on Cityscapes, while maintaining\ncomparable accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 15:26:39 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 21:20:48 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Chen", "Wuyang", ""], ["Gong", "Xinyu", ""], ["Liu", "Xianming", ""], ["Zhang", "Qian", ""], ["Li", "Yuan", ""], ["Wang", "Zhangyang", ""]]}, {"id": "1912.10934", "submitter": "Frederik Gossen", "authors": "Frederik Gossen and Bernhard Steffen", "title": "Large Random Forests: Optimisation for Rapid Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forests are one of the most popular classifiers in machine learning.\nThe larger they are, the more precise is the outcome of their predictions.\nHowever, this comes at a cost: their running time for classification grows\nlinearly with the number of trees, i.e. the size of the forest. In this paper,\nwe propose a method to aggregate large Random Forests into a single,\nsemantically equivalent decision diagram. Our experiments on various popular\ndatasets show speed-ups of several orders of magnitude, while, at the same\ntime, also significantly reducing the size of the required data structure.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 15:49:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Gossen", "Frederik", ""], ["Steffen", "Bernhard", ""]]}, {"id": "1912.10944", "submitter": "Kun Shao", "authors": "Kun Shao, Zhentao Tang, Yuanheng Zhu, Nannan Li, Dongbin Zhao", "title": "A Survey of Deep Reinforcement Learning in Video Games", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has made great achievements since proposed.\nGenerally, DRL agents receive high-dimensional inputs at each step, and make\nactions according to deep-neural-network-based policies. This learning\nmechanism updates the policy to maximize the return with an end-to-end method.\nIn this paper, we survey the progress of DRL methods, including value-based,\npolicy gradient, and model-based algorithms, and compare their main techniques\nand properties. Besides, DRL plays an important role in game artificial\nintelligence (AI). We also take a review of the achievements of DRL in various\nvideo games, including classical Arcade games, first-person perspective games\nand multi-agent real-time strategy games, from 2D to 3D, and from single-agent\nto multi-agent. A large number of video game AIs with DRL have achieved\nsuper-human performance, while there are still some challenges in this domain.\nTherefore, we also discuss some key points when applying DRL methods to this\nfield, including exploration-exploitation, sample efficiency, generalization\nand transfer, multi-agent learning, imperfect information, and delayed spare\nrewards, as well as some research directions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 16:04:40 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 14:47:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shao", "Kun", ""], ["Tang", "Zhentao", ""], ["Zhu", "Yuanheng", ""], ["Li", "Nannan", ""], ["Zhao", "Dongbin", ""]]}, {"id": "1912.10946", "submitter": "Shiv Ram Dubey", "authors": "Yash Srivastava, Vaishnav Murali, Shiv Ram Dubey", "title": "PSNet: Parametric Sigmoid Norm Based CNN for Face Recognition", "comments": "Accepted in IEEE CICT 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolutional Neural Networks (CNN) have become very popular recently due\nto its outstanding performance in various computer vision applications. It is\nalso used over widely studied face recognition problem. However, the existing\nlayers of CNN are unable to cope with the problem of hard examples which\ngenerally produce lower class scores. Thus, the existing methods become biased\ntowards the easy examples. In this paper, we resolve this problem by\nincorporating a Parametric Sigmoid Norm (PSN) layer just before the final\nfully-connected layer. We propose a PSNet CNN model by using the PSN layer. The\nPSN layer facilitates high gradient flow for harder examples as compared to\neasy examples. Thus, it forces the network to learn the visual characteristics\nof hard examples. We conduct the face recognition experiments to test the\nperformance of PSN layer. The suitability of the PSN layer with different loss\nfunctions is also experimented. The widely used Labeled Faces in the Wild (LFW)\nand YouTube Faces (YTF) datasets are used in the experiments. The experimental\nresults confirm the relevance of the proposed PSN layer.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 05:10:27 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Srivastava", "Yash", ""], ["Murali", "Vaishnav", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "1912.10952", "submitter": "Xin Chen", "authors": "Xin Chen, Lingxi Xie, Jun Wu and Qi Tian", "title": "Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild", "comments": "An extension of P-DARTS. Previous version: arXiv:1904.12760", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of neural architecture search (NAS), researchers\nfound powerful network architectures for a wide range of vision tasks. However,\nit remains unclear if the searched architecture can transfer across different\ntypes of tasks as manually designed ones did. This paper puts forward this\nproblem, referred to as NAS in the wild, which explores the possibility of\nfinding the optimal architecture in a proxy dataset and then deploying it to\nmostly unseen scenarios.\n  We instantiate this setting using a currently popular algorithm named\ndifferentiable architecture search (DARTS), which often suffers unsatisfying\nperformance while being transferred across different tasks. We argue that the\naccuracy drop originates from the formulation that uses a super-network for\nsearch but a sub-network for re-training. The different properties of these\nstages have resulted in a significant optimization gap, and consequently, the\narchitectural parameters \"over-fit\" the super-network. To alleviate the gap, we\npresent a progressive method that gradually increases the network depth during\nthe search stage, which leads to the Progressive DARTS (P-DARTS) algorithm.\nWith a reduced search cost (7 hours on a single GPU), P-DARTS achieves improved\nperformance on both the proxy dataset (CIFAR10) and a few target problems\n(ImageNet classification, COCO detection and three ReID benchmarks). Our code\nis available at \\url{https://github.com/chenxin061/pdarts}.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 16:23:28 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 16:03:32 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chen", "Xin", ""], ["Xie", "Lingxi", ""], ["Wu", "Jun", ""], ["Tian", "Qi", ""]]}, {"id": "1912.10979", "submitter": "Florian Lemmerich", "authors": "Michael Ellers, Michael Cochez, Tobias Schumacher, Markus Strohmaier,\n  Florian Lemmerich", "title": "Privacy Attacks on Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data ownership and data protection are increasingly important topics with\nethical and legal implications, e.g., with the right to erasure established in\nthe European General Data Protection Regulation (GDPR). In this light, we\ninvestigate network embeddings, i.e., the representation of network nodes as\nlow-dimensional vectors. We consider a typical social network scenario with\nnodes representing users and edges relationships between them. We assume that a\nnetwork embedding of the nodes has been trained. After that, a user demands the\nremoval of his data, requiring the full deletion of the corresponding network\ninformation, in particular the corresponding node and incident edges. In that\nsetting, we analyze whether after the removal of the node from the network and\nthe deletion of the vector representation of the respective node in the\nembedding significant information about the link structure of the removed node\nis still encoded in the embedding vectors of the remaining nodes. This would\nrequire a (potentially computationally expensive) retraining of the embedding.\nFor that purpose, we deploy an attack that leverages information from the\nremaining network and embedding to recover information about the neighbors of\nthe removed node. The attack is based on (i) measuring distance changes in\nnetwork embeddings and (ii) a machine learning classifier that is trained on\nnetworks that are constructed by removing additional nodes. Our experiments\ndemonstrate that substantial information about the edges of a removed node/user\ncan be retrieved across many different datasets. This implies that to fully\nprotect the privacy of users, node deletion requires complete retraining - or\nat least a significant modification - of original network embeddings. Our\nresults suggest that deleting the corresponding vector representation from\nnetwork embeddings alone is not sufficient from a privacy perspective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 17:10:20 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ellers", "Michael", ""], ["Cochez", "Michael", ""], ["Schumacher", "Tobias", ""], ["Strohmaier", "Markus", ""], ["Lemmerich", "Florian", ""]]}, {"id": "1912.10985", "submitter": "Felix Dangel", "authors": "Felix Dangel, Frederik Kunstner, Philipp Hennig", "title": "BackPACK: Packing more into backprop", "comments": "Main text: 10 pages, 7 figures, 1 table; Supplements: 10 pages, 4\n  figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic differentiation frameworks are optimized for exactly one thing:\ncomputing the average mini-batch gradient. Yet, other quantities such as the\nvariance of the mini-batch gradients or many approximations to the Hessian can,\nin theory, be computed efficiently, and at the same time as the gradient. While\nthese quantities are of great interest to researchers and practitioners,\ncurrent deep-learning software does not support their automatic calculation.\nManually implementing them is burdensome, inefficient if done naively, and the\nresulting code is rarely shared. This hampers progress in deep learning, and\nunnecessarily narrows research to focus on gradient descent and its variants;\nit also complicates replication studies and comparisons between newly developed\nmethods that require those quantities, to the point of impossibility. To\naddress this problem, we introduce BackPACK, an efficient framework built on\ntop of PyTorch, that extends the backpropagation algorithm to extract\nadditional information from first- and second-order derivatives. Its\ncapabilities are illustrated by benchmark reports for computing additional\nquantities on deep neural networks, and an example application by testing\nseveral recent curvature approximations for optimization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 17:22:45 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 15:10:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Dangel", "Felix", ""], ["Kunstner", "Frederik", ""], ["Hennig", "Philipp", ""]]}, {"id": "1912.10994", "submitter": "Luca Magri", "authors": "Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri", "title": "A physics-aware machine to predict extreme events in turbulence", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-aware machine learning method to time-accurately predict\nextreme events in a turbulent flow. The method combines two radically different\napproaches: empirical modelling based on reservoir computing, which learns the\nchaotic dynamics from data only, and physical modelling based on conservation\nlaws. We show that the combination of the two approaches is able to predict the\noccurrence and amplitude of extreme events in the self-sustaining process in\nturbulence-the abrupt transitions from turbulent to quasi-laminar states-which\ncannot be achieved by using either approach separately. This opens up new\npossibilities for enhancing synergistically data-driven methods with physical\nknowledge for the accurate prediction of extreme events in chaotic dynamical\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 17:45:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Doan", "Nguyen Anh Khoa", ""], ["Polifke", "Wolfgang", ""], ["Magri", "Luca", ""]]}, {"id": "1912.11006", "submitter": "Gongfan Fang", "authors": "Gongfan Fang, Jie Song, Chengchao Shen, Xinchao Wang, Da Chen, Mingli\n  Song", "title": "Data-Free Adversarial Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) has made remarkable progress in the last few\nyears and become a popular paradigm for model compression and knowledge\ntransfer. However, almost all existing KD algorithms are data-driven, i.e.,\nrelying on a large amount of original training data or alternative data, which\nis usually unavailable in real-world scenarios. In this paper, we devote\nourselves to this challenging problem and propose a novel adversarial\ndistillation mechanism to craft a compact student model without any real-world\ndata. We introduce a model discrepancy to quantificationally measure the\ndifference between student and teacher models and construct an optimizable\nupper bound. In our work, the student and the teacher jointly act the role of\nthe discriminator to reduce this discrepancy, when a generator adversarially\nproduces some \"hard samples\" to enlarge it. Extensive experiments demonstrate\nthat the proposed data-free method yields comparable performance to existing\ndata-driven methods. More strikingly, our approach can be directly extended to\nsemantic segmentation, which is more complicated than classification, and our\napproach achieves state-of-the-art results. Code and pretrained models are\navailable at https://github.com/VainF/Data-Free-Adversarial-Distillation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:08:33 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 07:01:32 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 12:12:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Fang", "Gongfan", ""], ["Song", "Jie", ""], ["Shen", "Chengchao", ""], ["Wang", "Xinchao", ""], ["Chen", "Da", ""], ["Song", "Mingli", ""]]}, {"id": "1912.11023", "submitter": "James Ault", "authors": "James Ault, Josiah P. Hanna, Guni Sharon", "title": "Learning an Interpretable Traffic Signal Control Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signalized intersections are managed by controllers that assign right of way\n(green, yellow, and red lights) to non-conflicting directions. Optimizing the\nactuation policy of such controllers is expected to alleviate traffic\ncongestion and its adverse impact. Given such a safety-critical domain, the\naffiliated actuation policy is required to be interpretable in a way that can\nbe understood and regulated by a human. This paper presents and analyzes\nseveral on-line optimization techniques for tuning interpretable control\nfunctions. Although these techniques are defined in a general way, this paper\nassumes a specific class of interpretable control functions (polynomial\nfunctions) for analysis purposes. We show that such an interpretable policy\nfunction can be as effective as a deep neural network for approximating an\noptimized signal actuation policy. We present empirical evidence that supports\nthe use of value-based reinforcement learning for on-line training of the\ncontrol function. Specifically, we present and study three variants of the Deep\nQ-learning algorithm that allow the training of an interpretable policy\nfunction. Our Deep Regulatable Hardmax Q-learning variant is shown to be\nparticularly effective in optimizing our interpretable actuation policy,\nresulting in up to 19.4% reduced vehicles delay compared to commonly deployed\nactuated signal controllers.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:41:59 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:59:27 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ault", "James", ""], ["Hanna", "Josiah P.", ""], ["Sharon", "Guni", ""]]}, {"id": "1912.11027", "submitter": "William Lotter", "authors": "William Lotter, Abdul Rahman Diab, Bryan Haslam, Jiye G. Kim, Giorgia\n  Grisot, Eric Wu, Kevin Wu, Jorge Onieva Onieva, Jerrold L. Boxerman, Meiyun\n  Wang, Mack Bandler, Gopal Vijayaraghavan, A. Gregory Sorensen", "title": "Robust breast cancer detection in mammography and digital breast\n  tomosynthesis using annotation-efficient deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer remains a global challenge, causing over 1 million deaths\nglobally in 2018. To achieve earlier breast cancer detection, screening x-ray\nmammography is recommended by health organizations worldwide and has been\nestimated to decrease breast cancer mortality by 20-40%. Nevertheless,\nsignificant false positive and false negative rates, as well as high\ninterpretation costs, leave opportunities for improving quality and access. To\naddress these limitations, there has been much recent interest in applying deep\nlearning to mammography; however, obtaining large amounts of annotated data\nposes a challenge for training deep learning models for this purpose, as does\nensuring generalization beyond the populations represented in the training\ndataset. Here, we present an annotation-efficient deep learning approach that\n1) achieves state-of-the-art performance in mammogram classification, 2)\nsuccessfully extends to digital breast tomosynthesis (DBT; \"3D mammography\"),\n3) detects cancers in clinically-negative prior mammograms of cancer patients,\n4) generalizes well to a population with low screening rates, and 5)\noutperforms five-out-of-five full-time breast imaging specialists by improving\nabsolute sensitivity by an average of 14%. Our results demonstrate promise\ntowards software that can improve the accuracy of and access to screening\nmammography worldwide.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:45:04 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 18:26:52 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Lotter", "William", ""], ["Diab", "Abdul Rahman", ""], ["Haslam", "Bryan", ""], ["Kim", "Jiye G.", ""], ["Grisot", "Giorgia", ""], ["Wu", "Eric", ""], ["Wu", "Kevin", ""], ["Onieva", "Jorge Onieva", ""], ["Boxerman", "Jerrold L.", ""], ["Wang", "Meiyun", ""], ["Bandler", "Mack", ""], ["Vijayaraghavan", "Gopal", ""], ["Sorensen", "A. Gregory", ""]]}, {"id": "1912.11029", "submitter": "Panagiotis Tsilifis", "authors": "Panagiotis Tsilifis and Iason Papaioannou and Daniel Straub and Fabio\n  Nobile", "title": "Sparse Polynomial Chaos expansions using Variational Relevance Vector\n  Machines", "comments": "Submitted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109498", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenges for non-intrusive methods for Polynomial Chaos modeling lie in\nthe computational efficiency and accuracy under a limited number of model\nsimulations. These challenges can be addressed by enforcing sparsity in the\nseries representation through retaining only the most important basis terms. In\nthis work, we present a novel sparse Bayesian learning technique for obtaining\nsparse Polynomial Chaos expansions which is based on a Relevance Vector Machine\nmodel and is trained using Variational Inference. The methodology shows great\npotential in high-dimensional data-driven settings using relatively few data\npoints and achieves user-controlled sparse levels that are comparable to other\nmethods such as compressive sensing. The proposed approach is illustrated on\ntwo numerical examples, a synthetic response function that is explored for\nvalidation purposes and a low-carbon steel plate with random Young's modulus\nand random loading, which is modeled by stochastic finite element with 38 input\nrandom variables.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:49:55 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tsilifis", "Panagiotis", ""], ["Papaioannou", "Iason", ""], ["Straub", "Daniel", ""], ["Nobile", "Fabio", ""]]}, {"id": "1912.11032", "submitter": "Richard Li", "authors": "Richard Li, Allan Jabri, Trevor Darrell, Pulkit Agrawal", "title": "Towards Practical Multi-Object Manipulation using Relational\n  Reinforcement Learning", "comments": "10 pages, 4 figures and 1 table in main article, 3 figures and 3\n  tables in appendix. Supplementary website and videos at\n  https://richardrl.github.io/relational-rl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robotic manipulation tasks using reinforcement learning with sparse\nrewards is currently impractical due to the outrageous data requirements. Many\npractical tasks require manipulation of multiple objects, and the complexity of\nsuch tasks increases with the number of objects. Learning from a curriculum of\nincreasingly complex tasks appears to be a natural solution, but unfortunately,\ndoes not work for many scenarios. We hypothesize that the inability of the\nstate-of-the-art algorithms to effectively utilize a task curriculum stems from\nthe absence of inductive biases for transferring knowledge from simpler to\ncomplex tasks. We show that graph-based relational architectures overcome this\nlimitation and enable learning of complex tasks when provided with a simple\ncurriculum of tasks with increasing numbers of objects. We demonstrate the\nutility of our framework on a simulated block stacking task. Starting from\nscratch, our agent learns to stack six blocks into a tower. Despite using\nstep-wise sparse rewards, our method is orders of magnitude more data-efficient\nand outperforms the existing state-of-the-art method that utilizes human\ndemonstrations. Furthermore, the learned policy exhibits zero-shot\ngeneralization, successfully stacking blocks into taller towers and previously\nunseen configurations such as pyramids, without any further training.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:56:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Li", "Richard", ""], ["Jabri", "Allan", ""], ["Darrell", "Trevor", ""], ["Agrawal", "Pulkit", ""]]}, {"id": "1912.11037", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Gabriel Gagnon-Turcotte, Angkoon Phinyomark,\n  Kyrre Glette, Erik Scheme, Fran\\c{c}ois Laviolette and Benoit Gosselin", "title": "Unsupervised Domain Adversarial Self-Calibration for\n  Electromyographic-based Gesture Recognition", "comments": "12 pages + 2 pages appendices. The last three authors shared senior\n  authorship", "journal-ref": "in IEEE Access, vol. 8, pp. 177941-177955, 2020", "doi": "10.1109/ACCESS.2020.3027497", "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) provides an intuitive and non-invasive\ninterface from which to control machines. However, preserving the myoelectric\ncontrol system's performance over multiple days is challenging, due to the\ntransient nature of the signals obtained with this recording technique. In\npractice, if the system is to remain usable, a time-consuming and periodic\nrecalibration is necessary. In the case where the sEMG interface is employed\nevery few days, the user might need to do this recalibration before every use.\nThus, severely limiting the practicality of such a control method.\nConsequently, this paper proposes tackling the especially challenging task of\nunsupervised adaptation of sEMG signals, when multiple days have elapsed\nbetween each recording, by introducing Self-Calibrating Asynchronous Domain\nAdversarial Neural Network (SCADANN). SCADANN is compared with two\nstate-of-the-art self-calibrating algorithms developed specifically for deep\nlearning within the context of EMG-based gesture recognition and three\nstate-of-the-art domain adversarial algorithms. The comparison is made both on\nan offline and a dynamic dataset (20 participants per dataset), using two\ndifferent deep network architectures with two different input modalities\n(temporal-spatial descriptors and spectrograms). Overall, SCADANN is shown to\nsubstantially and systematically improves classification performances over no\nrecalibration and obtains the highest average accuracy for all tested cases\nacross all methods.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 17:42:26 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 10:42:32 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 11:23:49 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2020 14:29:07 GMT"}, {"version": "v5", "created": "Fri, 9 Oct 2020 15:09:27 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Gagnon-Turcotte", "Gabriel", ""], ["Phinyomark", "Angkoon", ""], ["Glette", "Kyrre", ""], ["Scheme", "Erik", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Gosselin", "Benoit", ""]]}, {"id": "1912.11040", "submitter": "Chanwoo Kim", "authors": "Chanwoo Kim, Sungsoo Kim, Kwangyoun Kim, Mehul Kumar, Jiyeon Kim,\n  Kyungmin Lee, Changwoo Han, Abhinav Garg, Eunhyang Kim, Minkyoo Shin,\n  Shatrughan Singh, Larry Heck, Dhananjaya Gowda", "title": "end-to-end training of a large vocabulary end-to-end speech recognition\n  system", "comments": "Accepted and presented at the ASRU 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an end-to-end training framework for building\nstate-of-the-art end-to-end speech recognition systems. Our training system\nutilizes a cluster of Central Processing Units(CPUs) and Graphics Processing\nUnits (GPUs). The entire data reading, large scale data augmentation, neural\nnetwork parameter updates are all performed \"on-the-fly\". We use vocal tract\nlength perturbation [1] and an acoustic simulator [2] for data augmentation.\nThe processed features and labels are sent to the GPU cluster. The Horovod\nallreduce approach is employed to train neural network parameters. We evaluated\nthe effectiveness of our system on the standard Librispeech corpus [3] and the\n10,000-hr anonymized Bixby English dataset. Our end-to-end speech recognition\nsystem built using this training infrastructure showed a 2.44 % WER on\ntest-clean of the LibriSpeech test set after applying shallow fusion with a\nTransformer language model (LM). For the proprietary English Bixby open domain\ntest set, we obtained a WER of 7.92 % using a Bidirectional Full Attention\n(BFA) end-to-end model after applying shallow fusion with an RNN-LM. When the\nmonotonic chunckwise attention (MoCha) based approach is employed for streaming\nspeech recognition, we obtained a WER of 9.95 % on the same Bixby open domain\ntest set.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 02:59:28 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Kim", "Chanwoo", ""], ["Kim", "Sungsoo", ""], ["Kim", "Kwangyoun", ""], ["Kumar", "Mehul", ""], ["Kim", "Jiyeon", ""], ["Lee", "Kyungmin", ""], ["Han", "Changwoo", ""], ["Garg", "Abhinav", ""], ["Kim", "Eunhyang", ""], ["Shin", "Minkyoo", ""], ["Singh", "Shatrughan", ""], ["Heck", "Larry", ""], ["Gowda", "Dhananjaya", ""]]}, {"id": "1912.11041", "submitter": "Chanwoo Kim", "authors": "Chanwoo Kim, Mehul Kumar, Kwangyoun Kim, and Dhananjaya Gowda", "title": "power-law nonlinearity with maximally uniform distribution criterion for\n  improved neural network training in automatic speech recognition", "comments": "Accepted and presented at the ASRU 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the Maximum Uniformity of Distribution (MUD)\nalgorithm with the power-law nonlinearity. In this approach, we hypothesize\nthat neural network training will become more stable if feature distribution is\nnot too much skewed. We propose two different types of MUD approaches: power\nfunction-based MUD and histogram-based MUD. In these approaches, we first\nobtain the mel filterbank coefficients and apply nonlinearity functions for\neach filterbank channel. With the power function-based MUD, we apply a\npower-function based nonlinearity where power function coefficients are chosen\nto maximize the likelihood assuming that nonlinearity outputs follow the\nuniform distribution. With the histogram-based MUD, the empirical Cumulative\nDensity Function (CDF) from the training database is employed to transform the\noriginal distribution into a uniform distribution. In MUD processing, we do not\nuse any prior knowledge (e.g. logarithmic relation) about the energy of the\nincoming signal and the perceived intensity by a human. Experimental results\nusing an end-to-end speech recognition system demonstrate that power-function\nbased MUD shows better result than the conventional Mel Filterbank Cepstral\nCoefficients (MFCCs). On the LibriSpeech database, we could achieve 4.02 % WER\non test-clean and 13.34 % WER on test-other without using any Language Models\n(LMs). The major contribution of this work is that we developed a new algorithm\nfor designing the compressive nonlinearity in a data-driven way, which is much\nmore flexible than the previous approaches and may be extended to other domains\nas well.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 04:40:40 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Kim", "Chanwoo", ""], ["Kumar", "Mehul", ""], ["Kim", "Kwangyoun", ""], ["Gowda", "Dhananjaya", ""]]}, {"id": "1912.11077", "submitter": "Olivier Delalleau", "authors": "Olivier Delalleau, Maxim Peter, Eloi Alonso, Adrien Logut", "title": "Discrete and Continuous Action Representation for Practical RL in Video\n  Games", "comments": "Presented at the AAAI-20 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most current research in Reinforcement Learning (RL) focuses on\nimproving the performance of the algorithms in controlled environments, the use\nof RL under constraints like those met in the video game industry is rarely\nstudied. Operating under such constraints, we propose Hybrid SAC, an extension\nof the Soft Actor-Critic algorithm able to handle discrete, continuous and\nparameterized actions in a principled way. We show that Hybrid SAC can\nsuccessfully solve a highspeed driving task in one of our games, and is\ncompetitive with the state-of-the-art on parameterized actions benchmark tasks.\nWe also explore the impact of using normalizing flows to enrich the\nexpressiveness of the policy at minimal computational cost, and identify a\npotential undesired effect of SAC when used with normalizing flows, that may be\naddressed by optimizing a different objective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:37:13 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Delalleau", "Olivier", ""], ["Peter", "Maxim", ""], ["Alonso", "Eloi", ""], ["Logut", "Adrien", ""]]}, {"id": "1912.11078", "submitter": "Deven Santosh Shah", "authors": "Deven Shah, H. Andrew Schwartz, Dirk Hovy", "title": "Predictive Biases in Natural Language Processing Models: A Conceptual\n  Framework and Overview", "comments": "9 pages excluding references, 1 figure, 3 pages for appendix", "journal-ref": "Association for Computational Linguistics. (2020) 5248--5264", "doi": "10.18653/v1/2020.acl-main.468", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of works in natural language processing have addressed\nthe effect of bias on the predicted outcomes, introducing mitigation techniques\nthat act on different parts of the standard NLP pipeline (data and models).\nHowever, these works have been conducted in isolation, without a unifying\nframework to organize efforts within the field. This leads to repetitive\napproaches, and puts an undue focus on the effects of bias, rather than on\ntheir origins. Research focused on bias symptoms rather than the underlying\norigins could limit the development of effective countermeasures. In this\npaper, we propose a unifying conceptualization: the predictive bias framework\nfor NLP. We summarize the NLP literature and propose a general mathematical\ndefinition of predictive bias in NLP along with a conceptual framework,\ndifferentiating four main origins of biases: label bias, selection bias, model\noveramplification, and semantic bias. We discuss how past work has countered\neach bias origin. Our framework serves to guide an introductory overview of\npredictive bias in NLP, integrating existing work into a single structure and\nopening avenues for future research.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 23:53:19 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 19:56:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shah", "Deven", ""], ["Schwartz", "H. Andrew", ""], ["Hovy", "Dirk", ""]]}, {"id": "1912.11082", "submitter": "Xinsheng Xuan", "authors": "Xinsheng Xuan, Bo Peng, Wei Wang and Jing Dong", "title": "Scalable Fine-grained Generated Image Classification Based on Deep\n  Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, generated images could reach very high quality, even human eyes\ncould not tell them apart from real images. Although there are already some\nmethods for detecting generated images in current forensic community, most of\nthese methods are used to detect a single type of generated images. The new\ntypes of generated images are emerging one after another, and the existing\ndetection methods cannot cope well. These problems prompted us to propose a\nscalable framework for multi-class classification based on deep metric\nlearning, which aims to classify the generated images finer. In addition, we\nhave increased the scalability of our framework to cope with the constant\nemergence of new types of generated images, and through fine-tuning to make the\nmodel obtain better detection performance on the new type of generated data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 08:19:37 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Xuan", "Xinsheng", ""], ["Peng", "Bo", ""], ["Wang", "Wei", ""], ["Dong", "Jing", ""]]}, {"id": "1912.11084", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli", "title": "Where Are We? Using Scopus to Map the Literature at the Intersection\n  Between Artificial Intelligence and Research on Crime", "comments": "25 pages, 12 figures, pre-print (currently R&R in JCSS)", "journal-ref": "J Comput Soc Sc (2020)", "doi": "10.1007/s42001-020-00082-9", "report-no": null, "categories": "cs.DL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research on Artificial Intelligence (AI) applications has spread over many\nscientific disciplines. Scientists have tested the power of intelligent\nalgorithms developed to predict (or learn from) natural, physical and social\nphenomena. This also applies to crime-related research problems. Nonetheless,\nstudies that map the current state of the art at the intersection between AI\nand crime are lacking. What are the current research trends in terms of topics\nin this area? What is the structure of scientific collaboration when\nconsidering works investigating criminal issues using machine learning, deep\nlearning, and AI in general? What are the most active countries in this\nspecific scientific sphere? Using data retrieved from the Scopus database, this\nwork quantitatively analyzes 692 published works at the intersection between AI\nand crime employing network science to respond to these questions. Results show\nthat researchers are mainly focusing on cyber-related criminal topics and that\nrelevant themes such as algorithmic discrimination, fairness, and ethics are\nconsiderably overlooked. Furthermore, data highlight the extremely disconnected\nstructure of co-authorship networks. Such disconnectedness may represent a\nsubstantial obstacle to a more solid community of scientists interested in\nthese topics. Additionally, the graph of scientific collaboration indicates\nthat countries that are more prone to engage in international partnerships are\ngenerally less central in the network. This means that scholars working in\nhighly productive countries (e.g. the United States, China) tend to mostly\ncollaborate domestically. Finally, current issues and future developments\nwithin this scientific area are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:55:52 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 23:23:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Campedelli", "Gian Maria", ""]]}, {"id": "1912.11090", "submitter": "Matti Lassas j", "authors": "Maarten V. de Hoop, Matti Lassas, Christopher A. Wong", "title": "Deep learning architectures for nonlinear operator functions and\n  nonlinear inverse problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theoretical analysis for special neural network architectures,\ntermed operator recurrent neural networks, for approximating highly nonlinear\nfunctions whose inputs are linear operators. Such functions commonly arise in\nsolution algorithms for inverse problems for the wave equation. Traditional\nneural networks treat input data as vectors, and thus they do not effectively\ncapture the multiplicative structure associated with the linear operators that\ncorrespond to the measurement data in such inverse problems. We therefore\nintroduce a new parametric family that resembles a standard neural network\narchitecture, but where the input data acts multiplicatively on vectors.\nMotivated by compact operators appearing in boundary control and the analysis\nof inverse boundary value problems for the wave equation, we promote structure\nand sparsity in selected weight matrices in the network. After describing this\narchitecture, we study its representation properties as well as its\napproximation properties. We furthermore show that an explicit regularization\ncan be introduced that can be derived from the mathematical analysis of the\nmentioned inverse problems, and which leads to some guarantees on the\ngeneralization properties. We observe that the sparsity of the weight matrices\nimproves the generalization estimates. Lastly, we discuss how operator\nrecurrent networks can be viewed as a deep learning analogue to deterministic\nalgorithms such as boundary control for reconstructing the unknown wavespeed in\nthe acoustic wave equation from boundary measurements.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 20:05:47 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 18:20:08 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["de Hoop", "Maarten V.", ""], ["Lassas", "Matti", ""], ["Wong", "Christopher A.", ""]]}, {"id": "1912.11095", "submitter": "P. M. Krafft", "authors": "P. M. Krafft, Meg Young, Michael Katell, Karen Huang, Ghislain Bugingo", "title": "Defining AI in Policy versus Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent concern about harms of information technologies motivate consideration\nof regulatory action to forestall or constrain certain developments in the\nfield of artificial intelligence (AI). However, definitional ambiguity hampers\nthe possibility of conversation about this urgent topic of public concern.\nLegal and regulatory interventions require agreed-upon definitions, but\nconsensus around a definition of AI has been elusive, especially in policy\nconversations. With an eye towards practical working definitions and a broader\nunderstanding of positions on these issues, we survey experts and review\npublished policy documents to examine researcher and policy-maker conceptions\nof AI. We find that while AI researchers favor definitions of AI that emphasize\ntechnical functionality, policy-makers instead use definitions that compare\nsystems to human thinking and behavior. We point out that definitions adhering\nclosely to the functionality of AI systems are more inclusive of technologies\nin use today, whereas definitions that emphasize human-like capabilities are\nmost applicable to hypothetical future technologies. As a result of this gap,\nethical and regulatory efforts may overemphasize concern about future\ntechnologies at the expense of pressing issues with existing deployed\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 20:18:21 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Krafft", "P. M.", ""], ["Young", "Meg", ""], ["Katell", "Michael", ""], ["Huang", "Karen", ""], ["Bugingo", "Ghislain", ""]]}, {"id": "1912.11113", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren and Hao Zhu and Jiawei Zhang and Peng Dai and Liefeng Bo", "title": "EnsemFDet: An Ensemble Approach to Fraud Detection based on Bipartite\n  Graph", "comments": "Accepted by ICDE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection is extremely critical for e-commerce business. It is the\nintent of the companies to detect and prevent fraud as early as possible.\nExisting fraud detection methods try to identify unexpected dense subgraphs and\ntreat related nodes as suspicious. Spectral relaxation-based methods solve the\nproblem efficiently but hurt the performance due to the relaxed constraints.\nBesides, many methods cannot be accelerated with parallel computation or\ncontrol the number of returned suspicious nodes because they provide a set of\nsubgraphs with diverse node sizes. These drawbacks affect the real-world\napplications of existing methods. In this paper, we propose an Ensemble-based\nFraud Detection (EnsemFDet) method to scale up fraud detection in bipartite\ngraphs by decomposing the original problem into subproblems on small-sized\nsubgraphs. By oversampling the graph and solving the subproblems, the ensemble\napproach further votes suspicious nodes without sacrificing the prediction\naccuracy. Extensive experiments have been done on real transaction data from\nJD.com, which is one of the world's largest e-commerce platforms. Experimental\nresults demonstrate the effectiveness, practicability, and scalability of\nEnsemFDet. More specifically, EnsemFDet is up to 100x faster than the\nstate-of-the-art methods due to its parallelism with all aspects of data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 21:19:41 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:44:28 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 06:29:03 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 00:46:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ren", "Yuxiang", ""], ["Zhu", "Hao", ""], ["Zhang", "Jiawei", ""], ["Dai", "Peng", ""], ["Bo", "Liefeng", ""]]}, {"id": "1912.11114", "submitter": "Jiayang Xu", "authors": "Jiayang Xu, Karthik Duraisamy", "title": "Multi-level Convolutional Autoencoder Networks for Parametric Prediction\n  of Spatio-temporal Dynamics", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113379", "report-no": null, "categories": "physics.comp-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data-driven framework is proposed towards the end of predictive modeling of\ncomplex spatio-temporal dynamics, leveraging nested non-linear manifolds. Three\nlevels of neural networks are used, with the goal of predicting the future\nstate of a system of interest in a parametric setting. A convolutional\nautoencoder is used as the top level to encode the high dimensional input data\nalong spatial dimensions into a sequence of latent variables. A temporal\nconvolutional autoencoder (TCAE) serves as the second level, which further\nencodes the output sequence from the first level along the temporal dimension,\nand outputs a set of latent variables that encapsulate the spatio-temporal\nevolution of the dynamics. The use of dilated temporal convolutions grows the\nreceptive field exponentially with network depth, allowing for efficient\nprocessing of long temporal sequences typical of scientific computations. A\nfully-connected network is used as the third level to learn the mapping between\nthese latent variables and the global parameters from training data, and\npredict them for new parameters. For future state predictions, the second level\nuses a temporal convolutional network to predict subsequent steps of the output\nsequence from the top level. Latent variables at the bottom-most level are\ndecoded to obtain the dynamics in physical space at new global parameters\nand/or at a future time. Predictive capabilities are evaluated on a range of\nproblems involving discontinuities, wave propagation, strong transients, and\ncoherent structures. The sensitivity of the results to different modeling\nchoices is assessed. The results suggest that given adequate data and careful\ntraining, effective data-driven predictive models can be constructed.\nPerspectives are provided on the present approach and its place in the\nlandscape of model reduction.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 21:21:52 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 16:08:12 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Xu", "Jiayang", ""], ["Duraisamy", "Karthik", ""]]}, {"id": "1912.11121", "submitter": "Alexander Sax", "authors": "Alexander Sax, Jeffrey O. Zhang, Bradley Emi, Amir Zamir, Silvio\n  Savarese, Leonidas Guibas, Jitendra Malik", "title": "Learning to Navigate Using Mid-Level Visual Priors", "comments": "In Conference on Robot Learning, 2019. See project website and demos\n  at http://perceptual.actor/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much does having visual priors about the world (e.g. the fact that the\nworld is 3D) assist in learning to perform downstream motor tasks (e.g.\nnavigating a complex environment)? What are the consequences of not utilizing\nsuch visual priors in learning? We study these questions by integrating a\ngeneric perceptual skill set (a distance estimator, an edge detector, etc.)\nwithin a reinforcement learning framework (see Fig. 1). This skill set\n(\"mid-level vision\") provides the policy with a more processed state of the\nworld compared to raw images.\n  Our large-scale study demonstrates that using mid-level vision results in\npolicies that learn faster, generalize better, and achieve higher final\nperformance, when compared to learning from scratch and/or using\nstate-of-the-art visual and non-visual representation learning methods. We show\nthat conventional computer vision objectives are particularly effective in this\nregard and can be conveniently integrated into reinforcement learning\nframeworks. Finally, we found that no single visual representation was\nuniversally useful for all downstream tasks, hence we computationally derive a\ntask-agnostic set of representations optimized to support arbitrary downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 21:45:50 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Sax", "Alexander", ""], ["Zhang", "Jeffrey O.", ""], ["Emi", "Bradley", ""], ["Zamir", "Amir", ""], ["Savarese", "Silvio", ""], ["Guibas", "Leonidas", ""], ["Malik", "Jitendra", ""]]}, {"id": "1912.11123", "submitter": "Ming Zhong", "authors": "Mauro Maggioni, Jason Miller, Ming Zhong", "title": "Data-driven Discovery of Emergent Behaviors in Collective Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle- and agent-based systems are a ubiquitous modeling tool in many\ndisciplines. We consider the fundamental problem of inferring interaction\nkernels from observations of agent-based dynamical systems given observations\nof trajectories, in particular for collective dynamical systems exhibiting\nemergent behaviors with complicated interaction kernels, in a nonparametric\nfashion, and for kernels which are parametrized by a single unknown parameter.\nWe extend the estimators introduced in \\cite{PNASLU}, which are based on\nsuitably regularized least squares estimators, to these larger classes of\nsystems. We provide extensive numerical evidence that the estimators provide\nfaithful approximations to the interaction kernels, and provide accurate\npredictions for trajectories started at new initial conditions, both throughout\nthe ``training'' time interval in which the observations were made, and often\nmuch beyond. We demonstrate these features on prototypical systems displaying\ncollective behaviors, ranging from opinion dynamics, flocking dynamics,\nself-propelling particle dynamics, synchronized oscillator dynamics, and a\ngravitational system. Our experiments also suggest that our estimated systems\ncan display the same emergent behaviors of the observed systems, that occur at\nlarger timescales than those used in the training data. Finally, in the case of\nfamilies of systems governed by a parameterized family of interaction kernels,\nwe introduce novel estimators that estimate the parameterized family of\nkernels, splitting it into a common interaction kernel and the action of\nparameters. We demonstrate this in the case of gravity, by learning both the\n``common component'' $1/r^2$ and the dependency on mass, without any a priori\nknowledge of either one, from observations of planetary motions in our solar\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 21:54:48 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 20:51:55 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Maggioni", "Mauro", ""], ["Miller", "Jason", ""], ["Zhong", "Ming", ""]]}, {"id": "1912.11136", "submitter": "Matteo Maspero", "authors": "Matteo Maspero, Mark HF Savenije, Tristan CF van Heijst, Joost JC\n  Verhoeff, Alexis NTJ Kotte, Anette C Houweling, Cornelis AT van den Berg", "title": "CBCT-to-CT synthesis with a single neural network for head-and-neck,\n  lung and breast cancer adaptive radiotherapy", "comments": "Submitted to Medical Physics; 2019-12-23", "journal-ref": "Physics and Imaging in Radiation Oncology Volume 14, April 2020,\n  Pages 24-31", "doi": "10.1016/j.phro.2020.04.002", "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: CBCT-based adaptive radiotherapy requires daily images for accurate\ndose calculations. This study investigates the feasibility of applying a single\nconvolutional network to facilitate CBCT-to-CT synthesis for head-and-neck,\nlung, and breast cancer patients. Methods: Ninety-nine patients diagnosed with\nhead-and-neck, lung or breast cancer undergoing radiotherapy with CBCT-based\nposition verification were included in this study. CBCTs were registered to\nplanning CTs according to clinical procedures. Three cycle-consistent\ngenerative adversarial networks (cycle-GANs) were trained in an unpaired manner\non 15 patients per anatomical site generating synthetic-CTs (sCTs). Another\nnetwork was trained with all the anatomical sites together. Performances of all\nfour networks were compared and evaluated for image similarity against rescan\nCT (rCT). Clinical plans were recalculated on CT and sCT and analysed through\nvoxel-based dose differences and {\\gamma}-analysis. Results: A sCT was\ngenerated in 10 seconds. Image similarity was comparable between models trained\non different anatomical sites and a single model for all sites. Mean dose\ndifferences < 0.5% were obtained in high-dose regions. Mean gamma (2%,2mm)\npass-rates > 95% were achieved for all sites. Conclusions: Cycle-GAN reduced\nCBCT artefacts and increased HU similarity to CT, enabling sCT-based dose\ncalculations. The speed of the network can facilitate on-line adaptive\nradiotherapy using a single network for head-and-neck, lung and breast cancer\npatients.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 23:05:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Maspero", "Matteo", ""], ["Savenije", "Mark HF", ""], ["van Heijst", "Tristan CF", ""], ["Verhoeff", "Joost JC", ""], ["Kotte", "Alexis NTJ", ""], ["Houweling", "Anette C", ""], ["Berg", "Cornelis AT van den", ""]]}, {"id": "1912.11141", "submitter": "Matthias Karlbauer", "authors": "Matthias Karlbauer, Sebastian Otte, Hendrik P.A. Lensch, Thomas\n  Scholten, Volker Wulfmeyer, and Martin V. Butz", "title": "A Distributed Neural Network Architecture for Robust Non-Linear\n  Spatio-Temporal Prediction", "comments": "8 pages, 4 figures, video on\n  https://www.youtube.com/watch?v=4VHhHYeWTzo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a distributed spatio-temporal artificial neural network\narchitecture (DISTANA). It encodes mesh nodes using recurrent, neural\nprediction kernels (PKs), while neural transition kernels (TKs) transfer\ninformation between neighboring PKs, together modeling and predicting\nspatio-temporal time series dynamics. As a consequence, DISTANA assumes that\ngenerally applicable causes, which may be locally modified, generate the\nobserved data. DISTANA learns in a parallel, spatially distributed manner,\nscales to large problem spaces, is capable of approximating complex dynamics,\nand is particularly robust to overfitting when compared to other competitive\nANN models. Moreover, it is applicable to heterogeneously structured meshes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 23:15:17 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Karlbauer", "Matthias", ""], ["Otte", "Sebastian", ""], ["Lensch", "Hendrik P. A.", ""], ["Scholten", "Thomas", ""], ["Wulfmeyer", "Volker", ""], ["Butz", "Martin V.", ""]]}, {"id": "1912.11146", "submitter": "Evangelos Papapetrou", "authors": "Evangelos Papapetrou and Aristidis Likas", "title": "A Replication Strategy for Mobile Opportunistic Networks based on\n  Utility Clustering", "comments": "16 pages, 17 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic replication is a wide-spread multi-copy routing approach for\nefficiently coping with the intermittent connectivity in mobile opportunistic\nnetworks. According to it, a node forwards a message replica to an encountered\nnode based on a utility value that captures the latter's fitness for delivering\nthe message to the destination. The popularity of the approach stems from its\nflexibility to effectively operate in networks with diverse characteristics\nwithout requiring special customization. Nonetheless, its drawback is the\ntendency to produce a high number of replicas that consume limited resources\nsuch as energy and storage. To tackle the problem we make the observation that\nnetwork nodes can be grouped, based on their utility values, into clusters that\nportray different delivery capabilities. We exploit this finding to transform\nthe basic forwarding strategy, which is to move a packet using nodes of\nincreasing utility, and actually forward it through clusters of increasing\ndelivery capability. The new strategy works in synergy with the basic dynamic\nreplication algorithms and is fully configurable, in the sense that it can be\nused with virtually any utility function. We also extend our approach to work\nwith two utility functions at the same time, a feature that is especially\nefficient in mobile networks that exhibit social characteristics. By conducting\nexperiments in a wide set of real-life networks, we empirically show that our\nmethod is robust in reducing the overall number of replicas in networks with\ndiverse connectivity characteristics without at the same time hindering\ndelivery efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 23:46:54 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Papapetrou", "Evangelos", ""], ["Likas", "Aristidis", ""]]}, {"id": "1912.11160", "submitter": "Ilya Shenbin", "authors": "Ilya Shenbin, Anton Alekseev, Elena Tutubalina, Valentin Malykh,\n  Sergey I. Nikolenko", "title": "RecVAE: a New Variational Autoencoder for Top-N Recommendations with\n  Implicit Feedback", "comments": "In The Thirteenth ACM International Conference on Web Search and Data\n  Mining (WSDM '20), February 3-7, 2020, Houston, TX, USA. ACM, New York, NY,\n  USA, 9 pages", "journal-ref": null, "doi": "10.1145/3336191.3371831", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown the advantages of using autoencoders based on deep\nneural networks for collaborative filtering. In particular, the recently\nproposed Mult-VAE model, which used the multinomial likelihood variational\nautoencoders, has shown excellent results for top-N recommendations. In this\nwork, we propose the Recommender VAE (RecVAE) model that originates from our\nresearch on regularization techniques for variational autoencoders. RecVAE\nintroduces several novel ideas to improve Mult-VAE, including a novel composite\nprior distribution for the latent codes, a new approach to setting the $\\beta$\nhyperparameter for the $\\beta$-VAE framework, and a new approach to training\nbased on alternating updates. In experimental evaluation, we show that RecVAE\nsignificantly outperforms previously proposed autoencoder-based models,\nincluding Mult-VAE and RaCT, across classical collaborative filtering datasets,\nand present a detailed ablation study to assess our new developments. Code and\nmodels are available at https://github.com/ilya-shenbin/RecVAE.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 01:07:08 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Shenbin", "Ilya", ""], ["Alekseev", "Anton", ""], ["Tutubalina", "Elena", ""], ["Malykh", "Valentin", ""], ["Nikolenko", "Sergey I.", ""]]}, {"id": "1912.11165", "submitter": "S. Mohammad Mirbagheri", "authors": "S. Mohammad Mirbagheri, Howard J. Hamilton", "title": "High Utility Interval-Based Sequences", "comments": "To appear in Proceedings of the 22nd International Conference on Big\n  Data Analytics and Knowledge Discovery (DaWaK2020), Bratislava, Slovakia,\n  September 14-17. Springer, 2020", "journal-ref": "22nd International Conference on Big Data Analytics and Knowledge\n  Discovery (DaWaK2020), Bratislava, Slovakia, September 14-17, 2020. Springer,\n  Cham", "doi": "10.1007/978-3-030-59065-9_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential pattern mining is an interesting research area with broad range of\napplications. Most prior research on sequential pattern mining has considered\npoint-based data where events occur instantaneously. However, in many\napplication domains, events persist over intervals of time of varying lengths.\nFurthermore, traditional frameworks for sequential pattern mining assume all\nevents have the same weight or utility. This simplifying assumption neglects\nthe opportunity to find informative patterns in terms of utilities, such as\ncost. To address these issues, we incorporate the concept of utility into\ninterval-based sequences and define a framework to mine high utility patterns\nin interval-based sequences i.e., patterns whose utility meets or exceeds a\nminimum threshold. In the proposed framework, the utility of events is\nconsidered while assuming multiple events can occur coincidentally and persist\nover varying periods of time. An algorithm named High Utility Interval-based\nPattern Miner (HUIPMiner) is proposed and applied to real datasets. To achieve\nan efficient solution, HUIPMiner is augmented with a pruning strategy.\nExperimental results show that HUIPMiner is an effective solution to the\nproblem of mining high utility interval-based sequences.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 01:19:04 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 16:45:36 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mirbagheri", "S. Mohammad", ""], ["Hamilton", "Howard J.", ""]]}, {"id": "1912.11176", "submitter": "Jie Chen", "authors": "Tengfei Ma, Jie Chen", "title": "Unsupervised Learning of Graph Hierarchical Abstractions with\n  Differentiable Coarsening and Optimal Transport", "comments": "AAAI 2021. Code is available at\n  https://github.com/matenure/OTCoarsening", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical abstractions are a methodology for solving large-scale graph\nproblems in various disciplines. Coarsening is one such approach: it generates\na pyramid of graphs whereby the one in the next level is a structural summary\nof the prior one. With a long history in scientific computing, many coarsening\nstrategies were developed based on mathematically driven heuristics. Recently,\nresurgent interests exist in deep learning to design hierarchical methods\nlearnable through differentiable parameterization. These approaches are paired\nwith downstream tasks for supervised learning. In practice, however, supervised\nsignals (e.g., labels) are scarce and are often laborious to obtain. In this\nwork, we propose an unsupervised approach, coined OTCoarsening, with the use of\noptimal transport. Both the coarsening matrix and the transport cost matrix are\nparameterized, so that an optimal coarsening strategy can be learned and\ntailored for a given set of graphs. We demonstrate that the proposed approach\nproduces meaningful coarse graphs and yields competitive performance compared\nwith supervised methods for graph classification and regression.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 02:40:32 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 20:04:15 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ma", "Tengfei", ""], ["Chen", "Jie", ""]]}, {"id": "1912.11187", "submitter": "Yan Kang", "authors": "Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian\n  Chen, Mingyi Hong, Qiang Yang", "title": "A Communication Efficient Collaborative Learning Framework for\n  Distributed Features", "comments": "This paper is published at the 2nd International Workshop on\n  Federated Learning for Data Privacy and Confidentiality, in Conjunction with\n  NeurIPS 2019 (FL-NeurIPS 19):\n  https://nips.cc/Conferences/2019/ScheduleMultitrack?event=13202", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a collaborative learning framework allowing multiple parties\nhaving different sets of attributes about the same user to jointly build models\nwithout exposing their raw data or model parameters. In particular, we propose\na Federated Stochastic Block Coordinate Descent (FedBCD) algorithm, in which\neach party conducts multiple local updates before each communication to\neffectively reduce the number of communication rounds among parties, a\nprincipal bottleneck for collaborative learning problems. We analyze\ntheoretically the impact of the number of local updates and show that when the\nbatch size, sample size, and the local iterations are selected appropriately,\nwithin $T$ iterations, the algorithm performs $\\mathcal{O}(\\sqrt{T})$\ncommunication rounds and achieves some $\\mathcal{O}(1/\\sqrt{T})$ accuracy\n(measured by the average of the gradient norm squared). The approach is\nsupported by our empirical evaluations on a variety of tasks and datasets,\ndemonstrating advantages over stochastic gradient descent (SGD) approaches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:08:55 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 05:53:13 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 05:27:34 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 02:37:02 GMT"}, {"version": "v5", "created": "Wed, 24 Jun 2020 05:51:41 GMT"}, {"version": "v6", "created": "Fri, 31 Jul 2020 13:28:34 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Liu", "Yang", ""], ["Kang", "Yan", ""], ["Zhang", "Xinwei", ""], ["Li", "Liping", ""], ["Cheng", "Yong", ""], ["Chen", "Tianjian", ""], ["Hong", "Mingyi", ""], ["Yang", "Qiang", ""]]}, {"id": "1912.11188", "submitter": "Zhao Zhong", "authors": "Xinyu Zhang, Qiang Wang, Jian Zhang, Zhao Zhong", "title": "Adversarial AutoAugment", "comments": "ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation (DA) has been widely utilized to improve generalization in\ntraining deep neural networks. Recently, human-designed data augmentation has\nbeen gradually replaced by automatically learned augmentation policy. Through\nfinding the best policy in well-designed search space of data augmentation,\nAutoAugment can significantly improve validation accuracy on image\nclassification tasks. However, this approach is not computationally practical\nfor large-scale problems. In this paper, we develop an adversarial method to\narrive at a computationally-affordable solution called Adversarial AutoAugment,\nwhich can simultaneously optimize target related object and augmentation policy\nsearch loss. The augmentation policy network attempts to increase the training\nloss of a target network through generating adversarial augmentation policies,\nwhile the target network can learn more robust features from harder examples to\nimprove the generalization. In contrast to prior work, we reuse the computation\nin target network training for policy evaluation, and dispense with the\nretraining of the target network. Compared to AutoAugment, this leads to about\n12x reduction in computing cost and 11x shortening in time overhead on\nImageNet. We show experimental results of our approach on CIFAR-10/CIFAR-100,\nImageNet, and demonstrate significant performance improvements over\nstate-of-the-art. On CIFAR-10, we achieve a top-1 test error of 1.36%, which is\nthe currently best performing single model. On ImageNet, we achieve a leading\nperformance of top-1 accuracy 79.40% on ResNet-50 and 80.00% on ResNet-50-D\nwithout extra data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:17:17 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Zhang", "Xinyu", ""], ["Wang", "Qiang", ""], ["Zhang", "Jian", ""], ["Zhong", "Zhao", ""]]}, {"id": "1912.11191", "submitter": "Zhao Zhong", "authors": "Muyuan Fang, Qiang Wang, Zhao Zhong", "title": "BETANAS: BalancEd TrAining and selective drop for Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic neural architecture search techniques are becoming increasingly\nimportant in machine learning area. Especially, weight sharing methods have\nshown remarkable potentials on searching good network architectures with few\ncomputational resources. However, existing weight sharing methods mainly suffer\nlimitations on searching strategies: these methods either uniformly train all\nnetwork paths to convergence which introduces conflicts between branches and\nwastes a large amount of computation on unpromising candidates, or selectively\ntrain branches with different frequency which leads to unfair evaluation and\ncomparison among paths. To address these issues, we propose a novel neural\narchitecture search method with balanced training strategy to ensure fair\ncomparisons and a selective drop mechanism to reduce conflicts among candidate\npaths. The experimental results show that our proposed method can achieve a\nleading performance of 79.0% on ImageNet under mobile settings, which\noutperforms other state-of-the-art methods in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:24:06 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Fang", "Muyuan", ""], ["Wang", "Qiang", ""], ["Zhong", "Zhao", ""]]}, {"id": "1912.11193", "submitter": "Wanli Shi", "authors": "Wanli Shi, Bin Gu, Xinag Li, Heng Huang", "title": "Quadruply Stochastic Gradient Method for Large Scale Nonlinear\n  Semi-Supervised Ordinal Regression AUC Optimization", "comments": "12 pages, 9 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised ordinal regression (S$^2$OR) problems are ubiquitous in\nreal-world applications, where only a few ordered instances are labeled and\nmassive instances remain unlabeled. Recent researches have shown that directly\noptimizing concordance index or AUC can impose a better ranking on the data\nthan optimizing the traditional error rate in ordinal regression (OR) problems.\nIn this paper, we propose an unbiased objective function for S$^2$OR AUC\noptimization based on ordinal binary decomposition approach. Besides, to handle\nthe large-scale kernelized learning problems, we propose a scalable algorithm\ncalled QS$^3$ORAO using the doubly stochastic gradients (DSG) framework for\nfunctional optimization. Theoretically, we prove that our method can converge\nto the optimal solution at the rate of $O(1/t)$, where $t$ is the number of\niterations for stochastic data sampling. Extensive experimental results on\nvarious benchmark and real-world datasets also demonstrate that our method is\nefficient and effective while retaining similar generalization performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:45:24 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Shi", "Wanli", ""], ["Gu", "Bin", ""], ["Li", "Xinag", ""], ["Huang", "Heng", ""]]}, {"id": "1912.11194", "submitter": "Qi Qi", "authors": "Qi Qi, Yan Yan, Xiaoyu Wang, Tianbao Yang", "title": "A Simple and Effective Framework for Pairwise Deep Metric Learning", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning (DML) has received much attention in deep learning due\nto its wide applications in computer vision. Previous studies have focused on\ndesigning complicated losses and hard example mining methods, which are mostly\nheuristic and lack of theoretical understanding. In this paper, we cast DML as\na simple pairwise binary classification problem that classifies a pair of\nexamples as similar or dissimilar. It identifies the most critical issue in\nthis problem--imbalanced data pairs. To tackle this issue, we propose a simple\nand effective framework to sample pairs in a batch of data for updating the\nmodel. The key to this framework is to define a robust loss for all pairs over\na mini-batch of data, which is formulated by distributionally robust\noptimization. The flexibility in constructing the uncertainty decision set of\nthe dual variable allows us to recover state-of-the-art complicated losses and\nalso to induce novel variants. Empirical studies on several benchmark data sets\ndemonstrate that our simple and effective method outperforms the\nstate-of-the-art results. Codes are available at:\nhttps://github.com/qiqi-helloworld/A-Simple-and-Effective-Framework-for-Pairewise-Distance-Metric-Learning\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 03:47:25 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 15:58:11 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:44:21 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Qi", "Qi", ""], ["Yan", "Yan", ""], ["Wang", "Xiaoyu", ""], ["Yang", "Tianbao", ""]]}, {"id": "1912.11206", "submitter": "Chenjun Xiao", "authors": "Chenjun Xiao, Yifan Wu, Chen Ma, Dale Schuurmans and Martin M\\\"uller", "title": "Learning to Combat Compounding-Error in Model-Based Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its potential to improve sample complexity versus model-free\napproaches, model-based reinforcement learning can fail catastrophically if the\nmodel is inaccurate. An algorithm should ideally be able to trust an imperfect\nmodel over a reasonably long planning horizon, and only rely on model-free\nupdates when the model errors get infeasibly large. In this paper, we\ninvestigate techniques for choosing the planning horizon on a state-dependent\nbasis, where a state's planning horizon is determined by the maximum cumulative\nmodel error around that state. We demonstrate that these state-dependent model\nerrors can be learned with Temporal Difference methods, based on a novel\napproach of temporally decomposing the cumulative model errors. Experimental\nresults show that the proposed method can successfully adapt the planning\nhorizon to account for state-dependent model accuracy, significantly improving\nthe efficiency of policy learning compared to model-based and model-free\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 04:51:47 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Xiao", "Chenjun", ""], ["Wu", "Yifan", ""], ["Ma", "Chen", ""], ["Schuurmans", "Dale", ""], ["M\u00fcller", "Martin", ""]]}, {"id": "1912.11209", "submitter": "Vikas Singh", "authors": "Vikas Singh and Nishchal K. Verma", "title": "An Entropy-based Variable Feature Weighted Fuzzy k-Means Algorithm for\n  High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new fuzzy k-means algorithm for the clustering of high\ndimensional data in various subspaces. Since, In the case of high dimensional\ndata, some features might be irrelevant and relevant but may have different\nsignificance in the clustering. For a better clustering, it is crucial to\nincorporate the contribution of these features in the clustering process. To\ncombine these features, in this paper, we have proposed a new fuzzy k-means\nclustering algorithm in which the objective function of the fuzzy k-means is\nmodified using two different entropy term. The first entropy term helps to\nminimize the within-cluster dispersion and maximize the negative entropy to\ndetermine clusters to contribute to the association of data points. The second\nentropy term helps to control the weight of the features because different\nfeatures have different contributing weights in the clustering process for\nobtaining the better partition of the data. The efficacy of the proposed method\nis presented in terms of various clustering measures on multiple datasets and\ncompared with various state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 04:58:47 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Singh", "Vikas", ""], ["Verma", "Nishchal K.", ""]]}, {"id": "1912.11210", "submitter": "Mohamed Baza", "authors": "Mohamed Baza, Andrew Salazar, Mohamed Mahmoud, Mohamed Abdallah, Kemal\n  Akkaya", "title": "On Sharing Models Instead of Data using Mimic learning for Smart Health\n  Applications", "comments": "This paper is accepted in IEEE International Conference on\n  Informatics, IoT, and Enabling Technologies (ICIoT'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) systems contain vast amounts of medical\ninformation about patients. These data can be used to train machine learning\nmodels that can predict health status, as well as to help prevent future\ndiseases or disabilities. However, getting patients' medical data to obtain\nwell-trained machine learning models is a challenging task. This is because\nsharing the patients' medical records is prohibited by law in most countries\ndue to patients privacy concerns. In this paper, we tackle this problem by\nsharing the models instead of the original sensitive data by using the mimic\nlearning approach. The idea is first to train a model on the original sensitive\ndata, called the teacher model. Then, using this model, we can transfer its\nknowledge to another model, called the student model, without the need to learn\nthe original data used in training the teacher model. The student model is then\nshared to the public and can be used to make accurate predictions. To assess\nthe mimic learning approach, we have evaluated our scheme using different\nmedical datasets. The results indicate that the student model mimics the\nteacher model performance in terms of prediction accuracy without the need to\naccess to the patients' original data records.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 05:02:24 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Baza", "Mohamed", ""], ["Salazar", "Andrew", ""], ["Mahmoud", "Mohamed", ""], ["Abdallah", "Mohamed", ""], ["Akkaya", "Kemal", ""]]}, {"id": "1912.11213", "submitter": "Taichi Haruna", "authors": "Taichi Haruna, Kohei Nakajima", "title": "Optimal short-term memory before the edge of chaos in driven random\n  recurrent networks", "comments": null, "journal-ref": "Phys. Rev. E 100 (2019) 062312", "doi": "10.1103/PhysRevE.100.062312", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of discrete-time nonlinear recurrent neural networks to store\ntime-varying small input signals is investigated by mean-field theory. The\ncombination of a small input strength and mean-field assumptions makes it\npossible to derive an approximate expression for the conditional probability\ndensity of the state of a neuron given a past input signal. From this\nconditional probability density, we can analytically calculate short-term\nmemory measures, such as memory capacity, mutual information, and Fisher\ninformation, and determine the relationships among these measures, which have\nnot been clarified to date to the best of our knowledge. We show that the\nnetwork contribution of these short-term memory measures peaks before the edge\nof chaos, where the dynamics of input-driven networks is stable but\ncorresponding systems without input signals are unstable.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 05:44:30 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Haruna", "Taichi", ""], ["Nakajima", "Kohei", ""]]}, {"id": "1912.11217", "submitter": "Zhou Zhou", "authors": "Zhou Zhai, Bin Gu, Xiang Li, Heng Huang", "title": "Safe Sample Screening for Robust Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust support vector machine (RSVM) has been shown to perform remarkably\nwell to improve the generalization performance of support vector machine under\nthe noisy environment. Unfortunately, in order to handle the non-convexity\ninduced by ramp loss in RSVM, existing RSVM solvers often adopt the DC\nprogramming framework which is computationally inefficient for running multiple\nouter loops. This hinders the application of RSVM to large-scale problems. Safe\nsample screening that allows for the exclusion of training samples prior to or\nearly in the training process is an effective method to greatly reduce\ncomputational time. However, existing safe sample screening algorithms are\nlimited to convex optimization problems while RSVM is a non-convex problem. To\naddress this challenge, in this paper, we propose two safe sample screening\nrules for RSVM based on the framework of concave-convex procedure (CCCP).\nSpecifically, we provide screening rule for the inner solver of CCCP and\nanother rule for propagating screened samples between two successive solvers of\nCCCP. To the best of our knowledge, this is the first work of safe sample\nscreening to a non-convex optimization problem. More importantly, we provide\nthe security guarantee to our sample screening rules to RSVM. Experimental\nresults on a variety of benchmark datasets verify that our safe sample\nscreening rules can significantly reduce the computational time.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 05:52:29 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Zhai", "Zhou", ""], ["Gu", "Bin", ""], ["Li", "Xiang", ""], ["Huang", "Heng", ""]]}, {"id": "1912.11234", "submitter": "Feng Liang", "authors": "Feng Liang, Chen Lin, Ronghao Guo, Ming Sun, Wei Wu, Junjie Yan and\n  Wanli Ouyang", "title": "Computation Reallocation for Object Detection", "comments": "ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The allocation of computation resources in the backbone is a crucial issue in\nobject detection. However, classification allocation pattern is usually adopted\ndirectly to object detector, which is proved to be sub-optimal. In order to\nreallocate the engaged computation resources in a more efficient way, we\npresent CR-NAS (Computation Reallocation Neural Architecture Search) that can\nlearn computation reallocation strategies across different feature resolution\nand spatial position diectly on the target detection dataset. A two-level\nreallocation space is proposed for both stage and spatial reallocation. A novel\nhierarchical search procedure is adopted to cope with the complex search space.\nWe apply CR-NAS to multiple backbones and achieve consistent improvements. Our\nCR-ResNet50 and CR-MobileNetV2 outperforms the baseline by 1.9% and 1.7% COCO\nAP respectively without any additional computation budget. The models\ndiscovered by CR-NAS can be equiped to other powerful detection neck/head and\nbe easily transferred to other dataset, e.g. PASCAL VOC, and other vision\ntasks, e.g. instance segmentation. Our CR-NAS can be used as a plugin to\nimprove the performance of various networks, which is demanding.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 07:19:04 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Liang", "Feng", ""], ["Lin", "Chen", ""], ["Guo", "Ronghao", ""], ["Sun", "Ming", ""], ["Wu", "Wei", ""], ["Yan", "Junjie", ""], ["Ouyang", "Wanli", ""]]}, {"id": "1912.11235", "submitter": "Vikas Singh", "authors": "Vikas Singh and Nishchal K. Verma", "title": "Intelligent Condition Based Monitoring Techniques for Bearing Fault\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, intelligent condition-based monitor-ing of rotary machinery\nsystems has become a major researchfocus of machine fault diagnosis. In\ncondition-based monitoring,it is challenging to form a large-scale\nwell-annotated datasetdue to the expense of data acquisition and costly\nannotation.The generated data have a large number of redundant featureswhich\ndegraded the performance of the machine learning models.To overcome this, we\nhave utilized the advantages of minimumredundancy maximum relevance (mRMR) and\ntransfer learningwith a deep learning model. In this work,mRMRis combinedwith\ndeep learning and deep transfer learning framework toimprove the fault\ndiagnostics performance in terms of accuracyand computational complexity.\nThemRMRreduces the redundantinformation from data and increases the deep\nlearning perfor-mance, whereas transfer learning, reduces a large amount of\ndatadependency for training the model. In the proposed work, twoframeworks,\ni.e.,mRMRwith deep learning andmRMRwith deeptransfer learning, have explored\nand validated on CWRU andIMS rolling element bearings datasets. The analysis\nshows thatthe proposed frameworks can obtain better diagnostic accuracycompared\nto existing methods and can handle the data with alarge number of features more\nquickly.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 07:19:06 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 06:17:03 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 18:34:33 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Singh", "Vikas", ""], ["Verma", "Nishchal K.", ""]]}, {"id": "1912.11238", "submitter": "Guoxian Yu", "authors": "Jingzheng Tu and Guoxian Yu and Jun Wang and Carlotta Domeniconi and\n  Xiangliang Zhang", "title": "Attention-Aware Answers of the Crowd", "comments": "This paper was accepted by SDM'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is a relatively economic and efficient solution to collect\nannotations from the crowd through online platforms. Answers collected from\nworkers with different expertise may be noisy and unreliable, and the quality\nof annotated data needs to be further maintained. Various solutions have been\nattempted to obtain high-quality annotations. However, they all assume that\nworkers' label quality is stable over time (always at the same level whenever\nthey conduct the tasks). In practice, workers' attention level changes over\ntime, and the ignorance of which can affect the reliability of the annotations.\nIn this paper, we focus on a novel and realistic crowdsourcing scenario\ninvolving attention-aware annotations. We propose a new probabilistic model\nthat takes into account workers' attention to estimate the label quality.\nExpectation propagation is adopted for efficient Bayesian inference of our\nmodel, and a generalized Expectation Maximization algorithm is derived to\nestimate both the ground truth of all tasks and the label-quality of each\nindividual crowd worker with attention. In addition, the number of tasks best\nsuited for a worker is estimated according to changes in attention. Experiments\nagainst related methods on three real-world and one semi-simulated datasets\ndemonstrate that our method quantifies the relationship between workers'\nattention and label-quality on the given tasks, and improves the aggregated\nlabels.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 07:34:10 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:22:07 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Tu", "Jingzheng", ""], ["Yu", "Guoxian", ""], ["Wang", "Jun", ""], ["Domeniconi", "Carlotta", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "1912.11249", "submitter": "Sam Yen", "authors": "Yao Saint Yen, Zhe Wei Chen, Ying Ren Guo, Meng Chang Chen", "title": "Integration of Static and Dynamic Analysis for Malware Family\n  Classification with Composite Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been used in the research of malware analysis. Most\nclassification methods use either static analysis features or dynamic analysis\nfeatures for malware family classification, and rarely combine them as\nclassification features and also no extra effort is spent integrating the two\ntypes of features. In this paper, we combine static and dynamic analysis\nfeatures with deep neural networks for Windows malware classification. We\ndevelop several methods to generate static and dynamic analysis features to\nclassify malware in different ways. Given these features, we conduct\nexperiments with composite neural network, showing that the proposed approach\nperforms best with an accuracy of 83.17% on a total of 80 malware families with\n4519 malware samples. Additionally, we show that using integrated features for\nmalware family classification outperforms using static features or dynamic\nfeatures alone. We show how static and dynamic features complement each other\nfor malware classification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 08:50:00 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Yen", "Yao Saint", ""], ["Chen", "Zhe Wei", ""], ["Guo", "Ying Ren", ""], ["Chen", "Meng Chang", ""]]}, {"id": "1912.11252", "submitter": "Yimin Huang", "authors": "Yimin Huang, Weiran Huang, Liang Li, Zhenguo Li", "title": "Meta-Learning PAC-Bayes Priors in Model Averaging", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays model uncertainty has become one of the most important problems in\nboth academia and industry. In this paper, we mainly consider the scenario in\nwhich we have a common model set used for model averaging instead of selecting\na single final model via a model selection procedure to account for this\nmodel's uncertainty to improve reliability and accuracy of inferences. Here one\nmain challenge is to learn the prior over the model set. To tackle this\nproblem, we propose two data-based algorithms to get proper priors for model\naveraging. One is for meta-learner, the analysts should use historical similar\ntasks to extract the information about the prior. The other one is for\nbase-learner, a subsampling method is used to deal with the data step by step.\nTheoretically, an upper bound of risk for our algorithm is presented to\nguarantee the performance of the worst situation. In practice, both methods\nperform well in simulations and real data studies, especially with poor quality\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 08:55:16 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 03:11:11 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Huang", "Yimin", ""], ["Huang", "Weiran", ""], ["Li", "Liang", ""], ["Li", "Zhenguo", ""]]}, {"id": "1912.11258", "submitter": "Peng Xu", "authors": "Peng Xu, Chaitanya K. Joshi, Xavier Bresson", "title": "Multi-Graph Transformer for Free-Hand Sketch Recognition", "comments": "This paper has been accepted by IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful representations of free-hand sketches remains a\nchallenging task given the signal sparsity and the high-level abstraction of\nsketches. Existing techniques have focused on exploiting either the static\nnature of sketches with Convolutional Neural Networks (CNNs) or the temporal\nsequential property with Recurrent Neural Networks (RNNs). In this work, we\npropose a new representation of sketches as multiple sparsely connected graphs.\nWe design a novel Graph Neural Network (GNN), the Multi-Graph Transformer\n(MGT), for learning representations of sketches from multiple graphs which\nsimultaneously capture global and local geometric stroke structures, as well as\ntemporal information. We report extensive numerical experiments on a sketch\nrecognition task to demonstrate the performance of the proposed approach.\nParticularly, MGT applied on 414k sketches from Google QuickDraw: (i) achieves\nsmall recognition gap to the CNN-based performance upper bound (72.80% vs.\n74.22%), and (ii) outperforms all RNN-based models by a significant margin. To\nthe best of our knowledge, this is the first work proposing to represent\nsketches as graphs and apply GNNs for sketch recognition. Code and trained\nmodels are available at\nhttps://github.com/PengBoXiangShang/multigraph_transformer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 09:28:10 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 17:16:50 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 04:34:16 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Xu", "Peng", ""], ["Joshi", "Chaitanya K.", ""], ["Bresson", "Xavier", ""]]}, {"id": "1912.11259", "submitter": "Valentino Servizi", "authors": "Valentino Servizi, Francisco C. Pereira, Marie K. Anderson, and Otto\n  A. Nielsen", "title": "Mining User Behaviour from Smartphone data: a literature review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study users' travel behaviour and travel time between origin and\ndestination, researchers employ travel surveys. Although there is consensus in\nthe field about the potential, after over ten years of research and field\nexperimentation, Smartphone-based travel surveys still did not take off to a\nlarge scale. Here, computer intelligence algorithms take the role that\noperators have in Traditional Travel Surveys; since we train each algorithm on\ndata, performances rest on the data quality, thus on the ground truth.\nInaccurate validations affect negatively: labels, algorithms' training, travel\ndiaries precision, and therefore data validation, within a very critical loop.\nInterestingly, boundaries are proven burdensome to push even for Machine\nLearning methods. To support optimal investment decisions for practitioners, we\nexpose the drivers they should consider when assessing what they need against\nwhat they get. This paper highlights and examines the critical aspects of the\nunderlying research and provides some recommendations: (i) from the device\nperspective, on the main physical limitations; (ii) from the application\nperspective, the methodological framework deployed for the automatic generation\nof travel diaries; (iii)from the ground truth perspective, the relationship\nbetween user interaction, methods, and data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 09:34:13 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:37:19 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Servizi", "Valentino", ""], ["Pereira", "Francisco C.", ""], ["Anderson", "Marie K.", ""], ["Nielsen", "Otto A.", ""]]}, {"id": "1912.11279", "submitter": "Reza Shokri", "authors": "Hongyan Chang, Virat Shejwalkar, Reza Shokri, Amir Houmansadr", "title": "Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box\n  Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative (federated) learning enables multiple parties to train a model\nwithout sharing their private data, but through repeated sharing of the\nparameters of their local models. Despite its advantages, this approach has\nmany known privacy and security weaknesses and performance overhead, in\naddition to being limited only to models with homogeneous architectures. Shared\nparameters leak a significant amount of information about the local (and\nsupposedly private) datasets. Besides, federated learning is severely\nvulnerable to poisoning attacks, where some participants can adversarially\ninfluence the aggregate parameters. Large models, with high dimensional\nparameter vectors, are in particular highly susceptible to privacy and security\nattacks: curse of dimensionality in federated learning. We argue that sharing\nparameters is the most naive way of information exchange in collaborative\nlearning, as they open all the internal state of the model to inference\nattacks, and maximize the model's malleability by stealthy poisoning attacks.\nWe propose Cronus, a robust collaborative machine learning framework. The\nsimple yet effective idea behind designing Cronus is to control, unify, and\nsignificantly reduce the dimensions of the exchanged information between\nparties, through robust knowledge transfer between their black-box local\nmodels. We evaluate all existing federated learning algorithms against\npoisoning attacks, and we show that Cronus is the only secure method, due to\nits tight robustness guarantee. Treating local models as black-box, reduces the\ninformation leakage through models, and enables us using existing\nprivacy-preserving algorithms that mitigate the risk of information leakage\nthrough the model's output (predictions). Cronus also has a significantly lower\nsample complexity, compared to federated learning, which does not bind its\nsecurity to the number of participants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:20:38 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Chang", "Hongyan", ""], ["Shejwalkar", "Virat", ""], ["Shokri", "Reza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "1912.11283", "submitter": "Roberto Bruzzese", "authors": "Roberto Bruzzese", "title": "An Analisys of Application Logs with Splunk : developing an App for the\n  synthetic analysis of data and security incidents", "comments": "32 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work aims to enhance the application logs of an hypothetical\ninfrastructure platform, and to build an App that displays the synthetic data\nabout performance, anomalies and security incidents synthesized in the form of\na Dashboard. The reference architecture, with multiple applications and\nmultiple HW distribution, implementing a Service Oriented Architecture, is a\nreal case of which the details have been abstracted because we want to extend\nthe concept to all architectures with similar characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 10:42:42 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Bruzzese", "Roberto", ""]]}, {"id": "1912.11308", "submitter": "Frederik Gossen", "authors": "Frederik Gossen, Alnis Murtovi, Philip Zweihoff, Bernhard Steffen", "title": "ADD-Lib: Decision Diagrams in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we present the ADD-Lib, our efficient and easy to use framework\nfor Algebraic Decision Diagrams (ADDs). The focus of the ADD-Lib is not so much\non its efficient implementation of individual operations, which are taken by\nother established ADD frameworks, but its ease and flexibility, which arise at\ntwo levels: the level of individual ADD-tools, which come with a dedicated\nuser-friendly web-based graphical user interface, and at the meta level, where\nsuch tools are specified. Both levels are described in the paper: the meta\nlevel by explaining how we can construct an ADD-tool tailored for Random Forest\nrefinement and evaluation, and the accordingly generated Web-based\ndomain-specific tool, which we also provide as an artifact for cooperative\nexperimentation. In particular, the artifact allows readers to combine a given\nRandom Forest with their own ADDs regarded as expert knowledge and to\nexperience the corresponding effect.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 12:11:00 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gossen", "Frederik", ""], ["Murtovi", "Alnis", ""], ["Zweihoff", "Philip", ""], ["Steffen", "Bernhard", ""]]}, {"id": "1912.11312", "submitter": "Sabine M\\\"uller", "authors": "Sabine M\\\"uller, Joachim Weickert, Norbert Graf", "title": "Robustness of Brain Tumor Segmentation", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: The segmentation of brain tumors is one of the most active areas of\nmedical image analysis. While current methods perform superhuman on benchmark\ndata sets, their applicability in daily clinical practice has not been\nevaluated. In our work we investigate the generalization behavior of deep\nneural networks in this scenario.\n  Approach: We evaluate the performance of three state-of-the-art methods, a\nbasic U-net architecture and a cascadic Mumford-Shah approach. We also propose\ntwo simple modifications (which do not change the topology) to improve\ngeneralization performance.\n  Results: In our experiments we show that a well-trained U-network shows the\nbest generalization behavior and is sufficient to solve this segmentation\nproblem. We illustrate why extensions of this model in a realistic scenario can\nbe not only pointless but even harmful.\n  Conclusions: We conclude from our experiments that the generalization\nperformance of deep neural networks is severely limited in medical image\nanalysis especially in the area of brain tumor segmentation. In our opinion,\ncurrent topologies are optimized for the actual benchmark data set, but are not\ndirectly applicable in daily clinical practice.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 12:18:37 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 20:07:46 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 21:56:16 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["M\u00fcller", "Sabine", ""], ["Weickert", "Joachim", ""], ["Graf", "Norbert", ""]]}, {"id": "1912.11316", "submitter": "Gianni Franchi", "authors": "Gianni Franchi, Andrei Bursuc, Emanuel Aldea, Severine Dubuisson,\n  Isabelle Bloch", "title": "TRADI: Tracking deep neural network weight distributions for uncertainty\n  estimation", "comments": "Accepted to ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During training, the weights of a Deep Neural Network (DNN) are optimized\nfrom a random initialization towards a nearly optimum value minimizing a loss\nfunction. Only this final state of the weights is typically kept for testing,\nwhile the wealth of information on the geometry of the weight space,\naccumulated over the descent towards the minimum is discarded. In this work we\npropose to make use of this knowledge and leverage it for computing the\ndistributions of the weights of the DNN. This can be further used for\nestimating the epistemic uncertainty of the DNN by sampling an ensemble of\nnetworks from these distributions. To this end we introduce a method for\ntracking the trajectory of the weights during optimization, that does not\nrequire any changes in the architecture nor on the training procedure. We\nevaluate our method on standard classification and regression benchmarks, and\non out-of-distribution detection for classification and semantic segmentation.\nWe achieve competitive results, while preserving computational efficiency in\ncomparison to other popular approaches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 12:22:45 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 20:21:09 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 13:05:19 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 19:21:28 GMT"}, {"version": "v5", "created": "Thu, 25 Mar 2021 12:27:09 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Franchi", "Gianni", ""], ["Bursuc", "Andrei", ""], ["Aldea", "Emanuel", ""], ["Dubuisson", "Severine", ""], ["Bloch", "Isabelle", ""]]}, {"id": "1912.11328", "submitter": "Jonas Robl", "authors": "Daniel Bernau, Philip-William Grassal, Jonas Robl, Florian Kerschbaum", "title": "Assessing differentially private deep learning with Membership Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks that aim to identify the training data of public neural networks\nrepresent a severe threat to the privacy of individuals participating in the\ntraining data set. A possible protection is offered by anonymization of the\ntraining data or training function with differential privacy. However, data\nscientists can choose between local and central differential privacy and need\nto select meaningful privacy parameters $\\epsilon$ which is challenging for\nnon-privacy experts. We empirically compare local and central differential\nprivacy mechanisms under white- and black-box membership inference to evaluate\ntheir relative privacy-accuracy trade-offs. We experiment with several datasets\nand show that this trade-off is similar for both types of mechanisms. This\nsuggests that local differential privacy is a sound alternative to central\ndifferential privacy for differentially private deep learning, since small\n$\\epsilon$ in central differential privacy and large $\\epsilon$ in local\ndifferential privacy result in similar membership inference attack risk.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 13:00:24 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 11:19:08 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 16:43:11 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 14:27:16 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bernau", "Daniel", ""], ["Grassal", "Philip-William", ""], ["Robl", "Jonas", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1912.11333", "submitter": "WeiRan Yan", "authors": "WeiRan Yan, MaoLin Tang, Qijun Zhao, Peng Chen, Dunwu Qi, Rong Hou,\n  Zhihe Zhang", "title": "Audio-based automatic mating success prediction of giant pandas", "comments": "The manuscript needs further revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giant pandas, stereotyped as silent animals, make significantly more vocal\nsounds during breeding season, suggesting that sounds are essential for\ncoordinating their reproduction and expression of mating preference. Previous\nbiological studies have also proven that giant panda sounds are correlated with\nmating results and reproduction. This paper makes the first attempt to devise\nan automatic method for predicting mating success of giant pandas based on\ntheir vocal sounds. Given an audio sequence of mating giant pandas recorded\nduring breeding encounters, we first crop out the segments with vocal sound of\ngiant pandas, and normalize its magnitude, and length. We then extract acoustic\nfeatures from the audio segment and feed the features into a deep neural\nnetwork, which classifies the mating into success or failure. The proposed deep\nneural network employs convolution layers followed by bidirection gated\nrecurrent units to extract vocal features, and applies attention mechanism to\nforce the network to focus on most relevant features. Evaluation experiments on\na data set collected during the past nine years obtain promising results,\nproving the potential of audio-based automatic mating success prediction\nmethods in assisting giant panda reproduction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 16:08:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 09:42:01 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 06:30:54 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Yan", "WeiRan", ""], ["Tang", "MaoLin", ""], ["Zhao", "Qijun", ""], ["Chen", "Peng", ""], ["Qi", "Dunwu", ""], ["Hou", "Rong", ""], ["Zhang", "Zhihe", ""]]}, {"id": "1912.11341", "submitter": "Arunav Gupta", "authors": "Arunav Gupta, Lucas Nguyen, Camille Dunning, Ka Ming Chan", "title": "Quantifying the Effects of the 2008 Recession using the Zillow Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG cs.NA math.NA q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report explores the use of Zillow's housing metrics dataset to\ninvestigate the effects of the 2008 US subprime mortgage crisis on various US\nlocales. We begin by exploring the causes of the recession and the metrics\navailable to us in the dataset. We settle on using the Zillow Home Value Index\n(ZHVI) because it is seasonally adjusted and able to account for a variety of\ninventory factors. Then, we explore three methodologies for quantifying\nrecession impact: (a) Principal Components Analysis, (b) Area Under Baseline,\nand (c) ARIMA modeling and Confidence Intervals. While PCA does not yield\nuseable results, we ended up with six cities from both AUB and ARIMA analysis,\nthe top 3 \"losers\" and \"gainers\" of the 2008 recession, as determined by each\nanalysis. This gave us 12 cities in total. Finally, we tested the robustness of\nour analysis against three \"common knowledge\" metrics for the recession:\ngeographic clustering, population trends, and unemployment rate. While we did\nfind some overlap between the results of our analysis and geographic\nclustering, there was no positive regression outcome from comparing our\nmethodologies to population trends and the unemployment rate.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:27:08 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Gupta", "Arunav", ""], ["Nguyen", "Lucas", ""], ["Dunning", "Camille", ""], ["Chan", "Ka Ming", ""]]}, {"id": "1912.11346", "submitter": "Kamorudeen Amuda", "authors": "Kamorudeen A. Amuda, Adesesan B. Adeyemo", "title": "Customers Churn Prediction in Financial Institution Using Artificial\n  Neural Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, a predictive model using Multi-layer Perceptron of Artificial\nNeural Network architecture was developed to predict customer churn in a\nfinancial institution. Previous researches have used supervised machine\nlearning classifiers such as Logistic Regression, Decision Tree, Support Vector\nMachine, K-Nearest Neighbors, and Random Forest. These classifiers require\nhuman effort to perform feature engineering which leads to over-specified and\nincomplete feature selection. Therefore, this research developed a model to\neliminate manual feature engineering in data preprocessing stage. Fifty\nthousand customers? data were extracted from the database of one of the leading\nfinancial institution in Nigeria for the study. The multi-layer perceptron\nmodel was built with python programming language and used two overfitting\ntechniques (Dropout and L2 regularization). The implementation done in python\nwas compared with another model in Neuro solution infinity software. The\nresults showed that the Artificial Neural Network software development (Python)\nhad comparable performance with that obtained from the Neuro Solution Infinity\nsoftware. The accuracy rates are 97.53% and 97.4% while ROC (Receiver Operating\nCharacteristic) curve graphs are 0.89 and 0.85 respectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 08:24:29 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Amuda", "Kamorudeen A.", ""], ["Adeyemo", "Adesesan B.", ""]]}, {"id": "1912.11350", "submitter": "Jing Gao", "authors": "Jing Gao, N. Anantrasirichai and David Bull", "title": "Atmospheric turbulence removal using convolutional neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel deep learning-based method for mitigating the\neffects of atmospheric distortion. We have built an end-to-end supervised\nconvolutional neural network (CNN) to reconstruct turbulence-corrupted video\nsequence. Our framework has been developed on the residual learning concept,\nwhere the spatio-temporal distortions are learnt and predicted. Our experiments\ndemonstrate that the proposed method can deblur, remove ripple effect and\nenhance contrast of the video sequences simultaneously. Our model was trained\nand tested with both simulated and real distortions. Experimental results of\nthe real distortions show that our method outperforms the existing ones by up\nto 3.8% in term of the quality of restored images, and it achieves faster speed\nthan the state-of-the-art methods by up to 23 times with GPU implementation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 22:22:55 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Gao", "Jing", ""], ["Anantrasirichai", "N.", ""], ["Bull", "David", ""]]}, {"id": "1912.11356", "submitter": "Muhammad Nabeel Asim", "authors": "Muhammad Nabeel Asima, Muhammad Imran Malik, Andreas Dengela, Sheraz\n  Ahmed", "title": "A Robust and Precise ConvNet for small non-coding RNA classification\n  (RPC-snRC)", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Functional or non-coding RNAs are attracting more attention as they are now\npotentially considered valuable resources in the development of new drugs\nintended to cure several human diseases. The identification of drugs targeting\nthe regulatory circuits of functional RNAs depends on knowing its family, a\ntask which is known as RNA sequence classification. State-of-the-art small\nnoncoding RNA classification methodologies take secondary structural features\nas input. However, in such classification, feature extraction approaches only\ntake global characteristics into account and completely oversight co-relative\neffect of local structures. Furthermore secondary structure based approaches\nincorporate high dimensional feature space which proves computationally\nexpensive. This paper proposes a novel Robust and Precise ConvNet (RPC-snRC)\nmethodology which classifies small non-coding RNAs sequences into their\nrelevant families by utilizing the primary sequence of RNAs. RPC-snRC\nmethodology learns hierarchical representation of features by utilizing\npositioning and occurrences information of nucleotides. To avoid exploding and\nvanishing gradient problems, we use an approach similar to DenseNet in which\ngradient can flow straight from subsequent layers to previous layers. In order\nto assess the effectiveness of deeper architectures for small non-coding RNA\nclassification, we also adapted two ResNet architectures having different\nnumber of layers. Experimental results on a benchmark small non-coding RNA\ndataset show that our proposed methodology does not only outperform existing\nsmall non-coding RNA classification approaches with a significant performance\nmargin of 10% but it also outshines adapted ResNet architectures.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 08:33:42 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Asima", "Muhammad Nabeel", ""], ["Malik", "Muhammad Imran", ""], ["Dengela", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "1912.11367", "submitter": "Naresh Manwani", "authors": "Rajarshi Bhattacharjee and Naresh Manwani", "title": "Online Algorithms for Multiclass Classification using Partial Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose online algorithms for multiclass classification\nusing partial labels. We propose two variants of Perceptron called Avg\nPerceptron and Max Perceptron to deal with the partial labeled data. We also\npropose Avg Pegasos and Max Pegasos, which are extensions of Pegasos algorithm.\nWe also provide mistake bounds for Avg Perceptron and regret bound for Avg\nPegasos. We show the effectiveness of the proposed approaches by experimenting\non various datasets and comparing them with the standard Perceptron and\nPegasos.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 13:54:38 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Bhattacharjee", "Rajarshi", ""], ["Manwani", "Naresh", ""]]}, {"id": "1912.11368", "submitter": "Badong Chen", "authors": "Yunfei Zheng, Badong Chen, Senior Member, IEEE, Shiyuan Wang, Senior\n  Member, IEEE, and Weiqun Wang, Member, IEEE", "title": "Broad Learning System Based on Maximum Correntropy Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective and efficient discriminative learning method, Broad Learning\nSystem (BLS) has received increasing attention due to its outstanding\nperformance in various regression and classification problems. However, the\nstandard BLS is derived under the minimum mean square error (MMSE) criterion,\nwhich is, of course, not always a good choice due to its sensitivity to\noutliers. To enhance the robustness of BLS, we propose in this work to adopt\nthe maximum correntropy criterion (MCC) to train the output weights, obtaining\na correntropy based broad learning system (C-BLS). Thanks to the inherent\nsuperiorities of MCC, the proposed C-BLS is expected to achieve excellent\nrobustness to outliers while maintaining the original performance of the\nstandard BLS in Gaussian or noise-free environment. In addition, three\nalternative incremental learning algorithms, derived from a weighted\nregularized least-squares solution rather than pseudoinverse formula, for C-BLS\nare developed.With the incremental learning algorithms, the system can be\nupdated quickly without the entire retraining process from the beginning, when\nsome new samples arrive or the network deems to be expanded. Experiments on\nvarious regression and classification datasets are reported to demonstrate the\ndesirable performance of the new methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 13:56:55 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Zheng", "Yunfei", ""], ["Chen", "Badong", ""], ["Member", "Senior", ""], ["IEEE", "", ""], ["Wang", "Shiyuan", ""], ["Member", "Senior", ""], ["IEEE", "", ""], ["Wang", "Weiqun", ""], ["Member", "", ""], ["IEEE", "", ""]]}, {"id": "1912.11370", "submitter": "Xiaohua Zhai", "authors": "Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver,\n  Jessica Yung, Sylvain Gelly, Neil Houlsby", "title": "Big Transfer (BiT): General Visual Representation Learning", "comments": "The first three authors contributed equally. Results on ObjectNet are\n  reported in v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer of pre-trained representations improves sample efficiency and\nsimplifies hyperparameter tuning when training deep neural networks for vision.\nWe revisit the paradigm of pre-training on large supervised datasets and\nfine-tuning the model on a target task. We scale up pre-training, and propose a\nsimple recipe that we call Big Transfer (BiT). By combining a few carefully\nselected components, and transferring using a simple heuristic, we achieve\nstrong performance on over 20 datasets. BiT performs well across a surprisingly\nwide range of data regimes -- from 1 example per class to 1M total examples.\nBiT achieves 87.5% top-1 accuracy on ILSVRC-2012, 99.4% on CIFAR-10, and 76.3%\non the 19 task Visual Task Adaptation Benchmark (VTAB). On small datasets, BiT\nattains 76.8% on ILSVRC-2012 with 10 examples per class, and 97.0% on CIFAR-10\nwith 10 examples per class. We conduct detailed analysis of the main components\nthat lead to high transfer performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 14:04:11 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:47:49 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 20:48:23 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Kolesnikov", "Alexander", ""], ["Beyer", "Lucas", ""], ["Zhai", "Xiaohua", ""], ["Puigcerver", "Joan", ""], ["Yung", "Jessica", ""], ["Gelly", "Sylvain", ""], ["Houlsby", "Neil", ""]]}, {"id": "1912.11371", "submitter": "Amirmohammad Mijani", "authors": "S.A. Karimi, A.M.Mijani, M.T. Talebian and S. Mirzakuchaki", "title": "Comparison of the P300 detection accuracy related to the BCI speller and\n  image recognition scenarios", "comments": "8 pages, 3 figures, 2 tables, 24 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several protocols in the Electroencephalography (EEG) recording\nscenarios which produce various types of event-related potentials (ERP). P300\npattern is a well-known ERP which produced by auditory and visual oddball\nparadigm and BCI speller system. In this study, P300 and non-P300 separability\nare investigated in two scenarios including image recognition paradigm and BCI\nspeller. Image recognition scenario is an experiment that examines the\nparticipants, knowledge about an image that shown to them before by analyzing\nthe EEG signal recorded during the observing of that image as visual\nstimulation. To do this, three types of famous classifiers (SVM, Bayes LDA, and\nsparse logistic regression) were used to classify EEG recordings in six classes\nproblem. Filtered and down-sampled (temporal samples) of EEG recording were\nconsidered as features in classification P300 pattern. Also, different sets of\nEEG recording including 4, 8 and 16 channels and different trial numbers were\nused to considering various situations in comparison. The accuracy was\nincreased by increasing the number of trials and channels. The results prove\nthat better accuracy is observed in the case of the image recognition scenario\nfor the different sets of channels and by using the different number of trials.\nSo it can be concluded that P300 pattern which produced in image recognition\nparadigm is more separable than BCI (matrix speller).\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 14:04:24 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Karimi", "S. A.", ""], ["Mijani", "A. M.", ""], ["Talebian", "M. T.", ""], ["Mirzakuchaki", "S.", ""]]}, {"id": "1912.11398", "submitter": "Antoine Dedieu", "authors": "Antoine Dedieu", "title": "An error bound for Lasso and Group Lasso in high dimensions", "comments": "arXiv admin note: text overlap with arXiv:1910.08880", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage recent advances in high-dimensional statistics to derive new L2\nestimation upper bounds for Lasso and Group Lasso in high-dimensions. For\nLasso, our bounds scale as $(k^*/n) \\log(p/k^*)$---$n\\times p$ is the size of\nthe design matrix and $k^*$ the dimension of the ground truth\n$\\boldsymbol{\\beta}^*$---and match the optimal minimax rate. For Group Lasso,\nour bounds scale as $(s^*/n) \\log\\left( G / s^* \\right) + m^* / n$---$G$ is the\ntotal number of groups and $m^*$ the number of coefficients in the $s^*$ groups\nwhich contain $\\boldsymbol{\\beta}^*$---and improve over existing results. We\nadditionally show that when the signal is strongly group-sparse, Group Lasso is\nsuperior to Lasso.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 14:08:26 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:05:03 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Dedieu", "Antoine", ""]]}, {"id": "1912.11405", "submitter": "Angshul Majumdar Dr.", "authors": "Jyoti Maggu, Hemant K. Aggarwal and Angshul Majumdar", "title": "Label Consistent Transform Learning for Hyperspectral Image\n  Classification", "comments": "A modified version has been accepted at IEEE Geosciences and Remote\n  Sensing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new image analysis tool called Label Consistent\nTransform Learning (LCTL). Transform learning is a recent unsupervised\nrepresentation learning approach; we add supervision by incorporating a label\nconsistency constraint. The proposed technique is especially suited for\nhyper-spectral image classification problems owing to its ability to learn from\nfewer samples. We have compared our proposed method on state-of-the-art\ntechniques like label consistent KSVD, Stacked Autoencoder, Deep Belief Network\nand Convolutional Neural Network. Our method yields considerably better results\n(more than 0.1 improvement in Kappa coefficient) than all the aforesaid\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 09:55:54 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Maggu", "Jyoti", ""], ["Aggarwal", "Hemant K.", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.11425", "submitter": "Christopher J. Anders", "authors": "Christopher J. Anders, Leander Weber, David Neumann, Wojciech Samek,\n  Klaus-Robert M\\\"uller, Sebastian Lapuschkin", "title": "Finding and Removing Clever Hans: Using Explanation Methods to Debug and\n  Improve Deep Models", "comments": "47 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Contemporary learning models for computer vision are typically trained on\nvery large (benchmark) datasets with millions of samples. These may, however,\ncontain biases, artifacts, or errors that have gone unnoticed and are\nexploitable by the model. In the worst case, the trained model does not learn a\nvalid and generalizable strategy to solve the problem it was trained for, and\nbecomes a 'Clever-Hans' (CH) predictor that bases its decisions on spurious\ncorrelations in the training data, potentially yielding an unrepresentative or\nunfair, and possibly even hazardous predictor. In this paper, we contribute by\nproviding a comprehensive analysis framework based on a scalable statistical\nanalysis of attributions from explanation methods for large data corpora. Based\non a recent technique - Spectral Relevance Analysis - we propose the following\ntechnical contributions and resulting findings: (a) a scalable quantification\nof artifactual and poisoned classes where the machine learning models under\nstudy exhibit CH behavior, (b) several approaches denoted as Class Artifact\nCompensation (ClArC), which are able to effectively and significantly reduce a\nmodel's CH behavior. I.e., we are able to un-Hans models trained on (poisoned)\ndatasets, such as the popular ImageNet data corpus. We demonstrate that ClArC,\ndefined in a simple theoretical framework, may be implemented as part of a\nNeural Network's training or fine-tuning process, or in a post-hoc manner by\ninjecting additional layers, preventing any further propagation of undesired CH\nfeatures, into the network architecture. Using our proposed methods, we provide\nqualitative and quantitative analyses of the biases and artifacts in various\ndatasets. We demonstrate that these insights can give rise to improved, more\nrepresentative and fairer models operating on implicitly cleaned data corpora.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 22:40:27 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 20:13:21 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Anders", "Christopher J.", ""], ["Weber", "Leander", ""], ["Neumann", "David", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Lapuschkin", "Sebastian", ""]]}, {"id": "1912.11430", "submitter": "Yanxing Wang", "authors": "Yanxing Wang, Jianxing Hu, Junyong Lai, Yibo Li, Hongwei Jin, Lihe\n  Zhang, Liangren Zhang, Zhenming Liu", "title": "TF3P: Three-dimensional Force Fields Fingerprint Learned by Deep\n  Capsular Network", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jcim.0c00005", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular fingerprints are the workhorse in ligand-based drug discovery. In\nrecent years, an increasing number of research papers reported fascinating\nresults on using deep neural networks to learn 2D molecular representations as\nfingerprints. It is anticipated that the integration of deep learning would\nalso contribute to the prosperity of 3D fingerprints. Here, we unprecedentedly\nintroduce deep learning into 3D small molecule fingerprints, presenting a new\none we termed as the three-dimensional force fields fingerprint (TF3P). TF3P is\nlearned by a deep capsular network whose training is in no need of labeled\ndatasets for specific predictive tasks. TF3P can encode the 3D force fields\ninformation of molecules and demonstrates the stronger ability to capture 3D\nstructural changes, to recognize molecules alike in 3D but not in 2D, and to\nidentify similar targets inaccessible by other 2D or 3D fingerprints based on\nonly ligands similarity. Furthermore, TF3P is compatible with both statistical\nmodels (e.g. similarity ensemble approach) and machine learning models.\nAltogether, we report TF3P as a new 3D small molecule fingerprint with a\npromising future in ligand-based drug discovery. All codes are written in\nPython and available at https://github.com/canisw/tf3p.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 16:32:52 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 10:00:37 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 14:40:44 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Yanxing", ""], ["Hu", "Jianxing", ""], ["Lai", "Junyong", ""], ["Li", "Yibo", ""], ["Jin", "Hongwei", ""], ["Zhang", "Lihe", ""], ["Zhang", "Liangren", ""], ["Liu", "Zhenming", ""]]}, {"id": "1912.11460", "submitter": "Hamid Karimi", "authors": "Hamid Karimi, Tyler Derr, Jiliang Tang", "title": "Characterizing the Decision Boundary of Deep Neural Networks", "comments": "Please contact the first author for any issue or the question\n  regarding this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks and in particular, deep neural classifiers have become\nan integral part of many modern applications. Despite their practical success,\nwe still have limited knowledge of how they work and the demand for such an\nunderstanding is evergrowing. In this regard, one crucial aspect of deep neural\nnetwork classifiers that can help us deepen our knowledge about their\ndecision-making behavior is to investigate their decision boundaries.\nNevertheless, this is contingent upon having access to samples populating the\nareas near the decision boundary. To achieve this, we propose a novel approach\nwe call Deep Decision boundary Instance Generation (DeepDIG). DeepDIG utilizes\na method based on adversarial example generation as an effective way of\ngenerating samples near the decision boundary of any deep neural network model.\nThen, we introduce a set of important principled characteristics that take\nadvantage of the generated instances near the decision boundary to provide\nmultifaceted understandings of deep neural networks. We have performed\nextensive experiments on multiple representative datasets across various deep\nneural network models and characterized their decision boundaries. The code is\npublicly available at https://github.com/hamidkarimi/DeepDIG/.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 18:30:11 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 20:55:18 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:18:25 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Karimi", "Hamid", ""], ["Derr", "Tyler", ""], ["Tang", "Jiliang", ""]]}, {"id": "1912.11464", "submitter": "Shuhao Fu", "authors": "Shuhao Fu, Chulin Xie, Bo Li, Qifeng Chen", "title": "Attack-Resistant Federated Learning with Residual-based Reweighting", "comments": "8 pages, 6 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has a variety of applications in multiple domains by\nutilizing private training data stored on different devices. However, the\naggregation process in federated learning is highly vulnerable to adversarial\nattacks so that the global model may behave abnormally under attacks. To tackle\nthis challenge, we present a novel aggregation algorithm with residual-based\nreweighting to defend federated learning. Our aggregation algorithm combines\nrepeated median regression with the reweighting scheme in iteratively\nreweighted least squares. Our experiments show that our aggregation algorithm\noutperforms other alternative algorithms in the presence of label-flipping and\nbackdoor attacks. We also provide theoretical analysis for our aggregation\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 18:42:00 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:51:45 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 19:39:30 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Fu", "Shuhao", ""], ["Xie", "Chulin", ""], ["Li", "Bo", ""], ["Chen", "Qifeng", ""]]}, {"id": "1912.11475", "submitter": "Amir Ahmad", "authors": "Amir Ahmad and Srikanth Bezawada", "title": "One-Class Classification by Ensembles of Regression models -- a detailed\n  study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class classification (OCC) deals with the classification problem in which\nthe training data has data points belonging only to target class. In this\npaper, we study a one-class classification algorithm, One-Class Classification\nby Ensembles of Regression models (OCCER), that uses regression methods to\naddress OCC problems. The OCCER coverts an OCC problem into many regression\nproblems in the original feature space so that each feature of the original\nfeature space is used as the target variable in one of the regression problems.\nOther features are used as the variables on which the dependent variable\ndepends. The errors of regression of a data point by all the regression models\nare used to compute the outlier score of the data point. An extensive\ncomparison of the OCCER algorithm with state-of-the-art OCC algorithms on\nseveral datasets was conducted to show the effectiveness of the this approach.\nWe also demonstrate that the OCCER algorithm can work well with the latent\nfeature space created by autoencoders for image datasets. The implementation of\nOCCER is available at https://github.com/srikanthBezawada/OCCER.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 08:47:38 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 09:10:53 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 07:25:58 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ahmad", "Amir", ""], ["Bezawada", "Srikanth", ""]]}, {"id": "1912.11477", "submitter": "Shizhan Lu", "authors": "Shizhan Lu", "title": "Self-adaption grey DBSCAN clustering", "comments": "8 pages, 4 figures, 4 tables. arXiv admin note: text overlap with\n  arXiv:1906.11416", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis, a classical issue in data mining, is widely used in\nvarious research areas. This article aims at proposing a self-adaption grey\nDBSCAN clustering (SAG-DBSCAN) algorithm. First, the grey relational matrix is\nused to obtain the grey local density indicator, and then this indicator is\napplied to make self-adapting noise identification for obtaining a dense subset\nof clustering dataset, finally, the DBSCAN which automatically selects\nparameters is utilized to cluster the dense subset. Several frequently-used\ndatasets were used to demonstrate the performance and effectiveness of the\nproposed clustering algorithm and to compare the results with those of other\nstate-of-the-art algorithms. The comprehensive comparisons indicate that our\nmethod has advantages over other compared methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 02:46:15 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Lu", "Shizhan", ""]]}, {"id": "1912.11493", "submitter": "Konpat Preechakul", "authors": "Konpat Preechakul, Boonserm Kijsirikul", "title": "CProp: Adaptive Learning Rate Scaling from Past Gradient Conformity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most optimizers including stochastic gradient descent (SGD) and its adaptive\ngradient derivatives face the same problem where an effective learning rate\nduring the training is vastly different. A learning rate scheduling, mostly\ntuned by hand, is usually employed in practice. In this paper, we propose\nCProp, a gradient scaling method, which acts as a second-level learning rate\nadapting throughout the training process based on cues from past gradient\nconformity. When the past gradients agree on direction, CProp keeps the\noriginal learning rate. On the contrary, if the gradients do not agree on\ndirection, CProp scales down the gradient proportionally to its uncertainty.\nSince it works by scaling, it could apply to any existing optimizer extending\nits learning rate scheduling capability. We put CProp to a series of tests\nshowing significant gain in training speed on both SGD and adaptive gradient\nmethod like Adam. Codes are available at https://github.com/phizaz/cprop .\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 19:06:53 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Preechakul", "Konpat", ""], ["Kijsirikul", "Boonserm", ""]]}, {"id": "1912.11511", "submitter": "SiQi Zhou", "authors": "SiQi Zhou and Angela P. Schoellig", "title": "An Analysis of the Expressiveness of Deep Neural Network Architectures\n  Based on Their Lipschitz Constants", "comments": "L4DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have emerged as a popular mathematical tool for\nfunction approximation due to their capability of modelling highly nonlinear\nfunctions. Their applications range from image classification and natural\nlanguage processing to learning-based control. Despite their empirical\nsuccesses, there is still a lack of theoretical understanding of the\nrepresentative power of such deep architectures. In this work, we provide a\ntheoretical analysis of the expressiveness of fully-connected, feedforward DNNs\nwith 1-Lipschitz activation functions. In particular, we characterize the\nexpressiveness of a DNN by its Lipchitz constant. By leveraging random matrix\ntheory, we show that, given sufficiently large and randomly distributed\nweights, the expected upper and lower bounds of the Lipschitz constant of a DNN\nand hence their expressiveness increase exponentially with depth and\npolynomially with width, which gives rise to the benefit of the depth of DNN\narchitectures for efficient function approximation. This observation is\nconsistent with established results based on alternative expressiveness\nmeasures of DNNs. In contrast to most of the existing work, our analysis based\non the Lipschitz properties of DNNs is applicable to a wider range of\nactivation nonlinearities and potentially allows us to make sensible\ncomparisons between the complexity of a DNN and the function to be approximated\nby the DNN. We consider this work to be a step towards understanding the\nexpressive power of DNNs and towards designing appropriate deep architectures\nfor practical applications such as system control.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 20:00:26 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhou", "SiQi", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1912.11521", "submitter": "Tong He", "authors": "Jialin Gao, Tong He, Xi Zhou, Shiming Ge", "title": "Focusing and Diffusion: Bidirectional Attentive Graph Convolutional\n  Networks for Skeleton-based Action Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collection of approaches based on graph convolutional networks have proven\nsuccess in skeleton-based action recognition by exploring neighborhood\ninformation and dense dependencies between intra-frame joints. However, these\napproaches usually ignore the spatial-temporal global context as well as the\nlocal relation between inter-frame and intra-frame. In this paper, we propose a\nfocusing and diffusion mechanism to enhance graph convolutional networks by\npaying attention to the kinematic dependence of articulated human pose in a\nframe and their implicit dependencies over frames. In the focusing process, we\nintroduce an attention module to learn a latent node over the intra-frame\njoints to convey spatial contextual information. In this way, the sparse\nconnections between joints in a frame can be well captured, while the global\ncontext over the entire sequence is further captured by these hidden nodes with\na bidirectional LSTM. In the diffusing process, the learned spatial-temporal\ncontextual information is passed back to the spatial joints, leading to a\nbidirectional attentive graph convolutional network (BAGCN) that can facilitate\nskeleton-based action recognition. Extensive experiments on the challenging NTU\nRGB+D and Skeleton-Kinetics benchmarks demonstrate the efficacy of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 20:35:57 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gao", "Jialin", ""], ["He", "Tong", ""], ["Zhou", "Xi", ""], ["Ge", "Shiming", ""]]}, {"id": "1912.11527", "submitter": "Francisco Erivaldo Fernandes Junior", "authors": "Francisco Erivaldo Fernandes Junior, Gary G. Yen", "title": "Pruning Deep Convolutional Neural Networks Architectures with Evolution\n  Strategy", "comments": "Accepted at Information Sciences", "journal-ref": null, "doi": "10.1016/j.ins.2020.11.009", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Currently, Deep Convolutional Neural Networks (DCNNs) are used to solve all\nkinds of problems in the field of machine learning and artificial intelligence\ndue to their learning and adaptation capabilities. However, most successful\nDCNN models have a high computational complexity making them difficult to\ndeploy on mobile or embedded platforms. This problem has prompted many\nresearchers to develop algorithms and approaches to help reduce the\ncomputational complexity of such models. One of them is called filter pruning,\nwhere convolution filters are eliminated to reduce the number of parameters\nand, consequently, the computational complexity of the given model. In the\npresent work, we propose a novel algorithm to perform filter pruning by using\nMulti-Objective Evolution Strategy (ES) algorithm, called DeepPruningES. Our\napproach avoids the need for using any knowledge during the pruning procedure\nand helps decision-makers by returning three pruned CNN models with different\ntrade-offs between performance and computational complexity. We show that\nDeepPruningES can significantly reduce a model's computational complexity by\ntesting it on three DCNN architectures: Convolutional Neural Networks (CNNs),\nResidual Neural Networks (ResNets), and Densely Connected Neural Networks\n(DenseNets).\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 20:48:00 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 13:13:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Junior", "Francisco Erivaldo Fernandes", ""], ["Yen", "Gary G.", ""]]}, {"id": "1912.11531", "submitter": "Luca Pasqualini", "authors": "Luca Pasqualini, Maurizio Parton", "title": "Pseudo Random Number Generation: a Reinforcement Learning approach", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-Random Numbers Generators (PRNGs) are algorithms produced to generate\nlong sequences of statistically uncorrelated numbers, i.e. Pseudo-Random\nNumbers (PRNs). These numbers are widely employed in mid-level cryptography and\nin software applications. Test suites are used to evaluate PRNGs quality by\nchecking statistical properties of the generated sequences. Machine learning\ntechniques are often used to break these generators, for instance approximating\na certain generator or a certain sequence using a neural network. But what\nabout using machine learning to generate PRNs generators? This paper proposes a\nReinforcement Learning (RL) approach to the task of generating PRNGs from\nscratch by learning a policy to solve an N-dimensional navigation problem. In\nthis context, N is the length of the period of the generated sequence, and the\npolicy is iteratively improved using the average value of an appropriate test\nsuite run over that period. Aim of this work is to demonstrate the feasibility\nof the proposed approach, to compare it with classical methods, and to lay the\nfoundation of a research path which combines RL and PRNGs.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 13:32:07 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Pasqualini", "Luca", ""], ["Parton", "Maurizio", ""]]}, {"id": "1912.11540", "submitter": "Abdolreza Rashno Dr.", "authors": "Elyas Rashno, Abdolreza Rashno and Sadegh Fadaei", "title": "Fluid segmentation in Neutrosophic domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical coherence tomography (OCT) as retina imaging technology is currently\nused by ophthalmologist as a non-invasive and non-contact method for diagnosis\nof agerelated degeneration (AMD) and diabetic macular edema (DME) diseases.\nFluid regions in OCT images reveal the main signs of AMD and DME. In this\npaper, an efficient and fast clustering in neutrosophic (NS) domain referred as\nneutrosophic C-means is adapted for fluid segmentation. For this task, a NCM\ncost function in NS domain is adapted for fluid segmentation and then optimized\nby gradient descend methods which leads to binary segmentation of OCT Bscans to\nfluid and tissue regions. The proposed method is evaluated in OCT datasets of\nsubjects with DME abnormalities. Results showed that the proposed method\noutperforms existing fluid segmentation methods by 6% in dice coefficient and\nsensitivity criteria.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 09:52:00 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Rashno", "Elyas", ""], ["Rashno", "Abdolreza", ""], ["Fadaei", "Sadegh", ""]]}, {"id": "1912.11547", "submitter": "Alison Marczewski", "authors": "Alison Marczewski, Adriano Veloso, N\\'ivio Ziviani", "title": "Learning Transferable Features for Speech Emotion Recognition", "comments": "ACM-MM'17, October 23-27, 2017", "journal-ref": "Proceedings of the on Thematic Workshops of ACM Multimedia 2017.\n  ACM, 2017. Pages 529-536", "doi": "10.1145/3126686.3126735", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition from speech is one of the key steps towards emotional\nintelligence in advanced human-machine interaction. Identifying emotions in\nhuman speech requires learning features that are robust and discriminative\nacross diverse domains that differ in terms of language, spontaneity of speech,\nrecording conditions, and types of emotions. This corresponds to a learning\nscenario in which the joint distributions of features and labels may change\nsubstantially across domains. In this paper, we propose a deep architecture\nthat jointly exploits a convolutional network for extracting domain-shared\nfeatures and a long short-term memory network for classifying emotions using\ndomain-specific features. We use transferable features to enable model\nadaptation from multiple source domains, given the sparseness of speech emotion\ndata and the fact that target domains are short of labeled data. A\ncomprehensive cross-corpora experiment with diverse speech emotion domains\nreveals that transferable features provide gains ranging from 4.3% to 18.4% in\nspeech emotion recognition. We evaluate several domain adaptation approaches,\nand we perform an ablation study to understand which source domains add the\nmost to the overall recognition effectiveness for a given target domain.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:06:08 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Marczewski", "Alison", ""], ["Veloso", "Adriano", ""], ["Ziviani", "N\u00edvio", ""]]}, {"id": "1912.11548", "submitter": "David Craft", "authors": "Marleen Balvert, Georgios Patoulidis, Andrew Patti, Timo M. Deist,\n  Christine Eyler, Bas E. Dutilh, Alexander Sch\\\"onhuth, David Craft", "title": "A Drug Recommendation System (Dr.S) for cancer cell lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalizing drug prescriptions in cancer care based on genomic information\nrequires associating genomic markers with treatment effects. This is an\nunsolved challenge requiring genomic patient data in yet unavailable volumes as\nwell as appropriate quantitative methods. We attempt to solve this challenge\nfor an experimental proxy for which sufficient data is available: 42 drugs\ntested on 1018 cancer cell lines. Our goal is to develop a method to identify\nthe drug that is most promising based on a cell line's genomic information. For\nthis, we need to identify for each drug the machine learning method, choice of\nhyperparameters and genomic features for optimal predictive performance. We\nextensively compare combinations of gene sets (both curated and random),\ngenetic features, and machine learning algorithms for all 42 drugs. For each\ndrug, the best performing combination (considering only the curated gene sets)\nis selected. We use these top model parameters for each drug to build and\ndemonstrate a Drug Recommendation System (Dr.S). Insights resulting from this\nanalysis are formulated as best practices for developing drug recommendation\nsystems. The complete software system, called the Cell Line Analyzer, is\nwritten in Python and available on github.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 21:49:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Balvert", "Marleen", ""], ["Patoulidis", "Georgios", ""], ["Patti", "Andrew", ""], ["Deist", "Timo M.", ""], ["Eyler", "Christine", ""], ["Dutilh", "Bas E.", ""], ["Sch\u00f6nhuth", "Alexander", ""], ["Craft", "David", ""]]}, {"id": "1912.11554", "submitter": "Neeraj Pradhan", "authors": "Du Phan, Neeraj Pradhan, Martin Jankowiak", "title": "Composable Effects for Flexible and Accelerated Probabilistic\n  Programming in NumPyro", "comments": "10 pages, 2 figures; NeurIPS 2019 Program Transformations for Machine\n  Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NumPyro is a lightweight library that provides an alternate NumPy backend to\nthe Pyro probabilistic programming language with the same modeling interface,\nlanguage primitives and effect handling abstractions. Effect handlers allow\nPyro's modeling API to be extended to NumPyro despite its being built atop a\nfundamentally different JAX-based functional backend. In this work, we\ndemonstrate the power of composing Pyro's effect handlers with the program\ntransformations that enable hardware acceleration, automatic differentiation,\nand vectorization in JAX. In particular, NumPyro provides an iterative\nformulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT\ncompiled, yielding an implementation that is much faster than existing\nalternatives in both the small and large dataset regimes.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 22:09:36 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Phan", "Du", ""], ["Pradhan", "Neeraj", ""], ["Jankowiak", "Martin", ""]]}, {"id": "1912.11570", "submitter": "Alex Lamb", "authors": "Alex Lamb, Sherjil Ozair, Vikas Verma, David Ha", "title": "SketchTransfer: A Challenging New Task for Exploring Detail-Invariance\n  and the Abstractions Learned by Deep Networks", "comments": "Accepted WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have achieved excellent results in perceptual tasks, yet their\nability to generalize to variations not seen during training has come under\nincreasing scrutiny. In this work we focus on their ability to have invariance\ntowards the presence or absence of details. For example, humans are able to\nwatch cartoons, which are missing many visual details, without being explicitly\ntrained to do so. As another example, 3D rendering software is a relatively\nrecent development, yet people are able to understand such rendered scenes even\nthough they are missing details (consider a film like Toy Story). The failure\nof machine learning algorithms to do this indicates a significant gap in\ngeneralization between human abilities and the abilities of deep networks. We\npropose a dataset that will make it easier to study the detail-invariance\nproblem concretely. We produce a concrete task for this: SketchTransfer, and we\nshow that state-of-the-art domain transfer algorithms still struggle with this\ntask. The state-of-the-art technique which achieves over 95\\% on MNIST\n$\\xrightarrow{}$ SVHN transfer only achieves 59\\% accuracy on the\nSketchTransfer task, which is much better than random (11\\% accuracy) but falls\nshort of the 87\\% accuracy of a classifier trained directly on labeled\nsketches. This indicates that this task is approachable with today's best\nmethods but has substantial room for improvement.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 00:38:47 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Lamb", "Alex", ""], ["Ozair", "Sherjil", ""], ["Verma", "Vikas", ""], ["Ha", "David", ""]]}, {"id": "1912.11580", "submitter": "Muhammad Usman", "authors": "Muhammad Usman, Wenxi Wang, Kaiyuan Wang, Marko Vasic, Haris Vikalo,\n  Sarfraz Khurshid", "title": "A Study of the Learnability of Relational Properties: Model Counting\n  Meets Machine Learning (MCML)", "comments": null, "journal-ref": null, "doi": "10.1145/3385412.3386015", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the MCML approach for empirically studying the\nlearnability of relational properties that can be expressed in the well-known\nsoftware design language Alloy. A key novelty of MCML is quantification of the\nperformance of and semantic differences among trained machine learning (ML)\nmodels, specifically decision trees, with respect to entire (bounded) input\nspaces, and not just for given training and test datasets (as is the common\npractice). MCML reduces the quantification problems to the classic complexity\ntheory problem of model counting, and employs state-of-the-art model counters.\nThe results show that relatively simple ML models can achieve surprisingly high\nperformance (accuracy and F1-score) when evaluated in the common setting of\nusing training and test datasets - even when the training dataset is much\nsmaller than the test dataset - indicating the seeming simplicity of learning\nrelational properties. However, MCML metrics based on model counting show that\nthe performance can degrade substantially when tested against the entire\n(bounded) input space, indicating the high complexity of precisely learning\nthese properties, and the usefulness of model counting in quantifying the true\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 02:44:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 02:14:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Usman", "Muhammad", ""], ["Wang", "Wenxi", ""], ["Wang", "Kaiyuan", ""], ["Vasic", "Marko", ""], ["Vikalo", "Haris", ""], ["Khurshid", "Sarfraz", ""]]}, {"id": "1912.11589", "submitter": "Xin Liu", "authors": "Xin Liu, Haojie Pan, Mutian He, Yangqiu Song, Xin Jiang, Lifeng Shang", "title": "Neural Subgraph Isomorphism Counting", "comments": "Accepted by KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a new graph learning problem: learning to count\nsubgraph isomorphisms. Different from other traditional graph learning problems\nsuch as node classification and link prediction, subgraph isomorphism counting\nis NP-complete and requires more global inference to oversee the whole graph.\nTo make it scalable for large-scale graphs and patterns, we propose a learning\nframework which augments different representation learning architectures and\niteratively attends pattern and target data graphs to memorize subgraph\nisomorphisms for the global counting. We develop both small graphs (<= 1,024\nsubgraph isomorphisms in each) and large graphs (<= 4,096 subgraph isomorphisms\nin each) sets to evaluate different models. A mutagenic compound dataset,\nMUTAG, is also used to evaluate neural models and demonstrate the success of\ntransfer learning. While the learning based approach is inexact, we are able to\ngeneralize to count large patterns and data graphs in linear time compared to\nthe exponential time of the original NP-complete problem. Experimental results\nshow that learning based subgraph isomorphism counting can speed up the\ntraditional algorithm, VF2, 10-1,000 times with acceptable errors. Domain\nadaptation based on fine-tuning also shows the usefulness of our approach in\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 04:19:40 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:31:33 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 09:23:15 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Liu", "Xin", ""], ["Pan", "Haojie", ""], ["He", "Mutian", ""], ["Song", "Yangqiu", ""], ["Jiang", "Xin", ""], ["Shang", "Lifeng", ""]]}, {"id": "1912.11591", "submitter": "Tomoyuki Obuchi", "authors": "Alia Abbara, Yoshiyuki Kabashima, Tomoyuki Obuchi, Yingying Xu", "title": "Learning performance in inverse Ising problems with sparse teacher\n  couplings", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1742-5468/ab8c3a", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the learning performance of the pseudolikelihood maximization\nmethod for inverse Ising problems. In the teacher-student scenario under the\nassumption that the teacher's couplings are sparse and the student does not\nknow the graphical structure, the learning curve and order parameters are\nassessed in the typical case using the replica and cavity methods from\nstatistical mechanics. Our formulation is also applicable to a certain class of\ncost functions having locality; the standard likelihood does not belong to that\nclass. The derived analytical formulas indicate that the perfect inference of\nthe presence/absence of the teacher's couplings is possible in the\nthermodynamic limit taking the number of spins $N$ as infinity while keeping\nthe dataset size $M$ proportional to $N$, as long as $\\alpha=M/N > 2$.\nMeanwhile, the formulas also show that the estimated coupling values\ncorresponding to the truly existing ones in the teacher tend to be\noverestimated in the absolute value, manifesting the presence of estimation\nbias. These results are considered to be exact in the thermodynamic limit on\nlocally tree-like networks, such as the regular random or Erd\\H{o}s--R\\'enyi\ngraphs. Numerical simulation results fully support the theoretical predictions.\nAdditional biases in the estimators on loopy graphs are also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 04:31:29 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:38:14 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Abbara", "Alia", ""], ["Kabashima", "Yoshiyuki", ""], ["Obuchi", "Tomoyuki", ""], ["Xu", "Yingying", ""]]}, {"id": "1912.11597", "submitter": "Shin'ya Yamaguchi", "authors": "Shin'ya Yamaguchi, Sekitoshi Kanai, Takeharu Eda", "title": "Effective Data Augmentation with Multi-Domain Learning GANs", "comments": "AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For deep learning applications, the massive data development (e.g.,\ncollecting, labeling), which is an essential process in building practical\napplications, still incurs seriously high costs. In this work, we propose an\neffective data augmentation method based on generative adversarial networks\n(GANs), called Domain Fusion. Our key idea is to import the knowledge contained\nin an outer dataset to a target model by using a multi-domain learning GAN. The\nmulti-domain learning GAN simultaneously learns the outer and target dataset\nand generates new samples for the target tasks. The simultaneous learning\nprocess makes GANs generate the target samples with high fidelity and variety.\nAs a result, we can obtain accurate models for the target tasks by using these\ngenerated samples even if we only have an extremely low volume target dataset.\nWe experimentally evaluate the advantages of Domain Fusion in image\nclassification tasks on 3 target datasets: CIFAR-100, FGVC-Aircraft, and Indoor\nScene Recognition. When trained on each target dataset reduced the samples to\n5,000 images, Domain Fusion achieves better classification accuracy than the\ndata augmentation using fine-tuned GANs. Furthermore, we show that Domain\nFusion improves the quality of generated samples, and the improvements can\ncontribute to higher accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:39:45 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Yamaguchi", "Shin'ya", ""], ["Kanai", "Sekitoshi", ""], ["Eda", "Takeharu", ""]]}, {"id": "1912.11603", "submitter": "Shin'ya Yamaguchi", "authors": "Shin'ya Yamaguchi, Sekitoshi Kanai, Tetsuya Shioda, Shoichiro Takeda", "title": "Image Enhanced Rotation Prediction for Self-Supervised Learning", "comments": "Accepted to IEEE ICIP 2021. The title has been changed from \"Multiple\n  Pretext-Task for Self-Supervised Learning via Mixing Multiple Image\n  Transformations\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rotation prediction (Rotation) is a simple pretext-task for\nself-supervised learning (SSL), where models learn useful representations for\ntarget vision tasks by solving pretext-tasks. Although Rotation captures\ninformation of object shapes, it hardly captures information of textures. To\ntackle this problem, we introduce a novel pretext-task called image enhanced\nrotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and\nanother pretext-task based on image enhancement (e.g., sharpening and\nsolarizing) while maintaining simplicity. Through the simultaneous prediction\nof rotation and image enhancement, models learn representations to capture the\ninformation of not only object shapes but also textures. Our experimental\nresults show that IE-Rot models outperform Rotation on various standard\nbenchmarks including ImageNet classification, PASCAL-VOC detection, and COCO\ndetection/segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 06:11:35 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 08:12:54 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Yamaguchi", "Shin'ya", ""], ["Kanai", "Sekitoshi", ""], ["Shioda", "Tetsuya", ""], ["Takeda", "Shoichiro", ""]]}, {"id": "1912.11606", "submitter": "Shen Cai", "authors": "Hui Cao, Haikuan Du, Siyu Zhang, and Shen Cai", "title": "InSphereNet: a Concise Representation and Classification Method for 3D\n  Object", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an InSphereNet method for the problem of 3D object\nclassification. Unlike previous methods that use points, voxels, or multi-view\nimages as inputs of deep neural network (DNN), the proposed method constructs a\nclass of more representative features named infilling spheres from signed\ndistance field (SDF). Because of the admirable spatial representation of\ninfilling spheres, we can not only utilize very fewer number of spheres to\naccomplish classification task, but also design a lightweight InSphereNet with\nless layers and parameters than previous methods. Experiments on ModelNet40\nshow that the proposed method leads to superior performance than PointNet and\nPointNet++ in accuracy. In particular, if there are only a few dozen sphere\ninputs or about 100000 DNN parameters, the accuracy of our method remains at a\nvery high level (over 88%). This further validates the conciseness and\neffectiveness of the proposed InSphere 3D representation. Keywords: 3D object\nclassification , signed distance field , deep learning , infilling sphere\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 06:26:20 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 01:48:16 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Cao", "Hui", ""], ["Du", "Haikuan", ""], ["Zhang", "Siyu", ""], ["Cai", "Shen", ""]]}, {"id": "1912.11613", "submitter": "Lu Huang", "authors": "Lu Huang and Gaofeng Cheng and Pengyuan Zhang and Yi Yang and Shumin\n  Xu and Jiasong Sun", "title": "Utterance-level Permutation Invariant Training with Latency-controlled\n  BLSTM for Single-channel Multi-talker Speech Separation", "comments": "Proceedings of APSIPA Annual Summit and Conference 2019, 18-21\n  November 2019, Lanzhou, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utterance-level permutation invariant training (uPIT) has achieved promising\nprogress on single-channel multi-talker speech separation task. Long short-term\nmemory (LSTM) and bidirectional LSTM (BLSTM) are widely used as the separation\nnetworks of uPIT, i.e. uPIT-LSTM and uPIT-BLSTM. uPIT-LSTM has lower latency\nbut worse performance, while uPIT-BLSTM has better performance but higher\nlatency. In this paper, we propose using latency-controlled BLSTM (LC-BLSTM)\nduring inference to fulfill low-latency and good-performance speech separation.\nTo find a better training strategy for BLSTM-based separation network,\nchunk-level PIT (cPIT) and uPIT are compared. The experimental results show\nthat uPIT outperforms cPIT when LC-BLSTM is used during inference. It is also\nfound that the inter-chunk speaker tracing (ST) can further improve the\nseparation performance of uPIT-LC-BLSTM. Evaluated on the WSJ0 two-talker\nmixed-speech separation task, the absolute gap of signal-to-distortion ratio\n(SDR) between uPIT-BLSTM and uPIT-LC-BLSTM is reduced to within 0.7 dB.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 07:40:02 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Huang", "Lu", ""], ["Cheng", "Gaofeng", ""], ["Zhang", "Pengyuan", ""], ["Yang", "Yi", ""], ["Xu", "Shumin", ""], ["Sun", "Jiasong", ""]]}, {"id": "1912.11615", "submitter": "Guixiang Ma", "authors": "Guixiang Ma, Nesreen K. Ahmed, Theodore L. Willke, Philip S. Yu", "title": "Deep Graph Similarity Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains where data are represented as graphs, learning a similarity\nmetric among graphs is considered a key problem, which can further facilitate\nvarious learning tasks, such as classification, clustering, and similarity\nsearch. Recently, there has been an increasing interest in deep graph\nsimilarity learning, where the key idea is to learn a deep learning model that\nmaps input graphs to a target space such that the distance in the target space\napproximates the structural distance in the input space. Here, we provide a\ncomprehensive review of the existing literature of deep graph similarity\nlearning. We propose a systematic taxonomy for the methods and applications.\nFinally, we discuss the challenges and future directions for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 08:04:52 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 05:41:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ma", "Guixiang", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Theodore L.", ""], ["Yu", "Philip S.", ""]]}, {"id": "1912.11619", "submitter": "Qijie Wei", "authors": "Qijie Wei, Xirong Li, Weihong Yu, Xiao Zhang, Yongpeng Zhang, Bojie\n  Hu, Bin Mo, Di Gong, Ning Chen, Dayong Ding, Youxin Chen", "title": "Learn to Segment Retinal Lesions and Beyond", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Towards automated retinal screening, this paper makes an endeavor to\nsimultaneously achieve pixel-level retinal lesion segmentation and image-level\ndisease classification. Such a multi-task approach is crucial for accurate and\nclinically interpretable disease diagnosis. Prior art is insufficient due to\nthree challenges, i.e., lesions lacking objective boundaries, clinical\nimportance of lesions irrelevant to their size, and the lack of one-to-one\ncorrespondence between lesion and disease classes. This paper attacks the three\nchallenges in the context of diabetic retinopathy (DR) grading. We propose\nLesion-Net, a new variant of fully convolutional networks, with its expansive\npath re-designed to tackle the first challenge. A dual Dice loss that leverages\nboth semantic segmentation and image classification losses is introduced to\nresolve the second challenge. Lastly, we build a multi-task network that\nemploys Lesion-Net as a side-attention branch for both DR grading and result\ninterpretation. A set of 12K fundus images is manually segmented by 45\nophthalmologists for 8 DR-related lesions, resulting in 290K manual segments in\ntotal. Extensive experiments on this large-scale dataset show that our proposed\napproach surpasses the prior art for multiple tasks including lesion\nsegmentation, lesion classification and DR grading\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 08:14:04 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 01:44:53 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 03:43:34 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wei", "Qijie", ""], ["Li", "Xirong", ""], ["Yu", "Weihong", ""], ["Zhang", "Xiao", ""], ["Zhang", "Yongpeng", ""], ["Hu", "Bojie", ""], ["Mo", "Bin", ""], ["Gong", "Di", ""], ["Chen", "Ning", ""], ["Ding", "Dayong", ""], ["Chen", "Youxin", ""]]}, {"id": "1912.11637", "submitter": "Guangxiang Zhao", "authors": "Guangxiang Zhao, Junyang Lin, Zhiyuan Zhang, Xuancheng Ren, Qi Su, Xu\n  Sun", "title": "Explicit Sparse Transformer: Concentrated Attention Through Explicit\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention based Transformer has demonstrated the state-of-the-art\nperformances in a number of natural language processing tasks. Self-attention\nis able to model long-term dependencies, but it may suffer from the extraction\nof irrelevant information in the context. To tackle the problem, we propose a\nnovel model called \\textbf{Explicit Sparse Transformer}. Explicit Sparse\nTransformer is able to improve the concentration of attention on the global\ncontext through an explicit selection of the most relevant segments. Extensive\nexperimental results on a series of natural language processing and computer\nvision tasks, including neural machine translation, image captioning, and\nlanguage modeling, all demonstrate the advantages of Explicit Sparse\nTransformer in model performance. We also show that our proposed sparse\nattention method achieves comparable or better results than the previous sparse\nattention method, but significantly reduces training and testing time. For\nexample, the inference speed is twice that of sparsemax in Transformer model.\nCode will be available at\n\\url{https://github.com/lancopku/Explicit-Sparse-Transformer}\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 10:59:31 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhao", "Guangxiang", ""], ["Lin", "Junyang", ""], ["Zhang", "Zhiyuan", ""], ["Ren", "Xuancheng", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1912.11652", "submitter": "Yuru Zhu", "authors": "Shinyuu Lee and Yuru Zhu", "title": "Confounder Selection via Support Intersection", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confounding matters in almost all observational studies that focus on\ncausality. In order to eliminate bias caused by connfounders, oftentimes a\nsubstantial number of features need to be collected in the analysis. In this\ncase, large p small n problem can arise and dimensional reduction technique is\nrequired. However, the traditional variable selection methods which focus on\nprediction are problematic in this setting. Throughout this paper, we analyze\nthis issue in detail and assume the sparsity of confounders which is different\nfrom the previous works. Under this assumption we propose several variable\nselection methods based on support intersection to pick out the confounders.\nAlso we discussed the different approaches for estimation of causal effect and\nunconfoundedness test. To aid in our description, finally we provide numerical\nsimulations to support our claims and compare to common heuristic methods, as\nwell as applications on real dataset.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 12:23:58 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Lee", "Shinyuu", ""], ["Zhu", "Yuru", ""]]}, {"id": "1912.11675", "submitter": "Zengjie Song", "authors": "Zengjie Song, Oluwasanmi Koyejo, Jiangshe Zhang", "title": "Learning Controllable Disentangled Representations with Decorrelation\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial problem in learning disentangled image representations is\ncontrolling the degree of disentanglement during image editing, while\npreserving the identity of objects. In this work, we propose a simple yet\neffective model with the encoder-decoder architecture to address this\nchallenge. To encourage disentanglement, we devise a distance covariance based\ndecorrelation regularization. Further, for the reconstruction step, our model\nleverages a soft target representation combined with the latent image code. By\nexploiting the real-valued space of the soft target representations, we are\nable to synthesize novel images with the designated properties. We also design\na classification based protocol to quantitatively evaluate the disentanglement\nstrength of our model. Experimental results show that the proposed model\ncompetently disentangles factors of variation, and is able to manipulate face\nimages to synthesize the desired attributes.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 14:18:08 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Song", "Zengjie", ""], ["Koyejo", "Oluwasanmi", ""], ["Zhang", "Jiangshe", ""]]}, {"id": "1912.11676", "submitter": "Sajjad Mozaffari", "authors": "Sajjad Mozaffari, Omar Y. Al-Jarrah, Mehrdad Dianati, Paul Jennings,\n  and Alexandros Mouzakitis", "title": "Deep Learning-based Vehicle Behaviour Prediction For Autonomous Driving\n  Applications: A Review", "comments": null, "journal-ref": null, "doi": "10.1109/TITS.2020.3012034", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behaviour prediction function of an autonomous vehicle predicts the future\nstates of the nearby vehicles based on the current and past observations of the\nsurrounding environment. This helps enhance their awareness of the imminent\nhazards. However, conventional behaviour prediction solutions are applicable in\nsimple driving scenarios that require short prediction horizons. Most recently,\ndeep learning-based approaches have become popular due to their superior\nperformance in more complex environments compared to the conventional\napproaches. Motivated by this increased popularity, we provide a comprehensive\nreview of the state-of-the-art of deep learning-based approaches for vehicle\nbehaviour prediction in this paper. We firstly give an overview of the generic\nproblem of vehicle behaviour prediction and discuss its challenges, followed by\nclassification and review of the most recent deep learning-based solutions\nbased on three criteria: input representation, output type, and prediction\nmethod. The paper also discusses the performance of several well-known\nsolutions, identifies the research gaps in the literature and outlines\npotential new research directions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 14:22:41 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 15:52:45 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Mozaffari", "Sajjad", ""], ["Al-Jarrah", "Omar Y.", ""], ["Dianati", "Mehrdad", ""], ["Jennings", "Paul", ""], ["Mouzakitis", "Alexandros", ""]]}, {"id": "1912.11683", "submitter": "Rafael Valle", "authors": "Rafael Valle, Fitsum Reda, Mohammad Shoeybi, Patrick Legresley, Andrew\n  Tao, Bryan Catanzaro", "title": "Neural ODEs for Image Segmentation with Level Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for image segmentation that combines Neural\nOrdinary Differential Equations (NODEs) and the Level Set method. Our approach\nparametrizes the evolution of an initial contour with a NODE that implicitly\nlearns from data a speed function describing the evolution. In addition, for\ncases where an initial contour is not available and to alleviate the need for\ncareful choice or design of contour embedding functions, we propose a\nNODE-based method that evolves an image embedding into a dense per-pixel\nsemantic label space. We evaluate our methods on kidney segmentation (KiTS19)\nand on salient object detection (PASCAL-S, ECSSD and HKU-IS). In addition to\nimproving initial contours provided by deep learning models while using a\nfraction of their number of parameters, our approach achieves F scores that are\nhigher than several state-of-the-art deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 15:02:24 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Valle", "Rafael", ""], ["Reda", "Fitsum", ""], ["Shoeybi", "Mohammad", ""], ["Legresley", "Patrick", ""], ["Tao", "Andrew", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1912.11684", "submitter": "Chuang Gan", "authors": "Chuang Gan, Yiwei Zhang, Jiajun Wu, Boqing Gong, Joshua B. Tenenbaum", "title": "Look, Listen, and Act: Towards Audio-Visual Embodied Navigation", "comments": "Accepted by ICRA 2020. Project page: http://avn.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial ability of mobile intelligent agents is to integrate the evidence\nfrom multiple sensory inputs in an environment and to make a sequence of\nactions to reach their goals. In this paper, we attempt to approach the problem\nof Audio-Visual Embodied Navigation, the task of planning the shortest path\nfrom a random starting location in a scene to the sound source in an indoor\nenvironment, given only raw egocentric visual and audio sensory data. To\naccomplish this task, the agent is required to learn from various modalities,\ni.e. relating the audio signal to the visual environment. Here we describe an\napproach to audio-visual embodied navigation that takes advantage of both\nvisual and audio pieces of evidence. Our solution is based on three key ideas:\na visual perception mapper module that constructs its spatial memory of the\nenvironment, a sound perception module that infers the relative location of the\nsound source from the agent, and a dynamic path planner that plans a sequence\nof actions based on the audio-visual observations and the spatial memory of the\nenvironment to navigate toward the goal. Experimental results on a newly\ncollected Visual-Audio-Room dataset using the simulated multi-modal environment\ndemonstrate the effectiveness of our approach over several competitive\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 15:07:26 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 00:18:49 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Gan", "Chuang", ""], ["Zhang", "Yiwei", ""], ["Wu", "Jiajun", ""], ["Gong", "Boqing", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1912.11688", "submitter": "Abhishek Singh", "authors": "Abhishek Kumar Singh, Manish Gupta, Vasudeva Varma", "title": "Unity in Diversity: Learning Distributed Heterogeneous Sentence\n  Representation for Extractive Summarization", "comments": "Accepted in AAAI Conference on Artificial Intelligence, 2018.\n  Retrieved from\n  https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16977", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated multi-document extractive text summarization is a widely studied\nresearch problem in the field of natural language understanding. Such\nextractive mechanisms compute in some form the worthiness of a sentence to be\nincluded into the summary. While the conventional approaches rely on human\ncrafted document-independent features to generate a summary, we develop a\ndata-driven novel summary system called HNet, which exploits the various\nsemantic and compositional aspects latent in a sentence to capture document\nindependent features. The network learns sentence representation in a way that,\nsalient sentences are closer in the vector space than non-salient sentences.\nThis semantic and compositional feature vector is then concatenated with the\ndocument-dependent features for sentence ranking. Experiments on the DUC\nbenchmark datasets (DUC-2001, DUC-2002 and DUC-2004) indicate that our model\nshows significant performance gain of around 1.5-2 points in terms of ROUGE\nscore compared with the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 16:25:29 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singh", "Abhishek Kumar", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1912.11692", "submitter": "Pratik Bajaria", "authors": "Kshitij Singh and Pratik K. Bajaria", "title": "Thermostatic control for demand response using distributed averaging and\n  deep neural networks", "comments": "13 Pages, 21 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart buildings are the need of the day with increasing demand-supply ratios\nand deficiency to generate considerably. In any modern non-industrial\ninfrastructure, these demands mainly comprise of thermostatically controlled\nloads (TCLs), which can be manoeuvred. TCL loads like air-conditioner, heater,\nrefrigerator, are ubiquitous, and their operating times can be controlled to\nachieve desired aggregate power. This power aggregation, in turn, helps achieve\nload management targets and thereby serve as ancillary service (AS) to the\npower grid. In this work, a distributed averaging protocol is used to achieve\nthe desired power aggregate set by the utility using steady-state\ndesynchronization. The results are verified using a computer program for a\nhomogeneous and heterogeneous population of TCLs. Further, load following\nscenario has been implemented using the utility as a reference. Apart from\nproviding a significant AS to the power grid, the proposed idea also helps\nreduce the amplitude of power system oscillations imparted by the TCLs.\nHardware-based results are obtained to verify its implementation feasibility in\nreal-time. Additionally, we extend this idea to data-driven paradigm and\nprovide comparisons therein.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 17:00:46 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singh", "Kshitij", ""], ["Bajaria", "Pratik K.", ""]]}, {"id": "1912.11701", "submitter": "Abhishek Singh", "authors": "Abhishek Kumar Singh, Manish Gupta, Vasudeva Varma", "title": "Hybrid MemNet for Extractive Summarization", "comments": "Accepted in CIKM '17 Proceedings of the 2017 ACM on Conference on\n  Information and Knowledge Management", "journal-ref": "In Proceedings of the 2017 ACM on Conference on Information and\n  Knowledge Management (CIKM '17). ACM, New York, NY, USA, pages 2303-2306", "doi": "10.1145/3132847.3133127", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive text summarization has been an extensive research problem in the\nfield of natural language understanding. While the conventional approaches rely\nmostly on manually compiled features to generate the summary, few attempts have\nbeen made in developing data-driven systems for extractive summarization. To\nthis end, we present a fully data-driven end-to-end deep network which we call\nas Hybrid MemNet for single document summarization task. The network learns the\ncontinuous unified representation of a document before generating its summary.\nIt jointly captures local and global sentential information along with the\nnotion of summary worthy sentences. Experimental results on two different\ncorpora confirm that our model shows significant performance gains compared\nwith the state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 17:48:09 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singh", "Abhishek Kumar", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1912.11713", "submitter": "Jan Gra{\\ss}hoff", "authors": "Jan Gra{\\ss}hoff, Alexandra Jankowski and Philipp Rostalski", "title": "Scalable Gaussian Process Regression for Kernels with a Non-Stationary\n  Phase", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of Gaussian processes (GPs) to large data sets is limited due\nto heavy memory and computational requirements. A variety of methods has been\nproposed to enable scalability, one of which is to exploit structure in the\nkernel matrix. Previous methods, however, cannot easily deal with\nnon-stationary processes. This paper presents an efficient GP framework, that\nextends structured kernel interpolation methods to GPs with a non-stationary\nphase. We particularly treat mixtures of non-stationary processes, which are\ncommonly used in the context of separation problems e.g. in biomedical signal\nprocessing. Our approach employs multiple sets of non-equidistant inducing\npoints to account for the non-stationarity and retrieve Toeplitz and Kronecker\nstructure in the kernel matrix allowing for efficient inference. Kernel\nlearning is done by optimizing the marginal likelihood, which can be\napproximated efficiently using stochastic trace estimation methods. Our\napproach is demonstrated on numerical examples and large biomedical datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 20:15:54 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gra\u00dfhoff", "Jan", ""], ["Jankowski", "Alexandra", ""], ["Rostalski", "Philipp", ""]]}, {"id": "1912.11739", "submitter": "Haiyue Song", "authors": "Haiyue Song, Raj Dabre, Atsushi Fujita, Sadao Kurohashi", "title": "Coursera Corpus Mining and Multistage Fine-Tuning for Improving Lectures\n  Translation", "comments": "10 pages, 1 figure, 9 tables, under review by LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lectures translation is a case of spoken language translation and there is a\nlack of publicly available parallel corpora for this purpose. To address this,\nwe examine a language independent framework for parallel corpus mining which is\na quick and effective way to mine a parallel corpus from publicly available\nlectures at Coursera. Our approach determines sentence alignments, relying on\nmachine translation and cosine similarity over continuous-space sentence\nrepresentations. We also show how to use the resulting corpora in a multistage\nfine-tuning based domain adaptation for high-quality lectures translation. For\nJapanese--English lectures translation, we extracted parallel data of\napproximately 40,000 lines and created development and test sets through manual\nfiltering for benchmarking translation performance. We demonstrate that the\nmined corpus greatly enhances the quality of translation when used in\nconjunction with out-of-domain parallel corpora via multistage training. This\npaper also suggests some guidelines to gather and clean corpora, mine parallel\nsentences, address noise in the mined data, and create high-quality evaluation\nsplits. For the sake of reproducibility, we will release our code for parallel\ndata creation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 01:12:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:16:24 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Song", "Haiyue", ""], ["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1912.11747", "submitter": "Jen-Yu Liu", "authors": "Jen-Yu Liu and Yu-Hua Chen and Yin-Cheng Yeh and Yi-Hsuan Yang", "title": "Score and Lyrics-Free Singing Voice Generation", "comments": "Accepted by International Conference on Computational Creativity\n  (ICCC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for singing voice have been mostly concerned with the task\nof ``singing voice synthesis,'' i.e., to produce singing voice waveforms given\nmusical scores and text lyrics. In this work, we explore a novel yet\nchallenging alternative: singing voice generation without pre-assigned scores\nand lyrics, in both training and inference time. In particular, we outline\nthree such generation schemes, and propose a pipeline to tackle these new\ntasks. Moreover, we implement such models using generative adversarial networks\nand evaluate them both objectively and subjectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 01:45:03 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 06:48:42 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Liu", "Jen-Yu", ""], ["Chen", "Yu-Hua", ""], ["Yeh", "Yin-Cheng", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1912.11751", "submitter": "Davoud Hejazi", "authors": "Davoud Hejazi, Shuangjun Liu, Amirreza Farnoosh, Sarah Ostadabbas, and\n  Swastik Kar", "title": "Development of Use-specific High Performance Cyber-Nanomaterial Optical\n  Detectors by Effective Choice of Machine Learning Algorithms", "comments": "34 pages combined with images and references, 5 figures, added 1\n  table of content graphics image at the beginning of article, fixed the typo\n  in title", "journal-ref": null, "doi": "10.1088/2632-2153/ab8967", "report-no": null, "categories": "physics.app-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their inherent variabilities,nanomaterial-based sensors are\nchallenging to translate into real-world applications,where\nreliability/reproducibility is key.Recently we showed Bayesian inference can be\nemployed on engineered variability in layered nanomaterial-based optical\ntransmission filters to determine optical wavelengths with high\naccuracy/precision.In many practical applications the sensing cost/speed and\nlong-term reliability can be equal or more important considerations.Though\nvarious machine learning tools are frequently used on sensor/detector networks\nto address these,nonetheless their effectiveness on nanomaterial-based sensors\nhas not been explored.Here we show the best choice of ML algorithm in a\ncyber-nanomaterial detector is mainly determined by specific use\nconsiderations,e.g.,accuracy, computational cost,speed, and resilience against\ndrifts/ageing effects.When sufficient data/computing resources are\nprovided,highest sensing accuracy can be achieved by the kNN and Bayesian\ninference algorithms,but but can be computationally expensive for real-time\napplications.In contrast,artificial neural networks are computationally\nexpensive to train,but provide the fastest result under testing conditions and\nremain reasonably accurate.When data is limited,SVMs perform well even with\nsmall training sets,while other algorithms show considerable reduction in\naccuracy if data is scarce,hence,setting a lower limit on the size of required\ntraining data.We show by tracking/modeling the long-term drifts of the detector\nperformance over large (1year) period,it is possible to improve the predictive\naccuracy with no need for recalibration.Our research shows for the first time\nif the ML algorithm is chosen specific to use-case,low-cost solution-processed\ncyber-nanomaterial detectors can be practically implemented under diverse\noperational requirements,despite their inherent variabilities.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 02:44:55 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 20:52:20 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 18:50:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hejazi", "Davoud", ""], ["Liu", "Shuangjun", ""], ["Farnoosh", "Amirreza", ""], ["Ostadabbas", "Sarah", ""], ["Kar", "Swastik", ""]]}, {"id": "1912.11755", "submitter": "Min Shi Mr.", "authors": "Min Shi, Yufei Tang, Xingquan Zhu and Jianxun Liu", "title": "Feature-Attention Graph Convolutional Networks for Noise Resilient\n  Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise and inconsistency commonly exist in real-world information networks,\ndue to inherent error-prone nature of human or user privacy concerns. To date,\ntremendous efforts have been made to advance feature learning from networks,\nincluding the most recent Graph Convolutional Networks (GCN) or attention GCN,\nby integrating node content and topology structures. However, all existing\nmethods consider networks as error-free sources and treat feature content in\neach node as independent and equally important to model node relations. The\nerroneous node content, combined with sparse features, provide essential\nchallenges for existing methods to be used on real-world noisy networks. In\nthis paper, we propose FA-GCN, a feature-attention graph convolution learning\nframework, to handle networks with noisy and sparse node content. To tackle\nnoise and sparse content in each node, FA-GCN first employs a long short-term\nmemory (LSTM) network to learn dense representation for each feature. To model\ninteractions between neighboring nodes, a feature-attention mechanism is\nintroduced to allow neighboring nodes learn and vary feature importance, with\nrespect to their connections. By using spectral-based graph convolution\naggregation process, each node is allowed to concentrate more on the most\ndetermining neighborhood features aligned with the corresponding learning task.\nExperiments and validations, w.r.t. different noise levels, demonstrate that\nFA-GCN achieves better performance than state-of-the-art methods on both\nnoise-free and noisy networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 02:51:55 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shi", "Min", ""], ["Tang", "Yufei", ""], ["Zhu", "Xingquan", ""], ["Liu", "Jianxun", ""]]}, {"id": "1912.11757", "submitter": "Min Shi Mr.", "authors": "Min Shi, Yufei Tang, Xingquan Zhu and Jianxun Liu", "title": "Multi-Label Graph Convolutional Network Representation Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation of graph-based systems is fundamental across many\ndisciplines. To date, most existing methods for representation learning\nprimarily focus on networks with simplex labels, yet real-world objects (nodes)\nare inherently complex in nature and often contain rich semantics or labels,\ne.g., a user may belong to diverse interest groups of a social network,\nresulting in multi-label networks for many applications. The multi-label\nnetwork nodes not only have multiple labels for each node, such labels are\noften highly correlated making existing methods ineffective or fail to handle\nsuch correlation for node representation learning. In this paper, we propose a\nnovel multi-label graph convolutional network (ML-GCN) for learning node\nrepresentation for multi-label networks. To fully explore label-label\ncorrelation and network topology structures, we propose to model a multi-label\nnetwork as two Siamese GCNs: a node-node-label graph and a label-label-node\ngraph. The two GCNs each handle one aspect of representation learning for nodes\nand labels, respectively, and they are seamlessly integrated under one\nobjective function. The learned label representations can effectively preserve\nthe inner-label interaction and node label properties, and are then aggregated\nto enhance the node representation learning under a unified training framework.\nExperiments and comparisons on multi-label node classification validate the\neffectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 02:52:47 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shi", "Min", ""], ["Tang", "Yufei", ""], ["Zhu", "Xingquan", ""], ["Liu", "Jianxun", ""]]}, {"id": "1912.11760", "submitter": "Longfei Li", "authors": "Longfei Li, Ziqi Liu, Chaochao Chen, Ya-Lin Zhang, Jun Zhou, Xiaolong\n  Li", "title": "A Time Attention based Fraud Transaction Detection Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With online payment platforms being ubiquitous and important, fraud\ntransaction detection has become the key for such platforms, to ensure user\naccount safety and platform security. In this work, we present a novel method\nfor detecting fraud transactions by leveraging patterns from both users' static\nprofiles and users' dynamic behaviors in a unified framework. To address and\nexplore the information of users' behaviors in continuous time spaces, we\npropose to use \\emph{time attention based recurrent layers} to embed the\ndetailed information of the time interval, such as the durations of specific\nactions, time differences between different actions and sequential behavior\npatterns,etc., in the same latent space. We further combine the learned\nembeddings and users' static profiles altogether in a unified framework.\nExtensive experiments validate the effectiveness of our proposed methods over\nstate-of-the-art methods on various evaluation metrics, especially on\n\\emph{recall at top percent} which is an important metric for measuring the\nbalance between service experiences and risk of potential losses.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 03:09:43 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 11:13:52 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Li", "Longfei", ""], ["Liu", "Ziqi", ""], ["Chen", "Chaochao", ""], ["Zhang", "Ya-Lin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1912.11761", "submitter": "Jie Fang", "authors": "Jie Fang, Shutao Xia, Jianwu Lin, Zhikang Xia, Xiang Liu, and Yong\n  Jiang", "title": "Alpha Discovery Neural Network based on Prior Knowledge", "comments": "Accepted by KDD-2020-ML in Finance, 8 pages. KDD 2020 Workshop on\n  Machine Learning in Finance. https://sites.google.com/view/kdd-mlf-2020/home", "journal-ref": "KDD 2020 Workshop on Machine Learning in Finance", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic programming (GP) is the state-of-the-art in financial automated\nfeature construction task. It employs reverse polish expression to represent\nfeatures and then conducts the evolution process. However, with the development\nof deep learning, more powerful feature extraction tools are available. This\npaper proposes Alpha Discovery Neural Network (ADNN), a tailored neural network\nstructure which can automatically construct diversified financial technical\nindicators based on prior knowledge. We mainly made three contributions. First,\nwe use domain knowledge in quantitative trading to design the sampling rules\nand object function. Second, pre-training and model pruning has been used to\nreplace genetic programming, because it can conduct more efficient evolution\nprocess. Third, the feature extractors in ADNN can be replaced by different\nfeature extractors and produce different functions. The experiment results show\nthat ADNN can construct more informative and diversified features than GP,\nwhich can effectively enriches the current factor pool. The fully-connected\nnetwork and recurrent network are better at extracting information from the\nfinancial time series than the convolution neural network. In real practice,\nfeatures constructed by ADNN can always improve multi-factor strategies'\nrevenue, sharpe ratio, and max draw-down, compared with the investment\nstrategies without these factors.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 03:10:17 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 06:29:50 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 12:57:20 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 13:51:30 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 06:18:28 GMT"}, {"version": "v6", "created": "Sat, 3 Oct 2020 16:07:01 GMT"}, {"version": "v7", "created": "Tue, 13 Oct 2020 16:29:42 GMT"}, {"version": "v8", "created": "Thu, 26 Nov 2020 06:22:03 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Fang", "Jie", ""], ["Xia", "Shutao", ""], ["Lin", "Jianwu", ""], ["Xia", "Zhikang", ""], ["Liu", "Xiang", ""], ["Jiang", "Yong", ""]]}, {"id": "1912.11762", "submitter": "Rory Bunker", "authors": "Rory Bunker (1), Teo Susnjak (2) ((1) Nagoya Institute of Technology,\n  Japan, (2) Massey University, Auckland, New Zealand)", "title": "The Application of Machine Learning Techniques for Predicting Results in\n  Team Sport: A Review", "comments": "48 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, Machine Learning (ML) techniques have been\nincreasingly utilized for the purpose of predicting outcomes in sport. In this\npaper, we provide a review of studies that have used ML for predicting results\nin team sport, covering studies from 1996 to 2019. We sought to answer five key\nresearch questions while extensively surveying papers in this field. This paper\noffers insights into which ML algorithms have tended to be used in this field,\nas well as those that are beginning to emerge with successful outcomes. Our\nresearch highlights defining characteristics of successful studies and\nidentifies robust strategies for evaluating accuracy results in this\napplication domain. Our study considers accuracies that have been achieved\nacross different sports and explores the notion that outcomes of some team\nsports could be inherently more difficult to predict than others. Finally, our\nstudy uncovers common themes of future research directions across all surveyed\npapers, looking for gaps and opportunities, while proposing recommendations for\nfuture researchers in this domain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 03:12:21 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Bunker", "Rory", ""], ["Susnjak", "Teo", ""]]}, {"id": "1912.11785", "submitter": "Zhao Zhang", "authors": "Jiahuan Ren, Zhao Zhang, Sheng Li, Yang Wang, Guangcan Liu, Shuicheng\n  Yan, Meng Wang", "title": "Learning Hybrid Representation by Robust Dictionary Learning in\n  Factorized Compressed Space", "comments": "Accepted by IEEE TIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the robust dictionary learning (DL) to discover\nthe hybrid salient low-rank and sparse representation in a factorized\ncompressed space. A Joint Robust Factorization and Projective Dictionary\nLearning (J-RFDL) model is presented. The setting of J-RFDL aims at improving\nthe data representations by enhancing the robustness to outliers and noise in\ndata, encoding the reconstruction error more accurately and obtaining hybrid\nsalient coefficients with accurate reconstruction ability. Specifically, J-RFDL\nperforms the robust representation by DL in a factorized compressed space to\neliminate the negative effects of noise and outliers on the results, which can\nalso make the DL process efficient. To make the encoding process robust to\nnoise in data, J-RFDL clearly uses sparse L2, 1-norm that can potentially\nminimize the factorization and reconstruction errors jointly by forcing rows of\nthe reconstruction errors to be zeros. To deliver salient coefficients with\ngood structures to reconstruct given data well, J-RFDL imposes the joint\nlow-rank and sparse constraints on the embedded coefficients with a synthesis\ndictionary. Based on the hybrid salient coefficients, we also extend J-RFDL for\nthe joint classification and propose a discriminative J-RFDL model, which can\nimprove the discriminating abilities of learnt coeffi-cients by minimizing the\nclassification error jointly. Extensive experiments on public datasets\ndemonstrate that our formulations can deliver superior performance over other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 06:52:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ren", "Jiahuan", ""], ["Zhang", "Zhao", ""], ["Li", "Sheng", ""], ["Wang", "Yang", ""], ["Liu", "Guangcan", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "1912.11801", "submitter": "Georgios Papayiannis", "authors": "G. Domazakis, D. Drivaliaris, S. Koukoulas, G. Papayiannis, A.\n  Tsekrekos, A. Yannacopoulos", "title": "Clustering measure-valued data with Wasserstein barycenters", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, learning schemes for measure-valued data are proposed, i.e.\ndata that their structure can be more efficiently represented as probability\nmeasures instead of points on $\\R^d$, employing the concept of probability\nbarycenters as defined with respect to the Wasserstein metric. Such type of\nlearning approaches are highly appreciated in many fields where the\nobservational/experimental error is significant (e.g. astronomy, biology,\nremote sensing, etc.) or the data nature is more complex and the traditional\nlearning algorithms are not applicable or effective to treat them (e.g. network\ndata, interval data, high frequency records, matrix data, etc.). Under this\nperspective, each observation is identified by an appropriate probability\nmeasure and the proposed statistical learning schemes rely on discrimination\ncriteria that utilize the geometric structure of the space of probability\nmeasures through core techniques from the optimal transport theory. The\ndiscussed approaches are implemented in two real world applications: (a)\nclustering eurozone countries according to their observed government bond yield\ncurves and (b) classifying the areas of a satellite image to certain land uses\ncategories which is a standard task in remote sensing. In both case studies the\nresults are particularly interesting and meaningful while the accuracy obtained\nis high.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 08:46:00 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 10:04:04 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Domazakis", "G.", ""], ["Drivaliaris", "D.", ""], ["Koukoulas", "S.", ""], ["Papayiannis", "G.", ""], ["Tsekrekos", "A.", ""], ["Yannacopoulos", "A.", ""]]}, {"id": "1912.11809", "submitter": "Jiaxin Chen", "authors": "Jiaxin Chen, Li-Ming Zhan, Xiao-Ming Wu, Fu-lai Chung", "title": "Variational Metric Scaling for Metric-Based Meta-Learning", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric-based meta-learning has attracted a lot of attention due to its\neffectiveness and efficiency in few-shot learning. Recent studies show that\nmetric scaling plays a crucial role in the performance of metric-based\nmeta-learning algorithms. However, there still lacks a principled method for\nlearning the metric scaling parameter automatically. In this paper, we recast\nmetric-based meta-learning from a Bayesian perspective and develop a\nvariational metric scaling framework for learning a proper metric scaling\nparameter. Firstly, we propose a stochastic variational method to learn a\nsingle global scaling parameter. To better fit the embedding space to a given\ndata distribution, we extend our method to learn a dimensional scaling vector\nto transform the embedding space. Furthermore, to learn task-specific\nembeddings, we generate task-dependent dimensional scaling vectors with\namortized variational inference. Our method is end-to-end without any\npre-training and can be used as a simple plug-and-play module for existing\nmetric-based meta-algorithms. Experiments on mini-ImageNet show that our\nmethods can be used to consistently improve the performance of existing\nmetric-based meta-algorithms including prototypical networks and TADAM. The\nsource code can be downloaded from\nhttps://github.com/jiaxinchen666/variational-scaling.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 09:00:36 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 10:07:54 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Chen", "Jiaxin", ""], ["Zhan", "Li-Ming", ""], ["Wu", "Xiao-Ming", ""], ["Chung", "Fu-lai", ""]]}, {"id": "1912.11831", "submitter": "Mustafizur Rahman Shahid", "authors": "Mustafizur Rahman Shahid (SAMOVAR), Gregory Blanc (SAMOVAR), Zonghua\n  Zhang (SAMOVAR), Herv\\'e Debar (SAMOVAR)", "title": "Anomalous Communications Detection in IoT Networks Using Sparse\n  Autoencoders", "comments": null, "journal-ref": "2019 IEEE 18th International Symposium on Network Computing and\n  Applications (NCA), Sep 2019, Cambridge, United States. pp.1-5", "doi": "10.1109/NCA.2019.8935007", "report-no": null, "categories": "cs.CR cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, IoT devices have been widely deployed for enabling various smart\nservices, such as, smart home or e-healthcare. However, security remains as one\nof the paramount concern as many IoT devices are vulnerable. Moreover, IoT\nmalware are constantly evolving and getting more sophisticated. IoT devices are\nintended to perform very specific tasks, so their networking behavior is\nexpected to be reasonably stable and predictable. Any significant behavioral\ndeviation from the normal patterns would indicate anomalous events. In this\npaper, we present a method to detect anomalous network communications in IoT\nnetworks using a set of sparse autoencoders. The proposed approach allows us to\ndifferentiate malicious communications from legitimate ones. So that, if a\ndevice is compromised only malicious communications can be dropped while the\nservice provided by the device is not totally interrupted. To characterize\nnetwork behavior, bidirectional TCP flows are extracted and described using\nstatistics on the size of the first N packets sent and received, along with\nstatistics on the corresponding inter-arrival times between packets. A set of\nsparse autoencoders is then trained to learn the profile of the legitimate\ncommunications generated by an experimental smart home network. Depending on\nthe value of N, the developed model achieves attack detection rates ranging\nfrom 86.9% to 91.2%, and false positive rates ranging from 0.1% to 0.5%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 10:47:35 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Shahid", "Mustafizur Rahman", "", "SAMOVAR"], ["Blanc", "Gregory", "", "SAMOVAR"], ["Zhang", "Zonghua", "", "SAMOVAR"], ["Debar", "Herv\u00e9", "", "SAMOVAR"]]}, {"id": "1912.11852", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao,\n  Jun Zhu", "title": "Benchmarking Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, which becomes\none of the most important research problems in the development of deep\nlearning. While a lot of efforts have been made in recent years, it is of great\nsignificance to perform correct and complete evaluations of the adversarial\nattack and defense algorithms. In this paper, we establish a comprehensive,\nrigorous, and coherent benchmark to evaluate adversarial robustness on image\nclassification tasks. After briefly reviewing plenty of representative attack\nand defense methods, we perform large-scale experiments with two robustness\ncurves as the fair-minded evaluation criteria to fully understand the\nperformance of these methods. Based on the evaluation results, we draw several\nimportant findings and provide insights for future research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:37:01 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Dong", "Yinpeng", ""], ["Fu", "Qi-An", ""], ["Yang", "Xiao", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Xiao", "Zihao", ""], ["Zhu", "Jun", ""]]}, {"id": "1912.11853", "submitter": "Yosuke Shinya", "authors": "Laurent Dillard, Yosuke Shinya, Taiji Suzuki", "title": "Domain Adaptation Regularization for Spectral Pruning", "comments": "BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have recently been achieving state-of-the-art\nperformance on a variety of computer vision related tasks. However, their\ncomputational cost limits their ability to be implemented in embedded systems\nwith restricted resources or strict latency constraints. Model compression has\ntherefore been an active field of research to overcome this issue.\nAdditionally, DNNs typically require massive amounts of labeled data to be\ntrained. This represents a second limitation to their deployment. Domain\nAdaptation (DA) addresses this issue by allowing knowledge learned on one\nlabeled source distribution to be transferred to a target distribution,\npossibly unlabeled. In this paper, we investigate on possible improvements of\ncompression methods in DA setting. We focus on a compression method that was\npreviously developed in the context of a single data distribution and show\nthat, with a careful choice of data to use during compression and additional\nregularization terms directly related to DA objectives, it is possible to\nimprove compression results. We also show that our method outperforms an\nexisting compression method studied in the DA setting by a large margin for\nhigh compression rates. Although our work is based on one specific compression\nmethod, we also outline some general guidelines for improving compression in DA\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:38:13 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:27:50 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 09:08:08 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dillard", "Laurent", ""], ["Shinya", "Yosuke", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1912.11855", "submitter": "Aditi Sharma", "authors": "Aditi Sharma, Ravi Ranjan", "title": "Software Effort Estimation using Neuro Fuzzy Inference System: Past and\n  Present", "comments": null, "journal-ref": "International Journal on Recent and Innovation Trends in Computing\n  and Communication ISSN: 2321-8169 2017", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most important reason for project failure is poor effort estimation. Software\ndevelopment effort estimation is needed for assigning appropriate team members\nfor development, allocating resources for software development, binding etc.\nInaccurate software estimation may lead to delay in project, over-budget or\ncancellation of the project. But the effort estimation models are not very\nefficient. In this paper, we are analyzing the new approach for estimation i.e.\nNeuro Fuzzy Inference System (NFIS). It is a mixture model that consolidates\nthe components of artificial neural network with fuzzy logic for giving a\nbetter estimation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:55:38 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sharma", "Aditi", ""], ["Ranjan", "Ravi", ""]]}, {"id": "1912.11856", "submitter": "Issam Hammad", "authors": "Issam Hammad, Kamal El-Sankary, and Jason Gu", "title": "A Comparative Study on Machine Learning Algorithms for the Control of a\n  Wall Following Robot", "comments": "Accepted and presented at IEEE International Conference on Robotics\n  and Biomimetics (ROBIO) -2019", "journal-ref": "IEEE International Conference on Robotics and Biomimetics (ROBIO)\n  2019", "doi": "10.1109/ROBIO49542.2019.8961836", "report-no": null, "categories": "cs.LG cs.CV cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comparison of the performance of various machine learning models to predict\nthe direction of a wall following robot is presented in this paper. The models\nwere trained using an open-source dataset that contains 24 ultrasound sensors\nreadings and the corresponding direction for each sample. This dataset was\ncaptured using SCITOS G5 mobile robot by placing the sensors on the robot\nwaist. In addition to the full format with 24 sensors per record, the dataset\nhas two simplified formats with 4 and 2 input sensor readings per record.\nSeveral control models were proposed previously for this dataset using all\nthree dataset formats. In this paper, two primary research contributions are\npresented. First, presenting machine learning models with accuracies higher\nthan all previously proposed models for this dataset using all three formats. A\nperfect solution for the 4 and 2 inputs sensors formats is presented using\nDecision Tree Classifier by achieving a mean accuracy of 100%. On the other\nhand, a mean accuracy of 99.82% was achieves using the 24 sensor inputs by\nemploying the Gradient Boost Classifier. Second, presenting a comparative study\non the performance of different machine learning and deep learning algorithms\non this dataset. Therefore, providing an overall insight on the performance of\nthese algorithms for similar sensor fusion problems. All the models in this\npaper were evaluated using Monte-Carlo cross-validation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 13:05:05 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 13:27:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hammad", "Issam", ""], ["El-Sankary", "Kamal", ""], ["Gu", "Jason", ""]]}, {"id": "1912.11861", "submitter": "Filippos Gouidis Mr.", "authors": "Filippos Gouidis, Alexandros Vassiliades, Theodore Patkos, Antonis\n  Argyros, Nick Bassiliades and Dimitris Plexousakis", "title": "A Review on Intelligent Object Perception Methods Combining\n  Knowledge-based Reasoning and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object perception is a fundamental sub-field of Computer Vision, covering a\nmultitude of individual areas and having contributed high-impact results. While\nMachine Learning has been traditionally applied to address related problems,\nrecent works also seek ways to integrate knowledge engineering in order to\nexpand the level of intelligence of the visual interpretation of objects, their\nproperties and their relations with their environment. In this paper, we\nattempt a systematic investigation of how knowledge-based methods contribute to\ndiverse object perception tasks. We review the latest achievements and identify\nprominent research directions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 13:26:49 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 14:50:43 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Gouidis", "Filippos", ""], ["Vassiliades", "Alexandros", ""], ["Patkos", "Theodore", ""], ["Argyros", "Antonis", ""], ["Bassiliades", "Nick", ""], ["Plexousakis", "Dimitris", ""]]}, {"id": "1912.11896", "submitter": "Aly El Gamal", "authors": "Xingchen Wang, Shengtai Ju, Xiwen Zhang, Sharan Ramjee, Aly El Gamal", "title": "Efficient Training of Deep Classifiers for Wireless Source\n  Identification using Test SNR Estimates", "comments": "5 pages, 10 figures, 4 tables, accepted at IEEE Wireless\n  Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study efficient deep learning training algorithms that process received\nwireless signals, if a test Signal to Noise Ratio (SNR) estimate is available.\nWe focus on two tasks that facilitate source identification: 1- Identifying the\nmodulation type, 2- Identifying the wireless technology and channel in the 2.4\nGHz ISM band. For benchmarking, we rely on recent literature on testing deep\nlearning algorithms against two well-known datasets. We first demonstrate that\nusing training data corresponding only to the test SNR value leads to dramatic\nreductions in training time while incurring a small loss in average test\naccuracy, as it improves the accuracy for low SNR values. Further, we show that\nan erroneous test SNR estimate with a small positive offset is better for\ntraining than another having the same error magnitude with a negative offset.\nSecondly, we introduce a greedy training SNR Boosting algorithm that leads to\nuniform improvement in accuracy across all tested SNR values, while using a\nsmall subset of training SNR values at each test SNR. Finally, we demonstrate\nthe potential of bootstrap aggregating (Bagging) based on training SNR values\nto improve generalization at low test SNR values with scarcity of training\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 16:49:56 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 01:56:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wang", "Xingchen", ""], ["Ju", "Shengtai", ""], ["Zhang", "Xiwen", ""], ["Ramjee", "Sharan", ""], ["Gamal", "Aly El", ""]]}, {"id": "1912.11899", "submitter": "Mihailo Jovanovic", "authors": "Hesameddin Mohammadi, Armin Zare, Mahdi Soltanolkotabi, Mihailo R.\n  Jovanovi\\'c", "title": "Convergence and sample complexity of gradient methods for the model-free\n  linear quadratic regulator problem", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG cs.SY eess.SY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning attempts to find an optimal control action\nfor an unknown dynamical system by directly searching over the parameter space\nof controllers. The convergence behavior and statistical properties of these\napproaches are often poorly understood because of the nonconvex nature of the\nunderlying optimization problems and the lack of exact gradient computation. In\nthis paper, we take a step towards demystifying the performance and efficiency\nof such methods by focusing on the standard infinite-horizon linear quadratic\nregulator problem for continuous-time systems with unknown state-space\nparameters. We establish exponential stability for the ordinary differential\nequation (ODE) that governs the gradient-flow dynamics over the set of\nstabilizing feedback gains and show that a similar result holds for the\ngradient descent method that arises from the forward Euler discretization of\nthe corresponding ODE. We also provide theoretical bounds on the convergence\nrate and sample complexity of the random search method with two-point gradient\nestimates. We prove that the required simulation time for achieving\n$\\epsilon$-accuracy in the model-free setup and the total number of function\nevaluations both scale as $\\log \\, (1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 16:56:59 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:54:18 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 18:45:23 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Mohammadi", "Hesameddin", ""], ["Zare", "Armin", ""], ["Soltanolkotabi", "Mahdi", ""], ["Jovanovi\u0107", "Mihailo R.", ""]]}, {"id": "1912.11912", "submitter": "Devesh Jha", "authors": "Devesh Jha, Arvind Raghunathan, Diego Romeres", "title": "Quasi-Newton Trust Region Policy Optimization", "comments": "3rd Conference on Robot Learning (CoRL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a trust region method for policy optimization that employs\nQuasi-Newton approximation for the Hessian, called Quasi-Newton Trust Region\nPolicy Optimization QNTRPO. Gradient descent is the de facto algorithm for\nreinforcement learning tasks with continuous controls. The algorithm has\nachieved state-of-the-art performance when used in reinforcement learning\nacross a wide range of tasks. However, the algorithm suffers from a number of\ndrawbacks including: lack of stepsize selection criterion, and slow\nconvergence. We investigate the use of a trust region method using dogleg step\nand a Quasi-Newton approximation for the Hessian for policy optimization. We\ndemonstrate through numerical experiments over a wide range of challenging\ncontinuous control tasks that our particular choice is efficient in terms of\nnumber of samples and improves performance\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 18:29:38 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Jha", "Devesh", ""], ["Raghunathan", "Arvind", ""], ["Romeres", "Diego", ""]]}, {"id": "1912.11926", "submitter": "Art\\\"ur Manukyan", "authors": "Art\\\"ur Manukyan and Elvan Ceyhan", "title": "Parameter Free Clustering with Cluster Catch Digraphs (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose clustering algorithms based on a recently developed geometric\ndigraph family called cluster catch digraphs (CCDs). These digraphs are used to\ndevise clustering methods that are hybrids of density-based and graph-based\nclustering methods. CCDs are appealing digraphs for clustering, since they\nestimate the number of clusters; however, CCDs (and density-based methods in\ngeneral) require some information on a parameter representing the\n\\emph{intensity} of assumed clusters in the data set. We propose algorithms\nthat are parameter free versions of the CCD algorithm and does not require a\nspecification of the intensity parameter whose choice is often critical in\nfinding an optimal partitioning of the data set. We estimate the number of\nconvex clusters by borrowing a tool from spatial data analysis, namely Ripley's\n$K$ function. We call our new digraphs utilizing the $K$ function as RK-CCDs.\nWe show that the minimum dominating sets of RK-CCDs estimate and distinguish\nthe clusters from noise clusters in a data set, and hence allow the estimation\nof the correct number of clusters. Our robust clustering algorithms are\ncomprised of methods that estimate both the number of clusters and the\nintensity parameter, making them completely parameter free. We conduct Monte\nCarlo simulations and use real life data sets to compare RK-CCDs with some\ncommonly used density-based and prototype-based clustering methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 20:30:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Manukyan", "Art\u00fcr", ""], ["Ceyhan", "Elvan", ""]]}, {"id": "1912.11931", "submitter": "Thomas Zhang", "authors": "Thomas Zhang", "title": "Sparse Optimization on General Atomic Sets: Greedy and Forward-Backward\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sparse atomic optimization, where the notion of\n\"sparsity\" is generalized to meaning some linear combination of few atoms. The\ndefinition of atomic set is very broad; popular examples include the standard\nbasis, low-rank matrices, overcomplete dictionaries, permutation matrices,\northogonal matrices, etc. The model of sparse atomic optimization therefore\nincludes problems coming from many fields, including statistics, signal\nprocessing, machine learning, computer vision and so on. Specifically, we\nconsider the problem of maximizing a restricted strongly convex (or concave),\nsmooth function restricted to a sparse linear combination of atoms. We extend\nrecent work that establish linear convergence rates of greedy algorithms on\nrestricted strongly concave, smooth functions on sparse vectors to the realm of\ngeneral atomic sets, where the convergence rate involves a novel quantity: the\n\"sparse atomic condition number\". This leads to the strongest known\nmultiplicative approximation guarantees for various flavors of greedy\nalgorithms for sparse atomic optimization; in particular, we show that in many\nsettings of interest the greedy algorithm can attain strong approximation\nguarantees while maintaining sparsity. Furthermore, we introduce a scheme for\nforward-backward algorithms that achieves the same approximation guarantees.\nSecondly, we define an alternate notion of weak submodularity, which we show is\ntightly related to the more familiar version that has been used to prove\nearlier linear convergence rates. We prove analogous multiplicative\napproximation guarantees using this alternate weak submodularity, and establish\nits distinct identity and applications.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 20:52:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Thomas", ""]]}, {"id": "1912.11939", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Michael Field", "title": "On the Principle of Least Symmetry Breaking in Shallow ReLU Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization problem associated with fitting two-layer ReLU\nnetworks with respect to the squared loss, where labels are assumed to be\ngenerated by a target network. Focusing first on standard Gaussian inputs, we\nshow that the structure of spurious local minima detected by stochastic\ngradient descent (SGD) is, in a well-defined sense, the \\emph{least loss of\nsymmetry} with respect to the target weights. A closer look at the analysis\nindicates that this principle of least symmetry breaking may apply to a broader\nrange of settings. Motivated by this, we conduct a series of experiments which\ncorroborate this hypothesis for different classes of non-isotropic non-product\ndistributions, smooth activation functions and networks with a few layers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 22:04:41 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 16:53:26 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "1912.11940", "submitter": "Mingrui Liu", "authors": "Mingrui Liu, Youssef Mroueh, Jerret Ross, Wei Zhang, Xiaodong Cui,\n  Payel Das, Tianbao Yang", "title": "Towards Better Understanding of Adaptive Gradient Algorithms in\n  Generative Adversarial Nets", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient algorithms perform gradient-based updates using the history\nof gradients and are ubiquitous in training deep neural networks. While\nadaptive gradient methods theory is well understood for minimization problems,\nthe underlying factors driving their empirical success in min-max problems such\nas GANs remain unclear. In this paper, we aim at bridging this gap from both\ntheoretical and empirical perspectives. First, we analyze a variant of\nOptimistic Stochastic Gradient (OSG) proposed in~\\citep{daskalakis2017training}\nfor solving a class of non-convex non-concave min-max problem and establish\n$O(\\epsilon^{-4})$ complexity for finding $\\epsilon$-first-order stationary\npoint, in which the algorithm only requires invoking one stochastic first-order\noracle while enjoying state-of-the-art iteration complexity achieved by\nstochastic extragradient method by~\\citep{iusem2017extragradient}. Then we\npropose an adaptive variant of OSG named Optimistic Adagrad (OAdagrad) and\nreveal an \\emph{improved} adaptive complexity\n$O\\left(\\epsilon^{-\\frac{2}{1-\\alpha}}\\right)$, where $\\alpha$ characterizes\nthe growth rate of the cumulative stochastic gradient and $0\\leq \\alpha\\leq\n1/2$. To the best of our knowledge, this is the first work for establishing\nadaptive complexity in non-convex non-concave min-max optimization.\nEmpirically, our experiments show that indeed adaptive gradient algorithms\noutperform their non-adaptive counterparts in GAN training. Moreover, this\nobservation can be explained by the slow growth rate of the cumulative\nstochastic gradient, as observed empirically.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 22:10:10 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 02:17:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Liu", "Mingrui", ""], ["Mroueh", "Youssef", ""], ["Ross", "Jerret", ""], ["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Das", "Payel", ""], ["Yang", "Tianbao", ""]]}, {"id": "1912.11951", "submitter": "Roshan Dathathri", "authors": "Roshan Dathathri, Blagovesta Kostova, Olli Saarikivi, Wei Dai, Kim\n  Laine, Madanlal Musuvathi", "title": "EVA: An Encrypted Vector Arithmetic Language and Compiler for Efficient\n  Homomorphic Computation", "comments": null, "journal-ref": "Programming Language Design and Implementation (PLDI 2020) 546-561", "doi": "10.1145/3385412.3386023", "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-Homomorphic Encryption (FHE) offers powerful capabilities by enabling\nsecure offloading of both storage and computation, and recent innovations in\nschemes and implementations have made it all the more attractive. At the same\ntime, FHE is notoriously hard to use with a very constrained programming model,\na very unusual performance profile, and many cryptographic constraints.\nExisting compilers for FHE either target simpler but less efficient FHE schemes\nor only support specific domains where they can rely on expert-provided\nhigh-level runtimes to hide complications.\n  This paper presents a new FHE language called Encrypted Vector Arithmetic\n(EVA), which includes an optimizing compiler that generates correct and secure\nFHE programs, while hiding all the complexities of the target FHE scheme.\nBolstered by our optimizing compiler, programmers can develop efficient\ngeneral-purpose FHE applications directly in EVA. For example, we have\ndeveloped image processing applications using EVA, with a very few lines of\ncode.\n  EVA is designed to also work as an intermediate representation that can be a\ntarget for compiling higher-level domain-specific languages. To demonstrate\nthis, we have re-targeted CHET, an existing domain-specific compiler for neural\nnetwork inference, onto EVA. Due to the novel optimizations in EVA, its\nprograms are on average 5.3x faster than those generated by CHET. We believe\nthat EVA would enable a wider adoption of FHE by making it easier to develop\nFHE applications and domain-specific FHE compilers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 00:24:26 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 16:15:19 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Dathathri", "Roshan", ""], ["Kostova", "Blagovesta", ""], ["Saarikivi", "Olli", ""], ["Dai", "Wei", ""], ["Laine", "Kim", ""], ["Musuvathi", "Madanlal", ""]]}, {"id": "1912.11959", "submitter": "Thomas Dowdell BCom(Hons)", "authors": "Thomas Dowdell and Hongyu Zhang", "title": "Is Attention All What You Need? -- An Empirical Investigation on\n  Convolution-Based Active Memory and Self-Attention", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The key to a Transformer model is the self-attention mechanism, which allows\nthe model to analyze an entire sequence in a computationally efficient manner.\nRecent work has suggested the possibility that general attention mechanisms\nused by RNNs could be replaced by active-memory mechanisms. In this work, we\nevaluate whether various active-memory mechanisms could replace self-attention\nin a Transformer. Our experiments suggest that active-memory alone achieves\ncomparable results to the self-attention mechanism for language modelling, but\noptimal results are mostly achieved by using both active-memory and\nself-attention mechanisms together. We also note that, for some specific\nalgorithmic tasks, active-memory mechanisms alone outperform both\nself-attention and a combination of the two.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 02:01:13 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 09:01:18 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Dowdell", "Thomas", ""], ["Zhang", "Hongyu", ""]]}, {"id": "1912.11960", "submitter": "Sravanti Addepalli", "authors": "Sravanti Addepalli, Gaurav Kumar Nayak, Anirban Chakraborty, R.\n  Venkatesh Babu", "title": "DeGAN : Data-Enriching GAN for Retrieving Representative Samples from a\n  Trained Classifier", "comments": "Accepted at AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of digital information explosion, an abundance of data from\nnumerous modalities is being generated as well as archived everyday. However,\nmost problems associated with training Deep Neural Networks still revolve\naround lack of data that is rich enough for a given task. Data is required not\nonly for training an initial model, but also for future learning tasks such as\nModel Compression and Incremental Learning. A diverse dataset may be used for\ntraining an initial model, but it may not be feasible to store it throughout\nthe product life cycle due to data privacy issues or memory constraints. We\npropose to bridge the gap between the abundance of available data and lack of\nrelevant data, for the future learning tasks of a given trained network. We use\nthe available data, that may be an imbalanced subset of the original training\ndataset, or a related domain dataset, to retrieve representative samples from a\ntrained classifier, using a novel Data-enriching GAN (DeGAN) framework. We\ndemonstrate that data from a related domain can be leveraged to achieve\nstate-of-the-art performance for the tasks of Data-free Knowledge Distillation\nand Incremental Learning on benchmark datasets. We further demonstrate that our\nproposed framework can enrich any data, even from unrelated domains, to make it\nmore useful for the future learning tasks of a given network.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 02:05:45 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Addepalli", "Sravanti", ""], ["Nayak", "Gaurav Kumar", ""], ["Chakraborty", "Anirban", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1912.11969", "submitter": "Haizhong Zheng", "authors": "Haizhong Zheng, Ziqi Zhang, Juncheng Gu, Honglak Lee, Atul Prakash", "title": "Efficient Adversarial Training with Transferable Adversarial Examples", "comments": "Proceedings of the IEEE Conference on Computer Vision and Pattern\n  Recognition 2020 (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is an effective defense method to protect classification\nmodels against adversarial attacks. However, one limitation of this approach is\nthat it can require orders of magnitude additional training time due to high\ncost of generating strong adversarial examples during training. In this paper,\nwe first show that there is high transferability between models from\nneighboring epochs in the same training process, i.e., adversarial examples\nfrom one epoch continue to be adversarial in subsequent epochs. Leveraging this\nproperty, we propose a novel method, Adversarial Training with Transferable\nAdversarial Examples (ATTA), that can enhance the robustness of trained models\nand greatly improve the training efficiency by accumulating adversarial\nperturbations through epochs. Compared to state-of-the-art adversarial training\nmethods, ATTA enhances adversarial accuracy by up to 7.2% on CIFAR10 and\nrequires 12~14x less training time on MNIST and CIFAR10 datasets with\ncomparable model robustness.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 03:05:05 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 16:48:22 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zheng", "Haizhong", ""], ["Zhang", "Ziqi", ""], ["Gu", "Juncheng", ""], ["Lee", "Honglak", ""], ["Prakash", "Atul", ""]]}, {"id": "1912.11970", "submitter": "Natalia Arzeno", "authors": "Natalia M. Arzeno, Haris Vikalo", "title": "Evolutionary Clustering via Message Passing", "comments": "To be published in IEEE Transactions on Knowledge and Data\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are often interested in clustering objects that evolve over time and\nidentifying solutions to the clustering problem for every time step.\nEvolutionary clustering provides insight into cluster evolution and temporal\nchanges in cluster memberships while enabling performance superior to that\nachieved by independently clustering data collected at different time points.\nIn this paper we introduce evolutionary affinity propagation (EAP), an\nevolutionary clustering algorithm that groups data points by exchanging\nmessages on a factor graph. EAP promotes temporal smoothness of the solution to\nclustering time-evolving data by linking the nodes of the factor graph that are\nassociated with adjacent data snapshots, and introduces consensus nodes to\nenable cluster tracking and identification of cluster births and deaths. Unlike\nexisting evolutionary clustering methods that require additional processing to\napproximate the number of clusters or match them across time, EAP determines\nthe number of clusters and tracks them automatically. A comparison with\nexisting methods on simulated and experimental data demonstrates effectiveness\nof the proposed EAP algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 03:09:16 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Arzeno", "Natalia M.", ""], ["Vikalo", "Haris", ""]]}, {"id": "1912.11975", "submitter": "Kexin Huang", "authors": "Kexin Huang, Abhishek Singh, Sitong Chen, Edward T. Moseley, Chih-ying\n  Deng, Naomi George, Charlotta Lindvall", "title": "Clinical XLNet: Modeling Sequential Clinical Notes and Predicting\n  Prolonged Mechanical Ventilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinical notes contain rich data, which is unexploited in predictive modeling\ncompared to structured data. In this work, we developed a new text\nrepresentation Clinical XLNet for clinical notes which also leverages the\ntemporal information of the sequence of the notes. We evaluated our models on\nprolonged mechanical ventilation prediction problem and our experiments\ndemonstrated that Clinical XLNet outperforms the best baselines consistently.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 03:40:31 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Huang", "Kexin", ""], ["Singh", "Abhishek", ""], ["Chen", "Sitong", ""], ["Moseley", "Edward T.", ""], ["Deng", "Chih-ying", ""], ["George", "Naomi", ""], ["Lindvall", "Charlotta", ""]]}, {"id": "1912.11982", "submitter": "Weibo Shu", "authors": "Weibo Shu, Yaqiang Yao, Shengfei Lyu, Jinlong Li, and Huanhuan Chen", "title": "Use Short Isometric Shapelets to Accelerate Binary Time Series\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the research area of time series classification, the ensemble shapelet\ntransform algorithm is one of state-of-the-art algorithms for classification.\nHowever, its high time complexity is an issue to hinder its application since\nits base classifier shapelet transform includes a high time complexity of a\ndistance calculation and shapelet selection. Therefore, in this paper we\nintroduce a novel algorithm, i.e. short isometric shapelet transform, which\ncontains two strategies to reduce the time complexity. The first strategy of\nSIST fixes the length of shapelet based on a simplified distance calculation,\nwhich largely reduces the number of shapelet candidates as well as speeds up\nthe distance calculation in the ensemble shapelet transform algorithm. The\nsecond strategy is to train a single linear classifier in the feature space\ninstead of an ensemble classifier. The theoretical evidences of these two\nstrategies are presented to guarantee a near-lossless accuracy under some\npreconditions while reducing the time complexity. Furthermore, empirical\nexperiments demonstrate the superior performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 04:33:11 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 09:44:08 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Shu", "Weibo", ""], ["Yao", "Yaqiang", ""], ["Lyu", "Shengfei", ""], ["Li", "Jinlong", ""], ["Chen", "Huanhuan", ""]]}, {"id": "1912.12002", "submitter": "M. Sohaib Alam", "authors": "M. Sohaib Alam", "title": "Quantum Logic Gate Synthesis as a Markov Decision Process", "comments": "10 pages, 2 figures, 2 tables. Comments and feedback welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has witnessed recent applications to a variety of\ntasks in quantum programming. The underlying assumption is that those tasks\ncould be modeled as Markov Decision Processes (MDPs). Here, we investigate the\nfeasibility of this assumption by exploring its consequences for two of the\nsimplest tasks in quantum programming: state preparation and gate compilation.\nBy forming discrete MDPs, focusing exclusively on the single-qubit case, we\nsolve for the optimal policy exactly through policy iteration. We find optimal\npaths that correspond to the shortest possible sequence of gates to prepare a\nstate, or compile a gate, up to some target accuracy. As an example, we find\nsequences of H and T gates with length as small as 11 producing ~99% fidelity\nfor states of the form (HT)^{n} |0> with values as large as n=10^{10}. This\nwork provides strong evidence that reinforcement learning can be used for\noptimal state preparation and gate compilation for larger qubit spaces.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 06:36:09 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Alam", "M. Sohaib", ""]]}, {"id": "1912.12008", "submitter": "Haishan Ye", "authors": "Haishan Ye, Shusen Wang, Zhihua Zhang, Tong Zhang", "title": "Fast Generalized Matrix Regression with Applications in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fast matrix algorithms have become the fundamental tools of machine learning\nin big data era.\n  The generalized matrix regression problem is widely used in the matrix\napproximation such as CUR decomposition, kernel matrix approximation, and\nstream singular value decomposition (SVD), etc.\n  In this paper, we propose a fast generalized matrix regression algorithm\n(Fast GMR) which utilizes sketching technique to solve the GMR problem\nefficiently.\n  Given error parameter $0<\\epsilon<1$, the Fast GMR algorithm can achieve a\n$(1+\\epsilon)$ relative error with the sketching sizes being of order\n$\\cO(\\epsilon^{-1/2})$ for a large group of GMR problems.\n  We apply the Fast GMR algorithm to the symmetric positive definite matrix\napproximation and single pass singular value decomposition and they achieve a\nbetter performance than conventional algorithms.\n  Our empirical study also validates the effectiveness and efficiency of our\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 07:03:37 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ye", "Haishan", ""], ["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""], ["Zhang", "Tong", ""]]}, {"id": "1912.12011", "submitter": "Yu Tsao", "authors": "Xugang Lu, Peng Shen, Sheng Li, Yu Tsao, Hisashi Kawai", "title": "Cross-scale Attention Model for Acoustic Event Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major advantage of a deep convolutional neural network (CNN) is that the\nfocused receptive field size is increased by stacking multiple convolutional\nlayers. Accordingly, the model can explore the long-range dependency of\nfeatures from the top layers. However, a potential limitation of the network is\nthat the discriminative features from the bottom layers (which can model the\nshort-range dependency) are smoothed out in the final representation. This\nlimitation is especially evident in the acoustic event classification (AEC)\ntask, where both short- and long-duration events are involved in an audio clip\nand needed to be classified. In this paper, we propose a cross-scale attention\n(CSA) model, which explicitly integrates features from different scales to form\nthe final representation. Moreover, we propose the adoption of the attention\nmechanism to specify the weights of local and global features based on the\nspatial and temporal characteristics of acoustic events. Using mathematic\nformulations, we further reveal that the proposed CSA model can be regarded as\na weighted residual CNN (ResCNN) model when the ResCNN is used as a backbone\nmodel. We tested the proposed model on two AEC datasets: one is an urban AEC\ntask, and the other is an AEC task in smart car environments. Experimental\nresults show that the proposed CSA model can effectively improve the\nperformance of current state-of-the-art deep learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 07:28:57 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 21:10:38 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Lu", "Xugang", ""], ["Shen", "Peng", ""], ["Li", "Sheng", ""], ["Tsao", "Yu", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1912.12012", "submitter": "Teng Guo", "authors": "Teng Guo, Feng Xia, Shihao Zhen, Xiaomei Bai, Dongyu Zhang, Zitao Liu,\n  Jiliang Tang", "title": "Graduate Employment Prediction with Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The failure of landing a job for college students could cause serious social\nconsequences such as drunkenness and suicide. In addition to academic\nperformance, unconscious biases can become one key obstacle for hunting jobs\nfor graduating students. Thus, it is necessary to understand these unconscious\nbiases so that we can help these students at an early stage with more\npersonalized intervention. In this paper, we develop a framework, i.e., MAYA\n(Multi-mAjor emploYment stAtus) to predict students' employment status while\nconsidering biases. The framework consists of four major components. Firstly,\nwe solve the heterogeneity of student courses by embedding academic performance\ninto a unified space. Then, we apply a generative adversarial network (GAN) to\novercome the class imbalance problem. Thirdly, we adopt Long Short-Term Memory\n(LSTM) with a novel dropout mechanism to comprehensively capture sequential\ninformation among semesters. Finally, we design a bias-based regularization to\ncapture the job market biases. We conduct extensive experiments on a\nlarge-scale educational dataset and the results demonstrate the effectiveness\nof our prediction framework.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 07:30:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Guo", "Teng", ""], ["Xia", "Feng", ""], ["Zhen", "Shihao", ""], ["Bai", "Xiaomei", ""], ["Zhang", "Dongyu", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1912.12016", "submitter": "Jun Wang", "authors": "Jun Wang, Hefu Zhang, Qi Liu, Zhen Pan, Hanqing Tao", "title": "Crowdfunding Dynamics Tracking: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the increasing interests in research of\ncrowdfunding mechanism. In this area, dynamics tracking is a significant issue\nbut is still under exploration. Existing studies either fit the fluctuations of\ntime-series or employ regularization terms to constrain learned tendencies.\nHowever, few of them take into account the inherent decision-making process\nbetween investors and crowdfunding dynamics. To address the problem, in this\npaper, we propose a Trajectory-based Continuous Control for Crowdfunding (TC3)\nalgorithm to predict the funding progress in crowdfunding. Specifically,\nactor-critic frameworks are employed to model the relationship between\ninvestors and campaigns, where all of the investors are viewed as an agent that\ncould interact with the environment derived from the real dynamics of\ncampaigns. Then, to further explore the in-depth implications of patterns\n(i.e., typical characters) in funding series, we propose to subdivide them into\n$\\textit{fast-growing}$ and $\\textit{slow-growing}$ ones. Moreover, for the\npurpose of switching from different kinds of patterns, the actor component of\nTC3 is extended with a structure of options, which comes to the TC3-Options.\nFinally, extensive experiments on the Indiegogo dataset not only demonstrate\nthe effectiveness of our methods, but also validate our assumption that the\nentire pattern learned by TC3-Options is indeed the U-shaped one.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 08:00:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Wang", "Jun", ""], ["Zhang", "Hefu", ""], ["Liu", "Qi", ""], ["Pan", "Zhen", ""], ["Tao", "Hanqing", ""]]}, {"id": "1912.12033", "submitter": "Qingyong Hu", "authors": "Yulan Guo, Hanyun Wang, Qingyong Hu, Hao Liu, Li Liu, Mohammed\n  Bennamoun", "title": "Deep Learning for 3D Point Clouds: A Survey", "comments": "Accepted by IEEE TPAMI. Project page:\n  https://github.com/QingyongHu/SoTA-Point-Cloud", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point cloud learning has lately attracted increasing attention due to its\nwide applications in many areas, such as computer vision, autonomous driving,\nand robotics. As a dominating technique in AI, deep learning has been\nsuccessfully used to solve various 2D vision problems. However, deep learning\non point clouds is still in its infancy due to the unique challenges faced by\nthe processing of point clouds with deep neural networks. Recently, deep\nlearning on point clouds has become even thriving, with numerous methods being\nproposed to address different problems in this area. To stimulate future\nresearch, this paper presents a comprehensive review of recent progress in deep\nlearning methods for point clouds. It covers three major tasks, including 3D\nshape classification, 3D object detection and tracking, and 3D point cloud\nsegmentation. It also presents comparative results on several publicly\navailable datasets, together with insightful observations and inspiring future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 09:15:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:54:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Guo", "Yulan", ""], ["Wang", "Hanyun", ""], ["Hu", "Qingyong", ""], ["Liu", "Hao", ""], ["Liu", "Li", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "1912.12049", "submitter": "Luca Scrucca", "authors": "Luca Scrucca and Alessio Serafini", "title": "Projection pursuit based on Gaussian mixtures and evolutionary\n  algorithms", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics, 2019, 28:4,\n  847-860", "doi": "10.1080/10618600.2019.1598871", "report-no": null, "categories": "stat.ML cs.LG cs.NE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a projection pursuit (PP) algorithm based on Gaussian mixture\nmodels (GMMs). The negentropy obtained from a multivariate density estimated by\nGMMs is adopted as the PP index to be maximised. For a fixed dimension of the\nprojection subspace, the GMM-based density estimation is projected onto that\nsubspace, where an approximation of the negentropy for Gaussian mixtures is\ncomputed. Then, Genetic Algorithms (GAs) are used to find the optimal,\northogonal projection basis by maximising the former approximation. We show\nthat this semi-parametric approach to PP is flexible and allows highly\ninformative structures to be detected, by projecting multivariate datasets onto\na subspace, where the data can be feasibly visualised. The performance of the\nproposed approach is shown on both artificial and real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:25:41 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Scrucca", "Luca", ""], ["Serafini", "Alessio", ""]]}, {"id": "1912.12055", "submitter": "Kin Wai Cheuk", "authors": "Kin Wai Cheuk, Hans Anderson, Kat Agres, Dorien Herremans", "title": "nnAudio: An on-the-fly GPU Audio to Spectrogram Conversion Toolbox Using\n  1D Convolution Neural Networks", "comments": "Accepted In IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting time domain waveforms to frequency domain spectrograms is\ntypically considered to be a prepossessing step done before model training.\nThis approach, however, has several drawbacks. First, it takes a lot of hard\ndisk space to store different frequency domain representations. This is\nespecially true during the model development and tuning process, when exploring\nvarious types of spectrograms for optimal performance. Second, if another\ndataset is used, one must process all the audio clips again before the network\ncan be retrained. In this paper, we integrate the time domain to frequency\ndomain conversion as part of the model structure, and propose a neural network\nbased toolbox, nnAudio, which leverages 1D convolutional neural networks to\nperform time domain to frequency domain conversion during feed-forward. It\nallows on-the-fly spectrogram generation without the need to store any\nspectrograms on the disk. This approach also allows back-propagation on the\nwaveforms-to-spectrograms transformation layer, which implies that this\ntransformation process can be made trainable, and hence further optimized by\ngradient descent. nnAudio reduces the waveforms-to-spectrograms conversion time\nfor 1,770 waveforms (from the MAPS dataset) from $10.64$ seconds with librosa\nto only $0.001$ seconds for Short-Time Fourier Transform (STFT), $18.3$ seconds\nto $0.015$ seconds for Mel spectrogram, $103.4$ seconds to $0.258$ for\nconstant-Q transform (CQT), when using GPU on our DGX work station with CPU:\nIntel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz Tesla v100 32Gb GPUs. (Only 1 GPU is\nbeing used for all the experiments.) We also further optimize the existing CQT\nalgorithm, so that the CQT spectrogram can be obtained without aliasing in a\nmuch faster computation time (from $0.258$ seconds to only $0.001$ seconds).\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:50:31 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 05:46:20 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 03:17:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Cheuk", "Kin Wai", ""], ["Anderson", "Hans", ""], ["Agres", "Kat", ""], ["Herremans", "Dorien", ""]]}, {"id": "1912.12060", "submitter": "Yining Hu", "authors": "Yining Hu, Suranga Seneviratne, Kanchana Thilakarathna, Kensuke\n  Fukuda, Aruna Seneviratne", "title": "Characterizing and Detecting Money Laundering Activities on the Bitcoin\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin is by far the most popular crypto-currency solution enabling\npeer-to-peer payments. Despite some studies highlighting the network does not\nprovide full anonymity, it is still being heavily used for a wide variety of\ndubious financial activities such as money laundering, ponzi schemes, and\nransom-ware payments. In this paper, we explore the landscape of potential\nmoney laundering activities occurring across the Bitcoin network. Using data\ncollected over three years, we create transaction graphs and provide an\nin-depth analysis on various graph characteristics to differentiate money\nlaundering transactions from regular transactions. We found that the main\ndifference between laundering and regular transactions lies in their output\nvalues and neighbourhood information. Then, we propose and evaluate a set of\nclassifiers based on four types of graph features: immediate neighbours,\ncurated features, deepwalk embeddings, and node2vec embeddings to classify\nmoney laundering and regular transactions. Results show that the node2vec-based\nclassifier outperforms other classifiers in binary classification reaching an\naverage accuracy of 92.29% and an F1-measure of 0.93 and high robustness over a\n2.5-year time span. Finally, we demonstrate how effective our classifiers are\nin discovering unknown laundering services. The classifier performance dropped\ncompared to binary classification, however, the prediction can be improved with\nsimple ensemble techniques for some services.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 11:34:41 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Hu", "Yining", ""], ["Seneviratne", "Suranga", ""], ["Thilakarathna", "Kanchana", ""], ["Fukuda", "Kensuke", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "1912.12064", "submitter": "Muhammad Ahmad", "authors": "Muhammad Ahmad, Muhammad Haroon Shakeel, Sarwan Ali, Imdadullah Khan,\n  Arif Zaman, Asim Karim", "title": "Efficient Data Analytics on Augmented Similarity Triplets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning methods (classification, clustering, etc.) start with a\nknown kernel that provides similarity or distance measure between two objects.\nRecent work has extended this to situations where the information about objects\nis limited to comparisons of distances between three objects (triplets). Humans\nfind the comparison task much easier than the estimation of absolute\nsimilarities, so this kind of data can be easily obtained using crowd-sourcing.\nIn this work, we give an efficient method of augmenting the triplets data, by\nutilizing additional implicit information inferred from the existing data.\nTriplets augmentation improves the quality of kernel-based and kernel-free data\nanalytics tasks. Secondly, we also propose a novel set of algorithms for common\nsupervised and unsupervised machine learning tasks based on triplets. These\nmethods work directly with triplets, avoiding kernel evaluations. Experimental\nevaluation on real and synthetic datasets shows that our methods are more\naccurate than the current best-known techniques.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 11:50:43 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ahmad", "Muhammad", ""], ["Shakeel", "Muhammad Haroon", ""], ["Ali", "Sarwan", ""], ["Khan", "Imdadullah", ""], ["Zaman", "Arif", ""], ["Karim", "Asim", ""]]}, {"id": "1912.12090", "submitter": "Alexander Bauer", "authors": "Alexander Bauer, Shinichi Nakajima", "title": "Polynomial-Time Exact MAP Inference on Discrete Models with Global\n  Dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the worst-case scenario, junction tree algorithm remains the most\ngeneral solution for exact MAP inference with polynomial run-time guarantees.\nUnfortunately, its main tractability assumption requires the treewidth of a\ncorresponding MRF to be bounded strongly limiting the range of admissible\napplications. In fact, many practical problems in the area of structured\nprediction require modelling of global dependencies by either directly\nintroducing global factors or enforcing global constraints on the prediction\nvariables. That, however, always results in a fully-connected graph making\nexact inference by means of this algorithm intractable. Previous work [1]-[4]\nfocusing on the problem of loss-augmented inference has demonstrated how\nefficient inference can be performed on models with specific global factors\nrepresenting non-decomposable loss functions within the training regime of\nSSVMs. In this paper, we provide a more general framework for an efficient\nexact inference and extend the set of handleable problem instances by allowing\nmuch finer interactions between the energy of the core model and the sufficient\nstatistics of the global terms. We demonstrate the usefulness of our method in\nseveral use cases, including one that cannot be handled by any of the previous\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 13:30:29 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 07:43:58 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bauer", "Alexander", ""], ["Nakajima", "Shinichi", ""]]}, {"id": "1912.12098", "submitter": "Tolga Birdal", "authors": "Yongheng Zhao, Tolga Birdal, Jan Eric Lenssen, Emanuele Menegatti,\n  Leonidas Guibas, Federico Tombari", "title": "Quaternion Equivariant Capsule Networks for 3D Point Clouds", "comments": "Oral Presentation at ECCV 2020. Find our video under:\n  https://youtu.be/LHh56snwhTA. We release our sources at:\n  http://tolgabirdal.github.io/qecnetworks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a 3D capsule module for processing point clouds that is\nequivariant to 3D rotations and translations, as well as invariant to\npermutations of the input points. The operator receives a sparse set of local\nreference frames, computed from an input point cloud and establishes end-to-end\ntransformation equivariance through a novel dynamic routing procedure on\nquaternions. Further, we theoretically connect dynamic routing between capsules\nto the well-known Weiszfeld algorithm, a scheme for solving \\emph{iterative\nre-weighted least squares} (IRLS) problems with provable convergence\nproperties. It is shown that such group dynamic routing can be interpreted as\nrobust IRLS rotation averaging on capsule votes, where information is routed\nbased on the final inlier scores. Based on our operator, we build a capsule\nnetwork that disentangles geometry from pose, paving the way for more\ninformative descriptors and a structured latent space. Our architecture allows\njoint object classification and orientation estimation without explicit\nsupervision of rotations. We validate our algorithm empirically on common\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 13:51:17 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 19:09:44 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 13:12:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhao", "Yongheng", ""], ["Birdal", "Tolga", ""], ["Lenssen", "Jan Eric", ""], ["Menegatti", "Emanuele", ""], ["Guibas", "Leonidas", ""], ["Tombari", "Federico", ""]]}, {"id": "1912.12101", "submitter": "Linh K\\\"astner", "authors": "Linh K\\\"astner, Vlad Catalin Frasineanu, Jens Lambrecht", "title": "A 3D-Deep-Learning-based Augmented Reality Calibration Method for\n  Robotic Environments using Depth Sensor Data", "comments": "7 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmented Reality and mobile robots are gaining much attention within\nindustries due to the high potential to make processes cost and time efficient.\nTo facilitate augmented reality, a calibration between the Augmented Reality\ndevice and the environment is necessary. This is a challenge when dealing with\nmobile robots due to the mobility of all entities making the environment\ndynamic. On this account, we propose a novel approach to calibrate the\nAugmented Reality device using 3D depth sensor data. We use the depth camera of\na cutting edge Augmented Reality Device - the Microsoft Hololens for deep\nlearning based calibration. Therefore, we modified a neural network based on\nthe recently published VoteNet architecture which works directly on the point\ncloud input observed by the Hololens. We achieve satisfying results and\neliminate external tools like markers, thus enabling a more intuitive and\nflexible work flow for Augmented Reality integration. The results are adaptable\nto work with all depth cameras and are promising for further research.\nFurthermore, we introduce an open source 3D point cloud labeling tool, which is\nto our knowledge the first open source tool for labeling raw point cloud data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 13:56:13 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["K\u00e4stner", "Linh", ""], ["Frasineanu", "Vlad Catalin", ""], ["Lambrecht", "Jens", ""]]}, {"id": "1912.12115", "submitter": "Praneeth Vepakomma", "authors": "Maarten G.Poirot, Praneeth Vepakomma, Ken Chang, Jayashree\n  Kalpathy-Cramer, Rajiv Gupta, Ramesh Raskar", "title": "Split Learning for collaborative deep learning in healthcare", "comments": "Workshop paper: 8 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shortage of labeled data has been holding the surge of deep learning in\nhealthcare back, as sample sizes are often small, patient information cannot be\nshared openly, and multi-center collaborative studies are a burden to set up.\nDistributed machine learning methods promise to mitigate these problems. We\nargue for a split learning based approach and apply this distributed learning\nmethod for the first time in the medical field to compare performance against\n(1) centrally hosted and (2) non collaborative configurations for a range of\nparticipants. Two medical deep learning tasks are used to compare split\nlearning to conventional single and multi center approaches: a binary\nclassification problem of a data set of 9000 fundus photos, and multi-label\nclassification problem of a data set of 156,535 chest X-rays. The several\ndistributed learning setups are compared for a range of 1-50 distributed\nparticipants. Performance of the split learning configuration remained constant\nfor any number of clients compared to a single center study, showing a marked\ndifference compared to the non collaborative configuration after 2 clients (p <\n0.001) for both sets. Our results affirm the benefits of collaborative training\nof deep neural networks in health care. Our work proves the significant benefit\nof distributed learning in healthcare, and paves the way for future real-world\nimplementations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 14:39:58 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Poirot", "Maarten G.", ""], ["Vepakomma", "Praneeth", ""], ["Chang", "Ken", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Gupta", "Rajiv", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1912.12116", "submitter": "Xavier Rafael-Palou", "authors": "Xavier Rafael-Palou, Cecilia Turino, Alexander Steblin, Manuel\n  S\\'anchez-de-la-Torre, Ferran Barb\\'e, Eloisa Vargiu", "title": "Comparative Analysis of Predictive Methods for Early Assessment of\n  Compliance with Continuous Positive Airway Pressure Therapy", "comments": "22 pages, 11 figures", "journal-ref": "BMC Medical Informatics and Decision Making. 81 (2018)", "doi": "10.1186/s12911-018-0657-z", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients suffering from obstructive sleep apnea are mainly treated with\ncontinuous positive airway pressure (CPAP). Good compliance with this therapy\nis broadly accepted as more than 4h of CPAP average use nightly. Although it is\na highly effective treatment, compliance with this therapy is problematic to\nachieve with serious consequences for the patients' health. Previous works\nalready reported factors significantly related to compliance with the therapy.\nHowever, further research is still required to support clinicians to early\nanticipate patients' therapy compliance. This work intends to take a further\nstep in this direction by building compliance classifiers with CPAP therapy at\nthree different moments of the patient follow-up (i.e. before the therapy\nstarts and at months 1 and 3 after the baseline). Results of the clinical trial\nconfirmed that month 3 was the time-point with the most accurate classifier\nreaching an f1-score of 87% and 84% in cross-validation and test. At month 1,\nperformances were almost as high as in month 3 with 82% and 84% of f1-score. At\nbaseline, where no information about patients' CPAP use was given yet, the best\nclassifier achieved 73% and 76% of f1-score in cross-validation and test set\nrespectively. Subsequent analyses carried out with the best classifiers of each\ntime point revealed that certain baseline factors (i.e. headaches,\npsychological symptoms, arterial hypertension and EuroQol visual analogue\nscale) were closely related to the prediction of compliance independently of\nthe time-point. In addition, among the variables taken only during the\nfollow-up of the patients, Epworth and the average nighttime hours were the\nmost important to predict compliance with CPAP.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 14:44:21 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Rafael-Palou", "Xavier", ""], ["Turino", "Cecilia", ""], ["Steblin", "Alexander", ""], ["S\u00e1nchez-de-la-Torre", "Manuel", ""], ["Barb\u00e9", "Ferran", ""], ["Vargiu", "Eloisa", ""]]}, {"id": "1912.12120", "submitter": "Daniel San Martin", "authors": "Daniel San Martin, Daniel Manzano", "title": "A Deep Learning Model for Chilean Bills Classification", "comments": "3 pages, 3 figures, Posters Content EVIC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic bill classification is an attractive task with many potential\napplications such as automated detection and counting in images or videos. To\naddress this purpose we present a Deep Learning Model to classify Chilean\nBanknotes, because of its successful results in image processing applications.\nFor optimal performance of the proposed model, data augmentation techniques are\nintroduced due to the limited number of image samples. Positive results were\nachieved in this work, verifying that it could be a stating point to be\nextended to more complex applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 20:29:20 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Martin", "Daniel San", ""], ["Manzano", "Daniel", ""]]}, {"id": "1912.12121", "submitter": "Y. Alex Kolchinski", "authors": "Y. Alex Kolchinski, Sharon Zhou, Shengjia Zhao, Mitchell Gordon,\n  Stefano Ermon", "title": "Approximating Human Judgment of Generated Image Quality", "comments": "To appear in the Shared Visual Representations in Human and Machine\n  Intelligence workshop at NeurIPS 2019. The first two authors contributed\n  equally to the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have made immense progress in recent years, particularly in\ntheir ability to generate high quality images. However, that quality has been\ndifficult to evaluate rigorously, with evaluation dominated by heuristic\napproaches that do not correlate well with human judgment, such as the\nInception Score and Fr\\'echet Inception Distance. Real human labels have also\nbeen used in evaluation, but are inefficient and expensive to collect for each\nimage. Here, we present a novel method to automatically evaluate images based\non their quality as perceived by humans. By not only generating image\nembeddings from Inception network activations and comparing them to the\nactivations for real images, of which other methods perform a variant, but also\nregressing the activation statistics to match gold standard human labels, we\ndemonstrate 66% accuracy in predicting human scores of image realism, matching\nthe human inter-rater agreement rate. Our approach also generalizes across\ngenerative models, suggesting the potential for capturing a model-agnostic\nmeasure of image quality. We open source our dataset of human labels for the\nadvancement of research and techniques in this area.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 19:51:02 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Kolchinski", "Y. Alex", ""], ["Zhou", "Sharon", ""], ["Zhao", "Shengjia", ""], ["Gordon", "Mitchell", ""], ["Ermon", "Stefano", ""]]}, {"id": "1912.12127", "submitter": "Angshul Majumdar Dr.", "authors": "Anupriya Gogna, Angshul Majumdar and Rabab Ward", "title": "Semi-supervised Stacked Label Consistent Autoencoder for Reconstruction\n  and Analysis of Biomedical Signals", "comments": "Final version accepted at IEEE Transactions on Biomedical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose an autoencoder based framework for simultaneous\nreconstruction and classification of biomedical signals. Previously these two\ntasks, reconstruction and classification were treated as separate problems.\nThis is the first work to propose a combined framework to address the issue in\na holistic fashion. Reconstruction techniques for biomedical signals for\ntele-monitoring are largely based on compressed sensing (CS) based method,\nthese are designed techniques where the reconstruction formulation is based on\nsome assumption regarding the signal. In this work, we propose a new paradigm\nfor reconstruction we learn to reconstruct. An autoencoder can be trained for\nthe same. But since the final goal is to analyze classify the signal we learn a\nlinear classification map inside the autoencoder. The ensuing optimization\nproblem is solved using the Split Bregman technique. Experiments have been\ncarried out on reconstruction and classification of ECG arrhythmia\nclassification and EEG seizure classification signals. Our proposed tool is\ncapable of operating in a semi-supervised fashion. We show that our proposed\nmethod is better and more than an order magnitude faster in reconstruction than\nCS based methods; it is capable of real-time operation. Our method is also\nbetter than recently proposed classification methods. Significance: This is the\nfirst work offering an alternative to CS based reconstruction. It also shows\nthat representation learning can yield better results than hand-crafted\nfeatures for signal analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 12:22:06 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gogna", "Anupriya", ""], ["Majumdar", "Angshul", ""], ["Ward", "Rabab", ""]]}, {"id": "1912.12128", "submitter": "Angshul Majumdar Dr.", "authors": "Shikha Singh and Angshul Majumdar", "title": "Deep Sparse Coding for Non-Intrusive Load Monitoring", "comments": "Final version accepted at IEEE Transactions on Smartgrid", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy disaggregation is the task of segregating the aggregate energy of the\nentire building (as logged by the smartmeter) into the energy consumed by\nindividual appliances. This is a single channel (the only channel being the\nsmart-meter) blind source (different electrical appliances) separation problem.\nThe traditional way to address this is via stochastic finite state machines\n(e.g. Factorial Hidden Markov Model). In recent times dictionary learning based\napproaches have shown promise in addressing the disaggregation problem. The\nusual technique is to learn a dictionary for every device and use the learnt\ndictionaries as basis for blind source separation during disaggregation. Prior\nstudies in this area are shallow learning techniques, i.e. they learn a single\nlayer of dictionary for every device. In this work, we propose a deep learning\napproach, instead of learning one level of dictionary, we learn multiple layers\nof dictionaries for each device. These multi-level dictionaries are used as a\nbasis for source separation during disaggregation. Results on two benchmark\ndatasets and one actual implementation show that our method outperforms\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:18:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singh", "Shikha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.12129", "submitter": "Angshul Majumdar Dr.", "authors": "Jyoti Maggu and Angshul Majumdar", "title": "Kernel Transform Learning", "comments": null, "journal-ref": "Pattern Recognition Letters, 98, pp.117-122 (2017)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes kernel transform learning. The idea of dictionary learning\nis well known; it is a synthesis formulation where a basis is learnt along with\nthe coefficients so as to generate or synthesize the data. Transform learning\nis its analysis equivalent; the transforms operates or analyses on the data to\ngenerate the coefficients. The concept of kernel dictionary learning has been\nintroduced in the recent past, where the dictionary is represented as a linear\ncombination of non-linear version of the data. Its success has been showcased\nin feature extraction. In this work we propose to kernelize transform learning\non line similar to kernel dictionary learning. An efficient solution for kernel\ntransform learning has been proposed especially for problems where the number\nof samples is much larger than the dimensionality of the input samples making\nthe kernel matrix very high dimensional. Kernel transform learning has been\ncompared with other representation learning tools like autoencoder, restricted\nBoltzmann machine as well as with dictionary learning (and its kernelized\nversion). Our proposed kernel transform learning yields better results than all\nthe aforesaid techniques; experiments have been carried out on benchmark\ndatabases.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:55:38 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.12130", "submitter": "Angshul Majumdar Dr.", "authors": "Shikha Singh and Angshul Majumdar", "title": "Analysis Co-Sparse Coding for Energy Disaggregation", "comments": "Final version published in IEEE Transactions on Smartgrids", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy disaggregation is the task of segregating the aggregate energy of the\nentire building (as logged by the smartmeter) into the energy consumed by\nindividual appliances. This is a single channel (the only channel being the\nsmart-meter) blind source (different electrical appliances) separation problem.\nIn recent times dictionary learning based approaches have shown promise in\naddressing the disaggregation problem. The usual technique is to learn a\ndictionary for every device and use the learnt dictionaries as basis for blind\nsource separation during disaggregation. Dictionary learning is a synthesis\nformulation; in this work, we propose an analysis approach. The advantage of\nour proposed approach is that, the requirement of training volume drastically\nreduces compared to state-of-the-art techniques. This means that, we require\nfewer instrumented homes, or fewer days of instrumentation per home; in either\ncase this drastically reduces the sensing cost. Results on two benchmark\ndatasets show that our method produces the same level of disaggregation\naccuracy as state-of-the-art methods but with only a fraction of the training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:41:32 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singh", "Shikha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.12131", "submitter": "Angshul Majumdar Dr.", "authors": "Anupriya Gogna and Angshul Majumdar", "title": "Discriminative Autoencoder for Feature Extraction: Application to\n  Character Recognition", "comments": "The final version has been accepted at Neural Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, autoencoders are unsupervised representation learning tools.\nIn this work, we propose a novel discriminative autoencoder. Use of supervised\ndiscriminative learning ensures that the learned representation is robust to\nvariations commonly encountered in image datasets. Using the basic\ndiscriminating autoencoder as a unit, we build a stacked architecture aimed at\nextracting relevant representation from the training data. The efficiency of\nour feature extraction algorithm ensures a high classification accuracy with\neven simple classification schemes like KNN (K-nearest neighbor). We\ndemonstrate the superiority of our model for representation learning by\nconducting experiments on standard datasets for character/image recognition and\nsubsequent comparison with existing supervised deep architectures like class\nsparse stacked autoencoder and discriminative deep belief network.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 10:12:22 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gogna", "Anupriya", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1912.12132", "submitter": "Cenk Gazen", "authors": "Shreya Agrawal, Luke Barrington, Carla Bromberg, John Burge, Cenk\n  Gazen, Jason Hickey", "title": "Machine Learning for Precipitation Nowcasting from Radar Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution nowcasting is an essential tool needed for effective\nadaptation to climate change, particularly for extreme weather. As Deep\nLearning (DL) techniques have shown dramatic promise in many domains, including\nthe geosciences, we present an application of DL to the problem of\nprecipitation nowcasting, i.e., high-resolution (1 km x 1 km) short-term (1\nhour) predictions of precipitation. We treat forecasting as an image-to-image\ntranslation problem and leverage the power of the ubiquitous UNET convolutional\nneural network. We find this performs favorably when compared to three commonly\nused models: optical flow, persistence and NOAA's numerical one-hour HRRR\nnowcasting prediction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 22:46:54 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Agrawal", "Shreya", ""], ["Barrington", "Luke", ""], ["Bromberg", "Carla", ""], ["Burge", "John", ""], ["Gazen", "Cenk", ""], ["Hickey", "Jason", ""]]}, {"id": "1912.12138", "submitter": "Zhao Zhang", "authors": "Zhao Zhang, Yulin Sun, Yang Wang, Zhengjun Zha, Shuicheng Yan, Meng\n  Wang", "title": "Convolutional Dictionary Pair Learning Network for Image Representation\n  Learning", "comments": "Accepted by the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both the Dictionary Learning (DL) and Convolutional Neural Networks (CNN) are\npowerful image representation learning systems based on different mechanisms\nand principles, however whether we can seamlessly integrate them to improve the\nper-formance is noteworthy exploring. To address this issue, we propose a novel\ngeneralized end-to-end representation learning architecture, dubbed\nConvolutional Dictionary Pair Learning Network (CDPL-Net) in this paper, which\nintegrates the learning schemes of the CNN and dictionary pair learning into a\nunified framework. Generally, the architecture of CDPL-Net includes two\nconvolutional/pooling layers and two dictionary pair learn-ing (DPL) layers in\nthe representation learning module. Besides, it uses two fully-connected layers\nas the multi-layer perception layer in the nonlinear classification module. In\nparticular, the DPL layer can jointly formulate the discriminative synthesis\nand analysis representations driven by minimizing the batch based\nreconstruction error over the flatted feature maps from the convolution/pooling\nlayer. Moreover, DPL layer uses l1-norm on the analysis dictionary so that\nsparse representation can be delivered, and the embedding process will also be\nrobust to noise. To speed up the training process of DPL layer, the efficient\nstochastic gradient descent is used. Extensive simulations on real databases\nshow that our CDPL-Net can deliver enhanced performance over other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 01:34:28 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2019 09:49:42 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 12:12:14 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhang", "Zhao", ""], ["Sun", "Yulin", ""], ["Wang", "Yang", ""], ["Zha", "Zhengjun", ""], ["Yan", "Shuicheng", ""], ["Wang", "Meng", ""]]}, {"id": "1912.12139", "submitter": "Manh Duong Phung", "authors": "Qiuchen Zhu, Manh Duong Phung, Quang Ha", "title": "Crack Detection Using Enhanced Hierarchical Convolutional Neural\n  Networks", "comments": "In Proceedings of Australasian Conference on Robotics and Automation\n  2019 (ACRA), Adelaide, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAV) are expected to replace human in hazardous\ntasks of surface inspection due to their flexibility in operating space and\ncapability of collecting high quality visual data. In this study, we propose\nenhanced hierarchical convolutional neural networks (HCNN) to detect cracks\nfrom image data collected by UAVs. Unlike traditional HCNN, here a set of\nbranch networks is utilised to reduce the obscuration in the down-sampling\nprocess. Moreover, the feature preserving blocks combine the current and\nprevious terms from the convolutional blocks to provide input to the loss\nfunctions. As a result, the weights of resized images can be reduced to\nminimise the information loss. Experiments on images of different crack\ndatasets have been carried out to demonstrate the effectiveness of proposed\nHCNN.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 12:35:00 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhu", "Qiuchen", ""], ["Phung", "Manh Duong", ""], ["Ha", "Quang", ""]]}, {"id": "1912.12144", "submitter": "Joy Bose", "authors": "Kushal Singla, Niloy Mukherjee, Hari Manassery Koduvely, Joy Bose", "title": "Evaluating Usage of Images for App Classification", "comments": "5 pages, 3 figures, 3 tables, INDICON conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  App classification is useful in a number of applications such as adding apps\nto an app store or building a user model based on the installed apps. Presently\nthere are a number of existing methods to classify apps based on a given\ntaxonomy on the basis of their text metadata. However, text based methods for\napp classification may not work in all cases, such as when the text\ndescriptions are in a different language, or missing, or inadequate to classify\nthe app. One solution in such cases is to utilize the app images to supplement\nthe text description. In this paper, we evaluate a number of approaches in\nwhich app images can be used to classify the apps. In one approach, we use\nOptical character recognition (OCR) to extract text from images, which is then\nused to supplement the text description of the app. In another, we use pic2vec\nto convert the app images into vectors, then train an SVM to classify the\nvectors to the correct app label. In another, we use the captionbot.ai tool to\ngenerate natural language descriptions from the app images. Finally, we use a\nmethod to detect and label objects in the app images and use a voting technique\nto determine the category of the app based on all the images. We compare the\nperformance of our image-based techniques to classify a number of apps in our\ndataset. We use a text based SVM app classifier as our base and obtained an\nimproved classification accuracy of 96% for some classes when app images are\nadded.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 12:27:02 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Singla", "Kushal", ""], ["Mukherjee", "Niloy", ""], ["Koduvely", "Hari Manassery", ""], ["Bose", "Joy", ""]]}, {"id": "1912.12147", "submitter": "Eduardo Arnold", "authors": "Eduardo Arnold, Mehrdad Dianati, Robert de Temple, Saber Fallah", "title": "Cooperative Perception for 3D Object Detection in Driving Scenarios\n  using Infrastructure Sensors", "comments": "13 pages, 4 tables, 7 figures. Published in IEEE Transactions on\n  Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3028424", "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D object detection is a common function within the perception system of an\nautonomous vehicle and outputs a list of 3D bounding boxes around objects of\ninterest. Various 3D object detection methods have relied on fusion of\ndifferent sensor modalities to overcome limitations of individual sensors.\nHowever, occlusion, limited field-of-view and low-point density of the sensor\ndata cannot be reliably and cost-effectively addressed by multi-modal sensing\nfrom a single point of view. Alternatively, cooperative perception incorporates\ninformation from spatially diverse sensors distributed around the environment\nas a way to mitigate these limitations. This article proposes two schemes for\ncooperative 3D object detection using single modality sensors. The early fusion\nscheme combines point clouds from multiple spatially diverse sensing points of\nview before detection. In contrast, the late fusion scheme fuses the\nindependently detected bounding boxes from multiple spatially diverse sensors.\nWe evaluate the performance of both schemes, and their hybrid combination,\nusing a synthetic cooperative dataset created in two complex driving scenarios,\na T-junction and a roundabout. The evaluation shows that the early fusion\napproach outperforms late fusion by a significant margin at the cost of higher\ncommunication bandwidth. The results demonstrate that cooperative perception\ncan recall more than 95% of the objects as opposed to 30% for single-point\nsensing in the most challenging scenario. To provide practical insights into\nthe deployment of such system, we report how the number of sensors and their\nconfiguration impact the detection performance of the system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 12:19:27 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:59:08 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Arnold", "Eduardo", ""], ["Dianati", "Mehrdad", ""], ["de Temple", "Robert", ""], ["Fallah", "Saber", ""]]}, {"id": "1912.12150", "submitter": "Cencheng Shen", "authors": "Cencheng Shen, Sambit Panda, Joshua T. Vogelstein", "title": "The Chi-Square Test of Distance Correlation", "comments": "21 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance correlation has gained much recent attention in the data science\ncommunity: the sample statistic is straightforward to compute and\nasymptotically equals zero if and only if independence, making it an ideal\nchoice to discover any type of dependency structure given sufficient sample\nsize. One major bottleneck is the testing process: because the null\ndistribution of distance correlation depends on the underlying random variables\nand metric choice, it typically requires a permutation test to estimate the\nnull and compute the p-value, which is very costly for large amount of data. To\novercome the difficulty, in this paper we propose a chi-square test for\ndistance correlation. Method-wise, the chi-square test is non-parametric,\nextremely fast, and applicable to bias-corrected distance correlation using any\nstrong negative type metric or characteristic kernel. The test exhibits a\nsimilar testing power as the standard permutation test, and can be utilized for\nK-sample and partial testing. Theory-wise, we show that the underlying\nchi-square distribution well approximates and dominates the limiting null\ndistribution in upper tail, prove the chi-square test can be valid and\nuniversally consistent for testing independence, and establish a testing power\ninequality with respect to the permutation test.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 15:16:40 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 15:08:41 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 21:53:47 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 21:35:39 GMT"}, {"version": "v5", "created": "Fri, 14 May 2021 18:09:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Shen", "Cencheng", ""], ["Panda", "Sambit", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1912.12164", "submitter": "Arthur Pajot", "authors": "Arthur Pajot, Emmanuel de Bezenac, Patrick Gallinari", "title": "Unsupervised Adversarial Image Inpainting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inpainting in an unsupervised setting where there is neither\naccess to paired nor unpaired training data. The only available information is\nprovided by the uncomplete observations and the inpainting process statistics.\nIn this context, an observation should give rise to several plausible\nreconstructions which amounts at learning a distribution over the space of\nreconstructed images. We model the reconstruction process by using a\nconditional GAN with constraints on the stochastic component that introduce an\nexplicit dependency between this component and the generated output. This\nallows us sampling from the latent component in order to generate a\ndistribution of images associated to an observation. We demonstrate the\ncapacity of our model on several image datasets: faces (CelebA), food images\n(Recipe-1M) and bedrooms (LSUN Bedrooms) with different types of imputation\nmasks. The approach yields comparable performance to model variants trained\nwith additional supervision.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 16:06:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Pajot", "Arthur", ""], ["de Bezenac", "Emmanuel", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1912.12169", "submitter": "Haozhen Zhao", "authors": "Nathaniel Huber-Fliflet, Fusheng Wei, Haozhen Zhao, Han Qin, Shi Ye,\n  Amy Tsang", "title": "Image Analytics for Legal Document Review: A Transfer Learning Approach", "comments": "2019 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though technology assisted review in electronic discovery has been focusing\non text data, the need of advanced analytics to facilitate reviewing multimedia\ncontent is on the rise. In this paper, we present several applications of deep\nlearning in computer vision to Technology Assisted Review of image data in\nlegal industry. These applications include image classification, image\nclustering, and object detection. We use transfer learning techniques to\nleverage established pretrained models for feature extraction and fine tuning.\nThese applications are first of their kind in the legal industry for image\ndocument review. We demonstrate effectiveness of these applications with\nsolving real world business challenges.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 19:11:15 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Huber-Fliflet", "Nathaniel", ""], ["Wei", "Fusheng", ""], ["Zhao", "Haozhen", ""], ["Qin", "Han", ""], ["Ye", "Shi", ""], ["Tsang", "Amy", ""]]}, {"id": "1912.12170", "submitter": "Woohyung Chun", "authors": "Woohyung Chun, Sung-Min Hong, Junho Huh, Inyup Kang", "title": "Mitigating large adversarial perturbations on X-MAS (X minus Moving\n  Averaged Samples)", "comments": "X-MAS is the essential condition for the proposed mitigation as well\n  as human beings. The codes and data for evaluation are available in\n  https://github.com/stonylinux/mitigating_large_adversarial_perturbations_on_X-MAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the scheme that mitigates the adversarial perturbation $\\epsilon$\non the adversarial example $X_{adv}$ ($=$ $X$ $\\pm$ $\\epsilon$, $X$ is a benign\nsample) by subtracting the estimated perturbation $\\hat{\\epsilon}$ from $X$ $+$\n$\\epsilon$ and adding $\\hat{\\epsilon}$ to $X$ $-$ $\\epsilon$. The estimated\nperturbation $\\hat{\\epsilon}$ comes from the difference between $X_{adv}$ and\nits moving-averaged outcome $W_{avg}*X_{adv}$ where $W_{avg}$ is $N \\times N$\nmoving average kernel that all the coefficients are one. Usually, the adjacent\nsamples of an image are close to each other such that we can let $X$ $\\approx$\n$W_{avg}*X$ (naming this relation after X-MAS[X minus Moving Averaged\nSamples]). By doing that, we can make the estimated perturbation\n$\\hat{\\epsilon}$ falls within the range of $\\epsilon$. The scheme is also\nextended to do the multi-level mitigation by configuring the mitigated\nadversarial example $X_{adv}$ $\\pm$ $\\hat{\\epsilon}$ as a new adversarial\nexample to be mitigated. The multi-level mitigation gets $X_{adv}$ closer to\n$X$ with a smaller (i.e. mitigated) perturbation than original unmitigated\nperturbation by setting the moving averaged adversarial sample $W_{avg} *\nX_{adv}$ (which has the smaller perturbation than $X_{adv}$ if $X$ $\\approx$\n$W_{avg}*X$) as the boundary condition that the multi-level mitigation cannot\ncross over (i.e. decreasing $\\epsilon$ cannot go below and increasing\n$\\epsilon$ cannot go beyond). With the multi-level mitigation, we can get high\nprediction accuracies even in the adversarial example having a large\nperturbation (i.e. $\\epsilon$ $>$ $16$). The proposed scheme is evaluated with\nadversarial examples crafted by the FGSM (Fast Gradient Sign Method) based\nattacks on ResNet-50 trained with ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 22:37:12 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 13:52:44 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 11:23:15 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2020 14:16:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Chun", "Woohyung", ""], ["Hong", "Sung-Min", ""], ["Huh", "Junho", ""], ["Kang", "Inyup", ""]]}, {"id": "1912.12175", "submitter": "Yasemin Bozkurt Varolgunes", "authors": "Yasemin Bozkurt Varolgunes, Tristan Bereau, and Joseph F. Rudzinski", "title": "Interpretable Embeddings From Molecular Simulations Using Gaussian\n  Mixture Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting insight from the enormous quantity of data generated from\nmolecular simulations requires the identification of a small number of\ncollective variables whose corresponding low-dimensional free-energy landscape\nretains the essential features of the underlying system. Data-driven techniques\nprovide a systematic route to constructing this landscape, without the need for\nextensive a priori intuition into the relevant driving forces. In particular,\nautoencoders are powerful tools for dimensionality reduction, as they naturally\nforce an information bottleneck and, thereby, a low-dimensional embedding of\nthe essential features. While variational autoencoders ensure continuity of the\nembedding by assuming a unimodal Gaussian prior, this is at odds with the\nmulti-basin free-energy landscapes that typically arise from the identification\nof meaningful collective variables. In this work, we incorporate this physical\nintuition into the prior by employing a Gaussian mixture variational\nautoencoder (GMVAE), which encourages the separation of metastable states\nwithin the embedding. The GMVAE performs dimensionality reduction and\nclustering within a single unified framework, and is capable of identifying the\ninherent dimensionality of the input data, in terms of the number of Gaussians\nrequired to categorize the data. We illustrate our approach on two toy models,\nalanine dipeptide, and a challenging disordered peptide ensemble, demonstrating\nthe enhanced clustering effect of the GMVAE prior compared to standard VAEs.\nThe resulting embeddings appear to be promising representations for\nconstructing Markov state models, highlighting the transferability of the\ndimensionality reduction from static equilibrium properties to dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 15:30:54 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Varolgunes", "Yasemin Bozkurt", ""], ["Bereau", "Tristan", ""], ["Rudzinski", "Joseph F.", ""]]}, {"id": "1912.12178", "submitter": "Zilong Ji", "authors": "Zilong Ji, Xiaolong Zou, Tiejun Huang, Si Wu", "title": "Unsupervised Few-shot Learning via Self-supervised Training", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from limited exemplars (few-shot learning) is a fundamental,\nunsolved problem that has been laboriously explored in the machine learning\ncommunity. However, current few-shot learners are mostly supervised and rely\nheavily on a large amount of labeled examples. Unsupervised learning is a more\nnatural procedure for cognitive mammals and has produced promising results in\nmany machine learning tasks. In the current study, we develop a method to learn\nan unsupervised few-shot learner via self-supervised training (UFLST), which\ncan effectively generalize to novel but related classes. The proposed model\nconsists of two alternate processes, progressive clustering and episodic\ntraining. The former generates pseudo-labeled training examples for\nconstructing episodic tasks; and the later trains the few-shot learner using\nthe generated episodic tasks which further optimizes the feature\nrepresentations of data. The two processes facilitate with each other, and\neventually produce a high quality few-shot learner. Using the benchmark dataset\nOmniglot and Mini-ImageNet, we show that our model outperforms other\nunsupervised few-shot learning methods. Using the benchmark dataset Market1501,\nwe further demonstrate the feasibility of our model to a real-world application\non person re-identification.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 14:09:57 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ji", "Zilong", ""], ["Zou", "Xiaolong", ""], ["Huang", "Tiejun", ""], ["Wu", "Si", ""]]}, {"id": "1912.12179", "submitter": "Tristan Sylvain", "authors": "Tristan Sylvain, Linda Petrini, Devon Hjelm", "title": "Locality and compositionality in zero-shot learning", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study locality and compositionality in the context of\nlearning representations for Zero Shot Learning (ZSL). In order to well-isolate\nthe importance of these properties in learned representations, we impose the\nadditional constraint that, differently from most recent work in ZSL, no\npre-training on different datasets (e.g. ImageNet) is performed. The results of\nour experiments show how locality, in terms of small parts of the input, and\ncompositionality, i.e. how well can the learned representations be expressed as\na function of a smaller vocabulary, are both deeply related to generalization\nand motivate the focus on more local-aware models in future research directions\nfor representation learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:50:57 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sylvain", "Tristan", ""], ["Petrini", "Linda", ""], ["Hjelm", "Devon", ""]]}, {"id": "1912.12186", "submitter": "Hu Wang", "authors": "Hu Wang, Guansong Pang, Chunhua Shen, Congbo Ma", "title": "Unsupervised Representation Learning by Predicting Random Distances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have gained tremendous success in a broad range of\nmachine learning tasks due to its remarkable capability to learn semantic-rich\nfeatures from high-dimensional data. However, they often require large-scale\nlabelled data to successfully learn such features, which significantly hinders\ntheir adaption into unsupervised learning tasks, such as anomaly detection and\nclustering, and limits their applications into critical domains where obtaining\nmassive labelled data is prohibitively expensive. To enable unsupervised\nlearning on those domains, in this work we propose to learn features without\nusing any labelled data by training neural networks to predict data distances\nin a randomly projected space. Random mapping is a theoretically proven\napproach to obtain approximately preserved distances. To well predict these\nrandom distances, the representation learner is optimised to learn genuine\nclass structures that are implicitly embedded in the randomly projected space.\nEmpirical results on 19 real-world datasets show that our learned\nrepresentations substantially outperform a few state-of-the-art competing\nmethods in both anomaly detection and clustering tasks. Code is available at\nhttps://git.io/RDP\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 05:09:11 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 11:57:46 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wang", "Hu", ""], ["Pang", "Guansong", ""], ["Shen", "Chunhua", ""], ["Ma", "Congbo", ""]]}, {"id": "1912.12187", "submitter": "Amina Asif", "authors": "Fayyaz ul Amir Afsar Minhas and Amina Asif", "title": "Learning Neural Activations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An artificial neuron is modelled as a weighted summation followed by an\nactivation function which determines its output. A wide variety of activation\nfunctions such as rectified linear units (ReLU), leaky-ReLU, Swish, MISH, etc.\nhave been explored in the literature. In this short paper, we explore what\nhappens when the activation function of each neuron in an artificial neural\nnetwork is learned natively from data alone. This is achieved by modelling the\nactivation function of each neuron as a small neural network whose weights are\nshared by all neurons in the original network. We list our primary findings in\nthe conclusions section. The code for our analysis is available at:\nhttps://github.com/amina01/Learning-Neural-Activations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 15:52:07 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Minhas", "Fayyaz ul Amir Afsar", ""], ["Asif", "Amina", ""]]}, {"id": "1912.12197", "submitter": "Eric Sillekens", "authors": "Eric Sillekens, Wenting Yi, Daniel Semrau, Alessandro Ottino, Boris\n  Karanov, Sujie Zhou, Kevin Law, Jack Chen, Domanic Lavery, Lidia Galdino,\n  Polina Bayvel, Robert I. Killey", "title": "Experimental Demonstration of Learned Time-Domain Digital\n  Back-Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first experimental demonstration of learned time-domain\ndigital back-propagation (DBP), in 64-GBd dual-polarization 64-QAM signal\ntransmission over 1014 km. Performance gains were comparable to those obtained\nwith conventional, higher complexity, frequency-domain DBP.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 14:08:33 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Sillekens", "Eric", ""], ["Yi", "Wenting", ""], ["Semrau", "Daniel", ""], ["Ottino", "Alessandro", ""], ["Karanov", "Boris", ""], ["Zhou", "Sujie", ""], ["Law", "Kevin", ""], ["Chen", "Jack", ""], ["Lavery", "Domanic", ""], ["Galdino", "Lidia", ""], ["Bayvel", "Polina", ""], ["Killey", "Robert I.", ""]]}, {"id": "1912.12204", "submitter": "Boyi Liu", "authors": "Boyi Liu, Lujia Wang, Ming Liu, Cheng-Zhong Xu", "title": "Federated Imitation Learning: A Novel Framework for Cloud Robotic\n  Systems with Heterogeneous Sensor Data", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.00895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are capable of learning a new behavior by observing others to perform\nthe skill. Similarly, robots can also implement this by imitation learning.\nFurthermore, if with external guidance, humans can master the new behavior more\nefficiently. So, how can robots achieve this? To address the issue, we present\na novel framework named FIL. It provides a heterogeneous knowledge fusion\nmechanism for cloud robotic systems. Then, a knowledge fusion algorithm in FIL\nis proposed. It enables the cloud to fuse heterogeneous knowledge from local\nrobots and generate guide models for robots with service requests. After that,\nwe introduce a knowledge transfer scheme to facilitate local robots acquiring\nknowledge from the cloud. With FIL, a robot is capable of utilizing knowledge\nfrom other robots to increase its imitation learning in accuracy and\nefficiency. Compared with transfer learning and meta-learning, FIL is more\nsuitable to be deployed in cloud robotic systems. Finally, we conduct\nexperiments of a self-driving task for robots (cars). The experimental results\ndemonstrate that the shared model generated by FIL increases imitation learning\nefficiency of local robots in cloud robotic systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 11:23:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Liu", "Boyi", ""], ["Wang", "Lujia", ""], ["Liu", "Ming", ""], ["Xu", "Cheng-Zhong", ""]]}, {"id": "1912.12209", "submitter": "Wei Wang", "authors": "Wei Wang, Haojie Li, Zhihui Wang, Jing Sun, Zhengming Ding, and Fuming\n  Sun", "title": "Importance Filtered Cross-Domain Adaptation", "comments": "15 pages, 7 figures, IEEE Tansactions on Image Processing. arXiv\n  admin note: text overlap with arXiv:1906.07441 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Domain Adaptation (DA), the category-relevant losses usually occupy a\ndominant position, while they are usually built with hard or soft labels in\nexisting models. We observed that hard labels are overconfident due to hard\nsamples existed, and soft labels are ambiguous as too many small noisy\nprobabilities involved, and both of them are easily to cause negative transfer.\nBesides, the category-irrelevant losses in Closed-Set DA (CSDA) paradigm fail\nto work in Open-Set DA (OSDA), and they also have to be in a category-relevant\nform, since target data samples are split into shared and private classes. To\nthis end, we propose a newly-unified DA framework (i.e., Importance Filtered\nCross-Domain Adaptation, IFCDA). Firstly, an importance filtered mechanism is\ndevised to generate filtered soft labels to mitigate negative transfer\ndesirably. Specifically, the soft labels are divided into confident and\nambiguous ones. Then, only the maximum probability in each confident label is\nretained, and a threshold value is set to truncate each ambiguous label so that\nonly prominent probabilities are reserved. Moreover, a general graph-based\nlabel propagation is contrived to attain soft labels in both CSDA and OSDA,\nwhere an extra component is embedded into label vector, so that it could detect\ntarget novel classes. Finally, the category-relevant losses in both scenarios\nare reformulated using filtered soft labels, while the category-irrelevant MMD\nloss in CSDA is reformulated as a form like class-wise MMD using newly-designed\nimportance filtered soft labels. Notably, CSDA paradigm is a special case when\nall extra components are set to 0, thus the proposed approach is geared to both\nCSDA and OSDA. Comprehensive experiments on benchmark cross-domain object\nrecognition datasets verify that the proposed approach outperforms several\nstate-of-the-art methods in both scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 15:10:58 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 15:41:04 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 15:51:29 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wang", "Wei", ""], ["Li", "Haojie", ""], ["Wang", "Zhihui", ""], ["Sun", "Jing", ""], ["Ding", "Zhengming", ""], ["Sun", "Fuming", ""]]}, {"id": "1912.12211", "submitter": "Carlo Vittorio Cannistraci", "authors": "C. Duran, A. Acevedo, S. Ciucci, A. Muscoloni, and CV. Cannistraci", "title": "Nonlinear Markov Clustering by Minimum Curvilinear Sparse Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of algorithms for unsupervised pattern recognition by\nnonlinear clustering is a notable problem in data science. Markov clustering\n(MCL) is a renowned algorithm that simulates stochastic flows on a network of\nsample similarities to detect the structural organization of clusters in the\ndata, but it has never been generalized to deal with data nonlinearity. Minimum\nCurvilinearity (MC) is a principle that approximates nonlinear sample distances\nin the high-dimensional feature space by curvilinear distances, which are\ncomputed as transversal paths over their minimum spanning tree, and then stored\nin a kernel. Here we propose MC-MCL, which is the first nonlinear kernel\nextension of MCL and exploits Minimum Curvilinearity to enhance the performance\nof MCL in real and synthetic data with underlying nonlinear patterns. MC-MCL is\ncompared with baseline clustering methods, including DBSCAN, K-means and\naffinity propagation. We find that Minimum Curvilinearity provides a valuable\nframework to estimate nonlinear distances also when its kernel is applied in\ncombination with MCL. Indeed, MC-MCL overcomes classical MCL and even baseline\nclustering algorithms in different nonlinear datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 16:07:23 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Duran", "C.", ""], ["Acevedo", "A.", ""], ["Ciucci", "S.", ""], ["Muscoloni", "A.", ""], ["Cannistraci", "CV.", ""]]}, {"id": "1912.12215", "submitter": "Hao Tang", "authors": "Hao Tang, Dan Xu, Yan Yan, Philip H. S. Torr, Nicu Sebe", "title": "Local Class-Specific and Global Image-Level Generative Adversarial\n  Networks for Semantic-Guided Scene Generation", "comments": "Accepted to CVPR 2020, camera ready (10 pages) + supplementary (18\n  pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the task of semantic-guided scene generation. One\nopen challenge in scene generation is the difficulty of the generation of small\nobjects and detailed local texture, which has been widely observed in global\nimage-level generation methods. To tackle this issue, in this work we consider\nlearning the scene generation in a local context, and correspondingly design a\nlocal class-specific generative network with semantic maps as a guidance, which\nseparately constructs and learns sub-generators concentrating on the generation\nof different classes, and is able to provide more scene details. To learn more\ndiscriminative class-specific feature representations for the local generation,\na novel classification module is also proposed. To combine the advantage of\nboth the global image-level and the local class-specific generation, a joint\ngeneration network is designed with an attention fusion module and a\ndual-discriminator structure embedded. Extensive experiments on two scene image\ngeneration tasks show superior generation performance of the proposed model.\nThe state-of-the-art results are established by large margins on both tasks and\non challenging public benchmarks. The source code and trained models are\navailable at https://github.com/Ha0Tang/LGGAN.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 16:14:53 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 21:45:48 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 01:31:12 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Tang", "Hao", ""], ["Xu", "Dan", ""], ["Yan", "Yan", ""], ["Torr", "Philip H. S.", ""], ["Sebe", "Nicu", ""]]}, {"id": "1912.12244", "submitter": "Alberto Testolin Dr.", "authors": "Matteo Zambra, Alberto Testolin, Amos Maritan", "title": "Emergence of Network Motifs in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.3390/e22020204", "report-no": null, "categories": "nlin.AO cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network science can offer fundamental insights into the structural and\nfunctional properties of complex systems. For example, it is widely known that\nneuronal circuits tend to organize into basic functional topological modules,\ncalled \"network motifs\". In this article we show that network science tools can\nbe successfully applied also to the study of artificial neural networks\noperating according to self-organizing (learning) principles. In particular, we\nstudy the emergence of network motifs in multi-layer perceptrons, whose initial\nconnectivity is defined as a stack of fully-connected, bipartite graphs. Our\nsimulations show that the final network topology is primarily shaped by\nlearning dynamics, but can be strongly biased by choosing appropriate weight\ninitialization schemes. Overall, our results suggest that non-trivial\ninitialization strategies can make learning more effective by promoting the\ndevelopment of useful network motifs, which are often surprisingly consistent\nwith those observed in general transduction networks.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 17:05:38 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Zambra", "Matteo", ""], ["Testolin", "Alberto", ""], ["Maritan", "Amos", ""]]}, {"id": "1912.12264", "submitter": "Sarwan Ali", "authors": "Sarwan Ali, Muhammad Haroon Shakeel, Imdadullah Khan, Safiullah\n  Faizullah, Muhammad Asad Khan", "title": "Predicting Attributes of Nodes Using Network Structure", "comments": "This paper is Published at ACM Transactions on Intelligent Systems\n  and Technology (ACM TIST)", "journal-ref": "ACM Transactions on Intelligent Systems and Technology, 2021", "doi": "10.1145/3442390", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many graphs such as social networks, nodes have associated attributes\nrepresenting their behavior. Predicting node attributes in such graphs is an\nimportant problem with applications in many domains like recommendation\nsystems, privacy preservation, and targeted advertisement. Attributes values\ncan be predicted by analyzing patterns and correlations among attributes and\nemploying classification/regression algorithms. However, these approaches do\nnot utilize readily available network topology information. In this regard,\ninterconnections between different attributes of nodes can be exploited to\nimprove the prediction accuracy. In this paper, we propose an approach to\nrepresent a node by a feature map with respect to an attribute $a_i$ (which is\nused as input for machine learning algorithms) using all attributes of\nneighbors to predict attributes values for $a_i$. We perform extensive\nexperimentation on ten real-world datasets and show that the proposed feature\nmap significantly improves the prediction accuracy as compared to baseline\napproaches on these datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 17:59:33 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 19:59:59 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 12:11:15 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ali", "Sarwan", ""], ["Shakeel", "Muhammad Haroon", ""], ["Khan", "Imdadullah", ""], ["Faizullah", "Safiullah", ""], ["Khan", "Muhammad Asad", ""]]}, {"id": "1912.12265", "submitter": "Yuwen Yang", "authors": "Yuwen Yang, Feifei Gao, Zhimeng Zhong, Bo Ai and Ahmed Alkhateeb", "title": "Deep Transfer Learning Based Downlink Channel Prediction for FDD Massive\n  MIMO Systems", "comments": "Accepted by IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) based downlink channel state information (CSI)\nprediction for frequency division duplexing (FDD) massive multiple-input\nmultiple-output (MIMO) systems has attracted growing attention recently.\nHowever, existing works focus on the downlink CSI prediction for the users\nunder a given environment and is hard to adapt to users in new environment\nespecially when labeled data is limited. To address this issue, we formulate\nthe downlink channel prediction as a deep transfer learning (DTL) problem,\nwhere each learning task aims to predict the downlink CSI from the uplink CSI\nfor one single environment. Specifically, we develop the direct-transfer\nalgorithm based on the fully-connected neural network architecture, where the\nnetwork is trained on the data from all previous environments in the manner of\nclassical deep learning and is then fine-tuned for new environments. To further\nimprove the transfer efficiency, we propose the meta-learning algorithm that\ntrains the network by alternating inner-task and across-task updates and then\nadapts to a new environment with a small number of labeled data. Simulation\nresults show that the direct-transfer algorithm achieves better performance\nthan the deep learning algorithm, which implies that the transfer learning\nbenefits the downlink channel prediction in new environments. Moreover, the\nmeta-learning algorithm significantly outperforms the direct-transfer algorithm\nin terms of both prediction accuracy and stability, which validates its\neffectiveness and superiority.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 17:59:45 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:19:06 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 02:42:24 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 11:43:30 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Yang", "Yuwen", ""], ["Gao", "Feifei", ""], ["Zhong", "Zhimeng", ""], ["Ai", "Bo", ""], ["Alkhateeb", "Ahmed", ""]]}, {"id": "1912.12270", "submitter": "Siddharth Ancha", "authors": "Siddharth Ancha, Junyu Nan, David Held", "title": "Combining Deep Learning and Verification for Precise Object Instance\n  Detection", "comments": "9 pages main paper, 2 pages references, 10 pages supplementary\n  material", "journal-ref": "Conference on Robot Learning (CoRL), 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning object detectors often return false positives with very high\nconfidence. Although they optimize generic detection performance, such as mean\naverage precision (mAP), they are not designed for reliability. For a reliable\ndetection system, if a high confidence detection is made, we would want high\ncertainty that the object has indeed been detected. To achieve this, we have\ndeveloped a set of verification tests which a proposed detection must pass to\nbe accepted. We develop a theoretical framework which proves that, under\ncertain assumptions, our verification tests will not accept any false\npositives. Based on an approximation to this framework, we present a practical\ndetection system that can verify, with high precision, whether each detection\nof a machine-learning based object detector is correct. We show that these\ntests can improve the overall accuracy of a base detector and that accepted\nexamples are highly likely to be correct. This allows the detector to operate\nin a high precision regime and can thus be used for robotic perception systems\nas a reliable instance detection method. Code is available at\nhttps://github.com/siddancha/FlowVerify.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 18:11:20 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 20:51:23 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 21:40:48 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 15:18:52 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ancha", "Siddharth", ""], ["Nan", "Junyu", ""], ["Held", "David", ""]]}, {"id": "1912.12274", "submitter": "Juan Manuel Gorriz Saez Juan M", "authors": "J M Gorriz, SiPBA Group, and CAM neuroscience", "title": "Statistical Agnostic Mapping: a Framework in Neuroimaging based on\n  Concentration Inequalities", "comments": "18 pages, 10 figures, prepared to be submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the 70s a novel branch of statistics emerged focusing its effort in\nselecting a function in the pattern recognition problem, which fulfils a\ndefinite relationship between the quality of the approximation and its\ncomplexity. These data-driven approaches are mainly devoted to problems of\nestimating dependencies with limited sample sizes and comprise all the\nempirical out-of sample generalization approaches, e.g. cross validation (CV)\napproaches. Although the latter are \\emph{not designed for testing competing\nhypothesis or comparing different models} in neuroimaging, there are a number\nof theoretical developments within this theory which could be employed to\nderive a Statistical Agnostic (non-parametric) Mapping (SAM) at voxel or\nmulti-voxel level. Moreover, SAMs could relieve i) the problem of instability\nin limited sample sizes when estimating the actual risk via the CV approaches,\ne.g. large error bars, and provide ii) an alternative way of Family-wise-error\n(FWE) corrected p-value maps in inferential statistics for hypothesis testing.\nIn this sense, we propose a novel framework in neuroimaging based on\nconcentration inequalities, which results in (i) a rigorous development for\nmodel validation with a small sample/dimension ratio, and (ii) a\nless-conservative procedure than FWE p-value correction, to determine the brain\nsignificance maps from the inferences made using small upper bounds of the\nactual risk.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 18:27:50 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Gorriz", "J M", ""], ["Group", "SiPBA", ""], ["neuroscience", "CAM", ""]]}, {"id": "1912.12294", "submitter": "Dian Chen", "authors": "Dian Chen and Brady Zhou and Vladlen Koltun and Philipp Kr\\\"ahenb\\\"uhl", "title": "Learning by Cheating", "comments": "Paper published in CoRL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based urban driving is hard. The autonomous system needs to learn to\nperceive the world and act in it. We show that this challenging learning\nproblem can be simplified by decomposing it into two stages. We first train an\nagent that has access to privileged information. This privileged agent cheats\nby observing the ground-truth layout of the environment and the positions of\nall traffic participants. In the second stage, the privileged agent acts as a\nteacher that trains a purely vision-based sensorimotor agent. The resulting\nsensorimotor agent does not have access to any privileged information and does\nnot cheat. This two-stage training procedure is counter-intuitive at first, but\nhas a number of important advantages that we analyze and empirically\ndemonstrate. We use the presented approach to train a vision-based autonomous\ndriving system that substantially outperforms the state of the art on the CARLA\nbenchmark and the recent NoCrash benchmark. Our approach achieves, for the\nfirst time, 100% success rate on all tasks in the original CARLA benchmark,\nsets a new record on the NoCrash benchmark, and reduces the frequency of\ninfractions by an order of magnitude compared to the prior state of the art.\nFor the video that summarizes this work, see https://youtu.be/u9ZCxxD-UUw\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 18:59:04 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Chen", "Dian", ""], ["Zhou", "Brady", ""], ["Koltun", "Vladlen", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""]]}, {"id": "1912.12309", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis, Nikolai Matni, George J. Pappas", "title": "Sample Complexity of Kalman Filtering for Unknown Systems", "comments": "To appear in L4DC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the task of designing a Kalman Filter (KF) for an\nunknown and partially observed autonomous linear time invariant system driven\nby process and sensor noise. To do so, we propose studying the following two\nstep process: first, using system identification tools rooted in subspace\nmethods, we obtain coarse finite-data estimates of the state-space parameters\nand Kalman gain describing the autonomous system; and second, we use these\napproximate parameters to design a filter which produces estimates of the\nsystem state. We show that when the system identification step produces\nsufficiently accurate estimates, or when the underlying true KF is sufficiently\nrobust, that a Certainty Equivalent (CE) KF, i.e., one designed using the\nestimated parameters directly, enjoys provable sub-optimality guarantees. We\nfurther show that when these conditions fail, and in particular, when the CE KF\nis marginally stable (i.e., has eigenvalues very close to the unit circle),\nthat imposing additional robustness constraints on the filter leads to similar\nsub-optimality guarantees. We further show that with high probability, both the\nCE and robust filters have mean prediction error bounded by $\\tilde\nO(1/\\sqrt{N})$, where $N$ is the number of data points collected in the system\nidentification step. To the best of our knowledge, these are the first\nend-to-end sample complexity bounds for the Kalman Filtering of an unknown\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:00:42 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 22:05:03 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 06:23:16 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Matni", "Nikolai", ""], ["Pappas", "George J.", ""]]}, {"id": "1912.12318", "submitter": "Xiaofeng Yang", "authors": "Yabo Fu, Yang Lei, Tonghe Wang, Walter J. Curran, Tian Liu, Xiaofeng\n  Yang", "title": "Deep Learning in Medical Image Registration: A Review", "comments": "32 pages, 4 figures, 9 tables", "journal-ref": null, "doi": "10.1088/1361-6560/ab843e", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a review of deep learning (DL) based medical image\nregistration methods. We summarized the latest developments and applications of\nDL-based registration methods in the medical field. These methods were\nclassified into seven categories according to their methods, functions and\npopularity. A detailed review of each category was presented, highlighting\nimportant contributions and identifying specific challenges. A short assessment\nwas presented following the detailed review of each category to summarize its\nachievements and future potentials. We provided a comprehensive comparison\namong DL-based methods for lung and brain deformable registration using\nbenchmark datasets. Lastly, we analyzed the statistics of all the cited works\nfrom various aspects, revealing the popularity and future trend of development\nin medical image registration using deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:32:32 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fu", "Yabo", ""], ["Lei", "Yang", ""], ["Wang", "Tonghe", ""], ["Curran", "Walter J.", ""], ["Liu", "Tian", ""], ["Yang", "Xiaofeng", ""]]}, {"id": "1912.12322", "submitter": "Andreas Windisch", "authors": "Andreas Windisch, Thomas Gallien, Christopher Schwarzlmueller", "title": "Deep reinforcement learning for complex evaluation of one-loop diagrams\n  in quantum field theory", "comments": null, "journal-ref": "Phys. Rev. E 101, 033305 (2020)", "doi": "10.1103/PhysRevE.101.033305", "report-no": null, "categories": "hep-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel technique based on deep reinforcement\nlearning that allows for numerical analytic continuation of integrals that are\noften encountered in one-loop diagrams in quantum field theory. In order to\nextract certain quantities of two-point functions, such as spectral densities,\nmass poles or multi-particle thresholds, it is necessary to perform an analytic\ncontinuation of the correlator in question. At one-loop level in Euclidean\nspace, this results in the necessity to deform the integration contour of the\nloop integral in the complex plane of the square of the loop momentum, in order\nto avoid non-analyticities in the integration plane. Using a toy model for\nwhich an exact solution is known, we train a reinforcement learning agent to\nperform the required contour deformations. Our study shows great promise for an\nagent to be deployed in iterative numerical approaches used to compute\nnon-perturbative 2-point functions, such as the quark propagator\nDyson-Schwinger equation, or more generally, Fredholm equations of the second\nkind, in the complex domain.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:45:24 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Windisch", "Andreas", ""], ["Gallien", "Thomas", ""], ["Schwarzlmueller", "Christopher", ""]]}, {"id": "1912.12345", "submitter": "Richard Shin", "authors": "Richard Shin, Neel Kant, Kavi Gupta, Christopher Bender, Brandon\n  Trabucco, Rishabh Singh, Dawn Song", "title": "Synthetic Datasets for Neural Program Synthesis", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of program synthesis is to automatically generate programs in a\nparticular language from corresponding specifications, e.g. input-output\nbehavior. Many current approaches achieve impressive results after training on\nrandomly generated I/O examples in limited domain-specific languages (DSLs), as\nwith string transformations in RobustFill. However, we empirically discover\nthat applying test input generation techniques for languages with control flow\nand rich input space causes deep networks to generalize poorly to certain data\ndistributions; to correct this, we propose a new methodology for controlling\nand evaluating the bias of synthetic data distributions over both programs and\nspecifications. We demonstrate, using the Karel DSL and a small Calculator DSL,\nthat training deep networks on these distributions leads to improved\ncross-distribution generalization performance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 21:28:10 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Shin", "Richard", ""], ["Kant", "Neel", ""], ["Gupta", "Kavi", ""], ["Bender", "Christopher", ""], ["Trabucco", "Brandon", ""], ["Singh", "Rishabh", ""], ["Song", "Dawn", ""]]}, {"id": "1912.12355", "submitter": "A. Ali Heydari", "authors": "A. Ali Heydari, Craig A. Thompson and Asif Mehmood", "title": "SoftAdapt: Techniques for Adaptive Loss Weighting of Neural Networks\n  with Multi-Part Loss Functions", "comments": "8 pages with 2 pages of references. 6 Figures and 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive loss function formulation is an active area of research and has\ngained a great deal of popularity in recent years, following the success of\ndeep learning. However, existing frameworks of adaptive loss functions often\nsuffer from slow convergence and poor choice of weights for the loss\ncomponents. Traditionally, the elements of a multi-part loss function are\nweighted equally or their weights are determined through heuristic approaches\nthat yield near-optimal (or sub-optimal) results. To address this problem, we\npropose a family of methods, called SoftAdapt, that dynamically change function\nweights for multi-part loss functions based on live performance statistics of\nthe component losses. SoftAdapt is mathematically intuitive, computationally\nefficient and straightforward to implement. In this paper, we present the\nmathematical formulation and pseudocode for SoftAdapt, along with results from\napplying our methods to image reconstruction (Sparse Autoencoders) and\nsynthetic data generation (Introspective Variational Autoencoders).\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 22:23:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Heydari", "A. Ali", ""], ["Thompson", "Craig A.", ""], ["Mehmood", "Asif", ""]]}, {"id": "1912.12370", "submitter": "Josh Payne", "authors": "Josh Payne and Ashish Kundu", "title": "Towards Deep Federated Defenses Against Malware in Cloud Ecosystems", "comments": "IEEE International Conference on Trust, Privacy and Security in\n  Intelligent Systems, and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing environments with many virtual machines, containers, and\nother systems, an epidemic of malware can be highly threatening to business\nprocesses. In this vision paper, we introduce a hierarchical approach to\nperforming malware detection and analysis using several recent advances in\nmachine learning on graphs, hypergraphs, and natural language. We analyze\nindividual systems and their logs, inspecting and understanding their behavior\nwith attentional sequence models. Given a feature representation of each\nsystem's logs using this procedure, we construct an attributed network of the\ncloud with systems and other components as vertices and propose an analysis of\nmalware with inductive graph and hypergraph learning models. With this\nfoundation, we consider the multicloud case, in which multiple clouds with\ndiffering privacy requirements cooperate against the spread of malware,\nproposing the use of federated learning to perform inference and training while\npreserving privacy. Finally, we discuss several open problems that remain in\ndefending cloud computing environments against malware related to designing\nrobust ecosystems, identifying cloud-specific optimization problems for\nresponse strategy, action spaces for malware containment and eradication, and\ndeveloping priors and transfer learning tasks for machine learning models in\nthis area.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 23:46:06 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Payne", "Josh", ""], ["Kundu", "Ashish", ""]]}, {"id": "1912.12378", "submitter": "Chetan Srinidhi L", "authors": "Chetan L. Srinidhi, Ozan Ciga, Anne L. Martel", "title": "Deep neural network models for computational histopathology: A survey", "comments": "Published in Medical Image Analysis, Vol. 67, Jan 2021.\n  (10.1016/j.media.2020.101813)", "journal-ref": "Medical Image Analysis, Vol. 67, Jan 2021", "doi": "10.1016/j.media.2020.101813", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathological images contain rich phenotypic information that can be used\nto monitor underlying mechanisms contributing to diseases progression and\npatient survival outcomes. Recently, deep learning has become the mainstream\nmethodological choice for analyzing and interpreting cancer histology images.\nIn this paper, we present a comprehensive review of state-of-the-art deep\nlearning approaches that have been used in the context of histopathological\nimage analysis. From the survey of over 130 papers, we review the fields\nprogress based on the methodological aspect of different machine learning\nstrategies such as supervised, weakly supervised, unsupervised, transfer\nlearning and various other sub-variants of these methods. We also provide an\noverview of deep learning based survival models that are applicable for\ndisease-specific prognosis tasks. Finally, we summarize several existing open\ndatasets and highlight critical challenges and limitations with current deep\nlearning approaches, along with possible avenues for future research.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 01:04:25 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 19:49:53 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Srinidhi", "Chetan L.", ""], ["Ciga", "Ozan", ""], ["Martel", "Anne L.", ""]]}, {"id": "1912.12384", "submitter": "Abhinav Garg", "authors": "Abhinav Garg, Dhananjaya Gowda, Ankur Kumar, Kwangyoun Kim, Mehul\n  Kumar and Chanwoo Kim", "title": "Improved Multi-Stage Training of Online Attention-based Encoder-Decoder\n  Models", "comments": "Accepted and presented at the ASRU 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a refined multi-stage multi-task training strategy\nto improve the performance of online attention-based encoder-decoder (AED)\nmodels. A three-stage training based on three levels of architectural\ngranularity namely, character encoder, byte pair encoding (BPE) based encoder,\nand attention decoder, is proposed. Also, multi-task learning based on\ntwo-levels of linguistic granularity namely, character and BPE, is used. We\nexplore different pre-training strategies for the encoders including transfer\nlearning from a bidirectional encoder. Our encoder-decoder models with online\nattention show 35% and 10% relative improvement over their baselines for\nsmaller and bigger models, respectively. Our models achieve a word error rate\n(WER) of 5.04% and 4.48% on the Librispeech test-clean data for the smaller and\nbigger models respectively after fusion with long short-term memory (LSTM)\nbased external language model (LM).\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 02:29:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Garg", "Abhinav", ""], ["Gowda", "Dhananjaya", ""], ["Kumar", "Ankur", ""], ["Kim", "Kwangyoun", ""], ["Kumar", "Mehul", ""], ["Kim", "Chanwoo", ""]]}, {"id": "1912.12394", "submitter": "Da Ju", "authors": "Da Ju, Kurt Shuster, Y-Lan Boureau, Jason Weston", "title": "All-in-One Image-Grounded Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As single-task accuracy on individual language and image tasks has improved\nsubstantially in the last few years, the long-term goal of a generally skilled\nagent that can both see and talk becomes more feasible to explore. In this\nwork, we focus on leveraging individual language and image tasks, along with\nresources that incorporate both vision and language towards that objective. We\ndesign an architecture that combines state-of-the-art Transformer and ResNeXt\nmodules fed into a novel attentive multimodal module to produce a combined\nmodel trained on many tasks. We provide a thorough analysis of the components\nof the model, and transfer performance when training on one, some, or all of\nthe tasks. Our final models provide a single system that obtains good results\non all vision and language tasks considered, and improves the state-of-the-art\nin image-grounded conversational applications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 03:51:52 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 23:10:55 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ju", "Da", ""], ["Shuster", "Kurt", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""]]}, {"id": "1912.12397", "submitter": "Saptarshi Purkayastha", "authors": "Siddhartha Nuthakki, Sunil Neela, Judy W. Gichoya, Saptarshi\n  Purkayastha", "title": "Natural language processing of MIMIC-III clinical notes for identifying\n  diagnosis and procedures with neural networks", "comments": "This is a shortened version of the Capstone Project that was accepted\n  by the Faculty of Indiana University, in partial fulfillment of the\n  requirements for the degree of Master of Science in Health Informatics in Dec\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coding diagnosis and procedures in medical records is a crucial process in\nthe healthcare industry, which includes the creation of accurate billings,\nreceiving reimbursements from payers, and creating standardized patient care\nrecords. In the United States, Billing and Insurance related activities cost\naround $471 billion in 2012 which constitutes about 25% of all the U.S hospital\nspending. In this paper, we report the performance of a natural language\nprocessing model that can map clinical notes to medical codes, and predict\nfinal diagnosis from unstructured entries of history of present illness,\nsymptoms at the time of admission, etc. Previous studies have demonstrated that\ndeep learning models perform better at such mapping when compared to\nconventional machine learning models. Therefore, we employed state-of-the-art\ndeep learning method, ULMFiT on the largest emergency department clinical notes\ndataset MIMIC III which has 1.2M clinical notes to select for the top-10 and\ntop-50 diagnosis and procedure codes. Our models were able to predict the\ntop-10 diagnoses and procedures with 80.3% and 80.5% accuracy, whereas the\ntop-50 ICD-9 codes of diagnosis and procedures are predicted with 70.7% and\n63.9% accuracy. Prediction of diagnosis and procedures from unstructured\nclinical notes benefit human coders to save time, eliminate errors and minimize\ncosts. With promising scores from our present model, the next step would be to\ndeploy this on a small-scale real-world scenario and compare it with human\ncoders as the gold standard. We believe that further research of this approach\ncan create highly accurate predictions that can ease the workflow in a clinical\nsetting.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 04:05:15 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Nuthakki", "Siddhartha", ""], ["Neela", "Sunil", ""], ["Gichoya", "Judy W.", ""], ["Purkayastha", "Saptarshi", ""]]}, {"id": "1912.12398", "submitter": "Liang Yile", "authors": "Tieyun Qian, Yile Liang, Qing Li", "title": "Solving Cold Start Problem in Recommendation with Attribute Graph Neural\n  Networks", "comments": "Accepted by TKDE 2020, https://ieeexplore.ieee.org/document/9261110", "journal-ref": null, "doi": "10.1109/TKDE.2020.3038234", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a classic problem underlying recommender systems. It is\ntraditionally tackled with matrix factorization. Recently, deep learning based\nmethods, especially graph neural networks, have made impressive progress on\nthis problem. Despite their effectiveness, existing methods focus on modeling\nthe user-item interaction graph. The inherent drawback of such methods is that\ntheir performance is bound to the density of the interactions, which is however\nusually of high sparsity. More importantly, for a cold start user/item that\ndoes not have any interactions, such methods are unable to learn the preference\nembedding of the user/item since there is no link to this user/item in the\ngraph. In this work, we develop a novel framework Attribute Graph Neural\nNetworks (AGNN) by exploiting the attribute graph rather than the commonly used\ninteraction graph. This leads to the capability of learning embeddings for cold\nstart users/items. Our AGNN can produce the preference embedding for a cold\nuser/item by learning on the distribution of attributes with an extended\nvariational auto-encoder structure. Moreover, we propose a new graph neural\nnetwork variant, i.e., gated-GNN, to effectively aggregate various attributes\nof different modalities in a neighborhood. Empirical results on two real-world\ndatasets demonstrate that our model yields significant improvements for cold\nstart recommendations and outperforms or matches state-of-the-arts performance\nin the warm start scenario.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 04:07:55 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 14:01:00 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 06:36:08 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Qian", "Tieyun", ""], ["Liang", "Yile", ""], ["Li", "Qing", ""]]}, {"id": "1912.12406", "submitter": "Mohaned Chraiti", "authors": "ohaned Chraiti, Dmitry Chizhik, Jinfeng Du, Reinaldo A. Valenzuela,\n  Ali Ghrayeb and Chadi Assi", "title": "Beamforming Learning for mmWave Communication: Theory and Experimental\n  Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To establish reliable and long-range millimeter-wave (mmWave) communication,\nbeamforming is deemed to be a promising solution. Although beamforming can be\ndone in the digital and analog domains, both approaches are hindered by several\nconstraints when it comes to mmWave communications. For example, performing\nfully digital beamforming in mmWave systems involves using many radio frequency\n(RF) chains, which are expensive and consume high power. This necessitates\nfinding more efficient ways for using fewer RF chains while taking advantage of\nthe large antenna arrays. One way to overcome this challenge is to employ\n(partially or fully) analog beamforming through proper configuration of\nphase-shifters. Existing works on mmWave analog beam design either rely on the\nknowledge of the channel state information (CSI) per antenna within the array,\nrequire a large search time (e.g., exhaustive search) or do not guarantee a\nminimum beamforming gain (e.g., codebook based beamforming). In this paper, we\npropose a beam design technique that reduces the search time and does not\nrequire CSI while guaranteeing a minimum beamforming gain. The key idea derives\nfrom observations drawn from real-life measurements. It was observed that for a\ngiven propagation environment (e.g., coverage area of a mmWave BS) the\nazimuthal angles of dominant signals could be more probable from certain angles\nthan others. Thus, pre-collected measurements could used to build a beamforming\ncodebook that regroups the most probable beam designs. We invoke Bayesian\nlearning for measurements clustering. We evaluate the efficacy of the proposed\nscheme in terms of building the codebook and assessing its performance through\nreal-life measurements. We demonstrate that the training time required by the\nproposed scheme is only 5% of that of exhaustive search. This crucial gain is\nobtained while achieving a minimum targeted beamforming gain.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 05:46:39 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Chraiti", "ohaned", ""], ["Chizhik", "Dmitry", ""], ["Du", "Jinfeng", ""], ["Valenzuela", "Reinaldo A.", ""], ["Ghrayeb", "Ali", ""], ["Assi", "Chadi", ""]]}, {"id": "1912.12408", "submitter": "Songtao He", "authors": "Songtao He, Favyen Bastani, Satvat Jagwani, Edward Park, Sofiane\n  Abbar, Mohammad Alizadeh, Hari Balakrishnan, Sanjay Chawla, Samuel Madden,\n  Mohammad Amin Sadeghi", "title": "RoadTagger: Robust Road Attribute Inference with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring road attributes such as lane count and road type from satellite\nimagery is challenging. Often, due to the occlusion in satellite imagery and\nthe spatial correlation of road attributes, a road attribute at one position on\na road may only be apparent when considering far-away segments of the road.\nThus, to robustly infer road attributes, the model must integrate scattered\ninformation and capture the spatial correlation of features along roads.\nExisting solutions that rely on image classifiers fail to capture this\ncorrelation, resulting in poor accuracy. We find this failure is caused by a\nfundamental limitation -- the limited effective receptive field of image\nclassifiers. To overcome this limitation, we propose RoadTagger, an end-to-end\narchitecture which combines both Convolutional Neural Networks (CNNs) and Graph\nNeural Networks (GNNs) to infer road attributes. The usage of graph neural\nnetworks allows information propagation on the road network graph and\neliminates the receptive field limitation of image classifiers. We evaluate\nRoadTagger on both a large real-world dataset covering 688 km^2 area in 20 U.S.\ncities and a synthesized micro-dataset. In the evaluation, RoadTagger improves\ninference accuracy over the CNN image classifier based approaches. RoadTagger\nalso demonstrates strong robustness against different disruptions in the\nsatellite imagery and the ability to learn complicated inductive rules for\naggregating scattered information along the road network.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 06:09:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["He", "Songtao", ""], ["Bastani", "Favyen", ""], ["Jagwani", "Satvat", ""], ["Park", "Edward", ""], ["Abbar", "Sofiane", ""], ["Alizadeh", "Mohammad", ""], ["Balakrishnan", "Hari", ""], ["Chawla", "Sanjay", ""], ["Madden", "Samuel", ""], ["Sadeghi", "Mohammad Amin", ""]]}, {"id": "1912.12413", "submitter": "Jean Feng", "authors": "Jean Feng, Scott Emerson, Noah Simon", "title": "Approval policies for modifications to Machine Learning-Based Software\n  as a Medical Device: A study of bio-creep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful deployment of machine learning algorithms in healthcare requires\ncareful assessments of their performance and safety. To date, the FDA approves\nlocked algorithms prior to marketing and requires future updates to undergo\nseparate premarket reviews. However, this negates a key feature of machine\nlearning--the ability to learn from a growing dataset and improve over time.\nThis paper frames the design of an approval policy, which we refer to as an\nautomatic algorithmic change protocol (aACP), as an online hypothesis testing\nproblem. As this process has obvious analogy with noninferiority testing of new\ndrugs, we investigate how repeated testing and adoption of modifications might\nlead to gradual deterioration in prediction accuracy, also known as\n``biocreep'' in the drug development literature. We consider simple policies\nthat one might consider but do not necessarily offer any error-rate guarantees,\nas well as policies that do provide error-rate control. For the latter, we\ndefine two online error-rates appropriate for this context: Bad Approval Count\n(BAC) and Bad Approval and Benchmark Ratios (BABR). We control these rates in\nthe simple setting of a constant population and data source using policies\naACP-BAC and aACP-BABR, which combine alpha-investing, group-sequential, and\ngate-keeping methods. In simulation studies, bio-creep regularly occurred when\nusing policies with no error-rate guarantees, whereas aACP-BAC and -BABR\ncontrolled the rate of bio-creep without substantially impacting our ability to\napprove beneficial modifications.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 06:34:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Feng", "Jean", ""], ["Emerson", "Scott", ""], ["Simon", "Noah", ""]]}, {"id": "1912.12418", "submitter": "Carlo Vittorio Cannistraci", "authors": "A. Acevedo, S. Ciucci, MJ. Kuo, C. Duran and CV. Cannistraci", "title": "Measuring group-separability in geometrical space for evaluation of\n  pattern recognition and embedding algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating data separation in a geometrical space is fundamental for pattern\nrecognition. A plethora of dimensionality reduction (DR) algorithms have been\ndeveloped in order to reveal the emergence of geometrical patterns in a low\ndimensional visible representation space, in which high-dimensional samples\nsimilarities are approximated by geometrical distances. However, statistical\nmeasures to evaluate directly in the low dimensional geometrical space the\nsample group separability attaiend by these DR algorithms are missing.\nCertainly, these separability measures could be used both to compare algorithms\nperformance and to tune algorithms parameters. Here, we propose three\nstatistical measures (named as PSI-ROC, PSI-PR, and PSI-P) that have origin\nfrom the Projection Separability (PS) rationale introduced in this study, which\nis expressly designed to assess group separability of data samples in a\ngeometrical space. Traditional cluster validity indices (CVIs) might be applied\nin this context but they show limitations because they are not specifically\ntailored for DR. Our PS measures are compared to six baseline cluster validity\nindices, using five non-linear datasets and six different DR algorithms. The\nresults provide clear evidence that statistical-based measures based on PS\nrationale are more accurate than CVIs and can be adopted to control the tuning\nof parameter-dependent DR algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 07:34:35 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Acevedo", "A.", ""], ["Ciucci", "S.", ""], ["Kuo", "MJ.", ""], ["Duran", "C.", ""], ["Cannistraci", "CV.", ""]]}, {"id": "1912.12419", "submitter": "Yukuan Yang", "authors": "Yukuan Yang, Lei Deng, Peng Jiao, Yansong Chua, Jing Pei, Cheng Ma,\n  Guoqi Li", "title": "Transfer Learning in General Lensless Imaging through Scattering Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks (DNNs) have been successfully introduced to the\nfield of lensless imaging through scattering media. By solving an inverse\nproblem in computational imaging, DNNs can overcome several shortcomings in the\nconventional lensless imaging through scattering media methods, namely, high\ncost, poor quality, complex control, and poor anti-interference. However, for\ntraining, a large number of training samples on various datasets have to be\ncollected, with a DNN trained on one dataset generally performing poorly for\nrecovering images from another dataset. The underlying reason is that lensless\nimaging through scattering media is a high dimensional regression problem and\nit is difficult to obtain an analytical solution. In this work, transfer\nlearning is proposed to address this issue. Our main idea is to train a DNN on\na relatively complex dataset using a large number of training samples and\nfine-tune the last few layers using very few samples from other datasets.\nInstead of the thousands of samples required to train from scratch, transfer\nlearning alleviates the problem of costly data acquisition. Specifically,\nconsidering the difference in sample sizes and similarity among datasets, we\npropose two DNN architectures, namely LISMU-FCN and LISMU-OCN, and a balance\nloss function designed for balancing smoothness and sharpness. LISMU-FCN, with\nmuch fewer parameters, can achieve imaging across similar datasets while\nLISMU-OCN can achieve imaging across significantly different datasets. What's\nmore, we establish a set of simulation algorithms which are close to the real\nexperiment, and it is of great significance and practical value in the research\non lensless scattering imaging. In summary, this work provides a new solution\nfor lensless imaging through scattering media using transfer learning in DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 07:37:25 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Yang", "Yukuan", ""], ["Deng", "Lei", ""], ["Jiao", "Peng", ""], ["Chua", "Yansong", ""], ["Pei", "Jing", ""], ["Ma", "Cheng", ""], ["Li", "Guoqi", ""]]}, {"id": "1912.12422", "submitter": "Zhaoyi Wan", "authors": "Zhaoyi Wan, Minghang He, Haoran Chen, Xiang Bai and Cong Yao", "title": "TextScanner: Reading Characters in Order for Robust Scene Text\n  Recognition", "comments": "Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by deep learning and the large volume of data, scene text recognition\nhas evolved rapidly in recent years. Formerly, RNN-attention based methods have\ndominated this field, but suffer from the problem of \\textit{attention drift}\nin certain situations. Lately, semantic segmentation based algorithms have\nproven effective at recognizing text of different forms (horizontal, oriented\nand curved). However, these methods may produce spurious characters or miss\ngenuine characters, as they rely heavily on a thresholding procedure operated\non segmentation maps. To tackle these challenges, we propose in this paper an\nalternative approach, called TextScanner, for scene text recognition.\nTextScanner bears three characteristics: (1) Basically, it belongs to the\nsemantic segmentation family, as it generates pixel-wise, multi-channel\nsegmentation maps for character class, position and order; (2) Meanwhile, akin\nto RNN-attention based methods, it also adopts RNN for context modeling; (3)\nMoreover, it performs paralleled prediction for character position and class,\nand ensures that characters are transcripted in correct order. The experiments\non standard benchmark datasets demonstrate that TextScanner outperforms the\nstate-of-the-art methods. Moreover, TextScanner shows its superiority in\nrecognizing more difficult text such Chinese transcripts and aligning with\ntarget characters.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 07:52:00 GMT"}, {"version": "v2", "created": "Wed, 1 Jan 2020 10:18:26 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Wan", "Zhaoyi", ""], ["He", "Minghang", ""], ["Chen", "Haoran", ""], ["Bai", "Xiang", ""], ["Yao", "Cong", ""]]}, {"id": "1912.12463", "submitter": "Shin Yoo Dr", "authors": "Jeongju Sohn, Sungmin Kang, Shin Yoo", "title": "Search Based Repair of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are being adopted in various domains, including\nsafety critical ones. The wide-spread adoption also calls for ways to guide the\ntesting of their accuracy and robustness, for which various test adequacy\ncriteria and input generation methods have been recently introduced. In this\npaper, we explore the natural subsequent step: given an input that reveals\nunexpected behaviour in a trained DNN, we propose to repair the DNN using\ninput-output pairs as a specification. This paper introduces Arachne, a novel\nprogram repair technique for DNNs. Arachne first performs sensitivity based\nfault localisation to limit the number of neural weights it has to modify.\nSubsequently, Arachne uses Particle Swarm Optimisation (PSO) to directly\noptimise the localised neural weights until the behaviour is corrected. An\nempirical study using three different benchmark datasets shows that Arachne can\nreduce the instances of the most frequent misclassification type committed by a\npre-trained CIFAR-10 classifier by 27.5%, without any need for additional\ntraining data. Patches generated by Arachne tend to be more focused on the\ntargeted misbehaviour than DNN retraining, which is more disruptive to\nnon-targeted behaviour. The overall results suggest the feasibility of patching\nDNNs using Arachne until they can be retrained properly.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 14:36:43 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sohn", "Jeongju", ""], ["Kang", "Sungmin", ""], ["Yoo", "Shin", ""]]}, {"id": "1912.12476", "submitter": "Yang Shen", "authors": "Yue Cao and Yang Shen", "title": "Energy-based Graph Convolutional Networks for Scoring Protein Docking\n  Models", "comments": null, "journal-ref": "Proteins: Structure, Function, and Bioinformatics 88, no. 8\n  (2020): 1091-1099", "doi": "10.1002/prot.25888", "report-no": null, "categories": "q-bio.BM cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Structural information about protein-protein interactions, often missing at\nthe interactome scale, is important for mechanistic understanding of cells and\nrational discovery of therapeutics. Protein docking provides a computational\nalternative to predict such information. However, ranking near-native docked\nmodels high among a large number of candidates, often known as the scoring\nproblem, remains a critical challenge. Moreover, estimating model quality, also\nknown as the quality assessment problem, is rarely addressed in protein\ndocking.\n  In this study the two challenging problems in protein docking are regarded as\nrelative and absolute scoring, respectively, and addressed in one\nphysics-inspired deep learning framework. We represent proteins' and encounter\ncomplexes' 3D structures as intra- and inter-molecular residue contact graphs\nwith atom-resolution node and edge features. And we propose a novel graph\nconvolutional kernel that pool interacting nodes' features through edge\nfeatures so that generalized interaction energies can be learned directly from\ngraph data. The resulting energy-based graph convolutional networks (EGCN) with\nmulti-head attention are trained to predict intra- and inter-molecular\nenergies, binding affinities, and quality measures (interface RMSD) for\nencounter complexes. Compared to a state-of-the-art scoring function for model\nranking, EGCN has significantly improved ranking for a CAPRI test set involving\nhomology docking; and is comparable for Score_set, a CAPRI benchmark set\ngenerated by diverse community-wide docking protocols not known to training\ndata. For Score_set quality assessment, EGCN shows about 27% improvement to our\nprevious efforts. Directly learning from 3D structure data in graph\nrepresentation, EGCN represents the first successful development of graph\nconvolutional networks for protein docking.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 15:57:17 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Cao", "Yue", ""], ["Shen", "Yang", ""]]}, {"id": "1912.12479", "submitter": "Sarwan Ali", "authors": "Sarwan Ali, Haris Mansoor, Imdadullah Khan, Naveed Arshad, Muhammad\n  Asad Khan, Safiullah Faizullah", "title": "Short-Term Load Forecasting Using AMI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate short-term load forecasting is essential for efficient operation of\nthe power sector. Predicting load at a fine granularity such as individual\nhouseholds or buildings is challenging due to higher volatility and uncertainty\nin the load. In aggregate loads such as at grids level, the inherent\nstochasticity and fluctuations are averaged-out, the problem becomes\nsubstantially easier. We propose an approach for short-term load forecasting at\nindividual consumers (households) level, called Forecasting using Matrix\nFactorization (FMF). FMF does not use any consumers' demographic or activity\npatterns information. Therefore, it can be applied to any locality with the\nreadily available smart meters and weather data. We perform extensive\nexperiments on three benchmark datasets and demonstrate that FMF significantly\noutperforms the computationally expensive state-of-the-art methods for this\nproblem. We achieve up to 26.5% and 24.4 % improvement in RMSE over Regression\nTree and Support Vector Machine, respectively and up to 36% and 73.2%\nimprovement in MAPE over Random Forest and Long Short-Term Memory neural\nnetwork, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 16:07:52 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 20:50:28 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 04:35:34 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 20:40:02 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ali", "Sarwan", ""], ["Mansoor", "Haris", ""], ["Khan", "Imdadullah", ""], ["Arshad", "Naveed", ""], ["Khan", "Muhammad Asad", ""], ["Faizullah", "Safiullah", ""]]}, {"id": "1912.12481", "submitter": "Prakhar Gupta", "authors": "Ali Sabet, Prakhar Gupta, Jean-Baptiste Cordonnier, Robert West,\n  Martin Jaggi", "title": "Robust Cross-lingual Embeddings from Parallel Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in cross-lingual word embeddings have primarily relied on\nmapping-based methods, which project pretrained word embeddings from different\nlanguages into a shared space through a linear transformation. However, these\napproaches assume word embedding spaces are isomorphic between different\nlanguages, which has been shown not to hold in practice (S{\\o}gaard et al.,\n2018), and fundamentally limits their performance. This motivates investigating\njoint learning methods which can overcome this impediment, by simultaneously\nlearning embeddings across languages via a cross-lingual term in the training\nobjective. We propose a bilingual extension of the CBOW method which leverages\nsentence-aligned corpora to obtain robust cross-lingual word and sentence\nrepresentations. Our approach significantly improves cross-lingual sentence\nretrieval performance over all other approaches while maintaining parity with\nthe current state-of-the-art methods on word-translation. It also achieves\nparity with a deep RNN method on a zero-shot cross-lingual document\nclassification task, requiring far fewer computational resources for training\nand inference. As an additional advantage, our bilingual method leads to a much\nmore pronounced improvement in the the quality of monolingual word vectors\ncompared to other competing methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 16:18:33 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 17:02:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Sabet", "Ali", ""], ["Gupta", "Prakhar", ""], ["Cordonnier", "Jean-Baptiste", ""], ["West", "Robert", ""], ["Jaggi", "Martin", ""]]}, {"id": "1912.12482", "submitter": "Milan Cvitkovic", "authors": "Keng Wah Loon, Laura Graesser, Milan Cvitkovic", "title": "SLM Lab: A Comprehensive Benchmark and Modular Software Framework for\n  Reproducible Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SLM Lab, a software framework for reproducible reinforcement\nlearning (RL) research. SLM Lab implements a number of popular RL algorithms,\nprovides synchronous and asynchronous parallel experiment execution,\nhyperparameter search, and result analysis. RL algorithms in SLM Lab are\nimplemented in a modular way such that differences in algorithm performance can\nbe confidently ascribed to differences between algorithms, not between\nimplementations. In this work we present the design choices behind SLM Lab and\nuse it to produce a comprehensive single-codebase RL algorithm benchmark. In\naddition, as a consequence of SLM Lab's modular design, we introduce and\nevaluate a discrete-action variant of the Soft Actor-Critic algorithm (Haarnoja\net al., 2018) and a hybrid synchronous/asynchronous training method for RL\nagents.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 16:29:58 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loon", "Keng Wah", ""], ["Graesser", "Laura", ""], ["Cvitkovic", "Milan", ""]]}, {"id": "1912.12485", "submitter": "Song Tao", "authors": "Song Tao, Jia Wang", "title": "Alleviation of Gradient Exploding in GANs: Fake Can Be Real", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to alleviate the notorious mode collapse phenomenon in generative\nadversarial networks (GANs), we propose a novel training method of GANs in\nwhich certain fake samples are considered as real ones during the training\nprocess. This strategy can reduce the gradient value that generator receives in\nthe region where gradient exploding happens. We show the process of an\nunbalanced generation and a vicious circle issue resulted from gradient\nexploding in practical training, which explains the instability of GANs. We\nalso theoretically prove that gradient exploding can be alleviated by\npenalizing the difference between discriminator outputs and fake-as-real\nconsideration for very close real and fake samples. Accordingly, Fake-As-Real\nGAN (FARGAN) is proposed with a more stable training process and a more\nfaithful generated distribution. Experiments on different datasets verify our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 16:49:13 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 10:34:08 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Tao", "Song", ""], ["Wang", "Jia", ""]]}, {"id": "1912.12502", "submitter": "Manuel Arias Chao", "authors": "Manuel Arias Chao, Bryan T. Adey, Olga Fink", "title": "Implicit supervision for fault detection and segmentation of emerging\n  fault types with Deep Variational Autoencoders", "comments": "22 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data-driven fault diagnostics of safety-critical systems often faces the\nchallenge of a complete lack of labeled data associated with faulty system\nconditions (i.e., fault types) at training time. Since an unknown number and\nnature of fault types can arise during deployment, data-driven fault\ndiagnostics in this scenario is an open-set learning problem. Most of the\nalgorithms for open-set diagnostics are one-class classification and\nunsupervised algorithms that do not leverage all the available labeled and\nunlabeled data in the learning algorithm. As a result, their fault detection\nand segmentation performance (i.e., identifying and separating faults of\ndifferent types) are sub-optimal. With this work, we propose training a\nvariational autoencoder (VAE) with labeled and unlabeled samples while inducing\nimplicit supervision on the latent representation of the healthy conditions.\nThis, together with a modified sampling process of VAE, creates a compact and\ninformative latent representation that allows good detection and segmentation\nof unseen fault types using existing one-class and clustering algorithms. We\nrefer to the proposed methodology as \"knowledge induced variational autoencoder\nwith adaptive sampling\" (KIL-AdaVAE). The fault detection and segmentation\ncapabilities of the proposed methodology are demonstrated in a new simulated\ncase study using the Advanced Geared Turbofan 30000 (AGTF30) dynamical model\nunder real flight conditions. In an extensive comparison, we demonstrate that\nthe proposed method outperforms other learning strategies (supervised learning,\nsupervised learning with embedding and semi-supervised learning) and deep\nlearning algorithms, yielding significant performance improvements on fault\ndetection and fault segmentation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 18:40:33 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:23:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chao", "Manuel Arias", ""], ["Adey", "Bryan T.", ""], ["Fink", "Olga", ""]]}, {"id": "1912.12510", "submitter": "Chandramouli Shama Sastry", "authors": "Chandramouli Shama Sastry, Sageev Oore", "title": "Detecting Out-of-Distribution Examples with In-distribution Examples and\n  Gram Matrices", "comments": "NeurIPS 2019 Workshop on Safety and Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When presented with Out-of-Distribution (OOD) examples, deep neural networks\nyield confident, incorrect predictions. Detecting OOD examples is challenging,\nand the potential risks are high. In this paper, we propose to detect OOD\nexamples by identifying inconsistencies between activity patterns and class\npredicted. We find that characterizing activity patterns by Gram matrices and\nidentifying anomalies in gram matrix values can yield high OOD detection rates.\nWe identify anomalies in the gram matrices by simply comparing each value with\nits respective range observed over the training data. Unlike many approaches,\nthis can be used with any pre-trained softmax classifier and does not require\naccess to OOD data for fine-tuning hyperparameters, nor does it require OOD\naccess for inferring parameters. The method is applicable across a variety of\narchitectures and vision datasets and, for the important and surprisingly hard\ntask of detecting far-from-distribution out-of-distribution examples, it\ngenerally performs better than or equal to state-of-the-art OOD detection\nmethods (including those that do assume access to OOD examples).\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 19:44:03 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:17:55 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sastry", "Chandramouli Shama", ""], ["Oore", "Sageev", ""]]}, {"id": "1912.12514", "submitter": "Ali Fadel", "authors": "Ali Fadel, Ibraheem Tuffaha, Mahmoud Al-Ayyoub", "title": "Tha3aroon at NSURL-2019 Task 8: Semantic Question Similarity in Arabic", "comments": "8 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our team's effort on the semantic text question\nsimilarity task of NSURL 2019. Our top performing system utilizes several\ninnovative data augmentation techniques to enlarge the training data. Then, it\ntakes ELMo pre-trained contextual embeddings of the data and feeds them into an\nON-LSTM network with self-attention. This results in sequence representation\nvectors that are used to predict the relation between the question pairs. The\nmodel is ranked in the 1st place with 96.499 F1-score (same as the second place\nF1-score) and the 2nd place with 94.848 F1-score (differs by 1.076 F1-score\nfrom the first place) on the public and private leaderboards, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 20:11:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Fadel", "Ali", ""], ["Tuffaha", "Ibraheem", ""], ["Al-Ayyoub", "Mahmoud", ""]]}, {"id": "1912.12520", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Weifeng Yang, Fenglong Ma, Jin Xu, Bin Zhong, Qiang Deng,\n  Jing Gao", "title": "Weak Supervision for Fake News Detection via Reinforcement Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 21:20:25 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 03:03:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Yaqing", ""], ["Yang", "Weifeng", ""], ["Ma", "Fenglong", ""], ["Xu", "Jin", ""], ["Zhong", "Bin", ""], ["Deng", "Qiang", ""], ["Gao", "Jing", ""]]}, {"id": "1912.12522", "submitter": "Antoine Yang", "authors": "Antoine Yang, Pedro M. Esperan\\c{c}a, Fabio M. Carlucci", "title": "NAS evaluation is frustratingly hard", "comments": "Published as a conference paper at ICLR2020; 13 pages; 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is an exciting new field which promises to\nbe as much as a game-changer as Convolutional Neural Networks were in 2012.\nDespite many great works leading to substantial improvements on a variety of\ntasks, comparison between different methods is still very much an open issue.\nWhile most algorithms are tested on the same datasets, there is no shared\nexperimental protocol followed by all. As such, and due to the under-use of\nablation studies, there is a lack of clarity regarding why certain methods are\nmore effective than others. Our first contribution is a benchmark of $8$ NAS\nmethods on $5$ datasets. To overcome the hurdle of comparing methods with\ndifferent search spaces, we propose using a method's relative improvement over\nthe randomly sampled average architecture, which effectively removes advantages\narising from expertly engineered search spaces or training protocols.\nSurprisingly, we find that many NAS techniques struggle to significantly beat\nthe average architecture baseline. We perform further experiments with the\ncommonly used DARTS search space in order to understand the contribution of\neach component in the NAS pipeline. These experiments highlight that: (i) the\nuse of tricks in the evaluation protocol has a predominant impact on the\nreported performance of architectures; (ii) the cell-based search space has a\nvery narrow accuracy range, such that the seed has a considerable impact on\narchitecture rankings; (iii) the hand-designed macro-structure (cells) is more\nimportant than the searched micro-structure (operations); and (iv) the\ndepth-gap is a real phenomenon, evidenced by the change in rankings between $8$\nand $20$ cell architectures. To conclude, we suggest best practices, that we\nhope will prove useful for the community and help mitigate current NAS\npitfalls. The code used is available at\nhttps://github.com/antoyang/NAS-Benchmark.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 21:24:12 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 11:42:17 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 22:10:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Yang", "Antoine", ""], ["Esperan\u00e7a", "Pedro M.", ""], ["Carlucci", "Fabio M.", ""]]}, {"id": "1912.12528", "submitter": "Zhibin Zhao", "authors": "Zhibin Zhao, Qiyang Zhang, Xiaolei Yu, Chuang Sun, Shibin Wang,\n  Ruqiang Yan, Xuefeng Chen", "title": "Unsupervised Deep Transfer Learning for Intelligent Fault Diagnosis: An\n  Open Source and Comparative Study", "comments": "35 pages, 20 figures, 12 Tables, and a journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on intelligent fault diagnosis has greatly depended on the\ndeep learning and plenty of labeled data. However, the machine often operates\nwith various working conditions or the target task has different distributions\nwith the collected data used for training (we called the domain shift problem).\nThis leads to the deep transfer learning based (DTL-based) intelligent fault\ndiagnosis which attempts to remit this domain shift problem. Besides, the newly\ncollected testing data are usually unlabeled, which results in the subclass\nDTL-based methods called unsupervised deep transfer learning based (UDTL-based)\nintelligent fault diagnosis. Although it has achieved huge development in the\nfield of fault diagnosis, a standard and open source code framework and a\ncomparative study for UDTL-based intelligent fault diagnosis are not yet\nestablished. In this paper, commonly used UDTL-based algorithms in intelligent\nfault diagnosis are integrated into a unified testing framework and the\nframework is tested on five datasets. Extensive experiments are performed to\nprovide a systematically comparative analysis and the benchmark accuracy for\nmore comparable and meaningful further studies. To emphasize the importance and\nreproducibility of UDTL-based intelligent fault diagnosis, the testing\nframework with source codes will be released to the research community to\nfacilitate future research. Finally, comparative analysis of results also\nreveals some open and essential issues in DTL for intelligent fault diagnosis\nwhich are rarely studied including transferability of features, influence of\nbackbones, negative transfer, and physical priors. In summary, the released\nframework and comparative study can serve as an extended interface and the\nbenchmark results to carry out new studies on UDTL-based intelligent fault\ndiagnosis. The code framework is available at\nhttps://github.com/ZhaoZhibin/UDTL.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 21:45:34 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhao", "Zhibin", ""], ["Zhang", "Qiyang", ""], ["Yu", "Xiaolei", ""], ["Sun", "Chuang", ""], ["Wang", "Shibin", ""], ["Yan", "Ruqiang", ""], ["Chen", "Xuefeng", ""]]}, {"id": "1912.12534", "submitter": "Charalampos Andriotis", "authors": "C.P. Andriotis, K.G. Papakonstantinou, E.N. Chatzi", "title": "Value of structural health information in partially observable\n  stochastic environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient integration of uncertain observations with decision-making\noptimization is key for prescribing informed intervention actions, able to\npreserve structural safety of deteriorating engineering systems. To this end,\nit is necessary that scheduling of inspection and monitoring strategies be\nobjectively performed on the basis of their expected value-based gains that,\namong others, reflect quantitative metrics such as the Value of Information\n(VoI) and the Value of Structural Health Monitoring (VoSHM). In this work, we\nintroduce and study the theoretical and computational foundations of the above\nmetrics within the context of Partially Observable Markov Decision Processes\n(POMDPs), thus alluding to a broad class of decision-making problems of\npartially observable stochastic deteriorating environments that can be modeled\nas POMDPs. Step-wise and life-cycle VoI and VoSHM definitions are devised and\ntheir bounds are analyzed as per the properties stemming from the Bellman\nequation and the resulting optimal value function. It is shown that a POMDP\npolicy inherently leverages the notion of VoI to guide observational actions in\nan optimal way at every decision step, and that the permanent or intermittent\ninformation provided by SHM or inspection visits, respectively, can only\nimprove the cost of this policy in the long-term, something that is not\nnecessarily true under locally optimal policies, typically adopted in\ndecision-making of structures and infrastructure. POMDP solutions are derived\nbased on point-based value iteration methods, and the various definitions are\nquantified in stationary and non-stationary deteriorating environments, with\nboth infinite and finite planning horizons, featuring single- or\nmulti-component engineering systems.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 22:18:48 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 16:49:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Andriotis", "C. P.", ""], ["Papakonstantinou", "K. G.", ""], ["Chatzi", "E. N.", ""]]}, {"id": "1912.12553", "submitter": "Yang Shen", "authors": "Mostafa Karimi, Di Wu, Zhangyang Wang, Yang Shen", "title": "Explainable Deep Relational Networks for Predicting Compound-Protein\n  Affinities and Contacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predicting compound-protein affinity is critical for accelerating drug\ndiscovery. Recent progress made by machine learning focuses on accuracy but\nleaves much to be desired for interpretability. Through molecular contacts\nunderlying affinities, our large-scale interpretability assessment finds\ncommonly-used attention mechanisms inadequate. We thus formulate a hierarchical\nmulti-objective learning problem whose predicted contacts form the basis for\npredicted affinities. We further design a physics-inspired deep relational\nnetwork, DeepRelations, with intrinsically explainable architecture.\nSpecifically, various atomic-level contacts or \"relations\" lead to\nmolecular-level affinity prediction. And the embedded attentions are\nregularized with predicted structural contexts and supervised with partially\navailable training contacts. DeepRelations shows superior interpretability to\nthe state-of-the-art: without compromising affinity prediction, it boosts the\nAUPRC of contact prediction 9.5, 16.9, 19.3 and 5.7-fold for the test,\ncompound-unique, protein-unique, and both-unique sets, respectively. Our study\nrepresents the first dedicated model development and systematic model\nassessment for interpretable machine learning of compound-protein affinity.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 00:14:07 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Karimi", "Mostafa", ""], ["Wu", "Di", ""], ["Wang", "Zhangyang", ""], ["Shen", "Yang", ""]]}, {"id": "1912.12557", "submitter": "Sima Behpour", "authors": "Sima Behpour", "title": "Active Learning in Video Tracking", "comments": null, "journal-ref": "In International Conference on Machine Learning, pp. 563-572. 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning methods, like uncertainty sampling, combined with\nprobabilistic prediction techniques have achieved success in various problems\nlike image classification and text classification. For more complex\nmultivariate prediction tasks, the relationships between labels play an\nimportant role in designing structured classifiers with better performance.\nHowever, computational time complexity limits prevalent probabilistic methods\nfrom effectively supporting active learning. Specifically, while\nnon-probabilistic methods based on structured support vector machines can be\ntractably applied to predicting bipartite matchings, conditional random fields\nare intractable for these structures. We propose an adversarial approach for\nactive learning with structured prediction domains that is tractable for\nmatching. We evaluate this approach algorithmically in an important structured\nprediction problems: object tracking in videos. We demonstrate better accuracy\nand computational efficiency for our proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 00:42:06 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 05:53:18 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 00:15:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Behpour", "Sima", ""]]}, {"id": "1912.12566", "submitter": "Xiangyu Gao", "authors": "Xiangyu Gao, Guanbin Xing, Sumit Roy, and Hui Liu", "title": "Experiments with mmWave Automotive Radar Test-bed", "comments": "6 pages, 2019 Asilomar conference", "journal-ref": "2019 53rd Asilomar Conference on Signals, Systems, and Computers,\n  Pacific Grove, CA, USA, 2019, pp. 1-6", "doi": "10.1109/IEEECONF44664.2019.9048939", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmW) radars are being increasingly integrated in commercial\nvehicles to support new Adaptive Driver Assisted Systems (ADAS) for its ability\nto provide high accuracy location, velocity, and angle estimates of objects,\nlargely independent of environmental conditions. Such radar sensors not only\nperform basic functions such as detection and ranging/angular localization, but\nalso provide critical inputs for environmental perception via object\nrecognition and classification. To explore radar-based ADAS applications, we\nhave assembled a lab-scale frequency modulated continuous wave (FMCW) radar\ntest-bed (https://depts.washington.edu/funlab/research) based on Texas\nInstrument's (TI) automotive chipset family. In this work, we describe the\ntest-bed components and provide a summary of FMCW radar operational principles.\nTo date, we have created a large raw radar dataset for various objects under\ncontrolled scenarios. Thereafter, we apply some radar imaging algorithms to the\ncollected dataset, and present some preliminary results that validate its\ncapabilities in terms of object recognition.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 02:14:12 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 19:24:07 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gao", "Xiangyu", ""], ["Xing", "Guanbin", ""], ["Roy", "Sumit", ""], ["Liu", "Hui", ""]]}, {"id": "1912.12576", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Privacy-Preserving Public Release of Datasets for Support Vector Machine\n  Classification", "comments": null, "journal-ref": "IEEE Transactions on Big Data, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of publicly releasing a dataset for support vector\nmachine classification while not infringing on the privacy of data subjects\n(i.e., individuals whose private information is stored in the dataset). The\ndataset is systematically obfuscated using an additive noise for privacy\nprotection. Motivated by the Cramer-Rao bound, inverse of the trace of the\nFisher information matrix is used as a measure of the privacy. Conditions are\nestablished for ensuring that the classifier extracted from the original\ndataset and the obfuscated one are close to each other (capturing the utility).\nThe optimal noise distribution is determined by maximizing a weighted sum of\nthe measures of privacy and utility. The optimal privacy-preserving noise is\nproved to achieve local differential privacy. The results are generalized to a\nbroader class of optimization-based supervised machine learning algorithms.\nApplicability of the methodology is demonstrated on multiple datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 03:32:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "1912.12607", "submitter": "Ruihao Gong", "authors": "Feng Zhu, Ruihao Gong, Fengwei Yu, Xianglong Liu, Yanfei Wang, Zhelong\n  Li, Xiuqi Yang, Junjie Yan", "title": "Towards Unified INT8 Training for Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently low-bit (e.g., 8-bit) network quantization has been extensively\nstudied to accelerate the inference. Besides inference, low-bit training with\nquantized gradients can further bring more considerable acceleration, since the\nbackward process is often computation-intensive. Unfortunately, the\ninappropriate quantization of backward propagation usually makes the training\nunstable and even crash. There lacks a successful unified low-bit training\nframework that can support diverse networks on various tasks. In this paper, we\ngive an attempt to build a unified 8-bit (INT8) training framework for common\nconvolutional neural networks from the aspects of both accuracy and speed.\nFirst, we empirically find the four distinctive characteristics of gradients,\nwhich provide us insightful clues for gradient quantization. Then, we\ntheoretically give an in-depth analysis of the convergence bound and derive two\nprinciples for stable INT8 training. Finally, we propose two universal\ntechniques, including Direction Sensitive Gradient Clipping that reduces the\ndirection deviation of gradients and Deviation Counteractive Learning Rate\nScaling that avoids illegal gradient update along the wrong direction. The\nexperiments show that our unified solution promises accurate and efficient INT8\ntraining for a variety of networks and tasks, including MobileNetV2,\nInceptionV3 and object detection that prior studies have never succeeded.\nMoreover, it enjoys a strong flexibility to run on off-the-shelf hardware, and\nreduces the training time by 22% on Pascal GPU without too much optimization\neffort. We believe that this pioneering study will help lead the community\ntowards a fully unified INT8 training for convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 08:37:53 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhu", "Feng", ""], ["Gong", "Ruihao", ""], ["Yu", "Fengwei", ""], ["Liu", "Xianglong", ""], ["Wang", "Yanfei", ""], ["Li", "Zhelong", ""], ["Yang", "Xiuqi", ""], ["Yan", "Junjie", ""]]}, {"id": "1912.12612", "submitter": "Roy Fox", "authors": "Roy Fox, Richard Shin, William Paul, Yitian Zou, Dawn Song, Ken\n  Goldberg, Pieter Abbeel, Ion Stoica", "title": "Hierarchical Variational Imitation Learning of Control Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents can learn by imitating teacher demonstrations of the\nintended behavior. Hierarchical control policies are ubiquitously useful for\nsuch learning, having the potential to break down structured tasks into simpler\nsub-tasks, thereby improving data efficiency and generalization. In this paper,\nwe propose a variational inference method for imitation learning of a control\npolicy represented by parametrized hierarchical procedures (PHP), a\nprogram-like structure in which procedures can invoke sub-procedures to perform\nsub-tasks. Our method discovers the hierarchical structure in a dataset of\nobservation-action traces of teacher demonstrations, by learning an approximate\nposterior distribution over the latent sequence of procedure calls and\nterminations. Samples from this learned distribution then guide the training of\nthe hierarchical control policy. We identify and demonstrate a novel benefit of\nvariational inference in the context of hierarchical imitation learning: in\ndecomposing the policy into simpler procedures, inference can leverage acausal\ninformation that is unused by other methods. Training PHP with variational\ninference outperforms LSTM baselines in terms of data efficiency and\ngeneralization, requiring less than half as much data to achieve a 24% error\nrate in executing the bubble sort algorithm, and to achieve no error in\nexecuting Karel programs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 08:57:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Fox", "Roy", ""], ["Shin", "Richard", ""], ["Paul", "William", ""], ["Zou", "Yitian", ""], ["Song", "Dawn", ""], ["Goldberg", "Ken", ""], ["Abbeel", "Pieter", ""], ["Stoica", "Ion", ""]]}, {"id": "1912.12615", "submitter": "Anna Knezevic", "authors": "Anna Knezevic, Nikolai Dokuchaev", "title": "Approximating intractable short ratemodel distribution with neural\n  network", "comments": "Working on adding back the citations + figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm which predicts each subsequent time step relative to\nthe previous timestep of intractable short rate model (when adjusted for drift\nand overall distribution of previous percentile result) and show that the\nmethod achieves superior outcomes to the unbiased estimate both on the trained\ndataset and different validation data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 09:08:49 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 05:48:04 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 04:00:33 GMT"}, {"version": "v4", "created": "Sat, 18 Jan 2020 06:52:32 GMT"}, {"version": "v5", "created": "Wed, 5 Feb 2020 01:17:21 GMT"}, {"version": "v6", "created": "Tue, 11 Feb 2020 06:42:10 GMT"}, {"version": "v7", "created": "Sun, 23 Feb 2020 00:56:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Knezevic", "Anna", ""], ["Dokuchaev", "Nikolai", ""]]}, {"id": "1912.12616", "submitter": "Sherif Tarabishy", "authors": "Sherif Tarabishy, Stamatios Psarras, Marcin Kosicki, Martha Tsigkari", "title": "Deep learning surrogate models for spatial and visual connectivity", "comments": "Accepted manuscript in the International Journal of Architectural\n  Computing (2019)", "journal-ref": null, "doi": "10.1177/1478077119894483", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial and visual connectivity are important metrics when developing\nworkplace layouts. Calculating those metrics in real-time can be difficult,\ndepending on the size of the floor plan being analysed and the resolution of\nthe analyses. This paper investigates the possibility of considerably speeding\nup the outcomes of such computationally intensive simulations by using machine\nlearning to create models capable of identifying the spatial and visual\nconnectivity potential of a space. To that end we present the entire process of\ninvestigating different machine learning models and a pipeline for training\nthem on such task, from the incorporation of a bespoke spatial and visual\nconnectivity analysis engine through a distributed computation pipeline, to the\nprocess of synthesizing training data and evaluating the performance of\ndifferent neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 09:17:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Tarabishy", "Sherif", ""], ["Psarras", "Stamatios", ""], ["Kosicki", "Marcin", ""], ["Tsigkari", "Martha", ""]]}, {"id": "1912.12623", "submitter": "Marti Sanchez-Fibla", "authors": "Berkay Demirel, Mart\\'i S\\'anchez-Fibla", "title": "Speeding up reinforcement learning by combining attention and agency\n  features", "comments": "9 pages, 5 figures, Paper appeared in CCIA 2019", "journal-ref": null, "doi": "10.3233/FAIA190111", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When playing video-games we immediately detect which entity we control and we\ncenter the attention towards it to focus the learning and reduce its\ndimensionality. Reinforcement Learning (RL) has been able to deal with big\nstate spaces, including states derived from pixel images in Atari games, but\nthe learning is slow, depends on the brute force mapping from the global state\nto the action values (Q-function), thus its performance is severely affected by\nthe dimensionality of the state and cannot be transferred to other games or\nother parts of the same game. We propose different transformations of the input\nstate that combine attention and agency detection mechanisms which both have\nbeen addressed separately in RL but not together to our knowledge. We propose\nand benchmark different architectures including both global and local agency\ncentered versions of the state and also including summaries of the\nsurroundings. Results suggest that even a redundant global-local state network\ncan learn faster than the global alone. Summarized versions of the state look\npromising to achieve input-size independence learning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 10:23:01 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Demirel", "Berkay", ""], ["S\u00e1nchez-Fibla", "Mart\u00ed", ""]]}, {"id": "1912.12628", "submitter": "Jose Mena Rold\\'an", "authors": "Jos\\'e Mena, Oriol Pujol, Jordi Vitri\\`a", "title": "Dirichlet uncertainty wrappers for actionable algorithm accuracy\n  accountability and auditability", "comments": "13 pages, 5 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the use of machine learning models is becoming a utility in many\napplications. Companies deliver pre-trained models encapsulated as application\nprogramming interfaces (APIs) that developers combine with third party\ncomponents and their own models and data to create complex data products to\nsolve specific problems. The complexity of such products and the lack of\ncontrol and knowledge of the internals of each component used cause unavoidable\neffects, such as lack of transparency, difficulty in auditability, and\nemergence of potential uncontrolled risks. They are effectively black-boxes.\nAccountability of such solutions is a challenge for the auditors and the\nmachine learning community. In this work, we propose a wrapper that given a\nblack-box model enriches its output prediction with a measure of uncertainty.\nBy using this wrapper, we make the black-box auditable for the accuracy risk\n(risk derived from low quality or uncertain decisions) and at the same time we\nprovide an actionable mechanism to mitigate that risk in the form of decision\nrejection; we can choose not to issue a prediction when the risk or uncertainty\nin that decision is significant. Based on the resulting uncertainty measure, we\nadvocate for a rejection system that selects the more confident predictions,\ndiscarding those more uncertain, leading to an improvement in the trustability\nof the resulting system. We showcase the proposed technique and methodology in\na practical scenario where a simulated sentiment analysis API based on natural\nlanguage processing is applied to different domains. Results demonstrate the\neffectiveness of the uncertainty computed by the wrapper and its high\ncorrelation to bad quality predictions and misclassifications.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:05:47 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Mena", "Jos\u00e9", ""], ["Pujol", "Oriol", ""], ["Vitri\u00e0", "Jordi", ""]]}, {"id": "1912.12630", "submitter": "Pooyan Fazli", "authors": "Yuxiang Sun and Pooyan Fazli", "title": "Real-time Policy Distillation in Deep Reinforcement Learning", "comments": "In Proceedings of the Workshop on ML for Systems, Thirty-third\n  Conference on Neural Information Processing Systems (NeurIPS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy distillation in deep reinforcement learning provides an effective way\nto transfer control policies from a larger network to a smaller untrained\nnetwork without a significant degradation in performance. However, policy\ndistillation is underexplored in deep reinforcement learning, and existing\napproaches are computationally inefficient, resulting in a long distillation\ntime. In addition, the effectiveness of the distillation process is still\nlimited to the model capacity. We propose a new distillation mechanism, called\nreal-time policy distillation, in which training the teacher model and\ndistilling the policy to the student model occur simultaneously. Accordingly,\nthe teacher's latest policy is transferred to the student model in real time.\nThis reduces the distillation time to half the original time or even less and\nalso makes it possible for extremely small student models to learn skills at\nthe expert level. We evaluated the proposed algorithm in the Atari 2600 domain.\nThe results show that our approach can achieve full distillation in most games,\neven with compression ratios up to 1.7%.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:10:37 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sun", "Yuxiang", ""], ["Fazli", "Pooyan", ""]]}, {"id": "1912.12636", "submitter": "Tzofnat Greenberg-Toledo", "authors": "Tzofnat Greenberg Toledo, Ben Perach, Daniel Soudry and Shahar\n  Kvatinsky", "title": "MTJ-Based Hardware Synapse Design for Quantized Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized neural networks (QNNs) are being actively researched as a solution\nfor the computational complexity and memory intensity of deep neural networks.\nThis has sparked efforts to develop algorithms that support both inference and\ntraining with quantized weight and activation values without sacrificing\naccuracy. A recent example is the GXNOR framework for stochastic training of\nternary and binary neural networks. In this paper, we introduce a novel\nhardware synapse circuit that uses magnetic tunnel junction (MTJ) devices to\nsupport the GXNOR training. Our solution enables processing near memory (PNM)\nof QNNs, therefore can further reduce the data movements from and into the\nmemory. We simulated MTJ-based stochastic training of a TNN over the MNIST and\nSVHN datasets and achieved an accuracy of 98.61% and 93.99%, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:36:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Toledo", "Tzofnat Greenberg", ""], ["Perach", "Ben", ""], ["Soudry", "Daniel", ""], ["Kvatinsky", "Shahar", ""]]}, {"id": "1912.12637", "submitter": "Phillipe Sampaio", "authors": "Phillipe R. Sampaio", "title": "DEFT-FUNNEL: an open-source global optimization solver for constrained\n  grey-box and black-box problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast-growing need for grey-box and black-box optimization methods for\nconstrained global optimization problems in fields such as medicine, chemistry,\nengineering and artificial intelligence, has contributed for the design of new\nefficient algorithms for finding the best possible solution. In this work, we\npresent DEFT-FUNNEL, an open-source global optimization algorithm for general\nconstrained grey-box and black-box problems that belongs to the class of\ntrust-region sequential quadratic optimization algorithms. It extends the\nprevious works by Sampaio and Toint (2015, 2016) to a global optimization\nsolver that is able to exploit information from closed-form functions.\nPolynomial interpolation models are used as surrogates for the black-box\nfunctions and a clustering-based multistart strategy is applied for searching\nfor the global minima. Numerical experiments show that DEFT-FUNNEL compares\nfavorably with other state-of-the-art methods on two sets of benchmark\nproblems: one set containing problems where every function is a black box and\nanother set with problems where some of the functions and their derivatives are\nknown to the solver. The code as well as the test sets used for experiments are\navailable at the Github repository http://github.com/phrsampaio/deft-funnel.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 11:43:53 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sampaio", "Phillipe R.", ""]]}, {"id": "1912.12660", "submitter": "Xiao-Shan Gao", "authors": "Chen Zhao and Xiao-Shan Gao", "title": "QDNN: DNN with Quantum Neural Network Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a quantum extension of classical DNN, QDNN. The\nQDNN consisting of quantum structured layers can uniformly approximate any\ncontinuous function and has more representation power than the classical DNN.\nIt still keeps the advantages of the classical DNN such as the non-linear\nactivation, the multi-layer structure, and the efficient backpropagation\ntraining algorithm. Moreover, the QDNN can be used on near-term noisy\nintermediate-scale quantum processors. A numerical experiment for image\nclassification based on quantum DNN is given, where a high accuracy rate is\nachieved.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 14:28:37 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 09:43:41 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhao", "Chen", ""], ["Gao", "Xiao-Shan", ""]]}, {"id": "1912.12675", "submitter": "Lifu Zhang", "authors": "Lifu Zhang, Tarek S. Abdelrahman", "title": "Pipelined Training with Stale Weights of Deep Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth in the complexity of Convolutional Neural Networks (CNNs) is\nincreasing interest in partitioning a network across multiple accelerators\nduring training and pipelining the backpropagation computations over the\naccelerators. Existing approaches avoid or limit the use of stale weights\nthrough techniques such as micro-batching or weight stashing. These techniques\neither underutilize of accelerators or increase memory footprint. We explore\nthe impact of stale weights on the statistical efficiency and performance in a\npipelined backpropagation scheme that maximizes accelerator utilization and\nkeeps memory overhead modest. We use 4 CNNs (LeNet-5, AlexNet, VGG and ResNet)\nand show that when pipelining is limited to early layers in a network, training\nwith stale weights converges and results in models with comparable inference\naccuracies to those resulting from non-pipelined training on MNIST and CIFAR-10\ndatasets; a drop in accuracy of 0.4%, 4%, 0.83% and 1.45% for the 4 networks,\nrespectively. However, when pipelining is deeper in the network, inference\naccuracies drop significantly. We propose combining pipelined and non-pipelined\ntraining in a hybrid scheme to address this drop. We demonstrate the\nimplementation and performance of our pipelined backpropagation in PyTorch on 2\nGPUs using ResNet, achieving speedups of up to 1.8X over a 1-GPU baseline, with\na small drop in inference accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 15:28:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Lifu", ""], ["Abdelrahman", "Tarek S.", ""]]}, {"id": "1912.12676", "submitter": "Gurcan Comert", "authors": "Gurcan Comert, Zadid Khan, Mizanur Rahman, Mashrur Chowdhury", "title": "Grey Models for Short-Term Queue Length Predictions for Adaptive Traffic\n  Signal Control", "comments": "16 pages, 8 figures, submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion at a signalized intersection greatly reduces the travel\ntime reliability in urban areas. Adaptive signal control system (ASCS) is the\nmost advanced traffic signal technology that regulates the signal phasing and\ntimings considering the patterns in real-time in order to reduce congestion.\nReal-time prediction of queue lengths can be used to adjust the phasing and\ntimings for different movements at an intersection with ASCS. The accuracy of\nthe prediction varies based on the factors, such as the stochastic nature of\nthe vehicle arrival rates, time of the day, weather and driver characteristics.\nIn addition, accurate prediction for multilane, undersaturated and saturated\ntraffic scenarios is challenging. Thus, the objective of this study is to\ndevelop queue length prediction models for signalized intersections that can be\nleveraged by ASCS using four variations of Grey systems: (i) the first order\nsingle variable Grey model (GM(1,1)); (ii) GM(1,1) with Fourier error\ncorrections; (iii) the Grey Verhulst model (GVM), and (iv) GVM with Fourier\nerror corrections. The efficacy of the GM is that they facilitate fast\nprocessing; as these models do not require a large amount of data; as would be\nneeded in artificial intelligence models; and they are able to adapt to\nstochastic changes, unlike statistical models. We have conducted a case study\nusing queue length data from five intersections with ASCS on a calibrated\nroadway network in Lexington, South Carolina. GM were compared with linear,\nnonlinear time series models, and long short-term memory (LSTM) neural network.\nBased on our analyses, we found that EGVM reduces the prediction error over\nclosest competing models (i.e., LSTM and time series models) in predicting\naverage and maximum queue lengths by 40% and 42%, respectively, in terms of\nRoot Mean Squared Error, and 51% and 50%, respectively, in terms of Mean\nAbsolute Error.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 15:33:03 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Comert", "Gurcan", ""], ["Khan", "Zadid", ""], ["Rahman", "Mizanur", ""], ["Chowdhury", "Mashrur", ""]]}, {"id": "1912.12693", "submitter": "Federico Errica", "authors": "Davide Bacciu, Federico Errica, Alessio Micheli, Marco Podda", "title": "A Gentle Introduction to Deep Learning for Graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.06.006", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive processing of graph data is a long-standing research topic which\nhas been lately consolidated as a theme of major interest in the deep learning\ncommunity. The snap increase in the amount and breadth of related research has\ncome at the price of little systematization of knowledge and attention to\nearlier literature. This work is designed as a tutorial introduction to the\nfield of deep learning for graphs. It favours a consistent and progressive\nintroduction of the main concepts and architectural aspects over an exposition\nof the most recent literature, for which the reader is referred to available\nsurveys. The paper takes a top-down view to the problem, introducing a\ngeneralized formulation of graph representation learning based on a local and\niterative approach to structured information processing. It introduces the\nbasic building blocks that can be combined to design novel and effective neural\nmodels for graphs. The methodological exposition is complemented by a\ndiscussion of interesting research challenges and applications in the field.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 16:43:39 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 07:29:38 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bacciu", "Davide", ""], ["Errica", "Federico", ""], ["Micheli", "Alessio", ""], ["Podda", "Marco", ""]]}, {"id": "1912.12716", "submitter": "Zhaoxian Wu", "authors": "Zhaoxian Wu, Qing Ling, Tianyi Chen, and Georgios B. Giannakis", "title": "Federated Variance-Reduced Stochastic Gradient Descent with Robustness\n  to Byzantine Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with distributed finite-sum optimization for learning over\nnetworks in the presence of malicious Byzantine attacks. To cope with such\nattacks, most resilient approaches so far combine stochastic gradient descent\n(SGD) with different robust aggregation rules. However, the sizeable\nSGD-induced stochastic gradient noise makes it challenging to distinguish\nmalicious messages sent by the Byzantine attackers from noisy stochastic\ngradients sent by the 'honest' workers. This motivates us to reduce the\nvariance of stochastic gradients as a means of robustifying SGD in the presence\nof Byzantine attacks. To this end, the present work puts forth a Byzantine\nattack resilient distributed (Byrd-) SAGA approach for learning tasks involving\nfinite-sum optimization over networks. Rather than the mean employed by\ndistributed SAGA, the novel Byrd- SAGA relies on the geometric median to\naggregate the corrected stochastic gradients sent by the workers. When less\nthan half of the workers are Byzantine attackers, the robustness of geometric\nmedian to outliers enables Byrd-SAGA to attain provably linear convergence to a\nneighborhood of the optimal solution, with the asymptotic learning error\ndetermined by the number of Byzantine workers. Numerical tests corroborate the\nrobustness to various Byzantine attacks, as well as the merits of Byrd- SAGA\nover Byzantine attack resilient distributed SGD.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 19:46:03 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 07:34:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Wu", "Zhaoxian", ""], ["Ling", "Qing", ""], ["Chen", "Tianyi", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1912.12719", "submitter": "Mirza Rami\\v{c}i\\'c", "authors": "Mirza Ramicic, Andrea Bonarini", "title": "Augmented Replay Memory in Reinforcement Learning With Continuous\n  Control", "comments": null, "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems (2021)\n  1-12", "doi": "10.1109/TCDS.2021.3050723", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reinforcement learning agents are currently able to process an\nincreasing amount of data by converting it into a higher order value functions.\nThis expansion of the information collected from the environment increases the\nagent's state space enabling it to scale up to a more complex problems but also\nincreases the risk of forgetting by learning on redundant or conflicting data.\nTo improve the approximation of a large amount of data, a random mini-batch of\nthe past experiences that are stored in the replay memory buffer is often\nreplayed at each learning step. The proposed work takes inspiration from a\nbiological mechanism which act as a protective layer of human brain higher\ncognitive functions: active memory consolidation mitigates the effect of\nforgetting of previous memories by dynamically processing the new ones. The\nsimilar dynamics are implemented by a proposed augmented memory replay AMR\ncapable of optimizing the replay of the experiences from the agent's memory\nstructure by altering or augmenting their relevance. Experimental results show\nthat an evolved AMR augmentation function capable of increasing the\nsignificance of the specific memories is able to further increase the stability\nand convergence speed of the learning algorithms dealing with the complexity of\ncontinuous action domains.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 20:07:18 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Ramicic", "Mirza", ""], ["Bonarini", "Andrea", ""]]}, {"id": "1912.12726", "submitter": "Guilherme Nardari", "authors": "Steven W. Chen, Guilherme V. Nardari, Elijah S. Lee, Chao Qu, Xu Liu,\n  Roseli A. F. Romero, Vijay Kumar", "title": "SLOAM: Semantic Lidar Odometry and Mapping for Forest Inventory", "comments": "8 pages, 5 figures, IEEE Robotics and Automation Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an end-to-end pipeline for tree diameter estimation\nbased on semantic segmentation and lidar odometry and mapping. Accurate mapping\nof this type of environment is challenging since the ground and the trees are\nsurrounded by leaves, thorns and vines, and the sensor typically experiences\nextreme motion. We propose a semantic feature based pose optimization that\nsimultaneously refines the tree models while estimating the robot pose. The\npipeline utilizes a custom virtual reality tool for labeling 3D scans that is\nused to train a semantic segmentation network. The masked point cloud is used\nto compute a trellis graph that identifies individual instances and extracts\nrelevant features that are used by the SLAM module. We show that traditional\nlidar and image based methods fail in the forest environment on both Unmanned\nAerial Vehicle (UAV) and hand-carry systems, while our method is more robust,\nscalable, and automatically generates tree diameter estimations.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 20:38:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Chen", "Steven W.", ""], ["Nardari", "Guilherme V.", ""], ["Lee", "Elijah S.", ""], ["Qu", "Chao", ""], ["Liu", "Xu", ""], ["Romero", "Roseli A. F.", ""], ["Kumar", "Vijay", ""]]}, {"id": "1912.12728", "submitter": "Rachael Keller", "authors": "Rachael Keller and Qiang Du", "title": "Discovery of Dynamics Using Linear Multistep Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear multistep methods (LMMs) are popular time discretization techniques\nfor the numerical solution of differential equations. Traditionally they are\napplied to solve for the state given the dynamics (the forward problem), but\nhere we consider their application for learning the dynamics given the state\n(the inverse problem). This repurposing of LMMs is largely motivated by growing\ninterest in data-driven modeling of dynamics, but the behavior and analysis of\nLMMs for discovery turn out to be significantly different from the well-known,\nexisting theory for the forward problem. Assuming a highly idealized setting of\nbeing given the exact state with a zero residual of the discrete dynamics, we\nestablish for the first time a rigorous framework based on refined notions of\nconsistency and stability to yield convergence using LMMs for discovery. When\napplying these concepts to three popular $M-$step LMMs, the Adams-Bashforth,\nAdams-Moulton, and Backwards Differentiation Formula schemes, the new theory\nsuggests that Adams-Bashforth for $M$ ranging from $1$ and $6$, Adams-Moulton\nfor $M=0$ and $M=1$, and Backwards Differentiation Formula for all positive $M$\nare convergent, and, otherwise, the methods are not convergent in general. In\naddition, we provide numerical experiments to both motivate and substantiate\nour theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 20:41:01 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 16:24:30 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 19:41:35 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Keller", "Rachael", ""], ["Du", "Qiang", ""]]}, {"id": "1912.12761", "submitter": "Hussain Mohammed Kabir Mr", "authors": "H M Dipu Kabir, Abbas Khosravi, Abdollah Kavousi-Fard, Saeid\n  Nahavandi, Dipti Srinivasan", "title": "Optimal Uncertainty-guided Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The neural network (NN)-based direct uncertainty quantification (UQ) methods\nhave achieved the state of the art performance since the first inauguration,\nknown as the lower-upper-bound estimation (LUBE) method. However,\ncurrently-available cost functions for uncertainty guided NN training are not\nalways converging and all converged NNs are not generating optimized prediction\nintervals (PIs). Moreover, several groups have proposed different quality\ncriteria for PIs. These raise a question about their relative effectiveness.\nMost of the existing cost functions of uncertainty guided NN training are not\ncustomizable and the convergence of training is uncertain. Therefore, in this\npaper, we propose a highly customizable smooth cost function for developing NNs\nto construct optimal PIs. The optimized average width of PIs, PI-failure\ndistances and the PI coverage probability (PICP) are computed for the test\ndataset. The performance of the proposed method is examined for the wind power\ngeneration and the electricity demand data. Results show that the proposed\nmethod reduces variation in the quality of PIs, accelerates the training, and\nimproves convergence probability from 99.2% to 99.8%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 00:03:28 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kabir", "H M Dipu", ""], ["Khosravi", "Abbas", ""], ["Kavousi-Fard", "Abdollah", ""], ["Nahavandi", "Saeid", ""], ["Srinivasan", "Dipti", ""]]}, {"id": "1912.12766", "submitter": "Raman Arora", "authors": "Nils Holzenberger and Raman Arora", "title": "Multiview Representation Learning for a Union of Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a popular technique for learning\nrepresentations that are maximally correlated across multiple views in data. In\nthis paper, we extend the CCA based framework for learning a multiview mixture\nmodel. We show that the proposed model and a set of simple heuristics yield\nimprovements over standard CCA, as measured in terms of performance on\ndownstream tasks. Our experimental results show that our correlation-based\nobjective meaningfully generalizes the CCA objective to a mixture of CCA\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 00:44:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Holzenberger", "Nils", ""], ["Arora", "Raman", ""]]}, {"id": "1912.12773", "submitter": "Karl Schmeckpeper", "authors": "Karl Schmeckpeper, Annie Xie, Oleh Rybkin, Stephen Tian, Kostas\n  Daniilidis, Sergey Levine, Chelsea Finn", "title": "Learning Predictive Models From Observation and Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning predictive models from interaction with the world allows an agent,\nsuch as a robot, to learn about how the world works, and then use this learned\nmodel to plan coordinated sequences of actions to bring about desired outcomes.\nHowever, learning a model that captures the dynamics of complex skills\nrepresents a major challenge: if the agent needs a good model to perform these\nskills, it might never be able to collect the experience on its own that is\nrequired to learn these delicate and complex behaviors. Instead, we can imagine\naugmenting the training set with observational data of other agents, such as\nhumans. Such data is likely more plentiful, but represents a different\nembodiment. For example, videos of humans might show a robot how to use a tool,\nbut (i) are not annotated with suitable robot actions, and (ii) contain a\nsystematic distributional shift due to the embodiment differences between\nhumans and robots. We address the first challenge by formulating the\ncorresponding graphical model and treating the action as an observed variable\nfor the interaction data and an unobserved variable for the observation data,\nand the second challenge by using a domain-dependent prior. In addition to\ninteraction data, our method is able to leverage videos of passive observations\nin a driving dataset and a dataset of robotic manipulation videos. A robotic\nplanning agent equipped with our method can learn to use tools in a tabletop\nrobotic manipulation setting by observing humans without ever seeing a robotic\nvideo of tool use.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 01:10:41 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Schmeckpeper", "Karl", ""], ["Xie", "Annie", ""], ["Rybkin", "Oleh", ""], ["Tian", "Stephen", ""], ["Daniilidis", "Kostas", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1912.12795", "submitter": "Qinghe Jing", "authors": "Qinghe Jing, Weiyan Wang, Junxue Zhang, Han Tian, Kai Chen", "title": "Quantifying the Performance of Federated Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scarcity of data and isolated data islands encourage different\norganizations to share data with each other to train machine learning models.\nHowever, there are increasing concerns on the problems of data privacy and\nsecurity, which urges people to seek a solution like Federated Transfer\nLearning (FTL) to share training data without violating data privacy. FTL\nleverages transfer learning techniques to utilize data from different sources\nfor training, while achieving data privacy protection without significant\naccuracy loss. However, the benefits come with a cost of extra computation and\ncommunication consumption, resulting in efficiency problems. In order to\nefficiently deploy and scale up FTL solutions in practice, we need a deep\nunderstanding on how the infrastructure affects the efficiency of FTL. Our\npaper tries to answer this question by quantitatively measuring a real-world\nFTL implementation FATE on Google Cloud. According to the results of carefully\ndesigned experiments, we verified that the following bottlenecks can be further\noptimized: 1) Inter-process communication is the major bottleneck; 2) Data\nencryption adds considerable computation overhead; 3) The Internet networking\ncondition affects the performance a lot when the model is large.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 03:10:00 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Jing", "Qinghe", ""], ["Wang", "Weiyan", ""], ["Zhang", "Junxue", ""], ["Tian", "Han", ""], ["Chen", "Kai", ""]]}, {"id": "1912.12818", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, William Yang Wang", "title": "Disentangled Representation Learning with Wasserstein Total Correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of disentangled representations involves uncovering of\ndifferent factors of variations that contribute to the data generation process.\nTotal correlation penalization has been a key component in recent methods\ntowards disentanglement. However, Kullback-Leibler (KL) divergence-based total\ncorrelation is metric-agnostic and sensitive to data samples. In this paper, we\nintroduce Wasserstein total correlation in both variational autoencoder and\nWasserstein autoencoder settings to learn disentangled latent representations.\nA critic is adversarially trained along with the main objective to estimate the\nWasserstein total correlation term. We discuss the benefits of using\nWasserstein distance over KL divergence to measure independence and conduct\nquantitative and qualitative experiments on several data sets. Moreover, we\nintroduce a new metric to measure disentanglement. We show that the proposed\napproach has comparable performances on disentanglement with smaller sacrifices\nin reconstruction abilities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 05:31:28 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Xiao", "Yijun", ""], ["Wang", "William Yang", ""]]}, {"id": "1912.12825", "submitter": "Bo Zhang", "authors": "Jixiang Li, Chuming Liang, Bo Zhang, Zhao Wang, Fei Xiang, Xiangxiang\n  Chu", "title": "Neural Architecture Search on Acoustic Scene Classification", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are widely adopted in Acoustic Scene\nClassification (ASC) tasks, but they generally carry a heavy computational\nburden. In this work, we propose a lightweight yet high-performing baseline\nnetwork inspired by MobileNetV2, which replaces square convolutional kernels\nwith unidirectional ones to extract features alternately in temporal and\nfrequency dimensions. Furthermore, we explore a dynamic architecture space\nbuilt on the basis of the proposed baseline with the recent Neural Architecture\nSearch (NAS) paradigm, which first trains a supernet that incorporates all\ncandidate networks and then applies a well-known evolutionary algorithm NSGA-II\nto discover more efficient networks with higher accuracy and lower\ncomputational cost. Experimental results demonstrate that our searched network\nis competent in ASC tasks, which achieves 90.3% F1-score on the DCASE2018 task\n5 evaluation set, marking a new state-of-the-art performance while saving 25%\nof FLOPs compared to our baseline network.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 06:35:12 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 04:58:06 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Li", "Jixiang", ""], ["Liang", "Chuming", ""], ["Zhang", "Bo", ""], ["Wang", "Zhao", ""], ["Xiang", "Fei", ""], ["Chu", "Xiangxiang", ""]]}, {"id": "1912.12828", "submitter": "Feng Xiao", "authors": "Feng Xiao and Qiang Xu", "title": "ICSTrace: A Malicious IP Traceback Model for Attacking Data of\n  Industrial Control System", "comments": "14 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the attacks against industrial control system are mostly\norganized and premeditated actions, IP traceback is significant for the\nsecurity of industrial control system. Based on the infrastructure of the\nInternet, we have developed a novel malicious IP traceback model-ICSTrace,\nwithout deploying any new services. The model extracts the function codes and\ntheir parameters from the attack data according to the format of industrial\ncontrol protocol, and employs a short sequence probability method to transform\nthe function codes and their parameter into a vector, which characterizes the\nattack pattern of malicious IP addresses. Furthermore, a Partial Seeded K-Means\nalgorithm is proposed for the pattern's clustering, which helps in tracing the\nattacks back to an organization. ICSTrace is evaluated basing on the attack\ndata captured by the large-scale deployed honeypots for industrial control\nsystem, and the results demonstrate that ICSTrace is effective on malicious IP\ntraceback in industrial control system.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:00:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Xiao", "Feng", ""], ["Xu", "Qiang", ""]]}, {"id": "1912.12834", "submitter": "Andrew Wilson", "authors": "Ian A. Delbridge, David S. Bindel, Andrew Gordon Wilson", "title": "Randomly Projected Additive Gaussian Processes for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide flexible distributions over functions, with\ninductive biases controlled by a kernel. However, in many applications Gaussian\nprocesses can struggle with even moderate input dimensionality. Learning a low\ndimensional projection can help alleviate this curse of dimensionality, but\nintroduces many trainable hyperparameters, which can be cumbersome, especially\nin the small data regime. We use additive sums of kernels for GP regression,\nwhere each kernel operates on a different random projection of its inputs.\nSurprisingly, we find that as the number of random projections increases, the\npredictive performance of this approach quickly converges to the performance of\na kernel operating on the original full dimensional inputs, over a wide range\nof data sets, even if we are projecting into a single dimension. As a\nconsequence, many problems can remarkably be reduced to one dimensional input\nspaces, without learning a transformation. We prove this convergence and its\nrate, and additionally propose a deterministic approach that converges more\nquickly than purely random projections. Moreover, we demonstrate our approach\ncan achieve faster inference and improved predictive accuracy for\nhigh-dimensional inputs compared to kernels in the original input space.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:26:18 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Delbridge", "Ian A.", ""], ["Bindel", "David S.", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1912.12844", "submitter": "Xianfeng Liang", "authors": "Xianfeng Liang, Shuheng Shen, Jingchang Liu, Zhen Pan, Enhong Chen,\n  Yifei Cheng", "title": "Variance Reduced Local SGD with Lower Communication Complexity", "comments": "25 pages, 6 figures. The paper presents a novel variance reduction\n  algorithm for Local SGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accelerate the training of machine learning models, distributed stochastic\ngradient descent (SGD) and its variants have been widely adopted, which apply\nmultiple workers in parallel to speed up training. Among them, Local SGD has\ngained much attention due to its lower communication cost. Nevertheless, when\nthe data distribution on workers is non-identical, Local SGD requires\n$O(T^{\\frac{3}{4}} N^{\\frac{3}{4}})$ communications to maintain its\n\\emph{linear iteration speedup} property, where $T$ is the total number of\niterations and $N$ is the number of workers. In this paper, we propose Variance\nReduced Local SGD (VRL-SGD) to further reduce the communication complexity.\nBenefiting from eliminating the dependency on the gradient variance among\nworkers, we theoretically prove that VRL-SGD achieves a \\emph{linear iteration\nspeedup} with a lower communication complexity $O(T^{\\frac{1}{2}}\nN^{\\frac{3}{2}})$ even if workers access non-identical datasets. We conduct\nexperiments on three machine learning tasks, and the experimental results\ndemonstrate that VRL-SGD performs impressively better than Local SGD when the\ndata among workers are quite diverse.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 08:15:21 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Liang", "Xianfeng", ""], ["Shen", "Shuheng", ""], ["Liu", "Jingchang", ""], ["Pan", "Zhen", ""], ["Chen", "Enhong", ""], ["Cheng", "Yifei", ""]]}, {"id": "1912.12847", "submitter": "Yaojun Wu", "authors": "Yaojun Wu, Tianyu He, Zhibo Chen", "title": "Generative Memorize-Then-Recall framework for low bit-rate Surveillance\n  Video Compression", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of surveillance video have developed rapidly in recent years to\nprotect public safety and daily life, which often detect and recognize objects\nin video sequences. Traditional coding frameworks remove temporal redundancy in\nsurveillance video by block-wise motion compensation, lacking the extraction\nand utilization of inherent structure information. In this paper, we figure out\nthis issue by disentangling surveillance video into the structure of a global\nspatio-temporal feature (memory) for Group of Picture (GoP) and skeleton for\neach frame (clue). The memory is obtained by sequentially feeding frame inside\nGoP into a recurrent neural network, describing appearance for objects that\nappeared inside GoP. While the skeleton is calculated by a pose estimator, it\nis regarded as a clue to recall memory. Furthermore, an attention mechanism is\nintroduced to obtain the relation between appearance and skeletons. Finally, we\nemploy generative adversarial network to reconstruct each frame. Experimental\nresults indicate that our method effectively generates realistic reconstruction\nbased on appearance and skeleton, which show much higher compression\nperformance on surveillance video compared with the latest video compression\nstandard H.265.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 08:34:32 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 15:28:53 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 14:28:58 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Wu", "Yaojun", ""], ["He", "Tianyu", ""], ["Chen", "Zhibo", ""]]}, {"id": "1912.12854", "submitter": "Xi Lin", "authors": "Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, Sam Kwong", "title": "Pareto Multi-Task Learning", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning is a powerful method for solving multiple correlated\ntasks simultaneously. However, it is often impossible to find one single\nsolution to optimize all the tasks, since different tasks might conflict with\neach other. Recently, a novel method is proposed to find one single Pareto\noptimal solution with good trade-off among different tasks by casting\nmulti-task learning as multiobjective optimization. In this paper, we\ngeneralize this idea and propose a novel Pareto multi-task learning algorithm\n(Pareto MTL) to find a set of well-distributed Pareto solutions which can\nrepresent different trade-offs among different tasks. The proposed algorithm\nfirst formulates a multi-task learning problem as a multiobjective optimization\nproblem, and then decomposes the multiobjective optimization problem into a set\nof constrained subproblems with different trade-off preferences. By solving\nthese subproblems in parallel, Pareto MTL can find a set of well-representative\nPareto optimal solutions with different trade-off among all tasks.\nPractitioners can easily select their preferred solution from these Pareto\nsolutions, or use different trade-off solutions for different situations.\nExperimental results confirm that the proposed algorithm can generate\nwell-representative solutions and outperform some state-of-the-art algorithms\non many multi-task learning applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 08:58:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Lin", "Xi", ""], ["Zhen", "Hui-Ling", ""], ["Li", "Zhenhua", ""], ["Zhang", "Qingfu", ""], ["Kwong", "Sam", ""]]}, {"id": "1912.12860", "submitter": "Boyang Li", "authors": "Xin Zhou, Dejing Dou, Boyang Li", "title": "Searching for Stage-wise Neural Graphs In the Limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search space is a key consideration for neural architecture search. Recently,\nXie et al. (2019) found that randomly generated networks from the same\ndistribution perform similarly, which suggests we should search for random\ngraph distributions instead of graphs. We propose graphon as a new search\nspace. A graphon is the limit of Cauchy sequence of graphs and a scale-free\nprobabilistic distribution, from which graphs of different number of nodes can\nbe drawn. By utilizing properties of the graphon space and the associated\ncut-distance metric, we develop theoretically motivated techniques that search\nfor and scale up small-capacity stage-wise graphs found on small datasets to\nlarge-capacity graphs that can handle ImageNet. The scaled stage-wise graphs\noutperform DenseNet and randomly wired Watts-Strogatz networks, indicating the\nbenefits of graphon theory in NAS applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 09:17:23 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhou", "Xin", ""], ["Dou", "Dejing", ""], ["Li", "Boyang", ""]]}, {"id": "1912.12867", "submitter": "Martin Spindler", "authors": "Xi Chen, Ye Luo, Martin Spindler", "title": "Adaptive Discrete Smoothing for High-Dimensional and Nonlinear Panel\n  Data", "comments": "18 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a data-driven smoothing technique for\nhigh-dimensional and non-linear panel data models. We allow for individual\nspecific (non-linear) functions and estimation with econometric or machine\nlearning methods by using weighted observations from other individuals. The\nweights are determined by a data-driven way and depend on the similarity\nbetween the corresponding functions and are measured based on initial\nestimates. The key feature of such a procedure is that it clusters individuals\nbased on the distance / similarity between them, estimated in a first stage.\nOur estimation method can be combined with various statistical estimation\nprocedures, in particular modern machine learning methods which are in\nparticular fruitful in the high-dimensional case and with complex,\nheterogeneous data. The approach can be interpreted as a \\textquotedblleft\nsoft-clustering\\textquotedblright\\ in comparison to\ntraditional\\textquotedblleft\\ hard clustering\\textquotedblright that assigns\neach individual to exactly one group. We conduct a simulation study which shows\nthat the prediction can be greatly improved by using our estimator. Finally, we\nanalyze a big data set from didichuxing.com, a leading company in\ntransportation industry, to analyze and predict the gap between supply and\ndemand based on a large set of covariates. Our estimator clearly performs much\nbetter in out-of-sample prediction compared to existing linear panel data\nestimators.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 09:50:58 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 16:39:10 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Chen", "Xi", ""], ["Luo", "Ye", ""], ["Spindler", "Martin", ""]]}, {"id": "1912.12879", "submitter": "Alice Lucas", "authors": "Alice Lucas, Santiago Lopez-Tapia, Rafael Molina and Aggelos K.\n  Katsaggelos", "title": "Self-supervised Fine-tuning for Correcting Super-Resolution\n  Convolutional Neural Networks", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Convolutional Neural Networks (CNNs) trained for image and video\nsuper-resolution (SR) regularly achieve new state-of-the-art performance, they\nalso suffer from significant drawbacks. One of their limitations is their lack\nof robustness to unseen image formation models during training. Other\nlimitations include the generation of artifacts and hallucinated content when\ntraining Generative Adversarial Networks (GANs) for SR. While the Deep Learning\nliterature focuses on presenting new training schemes and settings to resolve\nthese various issues, we show that one can avoid training and correct for SR\nresults with a fully self-supervised fine-tuning approach. More specifically,\nat test time, given an image and its known image formation model, we fine-tune\nthe parameters of the trained network and iteratively update them using a data\nfidelity loss. We apply our fine-tuning algorithm on multiple image and video\nSR CNNs and show that it can successfully correct for a sub-optimal SR solution\nby entirely relying on internal learning at test time. We apply our method on\nthe problem of fine-tuning for unseen image formation models and on removal of\nartifacts introduced by GANs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 11:02:58 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 13:37:29 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 12:11:14 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lucas", "Alice", ""], ["Lopez-Tapia", "Santiago", ""], ["Molina", "Rafael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1912.12912", "submitter": "Julia Moosbauer", "authors": "Martin Binder, Julia Moosbauer, Janek Thomas, Bernd Bischl", "title": "Multi-Objective Hyperparameter Tuning and Feature Selection using Filter\n  Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Both feature selection and hyperparameter tuning are key tasks in machine\nlearning. Hyperparameter tuning is often useful to increase model performance,\nwhile feature selection is undertaken to attain sparse models. Sparsity may\nyield better model interpretability and lower cost of data acquisition, data\nhandling and model inference. While sparsity may have a beneficial or\ndetrimental effect on predictive performance, a small drop in performance may\nbe acceptable in return for a substantial gain in sparseness. We therefore\ntreat feature selection as a multi-objective optimization task. We perform\nhyperparameter tuning and feature selection simultaneously because the choice\nof features of a model may influence what hyperparameters perform well.\n  We present, benchmark, and compare two different approaches for\nmulti-objective joint hyperparameter optimization and feature selection: The\nfirst uses multi-objective model-based optimization. The second is an\nevolutionary NSGA-II-based wrapper approach to feature selection which\nincorporates specialized sampling, mutation and recombination operators. Both\nmethods make use of parameterized filter ensembles.\n  While model-based optimization needs fewer objective evaluations to achieve\ngood performance, it incurs computational overhead compared to the NSGA-II, so\nthe preferred choice depends on the cost of evaluating a model on given data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 13:04:06 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 10:41:13 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Binder", "Martin", ""], ["Moosbauer", "Julia", ""], ["Thomas", "Janek", ""], ["Bischl", "Bernd", ""]]}, {"id": "1912.12923", "submitter": "Shi-Ju Ran", "authors": "Shi-Ju Ran", "title": "Bayesian Tensor Network with Polynomial Complexity for Probabilistic\n  Machine Learning", "comments": "7 pages, 5 figures; in the second version, results of the BTN with a\n  new structure were added; other modifications including the formulation of\n  Bayes' equation in tensor forms were made", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that describing or calculating the conditional probabilities of\nmultiple events is exponentially expensive. In this work, Bayesian tensor\nnetwork (BTN) is proposed to efficiently capture the conditional probabilities\nof multiple sets of events with polynomial complexity. BTN is a directed\nacyclic graphical model that forms a subset of TN. To testify its validity for\nexponentially many events, BTN is implemented to the image recognition, where\nthe classification is mapped to capturing the conditional probabilities in an\nexponentially large sample space. Competitive performance is achieved by the\nBTN with simple tree network structures. Analogous to the tensor network\nsimulations of quantum systems, the validity of the simple-tree BTN implies an\n``area law'' of fluctuations in image recognition problems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 13:37:46 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 12:36:54 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ran", "Shi-Ju", ""]]}, {"id": "1912.12927", "submitter": "Lei Feng", "authors": "Lei Feng, Takuo Kaneko, Bo Han, Gang Niu, Bo An, Masashi Sugiyama", "title": "Learning with Multiple Complementary Labels", "comments": "ICML 2020 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complementary label (CL) simply indicates an incorrect class of an example,\nbut learning with CLs results in multi-class classifiers that can predict the\ncorrect class. Unfortunately, the problem setting only allows a single CL for\neach example, which notably limits its potential since our labelers may easily\nidentify multiple CLs (MCLs) to one example. In this paper, we propose a novel\nproblem setting to allow MCLs for each example and two ways for learning with\nMCLs. In the first way, we design two wrappers that decompose MCLs into many\nsingle CLs, so that we could use any method for learning with CLs. However, the\nsupervision information that MCLs hold is conceptually diluted after\ndecomposition. Thus, in the second way, we derive an unbiased risk estimator;\nminimizing it processes each set of MCLs as a whole and possesses an estimation\nerror bound. We further improve the second way into minimizing properly chosen\nupper bounds. Experiments show that the former way works well for learning with\nMCLs but the latter is even better.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 13:50:51 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 04:45:52 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 08:50:50 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Feng", "Lei", ""], ["Kaneko", "Takuo", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["An", "Bo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1912.12932", "submitter": "Regis Pierrard", "authors": "R\\'egis Pierrard (LIST, MICS), Jean-Philippe Poli (LIST), C\\'eline\n  Hudelot (MICS)", "title": "A New Approach for Explainable Multiple Organ Annotation with Few Data", "comments": null, "journal-ref": "IJCAI 2019 Workshop on Explainable Artificial Intelligence (XAI),\n  Aug 2019, Macao, Macau SAR China", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep learning, such models are still far from\nsome human abilities like learning from few examples, reasoning and explaining\ndecisions. In this paper, we focus on organ annotation in medical images and we\nintroduce a reasoning framework that is based on learning fuzzy relations on a\nsmall dataset for generating explanations. Given a catalogue of relations, it\nefficiently induces the most relevant relations and combines them for building\nconstraints in order to both solve the organ annotation task and generate\nexplanations. We test our approach on a publicly available dataset of medical\nimages where several organs are already segmented. A demonstration of our model\nis proposed with an example of explained annotations. It was trained on a small\ntraining set containing as few as a couple of examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:06:32 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pierrard", "R\u00e9gis", "", "LIST, MICS"], ["Poli", "Jean-Philippe", "", "LIST"], ["Hudelot", "C\u00e9line", "", "MICS"]]}, {"id": "1912.12941", "submitter": "Kilian Hendrickx", "authors": "Kilian Hendrickx, Wannes Meert, Yves Mollet, Johan Gyselinck, Bram\n  Cornelis, Konstantinos Gryllias, Jesse Davis", "title": "A general anomaly detection framework for fleet-based condition\n  monitoring of machines", "comments": "Accepted in Mechanical Systems and Signal Processing, SI: Machine\n  Diagnostics by AI", "journal-ref": null, "doi": "10.1016/j.ymssp.2019.106585", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine failures decrease up-time and can lead to extra repair costs or even\nto human casualties and environmental pollution. Recent condition monitoring\ntechniques use artificial intelligence in an effort to avoid time-consuming\nmanual analysis and handcrafted feature extraction. Many of these only analyze\na single machine and require a large historical data set. In practice, this can\nbe difficult and expensive to collect. However, some industrial condition\nmonitoring applications involve a fleet of similar operating machines. In most\nof these applications, it is safe to assume healthy conditions for the majority\nof machines. Deviating machine behavior is then an indicator for a machine\nfault. This work proposes an unsupervised, generic, anomaly detection framework\nfor fleet-based condition monitoring. It uses generic building blocks and\noffers three key advantages. First, a historical data set is not required due\nto online fleet-based comparisons. Second, it allows incorporating domain\nexpertise by user-defined comparison measures. Finally, contrary to most\nblack-box artificial intelligence techniques, easy interpretability allows a\ndomain expert to validate the predictions made by the framework. Two use-cases\non an electrical machine fleet demonstrate the applicability of the framework\nto detect a voltage unbalance by means of electrical and vibration signatures.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:35:45 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 11:10:06 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 11:06:06 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hendrickx", "Kilian", ""], ["Meert", "Wannes", ""], ["Mollet", "Yves", ""], ["Gyselinck", "Johan", ""], ["Cornelis", "Bram", ""], ["Gryllias", "Konstantinos", ""], ["Davis", "Jesse", ""]]}, {"id": "1912.12942", "submitter": "Jerome Tubiana", "authors": "Moshir Harsh (LPENS, PSL), J\\'er\\^ome Tubiana (TAU-CS), Simona Cocco\n  (LPENS, PSL), Remi Monasson (LPENS, PSL)", "title": "'Place-cell' emergence and learning of invariant data with restricted\n  Boltzmann machines: breaking and dynamical restoration of continuous\n  symmetries in the weight space", "comments": null, "journal-ref": null, "doi": "10.1088/1751-8121/ab7d00", "report-no": null, "categories": "cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions of data or sensory stimuli often enjoy underlying invariances.\nHow and to what extent those symmetries are captured by unsupervised learning\nmethods is a relevant question in machine learning and in computational\nneuroscience. We study here, through a combination of numerical and analytical\ntools, the learning dynamics of Restricted Boltzmann Machines (RBM), a neural\nnetwork paradigm for representation learning. As learning proceeds from a\nrandom configuration of the network weights, we show the existence of, and\ncharacterize a symmetry-breaking phenomenon, in which the latent variables\nacquire receptive fields focusing on limited parts of the invariant manifold\nsupporting the data. The symmetry is restored at large learning times through\nthe diffusion of the receptive field over the invariant manifold; hence, the\nRBM effectively spans a continuous attractor in the space of network weights.\nThis symmetry-breaking phenomenon takes place only if the amount of data\navailable for training exceeds some critical value, depending on the network\nsize and the intensity of symmetry-induced correlations in the data; below this\n'retarded-learning' threshold, the network weights are essentially noisy and\noverfit the data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:37:14 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Harsh", "Moshir", "", "LPENS, PSL"], ["Tubiana", "J\u00e9r\u00f4me", "", "TAU-CS"], ["Cocco", "Simona", "", "LPENS, PSL"], ["Monasson", "Remi", "", "LPENS, PSL"]]}, {"id": "1912.12945", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Xiaojie Mao, Masatoshi Uehara", "title": "Localized Debiased Machine Learning: Efficient Inference on Quantile\n  Treatment Effects and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the efficient estimation of a low-dimensional parameter in an\nestimating equation involving high-dimensional nuisances that depend on the\nparameter of interest. An important example is the (local) quantile treatment\neffect ((L)QTE) in causal inference, for which the efficient estimating\nequation involves as a nuisance the covariate-conditional cumulative\ndistribution function evaluated at the quantile to be estimated. Debiased\nmachine learning (DML) is a data-splitting approach to address the need to\nestimate nuisances using flexible machine learning methods that may not satisfy\nstrong metric entropy conditions, but applying it to problems with\nparameter-dependent nuisances is impractical. For (L)QTE estimation, DML\nrequires we learn the whole conditional cumulative distribution function,\nconditioned on potentially high-dimensional covariates, which is far more\nchallenging than the standard supervised regression task in machine learning.\nWe instead propose localized debiased machine learning (LDML), a new\ndata-splitting approach that avoids this burdensome step and needs only\nestimate the nuisances at a single initial rough guess for the parameter. For\n(L)QTE estimation, this involves just learning two binary regression (i.e.,\nclassification) models, for which many standard, time-tested machine learning\nmethods exist, and the initial rough guess may be given by inverse propensity\nweighting. We prove that under lax rate conditions on nuisances, our estimator\nhas the same favorable asymptotic behavior as the infeasible oracle estimator\nthat solves the estimating equation with the unknown true nuisance functions.\nThus, our proposed approach uniquely enables practically-feasible and\ntheoretically-grounded efficient estimation of important quantities in causal\ninference such as (L)QTEs and in other coarsened data settings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:42:52 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 17:02:07 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:50:56 GMT"}, {"version": "v4", "created": "Mon, 12 Oct 2020 20:23:00 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1912.12970", "submitter": "Wanxin Jin", "authors": "Wanxin Jin, Zhaoran Wang, Zhuoran Yang, Shaoshuai Mou", "title": "Pontryagin Differentiable Programming: An End-to-End Learning and\n  Control Framework", "comments": "Published in NeurIPS 2020, Codes are at\n  https://github.com/wanxinjin/Pontryagin-Differentiable-Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Pontryagin Differentiable Programming (PDP)\nmethodology, which establishes a unified framework to solve a broad class of\nlearning and control tasks. The PDP distinguishes from existing methods by two\nnovel techniques: first, we differentiate through Pontryagin's Maximum\nPrinciple, and this allows to obtain the analytical derivative of a trajectory\nwith respect to tunable parameters within an optimal control system, enabling\nend-to-end learning of dynamics, policies, or/and control objective functions;\nand second, we propose an auxiliary control system in the backward pass of the\nPDP framework, and the output of this auxiliary control system is the\nanalytical derivative of the original system's trajectory with respect to the\nparameters, which can be iteratively solved using standard control tools. We\ninvestigate three learning modes of the PDP: inverse reinforcement learning,\nsystem identification, and control/planning. We demonstrate the capability of\nthe PDP in each learning mode on different high-dimensional systems, including\nmulti-link robot arm, 6-DoF maneuvering quadrotor, and 6-DoF rocket powered\nlanding.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 15:35:43 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 13:22:39 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 19:49:57 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 14:07:37 GMT"}, {"version": "v5", "created": "Tue, 12 Jan 2021 14:01:47 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Jin", "Wanxin", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""], ["Mou", "Shaoshuai", ""]]}, {"id": "1912.12979", "submitter": "Corinne Jones", "authors": "Corinne Jones, Vincent Roulet, Zaid Harchaoui", "title": "End-to-end Learning, with or without Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for end-to-end learning that allows one to jointly\nlearn a feature representation from unlabeled data (with or without labeled\ndata) and predict labels for unlabeled data. The feature representation is\nassumed to be specified in a differentiable programming framework, that is, as\na parameterized mapping amenable to automatic differentiation. The proposed\napproach can be used with any amount of labeled and unlabeled data, gracefully\nadjusting to the amount of supervision. We provide experimental results\nillustrating the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:11:40 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Jones", "Corinne", ""], ["Roulet", "Vincent", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1912.12988", "submitter": "Ping Li", "authors": "Mostafa Rahmani and Ping Li", "title": "Outlier Detection and Data Clustering via Innovation Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of Innovation Search was proposed as a data clustering method in\nwhich the directions of innovation were utilized to compute the adjacency\nmatrix and it was shown that Innovation Pursuit can notably outperform the self\nrepresentation based subspace clustering methods. In this paper, we present a\nnew discovery that the directions of innovation can be used to design a\nprovable and strong robust (to outlier) PCA method. The proposed approach,\ndubbed iSearch, uses the direction search optimization problem to compute an\noptimal direction corresponding to each data point. iSearch utilizes the\ndirections of innovation to measure the innovation of the data points and it\nidentifies the outliers as the most innovative data points. Analytical\nperformance guarantees are derived for the proposed robust PCA method under\ndifferent models for the distribution of the outliers including randomly\ndistributed outliers, clustered outliers, and linearly dependent outliers. In\naddition, we study the problem of outlier detection in a union of subspaces and\nit is shown that iSearch provably recovers the span of the inliers when the\ninliers lie in a union of subspaces. Moreover, we present theoretical studies\nwhich show that the proposed measure of innovation remains stable in the\npresence of noise and the performance of iSearch is robust to noisy data. In\nthe challenging scenarios in which the outliers are close to each other or they\nare close to the span of the inliers, iSearch is shown to remarkably outperform\nmost of the existing methods. The presented method shows that the directions of\ninnovation are useful representation of the data which can be used to perform\nboth data clustering and outlier detection.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:29:04 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Rahmani", "Mostafa", ""], ["Li", "Ping", ""]]}, {"id": "1912.12999", "submitter": "Laura Kinkead", "authors": "Laura Kinkead, Ahmed Allam, Michael Krauthammer", "title": "AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:44:41 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 13:52:19 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 16:01:39 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kinkead", "Laura", ""], ["Allam", "Ahmed", ""], ["Krauthammer", "Michael", ""]]}, {"id": "1912.13000", "submitter": "Zhe Wu", "authors": "Zhe Wu, Zuxuan Wu, Bharat Singh, Larry S. Davis", "title": "Recognizing Instagram Filtered Images with Feature De-stylization", "comments": "Accepted in AAAI 2020 as an oral presentation paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to suffer from poor generalization when\nsmall perturbations are added (like Gaussian noise), yet little work has been\ndone to evaluate their robustness to more natural image transformations like\nphoto filters. This paper presents a study on how popular pretrained models are\naffected by commonly used Instagram filters. To this end, we introduce\nImageNet-Instagram, a filtered version of ImageNet, where 20 popular Instagram\nfilters are applied to each image in ImageNet. Our analysis suggests that\nsimple structure preserving filters which only alter the global appearance of\nan image can lead to large differences in the convolutional feature space. To\nimprove generalization, we introduce a lightweight de-stylization module that\npredicts parameters used for scaling and shifting feature maps to \"undo\" the\nchanges incurred by filters, inverting the process of style transfer tasks. We\nfurther demonstrate the module can be readily plugged into modern CNN\narchitectures together with skip connections. We conduct extensive studies on\nImageNet-Instagram, and show quantitatively and qualitatively, that the\nproposed module, among other things, can effectively improve generalization by\nsimply learning normalization parameters without retraining the entire network,\nthus recovering the alterations in the feature space caused by the filters.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:48:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Wu", "Zhe", ""], ["Wu", "Zuxuan", ""], ["Singh", "Bharat", ""], ["Davis", "Larry S.", ""]]}, {"id": "1912.13007", "submitter": "Marwin Segler", "authors": "Marwin H.S. Segler", "title": "World Programs for Model-Based Learning and Planning in Compositional\n  State and Action Spaces", "comments": "Accepted at the Generative Modeling and Model-Based Reasoning for\n  Robotics and AI workshop at ICML 2019. Presented on June 14th 2019. See\n  https://sites.google.com/view/mbrl-icml2019", "journal-ref": "https://sites.google.com/view/mbrl-icml2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the most important tasks take place in environments which lack cheap\nand perfect simulators, thus hampering the application of model-free\nreinforcement learning (RL). While model-based RL aims to learn a dynamics\nmodel, in a more general case the learner does not know a priori what the\naction space is. Here we propose a formalism where the learner induces a world\nprogram by learning a dynamics model and the actions in graph-based\ncompositional environments by observing state-state transition examples. Then,\nthe learner can perform RL with the world program as the simulator for complex\nplanning tasks. We highlight a recent application, and propose a challenge for\nthe community to assess world program-based planning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 17:03:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Segler", "Marwin H. S.", ""]]}, {"id": "1912.13025", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Polina Kirichenko, Marc Finzi, Andrew Gordon Wilson", "title": "Semi-Supervised Learning with Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows transform a latent distribution through an invertible\nneural network for a flexible and pleasingly simple approach to generative\nmodelling, while preserving an exact likelihood. We propose FlowGMM, an\nend-to-end approach to generative semi supervised learning with normalizing\nflows, using a latent Gaussian mixture model. FlowGMM is distinct in its\nsimplicity, unified treatment of labelled and unlabelled data with an exact\nlikelihood, interpretability, and broad applicability beyond image data. We\nshow promising results on a wide range of applications, including AG-News and\nYahoo Answers text data, tabular data, and semi-supervised image\nclassification. We also show that FlowGMM can discover interpretable structure,\nprovide real-time optimization-free feature visualizations, and specify well\ncalibrated predictive distributions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 17:36:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Izmailov", "Pavel", ""], ["Kirichenko", "Polina", ""], ["Finzi", "Marc", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1912.13032", "submitter": "Alexander Gutfraind", "authors": "Jos\\'e M. Maisog and Wenhong Li and Yanchun Xu and Brian Hurley and\n  Hetal Shah and Ryan Lemberg and Tina Borden and Stephen Bandeian and Melissa\n  Schline and Roxanna Cross and Alan Spiro and Russ Michael and Alexander\n  Gutfraind", "title": "Using massive health insurance claims data to predict very high-cost\n  claimants: a machine learning approach", "comments": "34 pages, 2 figures, In review in PLoS ONE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Due to escalating healthcare costs, accurately predicting which patients will\nincur high costs is an important task for payers and providers of healthcare.\nHigh-cost claimants (HiCCs) are patients who have annual costs above\n$\\$250,000$ and who represent just 0.16% of the insured population but\ncurrently account for 9% of all healthcare costs. In this study, we aimed to\ndevelop a high-performance algorithm to predict HiCCs to inform a novel care\nmanagement system. Using health insurance claims from 48 million people and\naugmented with census data, we applied machine learning to train binary\nclassification models to calculate the personal risk of HiCC. To train the\nmodels, we developed a platform starting with 6,006 variables across all\nclinical and demographic dimensions and constructed over one hundred candidate\nmodels. The best model achieved an area under the receiver operating\ncharacteristic curve of 91.2%. The model exceeds the highest published\nperformance (84%) and remains high for patients with no prior history of\nhigh-cost status (89%), who have less than a full year of enrollment (87%), or\nlack pharmacy claims data (88%). It attains an area under the precision-recall\ncurve of 23.1%, and precision of 74% at a threshold of 0.99. A care management\nprogram enrolling 500 people with the highest HiCC risk is expected to treat\n199 true HiCCs and generate a net savings of $\\$7.3$ million per year. Our\nresults demonstrate that high-performing predictive models can be constructed\nusing claims data and publicly available data alone, even for rare high-cost\nclaimants exceeding $\\$250,000$. Our model demonstrates the transformational\npower of machine learning and artificial intelligence in care management, which\nwould allow healthcare payers and providers to introduce the next generation of\ncare management programs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:01:30 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Maisog", "Jos\u00e9 M.", ""], ["Li", "Wenhong", ""], ["Xu", "Yanchun", ""], ["Hurley", "Brian", ""], ["Shah", "Hetal", ""], ["Lemberg", "Ryan", ""], ["Borden", "Tina", ""], ["Bandeian", "Stephen", ""], ["Schline", "Melissa", ""], ["Cross", "Roxanna", ""], ["Spiro", "Alan", ""], ["Michael", "Russ", ""], ["Gutfraind", "Alexander", ""]]}, {"id": "1912.13037", "submitter": "Daniel Hsu", "authors": "Daniel Hsu", "title": "A New Framework for Query Efficient Active Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to align agent policy with human expert behavior in a reinforcement\nlearning (RL) setting, without any prior knowledge about dynamics, reward\nfunction, and unsafe states. There is a human expert knowing the rewards and\nunsafe states based on his preference and objective, but querying that human\nexpert is expensive. To address this challenge, we propose a new framework for\nimitation learning (IL) algorithm that actively and interactively learns a\nmodel of the user's reward function with efficient queries. We build an\nadversarial generative model of states and a successor feature (SR) model\ntrained over transition experience collected by learning policy. Our method\nuses these models to select state-action pairs, asking the user to comment on\nthe optimality or safety, and trains a adversarial neural network to predict\nthe rewards. Different from previous papers, which are almost all based on\nuncertainty sampling, the key idea is to actively and efficiently select\nstate-action pairs from both on-policy and off-policy experience, by\ndiscriminating the queried (expert) and unqueried (generated) data and\nmaximizing the efficiency of value function learning. We call this method\nadversarial reward query with successor representation. We evaluate the\nproposed method with simulated human on a state-based 2D navigation task,\nrobotic control tasks and the image-based video games, which have\nhigh-dimensional observation and complex state dynamics. The results show that\nthe proposed method significantly outperforms uncertainty-based methods on\nlearning reward models, achieving better query efficiency, where the\nadversarial discriminator can make the agent learn human behavior more\nefficiently and the SR can select states which have stronger impact on value\nfunction. Moreover, the proposed method can also learn to avoid unsafe states\nwhen training the reward model.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:12:27 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hsu", "Daniel", ""]]}, {"id": "1912.13046", "submitter": "Edward Raff", "authors": "Edward Raff, Charles Nicholas, Mark McLean", "title": "A New Burrows Wheeler Transform Markov Distance", "comments": "To appear in: The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), AICS-2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work inspired by compression algorithms has described how the Burrows\nWheeler Transform can be used to create a distance measure for bioinformatics\nproblems. We describe issues with this approach that were not widely known, and\nintroduce our new Burrows Wheeler Markov Distance (BWMD) as an alternative. The\nBWMD avoids the shortcomings of earlier efforts, and allows us to tackle\nproblems in variable length DNA sequence clustering. BWMD is also more\nadaptable to other domains, which we demonstrate on malware classification\ntasks. Unlike other compression-based distance metrics known to us, BWMD works\nby embedding sequences into a fixed-length feature vector. This allows us to\nprovide significantly improved clustering performance on larger malware\ncorpora, a weakness of prior methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:33:32 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Raff", "Edward", ""], ["Nicholas", "Charles", ""], ["McLean", "Mark", ""]]}, {"id": "1912.13053", "submitter": "Samuel Schoenholz", "authors": "Lechao Xiao, Jeffrey Pennington, Samuel S. Schoenholz", "title": "Disentangling Trainability and Generalization in Deep Neural Networks", "comments": "22 pages, 3 figures, ICML 2020. Associated Colab notebook at\n  https://colab.research.google.com/github/google/neural-tangents/blob/master/notebooks/Disentangling_Trainability_and_Generalization.ipynb", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal in the theory of deep learning is to characterize the\nconditions under which a given neural network architecture will be trainable,\nand if so, how well it might generalize to unseen data. In this work, we\nprovide such a characterization in the limit of very wide and very deep\nnetworks, for which the analysis simplifies considerably. For wide networks,\nthe trajectory under gradient descent is governed by the Neural Tangent Kernel\n(NTK), and for deep networks the NTK itself maintains only weak data\ndependence. By analyzing the spectrum of the NTK, we formulate necessary\nconditions for trainability and generalization across a range of architectures,\nincluding Fully Connected Networks (FCNs) and Convolutional Neural Networks\n(CNNs). We identify large regions of hyperparameter space for which networks\ncan memorize the training set but completely fail to generalize. We find that\nCNNs without global average pooling behave almost identically to FCNs, but that\nCNNs with pooling have markedly different and often better generalization\nperformance. These theoretical results are corroborated experimentally on\nCIFAR10 for a variety of network architectures and we include a colab notebook\nthat reproduces the essential results of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:53:24 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:55:53 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Xiao", "Lechao", ""], ["Pennington", "Jeffrey", ""], ["Schoenholz", "Samuel S.", ""]]}, {"id": "1912.13072", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, Azadeh Hashemi, El Moatez Billah\n  Nagoudi", "title": "AraNet: A Deep Learning Toolkit for Arabic Social Media", "comments": "Accepted by The 4th Workshop on Open-Source Arabic Corpora and\n  Processing Tools (OSACT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe AraNet, a collection of deep learning Arabic social media\nprocessing tools. Namely, we exploit an extensive host of publicly available\nand novel social media datasets to train bidirectional encoders from\ntransformer models (BERT) to predict age, dialect, gender, emotion, irony, and\nsentiment. AraNet delivers state-of-the-art performance on a number of the\ncited tasks and competitively on others. In addition, AraNet has the advantage\nof being exclusively based on a deep learning framework and hence feature\nengineering free. To the best of our knowledge, AraNet is the first to performs\npredictions across such a wide range of tasks for Arabic NLP and thus meets a\ncritical needs. We publicly release AraNet to accelerate research and\nfacilitate comparisons across the different tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 20:05:37 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 18:31:26 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Hashemi", "Azadeh", ""], ["Nagoudi", "El Moatez Billah", ""]]}, {"id": "1912.13075", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa", "title": "Robust Federated Learning Through Representation Matching and Adaptive\n  Hyper-parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed, privacy-aware learning scenario which\ntrains a single model on data belonging to several clients. Each client trains\na local model on its data and the local models are then aggregated by a central\nparty. Current federated learning methods struggle in cases with heterogeneous\nclient-side data distributions which can quickly lead to divergent local models\nand a collapse in performance. Careful hyper-parameter tuning is particularly\nimportant in these cases but traditional automated hyper-parameter tuning\nmethods would require several training trials which is often impractical in a\nfederated learning setting. We describe a two-pronged solution to the issues of\nrobustness and hyper-parameter tuning in federated learning settings. We\npropose a novel representation matching scheme that reduces the divergence of\nlocal models by ensuring the feature representations in the global (aggregate)\nmodel can be derived from the locally learned representations. We also propose\nan online hyper-parameter tuning scheme which uses an online version of the\nREINFORCE algorithm to find a hyper-parameter distribution that maximizes the\nexpected improvements in training loss. We show on several benchmarks that our\ntwo-part scheme of local representation matching and global adaptive\nhyper-parameters significantly improves performance and training robustness.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 20:19:20 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Mostafa", "Hesham", ""]]}, {"id": "1912.13077", "submitter": "Changhao Chen", "authors": "Changhao Chen, Stefano Rosa, Chris Xiaoxuan Lu, Niki Trigoni, Andrew\n  Markham", "title": "SelectFusion: A Generic Framework to Selectively Learn Multisensory\n  Fusion", "comments": "An extended journal version of arXiv:1903.01534 (CVPR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous vehicles and mobile robotic systems are typically equipped with\nmultiple sensors to provide redundancy. By integrating the observations from\ndifferent sensors, these mobile agents are able to perceive the environment and\nestimate system states, e.g. locations and orientations. Although deep learning\napproaches for multimodal odometry estimation and localization have gained\ntraction, they rarely focus on the issue of robust sensor fusion - a necessary\nconsideration to deal with noisy or incomplete sensor observations in the real\nworld. Moreover, current deep odometry models also suffer from a lack of\ninterpretability. To this extent, we propose SelectFusion, an end-to-end\nselective sensor fusion module which can be applied to useful pairs of sensor\nmodalities such as monocular images and inertial measurements, depth images and\nLIDAR point clouds. During prediction, the network is able to assess the\nreliability of the latent features from different sensor modalities and\nestimate both trajectory at scale and global pose. In particular, we propose\ntwo fusion modules based on different attention strategies: deterministic soft\nfusion and stochastic hard fusion, and we offer a comprehensive study of the\nnew strategies compared to trivial direct fusion. We evaluate all fusion\nstrategies in both ideal conditions and on progressively degraded datasets that\npresent occlusions, noisy and missing data and time misalignment between\nsensors, and we investigate the effectiveness of the different fusion\nstrategies in attending the most reliable features, which in itself, provides\ninsights into the operation of the various models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 20:25:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Chen", "Changhao", ""], ["Rosa", "Stefano", ""], ["Lu", "Chris Xiaoxuan", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "1912.13080", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Luca Soldaini, Nazli Goharian", "title": "Teaching a New Dog Old Tricks: Resurrecting Multilingual Retrieval Using\n  Zero-shot Learning", "comments": "ECIR 2020 (short)", "journal-ref": null, "doi": "10.1007/978-3-030-45442-5_31", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While billions of non-English speaking users rely on search engines every\nday, the problem of ad-hoc information retrieval is rarely studied for\nnon-English languages. This is primarily due to a lack of data set that are\nsuitable to train ranking algorithms. In this paper, we tackle the lack of data\nby leveraging pre-trained multilingual language models to transfer a retrieval\nsystem trained on English collections to non-English queries and documents. Our\nmodel is evaluated in a zero-shot setting, meaning that we use them to predict\nrelevance scores for query-document pairs in languages never seen during\ntraining. Our results show that the proposed approach can significantly\noutperform unsupervised retrieval techniques for Arabic, Chinese Mandarin, and\nSpanish. We also show that augmenting the English training collection with some\nexamples from the target language can sometimes improve performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 20:46:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["MacAvaney", "Sean", ""], ["Soldaini", "Luca", ""], ["Goharian", "Nazli", ""]]}, {"id": "1912.13088", "submitter": "Peng Liao", "authors": "Peng Liao, Predrag Klasnja, Susan Murphy", "title": "Off-Policy Estimation of Long-Term Average Outcomes with Applications to\n  Mobile Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent advancements in wearables and sensing technology, health\nscientists are increasingly developing mobile health (mHealth) interventions.\nIn mHealth interventions, mobile devices are used to deliver treatment to\nindividuals as they go about their daily lives. These treatments are generally\ndesigned to impact a near time, proximal outcome such as stress or physical\nactivity. The mHealth intervention policies, often called just-in-time adaptive\ninterventions, are decision rules that map an individual's current state (e.g.,\nindividual's past behaviors as well as current observations of time, location,\nsocial activity, stress and urges to smoke) to a particular treatment at each\nof many time points. The vast majority of current mHealth interventions deploy\nexpert-derived policies. In this paper, we provide an approach for conducting\ninference about the performance of one or more such policies using historical\ndata collected under a possibly different policy. Our measure of performance is\nthe average of proximal outcomes over a long time period should the particular\nmHealth policy be followed. We provide an estimator as well as confidence\nintervals. This work is motivated by HeartSteps, an mHealth physical activity\nintervention.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 21:22:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:41:48 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 18:00:48 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Murphy", "Susan", ""]]}, {"id": "1912.13091", "submitter": "Chong You", "authors": "Daniel P. Robinson and Rene Vidal and Chong You", "title": "Basis Pursuit and Orthogonal Matching Pursuit for Subspace-preserving\n  Recovery: Theoretical Analysis", "comments": "31 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an overcomplete dictionary $A$ and a signal $b = Ac^*$ for some sparse\nvector $c^*$ whose nonzero entries correspond to linearly independent columns\nof $A$, classical sparse signal recovery theory considers the problem of\nwhether $c^*$ can be recovered as the unique sparsest solution to $b = A c$. It\nis now well-understood that such recovery is possible by practical algorithms\nwhen the dictionary $A$ is incoherent or restricted isometric. In this paper,\nwe consider the more general case where $b$ lies in a subspace $\\mathcal{S}_0$\nspanned by a subset of linearly dependent columns of $A$, and the remaining\ncolumns are outside of the subspace. In this case, the sparsest representation\nmay not be unique, and the dictionary may not be incoherent or restricted\nisometric. The goal is to have the representation $c$ correctly identify the\nsubspace, i.e. the nonzero entries of $c$ should correspond to columns of $A$\nthat are in the subspace $\\mathcal{S}_0$. Such a representation $c$ is called\nsubspace-preserving, a key concept that has found important applications for\nlearning low-dimensional structures in high-dimensional data. We present\nvarious geometric conditions that guarantee subspace-preserving recovery. Among\nthem, the major results are characterized by the covering radius and the\nangular distance, which capture the distribution of points in the subspace and\nthe similarity between points in the subspace and points outside the subspace,\nrespectively. Importantly, these conditions do not require the dictionary to be\nincoherent or restricted isometric. By establishing that the\nsubspace-preserving recovery problem and the classical sparse signal recovery\nproblem are equivalent under common assumptions on the latter, we show that\nseveral of our proposed conditions are generalizations of some well-known\nconditions in the sparse signal recovery literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 21:31:15 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Robinson", "Daniel P.", ""], ["Vidal", "Rene", ""], ["You", "Chong", ""]]}, {"id": "1912.13106", "submitter": "Xiaotong Liu", "authors": "Xiaotong Liu, Yingbei Tong, Anbang Xu, Rama Akkiraju", "title": "An Empirical Study of Factors Affecting Language-Independent Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling existing applications and solutions to multiple human languages has\ntraditionally proven to be difficult, mainly due to the language-dependent\nnature of preprocessing and feature engineering techniques employed in\ntraditional approaches. In this work, we empirically investigate the factors\naffecting language-independent models built with multilingual representations,\nincluding task type, language set and data resource. On two most representative\nNLP tasks -- sentence classification and sequence labeling, we show that\nlanguage-independent models can be comparable to or even outperforms the models\ntrained using monolingual data, and they are generally more effective on\nsentence classification. We experiment language-independent models with many\ndifferent languages and show that they are more suitable for typologically\nsimilar languages. We also explore the effects of different data sizes when\ntraining and testing language-independent models, and demonstrate that they are\nnot only suitable for high-resource languages, but also very effective in\nlow-resource languages.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 22:41:57 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Liu", "Xiaotong", ""], ["Tong", "Yingbei", ""], ["Xu", "Anbang", ""], ["Akkiraju", "Rama", ""]]}, {"id": "1912.13107", "submitter": "Jennifer Hobbs", "authors": "Jennifer Hobbs, Matthew Holbrook, Nathan Frank, Long Sha, Patrick\n  Lucey", "title": "Improved Structural Discovery and Representation Learning of Multi-Agent\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central to all machine learning algorithms is data representation. For\nmulti-agent systems, selecting a representation which adequately captures the\ninteractions among agents is challenging due to the latent group structure\nwhich tends to vary depending on context. However, in multi-agent systems with\nstrong group structure, we can simultaneously learn this structure and map a\nset of agents to a consistently ordered representation for further learning. In\nthis paper, we present a dynamic alignment method which provides a robust\nordering of structured multi-agent data enabling representation learning to\noccur in a fraction of the time of previous methods. We demonstrate the value\nof this approach using a large amount of soccer tracking data from a\nprofessional league.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 22:49:55 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hobbs", "Jennifer", ""], ["Holbrook", "Matthew", ""], ["Frank", "Nathan", ""], ["Sha", "Long", ""], ["Lucey", "Patrick", ""]]}, {"id": "1912.13109", "submitter": "Vivek Gupta", "authors": "Vivek Kumar Gupta", "title": "\"Hinglish\" Language -- Modeling a Messy Code-Mixed Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a sharp rise in fluency and users of \"Hinglish\" in linguistically\ndiverse country, India, it has increasingly become important to analyze social\ncontent written in this language in platforms such as Twitter, Reddit,\nFacebook. This project focuses on using deep learning techniques to tackle a\nclassification problem in categorizing social content written in Hindi-English\ninto Abusive, Hate-Inducing and Not offensive categories. We utilize\nbi-directional sequence models with easy text augmentation techniques such as\nsynonym replacement, random insertion, random swap, and random deletion to\nproduce a state of the art classifier that outperforms the previous work done\non analyzing this dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 23:01:28 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gupta", "Vivek Kumar", ""]]}, {"id": "1912.13122", "submitter": "Andres Garcia-Camino", "authors": "Andr\\'es Garc\\'ia-Camino", "title": "Declarative Mechanism Design", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report-no: 01", "categories": "cs.AI cs.LG cs.LO cs.MA cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agentswas Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide sI, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:10:50 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 22:36:52 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 17:19:26 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Garc\u00eda-Camino", "Andr\u00e9s", ""]]}, {"id": "1912.13143", "submitter": "Jack Umenberger", "authors": "Jack Umenberger and Thomas B. Schon", "title": "Optimistic robust linear quadratic dual control", "comments": "Preprint submitted to L4DC 2020. 11 pages. 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Mania et al. has proved that certainty equivalent control\nachieves nearly optimal regret for linear systems with quadratic costs.\nHowever, when parameter uncertainty is large, certainty equivalence cannot be\nrelied upon to stabilize the true, unknown system. In this paper, we present a\ndual control strategy that attempts to combine the performance of certainty\nequivalence, with the practical utility of robustness. The formulation\npreserves structure in the representation of parametric uncertainty, which\nallows the controller to target reduction of uncertainty in the parameters that\n`matter most' for the control task, while robustly stabilizing the uncertain\nsystem. Control synthesis proceeds via convex optimization, and the method is\nillustrated on a numerical example.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 02:02:11 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Umenberger", "Jack", ""], ["Schon", "Thomas B.", ""]]}, {"id": "1912.13149", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Dev Chauhan, Vinod K. Kurmi, Vinay P. Namboodiri", "title": "Revisiting Paraphrase Question Generator using Pairwise Discriminator", "comments": "This work is an extension of our COLING-2018 paper arXiv:1806.00807", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a method for obtaining sentence-level embeddings.\nWhile the problem of securing word-level embeddings is very well studied, we\npropose a novel method for obtaining sentence-level embeddings. This is\nobtained by a simple method in the context of solving the paraphrase generation\ntask. If we use a sequential encoder-decoder model for generating paraphrase,\nwe would like the generated paraphrase to be semantically close to the original\nsentence. One way to ensure this is by adding constraints for true paraphrase\nembeddings to be close and unrelated paraphrase candidate sentence embeddings\nto be far. This is ensured by using a sequential pair-wise discriminator that\nshares weights with the encoder that is trained with a suitable loss function.\nOur loss function penalizes paraphrase sentence embedding distances from being\ntoo large. This loss is used in combination with a sequential encoder-decoder\nnetwork. We also validated our method by evaluating the obtained embeddings for\na sentiment analysis task. The proposed method results in semantic embeddings\nand outperforms the state-of-the-art on the paraphrase generation and sentiment\nanalysis task on standard datasets. These results are also shown to be\nstatistically significant.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 02:46:29 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 14:06:19 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Patro", "Badri N.", ""], ["Chauhan", "Dev", ""], ["Kurmi", "Vinod K.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1912.13151", "submitter": "Mingyuan Zhou", "authors": "Xinjie Fan, Yizhe Zhang, Zhendong Wang, Mingyuan Zhou", "title": "Adaptive Correlated Monte Carlo for Contextual Categorical Sequence\n  Generation", "comments": "ICLR 2020 (updated to fix a typo in Algorithm 1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence generation models are commonly refined with reinforcement learning\nover user-defined metrics. However, high gradient variance hinders the\npractical use of this method. To stabilize this method, we adapt to contextual\ngeneration of categorical sequences a policy gradient estimator, which\nevaluates a set of correlated Monte Carlo (MC) rollouts for variance control.\nDue to the correlation, the number of unique rollouts is random and adaptive to\nmodel uncertainty; those rollouts naturally become baselines for each other,\nand hence are combined to effectively reduce gradient variance. We also\ndemonstrate the use of correlated MC rollouts for binary-tree softmax models,\nwhich reduce the high generation cost in large vocabulary scenarios by\ndecomposing each categorical action into a sequence of binary actions. We\nevaluate our methods on both neural program synthesis and image captioning. The\nproposed methods yield lower gradient variance and consistent improvement over\nrelated baselines.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 03:01:55 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:32:42 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Fan", "Xinjie", ""], ["Zhang", "Yizhe", ""], ["Wang", "Zhendong", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1912.13154", "submitter": "Nicholas Boffi", "authors": "Nicholas M. Boffi, Jean-Jacques E. Slotine", "title": "Implicit regularization and momentum algorithms in nonlinear adaptive\n  control and prediction", "comments": "v6: cosmetic adjustments to figures 4, 5, and 6. v5: final version,\n  accepted for publication in Neural Computation. v4: significant updates,\n  revamped section on dynamics prediction and exploiting structure. v3: new\n  general theorems and extensions to dynamic prediction. 37 pages, 3 figures.\n  v2: significant updates; submission ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stable concurrent learning and control of dynamical systems is the subject of\nadaptive control. Despite being an established field with many practical\napplications and a rich theory, much of the development in adaptive control for\nnonlinear systems revolves around a few key algorithms. By exploiting strong\nconnections between classical adaptive nonlinear control techniques and recent\nprogress in optimization and machine learning, we show that there exists\nconsiderable untapped potential in algorithm development for both adaptive\nnonlinear control and adaptive dynamics prediction. We first introduce\nfirst-order adaptation laws inspired by natural gradient descent and mirror\ndescent. We prove that when there are multiple dynamics consistent with the\ndata, these non-Euclidean adaptation laws implicitly regularize the learned\nmodel. Local geometry imposed during learning thus may be used to select\nparameter vectors - out of the many that will achieve perfect tracking or\nprediction - for desired properties such as sparsity. We apply this result to\nregularized dynamics predictor and observer design, and as concrete examples\nconsider Hamiltonian systems, Lagrangian systems, and recurrent neural\nnetworks. We subsequently develop a variational formalism based on the Bregman\nLagrangian to define adaptation laws with momentum applicable to linearly\nparameterized systems and to nonlinearly parameterized systems satisfying\nmonotonicity or convexity requirements. We show that the Euler Lagrange\nequations for the Bregman Lagrangian lead to natural gradient and mirror\ndescent-like adaptation laws with momentum, and we recover their first-order\nanalogues in the infinite friction limit. We illustrate our analyses with\nsimulations demonstrating our theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 03:13:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:59:10 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 15:28:38 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 14:55:17 GMT"}, {"version": "v5", "created": "Fri, 2 Oct 2020 22:45:50 GMT"}, {"version": "v6", "created": "Thu, 17 Dec 2020 17:51:02 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Boffi", "Nicholas M.", ""], ["Slotine", "Jean-Jacques E.", ""]]}, {"id": "1912.13156", "submitter": "Dingju Zhu", "authors": "Dingju Zhu", "title": "Hiding Information in Big Data based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current approach of information hiding based on deep learning model can\nnot directly use the original data as carriers, which means the approach can\nnot make use of the existing data in big data to hiding information. We\nproposed a novel method of information hiding in big data based on deep\nlearning. Our method uses the existing data in big data as carriers and uses\ndeep learning models to hide and extract secret messages in big data. The data\namount of big data is unlimited and thus the data amount of secret messages\nhided in big data can also be unlimited. Before opponents want to extract\nsecret messages from carriers, they need to find the carriers, however finding\nout the carriers from big data is just like finding out a box from the sea.\nDeep learning models are well known as deep black boxes in which the process\nfrom the input to the output is very complex, and thus the deep learning model\nfor information hiding is almost impossible for opponents to reconstruct. The\nresults also show that our method can hide secret messages safely,\nconveniently, quickly and with no limitation on the data amount.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 03:23:54 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 10:32:24 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhu", "Dingju", ""]]}, {"id": "1912.13161", "submitter": "Ibrahim Gashaw", "authors": "Ibrahim Gashaw and H L Shashirekha", "title": "Amharic-Arabic Neural Machine Translation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many automatic translation works have been addressed between major European\nlanguage pairs, by taking advantage of large scale parallel corpora, but very\nfew research works are conducted on the Amharic-Arabic language pair due to its\nparallel data scarcity. Two Long Short-Term Memory (LSTM) and Gated Recurrent\nUnits (GRU) based Neural Machine Translation (NMT) models are developed using\nAttention-based Encoder-Decoder architecture which is adapted from the\nopen-source OpenNMT system. In order to perform the experiment, a small\nparallel Quranic text corpus is constructed by modifying the existing\nmonolingual Arabic text and its equivalent translation of Amharic language text\ncorpora available on Tanzile. LSTM and GRU based NMT models and Google\nTranslation system are compared and found that LSTM based OpenNMT outperforms\nGRU based OpenNMT and Google Translation system, with a BLEU score of 12%, 11%,\nand 6% respectively.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 15:41:35 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gashaw", "Ibrahim", ""], ["Shashirekha", "H L", ""]]}, {"id": "1912.13163", "submitter": "Stefano Savazzi", "authors": "Stefano Savazzi, Monica Nicoli, Vittorio Rampa", "title": "Federated Learning with Cooperating Devices: A Consensus Approach for\n  Massive IoT Networks", "comments": "This work received support from the CHIST-ERA III Grant RadioSense\n  (Big Data and Process Modelling for the Smart Industry - BDSI). The paper has\n  been accepted for publication in the IEEE Internet of Things Journal. The\n  current arXiv contains an additional Appendix C that describes the database\n  and the Python scripts. Published version:\n  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8950073&isnumber=6702522", "journal-ref": "IEEE Internet of Things Journal, vol. 7, no. 5, pp. 4641-4654, May\n  2020", "doi": "10.1109/JIOT.2020.2964162", "report-no": null, "categories": "eess.SP cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is emerging as a new paradigm to train machine\nlearning models in distributed systems. Rather than sharing, and disclosing,\nthe training dataset with the server, the model parameters (e.g. neural\nnetworks weights and biases) are optimized collectively by large populations of\ninterconnected devices, acting as local learners. FL can be applied to\npower-constrained IoT devices with slow and sporadic connections. In addition,\nit does not need data to be exported to third parties, preserving privacy.\nDespite these benefits, a main limit of existing approaches is the centralized\noptimization which relies on a server for aggregation and fusion of local\nparameters; this has the drawback of a single point of failure and scaling\nissues for increasing network size. The paper proposes a fully distributed (or\nserver-less) learning approach: the proposed FL algorithms leverage the\ncooperation of devices that perform data operations inside the network by\niterating local computations and mutual interactions via consensus-based\nmethods. The approach lays the groundwork for integration of FL within 5G and\nbeyond networks characterized by decentralized connectivity and computing, with\nintelligence distributed over the end-devices. The proposed methodology is\nverified by experimental datasets collected inside an industrial IoT\nenvironment.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 15:16:04 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Savazzi", "Stefano", ""], ["Nicoli", "Monica", ""], ["Rampa", "Vittorio", ""]]}, {"id": "1912.13167", "submitter": "Xueyuan Zhao", "authors": "Xueyuan Zhao and Dario Pompili", "title": "Transform-Domain Classification of Human Cells based on DNA Methylation\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method to classify human cells is presented in this work based on the\ntransform-domain method on DNA methylation data. DNA methylation profile\nvariations are observed in human cells with the progression of disease stages,\nand the proposal is based on this DNA methylation variation to classify normal\nand disease cells including cancer cells. The cancer cell types investigated in\nthis work cover hepatocellular (sample size n = 40), colorectal (n = 44), lung\n(n = 70) and endometrial (n = 87) cancer cells. A new pipeline is proposed\nintegrating the DNA methylation intensity measurements on all the CpG islands\nby the transformation of Walsh-Hadamard Transform (WHT). The study reveals the\nthree-step properties of the DNA methylation transform-domain data and the step\nvalues of association with the cell status. Further assessments have been\ncarried out on the proposed machine learning pipeline to perform classification\nof the normal and cancer tissue cells. A number of machine learning classifiers\nare compared for whole sequence and WHT sequence classification based on public\nWhole-Genome Bisulfite Sequencing (WGBS) DNA methylation datasets. The\nWHT-based method can speed up the computation time by more than one order of\nmagnitude compared with whole original sequence classification, while\nmaintaining comparable classification accuracy by the selected machine learning\nclassifiers. The proposed method has broad applications in expedited disease\nand normal human cell classifications by the epigenome and genome datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 04:18:11 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhao", "Xueyuan", ""], ["Pompili", "Dario", ""]]}, {"id": "1912.13169", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient Decremental Learning Algorithms for Broad Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decremented learning algorithms are required in machine learning, to\nprune redundant nodes and remove obsolete inline training samples. In this\npaper, an efficient decremented learning algorithm to prune redundant nodes is\ndeduced from the incremental learning algorithm 1 proposed in [9] for added\nnodes, and two decremented learning algorithms to remove training samples are\ndeduced from the two incremental learning algorithms proposed in [10] for added\ninputs. The proposed decremented learning algorithm for reduced nodes utilizes\nthe inverse Cholesterol factor of the Herminia matrix in the ridge inverse, to\nupdate the output weights recursively, as the incremental learning algorithm 1\nfor added nodes in [9], while that inverse Cholesterol factor is updated with\nan unitary transformation. The proposed decremented learning algorithm 1 for\nreduced inputs updates the output weights recursively with the inverse of the\nHerminia matrix in the ridge inverse, and updates that inverse recursively, as\nthe incremental learning algorithm 1 for added inputs in [10].\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 04:46:27 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "1912.13179", "submitter": "Shadrokh Samavi", "authors": "Sajjad Abbasi, Mohsen Hajabdollahi, Nader Karimi, Shadrokh Samavi", "title": "Modeling Teacher-Student Techniques in Deep Neural Networks for\n  Knowledge Distillation", "comments": "six pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a new method for transferring knowledge of a\nstructure under training to another one. The typical application of KD is in\nthe form of learning a small model (named as a student) by soft labels produced\nby a complex model (named as a teacher). Due to the novel idea introduced in\nKD, recently, its notion is used in different methods such as compression and\nprocesses that are going to enhance the model accuracy. Although different\ntechniques are proposed in the area of KD, there is a lack of a model to\ngeneralize KD techniques. In this paper, various studies in the scope of KD are\ninvestigated and analyzed to build a general model for KD. All the methods and\ntechniques in KD can be summarized through the proposed model. By utilizing the\nproposed model, different methods in KD are better investigated and explored.\nThe advantages and disadvantages of different approaches in KD can be better\nunderstood and develop a new strategy for KD can be possible. Using the\nproposed model, different KD methods are represented in an abstract view.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 05:32:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Abbasi", "Sajjad", ""], ["Hajabdollahi", "Mohsen", ""], ["Karimi", "Nader", ""], ["Samavi", "Shadrokh", ""]]}, {"id": "1912.13192", "submitter": "Shaoshuai Shi", "authors": "Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang\n  Wang, Hongsheng Li", "title": "PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection", "comments": "Accepted by CVPR 2020. arXiv admin note: substantial text overlap\n  with arXiv:2102.00463", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel and high-performance 3D object detection framework, named\nPointVoxel-RCNN (PV-RCNN), for accurate 3D object detection from point clouds.\nOur proposed method deeply integrates both 3D voxel Convolutional Neural\nNetwork (CNN) and PointNet-based set abstraction to learn more discriminative\npoint cloud features. It takes advantages of efficient learning and\nhigh-quality proposals of the 3D voxel CNN and the flexible receptive fields of\nthe PointNet-based networks. Specifically, the proposed framework summarizes\nthe 3D scene with a 3D voxel CNN into a small set of keypoints via a novel\nvoxel set abstraction module to save follow-up computations and also to encode\nrepresentative scene features. Given the high-quality 3D proposals generated by\nthe voxel CNN, the RoI-grid pooling is proposed to abstract proposal-specific\nfeatures from the keypoints to the RoI-grid points via keypoint set abstraction\nwith multiple receptive fields. Compared with conventional pooling operations,\nthe RoI-grid feature points encode much richer context information for\naccurately estimating object confidences and locations. Extensive experiments\non both the KITTI dataset and the Waymo Open dataset show that our proposed\nPV-RCNN surpasses state-of-the-art 3D detection methods with remarkable margins\nby using only point clouds. Code is available at\nhttps://github.com/open-mmlab/OpenPCDet.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 06:34:10 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 06:37:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Shi", "Shaoshuai", ""], ["Guo", "Chaoxu", ""], ["Jiang", "Li", ""], ["Wang", "Zhe", ""], ["Shi", "Jianping", ""], ["Wang", "Xiaogang", ""], ["Li", "Hongsheng", ""]]}, {"id": "1912.13199", "submitter": "Seyed Vahid Mirnezami", "authors": "Ali HamidiSepehr, Seyed Vahid Mirnezami, Jason K. Ward", "title": "Comparison of object detection methods for crop damage assessment using\n  deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Severe weather events can cause large financial losses to farmers. Detailed\ninformation on the location and severity of damage will assist farmers,\ninsurance companies, and disaster response agencies in making wise post-damage\ndecisions. The goal of this study was a proof-of-concept to detect damaged crop\nareas from aerial imagery using computer vision and deep learning techniques. A\nspecific objective was to compare existing object detection algorithms to\ndetermine which was best suited for crop damage detection. Two modes of crop\ndamage common in maize (corn) production were simulated: stalk lodging at the\nlowest ear and stalk lodging at ground level. Simulated damage was used to\ncreate a training and analysis data set. An unmanned aerial system (UAS)\nequipped with a RGB camera was used for image acquisition. Three popular object\ndetectors (Faster R-CNN, YOLOv2, and RetinaNet) were assessed for their ability\nto detect damaged regions in a field. Average precision was used to compare\nobject detectors. YOLOv2 and RetinaNet were able to detect crop damage across\nmultiple late-season growth stages. Faster R-CNN was not successful as the\nother two advanced detectors. Detecting crop damage at later growth stages was\nmore difficult for all tested object detectors. Weed pressure in simulated\ndamage plots and increased target density added additional complexity.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 06:54:48 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 03:50:21 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 00:32:32 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["HamidiSepehr", "Ali", ""], ["Mirnezami", "Seyed Vahid", ""], ["Ward", "Jason K.", ""]]}, {"id": "1912.13204", "submitter": "Suchet Sapre", "authors": "Suchet Sapre, Pouyan Ahmadi and Khondkar Islam", "title": "A Robust Comparison of the KDDCup99 and NSL-KDD IoT Network Intrusion\n  Detection Datasets Through Various Machine Learning Algorithms", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, as intrusion attacks on IoT networks have grown\nexponentially, there is an immediate need for sophisticated intrusion detection\nsystems (IDSs). A vast majority of current IDSs are data-driven, which means\nthat one of the most important aspects of this area of research is the quality\nof the data acquired from IoT network traffic. Two of the most cited intrusion\ndetection datasets are the KDDCup99 and the NSL-KDD. The main goal of our\nproject was to conduct a robust comparison of both datasets by evaluating the\nperformance of various Machine Learning (ML) classifiers trained on them with a\nlarger set of classification metrics than previous researchers. From our\nresearch, we were able to conclude that the NSL-KDD dataset is of a higher\nquality than the KDDCup99 dataset as the classifiers trained on it were on\naverage 20.18% less accurate. This is because the classifiers trained on the\nKDDCup99 dataset exhibited a bias towards the redundancies within it, allowing\nthem to achieve higher accuracies.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 07:36:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Sapre", "Suchet", ""], ["Ahmadi", "Pouyan", ""], ["Islam", "Khondkar", ""]]}, {"id": "1912.13213", "submitter": "Francesco Orabona", "authors": "Francesco Orabona", "title": "A Modern Introduction to Online Learning", "comments": "Fixed more typos, added more history bits, added local norms bounds\n  for OMD and FTRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this monograph, I introduce the basic concepts of Online Learning through\na modern view of Online Convex Optimization. Here, online learning refers to\nthe framework of regret minimization under worst-case assumptions. I present\nfirst-order and second-order algorithms for online learning with convex losses,\nin Euclidean and non-Euclidean settings. All the algorithms are clearly\npresented as instantiation of Online Mirror Descent or\nFollow-The-Regularized-Leader and their variants. Particular attention is given\nto the issue of tuning the parameters of the algorithms and learning in\nunbounded domains, through adaptive and parameter-free online learning\nalgorithms. Non-convex losses are dealt through convex surrogate losses and\nthrough randomization. The bandit setting is also briefly discussed, touching\non the problem of adversarial and stochastic multi-armed bandits. These notes\ndo not require prior knowledge of convex analysis and all the required\nmathematical tools are rigorously explained. Moreover, all the proofs have been\ncarefully chosen to be as simple and as short as possible.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 08:16:31 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 19:03:07 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 22:14:47 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Orabona", "Francesco", ""]]}, {"id": "1912.13226", "submitter": "Yuntao Du", "authors": "Yuntao Du, Zhiwen Tan, Qian Chen, Yi Zhang, Chongjun Wang", "title": "Homogeneous Online Transfer Learning with Online Distribution\n  Discrepancy Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": "ECAI 2020", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Transfer learning has been demonstrated to be successful and essential in\ndiverse applications, which transfers knowledge from related but different\nsource domains to the target domain. Online transfer learning(OTL) is a more\nchallenging problem where the target data arrive in an online manner. Most OTL\nmethods combine source classifier and target classifier directly by assigning a\nweight to each classifier, and adjust the weights constantly. However, these\nmethods pay little attention to reducing the distribution discrepancy between\ndomains. In this paper, we propose a novel online transfer learning method\nwhich seeks to find a new feature representation, so that the marginal\ndistribution and conditional distribution discrepancy can be online reduced\nsimultaneously. We focus on online transfer learning with multiple source\ndomains and use the Hedge strategy to leverage knowledge from source domains.\nWe analyze the theoretical properties of the proposed algorithm and provide an\nupper mistake bound. Comprehensive experiments on two real-world datasets show\nthat our method outperforms state-of-the-art methods by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 08:58:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Du", "Yuntao", ""], ["Tan", "Zhiwen", ""], ["Chen", "Qian", ""], ["Zhang", "Yi", ""], ["Wang", "Chongjun", ""]]}, {"id": "1912.13230", "submitter": "Vahid Noroozi", "authors": "Vahid Noroozi, Sara Bahaadini, Samira Sheikhi, Nooshin Mojab, Philip\n  S. Yu", "title": "Leveraging Semi-Supervised Learning for Fairness using Neural Networks", "comments": "6 pages, 5 figures, accepted to ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing concern about the fairness of decision-making\nsystems based on machine learning. The shortage of labeled data has been always\na challenging problem facing machine learning based systems. In such scenarios,\nsemi-supervised learning has shown to be an effective way of exploiting\nunlabeled data to improve upon the performance of model. Notably, unlabeled\ndata do not contain label information which itself can be a significant source\nof bias in training machine learning systems. This inspired us to tackle the\nchallenge of fairness by formulating the problem in a semi-supervised\nframework. In this paper, we propose a semi-supervised algorithm using neural\nnetworks benefiting from unlabeled data to not just improve the performance but\nalso improve the fairness of the decision-making process. The proposed model,\ncalled SSFair, exploits the information in the unlabeled data to mitigate the\nbias in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:11:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Noroozi", "Vahid", ""], ["Bahaadini", "Sara", ""], ["Sheikhi", "Samira", ""], ["Mojab", "Nooshin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1912.13238", "submitter": "Alper Atamturk", "authors": "Alper Atamturk and Vishnu Narayanan", "title": "Submodular Function Minimization and Polarity", "comments": null, "journal-ref": null, "doi": null, "report-no": "BCOL 19.02, IEOR, UC Berkeley", "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using polarity, we give an outer polyhedral approximation for the epigraph of\nset functions. For a submodular function, we prove that the corresponding polar\nrelaxation is exact; hence, it is equivalent to the Lov\\'asz extension. The\npolar approach provides an alternative proof for the convex hull description of\nthe epigraph of a submodular function. Computational experiments show that the\ninequalities from outer approximations can be effective as cutting planes for\nsolving submodular as well as non-submodular set function minimization\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:33:10 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 06:08:31 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 06:41:30 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Atamturk", "Alper", ""], ["Narayanan", "Vishnu", ""]]}, {"id": "1912.13243", "submitter": "Pavol Bielik", "authors": "Philippe Schlattner, Pavol Bielik, Martin Vechev", "title": "Learning to Infer User Interface Attributes from Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a new domain of learning to infer user interface attributes that\nhelps developers automate the process of user interface implementation.\nConcretely, given an input image created by a designer, we learn to infer its\nimplementation which when rendered, looks visually the same as the input image.\nTo achieve this, we take a black box rendering engine and a set of attributes\nit supports (e.g., colors, border radius, shadow or text properties), use it to\ngenerate a suitable synthetic training dataset, and then train specialized\nneural models to predict each of the attribute values. To improve pixel-level\naccuracy, we additionally use imitation learning to train a neural policy that\nrefines the predicted attribute values by learning to compute the similarity of\nthe original and rendered images in their attribute space, rather than based on\nthe difference of pixel values. We instantiate our approach to the task of\ninferring Android Button attribute values and achieve 92.5% accuracy on a\ndataset consisting of real-world Google Play Store applications.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:45:59 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Schlattner", "Philippe", ""], ["Bielik", "Pavol", ""], ["Vechev", "Martin", ""]]}, {"id": "1912.13256", "submitter": "Lanfei Wang", "authors": "Lanfei Wang and Lingxi Xie and Tianyi Zhang and Jun Guo and Qi Tian", "title": "Scalable NAS with Factorizable Architectural Parameters", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is an emerging topic in machine learning and\ncomputer vision. The fundamental ideology of NAS is using an automatic\nmechanism to replace manual designs for exploring powerful network\narchitectures. One of the key factors of NAS is to scale-up the search space,\ne.g., increasing the number of operators, so that more possibilities are\ncovered, but existing search algorithms often get lost in a large number of\noperators. For avoiding huge computing and competition among similar operators\nin the same pool, this paper presents a scalable algorithm by factorizing a\nlarge set of candidate operators into smaller subspaces. As a practical\nexample, this allows us to search for effective activation functions along with\nthe regular operators including convolution, pooling, skip-connect, etc. With a\nsmall increase in search costs and no extra costs in re-training, we find\ninteresting architectures that were not explored before, and achieve\nstate-of-the-art performance on CIFAR10 and ImageNet, two standard image\nclassification benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 10:26:56 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 18:47:42 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Wang", "Lanfei", ""], ["Xie", "Lingxi", ""], ["Zhang", "Tianyi", ""], ["Guo", "Jun", ""], ["Tian", "Qi", ""]]}, {"id": "1912.13258", "submitter": "Yiqiang Han", "authors": "Yuan Gao, Yiqiang Han", "title": "Automated Testing for Deep Learning Systems with Differential Behavior\n  Criteria", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we conducted a study on building an automated testing system\nfor deep learning systems based on differential behavior criteria. The\nautomated testing goals were achieved by jointly optimizing two objective\nfunctions: maximizing differential behaviors from models under testing and\nmaximizing neuron coverage. By observing differential behaviors from three\npre-trained models during each testing iteration, the input image that\ntriggered erroneous feedback was registered as a corner-case. The generated\ncorner-cases can be used to examine the robustness of DNNs and consequently\nimprove model accuracy. A project called DeepXplore was also used as a baseline\nmodel. After we fully implemented and optimized the baseline system, we\nexplored its application as an augmenting training dataset with newly generated\ncorner cases. With the GTRSB dataset, by retraining the model based on\nautomated generated corner cases, the accuracy of three generic models\nincreased by 259.2%, 53.6%, and 58.3%, respectively. Further, to extend the\ncapability of automated testing, we explored other approaches based on\ndifferential behavior criteria to generate photo-realistic images for deep\nlearning systems. One approach was to apply various transformations to the seed\nimages for the deep learning framework. The other approach was to utilize the\nGenerative Adversarial Networks (GAN) technique, which was implemented on MNIST\nand Driving datasets. The style transferring capability has been observed very\neffective in adding additional visual effects, replacing image elements, and\nstyle-shifting (virtual image to real images). The GAN-based testing sample\ngeneration system was shown to be the next frontier for automated testing for\ndeep learning systems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 10:31:55 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Gao", "Yuan", ""], ["Han", "Yiqiang", ""]]}, {"id": "1912.13263", "submitter": "Gianluca Baldassarre PhD", "authors": "Gianluca Baldassarre", "title": "Intrinsic motivations and open-ended learning", "comments": "24 pages, 2 figures, 2 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest and literature on intrinsic motivations and\nopen-ended learning in both cognitive robotics and machine learning on one\nside, and in psychology and neuroscience on the other. This paper aims to\nreview some relevant contributions from the two literature threads and to draw\nlinks between them. To this purpose, the paper starts by defining intrinsic\nmotivations and by presenting a computationally-driven theoretical taxonomy of\ntheir different types. Then it presents relevant contributions from the\npsychological and neuroscientific literature related to intrinsic motivations,\ninterpreting them based on the grid, and elucidates the mechanisms and\nfunctions they play in animals and humans. Endowed with such concepts and their\nbiological underpinnings, the paper next presents a selection of models from\ncognitive robotics and machine learning that computationally operationalise the\nconcepts of intrinsic motivations and links them to biology concepts. The\ncontribution finally presents some of the open challenges of the field from\nboth the psychological/neuroscientific and computational perspectives.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 10:56:02 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Baldassarre", "Gianluca", ""]]}, {"id": "1912.13283", "submitter": "Alon Talmor", "authors": "Alon Talmor, Yanai Elazar, Yoav Goldberg, Jonathan Berant", "title": "oLMpics -- On what Language Model Pre-training Captures", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of pre-trained language models (LMs) has spurred widespread\ninterest in the language capabilities that they possess. However, efforts to\nunderstand whether LM representations are useful for symbolic reasoning tasks\nhave been limited and scattered. In this work, we propose eight reasoning\ntasks, which conceptually require operations such as comparison, conjunction,\nand composition. A fundamental challenge is to understand whether the\nperformance of a LM on a task should be attributed to the pre-trained\nrepresentations or to the process of fine-tuning on the task data. To address\nthis, we propose an evaluation protocol that includes both zero-shot evaluation\n(no fine-tuning), as well as comparing the learning curve of a fine-tuned LM to\nthe learning curve of multiple controls, which paints a rich picture of the LM\ncapabilities. Our main findings are that: (a) different LMs exhibit\nqualitatively different reasoning abilities, e.g., RoBERTa succeeds in\nreasoning tasks where BERT fails completely; (b) LMs do not reason in an\nabstract manner and are context-dependent, e.g., while RoBERTa can compare\nages, it can do so only when the ages are in the typical range of human ages;\n(c) On half of our reasoning tasks all models fail completely. Our findings and\ninfrastructure can help future work on designing new datasets, models and\nobjective functions for pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 12:11:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 08:24:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Talmor", "Alon", ""], ["Elazar", "Yanai", ""], ["Goldberg", "Yoav", ""], ["Berant", "Jonathan", ""]]}, {"id": "1912.13305", "submitter": "Xiaopeng Luo Dr.", "authors": "Xiaopeng Luo and Xin Xu", "title": "Stochastic gradient-free descents", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose stochastic gradient-free methods and accelerated\nmethods with momentum for solving stochastic optimization problems. All these\nmethods rely on stochastic directions rather than stochastic gradients. We\nanalyze the convergence behavior of these methods under the mean-variance\nframework, and also provide a theoretical analysis about the inclusion of\nmomentum in stochastic settings which reveals that the momentum term we used\nadds a deviation of order $\\mathcal{O}(1/k)$ but controls the variance at the\norder $\\mathcal{O}(1/k)$ for the $k$th iteration. So it is shown that, when\nemploying a decaying stepsize $\\alpha_k=\\mathcal{O}(1/k)$, the stochastic\ngradient-free methods can still maintain the sublinear convergence rate\n$\\mathcal{O}(1/k)$ and the accelerated methods with momentum can achieve a\nconvergence rate $\\mathcal{O}(1/k^2)$ in probability for the strongly convex\nobjectives with Lipschitz gradients; and all these methods converge to a\nsolution with a zero expected gradient norm when the objective function is\nnonconvex, twice differentiable and bounded below.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 13:56:36 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 14:20:50 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 10:36:52 GMT"}, {"version": "v4", "created": "Sun, 12 Jan 2020 06:33:31 GMT"}, {"version": "v5", "created": "Tue, 14 Jan 2020 10:31:56 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Luo", "Xiaopeng", ""], ["Xu", "Xin", ""]]}, {"id": "1912.13309", "submitter": "Naci Saldi", "authors": "Berkay Anahtarc{\\i}, Can Deha Kar{\\i}ks{\\i}z, and Naci Saldi", "title": "Learning in Discounted-cost and Average-cost Mean-field Games", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning approximate Nash equilibria for discrete-time mean-field\ngames with nonlinear stochastic state dynamics subject to both average and\ndiscounted costs. To this end, we introduce a mean-field equilibrium (MFE)\noperator, whose fixed point is a mean-field equilibrium (i.e. equilibrium in\nthe infinite population limit). We first prove that this operator is a\ncontraction, and propose a learning algorithm to compute an approximate\nmean-field equilibrium by approximating the MFE operator with a random one.\nMoreover, using the contraction property of the MFE operator, we establish the\nerror analysis of the proposed learning algorithm. We then show that the\nlearned mean-field equilibrium constitutes an approximate Nash equilibrium for\nfinite-agent games.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 14:05:49 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:51:54 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Anahtarc\u0131", "Berkay", ""], ["Kar\u0131ks\u0131z", "Can Deha", ""], ["Saldi", "Naci", ""]]}, {"id": "1912.13332", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie, Manas Gaur, Sam Anzaroot, William Groves, Ke Zhang,\n  Alejandro Jaimes", "title": "Unsupervised Detection of Sub-events in Large Scale Disasters", "comments": "AAAI-20 Social Impact Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media plays a major role during and after major natural disasters\n(e.g., hurricanes, large-scale fires, etc.), as people ``on the ground'' post\nuseful information on what is actually happening. Given the large amounts of\nposts, a major challenge is identifying the information that is useful and\nactionable. Emergency responders are largely interested in finding out what\nevents are taking place so they can properly plan and deploy resources. In this\npaper we address the problem of automatically identifying important sub-events\n(within a large-scale emergency ``event'', such as a hurricane). In particular,\nwe present a novel, unsupervised learning framework to detect sub-events in\nTweets for retrospective crisis analysis. We first extract noun-verb pairs and\nphrases from raw tweets as sub-event candidates. Then, we learn a semantic\nembedding of extracted noun-verb pairs and phrases, and rank them against a\ncrisis-specific ontology. We filter out noisy and irrelevant information then\ncluster the noun-verb pairs and phrases so that the top-ranked ones describe\nthe most important sub-events. Through quantitative experiments on two large\ncrisis data sets (Hurricane Harvey and the 2015 Nepal Earthquake), we\ndemonstrate the effectiveness of our approach over the state-of-the-art. Our\nqualitative evaluation shows better performance compared to our baseline.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 22:10:16 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Arachie", "Chidubem", ""], ["Gaur", "Manas", ""], ["Anzaroot", "Sam", ""], ["Groves", "William", ""], ["Zhang", "Ke", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "1912.13335", "submitter": "Muhammad Usman", "authors": "Muhammad Usman, Byoung-Dai Lee, Shi Sub Byon, Sung Hyun Kim, and\n  Byung-ilLee", "title": "Volumetric Lung Nodule Segmentation using Adaptive ROI with Multi-View\n  Residual Learning", "comments": "The manuscript is currently under review and copyright shall be\n  transferred to the publisher upon acceptance", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate quantification of pulmonary nodules can greatly assist the early\ndiagnosis of lung cancer, which can enhance patient survival possibilities. A\nnumber of nodule segmentation techniques have been proposed, however, all of\nthe existing techniques rely on radiologist 3-D volume of interest (VOI) input\nor use the constant region of interest (ROI) and only investigate the presence\nof nodule voxels within the given VOI. Such approaches restrain the solutions\nto investigate the nodule presence outside the given VOI and also include the\nredundant structures into VOI, which may lead to inaccurate nodule\nsegmentation. In this work, a novel semi-automated approach for 3-D\nsegmentation of nodule in volumetric computerized tomography (CT) lung scans\nhas been proposed. The proposed technique can be segregated into two stages, at\nthe first stage, it takes a 2-D ROI containing the nodule as input and it\nperforms patch-wise investigation along the axial axis with a novel adaptive\nROI strategy. The adaptive ROI algorithm enables the solution to dynamically\nselect the ROI for the surrounding slices to investigate the presence of nodule\nusing deep residual U-Net architecture. The first stage provides the initial\nestimation of nodule which is further utilized to extract the VOI. At the\nsecond stage, the extracted VOI is further investigated along the coronal and\nsagittal axis with two different networks and finally, all the estimated masks\nare fed into the consensus module to produce the final volumetric segmentation\nof nodule. The proposed approach has been rigorously evaluated on the LIDC\ndataset, which is the largest publicly available dataset. The result suggests\nthat the approach is significantly robust and accurate as compared to the\nprevious state of the art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 15:03:18 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 10:57:24 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Usman", "Muhammad", ""], ["Lee", "Byoung-Dai", ""], ["Byon", "Shi Sub", ""], ["Kim", "Sung Hyun", ""], ["Byung-ilLee", "", ""]]}, {"id": "1912.13357", "submitter": "Achraf Bahamou", "authors": "Achraf Bahamou, Donald Goldfarb", "title": "A Dynamic Sampling Adaptive-SGD Method for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a stochastic optimization method for minimizing loss functions,\nexpressed as an expected value, that adaptively controls the batch size used in\nthe computation of gradient approximations and the step size used to move along\nsuch directions, eliminating the need for the user to tune the learning rate.\nThe proposed method exploits local curvature information and ensures that\nsearch directions are descent directions with high probability using an\nacute-angle test and can be used as a method that has a global linear rate of\nconvergence on self-concordant functions with high probability. Numerical\nexperiments show that this method is able to choose the best learning rates and\ncompares favorably to fine-tuned SGD for training logistic regression and DNNs.\nWe also propose an adaptive version of ADAM that eliminates the need to tune\nthe base learning rate and compares favorably to fine-tuned ADAM on training\nDNNs. In our DNN experiments, we rarely encountered negative curvature at the\ncurrent point along the step direction in DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 15:36:44 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 00:39:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Bahamou", "Achraf", ""], ["Goldfarb", "Donald", ""]]}, {"id": "1912.13361", "submitter": "Ali Lotfi Rezaabad", "authors": "Ali Lotfi Rezaabad and Sriram Vishwanath", "title": "Learning Representations by Maximizing Mutual Information in Variational\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) have ushered in a new era of unsupervised\nlearning methods for complex distributions. Although these techniques are\nelegant in their approach, they are typically not useful for representation\nlearning. In this work, we propose a simple yet powerful class of VAEs that\nsimultaneously result in meaningful learned representations. Our solution is to\ncombine traditional VAEs with mutual information maximization, with the goal to\nenhance amortized inference in VAEs using Information Theoretic techniques. We\ncall this approach InfoMax-VAE, and such an approach can significantly boost\nthe quality of learned high-level representations. We realize this through the\nexplicit maximization of information measures associated with the\nrepresentation. Using extensive experiments on varied datasets and setups, we\nshow that InfoMax-VAE outperforms contemporary popular approaches, including\nInfo-VAE and $\\beta$-VAE.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 17:44:09 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 05:42:39 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Rezaabad", "Ali Lotfi", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1912.13362", "submitter": "Behnam Kiani Kalejahi", "authors": "Umid Suleymanov, Behnam Kiani Kalejahi, Elkhan Amrahov, Rashid\n  Badirkhanli", "title": "Text Classification for Azerbaijani Language Using Machine Learning and\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text classification systems will help to solve the text clustering problem in\nthe Azerbaijani language. There are some text-classification applications for\nforeign languages, but we tried to build a newly developed system to solve this\nproblem for the Azerbaijani language. Firstly, we tried to find out potential\npractice areas. The system will be useful in a lot of areas. It will be mostly\nused in news feed categorization. News websites can automatically categorize\nnews into classes such as sports, business, education, science, etc. The system\nis also used in sentiment analysis for product reviews. For example, the\ncompany shares a photo of a new product on Facebook and the company receives a\nthousand comments for new products. The systems classify the comments into\ncategories like positive or negative. The system can also be applied in\nrecommended systems, spam filtering, etc. Various machine learning techniques\nsuch as Naive Bayes, SVM, Decision Trees have been devised to solve the text\nclassification problem in Azerbaijani language.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 08:38:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Suleymanov", "Umid", ""], ["Kalejahi", "Behnam Kiani", ""], ["Amrahov", "Elkhan", ""], ["Badirkhanli", "Rashid", ""]]}, {"id": "1912.13366", "submitter": "Seungcheol Park", "authors": "Seungcheol Park, Huiwen Xu, Taehun Kim, Inhwan Hwang, Kyung-Jun Kim\n  and U Kang", "title": "Fast and Accurate Transferability Measurement for Heterogeneous\n  Multivariate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of heterogeneous source datasets with their classifiers, how can\nwe quickly find the most useful source dataset for a specific target task? We\naddress the problem of measuring transferability between source and target\ndatasets, where the source and the target have different feature spaces and\ndistributions. We propose Transmeter, a fast and accurate method to estimate\nthe transferability of two heterogeneous multivariate datasets. We address\nthree challenges in measuring transferability between two heterogeneous\nmultivariate datasets: reducing time, minimizing domain gap, and extracting\nmeaningful homogeneous representations. To overcome the above issues, we\nutilize a pre-trained source model, an adversarial network, and an\nencoder-decoder architecture. Extensive experiments on heterogeneous\nmultivariate datasets show that Transmeter gives the most accurate\ntransferability measurement with up to 10.3 times faster performance than its\ncompetitor. We also show that selecting the best source data with Transmeter\nfollowed by a full transfer leads to the best transfer accuracy and the fastest\nrunning time.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:42:17 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 09:25:12 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Park", "Seungcheol", ""], ["Xu", "Huiwen", ""], ["Kim", "Taehun", ""], ["Hwang", "Inhwan", ""], ["Kim", "Kyung-Jun", ""], ["Kang", "U", ""]]}, {"id": "1912.13377", "submitter": "Alexey Drutsa", "authors": "Alexey Drutsa", "title": "Finite-State Extreme Effect Variable", "comments": "15 pages; 2 figures; 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize to the finite-state case the notion of the extreme effect\nvariable $Y$ that accumulates all the effect of a variant variable $V$ observed\nin changes of another variable $X$. We conduct theoretical analysis and turn\nthe problem of finding of an effect variable into a problem of a simultaneous\ndecomposition of a set of distributions. The states of the extreme effect\nvariable, on the one hand, are minimally affected by the variant variable $V$\nand, on the other hand, are extremely different with respect to the observable\nvariable $X$. We apply our technique to online evaluation of a web search\nengine through A/B testing and show its utility.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 21:40:26 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Drutsa", "Alexey", ""]]}, {"id": "1912.13382", "submitter": "Jose Del Aguila Ferrandis Mr", "authors": "Jos\\'e del \\'Aguila Ferrandis, Michael Triantafyllou, Chryssostomos\n  Chryssostomidis, George Karniadakis", "title": "Learning functionals via LSTM neural networks for predicting vessel\n  dynamics in extreme sea states", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting motions of vessels in extreme sea states represents one of the\nmost challenging problems in naval hydrodynamics. It involves computing complex\nnonlinear wave-body interactions, hence taxing heavily computational resources.\nHere, we put forward a new simulation paradigm by training recurrent type\nneural networks (RNNs) that take as input the stochastic wave elevation at a\ncertain sea state and output the main vessel motions, e.g., pitch, heave and\nroll. We first compare the performance of standard RNNs versus GRU and LSTM\nneural networks (NNs) and show that LSTM NNs lead to the best performance. We\nthen examine the testing error of two representative vessels, a catamaran in\nsea state 1 and a battleship in sea state 8. We demonstrate that good accuracy\nis achieved for both cases in predicting the vessel motions for unseen wave\nelevations. We train the NNs with expensive CFD simulations offline, but upon\ntraining, the prediction of the vessel dynamics online can be obtained at a\nfraction of a second. This work is motivated by the universal approximation\ntheorem for functionals [1], and it is the first implementation of such theory\nto realistic engineering problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 18:39:12 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Ferrandis", "Jos\u00e9 del \u00c1guila", ""], ["Triantafyllou", "Michael", ""], ["Chryssostomidis", "Chryssostomos", ""], ["Karniadakis", "George", ""]]}, {"id": "1912.13384", "submitter": "Kasra Babaei", "authors": "Kasra Babaei, ZhiYuan Chen, Tomas Maul", "title": "Data Augmentation by AutoEncoders for Unsupervised Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an autoencoder (AE) that is used for improving the\nperformance of once-class classifiers for the purpose of detecting anomalies.\nTraditional one-class classifiers (OCCs) perform poorly under certain\nconditions such as high-dimensionality and sparsity. Also, the size of the\ntraining set plays an important role on the performance of one-class\nclassifiers. Autoencoders have been widely used for obtaining useful latent\nvariables from high-dimensional datasets. In the proposed approach, the AE is\ncapable of deriving meaningful features from high-dimensional datasets while\ndoing data augmentation at the same time. The augmented data is used for\ntraining the OCC algorithms. The experimental results show that the proposed\napproach enhance the performance of OCC algorithms and also outperforms other\nwell-known approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 09:30:54 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Babaei", "Kasra", ""], ["Chen", "ZhiYuan", ""], ["Maul", "Tomas", ""]]}, {"id": "1912.13387", "submitter": "Kasra Babaei", "authors": "Kasra Babaei, Zhi Yuan Chen, Tomas Maul", "title": "AEGR: A simple approach to gradient reversal in autoencoders for network\n  anomaly detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is referred to as a process in which the aim is to detect\ndata points that follow a different pattern from the majority of data points.\nAnomaly detection methods suffer from several well-known challenges that hinder\ntheir performance such as high dimensionality. Autoencoders are unsupervised\nneural networks that have been used for the purpose of reducing dimensionality\nand also detecting network anomalies in large datasets. The performance of\nautoencoders debilitates when the training set contains noise and anomalies. In\nthis paper, a new gradient-reversal method is proposed to overcome the\ninfluence of anomalies on the training phase for the purpose of detecting\nnetwork anomalies. The method is different from other approaches as it does not\nrequire an anomaly-free training set and is based on reconstruction error. Once\nlatent variables are extracted from the network, Local Outlier Factor is used\nto separate normal data points from anomalies. A simple pruning approach and\ndata augmentation is also added to further improve performance. The\nexperimental results show that the proposed model can outperform other\nwell-know approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 09:24:02 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 22:28:56 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Babaei", "Kasra", ""], ["Chen", "Zhi Yuan", ""], ["Maul", "Tomas", ""]]}, {"id": "1912.13405", "submitter": "Jesse Read", "authors": "Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank", "title": "Classifier Chains: A Review and Perspectives", "comments": null, "journal-ref": "Journal of Artificial Intelligence Research 70 (2021) 683-718", "doi": "10.1613/jair.1.12376", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of methods collectively known as classifier chains has become a\npopular approach to multi-label learning problems. This approach involves\nlinking together off-the-shelf binary classifiers in a chain structure, such\nthat class label predictions become features for other classifiers. Such\nmethods have proved flexible and effective and have obtained state-of-the-art\nempirical performance across many datasets and multi-label evaluation metrics.\nThis performance led to further studies of how exactly it works, and how it\ncould be improved, and in the recent decade numerous studies have explored\nclassifier chains mechanisms on a theoretical level, and many improvements have\nbeen made to the training and inference procedures, such that this method\nremains among the state-of-the-art options for multi-label learning. Given this\npast and ongoing interest, which covers a broad range of applications and\nresearch themes, the goal of this work is to provide a review of classifier\nchains, a survey of the techniques and extensions provided in the literature,\nas well as perspectives for this approach in the domain of multi-label\nclassification in the future. We conclude positively, with a number of\nrecommendations for researchers and practitioners, as well as outlining a\nnumber of areas for future research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 11:44:54 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 11:36:27 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Read", "Jesse", ""], ["Pfahringer", "Bernhard", ""], ["Holmes", "Geoff", ""], ["Frank", "Eibe", ""]]}, {"id": "1912.13408", "submitter": "Matthew Riemer", "authors": "Matthew Riemer, Ignacio Cases, Clemens Rosenbaum, Miao Liu, Gerald\n  Tesauro", "title": "On the Role of Weight Sharing During Deep Option Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The options framework is a popular approach for building temporally extended\nactions in reinforcement learning. In particular, the option-critic\narchitecture provides general purpose policy gradient theorems for learning\nactions from scratch that are extended in time. However, past work makes the\nkey assumption that each of the components of option-critic has independent\nparameters. In this work we note that while this key assumption of the policy\ngradient theorems of option-critic holds in the tabular case, it is always\nviolated in practice for the deep function approximation setting. We thus\nreconsider this assumption and consider more general extensions of\noption-critic and hierarchical option-critic training that optimize for the\nfull architecture with each update. It turns out that not assuming parameter\nindependence challenges a belief in prior work that training the policy over\noptions can be disentangled from the dynamics of the underlying options. In\nfact, learning can be sped up by focusing the policy over options on states\nwhere options are actually likely to terminate. We put our new algorithms to\nthe test in application to sample efficient learning of Atari games, and\ndemonstrate significantly improved stability and faster convergence when\nlearning long options.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 16:49:13 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 06:19:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Riemer", "Matthew", ""], ["Cases", "Ignacio", ""], ["Rosenbaum", "Clemens", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""]]}, {"id": "1912.13414", "submitter": "Xingyu Lu", "authors": "Xingyu Lu, Stas Tiomkin, Pieter Abbeel", "title": "Predictive Coding for Boosting Deep Reinforcement Learning with Sparse\n  Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent progress in deep reinforcement learning has enabled robots to\nlearn complex behaviors, tasks with long horizons and sparse rewards remain an\nongoing challenge. In this work, we propose an effective reward shaping method\nthrough predictive coding to tackle sparse reward problems. By learning\npredictive representations offline and using these representations for reward\nshaping, we gain access to reward signals that understand the structure and\ndynamics of the environment. In particular, our method achieves better learning\nby providing reward signals that 1) understand environment dynamics 2)\nemphasize on features most useful for learning 3) resist noise in learned\nrepresentations through reward accumulation. We demonstrate the usefulness of\nthis approach in different domains ranging from robotic manipulation to\nnavigation, and we show that reward signals produced through predictive coding\nare as effective for learning as hand-crafted rewards.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 03:32:00 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 01:28:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lu", "Xingyu", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1912.13415", "submitter": "John Giorgi", "authors": "John Giorgi, Xindi Wang, Nicola Sahar, Won Young Shin, Gary D. Bader,\n  Bo Wang", "title": "End-to-end Named Entity Recognition and Relation Extraction using\n  Pre-trained Language Models", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Named entity recognition (NER) and relation extraction (RE) are two important\ntasks in information extraction and retrieval (IE \\& IR). Recent work has\ndemonstrated that it is beneficial to learn these tasks jointly, which avoids\nthe propagation of error inherent in pipeline-based systems and improves\nperformance. However, state-of-the-art joint models typically rely on external\nnatural language processing (NLP) tools, such as dependency parsers, limiting\ntheir usefulness to domains (e.g. news) where those tools perform well. The few\nneural, end-to-end models that have been proposed are trained almost completely\nfrom scratch. In this paper, we propose a neural, end-to-end model for jointly\nextracting entities and their relations which does not rely on external NLP\ntools and which integrates a large, pre-trained language model. Because the\nbulk of our model's parameters are pre-trained and we eschew recurrence for\nself-attention, our model is fast to train. On 5 datasets across 3 domains, our\nmodel matches or exceeds state-of-the-art performance, sometimes by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:47:56 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Giorgi", "John", ""], ["Wang", "Xindi", ""], ["Sahar", "Nicola", ""], ["Shin", "Won Young", ""], ["Bader", "Gary D.", ""], ["Wang", "Bo", ""]]}, {"id": "1912.13421", "submitter": "Zacharie Naulet", "authors": "Yasaman Mahdaviyeh, Zacharie Naulet", "title": "Risk of the Least Squares Minimum Norm Estimator under the Spike\n  Covariance Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study risk of the minimum norm linear least squares estimator in when the\nnumber of parameters $d$ depends on $n$, and $\\frac{d}{n} \\rightarrow \\infty$.\nWe assume that data has an underlying low rank structure by restricting\nourselves to spike covariance matrices, where a fixed finite number of\neigenvalues grow with $n$ and are much larger than the rest of the eigenvalues,\nwhich are (asymptotically) in the same order. We show that in this setting risk\nof minimum norm least squares estimator vanishes in compare to risk of the null\nestimator. We give asymptotic and non asymptotic upper bounds for this risk,\nand also leverage the assumption of spike model to give an analysis of the bias\nthat leads to tighter bounds in compare to previous works.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 16:58:42 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:26:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mahdaviyeh", "Yasaman", ""], ["Naulet", "Zacharie", ""]]}, {"id": "1912.13440", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand and Carl Edward Rasmussen", "title": "Approximate Inference for Fully Bayesian Gaussian Process Regression", "comments": "Presented at 2nd Symposium on Advances in Approximate Bayesian\n  Inference 2019", "journal-ref": "Proceedings of Machine Learning Research, Volume 118 (2019) 1-12", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in Gaussian Process models occurs through the adaptation of\nhyperparameters of the mean and the covariance function. The classical approach\nentails maximizing the marginal likelihood yielding fixed point estimates (an\napproach called \\textit{Type II maximum likelihood} or ML-II). An alternative\nlearning procedure is to infer the posterior over hyperparameters in a\nhierarchical specification of GPs we call \\textit{Fully Bayesian Gaussian\nProcess Regression} (GPR). This work considers two approximation schemes for\nthe intractable hyperparameter posterior: 1) Hamiltonian Monte Carlo (HMC)\nyielding a sampling-based approximation and 2) Variational Inference (VI) where\nthe posterior over hyperparameters is approximated by a factorized Gaussian\n(mean-field) or a full-rank Gaussian accounting for correlations between\nhyperparameters. We analyze the predictive performance for fully Bayesian GPR\non a range of benchmark data sets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:18:48 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:22:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lalchand", "Vidhi", ""], ["Rasmussen", "Carl Edward", ""]]}, {"id": "1912.13445", "submitter": "Krishna Pillutla", "authors": "Krishna Pillutla, Sham M. Kakade, Zaid Harchaoui", "title": "Robust Aggregation for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a robust aggregation approach to make federated learning robust to\nsettings when a fraction of the devices may be sending corrupted updates to the\nserver. The proposed approach relies on a robust secure aggregation oracle\nbased on the geometric median, which returns a robust aggregate using a\nconstant number of calls to a regular non-robust secure average oracle. The\nrobust aggregation oracle is privacy-preserving, similar to the secure average\noracle it builds upon. We provide experimental results of the proposed approach\nwith linear models and deep networks for two tasks in computer vision and\nnatural language processing. The robust aggregation approach is agnostic to the\nlevel of corruption; it outperforms the classical aggregation approach in terms\nof robustness when the level of corruption is high, while being competitive in\nthe regime of low corruption.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 17:24:41 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Pillutla", "Krishna", ""], ["Kakade", "Sham M.", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "1912.13463", "submitter": "Kaizheng Wang", "authors": "Kaizheng Wang", "title": "Some compact notations for concentration inequalities and user-friendly\n  results", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents compact notations for concentration inequalities and\nconvenient results to streamline probabilistic analysis. The new expressions\ndescribe the typical sizes and tails of random variables, allowing for simple\noperations without heavy use of inessential constants. They bridge classical\nasymptotic notations and modern non-asymptotic tail bounds together. Examples\nof different kinds demonstrate their efficacy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:03:19 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 17:57:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Kaizheng", ""]]}, {"id": "1912.13464", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Sergey Levine", "title": "Model Inversion Networks for Model-Based Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to solve data-driven optimization problems, where the\ngoal is to find an input that maximizes an unknown score function given access\nto a dataset of inputs with corresponding scores. When the inputs are\nhigh-dimensional and valid inputs constitute a small subset of this space\n(e.g., valid protein sequences or valid natural images), such model-based\noptimization problems become exceptionally difficult, since the optimizer must\navoid out-of-distribution and invalid inputs. We propose to address such\nproblem with model inversion networks (MINs), which learn an inverse mapping\nfrom scores to inputs. MINs can scale to high-dimensional input spaces and\nleverage offline logged data for both contextual and non-contextual\noptimization problems. MINs can also handle both purely offline data sources\nand active data collection. We evaluate MINs on tasks from the Bayesian\noptimization literature, high-dimensional model-based optimization problems\nover images and protein designs, and contextual bandit optimization from logged\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:06:49 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kumar", "Aviral", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.13465", "submitter": "Aviral Kumar", "authors": "Aviral Kumar, Xue Bin Peng, Sergey Levine", "title": "Reward-Conditioned Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning offers the promise of automating the acquisition of\ncomplex behavioral skills. However, compared to commonly used and\nwell-understood supervised learning methods, reinforcement learning algorithms\ncan be brittle, difficult to use and tune, and sensitive to seemingly innocuous\nimplementation decisions. In contrast, imitation learning utilizes standard and\nwell-understood supervised learning methods, but requires near-optimal expert\ndata. Can we learn effective policies via supervised learning without\ndemonstrations? The main idea that we explore in this work is that non-expert\ntrajectories collected from sub-optimal policies can be viewed as optimal\nsupervision, not for maximizing the reward, but for matching the reward of the\ngiven trajectory. By then conditioning the policy on the numerical value of the\nreward, we can obtain a policy that generalizes to larger returns. We show how\nsuch an approach can be derived as a principled method for policy search,\ndiscuss several variants, and compare the method experimentally to a variety of\ncurrent reinforcement learning methods on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:07:43 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Kumar", "Aviral", ""], ["Peng", "Xue Bin", ""], ["Levine", "Sergey", ""]]}, {"id": "1912.13472", "submitter": "Shiyu Liang", "authors": "Shiyu Liang, Ruoyu Sun and R. Srikant", "title": "Revisiting Landscape Analysis in Deep Neural Networks: Eliminating\n  Decreasing Paths to Infinity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional landscape analysis of deep neural networks aims to show that no\nsub-optimal local minima exist in some appropriate sense. From this, one may be\ntempted to conclude that descent algorithms which escape saddle points will\nreach a good local minimum. However, basic optimization theory tell us that it\nis also possible for a descent algorithm to diverge to infinity if there are\npaths leading to infinity, along which the loss function decreases. It is not\nclear whether for non-linear neural networks there exists one setting that no\nbad local-min and no decreasing paths to infinity can be simultaneously\nachieved. In this paper, we give the first positive answer to this question.\nMore specifically, for a large class of over-parameterized deep neural networks\nwith appropriate regularizers, the loss function has no bad local minima and no\ndecreasing paths to infinity. The key mathematical trick is to show that the\nset of regularizers which may be undesirable can be viewed as the image of a\nLipschitz continuous mapping from a lower-dimensional Euclidean space to a\nhigher-dimensional Euclidean space, and thus has zero measure.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:17:34 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Liang", "Shiyu", ""], ["Sun", "Ruoyu", ""], ["Srikant", "R.", ""]]}, {"id": "1912.13480", "submitter": "Aleksander Wieczorek", "authors": "Aleksander Wieczorek and Volker Roth", "title": "On the Difference Between the Information Bottleneck and the Deep\n  Information Bottleneck", "comments": null, "journal-ref": null, "doi": "10.3390/e22020131", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the Information Bottleneck model with deep learning by replacing\nmutual information terms with deep neural nets has proved successful in areas\nranging from generative modelling to interpreting deep neural networks. In this\npaper, we revisit the Deep Variational Information Bottleneck and the\nassumptions needed for its derivation. The two assumed properties of the data\n$X$, $Y$ and their latent representation $T$ take the form of two Markov chains\n$T-X-Y$ and $X-T-Y$. Requiring both to hold during the optimisation process can\nbe limiting for the set of potential joint distributions $P(X,Y,T)$. We\ntherefore show how to circumvent this limitation by optimising a lower bound\nfor $I(T;Y)$ for which only the latter Markov chain has to be satisfied. The\nactual mutual information consists of the lower bound which is optimised in\nDVIB and cognate models in practice and of two terms measuring how much the\nformer requirement $T-X-Y$ is violated. Finally, we propose to interpret the\nfamily of information bottleneck models as directed graphical models and show\nthat in this framework the original and deep information bottlenecks are\nspecial cases of a fundamental IB model.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:31:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wieczorek", "Aleksander", ""], ["Roth", "Volker", ""]]}, {"id": "1912.13490", "submitter": "Gianluca Baldassarre PhD", "authors": "Gianluca Baldassarre and Giovanni Granato", "title": "Representation Internal-Manipulation (RIM): A Neuro-Inspired\n  Computational Theory of Consciousness", "comments": "16 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many theories, based on neuroscientific and psychological empirical evidence\nand on computational concepts, have been elaborated to explain the emergence of\nconsciousness in the central nervous system. These theories propose key\nfundamental mechanisms to explain consciousness, but they only partially\nconnect such mechanisms to the possible functional and adaptive role of\nconsciousness. Recently, some cognitive and neuroscientific models try to solve\nthis gap by linking consciousness to various aspects of goal-directed\nbehaviour, the pivotal cognitive process that allows mammals to flexibly act in\nchallenging environments. Here we propose the Representation\nInternal-Manipulation (RIM) theory of consciousness, a theory that links the\nmain elements of consciousness theories to components and functions of\ngoal-directed behaviour, ascribing a central role for consciousness to the\ngoal-directed manipulation of internal representations. This manipulation\nrelies on four specific computational operations to perform the flexible\ninternal adaptation of all key elements of goal-directed computation, from the\nrepresentations of objects to those of goals, actions, and plans. Finally, we\npropose the concept of `manipulation agency' relating the sense of agency to\nthe internal manipulation of representations. This allows us to propose that\nthe subjective experience of consciousness is associated to the human capacity\nto generate and control a simulated internal reality that is vividly perceived\nand felt through the same perceptual and emotional mechanisms used to tackle\nthe external world.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:45:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Baldassarre", "Gianluca", ""], ["Granato", "Giovanni", ""]]}, {"id": "1912.13494", "submitter": "Oran Gannot", "authors": "Oran Gannot", "title": "A frequency-domain analysis of inexact gradient methods", "comments": "42 pages; corrections and additional applications to accelerated\n  methods. To appear in Mathematical Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA cs.SY eess.SY math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study robustness properties of some iterative gradient-based methods for\nstrongly convex functions, as well as for the larger class of functions with\nsector-bounded gradients, under a relative error model. Proofs of the\ncorresponding convergence rates are based on frequency-domain criteria for the\nstability of nonlinear systems. Applications are given to inexact versions of\ngradient descent and the Triple Momentum Method. To further emphasize the\nusefulness of frequency-domain methods, we derive improved analytic bounds for\nthe convergence rate of Nesterov's accelerated method (in the exact setting) on\nstrongly convex functions.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:47:30 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 15:53:10 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gannot", "Oran", ""]]}, {"id": "1912.13497", "submitter": "Yuhao Long", "authors": "Yuhao Long, Jingcheng Wang, Jingyi Wang", "title": "Water Supply Prediction Based on Initialized Attention Residual Network", "comments": "7 pages, 4 figures. This work has been submitted to IFAC for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time and accurate water supply forecast is crucial for water plant.\nHowever, most existing methods are likely affected by factors such as weather\nand holidays, which lead to a decline in the reliability of water supply\nprediction. In this paper, we address a generic artificial neural network,\ncalled Initialized Attention Residual Network (IARN), which is combined with an\nattention module and residual modules. Specifically, instead of continuing to\nuse the recurrent neural network (RNN) in time-series tasks, we try to build a\nconvolution neural network (CNN)to recede the disturb from other factors,\nrelieve the limitation of memory size and get a more credible results. Our\nmethod achieves state-of-the-art performance on several data sets, in terms of\naccuracy, robustness and generalization ability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 10:59:44 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Long", "Yuhao", ""], ["Wang", "Jingcheng", ""], ["Wang", "Jingyi", ""]]}, {"id": "1912.13503", "submitter": "Alexander Sax", "authors": "Jeffrey O Zhang, Alexander Sax, Amir Zamir, Leonidas Guibas, Jitendra\n  Malik", "title": "Side-Tuning: A Baseline for Network Adaptation via Additive Side\n  Networks", "comments": "In ECCV 2020 (Spotlight). For more, see project website and code at\n  http://sidetuning.berkeley.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a neural network for a desired task, one may prefer to adapt a\npre-trained network rather than starting from randomly initialized weights.\nAdaptation can be useful in cases when training data is scarce, when a single\nlearner needs to perform multiple tasks, or when one wishes to encode priors in\nthe network. The most commonly employed approaches for network adaptation are\nfine-tuning and using the pre-trained network as a fixed feature extractor,\namong others.\n  In this paper, we propose a straightforward alternative: side-tuning.\nSide-tuning adapts a pre-trained network by training a lightweight \"side\"\nnetwork that is fused with the (unchanged) pre-trained network via summation.\nThis simple method works as well as or better than existing solutions and it\nresolves some of the basic issues with fine-tuning, fixed features, and other\ncommon approaches. In particular, side-tuning is less prone to overfitting, is\nasymptotically consistent, and does not suffer from catastrophic forgetting in\nincremental learning. We demonstrate the performance of side-tuning under a\ndiverse set of scenarios, including incremental learning (iCIFAR, iTaskonomy),\nreinforcement learning, imitation learning (visual navigation in Habitat), NLP\nquestion-answering (SQuAD v2), and single-task transfer learning (Taskonomy),\nwith consistently promising results.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:52:32 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 00:02:34 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 22:36:58 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2020 00:44:06 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Zhang", "Jeffrey O", ""], ["Sax", "Alexander", ""], ["Zamir", "Amir", ""], ["Guibas", "Leonidas", ""], ["Malik", "Jitendra", ""]]}, {"id": "1912.13515", "submitter": "Huizhuo Yuan", "authors": "Huizhuo Yuan, Xiangru Lian, Ji Liu", "title": "Stochastic Recursive Variance Reduction for Efficient Smooth Non-Convex\n  Compositional Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic compositional optimization arises in many important machine\nlearning tasks such as value function evaluation in reinforcement learning and\nportfolio management. The objective function is the composition of two\nexpectations of stochastic functions, and is more challenging to optimize than\nvanilla stochastic optimization problems. In this paper, we investigate the\nstochastic compositional optimization in the general smooth non-convex setting.\nWe employ a recently developed idea of \\textit{Stochastic Recursive Gradient\nDescent} to design a novel algorithm named SARAH-Compositional, and prove a\nsharp Incremental First-order Oracle (IFO) complexity upper bound for\nstochastic compositional optimization: $\\mathcal{O}((n+m)^{1/2}\n\\varepsilon^{-2})$ in the finite-sum case and $\\mathcal{O}(\\varepsilon^{-3})$\nin the online case. Such a complexity is known to be the best one among IFO\ncomplexity results for non-convex stochastic compositional optimization, and is\nbelieved to be optimal. Our experiments validate the theoretical performance of\nour algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:59:13 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 10:52:11 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yuan", "Huizhuo", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""]]}]