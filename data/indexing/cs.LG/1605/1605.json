[{"id": "1605.00003", "submitter": "Snehanshu Saha", "authors": "Luckyson Khaidem, Snehanshu Saha and Sudeepa Roy Dey", "title": "Predicting the direction of stock market prices using random forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting trends in stock market prices has been an area of interest for\nresearchers for many years due to its complex and dynamic nature. Intrinsic\nvolatility in stock market across the globe makes the task of prediction\nchallenging. Forecasting and diffusion modeling, although effective can't be\nthe panacea to the diverse range of problems encountered in prediction,\nshort-term or otherwise. Market risk, strongly correlated with forecasting\nerrors, needs to be minimized to ensure minimal risk in investment. The authors\npropose to minimize forecasting error by treating the forecasting problem as a\nclassification problem, a popular suite of algorithms in Machine learning. In\nthis paper, we propose a novel way to minimize the risk of investment in stock\nmarket by predicting the returns of a stock using a class of powerful machine\nlearning algorithms known as ensemble learning. Some of the technical\nindicators such as Relative Strength Index (RSI), stochastic oscillator etc are\nused as inputs to train our model. The learning model used is an ensemble of\nmultiple decision trees. The algorithm is shown to outperform existing algo-\nrithms found in the literature. Out of Bag (OOB) error estimates have been\nfound to be encouraging. Key Words: Random Forest Classifier, stock price\nforecasting, Exponential smoothing, feature extraction, OOB error and\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 17:53:08 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Khaidem", "Luckyson", ""], ["Saha", "Snehanshu", ""], ["Dey", "Sudeepa Roy", ""]]}, {"id": "1605.00017", "submitter": "Seunghyun Park", "authors": "Seunghyun Park, Seonwoo Min, Hyunsoo Choi, and Sungroh Yoon", "title": "deepMiRGene: Deep Neural Network based Precursor microRNA Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since microRNAs (miRNAs) play a crucial role in post-transcriptional gene\nregulation, miRNA identification is one of the most essential problems in\ncomputational biology. miRNAs are usually short in length ranging between 20\nand 23 base pairs. It is thus often difficult to distinguish miRNA-encoding\nsequences from other non-coding RNAs and pseudo miRNAs that have a similar\nlength, and most previous studies have recommended using precursor miRNAs\ninstead of mature miRNAs for robust detection. A great number of conventional\nmachine-learning-based classification methods have been proposed, but they\noften have the serious disadvantage of requiring manual feature engineering,\nand their performance is limited as well. In this paper, we propose a novel\nmiRNA precursor prediction algorithm, deepMiRGene, based on recurrent neural\nnetworks, specifically long short-term memory networks. deepMiRGene\nautomatically learns suitable features from the data themselves without manual\nfeature engineering and constructs a model that can successfully reflect\nstructural characteristics of precursor miRNAs. For the performance evaluation\nof our approach, we have employed several widely used evaluation metrics on\nthree recent benchmark datasets and verified that deepMiRGene delivered\ncomparable performance among the current state-of-the-art tools.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 20:12:04 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Park", "Seunghyun", ""], ["Min", "Seonwoo", ""], ["Choi", "Hyunsoo", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1605.00031", "submitter": "Thomas Wiatowski", "authors": "Philipp Grohs, Thomas Wiatowski, Helmut B\\\"olcskei", "title": "Deep Convolutional Neural Networks on Cartoon Functions", "comments": "This is a slightly updated version of the paper published in the ISIT\n  proceedings. Specifically, we corrected errors in the arguments on the volume\n  of tubes. Note that this correction does not affect the main statements of\n  the paper", "journal-ref": "Proc. of IEEE International Symposium on Information Theory\n  (ISIT), Barcelona, Spain, pp. 1163-1167, July 2016", "doi": "10.1109/ISIT.2016.7541482", "report-no": null, "categories": "cs.LG cs.CV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wiatowski and B\\\"olcskei, 2015, proved that deformation stability and\nvertical translation invariance of deep convolutional neural network-based\nfeature extractors are guaranteed by the network structure per se rather than\nthe specific convolution kernels and non-linearities. While the translation\ninvariance result applies to square-integrable functions, the deformation\nstability bound holds for band-limited functions only. Many signals of\npractical relevance (such as natural images) exhibit, however, sharp and curved\ndiscontinuities and are, hence, not band-limited. The main contribution of this\npaper is a deformation stability result that takes these structural properties\ninto account. Specifically, we establish deformation stability bounds for the\nclass of cartoon functions introduced by Donoho, 2001.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 21:40:16 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 13:47:49 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Grohs", "Philipp", ""], ["Wiatowski", "Thomas", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1605.00042", "submitter": "Ankit Parekh", "authors": "Ankit Parekh and Ivan W. Selesnick", "title": "Improved Sparse Low-Rank Matrix Estimation", "comments": "10 pages, 10 figures", "journal-ref": "Signal Processing, Apr. 2017", "doi": "10.1016/j.sigpro.2017.04.011", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating a sparse low-rank matrix from its noisy\nobservation. We propose an objective function consisting of a data-fidelity\nterm and two parameterized non-convex penalty functions. Further, we show how\nto set the parameters of the non-convex penalty functions, in order to ensure\nthat the objective function is strictly convex. The proposed objective function\nbetter estimates sparse low-rank matrices than a convex method which utilizes\nthe sum of the nuclear norm and the $\\ell_1$ norm. We derive an algorithm (as\nan instance of ADMM) to solve the proposed problem, and guarantee its\nconvergence provided the scalar augmented Lagrangian parameter is set\nappropriately. We demonstrate the proposed method for denoising an audio signal\nand an adjacency matrix representing protein interactions in the `Escherichia\ncoli' bacteria.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 23:36:39 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 16:42:20 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Parekh", "Ankit", ""], ["Selesnick", "Ivan W.", ""]]}, {"id": "1605.00057", "submitter": "Setareh Maghsudi", "authors": "Setareh Maghsudi and Ekram Hossain", "title": "Distributed Cell Association for Energy Harvesting IoT Devices in Dense\n  Small Cell Networks: A Mean-Field Multi-Armed Bandit Approach", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2017.2676166", "report-no": null, "categories": "cs.NI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging Internet of Things (IoT)-driven ultra-dense small cell networks\n(UD-SCNs) will need to combat a variety of challenges. On one hand, massive\nnumber of devices sharing the limited wireless resources will render\ncentralized control mechanisms infeasible due to the excessive cost of\ninformation acquisition and computations. On the other hand, to reduce energy\nconsumption from fixed power grid and/or battery, many IoT devices may need to\ndepend on the energy harvested from the ambient environment (e.g., from RF\ntransmissions, environmental sources). However, due to the opportunistic nature\nof energy harvesting, this will introduce uncertainty in the network operation.\nIn this article, we study the distributed cell association problem for energy\nharvesting IoT devices in UD-SCNs. After reviewing the state-of-the-art\nresearch on the cell association problem in small cell networks, we outline the\nmajor challenges for distributed cell association in IoT-driven UD-SCNs where\nthe IoT devices will need to perform cell association in a distributed manner\nin presence of uncertainty (e.g., limited knowledge on channel/network) and\nlimited computational capabilities. To this end, we propose an approach based\non mean-field multi-armed bandit games to solve the uplink cell association\nproblem for energy harvesting IoT devices in a UD-SCN. This approach is\nparticularly suitable to analyze large multi-agent systems under uncertainty\nand lack of information. We provide some theoretical results as well as\npreliminary performance evaluation results for the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 02:52:16 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Maghsudi", "Setareh", ""], ["Hossain", "Ekram", ""]]}, {"id": "1605.00079", "submitter": "Jinshan Zeng", "authors": "Shaobo Lin, Jinshan Zeng, and Xiaoqin Zhang", "title": "Constructive neural network learning", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at developing scalable neural network-type learning\nsystems. Motivated by the idea of \"constructive neural networks\" in\napproximation theory, we focus on \"constructing\" rather than \"training\"\nfeed-forward neural networks (FNNs) for learning, and propose a novel FNNs\nlearning system called the constructive feed-forward neural network (CFN).\nTheoretically, we prove that the proposed method not only overcomes the\nclassical saturation problem for FNN approximation, but also reaches the\noptimal learning rate when the regression function is smooth, while the\nstate-of-the-art learning rates established for traditional FNNs are only near\noptimal (up to a logarithmic factor). A series of numerical simulations are\nprovided to show the efficiency and feasibility of CFN via comparing with the\nwell-known regularized least squares (RLS) with Gaussian kernel and extreme\nlearning machine (ELM).\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 08:39:38 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Lin", "Shaobo", ""], ["Zeng", "Jinshan", ""], ["Zhang", "Xiaoqin", ""]]}, {"id": "1605.00164", "submitter": "Dinesh Jayaraman", "authors": "Dinesh Jayaraman and Kristen Grauman", "title": "Look-ahead before you leap: end-to-end active recognition by forecasting\n  the effect of motion", "comments": "A preliminary version of the material in this document was filed as\n  University of Texas technical report no. UT AI15-06, December, 2015, at:\n  http://apps.cs.utexas.edu/tech_reports/reports/ai/AI-2214.pdf, ECCV 2016", "journal-ref": null, "doi": null, "report-no": "University of Texas Technical Report UT AI 15-06 (December 2015)", "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual recognition systems mounted on autonomous moving agents face the\nchallenge of unconstrained data, but simultaneously have the opportunity to\nimprove their performance by moving to acquire new views of test data. In this\nwork, we first show how a recurrent neural network-based system may be trained\nto perform end-to-end learning of motion policies suited for this \"active\nrecognition\" setting. Further, we hypothesize that active vision requires an\nagent to have the capacity to reason about the effects of its motions on its\nview of the world. To verify this hypothesis, we attempt to induce this\ncapacity in our active recognition pipeline, by simultaneously learning to\nforecast the effects of the agent's motions on its internal representation of\nthe environment conditional on all past views. Results across two challenging\ndatasets confirm both that our end-to-end system successfully learns meaningful\npolicies for active category recognition, and that \"learning to look ahead\"\nfurther boosts recognition performance.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 20:39:16 GMT"}, {"version": "v2", "created": "Fri, 5 Aug 2016 22:15:48 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Jayaraman", "Dinesh", ""], ["Grauman", "Kristen", ""]]}, {"id": "1605.00176", "submitter": "Pranav Sakulkar", "authors": "Pranav Sakulkar and Bhaskar Krishnamachari", "title": "Stochastic Contextual Bandits with Known Reward Functions", "comments": "A version of this technical report is under submission in IEEE/ACM\n  Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequential decision-making problems in communication networks can be\nmodeled as contextual bandit problems, which are natural extensions of the\nwell-known multi-armed bandit problem. In contextual bandit problems, at each\ntime, an agent observes some side information or context, pulls one arm and\nreceives the reward for that arm. We consider a stochastic formulation where\nthe context-reward tuples are independently drawn from an unknown distribution\nin each trial. Motivated by networking applications, we analyze a setting where\nthe reward is a known non-linear function of the context and the chosen arm's\ncurrent state. We first consider the case of discrete and finite context-spaces\nand propose DCB($\\epsilon$), an algorithm that we prove, through a careful\nanalysis, yields regret (cumulative reward gap compared to a distribution-aware\ngenie) scaling logarithmically in time and linearly in the number of arms that\nare not optimal for any context, improving over existing algorithms where the\nregret scales linearly in the total number of arms. We then study continuous\ncontext-spaces with Lipschitz reward functions and propose CCB($\\epsilon,\n\\delta$), an algorithm that uses DCB($\\epsilon$) as a subroutine.\nCCB($\\epsilon, \\delta$) reveals a novel regret-storage trade-off that is\nparametrized by $\\delta$. Tuning $\\delta$ to the time horizon allows us to\nobtain sub-linear regret bounds, while requiring sub-linear storage. By\nexploiting joint learning for all contexts we get regret bounds for\nCCB($\\epsilon, \\delta$) that are unachievable by any existing contextual bandit\nalgorithm for continuous context-spaces. We also show similar performance\nbounds for the unknown horizon case.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 22:16:22 GMT"}, {"version": "v2", "created": "Fri, 6 May 2016 20:32:36 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Sakulkar", "Pranav", ""], ["Krishnamachari", "Bhaskar", ""]]}, {"id": "1605.00223", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti, Romy Lorenz, Robert Leech, Christoforos\n  Anagnostopoulos and Giovanni Montana", "title": "Text-mining the NeuroSynth corpus using Deep Boltzmann Machines", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale automated meta-analysis of neuroimaging data has recently\nestablished itself as an important tool in advancing our understanding of human\nbrain function. This research has been pioneered by NeuroSynth, a database\ncollecting both brain activation coordinates and associated text across a large\ncohort of neuroimaging research papers. One of the fundamental aspects of such\nmeta-analysis is text-mining. To date, word counts and more sophisticated\nmethods such as Latent Dirichlet Allocation have been proposed. In this work we\npresent an unsupervised study of the NeuroSynth text corpus using Deep\nBoltzmann Machines (DBMs). The use of DBMs yields several advantages over the\naforementioned methods, principal among which is the fact that it yields both\nword and document embeddings in a high-dimensional vector space. Such\nembeddings serve to facilitate the use of traditional machine learning\ntechniques on the text corpus. The proposed DBM model is shown to learn\nembeddings with a clear semantic structure.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 09:01:13 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Lorenz", "Romy", ""], ["Leech", "Robert", ""], ["Anagnostopoulos", "Christoforos", ""], ["Montana", "Giovanni", ""]]}, {"id": "1605.00241", "submitter": "Basem Elbarashy", "authors": "Basem G. El-Barashy", "title": "Common-Description Learning: A Framework for Learning Algorithms and\n  Generating Subproblems from Few Examples", "comments": "32 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current learning algorithms face many difficulties in learning simple\npatterns and using them to learn more complex ones. They also require more\nexamples than humans do to learn the same pattern, assuming no prior knowledge.\nIn this paper, a new learning framework is introduced that is called\ncommon-description learning (CDL). This framework has been tested on 32 small\nmulti-task datasets, and the results show that it was able to learn complex\nalgorithms from a few number of examples. The final model is perfectly\ninterpretable and its depth depends on the question. What is meant by depth\nhere is that whenever needed, the model learns to break down the problem into\nsimpler subproblems and solves them using previously learned models. Finally,\nwe explain the capabilities of our framework in discovering complex relations\nin data and how it can help in improving language understanding in machines.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 11:56:01 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["El-Barashy", "Basem G.", ""]]}, {"id": "1605.00251", "submitter": "Andreas Maurer", "authors": "Andreas Maurer", "title": "A vector-contraction inequality for Rademacher complexities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contraction inequality for Rademacher averages is extended to Lipschitz\nfunctions with vector-valued domains, and it is also shown that in the bounding\nexpression the Rademacher variables can be replaced by arbitrary iid symmetric\nand sub-gaussian variables. Example applications are given for multi-category\nlearning, K-means clustering and learning-to-learn.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 13:19:57 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Maurer", "Andreas", ""]]}, {"id": "1605.00252", "submitter": "Nishant Mehta", "authors": "Peter D. Gr\\\"unwald and Nishant A. Mehta", "title": "Fast Rates for General Unbounded Loss Functions: from ERM to Generalized\n  Bayes", "comments": "accepted to JMLR pending minor final modifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new excess risk bounds for general unbounded loss functions\nincluding log loss and squared loss, where the distribution of the losses may\nbe heavy-tailed. The bounds hold for general estimators, but they are optimized\nwhen applied to $\\eta$-generalized Bayesian, MDL, and empirical risk\nminimization estimators. In the case of log loss, the bounds imply convergence\nrates for generalized Bayesian inference under misspecification in terms of a\ngeneralization of the Hellinger metric as long as the learning rate $\\eta$ is\nset correctly. For general loss functions, our bounds rely on two separate\nconditions: the $v$-GRIP (generalized reversed information projection)\nconditions, which control the lower tail of the excess loss; and the newly\nintroduced witness condition, which controls the upper tail. The parameter $v$\nin the $v$-GRIP conditions determines the achievable rate and is akin to the\nexponent in the Tsybakov margin condition and the Bernstein condition for\nbounded losses, which the $v$-GRIP conditions generalize; favorable $v$ in\ncombination with small model complexity leads to $\\tilde{O}(1/n)$ rates. The\nwitness condition allows us to connect the excess risk to an \"annealed\" version\nthereof, by which we generalize several previous results connecting Hellinger\nand R\\'enyi divergence to KL divergence.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 13:35:15 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 07:39:14 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 16:26:22 GMT"}, {"version": "v4", "created": "Tue, 5 Nov 2019 18:36:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Gr\u00fcnwald", "Peter D.", ""], ["Mehta", "Nishant A.", ""]]}, {"id": "1605.00278", "submitter": "Hans-Christian Ruiz Dipl-Phys", "authors": "H.-Ch. Ruiz and H. J. Kappen", "title": "Particle Smoothing for Hidden Diffusion Processes: Adaptive Path\n  Integral Smoother", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": "10.1109/TSP.2017.2686340", "report-no": null, "categories": "cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle smoothing methods are used for inference of stochastic processes\nbased on noisy observations. Typically, the estimation of the marginal\nposterior distribution given all observations is cumbersome and computational\nintensive. In this paper, we propose a simple algorithm based on path integral\ncontrol theory to estimate the smoothing distribution of continuous-time\ndiffusion processes with partial observations. In particular, we use an\nadaptive importance sampling method to improve the effective sampling size of\nthe posterior over processes given the observations and the reliability of the\nestimation of the marginals. This is achieved by estimating a feedback\ncontroller to sample efficiently from the joint smoothing distributions. We\ncompare the results with estimations obtained from the standard Forward\nFilter/Backward Simulator for two diffusion processes of different complexity.\nWe show that the proposed method gives more reliable estimations than the\nstandard FFBSi when the smoothing distribution is poorly represented by the\nfilter distribution.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 16:56:49 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 15:15:00 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Ruiz", "H. -Ch.", ""], ["Kappen", "H. J.", ""]]}, {"id": "1605.00329", "submitter": "Ewout van den Berg", "authors": "Ewout van den Berg", "title": "Some Insights into the Geometry and Training of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been successfully used for classification tasks in a\nrapidly growing number of practical applications. Despite their popularity and\nwidespread use, there are still many aspects of training and classification\nthat are not well understood. In this paper we aim to provide some new insights\ninto training and classification by analyzing neural networks from a\nfeature-space perspective. We review and explain the formation of decision\nregions and study some of their combinatorial aspects. We place a particular\nemphasis on the connections between the neural network weight and bias terms\nand properties of decision boundaries and other regions that exhibit varying\nlevels of classification confidence. We show how the error backpropagates in\nthese regions and emphasize the important role they have in the formation of\ngradients. These findings expose the connections between scaling of the weight\nparameters and the density of the training samples. This sheds more light on\nthe vanishing gradient problem, explains the need for regularization, and\nsuggests an approach for subsampling training data to improve performance.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 01:37:57 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Berg", "Ewout van den", ""]]}, {"id": "1605.00391", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Arthur Gretton, Bernhard Sch\\\"olkopf, Moritz\n  Grosse-Wentrup", "title": "Recovery of non-linear cause-effect relationships from linearly mixed\n  neuroimaging data", "comments": "arXiv admin note: text overlap with arXiv:1512.01255", "journal-ref": "Pattern Recognition in Neuroimaging (PRNI), International Workshop\n  on, 1-4, 2016", "doi": "10.1109/PRNI.2016.7552331", "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference concerns the identification of cause-effect relationships\nbetween variables. However, often only linear combinations of variables\nconstitute meaningful causal variables. For example, recovering the signal of a\ncortical source from electroencephalography requires a well-tuned combination\nof signals recorded at multiple electrodes. We recently introduced the MERLiN\n(Mixture Effect Recovery in Linear Networks) algorithm that is able to recover,\nfrom an observed linear mixture, a causal variable that is a linear effect of\nanother given variable. Here we relax the assumption of this cause-effect\nrelationship being linear and present an extended algorithm that can pick up\nnon-linear cause-effect relationships. Thus, the main contribution is an\nalgorithm (and ready to use code) that has broader applicability and allows for\na richer model class. Furthermore, a comparative analysis indicates that the\nassumption of linear cause-effect relationships is not restrictive in analysing\nelectroencephalographic data.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 08:45:59 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 20:01:00 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Gretton", "Arthur", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1605.00404", "submitter": "Ming Li", "authors": "Ming Li", "title": "Simple2Complex: Global Optimization by Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method named simple2complex for modeling and training deep neural networks\nis proposed. Simple2complex train deep neural networks by smoothly adding more\nand more layers to the shallow networks, as the learning procedure going on,\nthe network is just like growing. Compared with learning by end2end,\nsimple2complex is with less possibility trapping into local minimal, namely,\nowning ability for global optimization. Cifar10 is used for verifying the\nsuperiority of simple2complex.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 09:33:46 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Li", "Ming", ""]]}, {"id": "1605.00405", "submitter": "Ioannis Panageas", "authors": "Ioannis Panageas and Georgios Piliouras", "title": "Gradient Descent Only Converges to Minimizers: Non-Isolated Critical\n  Points and Invariant Regions", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a non-convex twice differentiable cost function f, we prove that the\nset of initial conditions so that gradient descent converges to saddle points\nwhere \\nabla^2 f has at least one strictly negative eigenvalue has (Lebesgue)\nmeasure zero, even for cost functions f with non-isolated critical points,\nanswering an open question in [Lee, Simchowitz, Jordan, Recht, COLT2016].\nMoreover, this result extends to forward-invariant convex subspaces, allowing\nfor weak (non-globally Lipschitz) smoothness assumptions. Finally, we produce\nan upper bound on the allowable step-size.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 09:34:19 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 07:49:13 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Panageas", "Ioannis", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1605.00507", "submitter": "Ping Li", "authors": "Ping Li and Syama Sundar Rangapuram and Martin Slawski", "title": "Methods for Sparse and Low-Rank Recovery under Simplex Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The de-facto standard approach of promoting sparsity by means of\n$\\ell_1$-regularization becomes ineffective in the presence of simplex\nconstraints, i.e.,~the target is known to have non-negative entries summing up\nto a given constant. The situation is analogous for the use of nuclear norm\nregularization for low-rank recovery of Hermitian positive semidefinite\nmatrices with given trace. In the present paper, we discuss several strategies\nto deal with this situation, from simple to more complex. As a starting point,\nwe consider empirical risk minimization (ERM). It follows from existing theory\nthat ERM enjoys better theoretical properties w.r.t.~prediction and\n$\\ell_2$-estimation error than $\\ell_1$-regularization. In light of this, we\nargue that ERM combined with a subsequent sparsification step like thresholding\nis superior to the heuristic of using $\\ell_1$-regularization after dropping\nthe sum constraint and subsequent normalization.\n  At the next level, we show that any sparsity-promoting regularizer under\nsimplex constraints cannot be convex. A novel sparsity-promoting regularization\nscheme based on the inverse or negative of the squared $\\ell_2$-norm is\nproposed, which avoids shortcomings of various alternative methods from the\nliterature. Our approach naturally extends to Hermitian positive semidefinite\nmatrices with given trace. Numerical studies concerning compressed sensing,\nsparse mixture density estimation, portfolio optimization and quantum state\ntomography are used to illustrate the key points of the paper.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 14:37:59 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Li", "Ping", ""], ["Rangapuram", "Syama Sundar", ""], ["Slawski", "Martin", ""]]}, {"id": "1605.00519", "submitter": "Mario Lucic", "authors": "Mario Lucic, Olivier Bachem, Andreas Krause", "title": "Linear-time Outlier Detection via Sensitivity", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outliers are ubiquitous in modern data sets. Distance-based techniques are a\npopular non-parametric approach to outlier detection as they require no prior\nassumptions on the data generating distribution and are simple to implement.\nScaling these techniques to massive data sets without sacrificing accuracy is a\nchallenging task. We propose a novel algorithm based on the intuition that\noutliers have a significant influence on the quality of divergence-based\nclustering solutions. We propose sensitivity - the worst-case impact of a data\npoint on the clustering objective - as a measure of outlierness. We then prove\nthat influence, a (non-trivial) upper-bound on the sensitivity, can be computed\nby a simple linear time algorithm. To scale beyond a single machine, we propose\na communication efficient distributed algorithm. In an extensive experimental\nevaluation, we demonstrate the effectiveness and establish the statistical\nsignificance of the proposed approach. In particular, it outperforms the most\npopular distance-based approaches while being several orders of magnitude\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 15:17:02 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Lucic", "Mario", ""], ["Bachem", "Olivier", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.00529", "submitter": "Mario Lucic", "authors": "Mario Lucic, Mesrob I. Ohannessian, Amin Karbasi, Andreas Krause", "title": "Tradeoffs for Space, Time, Data and Risk in Unsupervised Learning", "comments": "Conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with massive data, is it possible to trade off (statistical) risk, and\n(computational) space and time? This challenge lies at the heart of large-scale\nmachine learning. Using k-means clustering as a prototypical unsupervised\nlearning problem, we show how we can strategically summarize the data (control\nspace) in order to trade off risk and time when data is generated by a\nprobabilistic model. Our summarization is based on coreset constructions from\ncomputational geometry. We also develop an algorithm, TRAM, to navigate the\nspace/time/data/risk tradeoff in practice. In particular, we show that for a\nfixed risk (or data size), as the data size increases (resp. risk increases)\nthe running time of TRAM decreases. Our extensive experiments on real data sets\ndemonstrate the existence and practical utility of such tradeoffs, not only for\nk-means but also for Gaussian Mixture Models.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 15:32:14 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Lucic", "Mario", ""], ["Ohannessian", "Mesrob I.", ""], ["Karbasi", "Amin", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.00596", "submitter": "Shuai Li", "authors": "Shuai Li and Claudio Gentile and Alexandros Karatzoglou", "title": "Graph Clustering Bandits for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an efficient context-dependent clustering technique for\nrecommender systems based on exploration-exploitation strategies through\nmulti-armed bandits over multiple users. Our algorithm dynamically groups users\nbased on their observed behavioral similarity during a sequence of logged\nactivities. In doing so, the algorithm reacts to the currently served user by\nshaping clusters around him/her but, at the same time, it explores the\ngeneration of clusters over users which are not currently engaged. We motivate\nthe effectiveness of this clustering policy, and provide an extensive empirical\nanalysis on real-world datasets, showing scalability and improved prediction\nperformance over state-of-the-art methods for sequential clustering of users in\nmulti-armed bandit scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 18:13:04 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Li", "Shuai", ""], ["Gentile", "Claudio", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1605.00609", "submitter": "Hemant Tyagi", "authors": "Hemant Tyagi, Anastasios Kyrillidis, Bernd G\\\"artner, Andreas Krause", "title": "Algorithms for Learning Sparse Additive Models with Interactions in High\n  Dimensions", "comments": "To appear in Information and Inference: A Journal of the IMA. Made\n  following changes after review process: (a) Corrected typos throughout the\n  text. (b) Corrected choice of sampling distribution in Section 5, see eqs.\n  (5.2), (5.3). (c) More detailed comparison with existing work in Section 8.\n  (d) Added Section B in appendix on roots of cubic equation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a Sparse Additive\nModel (SPAM), if it is of the form $f(\\mathbf{x}) = \\sum_{l \\in\n\\mathcal{S}}\\phi_{l}(x_l)$ where $\\mathcal{S} \\subset [d]$, $|\\mathcal{S}| \\ll\nd$. Assuming $\\phi$'s, $\\mathcal{S}$ to be unknown, there exists extensive work\nfor estimating $f$ from its samples. In this work, we consider a generalized\nversion of SPAMs, that also allows for the presence of a sparse number of\nsecond order interaction terms. For some $\\mathcal{S}_1 \\subset [d],\n\\mathcal{S}_2 \\subset {[d] \\choose 2}$, with $|\\mathcal{S}_1| \\ll d,\n|\\mathcal{S}_2| \\ll d^2$, the function $f$ is now assumed to be of the form:\n$\\sum_{p \\in \\mathcal{S}_1}\\phi_{p} (x_p) + \\sum_{(l,l^{\\prime}) \\in\n\\mathcal{S}_2}\\phi_{(l,l^{\\prime})} (x_l,x_{l^{\\prime}})$. Assuming we have the\nfreedom to query $f$ anywhere in its domain, we derive efficient algorithms\nthat provably recover $\\mathcal{S}_1,\\mathcal{S}_2$ with finite sample bounds.\nOur analysis covers the noiseless setting where exact samples of $f$ are\nobtained, and also extends to the noisy setting where the queries are corrupted\nwith noise. For the noisy setting in particular, we consider two noise models\nnamely: i.i.d Gaussian noise and arbitrary but bounded noise. Our main methods\nfor identification of $\\mathcal{S}_2$ essentially rely on estimation of sparse\nHessian matrices, for which we provide two novel compressed sensing based\nschemes. Once $\\mathcal{S}_1, \\mathcal{S}_2$ are known, we show how the\nindividual components $\\phi_p$, $\\phi_{(l,l^{\\prime})}$ can be estimated via\nadditional queries of $f$, with uniform error bounds. Lastly, we provide\nsimulation results on synthetic data that validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 18:32:19 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 14:47:25 GMT"}, {"version": "v3", "created": "Mon, 8 May 2017 15:44:45 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Tyagi", "Hemant", ""], ["Kyrillidis", "Anastasios", ""], ["G\u00e4rtner", "Bernd", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.00659", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara, Wen-Qiang Wang, Onur Varol, Alessandro Flammini, Aram\n  Galstyan", "title": "Predicting online extremism, content adopters, and interaction\n  reciprocity", "comments": "9 pages, 3 figures, 8 tables", "journal-ref": "International Conference on Social Informatics (pp. 22-39).\n  Springer. 2016", "doi": "10.1007/978-3-319-47874-6_3", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning framework that leverages a mixture of metadata,\nnetwork, and temporal features to detect extremist users, and predict content\nadopters and interaction reciprocity in social media. We exploit a unique\ndataset containing millions of tweets generated by more than 25 thousand users\nwho have been manually identified, reported, and suspended by Twitter due to\ntheir involvement with extremist campaigns. We also leverage millions of tweets\ngenerated by a random sample of 25 thousand regular users who were exposed to,\nor consumed, extremist content. We carry out three forecasting tasks, (i) to\ndetect extremist users, (ii) to estimate whether regular users will adopt\nextremist content, and finally (iii) to predict whether users will reciprocate\ncontacts initiated by extremists. All forecasting tasks are set up in two\nscenarios: a post hoc (time independent) prediction task on aggregated data,\nand a simulated real-time prediction task. The performance of our framework is\nextremely promising, yielding in the different forecasting scenarios up to 93%\nAUC for extremist user detection, up to 80% AUC for content adoption\nprediction, and finally up to 72% AUC for interaction reciprocity forecasting.\nWe conclude by providing a thorough feature analysis that helps determine which\nare the emerging signals that provide predictive power in different scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 20:00:36 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Ferrara", "Emilio", ""], ["Wang", "Wen-Qiang", ""], ["Varol", "Onur", ""], ["Flammini", "Alessandro", ""], ["Galstyan", "Aram", ""]]}, {"id": "1605.00716", "submitter": "Timothy O'Shea", "authors": "Timothy J O'Shea, Latha Pemula, Dhruv Batra, T. Charles Clancy", "title": "Radio Transformer Networks: Attention Models for Learning to Synchronize\n  in Wireless Systems", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce learned attention models into the radio machine learning domain\nfor the task of modulation recognition by leveraging spatial transformer\nnetworks and introducing new radio domain appropriate transformations. This\nattention model allows the network to learn a localization network capable of\nsynchronizing and normalizing a radio signal blindly with zero knowledge of the\nsignals structure based on optimization of the network for classification\naccuracy, sparse representation, and regularization. Using this architecture we\nare able to outperform our prior results in accuracy vs signal to noise ratio\nagainst an identical system without attention, however we believe such an\nattention model has implication far beyond the task of modulation recognition.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 00:45:35 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["O'Shea", "Timothy J", ""], ["Pemula", "Latha", ""], ["Batra", "Dhruv", ""], ["Clancy", "T. Charles", ""]]}, {"id": "1605.00740", "submitter": "Enyi Yao", "authors": "Enyi Yao and Arindam Basu", "title": "VLSI Extreme Learning Machine: A Design Space Exploration", "comments": "14 pages, 18 figures, accepted by IEEE Transactions on VLSI Systems\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a compact low-power, high performance hardware\nimplementation of the extreme learning machine (ELM) for machine learning\napplications. Mismatch in current mirrors are used to perform the vector-matrix\nmultiplication that forms the first stage of this classifier and is the most\ncomputationally intensive. Both regression and classification (on UCI data\nsets) are demonstrated and a design space trade-off between speed, power and\naccuracy is explored. Our results indicate that for a wide set of problems,\n$\\sigma V_T$ in the range of $15-25$mV gives optimal results. An input weight\nmatrix rotation method to extend the input dimension and hidden layer size\nbeyond the physical limits imposed by the chip is also described. This allows\nus to overcome a major limit imposed on most hardware machine learners. The\nchip is implemented in a $0.35 \\mu$m CMOS process and occupies a die area of\naround 5 mm $\\times$ 5 mm. Operating from a $1$ V power supply, it achieves an\nenergy efficiency of $0.47$ pJ/MAC at a classification rate of $31.6$ kHz.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 02:52:51 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Yao", "Enyi", ""], ["Basu", "Arindam", ""]]}, {"id": "1605.00751", "submitter": "Aditya Menon", "authors": "Aditya Krishna Menon, Brendan van Rooyen, Nagarajan Natarajan", "title": "Learning from Binary Labels with Instance-Dependent Corruption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have a sample of instances paired with binary labels corrupted by\narbitrary instance- and label-dependent noise. With sufficiently many such\nsamples, can we optimally classify and rank instances with respect to the\nnoise-free distribution? We provide a theoretical analysis of this question,\nwith three main contributions. First, we prove that for instance-dependent\nnoise, any algorithm that is consistent for classification on the noisy\ndistribution is also consistent on the clean distribution. Second, we prove\nthat for a broad class of instance- and label-dependent noise, a similar\nconsistency result holds for the area under the ROC curve. Third, for the\nlatter noise model, when the noise-free class-probability function belongs to\nthe generalised linear model family, we show that the Isotron can efficiently\nand provably learn from the corrupted sample.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 04:47:02 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 04:59:21 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Menon", "Aditya Krishna", ""], ["van Rooyen", "Brendan", ""], ["Natarajan", "Nagarajan", ""]]}, {"id": "1605.00788", "submitter": "Guy Uziel", "authors": "Guy Uziel and Ran El-Yaniv", "title": "Online Learning of Commission Avoidant Portfolio Ensembles", "comments": "arXiv admin note: text overlap with arXiv:1604.03266", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel online ensemble learning strategy for portfolio selection.\nThe new strategy controls and exploits any set of commission-oblivious\nportfolio selection algorithms. The strategy handles transaction costs using a\nnovel commission avoidance mechanism. We prove a logarithmic regret bound for\nour strategy with respect to optimal mixtures of the base algorithms. Numerical\nexamples validate the viability of our method and show significant improvement\nover the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 08:38:34 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 14:20:01 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Uziel", "Guy", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1605.00937", "submitter": "Arthur Mensch", "authors": "Arthur Mensch (PARIETAL), Julien Mairal (LEAR), Bertrand Thirion\n  (PARIETAL), Ga\\\"el Varoquaux (PARIETAL)", "title": "Dictionary Learning for Massive Matrix Factorization", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2016, pp 1737-1746", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix factorization is a popular tool to obtain interpretable data\ndecompositions, which are also effective to perform data completion or\ndenoising. Its applicability to large datasets has been addressed with online\nand randomized methods, that reduce the complexity in one of the matrix\ndimension, but not in both of them. In this paper, we tackle very large\nmatrices in both dimensions. We propose a new factoriza-tion method that scales\ngracefully to terabyte-scale datasets, that could not be processed by previous\nalgorithms in a reasonable amount of time. We demonstrate the efficiency of our\napproach on massive functional Magnetic Resonance Imaging (fMRI) data, and on\nmatrix completion problems for recommender systems, where we obtain significant\nspeed-ups compared to state-of-the art coordinate descent methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 15:05:32 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 06:33:22 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Mensch", "Arthur", "", "PARIETAL"], ["Mairal", "Julien", "", "LEAR"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"]]}, {"id": "1605.00959", "submitter": "Ahmed Alaa", "authors": "Ahmed M. Alaa, Jinsung Yoon, Scott Hu, Mihaela van der Schaar", "title": "Personalized Risk Scoring for Critical Care Patients using Mixtures of\n  Gaussian Process Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a personalized real time risk scoring algorithm that provides\ntimely and granular assessments for the clinical acuity of ward patients based\non their (temporal) lab tests and vital signs. Heterogeneity of the patients\npopulation is captured via a hierarchical latent class model. The proposed\nalgorithm aims to discover the number of latent classes in the patients\npopulation, and train a mixture of Gaussian Process (GP) experts, where each\nexpert models the physiological data streams associated with a specific class.\nSelf-taught transfer learning is used to transfer the knowledge of latent\nclasses learned from the domain of clinically stable patients to the domain of\nclinically deteriorating patients. For new patients, the posterior beliefs of\nall GP experts about the patient's clinical status given her physiological data\nstream are computed, and a personalized risk score is evaluated as a weighted\naverage of those beliefs, where the weights are learned from the patient's\nhospital admission information. Experiments on a heterogeneous cohort of 6,313\npatients admitted to Ronald Regan UCLA medical center show that our risk score\noutperforms the currently deployed risk scores, such as MEWS and Rothman\nscores.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 15:54:33 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Alaa", "Ahmed M.", ""], ["Yoon", "Jinsung", ""], ["Hu", "Scott", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1605.01029", "submitter": "Ahmet Anil Pala", "authors": "Ahmet Anil Pala", "title": "Online Machine Learning Techniques for Predicting Operator Performance", "comments": "Master Thesis defended at TU Berlin in Summer 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis explores a number of online machine learning algorithms. From a\ntheoret- ical perspective, it assesses their employability for a particular\nfunction approximation problem where the analytical models fall short.\nFurthermore, it discusses the applica- tion of theoretically suitable learning\nalgorithms to the function approximation problem at hand through an efficient\nimplementation that exploits various computational and mathematical shortcuts.\nFinally, this thesis work evaluates the implemented learning algorithms\naccording to various evaluation criteria through rigorous testing.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 19:16:12 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Pala", "Ahmet Anil", ""]]}, {"id": "1605.01046", "submitter": "Pavel Chebotarev", "authors": "Vladimir Ivashkin and Pavel Chebotarev", "title": "Do logarithmic proximity measures outperform plain ones in graph\n  clustering?", "comments": "11 pages, 5 tables, 9 figures. Accepted for publication in the\n  Proceedings of 6th International Conference on Network Analysis, May 26-28,\n  2016, Nizhny Novgorod, Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a number of graph kernels and proximity measures including\ncommute time kernel, regularized Laplacian kernel, heat kernel, exponential\ndiffusion kernel (also called \"communicability\"), etc., and the corresponding\ndistances as applied to clustering nodes in random graphs and several\nwell-known datasets. The model of generating random graphs involves edge\nprobabilities for the pairs of nodes that belong to the same class or different\npredefined classes of nodes. It turns out that in most cases, logarithmic\nmeasures (i.e., measures resulting after taking logarithm of the proximities)\nperform better while distinguishing underlying classes than the \"plain\"\nmeasures. A comparison in terms of reject curves of inter-class and intra-class\ndistances confirms this conclusion. A similar conclusion can be made for\nseveral well-known datasets. A possible origin of this effect is that most\nkernels have a multiplicative nature, while the nature of distances used in\ncluster algorithms is an additive one (cf. the triangle inequality). The\nlogarithmic transformation is a tool to transform the first nature to the\nsecond one. Moreover, some distances corresponding to the logarithmic measures\npossess a meaningful cutpoint additivity property. In our experiments, the\nleader is usually the logarithmic Communicability measure. However, we indicate\nsome more complicated cases in which other measures, typically, Communicability\nand plain Walk, can be the winners.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 19:52:48 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 20:01:08 GMT"}, {"version": "v3", "created": "Sat, 18 Feb 2017 09:04:02 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Ivashkin", "Vladimir", ""], ["Chebotarev", "Pavel", ""]]}, {"id": "1605.01107", "submitter": "Alec Koppel", "authors": "Alec Koppel, Garrett Warnell, Ethan Stump, Alejandro Ribeiro", "title": "Decentralized Dynamic Discriminative Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider discriminative dictionary learning in a distributed online\nsetting, where a network of agents aims to learn a common set of dictionary\nelements of a feature space and model parameters while sequentially receiving\nobservations. We formulate this problem as a distributed stochastic program\nwith a non-convex objective and present a block variant of the Arrow-Hurwicz\nsaddle point algorithm to solve it. Using Lagrange multipliers to penalize the\ndiscrepancy between them, only neighboring nodes exchange model information. We\nshow that decisions made with this saddle point algorithm asymptotically\nachieve a first-order stationarity condition on average.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 22:37:05 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Koppel", "Alec", ""], ["Warnell", "Garrett", ""], ["Stump", "Ethan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1605.01116", "submitter": "Truyen Tran", "authors": "Thuong Nguyen, Truyen Tran, Shivapratap Gopakumar, Dinh Phung, Svetha\n  Venkatesh", "title": "An evaluation of randomized machine learning methods for redundant data:\n  Predicting short and medium-term suicide risk from administrative records and\n  risk assessments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of suicide risk in mental health patients remains an open\nproblem. Existing methods including clinician judgments have acceptable\nsensitivity, but yield many false positives. Exploiting administrative data has\na great potential, but the data has high dimensionality and redundancies in the\nrecording processes. We investigate the efficacy of three most effective\nrandomized machine learning techniques random forests, gradient boosting\nmachines, and deep neural nets with dropout in predicting suicide risk. Using a\ncohort of mental health patients from a regional Australian hospital, we\ncompare the predictive performance with popular traditional approaches\nclinician judgments based on a checklist, sparse logistic regression and\ndecision trees. The randomized methods demonstrated robustness against data\nredundancies and superior predictive performance on AUC and F-measure.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 23:46:48 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Nguyen", "Thuong", ""], ["Tran", "Truyen", ""], ["Gopakumar", "Shivapratap", ""], ["Phung", "Dinh", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1605.01133", "submitter": "Jack Lanchantin", "authors": "Jack Lanchantin, Ritambhara Singh, Zeming Lin, Yanjun Qi", "title": "Deep Motif: Visualizing Genomic Sequence Classifications", "comments": "5 pages; 3 figures ; deep learning ; genomic sequence classification;\n  understanding deep models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies a deep convolutional/highway MLP framework to classify\ngenomic sequences on the transcription factor binding site task. To make the\nmodel understandable, we propose an optimization driven strategy to extract\n\"motifs\", or symbolic patterns which visualize the positive class learned by\nthe network. We show that our system, Deep Motif (DeMo), extracts motifs that\nare similar to, and in some cases outperform the current well known motifs. In\naddition, we find that a deeper model consisting of multiple convolutional and\nhighway layers can outperform a single convolutional and fully connected layer\nin the previous state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 03:33:48 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 14:17:51 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Lanchantin", "Jack", ""], ["Singh", "Ritambhara", ""], ["Lin", "Zeming", ""], ["Qi", "Yanjun", ""]]}, {"id": "1605.01185", "submitter": "Nandan Sudarsanam", "authors": "Nandan Sudarsanam and Balaraman Ravindran", "title": "Linear Bandit algorithms using the Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents two new algorithms for solving linear stochastic bandit\nproblems. The proposed methods use an approach from non-parametric statistics\ncalled bootstrapping to create confidence bounds. This is achieved without\nmaking any assumptions about the distribution of noise in the underlying\nsystem. We present the X-Random and X-Fixed bootstrap bandits which correspond\nto the two well-known approaches for conducting bootstraps on models, in the\nliterature. The proposed methods are compared to other popular solutions for\nlinear stochastic bandit problems, namely, OFUL, LinUCB and Thompson Sampling.\nThe comparisons are carried out using a simulation study on a hierarchical\nprobability meta-model, built from published data of experiments, which are run\non real systems. The model representing the response surfaces is conceptualized\nas a Bayesian Network which is presented with varying degrees of noise for the\nsimulations. One of the proposed methods, X-Random bootstrap, performs better\nthan the baselines in-terms of cumulative regret across various degrees of\nnoise and different number of trials. In certain settings the cumulative regret\nof this method is less than half of the best baseline. The X-Fixed bootstrap\nperforms comparably in most situations and particularly well when the number of\ntrials is low. The study concludes that these algorithms could be a preferred\nalternative for solving linear bandit problems, especially when the\ndistribution of the noise in the system is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 08:52:10 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Sudarsanam", "Nandan", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.01278", "submitter": "Adrian \\v{S}o\\v{s}i\\'c", "authors": "Adrian \\v{S}o\\v{s}i\\'c, Abdelhak M. Zoubir, Heinz Koeppl", "title": "A Bayesian Approach to Policy Recognition and State Representation\n  Learning", "comments": "17 pages, 8 figures; ### Version 4 ### to appear in IEEE Transactions\n  on Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2017.2711024", "report-no": null, "categories": "stat.ML cs.LG cs.SY math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstration (LfD) is the process of building behavioral\nmodels of a task from demonstrations provided by an expert. These models can be\nused e.g. for system control by generalizing the expert demonstrations to\npreviously unencountered situations. Most LfD methods, however, make strong\nassumptions about the expert behavior, e.g. they assume the existence of a\ndeterministic optimal ground truth policy or require direct monitoring of the\nexpert's controls, which limits their practical use as part of a general system\nidentification framework. In this work, we consider the LfD problem in a more\ngeneral setting where we allow for arbitrary stochastic expert policies,\nwithout reasoning about the optimality of the demonstrations. Following a\nBayesian methodology, we model the full posterior distribution of possible\nexpert controllers that explain the provided demonstration data. Moreover, we\nshow that our methodology can be applied in a nonparametric context to infer\nthe complexity of the state representation used by the expert, and to learn\ntask-appropriate partitionings of the system state space.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 13:44:53 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 15:05:59 GMT"}, {"version": "v3", "created": "Fri, 19 May 2017 14:13:55 GMT"}, {"version": "v4", "created": "Fri, 4 Aug 2017 12:50:01 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["\u0160o\u0161i\u0107", "Adrian", ""], ["Zoubir", "Abdelhak M.", ""], ["Koeppl", "Heinz", ""]]}, {"id": "1605.01288", "submitter": "Nishant Mehta", "authors": "Nishant A. Mehta", "title": "Fast rates with high probability in exp-concave statistical learning", "comments": "added results on model selection aggregation (Section 7)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the statistical learning setting with a bounded\nexp-concave loss in $d$ dimensions that obtains excess risk $O(d\n\\log(1/\\delta)/n)$ with probability at least $1 - \\delta$. The core technique\nis to boost the confidence of recent in-expectation $O(d/n)$ excess risk bounds\nfor empirical risk minimization (ERM), without sacrificing the rate, by\nleveraging a Bernstein condition which holds due to exp-concavity. We also show\nthat with probability $1 - \\delta$ the standard ERM method obtains excess risk\n$O(d (\\log(n) + \\log(1/\\delta))/n)$. We further show that a regret bound for\nany online learner in this setting translates to a high probability excess risk\nbound for the corresponding online-to-batch conversion of the online learner.\nLastly, we present two high probability bounds for the exp-concave model\nselection aggregation problem that are quantile-adaptive in a certain sense.\nThe first bound is a purely exponential weights type algorithm, obtains a\nnearly optimal rate, and has no explicit dependence on the Lipschitz continuity\nof the loss. The second bound requires Lipschitz continuity but obtains the\noptimal rate.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 14:22:59 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 09:15:28 GMT"}, {"version": "v3", "created": "Thu, 18 Aug 2016 13:52:47 GMT"}, {"version": "v4", "created": "Fri, 14 Oct 2016 15:24:08 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Mehta", "Nishant A.", ""]]}, {"id": "1605.01329", "submitter": "Eunjoon Cho", "authors": "Eunjoon Cho, Bowon Lee, Ronald Schafer, Bernard Widrow", "title": "Single Channel Speech Enhancement Using Outlier Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distortion of the underlying speech is a common problem for single-channel\nspeech enhancement algorithms, and hinders such methods from being used more\nextensively. A dictionary based speech enhancement method that emphasizes\npreserving the underlying speech is proposed. Spectral patches of clean speech\nare sampled and clustered to train a dictionary. Given a noisy speech spectral\npatch, the best matching dictionary entry is selected and used to estimate the\nnoise power at each time-frequency bin. The noise estimation step is formulated\nas an outlier detection problem, where the noise at each bin is assumed present\nonly if it is an outlier to the corresponding bin of the best matching\ndictionary entry. This framework assigns higher priority in removing spectral\nelements that strongly deviate from a typical spoken unit stored in the trained\ndictionary. Even without the aid of a separate noise model, this method can\nachieve significant noise reduction for various non-stationary noises, while\neffectively preserving the underlying speech in more challenging noisy\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 16:16:12 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Cho", "Eunjoon", ""], ["Lee", "Bowon", ""], ["Schafer", "Ronald", ""], ["Widrow", "Bernard", ""]]}, {"id": "1605.01335", "submitter": "Jakub Sygnowski", "authors": "Jakub Sygnowski and Henryk Michalewski", "title": "Learning from the memory of Atari 2600", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train a number of neural networks to play games Bowling, Breakout and\nSeaquest using information stored in the memory of a video game console Atari\n2600. We consider four models of neural networks which differ in size and\narchitecture: two networks which use only information contained in the RAM and\ntwo mixed networks which use both information in the RAM and information from\nthe screen. As the benchmark we used the convolutional model proposed in NIPS\nand received comparable results in all considered games. Quite surprisingly, in\nthe case of Seaquest we were able to train RAM-only agents which behave better\nthan the benchmark screen-only agent. Mixing screen and RAM did not lead to an\nimproved performance comparing to screen-only and RAM-only agents.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 16:23:34 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Sygnowski", "Jakub", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1605.01369", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Abhinav Vishnu, Chris Ding", "title": "Accelerating Deep Learning with Shrinkage and Recall", "comments": "The 22nd IEEE International Conference on Parallel and Distributed\n  Systems (ICPADS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is a very powerful machine learning model. Deep Learning trains\na large number of parameters for multiple layers and is very slow when data is\nin large scale and the architecture size is large. Inspired from the shrinking\ntechnique used in accelerating computation of Support Vector Machines (SVM)\nalgorithm and screening technique used in LASSO, we propose a shrinking Deep\nLearning with recall (sDLr) approach to speed up deep learning computation. We\nexperiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network\n(DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data\nsets. Results show that the speedup using shrinking Deep Learning with recall\n(sDLr) can reach more than 2.0 while still giving competitive classification\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 18:17:37 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 19:27:39 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Zheng", "Shuai", ""], ["Vishnu", "Abhinav", ""], ["Ding", "Chris", ""]]}, {"id": "1605.01451", "submitter": "Panayotis Mertikopoulos", "authors": "Panayotis Mertikopoulos and Aris L. Moustakas and Anna Tzanakaki", "title": "Boltzmann meets Nash: Energy-efficient routing in optical networks under\n  uncertainty", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the massive deployment of power-hungry data centers for service\nprovisioning, we examine the problem of routing in optical networks with the\naim of minimizing traffic-driven power consumption. To tackle this issue,\nrouting must take into account energy efficiency as well as capacity\nconsiderations; moreover, in rapidly-varying network environments, this must be\naccomplished in a real-time, distributed manner that remains robust in the\npresence of random disturbances and noise. In view of this, we derive a pricing\nscheme whose Nash equilibria coincide with the network's socially optimum\nstates, and we propose a distributed learning method based on the Boltzmann\ndistribution of statistical mechanics. Using tools from stochastic calculus, we\nshow that the resulting Boltzmann routing scheme exhibits remarkable\nconvergence properties under uncertainty: specifically, the long-term average\nof the network's power consumption converges within $\\varepsilon$ of its\nminimum value in time which is at most $\\tilde O(1/\\varepsilon^2)$,\nirrespective of the fluctuations' magnitude; additionally, if the network\nadmits a strict, non-mixing optimum state, the algorithm converges to it -\nagain, no matter the noise level. Our analysis is supplemented by extensive\nnumerical simulations which show that Boltzmann routing can lead to a\nsignificant decrease in power consumption over basic, shortest-path routing\nschemes in realistic network conditions.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 22:55:17 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Mertikopoulos", "Panayotis", ""], ["Moustakas", "Aris L.", ""], ["Tzanakaki", "Anna", ""]]}, {"id": "1605.01569", "submitter": "Matthias Plappert", "authors": "Matthias Plappert", "title": "Classification of Human Whole-Body Motion using Hidden Markov Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Human motion plays an important role in many fields. Large databases exist\nthat store and make available recordings of human motions. However, annotating\neach motion with multiple labels is a cumbersome and error-prone process. This\nbachelor's thesis presents different approaches to solve the multi-label\nclassification problem using Hidden Markov Models (HMMs). First, different\nfeatures that can be directly obtained from the raw data are introduced. Next,\nadditional features are derived to improve classification performance. These\nfeatures are then used to perform the multi-label classification using two\ndifferent approaches. The first approach simply transforms the multi-label\nproblem into a multi-class problem. The second, novel approach solves the same\nproblem without the need to construct a transformation by predicting the labels\ndirectly from the likelihood scores. The second approach scales linearly with\nthe number of labels whereas the first approach is subject to combinatorial\nexplosion. All aspects of the classification process are evaluated on a data\nset that consists of 454 motions. System 1 achieves an accuracy of 98.02% and\nsystem 2 an accuracy of 93.39% on the test set.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 12:38:18 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Plappert", "Matthias", ""]]}, {"id": "1605.01623", "submitter": "Bo Han", "authors": "Bo Han and Ivor W. Tsang and Ling Chen", "title": "On the Convergence of A Family of Robust Losses for Stochastic Gradient\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence of Stochastic Gradient Descent (SGD) using convex loss\nfunctions has been widely studied. However, vanilla SGD methods using convex\nlosses cannot perform well with noisy labels, which adversely affect the update\nof the primal variable in SGD methods. Unfortunately, noisy labels are\nubiquitous in real world applications such as crowdsourcing. To handle noisy\nlabels, in this paper, we present a family of robust losses for SGD methods. By\nemploying our robust losses, SGD methods successfully reduce negative effects\ncaused by noisy labels on each update of the primal variable. We not only\nreveal that the convergence rate is O(1/T) for SGD methods using robust losses,\nbut also provide the robustness analysis on two representative robust losses.\nComprehensive experimental results on six real-world datasets show that SGD\nmethods using robust losses are obviously more robust than other baseline\nmethods in most situations with fast convergence.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 15:22:46 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Han", "Bo", ""], ["Tsang", "Ivor W.", ""], ["Chen", "Ling", ""]]}, {"id": "1605.01636", "submitter": "Bo Xin", "authors": "Bo Xin, Yizhou Wang, Wen Gao and David Wipf", "title": "Maximal Sparsity with Deep Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterations of many sparse estimation algorithms are comprised of a fixed\nlinear filter cascaded with a thresholding nonlinearity, which collectively\nresemble a typical neural network layer. Consequently, a lengthy sequence of\nalgorithm iterations can be viewed as a deep network with shared, hand-crafted\nlayer weights. It is therefore quite natural to examine the degree to which a\nlearned network model might act as a viable surrogate for traditional sparse\nestimation in domains where ample training data is available. While the\npossibility of a reduced computational budget is readily apparent when a\nceiling is imposed on the number of layers, our work primarily focuses on\nestimation accuracy. In particular, it is well-known that when a signal\ndictionary has coherent columns, as quantified by a large RIP constant, then\nmost tractable iterative algorithms are unable to find maximally sparse\nrepresentations. In contrast, we demonstrate both theoretically and empirically\nthe potential for a trained deep network to recover minimal $\\ell_0$-norm\nrepresentations in regimes where existing methods fail. The resulting system is\ndeployed on a practical photometric stereo estimation problem, where the goal\nis to remove sparse outliers that can disrupt the estimation of surface normals\nfrom a 3D scene.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 15:58:55 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 05:38:46 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Xin", "Bo", ""], ["Wang", "Yizhou", ""], ["Gao", "Wen", ""], ["Wipf", "David", ""]]}, {"id": "1605.01656", "submitter": "Jie Shen", "authors": "Jie Shen and Ping Li", "title": "A Tight Bound of Hard Thresholding", "comments": "V1 was submitted to COLT 2016. V2 fixes minor flaws, adds extra\n  experiments and discusses time complexity, V3 has been accepted to JMLR", "journal-ref": "Journal of Machine Learning Research 18(208): 1-42, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.NA math.IT math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the hard thresholding operator which sets all\nbut the $k$ largest absolute elements of a vector to zero. We establish a {\\em\ntight} bound to quantitatively characterize the deviation of the thresholded\nsolution from a given signal. Our theoretical result is universal in the sense\nthat it holds for all choices of parameters, and the underlying analysis\ndepends only on fundamental arguments in mathematical optimization. We discuss\nthe implications for two domains:\n  Compressed Sensing. On account of the crucial estimate, we bridge the\nconnection between the restricted isometry property (RIP) and the sparsity\nparameter for a vast volume of hard thresholding based algorithms, which\nrenders an improvement on the RIP condition especially when the true sparsity\nis unknown. This suggests that in essence, many more kinds of sensing matrices\nor fewer measurements are admissible for the data acquisition procedure.\n  Machine Learning. In terms of large-scale machine learning, a significant yet\nchallenging problem is learning accurate sparse models in an efficient manner.\nIn stark contrast to prior work that attempted the $\\ell_1$-relaxation for\npromoting sparsity, we present a novel stochastic algorithm which performs hard\nthresholding in each iteration, hence ensuring such parsimonious solutions.\nEquipped with the developed bound, we prove the {\\em global linear convergence}\nfor a number of prevalent statistical models under mild assumptions, even\nthough the problem turns out to be non-convex.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 17:10:34 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 03:04:09 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 17:58:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Shen", "Jie", ""], ["Li", "Ping", ""]]}, {"id": "1605.01677", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama, Junya Honda, Hiroshi Nakagawa", "title": "Copeland Dueling Bandit Problem: Regret Lower Bound, Optimal Algorithm,\n  and Computationally Efficient Algorithm", "comments": "To appear in ICML2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the K-armed dueling bandit problem, a variation of the standard\nstochastic bandit problem where the feedback is limited to relative comparisons\nof a pair of arms. The hardness of recommending Copeland winners, the arms that\nbeat the greatest number of other arms, is characterized by deriving an\nasymptotic regret bound. We propose Copeland Winners Relative Minimum Empirical\nDivergence (CW-RMED) and derive an asymptotically optimal regret bound for it.\nHowever, it is not known whether the algorithm can be efficiently computed or\nnot. To address this issue, we devise an efficient version (ECW-RMED) and\nderive its asymptotic regret bound. Experimental comparisons of dueling bandit\nalgorithms show that ECW-RMED significantly outperforms existing ones.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 18:08:13 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 12:42:15 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Komiyama", "Junpei", ""], ["Honda", "Junya", ""], ["Nakagawa", "Hiroshi", ""]]}, {"id": "1605.01703", "submitter": "Indre Zliobaite", "authors": "Indre Zliobaite and Nikolaj Tatti", "title": "A note on adjusting $R^2$ for using with cross-validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to adjust the coefficient of determination ($R^2$) when used for\nmeasuring predictive accuracy via leave-one-out cross-validation.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:34:08 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Zliobaite", "Indre", ""], ["Tatti", "Nikolaj", ""]]}, {"id": "1605.01713", "submitter": "Avanti Shrikumar", "authors": "Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, Anshul Kundaje", "title": "Not Just a Black Box: Learning Important Features Through Propagating\n  Activation Differences", "comments": "6 pages, 3 figures, this is an older version; see\n  https://arxiv.org/abs/1704.02685 for the newer version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Note: This paper describes an older version of DeepLIFT. See\nhttps://arxiv.org/abs/1704.02685 for the newer version. Original abstract\nfollows: The purported \"black box\" nature of neural networks is a barrier to\nadoption in applications where interpretability is essential. Here we present\nDeepLIFT (Learning Important FeaTures), an efficient and effective method for\ncomputing importance scores in a neural network. DeepLIFT compares the\nactivation of each neuron to its 'reference activation' and assigns\ncontribution scores according to the difference. We apply DeepLIFT to models\ntrained on natural images and genomic data, and show significant advantages\nover gradient-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:52:32 GMT"}, {"version": "v2", "created": "Sun, 8 May 2016 21:34:42 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 15:58:48 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Shrikumar", "Avanti", ""], ["Greenside", "Peyton", ""], ["Shcherbina", "Anna", ""], ["Kundaje", "Anshul", ""]]}, {"id": "1605.01749", "submitter": "Paul Bertens", "authors": "Paul Bertens", "title": "Rank Ordered Autoencoders", "comments": "Personal project, 14 pages, 9 figures. For source code see:\n  https://github.com/paulbertens", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for the unsupervised learning of sparse representations using\nautoencoders is proposed and implemented by ordering the output of the hidden\nunits by their activation value and progressively reconstructing the input in\nthis order. This can be done efficiently in parallel with the use of cumulative\nsums and sorting only slightly increasing the computational costs. Minimizing\nthe difference of this progressive reconstruction with respect to the input can\nbe seen as minimizing the number of active output units required for the\nreconstruction of the input. The model thus learns to reconstruct optimally\nusing the least number of active output units. This leads to high sparsity\nwithout the need for extra hyperparameters, the amount of sparsity is instead\nimplicitly learned by minimizing this progressive reconstruction error. Results\nof the trained model are given for patches of the CIFAR10 dataset, showing\nrapid convergence of features and extremely sparse output activations while\nmaintaining a minimal reconstruction error and showing extreme robustness to\noverfitting. Additionally the reconstruction as function of number of active\nunits is presented which shows the autoencoder learns a rank order code over\nthe input where the highest ranked units correspond to the highest decrease in\nreconstruction error.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 20:33:38 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Bertens", "Paul", ""]]}, {"id": "1605.01755", "submitter": "Yin Xian", "authors": "Yin Xian, Andrew Thompson, Xiaobai Sun, Douglas Nowacek, and Loren\n  Nolte", "title": "DCTNet and PCANet for acoustic signal feature extraction", "comments": "22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of DCTNet, an efficient approximation and alternative to\nPCANet, for acoustic signal classification. In PCANet, the eigenfunctions of\nthe local sample covariance matrix (PCA) are used as filterbanks for\nconvolution and feature extraction. When the eigenfunctions are well\napproximated by the Discrete Cosine Transform (DCT) functions, each layer of of\nPCANet and DCTNet is essentially a time-frequency representation. We relate\nDCTNet to spectral feature representation methods, such as the the short time\nFourier transform (STFT), spectrogram and linear frequency spectral\ncoefficients (LFSC). Experimental results on whale vocalization data show that\nDCTNet improves classification rate, demonstrating DCTNet's applicability to\nsignal processing problems such as underwater acoustics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 22:21:01 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Xian", "Yin", ""], ["Thompson", "Andrew", ""], ["Sun", "Xiaobai", ""], ["Nowacek", "Douglas", ""], ["Nolte", "Loren", ""]]}, {"id": "1605.01832", "submitter": "Hanxiao Liu", "authors": "Hanxiao Liu, Yiming Yang", "title": "Cross-Graph Learning of Multi-Relational Associations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-graph Relational Learning (CGRL) refers to the problem of predicting\nthe strengths or labels of multi-relational tuples of heterogeneous object\ntypes, through the joint inference over multiple graphs which specify the\ninternal connections among each type of objects. CGRL is an open challenge in\nmachine learning due to the daunting number of all possible tuples to deal with\nwhen the numbers of nodes in multiple graphs are large, and because the labeled\ntraining instances are extremely sparse as typical. Existing methods such as\ntensor factorization or tensor-kernel machines do not work well because of the\nlack of convex formulation for the optimization of CGRL models, the poor\nscalability of the algorithms in handling combinatorial numbers of tuples,\nand/or the non-transductive nature of the learning methods which limits their\nability to leverage unlabeled data in training. This paper proposes a novel\nframework which formulates CGRL as a convex optimization problem, enables\ntransductive learning using both labeled and unlabeled tuples, and offers a\nscalable algorithm that guarantees the optimal solution and enjoys a linear\ntime complexity with respect to the sizes of input graphs. In our experiments\nwith a subset of DBLP publication records and an Enzyme multi-source dataset,\nthe proposed method successfully scaled to the large cross-graph inference\nproblem, and outperformed other representative approaches significantly.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 06:15:20 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Liu", "Hanxiao", ""], ["Yang", "Yiming", ""]]}, {"id": "1605.01838", "submitter": "Huichao Gong", "authors": "Feng Wang and Huichao Gong and Gaochao liu and Meijing Li and Chuangye\n  Yan and Tian Xia and Xueming Li and Jianyang Zeng", "title": "DeepPicker: a Deep Learning Approach for Fully Automated Particle\n  Picking in Cryo-EM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle picking is a time-consuming step in single-particle analysis and\noften requires significant interventions from users, which has become a\nbottleneck for future automated electron cryo-microscopy (cryo-EM). Here we\nreport a deep learning framework, called DeepPicker, to address this problem\nand fill the current gaps toward a fully automated cryo-EM pipeline. DeepPicker\nemploys a novel cross-molecule training strategy to capture common features of\nparticles from previously-analyzed micrographs, and thus does not require any\nhuman intervention during particle picking. Tests on the recently-published\ncryo-EM data of three complexes have demonstrated that our deep learning based\nscheme can successfully accomplish the human-level particle picking process and\nidentify a sufficient number of particles that are comparable to those manually\nby human experts. These results indicate that DeepPicker can provide a\npractically useful tool to significantly reduce the time and manual effort\nspent in single-particle analysis and thus greatly facilitate high-resolution\ncryo-EM structure determination.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 06:51:02 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Wang", "Feng", ""], ["Gong", "Huichao", ""], ["liu", "Gaochao", ""], ["Li", "Meijing", ""], ["Yan", "Chuangye", ""], ["Xia", "Tian", ""], ["Li", "Xueming", ""], ["Zeng", "Jianyang", ""]]}, {"id": "1605.01939", "submitter": "Elena Mocanu", "authors": "Elena Mocanu, Phuong H. Nguyen, Madeleine Gibescu", "title": "Energy Disaggregation for Real-Time Building Flexibility Detection", "comments": "To appear in IEEE PES General Meeting, 2016, Boston, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy is a limited resource which has to be managed wisely, taking into\naccount both supply-demand matching and capacity constraints in the\ndistribution grid. One aspect of the smart energy management at the building\nlevel is given by the problem of real-time detection of flexible demand\navailable. In this paper we propose the use of energy disaggregation techniques\nto perform this task. Firstly, we investigate the use of existing\nclassification methods to perform energy disaggregation. A comparison is\nperformed between four classifiers, namely Naive Bayes, k-Nearest Neighbors,\nSupport Vector Machine and AdaBoost. Secondly, we propose the use of Restricted\nBoltzmann Machine to automatically perform feature extraction. The extracted\nfeatures are then used as inputs to the four classifiers and consequently shown\nto improve their accuracy. The efficiency of our approach is demonstrated on a\nreal database consisting of detailed appliance-level measurements with high\ntemporal resolution, which has been used for energy disaggregation in previous\nstudies, namely the REDD. The results show robustness and good generalization\ncapabilities to newly presented buildings with at least 96% accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 13:52:45 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Mocanu", "Elena", ""], ["Nguyen", "Phuong H.", ""], ["Gibescu", "Madeleine", ""]]}, {"id": "1605.01950", "submitter": "Alonso Marco", "authors": "Alonso Marco, Philipp Hennig, Jeannette Bohg, Stefan Schaal and\n  Sebastian Trimpe", "title": "Automatic LQR Tuning Based on Gaussian Process Global Optimization", "comments": "8 pages, 5 figures, to appear in IEEE 2016 International Conference\n  on Robotics and Automation. Video demonstration of the experiments available\n  at https://am.is.tuebingen.mpg.de/publications/marco_icra_2016", "journal-ref": null, "doi": "10.1109/ICRA.2016.7487144", "report-no": null, "categories": "cs.RO cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an automatic controller tuning framework based on linear\noptimal control combined with Bayesian optimization. With this framework, an\ninitial set of controller gains is automatically improved according to a\npre-defined performance objective evaluated from experimental data. The\nunderlying Bayesian optimization algorithm is Entropy Search, which represents\nthe latent objective as a Gaussian process and constructs an explicit belief\nover the location of the objective minimum. This is used to maximize the\ninformation gain from each experimental evaluation. Thus, this framework shall\nyield improved controllers with fewer evaluations compared to alternative\napproaches. A seven-degree-of-freedom robot arm balancing an inverted pole is\nused as the experimental demonstrator. Results of a two- and four-dimensional\ntuning problems highlight the method's potential for automatic controller\ntuning on robotic platforms.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 14:28:54 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Marco", "Alonso", ""], ["Hennig", "Philipp", ""], ["Bohg", "Jeannette", ""], ["Schaal", "Stefan", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1605.02026", "submitter": "Thomas Goldstein", "authors": "Gavin Taylor, Ryan Burmeister, Zheng Xu, Bharat Singh, Ankit Patel,\n  Tom Goldstein", "title": "Training Neural Networks Without Gradients: A Scalable ADMM Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing importance of large network models and enormous training\ndatasets, GPUs have become increasingly necessary to train neural networks.\nThis is largely because conventional optimization algorithms rely on stochastic\ngradient methods that don't scale well to large numbers of cores in a cluster\nsetting. Furthermore, the convergence of all gradient methods, including batch\nmethods, suffers from common problems like saturation effects, poor\nconditioning, and saddle points. This paper explores an unconventional training\nmethod that uses alternating direction methods and Bregman iteration to train\nnetworks without gradient descent steps. The proposed method reduces the\nnetwork training problem to a sequence of minimization sub-steps that can each\nbe solved globally in closed form. The proposed method is advantageous because\nit avoids many of the caveats that make gradient methods slow on highly\nnon-convex problems. The method exhibits strong scaling in the distributed\nsetting, yielding linear speedups even when split over thousands of cores.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 18:38:45 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Taylor", "Gavin", ""], ["Burmeister", "Ryan", ""], ["Xu", "Zheng", ""], ["Singh", "Bharat", ""], ["Patel", "Ankit", ""], ["Goldstein", "Tom", ""]]}, {"id": "1605.02046", "submitter": "Mahdi Jafari Siavoshani", "authors": "Farzin Haddadpour, Mahdi Jafari Siavoshani, Morteza Noshad", "title": "Low-Complexity Stochastic Generalized Belief Propagation", "comments": "18 pages, 11 figures, a shorter version of this paper was accepted in\n  ISIT'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized belief propagation (GBP), introduced by Yedidia et al., is an\nextension of the belief propagation (BP) algorithm, which is widely used in\ndifferent problems involved in calculating exact or approximate marginals of\nprobability distributions. In many problems, it has been observed that the\naccuracy of GBP considerably outperforms that of BP. However, because in\ngeneral the computational complexity of GBP is higher than BP, its application\nis limited in practice.\n  In this paper, we introduce a stochastic version of GBP called stochastic\ngeneralized belief propagation (SGBP) that can be considered as an extension to\nthe stochastic BP (SBP) algorithm introduced by Noorshams et al. They have\nshown that SBP reduces the complexity per iteration of BP by an order of\nmagnitude in alphabet size. In contrast to SBP, SGBP can reduce the computation\ncomplexity if certain topological conditions are met by the region graph\nassociated to a graphical model. However, this reduction can be larger than\nonly one order of magnitude in alphabet size. In this paper, we characterize\nthese conditions and the amount of computation gain that we can obtain by using\nSGBP. Finally, using similar proof techniques employed by Noorshams et al., for\ngeneral graphical models satisfy contraction conditions, we prove the\nasymptotic convergence of SGBP to the unique GBP fixed point, as well as\nproviding non-asymptotic upper bounds on the mean square error and on the high\nprobability error.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 19:17:33 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Haddadpour", "Farzin", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Noshad", "Morteza", ""]]}, {"id": "1605.02065", "submitter": "Thomas Steinke", "authors": "Mark Bun, Thomas Steinke", "title": "Concentrated Differential Privacy: Simplifications, Extensions, and\n  Lower Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Concentrated differential privacy\" was recently introduced by Dwork and\nRothblum as a relaxation of differential privacy, which permits sharper\nanalyses of many privacy-preserving computations. We present an alternative\nformulation of the concept of concentrated differential privacy in terms of the\nRenyi divergence between the distributions obtained by running an algorithm on\nneighboring inputs. With this reformulation in hand, we prove sharper\nquantitative results, establish lower bounds, and raise a few new questions. We\nalso unify this approach with approximate differential privacy by giving an\nappropriate definition of \"approximate concentrated differential privacy.\"\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 19:57:35 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Bun", "Mark", ""], ["Steinke", "Thomas", ""]]}, {"id": "1605.02077", "submitter": "Maxim Rabinovich", "authors": "Maxim Rabinovich, Aaditya Ramdas, Michael I. Jordan, and Martin J.\n  Wainwright", "title": "Function-Specific Mixing Times and Concentration Away from Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slow mixing is the central hurdle when working with Markov chains, especially\nthose used for Monte Carlo approximations (MCMC). In many applications, it is\nonly of interest to estimate the stationary expectations of a small set of\nfunctions, and so the usual definition of mixing based on total variation\nconvergence may be too conservative. Accordingly, we introduce\nfunction-specific analogs of mixing times and spectral gaps, and use them to\nprove Hoeffding-like function-specific concentration inequalities. These\nresults show that it is possible for empirical expectations of functions to\nconcentrate long before the underlying chain has mixed in the classical sense,\nand we show that the concentration rates we achieve are optimal up to\nconstants. We use our techniques to derive confidence intervals that are\nsharper than those implied by both classical Markov chain Hoeffding bounds and\nBerry-Esseen-corrected CLT bounds. For applications that require testing,\nrather than point estimation, we show similar improvements over recent\nsequential testing results for MCMC. We conclude by applying our framework to\nreal data examples of MCMC, providing evidence that our theory is both accurate\nand relevant to practice.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 20:00:06 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 20:53:08 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Rabinovich", "Maxim", ""], ["Ramdas", "Aaditya", ""], ["Jordan", "Michael I.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1605.02097", "submitter": "Wojciech Ja\\'skowski", "authors": "Micha{\\l} Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek and\n  Wojciech Ja\\'skowski", "title": "ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement\n  Learning", "comments": null, "journal-ref": "Proceedings of IEEE Conference of Computational Intelligence in\n  Games 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep neural networks have led to effective\nvision-based reinforcement learning methods that have been employed to obtain\nhuman-level controllers in Atari 2600 games from pixel data. Atari 2600 games,\nhowever, do not resemble real-world tasks since they involve non-realistic 2D\nenvironments and the third-person perspective. Here, we propose a novel\ntest-bed platform for reinforcement learning research from raw visual\ninformation which employs the first-person perspective in a semi-realistic 3D\nworld. The software, called ViZDoom, is based on the classical first-person\nshooter video game, Doom. It allows developing bots that play the game using\nthe screen buffer. ViZDoom is lightweight, fast, and highly customizable via a\nconvenient mechanism of user scenarios. In the experimental part, we test the\nenvironment by trying to learn bots for two scenarios: a basic move-and-shoot\ntask and a more complex maze-navigation problem. Using convolutional deep\nneural networks with Q-learning and experience replay, for both scenarios, we\nwere able to train competent bots, which exhibit human-like behaviors. The\nresults confirm the utility of ViZDoom as an AI research platform and imply\nthat visual reinforcement learning in 3D realistic first-person perspective\nenvironments is feasible.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 20:46:34 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:12:49 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Kempka", "Micha\u0142", ""], ["Wydmuch", "Marek", ""], ["Runc", "Grzegorz", ""], ["Toczek", "Jakub", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "1605.02099", "submitter": "Huizhen Yu", "authors": "Huizhen Yu", "title": "Some Simulation Results for Emphatic Temporal-Difference Learning\n  Algorithms", "comments": "A companion note to the article arxiv:1511.07471; 30 pages; 34\n  figures, best viewed on screen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a companion note to our recent study of the weak convergence\nproperties of constrained emphatic temporal-difference learning (ETD)\nalgorithms from a theoretic perspective. It supplements the latter analysis\nwith simulation results and illustrates the behavior of some of the ETD\nalgorithms using three example problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 20:52:26 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Yu", "Huizhen", ""]]}, {"id": "1605.02105", "submitter": "Cesar A. Uribe", "authors": "Angelia Nedi\\'c and Alex Olshevsky and C\\'esar Uribe", "title": "Distributed Learning with Infinitely Many Hypotheses", "comments": "Submitted to CDC2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning setup where a network of agents\nsequentially access realizations of a set of random variables with unknown\ndistributions. The network objective is to find a parametrized distribution\nthat best describes their joint observations in the sense of the\nKullback-Leibler divergence. Apart from recent efforts in the literature, we\nanalyze the case of countably many hypotheses and the case of a continuum of\nhypotheses. We provide non-asymptotic bounds for the concentration rate of the\nagents' beliefs around the correct hypothesis in terms of the number of agents,\nthe network parameters, and the learning abilities of the agents. Additionally,\nwe provide a novel motivation for a general set of distributed Non-Bayesian\nupdate rules as instances of the distributed stochastic mirror descent\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 21:47:36 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Nedi\u0107", "Angelia", ""], ["Olshevsky", "Alex", ""], ["Uribe", "C\u00e9sar", ""]]}, {"id": "1605.02129", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Trung H. Bui, and Hung H. Bui", "title": "Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot\n  task", "comments": "Paper accepted at IWSDS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dialog State Tracking Challenge 4 (DSTC 4) proposes several pilot tasks.\nIn this paper, we focus on the spoken language understanding pilot task, which\nconsists of tagging a given utterance with speech acts and semantic slots. We\ncompare different classifiers: the best system obtains 0.52 and 0.67 F1-scores\non the test set for speech act recognition for the tourist and the guide\nrespectively, and 0.52 F1-score for semantic tagging for both the guide and the\ntourist.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 01:55:51 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Bui", "Trung H.", ""], ["Bui", "Hung H.", ""]]}, {"id": "1605.02130", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Trung H. Bui, Hung H. Bui", "title": "Robust Dialog State Tracking for Large Ontologies", "comments": "Paper accepted at IWSDS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dialog State Tracking Challenge 4 (DSTC 4) differentiates itself from the\nprevious three editions as follows: the number of slot-value pairs present in\nthe ontology is much larger, no spoken language understanding output is given,\nand utterances are labeled at the subdialog level. This paper describes a novel\ndialog state tracking method designed to work robustly under these conditions,\nusing elaborate string matching, coreference resolution tailored for dialogs\nand a few other improvements. The method can correctly identify many values\nthat are not explicitly present in the utterance. On the final evaluation, our\nmethod came in first among 7 competing teams and 24 entries. The F1-score\nachieved by our method was 9 and 7 percentage points higher than that of the\nrunner-up for the utterance-level evaluation and for the subdialog-level\nevaluation, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 02:00:30 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Bui", "Trung H.", ""], ["Bui", "Hung H.", ""]]}, {"id": "1605.02196", "submitter": "Peter Radecki", "authors": "Peter Radecki, Mark Campbell and Kevin Matzen", "title": "All Weather Perception: Joint Data Association, Tracking, and\n  Classification for Autonomous Ground Vehicles", "comments": "35 pages, 21 figures, 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel probabilistic perception algorithm is presented as a real-time joint\nsolution to data association, object tracking, and object classification for an\nautonomous ground vehicle in all-weather conditions. The presented algorithm\nextends a Rao-Blackwellized Particle Filter originally built with a particle\nfilter for data association and a Kalman filter for multi-object tracking\n(Miller et al. 2011a) to now also include multiple model tracking for\nclassification. Additionally a state-of-the-art vision detection algorithm that\nincludes heading information for autonomous ground vehicle (AGV) applications\nwas implemented. Cornell's AGV from the DARPA Urban Challenge was upgraded and\nused to experimentally examine if and how state-of-the-art vision algorithms\ncan complement or replace lidar and radar sensors. Sensor and algorithm\nperformance in adverse weather and lighting conditions is tested. Experimental\nevaluation demonstrates robust all-weather data association, tracking, and\nclassification where camera, lidar, and radar sensors complement each other\ninside the joint probabilistic perception algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 14:36:34 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Radecki", "Peter", ""], ["Campbell", "Mark", ""], ["Matzen", "Kevin", ""]]}, {"id": "1605.02216", "submitter": "Sixin Zhang Sixin Zhang", "authors": "Sixin Zhang", "title": "Distributed stochastic optimization for deep learning (thesis)", "comments": "This is the author's thesis at under supervision of Yann LeCun. Part\n  of the results are based on the paper arXiv:1412.6651 in collaboration with\n  Anna Choromanska and Yann LeCun", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of how to distribute the training of large-scale deep\nlearning models in the parallel computing environment. We propose a new\ndistributed stochastic optimization method called Elastic Averaging SGD\n(EASGD). We analyze the convergence rate of the EASGD method in the synchronous\nscenario and compare its stability condition with the existing ADMM method in\nthe round-robin scheme. An asynchronous and momentum variant of the EASGD\nmethod is applied to train deep convolutional neural networks for image\nclassification on the CIFAR and ImageNet datasets. Our approach accelerates the\ntraining and furthermore achieves better test accuracy. It also requires a much\nsmaller amount of communication than other common baseline approaches such as\nthe DOWNPOUR method.\n  We then investigate the limit in speedup of the initial and the asymptotic\nphase of the mini-batch SGD, the momentum SGD, and the EASGD methods. We find\nthat the spread of the input data distribution has a big impact on their\ninitial convergence rate and stability region. We also find a surprising\nconnection between the momentum SGD and the EASGD method with a negative moving\naverage rate. A non-convex case is also studied to understand when EASGD can\nget trapped by a saddle point.\n  Finally, we scale up the EASGD method by using a tree structured network\ntopology. We show empirically its advantage and challenge. We also establish a\nconnection between the EASGD and the DOWNPOUR method with the classical Jacobi\nand the Gauss-Seidel method, thus unifying a class of distributed stochastic\noptimization methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 16:55:22 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Zhang", "Sixin", ""]]}, {"id": "1605.02226", "submitter": "Marc-Alexandre C\\^ot\\'e", "authors": "Benigno Uria, Marc-Alexandre C\\^ot\\'e, Karol Gregor, Iain Murray, Hugo\n  Larochelle", "title": "Neural Autoregressive Distribution Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural Autoregressive Distribution Estimation (NADE) models, which\nare neural network architectures applied to the problem of unsupervised\ndistribution and density estimation. They leverage the probability product rule\nand a weight sharing scheme inspired from restricted Boltzmann machines, to\nyield an estimator that is both tractable and has good generalization\nperformance. We discuss how they achieve competitive performance in modeling\nboth binary and real-valued observations. We also present how deep NADE models\ncan be trained to be agnostic to the ordering of input dimensions used by the\nautoregressive product rule decomposition. Finally, we also show how to exploit\nthe topological structure of pixels in images using a deep convolutional\narchitecture for NADE.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 18:13:25 GMT"}, {"version": "v2", "created": "Wed, 11 May 2016 12:00:17 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 14:25:41 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Uria", "Benigno", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Gregor", "Karol", ""], ["Murray", "Iain", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1605.02268", "submitter": "Ahmad Beirami", "authors": "Matthew Nokleby, Ahmad Beirami, and Robert Calderbank", "title": "Rate-Distortion Bounds on Bayes Risk in Supervised Learning", "comments": "Revised submission to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-theoretic framework for bounding the number of\nlabeled samples needed to train a classifier in a parametric Bayesian setting.\nWe derive bounds on the average $L_p$ distance between the learned classifier\nand the true maximum a posteriori classifier, which are well-established\nsurrogates for the excess classification error due to imperfect learning. We\nprovide lower and upper bounds on the rate-distortion function, using $L_p$\nloss as the distortion measure, of a maximum a priori classifier in terms of\nthe differential entropy of the posterior distribution and a quantity called\nthe interpolation dimension, which characterizes the complexity of the\nparametric distribution family. In addition to expressing the information\ncontent of a classifier in terms of lossy compression, the rate-distortion\nfunction also expresses the minimum number of bits a learning machine needs to\nextract from training data to learn a classifier to within a specified $L_p$\ntolerance. We use results from universal source coding to express the\ninformation content in the training data in terms of the Fisher information of\nthe parametric family and the number of training samples available. The result\nis a framework for computing lower bounds on the Bayes $L_p$ risk. This\nframework complements the well-known probably approximately correct (PAC)\nframework, which provides minimax risk bounds involving the Vapnik-Chervonenkis\ndimension or Rademacher complexity. Whereas the PAC framework provides upper\nbounds the risk for the worst-case data distribution, the proposed\nrate-distortion framework lower bounds the risk averaged over the data\ndistribution. We evaluate the bounds for a variety of data models, including\ncategorical, multinomial, and Gaussian models. In each case the bounds are\nprovably tight orderwise, and in two cases we prove that the bounds are tight\nup to multiplicative constants.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2016 03:54:34 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 17:58:36 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Nokleby", "Matthew", ""], ["Beirami", "Ahmad", ""], ["Calderbank", "Robert", ""]]}, {"id": "1605.02269", "submitter": "Zhiyun Ren", "authors": "Zhiyun Ren, Huzefa Rangwala, Aditya Johri", "title": "Predicting Performance on MOOC Assessments using Multi-Regression Models", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past few years has seen the rapid growth of data min- ing approaches for\nthe analysis of data obtained from Mas- sive Open Online Courses (MOOCs). The\nobjectives of this study are to develop approaches to predict the scores a stu-\ndent may achieve on a given grade-related assessment based on information,\nconsidered as prior performance or prior ac- tivity in the course. We develop a\npersonalized linear mul- tiple regression (PLMR) model to predict the grade for\na student, prior to attempting the assessment activity. The developed model is\nreal-time and tracks the participation of a student within a MOOC (via\nclick-stream server logs) and predicts the performance of a student on the next\nas- sessment within the course offering. We perform a com- prehensive set of\nexperiments on data obtained from three openEdX MOOCs via a Stanford University\ninitiative. Our experimental results show the promise of the proposed ap-\nproach in comparison to baseline approaches and also helps in identification of\nkey features that are associated with the study habits and learning behaviors\nof students.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2016 04:00:31 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Ren", "Zhiyun", ""], ["Rangwala", "Huzefa", ""], ["Johri", "Aditya", ""]]}, {"id": "1605.02372", "submitter": "Akshay Gadde", "authors": "Akshay Gadde, Eyal En Gad, Salman Avestimehr and Antonio Ortega", "title": "Active Learning for Community Detection in Stochastic Block Models", "comments": "5 pages, 3 figures, To appear in IEEE International Symposium on\n  Information Theory 2016", "journal-ref": null, "doi": "10.1109/ISIT.2016.7541627", "report-no": null, "categories": "cs.LG cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model (SBM) is an important generative model for random\ngraphs in network science and machine learning, useful for benchmarking\ncommunity detection (or clustering) algorithms. The symmetric SBM generates a\ngraph with $2n$ nodes which cluster into two equally sized communities. Nodes\nconnect with probability $p$ within a community and $q$ across different\ncommunities. We consider the case of $p=a\\ln (n)/n$ and $q=b\\ln (n)/n$. In this\ncase, it was recently shown that recovering the community membership (or label)\nof every node with high probability (w.h.p.) using only the graph is possible\nif and only if the Chernoff-Hellinger (CH) divergence\n$D(a,b)=(\\sqrt{a}-\\sqrt{b})^2 \\geq 1$. In this work, we study if, and by how\nmuch, community detection below the clustering threshold (i.e. $D(a,b)<1$) is\npossible by querying the labels of a limited number of chosen nodes (i.e.,\nactive learning). Our main result is to show that, under certain conditions,\nsampling the labels of a vanishingly small fraction of nodes (a number\nsub-linear in $n$) is sufficient for exact community detection even when\n$D(a,b)<1$. Furthermore, we provide an efficient learning algorithm which\nrecovers the community memberships of all nodes w.h.p. as long as the number of\nsampled points meets the sufficient condition. We also show that recovery is\nnot possible if the number of observed labels is less than $n^{1-D(a,b)}$. The\nvalidity of our results is demonstrated through numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2016 22:07:00 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Gadde", "Akshay", ""], ["Gad", "Eyal En", ""], ["Avestimehr", "Salman", ""], ["Ortega", "Antonio", ""]]}, {"id": "1605.02408", "submitter": "Shiqian Ma", "authors": "Bo Jiang, Tianyi Lin, Shiqian Ma, Shuzhong Zhang", "title": "Structured Nonconvex and Nonsmooth Optimization: Algorithms and\n  Iteration Complexity Analysis", "comments": "Section 4.1 is updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex and nonsmooth optimization problems are frequently encountered in\nmuch of statistics, business, science and engineering, but they are not yet\nwidely recognized as a technology in the sense of scalability. A reason for\nthis relatively low degree of popularity is the lack of a well developed system\nof theory and algorithms to support the applications, as is the case for its\nconvex counterpart. This paper aims to take one step in the direction of\ndisciplined nonconvex and nonsmooth optimization. In particular, we consider in\nthis paper some constrained nonconvex optimization models in block decision\nvariables, with or without coupled affine constraints. In the case of without\ncoupled constraints, we show a sublinear rate of convergence to an\n$\\epsilon$-stationary solution in the form of variational inequality for a\ngeneralized conditional gradient method, where the convergence rate is shown to\nbe dependent on the H\\\"olderian continuity of the gradient of the smooth part\nof the objective. For the model with coupled affine constraints, we introduce\ncorresponding $\\epsilon$-stationarity conditions, and apply two proximal-type\nvariants of the ADMM to solve such a model, assuming the proximal ADMM updates\ncan be implemented for all the block variables except for the last block, for\nwhich either a gradient step or a majorization-minimization step is\nimplemented. We show an iteration complexity bound of $O(1/\\epsilon^2)$ to\nreach an $\\epsilon$-stationary solution for both algorithms. Moreover, we show\nthat the same iteration complexity of a proximal BCD method follows\nimmediately. Numerical results are provided to illustrate the efficacy of the\nproposed algorithms for tensor robust PCA.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 03:39:49 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 05:50:42 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 17:17:58 GMT"}, {"version": "v4", "created": "Wed, 15 Nov 2017 00:04:35 GMT"}, {"version": "v5", "created": "Wed, 17 Jan 2018 22:57:33 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Jiang", "Bo", ""], ["Lin", "Tianyi", ""], ["Ma", "Shiqian", ""], ["Zhang", "Shuzhong", ""]]}, {"id": "1605.02470", "submitter": "Nikhil Karamchandani", "authors": "Vivek S. Borkar, Nikhil Karamchandani, Sharad Mirani", "title": "Randomized Kaczmarz for Rank Aggregation from Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of inferring the overall ranking among entities in the\nframework of Bradley-Terry-Luce (BTL) model, based on available empirical data\non pairwise preferences. By a simple transformation, we can cast the problem as\nthat of solving a noisy linear system, for which a ready algorithm is available\nin the form of the randomized Kaczmarz method. This scheme is provably\nconvergent, has excellent empirical performance, and is amenable to on-line,\ndistributed and asynchronous variants. Convergence, convergence rate, and error\nanalysis of the proposed algorithm are presented and several numerical\nexperiments are conducted whose results validate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 08:36:55 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Borkar", "Vivek S.", ""], ["Karamchandani", "Nikhil", ""], ["Mirani", "Sharad", ""]]}, {"id": "1605.02531", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba and Shie Mannor", "title": "Clustering Time Series and the Surprising Robustness of HMMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we are given a time series where consecutive samples are\nbelieved to come from a probabilistic source, that the source changes from time\nto time and that the total number of sources is fixed. Our objective is to\nestimate the distributions of the sources. A standard approach to this problem\nis to model the data as a hidden Markov model (HMM). However, since the data\noften lacks the Markov or the stationarity properties of an HMM, one can ask\nwhether this approach is still suitable or perhaps another approach is\nrequired. In this paper we show that a maximum likelihood HMM estimator can be\nused to approximate the source distributions in a much larger class of models\nthan HMMs. Specifically, we propose a natural and fairly general non-stationary\nmodel of the data, where the only restriction is that the sources do not change\ntoo often. Our main result shows that for this model, a maximum-likelihood HMM\nestimator produces the correct second moment of the data, and the results can\nbe extended to higher moments.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 11:24:19 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2016 13:49:37 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""]]}, {"id": "1605.02536", "submitter": "Romain Brault Rb", "authors": "Romain Brault, Florence d'Alch\\'e-Buc, Markus Heinonen", "title": "Random Fourier Features for Operator-Valued Kernels", "comments": "32 pages, 6 figures", "journal-ref": "ACML, Hamilton, New-Zealand, JMLR Workshop and Conference\n  Proceedings, November 2016, vol. 63, pp. 110-125", "doi": null, "report-no": "PMLR 63:110-125", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devoted to multi-task learning and structured output learning,\noperator-valued kernels provide a flexible tool to build vector-valued\nfunctions in the context of Reproducing Kernel Hilbert Spaces. To scale up\nthese methods, we extend the celebrated Random Fourier Feature methodology to\nget an approximation of operator-valued kernels. We propose a general principle\nfor Operator-valued Random Fourier Feature construction relying on a\ngeneralization of Bochner's theorem for translation-invariant operator-valued\nMercer kernels. We prove the uniform convergence of the kernel approximation\nfor bounded and unbounded operator random Fourier features using appropriate\nBernstein matrix concentration inequality. An experimental proof-of-concept\nshows the quality of the approximation and the efficiency of the corresponding\nlinear models on example datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 11:36:40 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 16:35:41 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 12:59:58 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Brault", "Romain", ""], ["d'Alch\u00e9-Buc", "Florence", ""], ["Heinonen", "Markus", ""]]}, {"id": "1605.02633", "submitter": "Chong You", "authors": "Chong You, Chun-Guang Li, Daniel P. Robinson, Rene Vidal", "title": "Oracle Based Active Set Algorithm for Scalable Elastic Net Subspace\n  Clustering", "comments": "15 pages, 6 figures, accepted to CVPR 2016 for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art subspace clustering methods are based on expressing each\ndata point as a linear combination of other data points while regularizing the\nmatrix of coefficients with $\\ell_1$, $\\ell_2$ or nuclear norms. $\\ell_1$\nregularization is guaranteed to give a subspace-preserving affinity (i.e.,\nthere are no connections between points from different subspaces) under broad\ntheoretical conditions, but the clusters may not be connected. $\\ell_2$ and\nnuclear norm regularization often improve connectivity, but give a\nsubspace-preserving affinity only for independent subspaces. Mixed $\\ell_1$,\n$\\ell_2$ and nuclear norm regularizations offer a balance between the\nsubspace-preserving and connectedness properties, but this comes at the cost of\nincreased computational complexity. This paper studies the geometry of the\nelastic net regularizer (a mixture of the $\\ell_1$ and $\\ell_2$ norms) and uses\nit to derive a provably correct and scalable active set method for finding the\noptimal coefficients. Our geometric analysis also provides a theoretical\njustification and a geometric interpretation for the balance between the\nconnectedness (due to $\\ell_2$ regularization) and subspace-preserving (due to\n$\\ell_1$ regularization) properties for elastic net subspace clustering. Our\nexperiments show that the proposed active set method not only achieves\nstate-of-the-art clustering performance, but also efficiently handles\nlarge-scale datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 15:49:36 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["You", "Chong", ""], ["Li", "Chun-Guang", ""], ["Robinson", "Daniel P.", ""], ["Vidal", "Rene", ""]]}, {"id": "1605.02688", "submitter": "Simon Lefrancois", "authors": "The Theano Development Team: Rami Al-Rfou, Guillaume Alain, Amjad\n  Almahairi, Christof Angermueller, Dzmitry Bahdanau, Nicolas Ballas,\n  Fr\\'ed\\'eric Bastien, Justin Bayer, Anatoly Belikov, Alexander Belopolsky,\n  Yoshua Bengio, Arnaud Bergeron, James Bergstra, Valentin Bisson, Josh\n  Bleecher Snyder, Nicolas Bouchard, Nicolas Boulanger-Lewandowski, Xavier\n  Bouthillier, Alexandre de Br\\'ebisson, Olivier Breuleux, Pierre-Luc Carrier,\n  Kyunghyun Cho, Jan Chorowski, Paul Christiano, Tim Cooijmans, Marc-Alexandre\n  C\\^ot\\'e, Myriam C\\^ot\\'e, Aaron Courville, Yann N. Dauphin, Olivier\n  Delalleau, Julien Demouth, Guillaume Desjardins, Sander Dieleman, Laurent\n  Dinh, M\\'elanie Ducoffe, Vincent Dumoulin, Samira Ebrahimi Kahou, Dumitru\n  Erhan, Ziye Fan, Orhan Firat, Mathieu Germain, Xavier Glorot, Ian Goodfellow,\n  Matt Graham, Caglar Gulcehre, Philippe Hamel, Iban Harlouchet, Jean-Philippe\n  Heng, Bal\\'azs Hidasi, Sina Honari, Arjun Jain, S\\'ebastien Jean, Kai Jia,\n  Mikhail Korobov, Vivek Kulkarni, Alex Lamb, Pascal Lamblin, Eric Larsen,\n  C\\'esar Laurent, Sean Lee, Simon Lefrancois, Simon Lemieux, Nicholas\n  L\\'eonard, Zhouhan Lin, Jesse A. Livezey, Cory Lorenz, Jeremiah Lowin, Qianli\n  Ma, Pierre-Antoine Manzagol, Olivier Mastropietro, Robert T. McGibbon, Roland\n  Memisevic, Bart van Merri\\\"enboer, Vincent Michalski, Mehdi Mirza, Alberto\n  Orlandi, Christopher Pal, Razvan Pascanu, Mohammad Pezeshki, Colin Raffel,\n  Daniel Renshaw, Matthew Rocklin, Adriana Romero, Markus Roth, Peter Sadowski,\n  John Salvatier, Fran\\c{c}ois Savard, Jan Schl\\\"uter, John Schulman, Gabriel\n  Schwartz, Iulian Vlad Serban, Dmitriy Serdyuk, Samira Shabanian, \\'Etienne\n  Simon, Sigurd Spieckermann, S. Ramana Subramanyam, Jakub Sygnowski,\n  J\\'er\\'emie Tanguay, Gijs van Tulder, Joseph Turian, Sebastian Urban, Pascal\n  Vincent, Francesco Visin, Harm de Vries, David Warde-Farley, Dustin J. Webb,\n  Matthew Willson, Kelvin Xu, Lijun Xue, Li Yao, Saizheng Zhang, Ying Zhang", "title": "Theano: A Python framework for fast computation of mathematical\n  expressions", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theano is a Python library that allows to define, optimize, and evaluate\nmathematical expressions involving multi-dimensional arrays efficiently. Since\nits introduction, it has been one of the most used CPU and GPU mathematical\ncompilers - especially in the machine learning community - and has shown steady\nperformance improvements. Theano is being actively and continuously developed\nsince 2008, multiple frameworks have been built on top of it and it has been\nused to produce many state-of-the-art machine learning models.\n  The present article is structured as follows. Section I provides an overview\nof the Theano software and its community. Section II presents the principal\nfeatures of Theano and how to use them, and compares them with other similar\nprojects. Section III focuses on recently-introduced functionalities and\nimprovements. Section IV compares the performance of Theano against Torch7 and\nTensorFlow on several machine learning models. Section V discusses current\nlimitations of Theano and potential ways of improving it.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 18:32:34 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["The Theano Development Team", "", ""], ["Al-Rfou", "Rami", ""], ["Alain", "Guillaume", ""], ["Almahairi", "Amjad", ""], ["Angermueller", "Christof", ""], ["Bahdanau", "Dzmitry", ""], ["Ballas", "Nicolas", ""], ["Bastien", "Fr\u00e9d\u00e9ric", ""], ["Bayer", "Justin", ""], ["Belikov", "Anatoly", ""], ["Belopolsky", "Alexander", ""], ["Bengio", "Yoshua", ""], ["Bergeron", "Arnaud", ""], ["Bergstra", "James", ""], ["Bisson", "Valentin", ""], ["Snyder", "Josh Bleecher", ""], ["Bouchard", "Nicolas", ""], ["Boulanger-Lewandowski", "Nicolas", ""], ["Bouthillier", "Xavier", ""], ["de Br\u00e9bisson", "Alexandre", ""], ["Breuleux", "Olivier", ""], ["Carrier", "Pierre-Luc", ""], ["Cho", "Kyunghyun", ""], ["Chorowski", "Jan", ""], ["Christiano", "Paul", ""], ["Cooijmans", "Tim", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["C\u00f4t\u00e9", "Myriam", ""], ["Courville", "Aaron", ""], ["Dauphin", "Yann N.", ""], ["Delalleau", "Olivier", ""], ["Demouth", "Julien", ""], ["Desjardins", "Guillaume", ""], ["Dieleman", "Sander", ""], ["Dinh", "Laurent", ""], ["Ducoffe", "M\u00e9lanie", ""], ["Dumoulin", "Vincent", ""], ["Kahou", "Samira Ebrahimi", ""], ["Erhan", "Dumitru", ""], ["Fan", "Ziye", ""], ["Firat", "Orhan", ""], ["Germain", "Mathieu", ""], ["Glorot", "Xavier", ""], ["Goodfellow", "Ian", ""], ["Graham", "Matt", ""], ["Gulcehre", "Caglar", ""], ["Hamel", "Philippe", ""], ["Harlouchet", "Iban", ""], ["Heng", "Jean-Philippe", ""], ["Hidasi", "Bal\u00e1zs", ""], ["Honari", "Sina", ""], ["Jain", "Arjun", ""], ["Jean", "S\u00e9bastien", ""], ["Jia", "Kai", ""], ["Korobov", "Mikhail", ""], ["Kulkarni", "Vivek", ""], ["Lamb", "Alex", ""], ["Lamblin", "Pascal", ""], ["Larsen", "Eric", ""], ["Laurent", "C\u00e9sar", ""], ["Lee", "Sean", ""], ["Lefrancois", "Simon", ""], ["Lemieux", "Simon", ""], ["L\u00e9onard", "Nicholas", ""], ["Lin", "Zhouhan", ""], ["Livezey", "Jesse A.", ""], ["Lorenz", "Cory", ""], ["Lowin", "Jeremiah", ""], ["Ma", "Qianli", ""], ["Manzagol", "Pierre-Antoine", ""], ["Mastropietro", "Olivier", ""], ["McGibbon", "Robert T.", ""], ["Memisevic", "Roland", ""], ["van Merri\u00ebnboer", "Bart", ""], ["Michalski", "Vincent", ""], ["Mirza", "Mehdi", ""], ["Orlandi", "Alberto", ""], ["Pal", "Christopher", ""], ["Pascanu", "Razvan", ""], ["Pezeshki", "Mohammad", ""], ["Raffel", "Colin", ""], ["Renshaw", "Daniel", ""], ["Rocklin", "Matthew", ""], ["Romero", "Adriana", ""], ["Roth", "Markus", ""], ["Sadowski", "Peter", ""], ["Salvatier", "John", ""], ["Savard", "Fran\u00e7ois", ""], ["Schl\u00fcter", "Jan", ""], ["Schulman", "John", ""], ["Schwartz", "Gabriel", ""], ["Serban", "Iulian Vlad", ""], ["Serdyuk", "Dmitriy", ""], ["Shabanian", "Samira", ""], ["Simon", "\u00c9tienne", ""], ["Spieckermann", "Sigurd", ""], ["Subramanyam", "S. Ramana", ""], ["Sygnowski", "Jakub", ""], ["Tanguay", "J\u00e9r\u00e9mie", ""], ["van Tulder", "Gijs", ""], ["Turian", "Joseph", ""], ["Urban", "Sebastian", ""], ["Vincent", "Pascal", ""], ["Visin", "Francesco", ""], ["de Vries", "Harm", ""], ["Warde-Farley", "David", ""], ["Webb", "Dustin J.", ""], ["Willson", "Matthew", ""], ["Xu", "Kelvin", ""], ["Xue", "Lijun", ""], ["Yao", "Li", ""], ["Zhang", "Saizheng", ""], ["Zhang", "Ying", ""]]}, {"id": "1605.02699", "submitter": "Saikat Basu", "authors": "Saikat Basu, Manohar Karki, Robert DiBiano, Supratik Mukhopadhyay,\n  Sangram Ganguly, Ramakrishna Nemani and Shreekant Gayaka", "title": "A Theoretical Analysis of Deep Neural Networks for Texture\n  Classification", "comments": "Accepted in International Joint Conference on Neural Networks, IJCNN\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Deep Neural Networks for the classification of\nimage datasets where texture features are important for generating\nclass-conditional discriminative representations. To this end, we first derive\nthe size of the feature space for some standard textural features extracted\nfrom the input dataset and then use the theory of Vapnik-Chervonenkis dimension\nto show that hand-crafted feature extraction creates low-dimensional\nrepresentations which help in reducing the overall excess error rate. As a\ncorollary to this analysis, we derive for the first time upper bounds on the VC\ndimension of Convolutional Neural Network as well as Dropout and Dropconnect\nnetworks and the relation between excess error rate of Dropout and Dropconnect\nnetworks. The concept of intrinsic dimension is used to validate the intuition\nthat texture-based datasets are inherently higher dimensional as compared to\nhandwritten digits or other object recognition datasets and hence more\ndifficult to be shattered by neural networks. We then derive the mean distance\nfrom the centroid to the nearest and farthest sampling points in an\nn-dimensional manifold and show that the Relative Contrast of the sample data\nvanishes as dimensionality of the underlying vector space tends to infinity.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 19:11:22 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 19:32:06 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Basu", "Saikat", ""], ["Karki", "Manohar", ""], ["DiBiano", "Robert", ""], ["Mukhopadhyay", "Supratik", ""], ["Ganguly", "Sangram", ""], ["Nemani", "Ramakrishna", ""], ["Gayaka", "Shreekant", ""]]}, {"id": "1605.02711", "submitter": "Xingguo Li", "authors": "Xingguo Li, Raman Arora, Han Liu, Jarvis Haupt, Tuo Zhao", "title": "Nonconvex Sparse Learning via Stochastic Optimization with Progressive\n  Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic variance reduced optimization algorithm for solving\nsparse learning problems with cardinality constraints. Sufficient conditions\nare provided, under which the proposed algorithm enjoys strong linear\nconvergence guarantees and optimal estimation accuracy in high dimensions. We\nfurther extend the proposed algorithm to an asynchronous parallel variant with\na near linear speedup. Numerical experiments demonstrate the efficiency of our\nalgorithm in terms of both parameter estimation and computational performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 19:44:17 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 20:20:12 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2016 20:50:18 GMT"}, {"version": "v4", "created": "Mon, 13 Mar 2017 17:50:18 GMT"}, {"version": "v5", "created": "Sat, 23 Dec 2017 17:54:03 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Li", "Xingguo", ""], ["Arora", "Raman", ""], ["Liu", "Han", ""], ["Haupt", "Jarvis", ""], ["Zhao", "Tuo", ""]]}, {"id": "1605.02766", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Chen Zhao, Yezhou Yang, Cornelia Fermuller, Yiannis\n  Aloimonos", "title": "LightNet: A Versatile, Standalone Matlab-based Environment for Deep\n  Learning", "comments": "Accepted to ACM MULTIMEDIA 2016 Open Source Software Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LightNet is a lightweight, versatile and purely Matlab-based deep learning\nframework. The idea underlying its design is to provide an easy-to-understand,\neasy-to-use and efficient computational platform for deep learning research.\nThe implemented framework supports major deep learning architectures such as\nMultilayer Perceptron Networks (MLP), Convolutional Neural Networks (CNN) and\nRecurrent Neural Networks (RNN). The framework also supports both CPU and GPU\ncomputation, and the switch between them is straightforward. Different\napplications in computer vision, natural language processing and robotics are\ndemonstrated as experiments.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 20:33:30 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 00:20:14 GMT"}, {"version": "v3", "created": "Tue, 2 Aug 2016 04:00:30 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Ye", "Chengxi", ""], ["Zhao", "Chen", ""], ["Yang", "Yezhou", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1605.02832", "submitter": "Sho Sonoda Dr", "authors": "Sho Sonoda, Noboru Murata", "title": "Transport Analysis of Infinitely Deep Neural Network", "comments": null, "journal-ref": "Journal of Machine Learning Research 20(2):1-52, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the feature map inside deep neural networks (DNNs) by\ntracking the transport map. We are interested in the role of depth (why do DNNs\nperform better than shallow models?) and the interpretation of DNNs (what do\nintermediate layers do?) Despite the rapid development in their application,\nDNNs remain analytically unexplained because the hidden layers are nested and\nthe parameters are not faithful. Inspired by the integral representation of\nshallow NNs, which is the continuum limit of the width, or the hidden unit\nnumber, we developed the flow representation and transport analysis of DNNs.\nThe flow representation is the continuum limit of the depth or the hidden layer\nnumber, and it is specified by an ordinary differential equation with a vector\nfield. We interpret an ordinary DNN as a transport map or a Euler broken line\napproximation of the flow. Technically speaking, a dynamical system is a\nnatural model for the nested feature maps. In addition, it opens a new way to\nthe coordinate-free treatment of DNNs by avoiding the redundant parametrization\nof DNNs. Following Wasserstein geometry, we analyze a flow in three aspects:\ndynamical system, continuity equation, and Wasserstein gradient flow. A key\nfinding is that we specified a series of transport maps of the denoising\nautoencoder (DAE). Starting from the shallow DAE, this paper develops three\ntopics: the transport map of the deep DAE, the equivalence between the stacked\nDAE and the composition of DAEs, and the development of the double continuum\nlimit or the integral representation of the flow representation. As partial\nanswers to the research questions, we found that deeper DAEs converge faster\nand the extracted features are better; in addition, a deep Gaussian DAE\ntransports mass to decrease the Shannon entropy of the data distribution.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 03:06:23 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 17:53:12 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Sonoda", "Sho", ""], ["Murata", "Noboru", ""]]}, {"id": "1605.02877", "submitter": "Bijit Kumar Das", "authors": "Bijit Kumar Das and Mrityunjoy Chakraborty", "title": "Performance Analysis of the Gradient Comparator LMS Algorithm", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparsity-aware zero attractor least mean square (ZA-LMS) algorithm\nmanifests much lower misadjustment in strongly sparse environment than its\nsparsity-agnostic counterpart, the least mean square (LMS), but is shown to\nperform worse than the LMS when sparsity of the impulse response decreases. The\nreweighted variant of the ZA-LMS, namely RZA-LMS shows robustness against this\nvariation in sparsity, but at the price of increased computational complexity.\nThe other variants such as the l 0 -LMS and the improved proportionate\nnormalized LMS (IPNLMS), though perform satisfactorily, are also\ncomputationally intensive. The gradient comparator LMS (GC-LMS) is a practical\nsolution of this trade-off when hardware constraint is to be considered. In\nthis paper, we analyse the mean and the mean square convergence performance of\nthe GC-LMS algorithm in detail. The analyses satisfactorily match with the\nsimulation results.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 07:30:12 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Das", "Bijit Kumar", ""], ["Chakraborty", "Mrityunjoy", ""]]}, {"id": "1605.02878", "submitter": "Bijit Kumar Das", "authors": "Bijit Kumar Das and Mrityunjoy Chakraborty", "title": "Adaptive Combination of l0 LMS Adaptive Filters for Sparse System\n  Identification in Fluctuating Noise Power", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the l0-least mean square (l0-LMS) algorithm has been proposed to\nidentify sparse linear systems by employing a sparsity-promoting continuous\nfunction as an approximation of l0 pseudonorm penalty. However, the performance\nof this algorithm is sensitive to the appropriate choice of the some parameter\nresponsible for the zero-attracting intensity. The optimum choice for this\nparameter depends on the signal-to-noise ratio (SNR) prevailing in the system.\nThus, it becomes difficult to fix a suitable value for this parameter,\nparticularly in a situation where SNR fluctuates over time. In this work, we\npropose several adaptive combinations of differently parameterized l0-LMS to\nget an overall satisfactory performance independent of the SNR, and discuss\nsome issues relevant to these combination structures. We also demonstrate an\nefficient partial update scheme which not only reduces the number of\ncomputations per iteration, but also achieves some interesting performance gain\ncompared with the full update case. Then, we propose a new recursive least\nsquares (RLS)-type rule to update the combining parameter more efficiently.\nFinally, we extend the combination of two filters to a combination of M number\nadaptive filters, which manifests further improvement for M > 2.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 07:30:20 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Das", "Bijit Kumar", ""], ["Chakraborty", "Mrityunjoy", ""]]}, {"id": "1605.02887", "submitter": "Yunlong Feng", "authors": "Hanyuan Hang, Yunlong Feng, Ingo Steinwart, and Johan A.K. Suykens", "title": "Learning theory estimates with observations from general stationary\n  stochastic processes", "comments": "arXiv admin note: text overlap with arXiv:1501.03059", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the supervised learning problem with observations\ndrawn from certain general stationary stochastic processes. Here by\n\\emph{general}, we mean that many stationary stochastic processes can be\nincluded. We show that when the stochastic processes satisfy a generalized\nBernstein-type inequality, a unified treatment on analyzing the learning\nschemes with various mixing processes can be conducted and a sharp oracle\ninequality for generic regularized empirical risk minimization schemes can be\nestablished. The obtained oracle inequality is then applied to derive\nconvergence rates for several learning schemes such as empirical risk\nminimization (ERM), least squares support vector machines (LS-SVMs) using given\ngeneric kernels, and SVMs using Gaussian kernels for both least squares and\nquantile regression. It turns out that for i.i.d.~processes, our learning rates\nfor ERM recover the optimal rates. On the other hand, for non-i.i.d.~processes\nincluding geometrically $\\alpha$-mixing Markov processes, geometrically\n$\\alpha$-mixing processes with restricted decay, $\\phi$-mixing processes, and\n(time-reversed) geometrically $\\mathcal{C}$-mixing processes, our learning\nrates for SVMs with Gaussian kernels match, up to some arbitrarily small extra\nterm in the exponent, the optimal rates. For the remaining cases, our rates are\nat least close to the optimal rates. As a by-product, the assumed generalized\nBernstein-type inequality also provides an interpretation of the so-called\n\"effective number of observations\" for various mixing processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 08:18:24 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Hang", "Hanyuan", ""], ["Feng", "Yunlong", ""], ["Steinwart", "Ingo", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "1605.02917", "submitter": "Mohammad Ali Zare Chahooki", "authors": "Seyed Hamid Reza Mohammadi, Mohammad Ali Zare Chahooki", "title": "Web Spam Detection Using Multiple Kernels in Twin Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engines are the most important tools for web data acquisition. Web\npages are crawled and indexed by search Engines. Users typically locate useful\nweb pages by querying a search engine. One of the challenges in search engines\nadministration is spam pages which waste search engine resources. These pages\nby deception of search engine ranking algorithms try to be showed in the first\npage of results. There are many approaches to web spam pages detection such as\nmeasurement of HTML code style similarity, pages linguistic pattern analysis\nand machine learning algorithm on page content features. One of the famous\nalgorithms has been used in machine learning approach is Support Vector Machine\n(SVM) classifier. Recently basic structure of SVM has been changed by new\nextensions to increase robustness and classification accuracy. In this paper we\nimproved accuracy of web spam detection by using two nonlinear kernels into\nTwin SVM (TSVM) as an improved extension of SVM. The classifier ability to data\nseparation has been increased by using two separated kernels for each class of\ndata. Effectiveness of new proposed method has been experimented with two\npublicly used spam datasets called UK-2007 and UK-2006. Results show the\neffectiveness of proposed kernelized version of TSVM in web spam page\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 10:05:40 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Mohammadi", "Seyed Hamid Reza", ""], ["Chahooki", "Mohammad Ali Zare", ""]]}, {"id": "1605.02989", "submitter": "Marco Capo MSc", "authors": "Marco Cap\\'o, Aritz P\\'erez, Jos\\'e Antonio Lozano", "title": "An efficient K-means algorithm for Massive Data", "comments": "38 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the progressive growth of the amount of data available in a wide\nvariety of scientific fields, it has become more difficult to ma- nipulate and\nanalyze such information. Even though datasets have grown in size, the K-means\nalgorithm remains as one of the most popular clustering methods, in spite of\nits dependency on the initial settings and high computational cost, especially\nin terms of distance computations. In this work, we propose an efficient\napproximation to the K-means problem intended for massive data. Our approach\nrecursively partitions the entire dataset into a small number of sub- sets,\neach of which is characterized by its representative (center of mass) and\nweight (cardinality), afterwards a weighted version of the K-means algorithm is\napplied over such local representation, which can drastically reduce the number\nof distances computed. In addition to some theoretical properties, experimental\nresults indicate that our method outperforms well-known approaches, such as the\nK-means++ and the minibatch K-means, in terms of the relation between number of\ndistance computations and the quality of the approximation.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 13:01:37 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Cap\u00f3", "Marco", ""], ["P\u00e9rez", "Aritz", ""], ["Lozano", "Jos\u00e9 Antonio", ""]]}, {"id": "1605.03004", "submitter": "Yanjun  Qi Dr.", "authors": "Zeming Lin, Jack Lanchantin, Yanjun Qi", "title": "MUST-CNN: A Multilayer Shift-and-Stitch Deep Convolutional Architecture\n  for Sequence-based Protein Structure Prediction", "comments": "8 pages ; 3 figures ; deep learning based sequence-sequence\n  prediction. in AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting protein properties such as solvent accessibility and secondary\nstructure from its primary amino acid sequence is an important task in\nbioinformatics. Recently, a few deep learning models have surpassed the\ntraditional window based multilayer perceptron. Taking inspiration from the\nimage classification domain we propose a deep convolutional neural network\narchitecture, MUST-CNN, to predict protein properties. This architecture uses a\nnovel multilayer shift-and-stitch (MUST) technique to generate fully dense\nper-position predictions on protein sequences. Our model is significantly\nsimpler than the state-of-the-art, yet achieves better results. By combining\nMUST and the efficient convolution operation, we can consider far more\nparameters while retaining very fast prediction speeds. We beat the\nstate-of-the-art performance on two large protein property prediction datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 13:31:52 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Lin", "Zeming", ""], ["Lanchantin", "Jack", ""], ["Qi", "Yanjun", ""]]}, {"id": "1605.03072", "submitter": "Ershad Banijamali Mr.", "authors": "Ershad Banijamali and Ali Ghodsi", "title": "Semi-Supervised Representation Learning based on Probabilistic Labeling", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new algorithm for semi-supervised representation\nlearning. In this algorithm, we first find a vector representation for the\nlabels of the data points based on their local positions in the space. Then, we\nmap the data to lower-dimensional space using a linear transformation such that\nthe dependency between the transformed data and the assigned labels is\nmaximized. In fact, we try to find a mapping that is as discriminative as\npossible. The approach will use Hilber-Schmidt Independence Criterion (HSIC) as\nthe dependence measure. We also present a kernelized version of the algorithm,\nwhich allows non-linear transformations and provides more flexibility in\nfinding the appropriate mapping. Use of unlabeled data for learning new\nrepresentation is not always beneficial and there is no algorithm that can\ndeterministically guarantee the improvement of the performance by exploiting\nunlabeled data. Therefore, we also propose a bound on the performance of the\nalgorithm, which can be used to determine the effectiveness of using the\nunlabeled data in the algorithm. We demonstrate the ability of the algorithm in\nfinding the transformation using both toy examples and real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 15:57:18 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2016 21:27:06 GMT"}, {"version": "v3", "created": "Thu, 15 Sep 2016 19:44:51 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 04:40:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Banijamali", "Ershad", ""], ["Ghodsi", "Ali", ""]]}, {"id": "1605.03364", "submitter": "Hans Kersting", "authors": "Hans Kersting, Philipp Hennig", "title": "Active Uncertainty Calibration in Bayesian ODE Solvers", "comments": "10 pages, 3 figures, published at UAI 2016. Changes for Version 3:\n  fixed minor index mistake in equation (14) (q-1-i instead of q+1-i on top of\n  the product)", "journal-ref": "Proceedings of the Thirty-Second Conference on Uncertainty in\n  Artificial Intelligence (UAI2016) 309--3018", "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is resurging interest, in statistics and machine learning, in solvers\nfor ordinary differential equations (ODEs) that return probability measures\ninstead of point estimates. Recently, Conrad et al. introduced a sampling-based\nclass of methods that are 'well-calibrated' in a specific sense. But the\ncomputational cost of these methods is significantly above that of classic\nmethods. On the other hand, Schober et al. pointed out a precise connection\nbetween classic Runge-Kutta ODE solvers and Gaussian filters, which gives only\na rough probabilistic calibration, but at negligible cost overhead. By\nformulating the solution of ODEs as approximate inference in linear Gaussian\nSDEs, we investigate a range of probabilistic ODE solvers, that bridge the\ntrade-off between computational cost and probabilistic calibration, and\nidentify the inaccurate gradient measurement as the crucial source of\nuncertainty. We propose the novel filtering-based method Bayesian Quadrature\nfiltering (BQF) which uses Bayesian quadrature to actively learn the\nimprecision in the gradient measurement by collecting multiple gradient\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 10:24:04 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 13:56:57 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 09:39:02 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kersting", "Hans", ""], ["Hennig", "Philipp", ""]]}, {"id": "1605.03391", "submitter": "Marvin N Wright", "authors": "Marvin N. Wright, Theresa Dankowski and Andreas Ziegler", "title": "Unbiased split variable selection for random survival forests using\n  maximally selected rank statistics", "comments": null, "journal-ref": "Wright, M. N., Dankowski, T. & Ziegler, A. (2017). Unbiased split\n  variable selection for random survival forests using maximally selected rank\n  statistics. Statistics in Medicine 36:1272-1284", "doi": "10.1002/sim.7212", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular approach for analyzing survival data is the Cox regression\nmodel. The Cox model may, however, be misspecified, and its proportionality\nassumption may not always be fulfilled. An alternative approach for survival\nprediction is random forests for survival outcomes. The standard split\ncriterion for random survival forests is the log-rank test statistics, which\nfavors splitting variables with many possible split points. Conditional\ninference forests avoid this split variable selection bias. However, linear\nrank statistics are utilized by default in conditional inference forests to\nselect the optimal splitting variable, which cannot detect non-linear effects\nin the independent variables. An alternative is to use maximally selected rank\nstatistics for the split point selection. As in conditional inference forests,\nsplitting variables are compared on the p-value scale. However, instead of the\nconditional Monte-Carlo approach used in conditional inference forests, p-value\napproximations are employed. We describe several p-value approximations and the\nimplementation of the proposed random forest approach. A simulation study\ndemonstrates that unbiased split variable selection is possible. However, there\nis a trade-off between unbiased split variable selection and runtime. In\nbenchmark studies of prediction performance on simulated and real datasets the\nnew method performs better than random survival forests if informative\ndichotomous variables are combined with uninformative variables with more\ncategories and better than conditional inference forests if non-linear\ncovariate effects are included. In a runtime comparison the method proves to be\ncomputationally faster than both alternatives, if a simple p-value\napproximation is used.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 11:48:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 12:24:46 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Wright", "Marvin N.", ""], ["Dankowski", "Theresa", ""], ["Ziegler", "Andreas", ""]]}, {"id": "1605.03468", "submitter": "Yanjun  Qi Dr.", "authors": "Beilun Wang, Ritambhara Singh and Yanjun Qi", "title": "A constrained L1 minimization approach for estimating multiple Sparse\n  Gaussian or Nonparanormal Graphical Models", "comments": "Extended Journal Version / Previously @ ICML 2016 comp. bio workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying context-specific entity networks from aggregated data is an\nimportant task, arising often in bioinformatics and neuroimaging.\nComputationally, this task can be formulated as jointly estimating multiple\ndifferent, but related, sparse Undirected Graphical Models (UGM) from\naggregated samples across several contexts. Previous joint-UGM studies have\nmostly focused on sparse Gaussian Graphical Models (sGGMs) and can't identify\ncontext-specific edge patterns directly. We, therefore, propose a novel\napproach, SIMULE (detecting Shared and Individual parts of MULtiple graphs\nExplicitly) to learn multi-UGM via a constrained L1 minimization. SIMULE\nautomatically infers both specific edge patterns that are unique to each\ncontext and shared interactions preserved among all the contexts. Through the\nL1 constrained formulation, this problem is cast as multiple independent\nsubtasks of linear programming that can be solved efficiently in parallel. In\naddition to Gaussian data, SIMULE can also handle multivariate Nonparanormal\ndata that greatly relaxes the normality assumption that many real-world\napplications do not follow. We provide a novel theoretical proof showing that\nSIMULE achieves a consistent result at the rate O(log(Kp)/n_{tot}). On multiple\nsynthetic datasets and two biomedical datasets, SIMULE shows significant\nimprovement over state-of-the-art multi-sGGM and single-UGM baselines.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 14:54:44 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 11:05:24 GMT"}, {"version": "v3", "created": "Thu, 2 Jun 2016 21:40:33 GMT"}, {"version": "v4", "created": "Tue, 18 Oct 2016 18:11:38 GMT"}, {"version": "v5", "created": "Wed, 8 Mar 2017 20:34:04 GMT"}, {"version": "v6", "created": "Mon, 18 Sep 2017 11:29:14 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Wang", "Beilun", ""], ["Singh", "Ritambhara", ""], ["Qi", "Yanjun", ""]]}, {"id": "1605.03481", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Zhong Zhou, Dylan Fitzpatrick, Michael Muehl, William\n  W. Cohen", "title": "Tweet2Vec: Character-Based Distributed Representations for Social Media", "comments": "6 pages, 2 figures, 4 tables, accepted as conference paper at ACL\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text from social media provides a set of challenges that can cause\ntraditional NLP approaches to fail. Informal language, spelling errors,\nabbreviations, and special characters are all commonplace in these posts,\nleading to a prohibitively large vocabulary size for word-level approaches. We\npropose a character composition model, tweet2vec, which finds vector-space\nrepresentations of whole tweets by learning complex, non-local dependencies in\ncharacter sequences. The proposed model outperforms a word-level baseline at\npredicting user-annotated hashtags associated with the posts, doing\nsignificantly better when the input contains many out-of-vocabulary words or\nunusual character sequences. Our tweet2vec encoder is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 15:30:09 GMT"}, {"version": "v2", "created": "Tue, 17 May 2016 15:00:38 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Zhou", "Zhong", ""], ["Fitzpatrick", "Dylan", ""], ["Muehl", "Michael", ""], ["Cohen", "William W.", ""]]}, {"id": "1605.03529", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani and Ohad Shamir", "title": "On the Iteration Complexity of Oblivious First-Order Optimization\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a broad class of first-order optimization algorithms which are\n\\emph{oblivious}, in the sense that their step sizes are scheduled regardless\nof the function under consideration, except for limited side-information such\nas smoothness or strong convexity parameters. With the knowledge of these two\nparameters, we show that any such algorithm attains an iteration complexity\nlower bound of $\\Omega(\\sqrt{L/\\epsilon})$ for $L$-smooth convex functions, and\n$\\tilde{\\Omega}(\\sqrt{L/\\mu}\\ln(1/\\epsilon))$ for $L$-smooth $\\mu$-strongly\nconvex functions. These lower bounds are stronger than those in the traditional\noracle model, as they hold independently of the dimension. To attain these, we\nabandon the oracle model in favor of a structure-based approach which builds\nupon a framework recently proposed in (Arjevani et al., 2015). We further show\nthat without knowing the strong convexity parameter, it is impossible to attain\nan iteration complexity better than\n$\\tilde{\\Omega}\\left((L/\\mu)\\ln(1/\\epsilon)\\right)$. This result is then used\nto formalize an observation regarding $L$-smooth convex functions, namely, that\nthe iteration complexity of algorithms employing time-invariant step sizes must\nbe at least $\\Omega(L/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 17:30:08 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Arjevani", "Yossi", ""], ["Shamir", "Ohad", ""]]}, {"id": "1605.03631", "submitter": "Bo Tang", "authors": "Bo Tang, Steven Kay, Haibo He, and Paul M. Baggenstoss", "title": "EEF: Exponentially Embedded Families with Class-Specific Features for\n  Classification", "comments": "9 pages, 3 figures, to be published in IEEE Signal Processing Letter.\n  IEEE Signal Processing Letter, 2016", "journal-ref": null, "doi": "10.1109/LSP.2016.2574327", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present a novel exponentially embedded families (EEF)\nbased classification method, in which the probability density function (PDF) on\nraw data is estimated from the PDF on features. With the PDF construction, we\nshow that class-specific features can be used in the proposed classification\nmethod, instead of a common feature subset for all classes as used in\nconventional approaches. We apply the proposed EEF classifier for text\ncategorization as a case study and derive an optimal Bayesian classification\nrule with class-specific feature selection based on the Information Gain (IG)\nscore. The promising performance on real-life data sets demonstrates the\neffectiveness of the proposed approach and indicates its wide potential\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 22:25:07 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 19:01:31 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Tang", "Bo", ""], ["Kay", "Steven", ""], ["He", "Haibo", ""], ["Baggenstoss", "Paul M.", ""]]}, {"id": "1605.03661", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, Uri Shalit and David Sontag", "title": "Learning Representations for Counterfactual Inference", "comments": "Appeared in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational studies are rising in importance due to the widespread\naccumulation of data in fields such as healthcare, education, employment and\necology. We consider the task of answering counterfactual questions such as,\n\"Would this patient have lower blood sugar had she received a different\nmedication?\". We propose a new algorithmic framework for counterfactual\ninference which brings together ideas from domain adaptation and representation\nlearning. In addition to a theoretical justification, we perform an empirical\ncomparison with previous approaches to causal inference from observational\ndata. Our deep learning algorithm significantly outperforms the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 02:59:40 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 17:04:07 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 13:00:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Shalit", "Uri", ""], ["Sontag", "David", ""]]}, {"id": "1605.03795", "submitter": "Alexander Novikov", "authors": "Alexander Novikov, Mikhail Trofimov, Ivan Oseledets", "title": "Exponential Machines", "comments": "ICLR-2017 workshop track paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling interactions between features improves the performance of machine\nlearning solutions in many domains (e.g. recommender systems or sentiment\nanalysis). In this paper, we introduce Exponential Machines (ExM), a predictor\nthat models all interactions of every order. The key idea is to represent an\nexponentially large tensor of parameters in a factorized format called Tensor\nTrain (TT). The Tensor Train format regularizes the model and lets you control\nthe number of underlying parameters. To train the model, we develop a\nstochastic Riemannian optimization procedure, which allows us to fit tensors\nwith 2^160 entries. We show that the model achieves state-of-the-art\nperformance on synthetic data with high-order interactions and that it works on\npar with high-order factorization machines on a recommender system dataset\nMovieLens 100K.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 13:08:11 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 10:24:08 GMT"}, {"version": "v3", "created": "Fri, 8 Dec 2017 08:17:58 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Novikov", "Alexander", ""], ["Trofimov", "Mikhail", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1605.03805", "submitter": "Richard Neuberg", "authors": "Richard Neuberg and Yixin Shi", "title": "Detecting Relative Anomaly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System states that are anomalous from the perspective of a domain expert\noccur frequently in some anomaly detection problems. The performance of\ncommonly used unsupervised anomaly detection methods may suffer in that\nsetting, because they use frequency as a proxy for anomaly. We propose a novel\nconcept for anomaly detection, called relative anomaly detection. It is\ntailored to be robust towards anomalies that occur frequently, by taking into\naccount their location relative to the most typical observations. The\napproaches we develop are computationally feasible even for large data sets,\nand they allow real-time detection. We illustrate using data sets of potential\nscraping attempts and Wi-Fi channel utilization, both from Google, Inc.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 13:29:45 GMT"}, {"version": "v2", "created": "Mon, 16 May 2016 15:29:52 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Neuberg", "Richard", ""], ["Shi", "Yixin", ""]]}, {"id": "1605.03835", "submitter": "KyungHyun Cho", "authors": "Kyunghyun Cho", "title": "Noisy Parallel Approximate Decoding for Conditional Recurrent Language\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in conditional recurrent language modelling have mainly\nfocused on network architectures (e.g., attention mechanism), learning\nalgorithms (e.g., scheduled sampling and sequence-level training) and novel\napplications (e.g., image/video description generation, speech recognition,\netc.) On the other hand, we notice that decoding algorithms/strategies have not\nbeen investigated as much, and it has become standard to use greedy or beam\nsearch. In this paper, we propose a novel decoding strategy motivated by an\nearlier observation that nonlinear hidden layers of a deep neural network\nstretch the data manifold. The proposed strategy is embarrassingly\nparallelizable without any communication overhead, while improving an existing\ndecoding algorithm. We extensively evaluate it with attention-based neural\nmachine translation on the task of En->Cz translation.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 14:39:50 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Cho", "Kyunghyun", ""]]}, {"id": "1605.03843", "submitter": "Dmitry Rokhlin B.", "authors": "Dmitry B. Rokhlin", "title": "Asymptotic sequential Rademacher complexity of a finite function class", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a finite function class we describe the large sample limit of the\nsequential Rademacher complexity in terms of the viscosity solution of a\n$G$-heat equation. In the language of Peng's sublinear expectation theory, the\nsame quantity equals to the expected value of the largest order statistics of a\nmultidimensional $G$-normal random variable. We illustrate this result by\nderiving upper and lower bounds for the asymptotic sequential Rademacher\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 19:49:57 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Rokhlin", "Dmitry B.", ""]]}, {"id": "1605.03848", "submitter": "Gilles Louppe", "authors": "Antonio Sutera, Gilles Louppe, V\\^an Anh Huynh-Thu, Louis Wehenkel,\n  Pierre Geurts", "title": "Context-dependent feature analysis with random forests", "comments": "Accepted for presentation at UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, feature selection is often more complicated than identifying a\nsingle subset of input variables that would together explain the output. There\nmay be interactions that depend on contextual information, i.e., variables that\nreveal to be relevant only in some specific circumstances. In this setting, the\ncontribution of this paper is to extend the random forest variable importances\nframework in order (i) to identify variables whose relevance is\ncontext-dependent and (ii) to characterize as precisely as possible the effect\nof contextual information on these variables. The usage and the relevance of\nour framework for highlighting context-dependent variables is illustrated on\nboth artificial and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 14:59:42 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Sutera", "Antonio", ""], ["Louppe", "Gilles", ""], ["Huynh-Thu", "V\u00e2n Anh", ""], ["Wehenkel", "Louis", ""], ["Geurts", "Pierre", ""]]}, {"id": "1605.03933", "submitter": "Jieming Mao", "authors": "Xi Chen, Sivakanth Gopi, Jieming Mao, Jon Schneider", "title": "Competitive analysis of the top-K ranking problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in recommender systems, web search, social choice\nand crowdsourcing, we consider the problem of identifying the set of top $K$\nitems from noisy pairwise comparisons. In our setting, we are non-actively\ngiven $r$ pairwise comparisons between each pair of $n$ items, where each\ncomparison has noise constrained by a very general noise model called the\nstrong stochastic transitivity (SST) model. We analyze the competitive ratio of\nalgorithms for the top-$K$ problem. In particular, we present a linear time\nalgorithm for the top-$K$ problem which has a competitive ratio of\n$\\tilde{O}(\\sqrt{n})$; i.e. to solve any instance of top-$K$, our algorithm\nneeds at most $\\tilde{O}(\\sqrt{n})$ times as many samples needed as the best\npossible algorithm for that instance (in contrast, all previous known\nalgorithms for the top-$K$ problem have competitive ratios of\n$\\tilde{\\Omega}(n)$ or worse). We further show that this is tight: any\nalgorithm for the top-$K$ problem has competitive ratio at least\n$\\tilde{\\Omega}(\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 19:07:31 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Chen", "Xi", ""], ["Gopi", "Sivakanth", ""], ["Mao", "Jieming", ""], ["Schneider", "Jon", ""]]}, {"id": "1605.04034", "submitter": "Joey Tianyi Zhou Dr", "authors": "Joey Tianyi Zhou, Xinxing Xu, Sinno Jialin Pan, Ivor W. Tsang, Zheng\n  Qin and Rick Siow Mong Goh", "title": "Transfer Hashing with Privileged Information", "comments": "Accepted by IJCAI-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing learning to hash methods assume that there are sufficient data,\neither labeled or unlabeled, on the domain of interest (i.e., the target\ndomain) for training. However, this assumption cannot be satisfied in some\nreal-world applications. To address this data sparsity issue in hashing,\ninspired by transfer learning, we propose a new framework named Transfer\nHashing with Privileged Information (THPI). Specifically, we extend the\nstandard learning to hash method, Iterative Quantization (ITQ), in a transfer\nlearning manner, namely ITQ+. In ITQ+, a new slack function is learned from\nauxiliary data to approximate the quantization error in ITQ. We developed an\nalternating optimization approach to solve the resultant optimization problem\nfor ITQ+. We further extend ITQ+ to LapITQ+ by utilizing the geometry structure\namong the auxiliary data for learning more precise binary codes in the target\ndomain. Extensive experiments on several benchmark datasets verify the\neffectiveness of our proposed approaches through comparisons with several\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 02:49:43 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Zhou", "Joey Tianyi", ""], ["Xu", "Xinxing", ""], ["Pan", "Sinno Jialin", ""], ["Tsang", "Ivor W.", ""], ["Qin", "Zheng", ""], ["Goh", "Rick Siow Mong", ""]]}, {"id": "1605.04056", "submitter": "Rumi Ghosh", "authors": "Katerina Marazopoulou, Rumi Ghosh, Prasanth Lade, David Jensen", "title": "Causal Discovery for Manufacturing Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yield and quality improvement is of paramount importance to any manufacturing\ncompany. One of the ways of improving yield is through discovery of the root\ncausal factors affecting yield. We propose the use of data-driven interpretable\ncausal models to identify key factors affecting yield. We focus on factors that\nare measured in different stages of production and testing in the manufacturing\ncycle of a product. We apply causal structure learning techniques on real data\ncollected from this line. Specifically, the goal of this work is to learn\ninterpretable causal models from observational data produced by manufacturing\nlines.\n  Emphasis has been given to the interpretability of the models to make them\nactionable in the field of manufacturing. We highlight the challenges presented\nby assembly line data and propose ways to alleviate them.We also identify\nunique characteristics of data originating from assembly lines and how to\nleverage them in order to improve causal discovery. Standard evaluation\ntechniques for causal structure learning shows that the learned causal models\nseem to closely represent the underlying latent causal relationship between\ndifferent factors in the production process. These results were also validated\nby manufacturing domain experts who found them promising. This work\ndemonstrates how data mining and knowledge discovery can be used for root cause\nanalysis in the domain of manufacturing and connected industry.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 06:17:54 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 22:51:23 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Marazopoulou", "Katerina", ""], ["Ghosh", "Rumi", ""], ["Lade", "Prasanth", ""], ["Jensen", "David", ""]]}, {"id": "1605.04070", "submitter": "Elad Yom-Tov", "authors": "Irit Hochberg and Guy Feraru and Mark Kozdoba and Shie Mannor and\n  Moshe Tennenholtz and Elad Yom-Tov", "title": "A Reinforcement Learning System to Encourage Physical Activity in\n  Diabetes Patients", "comments": null, "journal-ref": null, "doi": "10.2196/jmir.7994", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular physical activity is known to be beneficial to people suffering from\ndiabetes type 2. Nevertheless, most such people are sedentary. Smartphones\ncreate new possibilities for helping people to adhere to their physical\nactivity goals, through continuous monitoring and communication, coupled with\npersonalized feedback.\n  We provided 27 sedentary diabetes type 2 patients with a smartphone-based\npedometer and a personal plan for physical activity. Patients were sent SMS\nmessages to encourage physical activity between once a day and once per week.\nMessages were personalized through a Reinforcement Learning (RL) algorithm\nwhich optimized messages to improve each participant's compliance with the\nactivity regimen. The RL algorithm was compared to a static policy for sending\nmessages and to weekly reminders.\n  Our results show that participants who received messages generated by the RL\nalgorithm increased the amount of activity and pace of walking, while the\ncontrol group patients did not. Patients assigned to the RL algorithm group\nexperienced a superior reduction in blood glucose levels (HbA1c) compared to\ncontrol policies, and longer participation caused greater reductions in blood\nglucose levels. The learning algorithm improved gradually in predicting which\nmessages would lead participants to exercise.\n  Our results suggest that a mobile phone application coupled with a learning\nalgorithm can improve adherence to exercise in diabetic patients. As a learning\nalgorithm is automated, and delivers personalized messages, it could be used in\nlarge populations of diabetic patients to improve health and glycemic control.\nOur results can be expanded to other areas where computer-led health coaching\nof humans may have a positive impact.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 07:25:14 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Hochberg", "Irit", ""], ["Feraru", "Guy", ""], ["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""], ["Tennenholtz", "Moshe", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1605.04131", "submitter": "Conghui Tan", "authors": "Conghui Tan, Shiqian Ma, Yu-Hong Dai, Yuqiu Qian", "title": "Barzilai-Borwein Step Size for Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major issues in stochastic gradient descent (SGD) methods is how\nto choose an appropriate step size while running the algorithm. Since the\ntraditional line search technique does not apply for stochastic optimization\nalgorithms, the common practice in SGD is either to use a diminishing step\nsize, or to tune a fixed step size by hand, which can be time consuming in\npractice. In this paper, we propose to use the Barzilai-Borwein (BB) method to\nautomatically compute step sizes for SGD and its variant: stochastic variance\nreduced gradient (SVRG) method, which leads to two algorithms: SGD-BB and\nSVRG-BB. We prove that SVRG-BB converges linearly for strongly convex objective\nfunctions. As a by-product, we prove the linear convergence result of SVRG with\nOption I proposed in [10], whose convergence result is missing in the\nliterature. Numerical experiments on standard data sets show that the\nperformance of SGD-BB and SVRG-BB is comparable to and sometimes even better\nthan SGD and SVRG with best-tuned step sizes, and is superior to some advanced\nSGD variants.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 11:08:50 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 02:51:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Tan", "Conghui", ""], ["Ma", "Shiqian", ""], ["Dai", "Yu-Hong", ""], ["Qian", "Yuqiu", ""]]}, {"id": "1605.04135", "submitter": "Purushottam Kar", "authors": "Purushottam Kar and Shuai Li and Harikrishna Narasimhan and Sanjay\n  Chawla and Fabrizio Sebastiani", "title": "Online Optimization Methods for the Quantification Problem", "comments": "26 pages, 6 figures. A short version of this manuscript will appear\n  in the proceedings of the 22nd ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining, KDD 2016", "journal-ref": null, "doi": "10.1145/2939672.2939832", "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of class prevalence, i.e., the fraction of a population that\nbelongs to a certain class, is a very useful tool in data analytics and\nlearning, and finds applications in many domains such as sentiment analysis,\nepidemiology, etc. For example, in sentiment analysis, the objective is often\nnot to estimate whether a specific text conveys a positive or a negative\nsentiment, but rather estimate the overall distribution of positive and\nnegative sentiments during an event window. A popular way of performing the\nabove task, often dubbed quantification, is to use supervised learning to train\na prevalence estimator from labeled data.\n  Contemporary literature cites several performance measures used to measure\nthe success of such prevalence estimators. In this paper we propose the first\nonline stochastic algorithms for directly optimizing these\nquantification-specific performance measures. We also provide algorithms that\noptimize hybrid performance measures that seek to balance quantification and\nclassification performance. Our algorithms present a significant advancement in\nthe theory of multivariate optimization and we show, by a rigorous theoretical\nanalysis, that they exhibit optimal convergence. We also report extensive\nexperiments on benchmark and real data sets which demonstrate that our methods\nsignificantly outperform existing optimization techniques used for these\nperformance measures.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 11:14:58 GMT"}, {"version": "v2", "created": "Mon, 16 May 2016 04:29:47 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 18:11:54 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Kar", "Purushottam", ""], ["Li", "Shuai", ""], ["Narasimhan", "Harikrishna", ""], ["Chawla", "Sanjay", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1605.04337", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Shivani Agarwal", "title": "Support Vector Algorithms for Optimizing the Partial Area Under the ROC\n  Curve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area under the ROC curve (AUC) is a widely used performance measure in\nmachine learning. Increasingly, however, in several applications, ranging from\nranking to biometric screening to medicine, performance is measured not in\nterms of the full area under the ROC curve, but in terms of the \\emph{partial}\narea under the ROC curve between two false positive rates. In this paper, we\ndevelop support vector algorithms for directly optimizing the partial AUC\nbetween any two false positive rates. Our methods are based on minimizing a\nsuitable proxy or surrogate objective for the partial AUC error. In the case of\nthe full AUC, one can readily construct and optimize convex surrogates by\nexpressing the performance measure as a summation of pairwise terms. The\npartial AUC, on the other hand, does not admit such a simple decomposable\nstructure, making it more challenging to design and optimize (tight) convex\nsurrogates for this measure.\n  Our approach builds on the structural SVM framework of Joachims (2005) to\ndesign convex surrogates for partial AUC, and solves the resulting optimization\nproblem using a cutting plane solver. Unlike the full AUC, where the\ncombinatorial optimization needed in each iteration of the cutting plane solver\ncan be decomposed and solved efficiently, the corresponding problem for the\npartial AUC is harder to decompose. One of our main contributions is a\npolynomial time algorithm for solving the combinatorial optimization problem\nassociated with partial AUC. We also develop an approach for optimizing a\ntighter non-convex hinge loss based surrogate for the partial AUC using\ndifference-of-convex programming. Our experiments on a variety of real-world\nand benchmark tasks confirm the efficacy of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 21:33:45 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Agarwal", "Shivani", ""]]}, {"id": "1605.04465", "submitter": "Avradeep Bhowmik", "authors": "Avradeep Bhowmik, Joydeep Ghosh", "title": "Monotone Retargeting for Unsupervised Rank Aggregation with Object\n  Features", "comments": "15 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the true ordering between objects by aggregating a set of expert\nopinion rank order lists is an important and ubiquitous problem in many\napplications ranging from social choice theory to natural language processing\nand search aggregation. We study the problem of unsupervised rank aggregation\nwhere no ground truth ordering information in available, neither about the true\npreference ordering between any set of objects nor about the quality of\nindividual rank lists. Aggregating the often inconsistent and poor quality rank\nlists in such an unsupervised manner is a highly challenging problem, and\nstandard consensus-based methods are often ill-defined, and difficult to solve.\nIn this manuscript we propose a novel framework to bypass these issues by using\nobject attributes to augment the standard rank aggregation framework. We design\nalgorithms that learn joint models on both rank lists and object features to\nobtain an aggregated rank ordering that is more accurate and robust, and also\nhelps weed out rank lists of dubious validity. We validate our techniques on\nsynthetic datasets where our algorithm is able to estimate the true rank\nordering even when the rank lists are corrupted. Experiments on three real\ndatasets, MQ2008, MQ2008 and OHSUMED, show that using object features can\nresult in significant improvement in performance over existing rank aggregation\nmethods that do not use object information. Furthermore, when at least some of\nthe rank lists are of high quality, our methods are able to effectively exploit\ntheir high expertise to output an aggregated rank ordering of great accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 20:35:20 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bhowmik", "Avradeep", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1605.04466", "submitter": "Avradeep Bhowmik", "authors": "Avradeep Bhowmik, Joydeep Ghosh, Oluwasanmi Koyejo", "title": "Generalized Linear Models for Aggregated Data", "comments": "AISTATS 2015, 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Databases in domains such as healthcare are routinely released to the public\nin aggregated form. Unfortunately, naive modeling with aggregated data may\nsignificantly diminish the accuracy of inferences at the individual level. This\npaper addresses the scenario where features are provided at the individual\nlevel, but the target variables are only available as histogram aggregates or\norder statistics. We consider a limiting case of generalized linear modeling\nwhen the target variables are only known up to permutation, and explore how\nthis relates to permutation testing; a standard technique for assessing\nstatistical dependency. Based on this relationship, we propose a simple\nalgorithm to estimate the model parameters and individual level inferences via\nalternating imputation and standard generalized linear model fitting. Our\nresults suggest the effectiveness of the proposed approach when, in the\noriginal data, permutation testing accurately ascertains the veracity of the\nlinear relationship. The framework is extended to general histogram data with\nlarger bins - with order statistics such as the median as a limiting case. Our\nexperimental results on simulated data and aggregated healthcare data suggest a\ndiminishing returns property with respect to the granularity of the histogram -\nwhen a linear relationship holds in the original data, the targets can be\npredicted accurately given relatively coarse histograms.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 21:09:10 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bhowmik", "Avradeep", ""], ["Ghosh", "Joydeep", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1605.04614", "submitter": "Amund Tveit", "authors": "Amund Tveit, Torbj{\\o}rn Morland and Thomas Brox R{\\o}st", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's\n  iOS, OS X and tvOS developed in Metal and Swift", "comments": "9 pages, 12 figures, open source documentation and code at\n  deeplearningkit.org and github.com/deeplearningkit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present DeepLearningKit - an open source framework that\nsupports using pretrained deep learning models (convolutional neural networks)\nfor iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to\nutilize the GPU efficiently and Swift for integration with applications, e.g.\niOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS\nX desktop applications. The goal is to support using deep learning models\ntrained with popular frameworks such as Caffe, Torch, TensorFlow, Theano,\nPylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time\nrequired to train Deep Learning models we suggest an App Store like model to\ndistribute and download pretrained and reusable Deep Learning models.\n", "versions": [{"version": "v1", "created": "Sun, 15 May 2016 23:19:48 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Tveit", "Amund", ""], ["Morland", "Torbj\u00f8rn", ""], ["R\u00f8st", "Thomas Brox", ""]]}, {"id": "1605.04624", "submitter": "Viet Ha-Thuc", "authors": "Viet Ha-Thuc and Shakti Sinha", "title": "Learning to Rank Personalized Search Results in Professional Networks", "comments": null, "journal-ref": "SIGIR 2016", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LinkedIn search is deeply personalized - for the same queries, different\nsearchers expect completely different results. This paper presents our approach\nto achieving this by mining various data sources available in LinkedIn to infer\nsearchers' intents (such as hiring, job seeking, etc.), as well as extending\nthe concept of homophily to capture the searcher-result similarities on many\naspects. Then, learning-to-rank (LTR) is applied to combine these signals with\nstandard search features.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 00:59:07 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Ha-Thuc", "Viet", ""], ["Sinha", "Shakti", ""]]}, {"id": "1605.04638", "submitter": "Tianbao Yang", "authors": "Tianbao Yang, Lijun Zhang, Rong Jin, Jinfeng Yi", "title": "Tracking Slowly Moving Clairvoyant: Optimal Dynamic Regret of Online\n  Learning with True and Noisy Gradient", "comments": "Accepted by the 33rd International Conference on Machine Learning\n  (ICML 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on dynamic regret of online convex optimization that\ncompares the performance of online learning to a clairvoyant who knows the\nsequence of loss functions in advance and hence selects the minimizer of the\nloss function at each step. By assuming that the clairvoyant moves slowly\n(i.e., the minimizers change slowly), we present several improved\nvariation-based upper bounds of the dynamic regret under the true and noisy\ngradient feedback, which are {\\it optimal} in light of the presented lower\nbounds. The key to our analysis is to explore a regularity metric that measures\nthe temporal changes in the clairvoyant's minimizers, to which we refer as {\\it\npath variation}. Firstly, we present a general lower bound in terms of the path\nvariation, and then show that under full information or gradient feedback we\nare able to achieve an optimal dynamic regret. Secondly, we present a lower\nbound with noisy gradient feedback and then show that we can achieve optimal\ndynamic regrets under a stochastic gradient feedback and two-point bandit\nfeedback. Moreover, for a sequence of smooth loss functions that admit a small\nvariation in the gradients, our dynamic regret under the two-point bandit\nfeedback matches what is achieved with full information.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 03:01:41 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Yang", "Tianbao", ""], ["Zhang", "Lijun", ""], ["Jin", "Rong", ""], ["Yi", "Jinfeng", ""]]}, {"id": "1605.04639", "submitter": "Akira Imakura", "authors": "Tetsuya Sakurai, Akira Imakura, Yuto Inoue and Yasunori Futamura", "title": "Alternating optimization method based on nonnegative matrix\n  factorizations for deep neural networks", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm for calculating gradients has been widely used\nin computation of weights for deep neural networks (DNNs). This method requires\nderivatives of objective functions and has some difficulties finding\nappropriate parameters such as learning rate. In this paper, we propose a novel\napproach for computing weight matrices of fully-connected DNNs by using two\ntypes of semi-nonnegative matrix factorizations (semi-NMFs). In this method,\noptimization processes are performed by calculating weight matrices\nalternately, and backpropagation (BP) is not used. We also present a method to\ncalculate stacked autoencoder using a NMF. The output results of the\nautoencoder are used as pre-training data for DNNs. The experimental results\nshow that our method using three types of NMFs attains similar error rates to\nthe conventional DNNs with BP.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 03:11:17 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Sakurai", "Tetsuya", ""], ["Imakura", "Akira", ""], ["Inoue", "Yuto", ""], ["Futamura", "Yasunori", ""]]}, {"id": "1605.04652", "submitter": "Anand Padmanabha Iyer", "authors": "Anand Padmanabha Iyer, Ion Stoica, Mosharaf Chowdhury, Li Erran Li", "title": "Fast and Accurate Performance Analysis of LTE Radio Access Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of analytics is performed on data that is procured in a\nreal-time fashion to make real-time decisions. Such tasks include simple\nreporting on streams to sophisticated model building. However, the practicality\nof such analyses are impeded in several domains because they are faced with a\nfundamental trade-off between data collection latency and analysis accuracy.\n  In this paper, we study this trade-off in the context of a specific domain,\nCellular Radio Access Networks (RAN). Our choice of this domain is influenced\nby its commonalities with several other domains that produce real-time data,\nour access to a large live dataset, and their real-time nature and\ndimensionality which makes it a natural fit for a popular analysis technique,\nmachine learning (ML). We find that the latency accuracy trade-off can be\nresolved using two broad, general techniques: intelligent data grouping and\ntask formulations that leverage domain characteristics. Based on this, we\npresent CellScope, a system that addresses this challenge by applying a domain\nspecific formulation and application of Multi-task Learning (MTL) to RAN\nperformance analysis. It achieves this goal using three techniques: feature\nengineering to transform raw data into effective features, a PCA inspired\nsimilarity metric to group data from geographically nearby base stations\nsharing performance commonalities, and a hybrid online-offline model for\nefficient model updates. Our evaluation of CellScope shows that its accuracy\nimprovements over direct application of ML range from 2.5x to 4.4x while\nreducing the model update overhead by up to 4.8x. We have also used CellScope\nto analyze a live LTE consisting of over 2 million subscribers for a period of\nover 10 months, where it uncovered several problems and insights, some of them\npreviously unknown.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 05:31:01 GMT"}, {"version": "v2", "created": "Tue, 17 May 2016 20:00:59 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Iyer", "Anand Padmanabha", ""], ["Stoica", "Ion", ""], ["Chowdhury", "Mosharaf", ""], ["Li", "Li Erran", ""]]}, {"id": "1605.04655", "submitter": "Petr Baudi\\v{s}", "authors": "Petr Baudis, Silvestr Stanko and Jan Sedivy", "title": "Joint Learning of Sentence Embeddings for Relevance and Entailment", "comments": "repl4nlp workshop at ACL Berlin 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of Recognizing Textual Entailment within an\nInformation Retrieval context, where we must simultaneously determine the\nrelevancy as well as degree of entailment for individual pieces of evidence to\ndetermine a yes/no answer to a binary natural language question.\n  We compare several variants of neural networks for sentence embeddings in a\nsetting of decision-making based on evidence of varying relevance. We propose a\nbasic model to integrate evidence for entailment, show that joint training of\nthe sentence embeddings to model relevance and entailment is feasible even with\nno explicit per-evidence supervision, and show the importance of evaluating\nstrong baselines. We also demonstrate the benefit of carrying over text\ncomprehension model trained on an unrelated task for our small datasets.\n  Our research is motivated primarily by a new open dataset we introduce,\nconsisting of binary questions and news-based evidence snippets. We also apply\nthe proposed relevance-entailment model on a similar task of ranking\nmultiple-choice test answers, evaluating it on a preliminary dataset of school\ntest questions as well as the standard MCTest dataset, where we improve the\nneural model state-of-art.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 05:50:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 22:41:26 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Baudis", "Petr", ""], ["Stanko", "Silvestr", ""], ["Sedivy", "Jan", ""]]}, {"id": "1605.04657", "submitter": "Mithun Das Gupta", "authors": "Mithun Das Gupta", "title": "Solve-Select-Scale: A Three Step Process For Sparse Signal Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the theory of compressed sensing (CS), the sparsity $\\|x\\|_0$ of the\nunknown signal $\\mathbf{x} \\in \\mathcal{R}^n$ is of prime importance and the\nfocus of reconstruction algorithms has mainly been either $\\|x\\|_0$ or its\nconvex relaxation (via $\\|x\\|_1$). However, it is typically unknown in practice\nand has remained a challenge when nothing about the size of the support is\nknown. As pointed recently, $\\|x\\|_0$ might not be the best metric to minimize\ndirectly, both due to its inherent complexity as well as its noise performance.\nRecently a novel stable measure of sparsity $s(\\mathbf{x}) :=\n\\|\\mathbf{x}\\|_1^2/\\|\\mathbf{x}\\|_2^2$ has been investigated by Lopes\n\\cite{Lopes2012}, which is a sharp lower bound on $\\|\\mathbf{x}\\|_0$. The\nestimation procedure for this measure uses only a small number of linear\nmeasurements, does not rely on any sparsity assumptions, and requires very\nlittle computation. The usage of the quantity $s(\\mathbf{x})$ in sparse signal\nestimation problems has not received much importance yet. We develop the idea\nof incorporating $s(\\mathbf{x})$ into the signal estimation framework. We also\nprovide a three step algorithm to solve problems of the form $\\mathbf{Ax=b}$\nwith no additional assumptions on the original signal $\\mathbf{x}$.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 06:10:44 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Gupta", "Mithun Das", ""]]}, {"id": "1605.04672", "submitter": "Pushpendre Rastogi", "authors": "Pushpendre Rastogi, Benjamin Van Durme", "title": "A Critical Examination of RESCAL for Completion of Knowledge Bases with\n  Transitive Relations", "comments": "Four and a half page", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction in large knowledge graphs has received a lot of attention\nrecently because of its importance for inferring missing relations and for\ncompleting and improving noisily extracted knowledge graphs. Over the years a\nnumber of machine learning researchers have presented various models for\npredicting the presence of missing relations in a knowledge base. Although all\nthe previous methods are presented with empirical results that show high\nperformance on select datasets, there is almost no previous work on\nunderstanding the connection between properties of a knowledge base and the\nperformance of a model. In this paper we analyze the RESCAL method and prove\nthat it can not encode asymmetric transitive relations in knowledge bases.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 07:43:28 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Rastogi", "Pushpendre", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1605.04731", "submitter": "Xianye Liang", "authors": "Xianye Liang, Bocheng Zhuo, Peijie Li, Liangju He", "title": "CNN based texture synthesize with Semantic segment", "comments": "7 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1505.07376, arXiv:1604.04339, arXiv:1602.07188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithm display powerful ability in Computer Vision area, in\nrecent year, the CNN has been applied to solve problems in the subarea of\nImage-generating, which has been widely applied in areas such as photo editing,\nimage design, computer animation, real-time rendering for large scale of scenes\nand for visual effects in movies. However in the texture synthesize procedure.\nThe state-of-art CNN can not capture the spatial location of texture in image,\nlead to significant distortion after texture synthesize, we propose a new way\nto generating-image by adding the semantic segment step with deep learning\nalgorithm as Pre-Processing and analyze the outcome.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 11:24:03 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Liang", "Xianye", ""], ["Zhuo", "Bocheng", ""], ["Li", "Peijie", ""], ["He", "Liangju", ""]]}, {"id": "1605.04764", "submitter": "Avradeep Bhowmik", "authors": "Avradeep Bhowmik, Nathan Liu, Erheng Zhong, Badri Narayan Bhaskar,\n  Suju Rajan", "title": "Geometry Aware Mappings for High Dimensional Sparse Factors", "comments": "AISTATS 2016, 13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While matrix factorisation models are ubiquitous in large scale\nrecommendation and search, real time application of such models requires inner\nproduct computations over an intractably large set of item factors. In this\nmanuscript we present a novel framework that uses the inverted index\nrepresentation to exploit structural properties of sparse vectors to\nsignificantly reduce the run time computational cost of factorisation models.\nWe develop techniques that use geometry aware permutation maps on a tessellated\nunit sphere to obtain high dimensional sparse embeddings for latent factors\nwith sparsity patterns related to angular closeness of the original latent\nfactors. We also design several efficient and deterministic realisations within\nthis framework and demonstrate with experiments that our techniques lead to\nfaster run time operation with minimal loss of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 13:21:15 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Bhowmik", "Avradeep", ""], ["Liu", "Nathan", ""], ["Zhong", "Erheng", ""], ["Bhaskar", "Badri Narayan", ""], ["Rajan", "Suju", ""]]}, {"id": "1605.04812", "submitter": "Adith Swaminathan", "authors": "Adith Swaminathan, Akshay Krishnamurthy, Alekh Agarwal, Miroslav\n  Dud\\'ik, John Langford, Damien Jose, Imed Zitouni", "title": "Off-policy evaluation for slate recommendation", "comments": "31 pages (9 main paper, 20 supplementary), 12 figures (2 main paper,\n  10 supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the evaluation of policies that recommend an ordered set\nof items (e.g., a ranking) based on some context---a common scenario in web\nsearch, ads, and recommendation. We build on techniques from combinatorial\nbandits to introduce a new practical estimator that uses logged data to\nestimate a policy's performance. A thorough empirical evaluation on real-world\ndata reveals that our estimator is accurate in a variety of settings, including\nas a subroutine in a learning-to-rank task, where it achieves competitive\nperformance. We derive conditions under which our estimator is unbiased---these\nconditions are weaker than prior heuristics for slate evaluation---and\nexperimentally demonstrate a smaller bias than parametric approaches, even when\nthese conditions are violated. Finally, our theory and experiments also show\nexponential savings in the amount of required data compared with general\nunbiased estimators.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 15:47:21 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 10:34:21 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 22:55:48 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Swaminathan", "Adith", ""], ["Krishnamurthy", "Akshay", ""], ["Agarwal", "Alekh", ""], ["Dud\u00edk", "Miroslav", ""], ["Langford", "John", ""], ["Jose", "Damien", ""], ["Zitouni", "Imed", ""]]}, {"id": "1605.04859", "submitter": "Ming Tu", "authors": "Ming Tu, Visar Berisha, Yu Cao, Jae-sun Seo", "title": "Reducing the Model Order of Deep Neural Networks Using Information\n  Theory", "comments": "To appear in ISVLSI 2016 special session", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically represented by a much larger number of\nparameters than shallow models, making them prohibitive for small footprint\ndevices. Recent research shows that there is considerable redundancy in the\nparameter space of deep neural networks. In this paper, we propose a method to\ncompress deep neural networks by using the Fisher Information metric, which we\nestimate through a stochastic optimization method that keeps track of\nsecond-order information in the network. We first remove unimportant parameters\nand then use non-uniform fixed point quantization to assign more bits to\nparameters with higher Fisher Information estimates. We evaluate our method on\na classification task with a convolutional neural network trained on the MNIST\ndata set. Experimental results show that our method outperforms existing\nmethods for both network pruning and quantization.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 18:12:45 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Tu", "Ming", ""], ["Berisha", "Visar", ""], ["Cao", "Yu", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1605.04874", "submitter": "Amir Hosein Zamanian", "authors": "Amir Hosein Zamanian, Abdolreza Ohadi", "title": "Gearbox Fault Detection through PSO Exact Wavelet Analysis and SVM\n  Classifier", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.4983.3442", "report-no": "ISME2010-3820", "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-frequency methods for vibration-based gearbox faults detection have been\nconsidered the most efficient method. Among these methods, continuous wavelet\ntransform (CWT) as one of the best time-frequency method has been used for both\nstationary and transitory signals. Some deficiencies of CWT are problem of\noverlapping and distortion ofsignals. In this condition, a large amount of\nredundant information exists so that it may cause false alarm or\nmisinterpretation of the operator. In this paper a modified method called Exact\nWavelet Analysis is used to minimize the effects of overlapping and distortion\nin case of gearbox faults. To implement exact wavelet analysis, Particle Swarm\nOptimization (PSO) algorithm has been used for this purpose. This method have\nbeen implemented for the acceleration signals from 2D acceleration sensor\nacquired by Advantech PCI-1710 card from a gearbox test setup in Amirkabir\nUniversity of Technology. Gearbox has been considered in both healthy and\nchipped tooth gears conditions. Kernelized Support Vector Machine (SVM) with\nradial basis functions has used the extracted features from exact wavelet\nanalysis for classification. The efficiency of this classifier is then\nevaluated with the other signals acquired from the setup test. The results show\nthat in comparison of CWT, PSO Exact Wavelet Transform has better ability in\nfeature extraction in price of more computational effort. In addition, PSO\nexact wavelet has better speed comparing to Genetic Algorithm (GA) exact\nwavelet in condition of equal population because of factoring mutation and\ncrossover in PSO algorithm. SVM classifier with the extracted features in\ngearbox shows very good results and its ability has been proved.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 23:29:29 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Zamanian", "Amir Hosein", ""], ["Ohadi", "Abdolreza", ""]]}, {"id": "1605.04986", "submitter": "Dennis Wei", "authors": "Dennis Wei", "title": "A Constant-Factor Bi-Criteria Approximation Guarantee for $k$-means++", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the $k$-means++ algorithm for clustering as well as the\nclass of $D^\\ell$ sampling algorithms to which $k$-means++ belongs. It is shown\nthat for any constant factor $\\beta > 1$, selecting $\\beta k$ cluster centers\nby $D^\\ell$ sampling yields a constant-factor approximation to the optimal\nclustering with $k$ centers, in expectation and without conditions on the\ndataset. This result extends the previously known $O(\\log k)$ guarantee for the\ncase $\\beta = 1$ to the constant-factor bi-criteria regime. It also improves\nupon an existing constant-factor bi-criteria result that holds only with\nconstant probability.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 23:41:55 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Wei", "Dennis", ""]]}, {"id": "1605.05011", "submitter": "Dong Huang", "authors": "Dong Huang, Chang-Dong Wang, Jian-Huang Lai", "title": "Locally Weighted Ensemble Clustering", "comments": "The MATLAB source code and experimental data of this work are\n  available at: https://www.researchgate.net/publication/316681928", "journal-ref": "IEEE Transactions on Cybernetics, 2018, vol.48, no.5, pp.1460-1473", "doi": "10.1109/TCYB.2017.2702343", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its ability to combine multiple base clusterings into a probably\nbetter and more robust clustering, the ensemble clustering technique has been\nattracting increasing attention in recent years. Despite the significant\nsuccess, one limitation to most of the existing ensemble clustering methods is\nthat they generally treat all base clusterings equally regardless of their\nreliability, which makes them vulnerable to low-quality base clusterings.\nAlthough some efforts have been made to (globally) evaluate and weight the base\nclusterings, yet these methods tend to view each base clustering as an\nindividual and neglect the local diversity of clusters inside the same base\nclustering. It remains an open problem how to evaluate the reliability of\nclusters and exploit the local diversity in the ensemble to enhance the\nconsensus performance, especially in the case when there is no access to data\nfeatures or specific assumptions on data distribution. To address this, in this\npaper, we propose a novel ensemble clustering approach based on ensemble-driven\ncluster uncertainty estimation and local weighting strategy. In particular, the\nuncertainty of each cluster is estimated by considering the cluster labels in\nthe entire ensemble via an entropic criterion. A novel ensemble-driven cluster\nvalidity measure is introduced, and a locally weighted co-association matrix is\npresented to serve as a summary for the ensemble of diverse clusters. With the\nlocal diversity in ensembles exploited, two novel consensus functions are\nfurther proposed. Extensive experiments on a variety of real-world datasets\ndemonstrate the superiority of the proposed approach over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 03:52:38 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 16:35:41 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 10:00:22 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Huang", "Dong", ""], ["Wang", "Chang-Dong", ""], ["Lai", "Jian-Huang", ""]]}, {"id": "1605.05045", "submitter": "Raffaello Camoriano", "authors": "Raffaello Camoriano, Giulia Pasquale, Carlo Ciliberto, Lorenzo Natale,\n  Lorenzo Rosasco, Giorgio Metta", "title": "Incremental Robot Learning of New Objects with Fixed Update Time", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider object recognition in the context of lifelong learning, where a\nrobotic agent learns to discriminate between a growing number of object classes\nas it accumulates experience about the environment. We propose an incremental\nvariant of the Regularized Least Squares for Classification (RLSC) algorithm,\nand exploit its structure to seamlessly add new classes to the learned model.\nThe presented algorithm addresses the problem of having an unbalanced\nproportion of training examples per class, which occurs when new objects are\npresented to the system for the first time.\n  We evaluate our algorithm on both a machine learning benchmark dataset and\ntwo challenging object recognition tasks in a robotic setting. Empirical\nevidence shows that our approach achieves comparable or higher classification\nperformance than its batch counterpart when classes are unbalanced, while being\nsignificantly faster.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 07:50:58 GMT"}, {"version": "v2", "created": "Wed, 25 Jan 2017 20:50:38 GMT"}, {"version": "v3", "created": "Tue, 28 Feb 2017 16:53:19 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Camoriano", "Raffaello", ""], ["Pasquale", "Giulia", ""], ["Ciliberto", "Carlo", ""], ["Natale", "Lorenzo", ""], ["Rosasco", "Lorenzo", ""], ["Metta", "Giorgio", ""]]}, {"id": "1605.05087", "submitter": "Hirotaka Niitsuma", "authors": "Hirotaka Niitsuma and Minho Lee", "title": "Word2Vec is a special case of Kernel Correspondence Analysis and Kernels\n  for Natural Language Processing", "comments": "add expeiments and code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that correspondence analysis (CA) is equivalent to defining a Gini\nindex with appropriately scaled one-hot encoding. Using this relation, we\nintroduce a nonlinear kernel extension to CA. This extended CA gives a known\nanalysis for natural language via specialized kernels that use an appropriate\ncontingency table. We propose a semi-supervised CA, which is a special case of\nthe kernel extension to CA. Because CA requires excessive memory if applied to\nnumerous categories, CA has not been used for natural language processing. We\naddress this problem by introducing delayed evaluation to randomized singular\nvalue decomposition. The memory-efficient CA is then applied to a word-vector\nrepresentation task. We propose a tail-cut kernel, which is an extension to the\nskip-gram within the kernel extension to CA. Our tail-cut kernel outperforms\nexisting word-vector representation methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 10:07:34 GMT"}, {"version": "v2", "created": "Sun, 14 Aug 2016 19:13:22 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 17:49:08 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Niitsuma", "Hirotaka", ""], ["Lee", "Minho", ""]]}, {"id": "1605.05142", "submitter": "Santosh Tirunagari", "authors": "Santosh Tirunagari, Simon Bull and Norman Poh", "title": "Automatic Classification of Irregularly Sampled Time Series with Unequal\n  Lengths: A Case Study on Estimated Glomerular Filtration Rate", "comments": null, "journal-ref": null, "doi": null, "report-no": "CS-CKD-2016-01", "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A patient's estimated glomerular filtration rate (eGFR) can provide important\ninformation about disease progression and kidney function. Traditionally, an\neGFR time series is interpreted by a human expert labelling it as stable or\nunstable. While this approach works for individual patients, the time consuming\nnature of it precludes the quick evaluation of risk in large numbers of\npatients. However, automating this process poses significant challenges as eGFR\nmeasurements are usually recorded at irregular intervals and the series of\nmeasurements differs in length between patients. Here we present a two-tier\nsystem to automatically classify an eGFR trend. First, we model the time series\nusing Gaussian process regression (GPR) to fill in `gaps' by resampling a fixed\nsize vector of fifty time-dependent observations. Second, we classify the\nresampled eGFR time series using a K-NN/SVM classifier, and evaluate its\nperformance via 5-fold cross validation. Using this approach we achieved an\nF-score of 0.90, compared to 0.96 for 5 human experts when scored amongst\nthemselves.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 12:46:46 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Tirunagari", "Santosh", ""], ["Bull", "Simon", ""], ["Poh", "Norman", ""]]}, {"id": "1605.05212", "submitter": "Youngjune Gwon", "authors": "Youngjune Gwon and William Campbell and Kevin Brady and Douglas Sturim\n  and Miriam Cha and H.T. Kung", "title": "Multimodal Sparse Coding for Event Detection", "comments": "Multimodal Machine Learning Workshop at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature learning methods have proven effective for\nclassification tasks based on a single modality. We present multimodal sparse\ncoding for learning feature representations shared across multiple modalities.\nThe shared representations are applied to multimedia event detection (MED) and\nevaluated in comparison to unimodal counterparts, as well as other feature\nlearning methods such as GMM supervectors and sparse RBM. We report the\ncross-validated classification accuracy and mean average precision of the MED\nsystem trained on features learned from our unimodal and multimodal settings\nfor a subset of the TRECVID MED 2014 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 15:37:19 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Gwon", "Youngjune", ""], ["Campbell", "William", ""], ["Brady", "Kevin", ""], ["Sturim", "Douglas", ""], ["Cha", "Miriam", ""], ["Kung", "H. T.", ""]]}, {"id": "1605.05223", "submitter": "Anna Choromanska", "authors": "Anna Choromanska and Krzysztof Choromanski and Mariusz Bojarski", "title": "On the boosting ability of top-down decision tree learning algorithm for\n  multiclass classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of the top-down multiclass classification\nalgorithm for decision tree learning called LOMtree, recently proposed in the\nliterature Choromanska and Langford (2014) for solving efficiently\nclassification problems with very large number of classes. The algorithm online\noptimizes the objective function which simultaneously controls the depth of the\ntree and its statistical accuracy. We prove important properties of this\nobjective and explore its connection to three well-known entropy-based decision\ntree objectives, i.e. Shannon entropy, Gini-entropy and its modified version,\nfor which instead online optimization schemes were not yet developed. We show,\nvia boosting-type guarantees, that maximizing the considered objective leads\nalso to the reduction of all of these entropy-based objectives. The bounds we\nobtain critically depend on the strong-concavity properties of the\nentropy-based criteria, where the mildest dependence on the number of classes\n(only logarithmic) corresponds to the Shannon entropy.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 16:11:36 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Choromanska", "Anna", ""], ["Choromanski", "Krzysztof", ""], ["Bojarski", "Mariusz", ""]]}, {"id": "1605.05239", "submitter": "Benjamin Migliori", "authors": "Benjamin Migliori, Riley Zeller-Townson, Daniel Grady, Daniel Gebhardt", "title": "Biologically Inspired Radio Signal Feature Extraction with Sparse\n  Denoising Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic modulation classification (AMC) is an important task for modern\ncommunication systems; however, it is a challenging problem when signal\nfeatures and precise models for generating each modulation may be unknown. We\npresent a new biologically-inspired AMC method without the need for models or\nmanually specified features --- thus removing the requirement for expert prior\nknowledge. We accomplish this task using regularized stacked sparse denoising\nautoencoders (SSDAs). Our method selects efficient classification features\ndirectly from raw in-phase/quadrature (I/Q) radio signals in an unsupervised\nmanner. These features are then used to construct higher-complexity abstract\nfeatures which can be used for automatic modulation classification. We\ndemonstrate this process using a dataset generated with a software defined\nradio, consisting of random input bits encoded in 100-sample segments of\nvarious common digital radio modulations. Our results show correct\nclassification rates of > 99% at 7.5 dB signal-to-noise ratio (SNR) and > 92%\nat 0 dB SNR in a 6-way classification test. Our experiments demonstrate a\ndramatically new and broadly applicable mechanism for performing AMC and\nrelated tasks without the need for expert-defined or modulation-specific signal\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 17:03:02 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Migliori", "Benjamin", ""], ["Zeller-Townson", "Riley", ""], ["Grady", "Daniel", ""], ["Gebhardt", "Daniel", ""]]}, {"id": "1605.05273", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Mohamed Ahmed and Konstantin Kutzkov", "title": "Learning Convolutional Neural Networks for Graphs", "comments": "To be presented at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous important problems can be framed as learning from graph data. We\npropose a framework for learning convolutional neural networks for arbitrary\ngraphs. These graphs may be undirected, directed, and with both discrete and\ncontinuous node and edge attributes. Analogous to image-based convolutional\nnetworks that operate on locally connected regions of the input, we present a\ngeneral approach to extracting locally connected regions from graphs. Using\nestablished benchmark data sets, we demonstrate that the learned feature\nrepresentations are competitive with state of the art graph kernels and that\ntheir computation is highly efficient.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 18:13:13 GMT"}, {"version": "v2", "created": "Wed, 18 May 2016 15:38:30 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 13:33:38 GMT"}, {"version": "v4", "created": "Wed, 8 Jun 2016 11:40:13 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Niepert", "Mathias", ""], ["Ahmed", "Mohamed", ""], ["Kutzkov", "Konstantin", ""]]}, {"id": "1605.05284", "submitter": "Zahra Shakeri", "authors": "Zahra Shakeri, Waheed U. Bajwa, Anand D. Sarwate", "title": "Minimax Lower Bounds for Kronecker-Structured Dictionary Learning", "comments": "5 pages, 1 figure. To appear in 2016 IEEE International Symposium on\n  Information Theory", "journal-ref": "Proc. IEEE Intl. Symp. Information Theory, Barcelona, Spain, Jul.\n  10-15, 2016, pp. 1148-1152", "doi": "10.1109/ISIT.2016.7541479", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is the problem of estimating the collection of atomic\nelements that provide a sparse representation of measured/collected signals or\ndata. This paper finds fundamental limits on the sample complexity of\nestimating dictionaries for tensor data by proving a lower bound on the minimax\nrisk. This lower bound depends on the dimensions of the tensor and parameters\nof the generative model. The focus of this paper is on second-order tensor\ndata, with the underlying dictionaries constructed by taking the Kronecker\nproduct of two smaller dictionaries and the observed data generated by sparse\nlinear combinations of dictionary atoms observed through white Gaussian noise.\nIn this regard, the paper provides a general lower bound on the minimax risk\nand also adapts the proof techniques for equivalent results using sparse and\nGaussian coefficient models. The reported results suggest that the sample\ncomplexity of dictionary learning for tensor data can be significantly lower\nthan that for unstructured data.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 18:42:31 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Shakeri", "Zahra", ""], ["Bajwa", "Waheed U.", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1605.05359", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Ramnandan Krishnamurthy, Peeyush Kumar and Balaraman\n  Ravindran", "title": "Option Discovery in Hierarchical Reinforcement Learning using\n  Spatio-Temporal Clustering", "comments": "Revised version of ICML 16 Abstraction in Reinforcement Learning\n  workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an automated skill acquisition framework in\nreinforcement learning which involves identifying a hierarchical description of\nthe given task in terms of abstract states and extended actions between\nabstract states. Identifying such structures present in the task provides ways\nto simplify and speed up reinforcement learning algorithms. These structures\nalso help to generalize such algorithms over multiple tasks without relearning\npolicies from scratch. We use ideas from dynamical systems to find metastable\nregions in the state space and associate them with abstract states. The\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\naligned to the underlying structure. Skills are defined in terms of the\nsequence of actions that lead to transitions between such abstract states. The\nconnectivity information from PCCA+ is used to generate these skills or\noptions. These skills are independent of the learning task and can be\nefficiently reused across a variety of tasks defined over the same model. This\napproach works well even without the exact model of the environment by using\nsample trajectories to construct an approximate estimate. We also present our\napproach to scaling the skill acquisition framework to complex tasks with large\nstate spaces for which we perform state aggregation using the representation\nlearned from an action conditional video prediction network and use the skill\nacquisition framework on the aggregated state space.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:44:19 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:14:20 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:18:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Krishnamurthy", "Ramnandan", ""], ["Kumar", "Peeyush", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05362", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar", "title": "Yelp Dataset Challenge: Review Rating Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Review websites, such as TripAdvisor and Yelp, allow users to post online\nreviews for various businesses, products and services, and have been recently\nshown to have a significant influence on consumer shopping behaviour. An online\nreview typically consists of free-form text and a star rating out of 5. The\nproblem of predicting a user's star rating for a product, given the user's text\nreview for that product, is called Review Rating Prediction and has lately\nbecome a popular, albeit hard, problem in machine learning. In this paper, we\ntreat Review Rating Prediction as a multi-class classification problem, and\nbuild sixteen different prediction models by combining four feature extraction\nmethods, (i) unigrams, (ii) bigrams, (iii) trigrams and (iv) Latent Semantic\nIndexing, with four machine learning algorithms, (i) logistic regression, (ii)\nNaive Bayes classification, (iii) perceptrons, and (iv) linear Support Vector\nClassification. We analyse the performance of each of these sixteen models to\ncome up with the best model for predicting the ratings from reviews. We use the\ndataset provided by Yelp for training and testing the models.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:52:33 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Asghar", "Nabiha", ""]]}, {"id": "1605.05365", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Sahil Sharma and Balaraman Ravindran", "title": "Dynamic Frame skip Deep Q Network", "comments": "IJCAI 2016 Workshop on Deep Reinforcement Learning: Frontiers and\n  Challenges; 6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning methods have achieved state of the art\nperformance in learning control policies for the games in the Atari 2600\ndomain. One of the important parameters in the Arcade Learning Environment\n(ALE) is the frame skip rate. It decides the granularity at which agents can\ncontrol game play. A frame skip value of $k$ allows the agent to repeat a\nselected action $k$ number of times. The current state of the art architectures\nlike Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of\na framework with a static frame skip rate, where the action output from the\nnetwork is repeated for a fixed number of frames regardless of the current\nstate. In this paper, we propose a new architecture, Dynamic Frame skip Deep\nQ-Network (DFDQN) which makes the frame skip rate a dynamic learnable\nparameter. This allows us to choose the number of times an action is to be\nrepeated based on the current state. We show empirically that such a setting\nimproves the performance on relatively harder games like Seaquest.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:58:41 GMT"}, {"version": "v2", "created": "Sat, 11 Jun 2016 01:04:13 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:20:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Sharma", "Sahil", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05368", "submitter": "Kin Gwn Lore", "authors": "Kin Gwn Lore, Daniel Stoecklein, Michael Davies, Baskar\n  Ganapathysubramanian, Soumik Sarkar", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning became the method of choice in recent year for solving a wide\nvariety of predictive analytics tasks. For sequence prediction, recurrent\nneural networks (RNN) are often the go-to architecture for exploiting\nsequential information where the output is dependent on previous computation.\nHowever, the dependencies of the computation lie in the latent domain which may\nnot be suitable for certain applications involving the prediction of a\nstep-wise transformation sequence that is dependent on the previous computation\nonly in the visible domain. We propose that a hybrid architecture of\nconvolution neural networks (CNN) and stacked autoencoders (SAE) is sufficient\nto learn a sequence of actions that nonlinearly transforms an input shape or\ndistribution into a target shape or distribution with the same support. While\nsuch a framework can be useful in a variety of problems such as robotic path\nplanning, sequential decision-making in games, and identifying material\nprocessing pathways to achieve desired microstructures, the application of the\nframework is exemplified by the control of fluid deformations in a microfluidic\nchannel by deliberately placing a sequence of pillars. Learning of a multistep\ntopological transform has significant implications for rapid advances in\nmaterial science and biomedical applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 21:07:18 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 02:01:37 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 20:48:47 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Lore", "Kin Gwn", ""], ["Stoecklein", "Daniel", ""], ["Davies", "Michael", ""], ["Ganapathysubramanian", "Baskar", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1605.05414", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Iulian V. Serban, Mike Noseworthy, Laurent Charlin, Joelle\n  Pineau", "title": "On the Evaluation of Dialogue Systems with Next Utterance Classification", "comments": "Accepted to SIGDIAL 2016 (short paper). 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open challenge in constructing dialogue systems is developing methods for\nautomatically learning dialogue strategies from large amounts of unlabelled\ndata. Recent work has proposed Next-Utterance-Classification (NUC) as a\nsurrogate task for building dialogue systems from text data. In this paper we\ninvestigate the performance of humans on this task to validate the relevance of\nNUC as a method of evaluation. Our results show three main findings: (1) humans\nare able to correctly classify responses at a rate much better than chance,\nthus confirming that the task is feasible, (2) human performance levels vary\nacross task domains (we consider 3 datasets) and expertise levels (novice vs\nexperts), thus showing that a range of performance is possible on this type of\ntask, (3) automated dialogue systems built using state-of-the-art machine\nlearning methods have similar performance to the human novices, but worse than\nthe experts, thus confirming the utility of this class of tasks for driving\nfurther research in automated dialogue systems.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 01:36:29 GMT"}, {"version": "v2", "created": "Sat, 23 Jul 2016 00:00:36 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Lowe", "Ryan", ""], ["Serban", "Iulian V.", ""], ["Noseworthy", "Mike", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""]]}, {"id": "1605.05422", "submitter": "Shinji Ito", "authors": "Shinji Ito and Ryohei Fujimaki", "title": "Optimization Beyond Prediction: Prescriptive Price Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a novel data science problem, prescriptive price\noptimization, which derives the optimal price strategy to maximize future\nprofit/revenue on the basis of massive predictive formulas produced by machine\nlearning. The prescriptive price optimization first builds sales forecast\nformulas of multiple products, on the basis of historical data, which reveal\ncomplex relationships between sales and prices, such as price elasticity of\ndemand and cannibalization. Then, it constructs a mathematical optimization\nproblem on the basis of those predictive formulas. We present that the\noptimization problem can be formulated as an instance of binary quadratic\nprogramming (BQP). Although BQP problems are NP-hard in general and\ncomputationally intractable, we propose a fast approximation algorithm using a\nsemi-definite programming (SDP) relaxation, which is closely related to the\nGoemans-Williamson's Max-Cut approximation. Our experiments on simulation and\nreal retail datasets show that our prescriptive price optimization\nsimultaneously derives the optimal prices of tens/hundreds products with\npractical computational time, that potentially improve 8.2% of gross profit of\nthose products.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 02:46:14 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 06:38:18 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Ito", "Shinji", ""], ["Fujimaki", "Ryohei", ""]]}, {"id": "1605.05509", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Michele Scarpiniti, Danilo Comminiello, Aurelio\n  Uncini", "title": "Learning activation functions from data using cubic spline interpolation", "comments": "Submitted to the 27th Italian Workshop on Neural Networks (WIRN 2017)", "journal-ref": "Neural Advances in Processing Nonlinear Dynamic Signals, 2017", "doi": "10.1007/978-3-319-95098-3_7", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks require a careful design in order to perform properly on a\ngiven task. In particular, selecting a good activation function (possibly in a\ndata-dependent fashion) is a crucial step, which remains an open problem in the\nresearch community. Despite a large amount of investigations, most current\nimplementations simply select one fixed function from a small set of\ncandidates, which is not adapted during training, and is shared among all\nneurons throughout the different layers. However, neither two of these\nassumptions can be supposed optimal in practice. In this paper, we present a\nprincipled way to have data-dependent adaptation of the activation functions,\nwhich is performed independently for each neuron. This is achieved by\nleveraging over past and present advances on cubic spline interpolation,\nallowing for local adaptation of the functions around their regions of use. The\nresulting algorithm is relatively cheap to implement, and overfitting is\ncounterbalanced by the inclusion of a novel damping criterion, which penalizes\nunwanted oscillations from a predefined shape. Experimental results validate\nthe proposal over two well-known benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 10:46:01 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 07:28:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Comminiello", "Danilo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1605.05628", "submitter": "Christian Gruhl", "authors": "Christian Gruhl, Bernhard Sick", "title": "Detecting Novel Processes with CANDIES -- An Holistic Novelty Detection\n  Technique based on Probabilistic Models", "comments": "17 Pages, contains 21 Figures. Currently under review for publication\n  in International Journal of Machine Learning and Cybernetics (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose CANDIES (Combined Approach for Novelty Detection\nin Intelligent Embedded Systems), a new approach to novelty detection in\ntechnical systems. We assume that in a technical system several processes\ninteract. If we observe these processes with sensors, we are able to model the\nobservations (samples) with a probabilistic model, where, in an ideal case, the\ncomponents of the parametric mixture density model we use, correspond to the\nprocesses in the real world. Eventually, at run-time, novel processes emerge in\nthe technical systems such as in the case of an unpredictable failure. As a\nconsequence, new kinds of samples are observed that require an adaptation of\nthe model. CANDIES relies on mixtures of Gaussians which can be used for\nclassification purposes, too. New processes may emerge in regions of the\nmodels' input spaces where few samples were observed before (low-density\nregions) or in regions where already many samples were available (high-density\nregions). The latter case is more difficult, but most existing solutions focus\non the former. Novelty detection in low- and high-density regions requires\ndifferent detection strategies. With CANDIES, we introduce a new technique to\ndetect novel processes in high-density regions by means of a fast online\ngoodness-of-fit test. For detection in low-density regions we combine this\napproach with a 2SND (Two-Stage-Novelty-Detector) which we presented in\npreliminary work. The properties of CANDIES are evaluated using artificial data\nand benchmark data from the field of intrusion detection in computer networks,\nwhere the task is to detect new kinds of attacks.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 15:47:59 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Gruhl", "Christian", ""], ["Sick", "Bernhard", ""]]}, {"id": "1605.05710", "submitter": "Eyal En Gad", "authors": "Eyal En Gad, Akshay Gadde, A. Salman Avestimehr and Antonio Ortega", "title": "Active Learning On Weighted Graphs Using Adaptive And Non-adaptive\n  Approaches", "comments": "In ICASSP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies graph-based active learning, where the goal is to\nreconstruct a binary signal defined on the nodes of a weighted graph, by\nsampling it on a small subset of the nodes. A new sampling algorithm is\nproposed, which sequentially selects the graph nodes to be sampled, based on an\naggressive search for the boundary of the signal over the graph. The algorithm\ngeneralizes a recent method for sampling nodes in unweighted graphs. The\ngeneralization improves the sampling performance using the information gained\nfrom the available graph weights. An analysis of the number of samples required\nby the proposed algorithm is provided, and the gain over the unweighted method\nis further demonstrated in simulations. Additionally, the proposed method is\ncompared with an alternative state of-the-art method, which is based on the\ngraph's spectral properties. It is shown that the proposed method significantly\noutperforms the spectral sampling method, if the signal needs to be predicted\nwith high accuracy. On the other hand, if a higher level of inaccuracy is\ntolerable, then the spectral method outperforms the proposed aggressive search\nmethod. Consequently, we propose a hybrid method, which is shown to combine the\nadvantages of both approaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 19:21:22 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Gad", "Eyal En", ""], ["Gadde", "Akshay", ""], ["Avestimehr", "A. Salman", ""], ["Ortega", "Antonio", ""]]}, {"id": "1605.05721", "submitter": "Ping Li", "authors": "Ping Li", "title": "Linearized GMM Kernels and Normalized Random Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of \"random Fourier features (RFF)\" has become a popular tool for\napproximating the \"radial basis function (RBF)\" kernel. The variance of RFF is\nactually large. Interestingly, the variance can be substantially reduced by a\nsimple normalization step as we theoretically demonstrate. We name the improved\nscheme as the \"normalized RFF (NRFF)\".\n  We also propose the \"generalized min-max (GMM)\" kernel as a measure of data\nsimilarity. GMM is positive definite as there is an associated hashing method\nnamed \"generalized consistent weighted sampling (GCWS)\" which linearizes this\nnonlinear kernel. We provide an extensive empirical evaluation of the RBF\nkernel and the GMM kernel on more than 50 publicly available datasets. For a\nmajority of the datasets, the (tuning-free) GMM kernel outperforms the\nbest-tuned RBF kernel.\n  We conduct extensive experiments for comparing the linearized RBF kernel\nusing NRFF with the linearized GMM kernel using GCWS. We observe that, to reach\na comparable classification accuracy, GCWS typically requires substantially\nfewer samples than NRFF, even on datasets where the original RBF kernel\noutperforms the original GMM kernel. The empirical success of GCWS (compared to\nNRFF) can also be explained from a theoretical perspective. Firstly, the\nrelative variance (normalized by the squared expectation) of GCWS is\nsubstantially smaller than that of NRFF, except for the very high similarity\nregion (where the variances of both methods are close to zero). Secondly, if we\nmake a model assumption on the data, we can show analytically that GCWS\nexhibits much smaller variance than NRFF for estimating the same object (e.g.,\nthe RBF kernel), except for the very high similarity region.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 19:54:22 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 19:51:39 GMT"}, {"version": "v3", "created": "Thu, 3 Nov 2016 18:42:09 GMT"}, {"version": "v4", "created": "Tue, 21 Feb 2017 17:11:48 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1605.05775", "submitter": "E.M. Stoudenmire", "authors": "E. Miles Stoudenmire and David J. Schwab", "title": "Supervised Learning with Quantum-Inspired Tensor Networks", "comments": "11 pages, 15 figures; updated version includes corrections, links to\n  sample codes, expanded discussion, and additional references", "journal-ref": "Advances in Neural Information Processing Systems 29, 4799 (2016)", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor networks are efficient representations of high-dimensional tensors\nwhich have been very successful for physics and mathematics applications. We\ndemonstrate how algorithms for optimizing such networks can be adapted to\nsupervised learning tasks by using matrix product states (tensor trains) to\nparameterize models for classifying images. For the MNIST data set we obtain\nless than 1% test set classification error. We discuss how the tensor network\nform imparts additional structure to the learned model and suggest a possible\ngenerative interpretation.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 22:20:35 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 18:03:45 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Stoudenmire", "E. Miles", ""], ["Schwab", "David J.", ""]]}, {"id": "1605.05799", "submitter": "Joseph Makin", "authors": "Joseph G. Makin, Benjamin K. Dichter, Philip N. Sabes", "title": "Recurrent Exponential-Family Harmoniums without Backprop-Through-Time", "comments": "28 pages, 6 figures. Under review at JMLR since January 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential-family harmoniums (EFHs), which extend restricted Boltzmann\nmachines (RBMs) from Bernoulli random variables to other exponential families\n(Welling et al., 2005), are generative models that can be trained with\nunsupervised-learning techniques, like contrastive divergence (Hinton et al.\n2006; Hinton, 2002), as density estimators for static data. Methods for\nextending RBMs--and likewise EFHs--to data with temporal dependencies have been\nproposed previously (Sutskever and Hinton, 2007; Sutskever et al., 2009), the\nlearning procedure being validated by qualitative assessment of the generative\nmodel. Here we propose and justify, from a very different perspective, an\nalternative training procedure, proving sufficient conditions for optimal\ninference under that procedure. The resulting algorithm can be learned with\nonly forward passes through the data--backprop-through-time is not required, as\nin previous approaches. The proof exploits a recent result about information\nretention in density estimators (Makin and Sabes, 2015), and applies it to a\n\"recurrent EFH\" (rEFH) by induction. Finally, we demonstrate optimality by\nsimulation, testing the rEFH: (1) as a filter on training data generated with a\nlinear dynamical system, the position of which is noisily reported by a\npopulation of \"neurons\" with Poisson-distributed spike counts; and (2) with the\nqualitative experiments proposed by Sutskever et al. (2009).\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 03:19:31 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Makin", "Joseph G.", ""], ["Dichter", "Benjamin K.", ""], ["Sabes", "Philip N.", ""]]}, {"id": "1605.05826", "submitter": "Matthias Boehm", "authors": "Matthias Boehm, Alexandre V. Evfimievski, Niketan Pansare, Berthold\n  Reinwald", "title": "Declarative Machine Learning - A Classification of Basic Properties and\n  Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Declarative machine learning (ML) aims at the high-level specification of ML\ntasks or algorithms, and automatic generation of optimized execution plans from\nthese specifications. The fundamental goal is to simplify the usage and/or\ndevelopment of ML algorithms, which is especially important in the context of\nlarge-scale computations. However, ML systems at different abstraction levels\nhave emerged over time and accordingly there has been a controversy about the\nmeaning of this general definition of declarative ML. Specification\nalternatives range from ML algorithms expressed in domain-specific languages\n(DSLs) with optimization for performance, to ML task (learning problem)\nspecifications with optimization for performance and accuracy. We argue that\nthese different types of declarative ML complement each other as they address\ndifferent users (data scientists and end users). This paper makes an attempt to\ncreate a taxonomy for declarative ML, including a definition of essential basic\nproperties and types of declarative ML. Along the way, we provide insights into\nimplications of these properties. We also use this taxonomy to classify\nexisting systems. Finally, we draw conclusions on defining appropriate\nbenchmarks and specification languages for declarative ML.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 06:39:28 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Boehm", "Matthias", ""], ["Evfimievski", "Alexandre V.", ""], ["Pansare", "Niketan", ""], ["Reinwald", "Berthold", ""]]}, {"id": "1605.06049", "submitter": "Albert Berahas", "authors": "Albert S. Berahas, Jorge Nocedal, Martin Tak\\'a\\v{c}", "title": "A Multi-Batch L-BFGS Method for Machine Learning", "comments": "NIPS 2016. 31 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how to parallelize the stochastic gradient descent (SGD)\nmethod has received much attention in the literature. In this paper, we focus\ninstead on batch methods that use a sizeable fraction of the training set at\neach iteration to facilitate parallelism, and that employ second-order\ninformation. In order to improve the learning process, we follow a multi-batch\napproach in which the batch changes at each iteration. This can cause\ndifficulties because L-BFGS employs gradient differences to update the Hessian\napproximations, and when these gradients are computed using different data\npoints the process can be unstable. This paper shows how to perform stable\nquasi-Newton updating in the multi-batch setting, illustrates the behavior of\nthe algorithm in a distributed computing platform, and studies its convergence\nproperties for both the convex and nonconvex cases.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 16:53:50 GMT"}, {"version": "v2", "created": "Sun, 23 Oct 2016 22:48:01 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Berahas", "Albert S.", ""], ["Nocedal", "Jorge", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1605.06065", "submitter": "Adam Santoro", "authors": "Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra,\n  Timothy Lillicrap", "title": "One-shot Learning with Memory-Augmented Neural Networks", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent breakthroughs in the applications of deep neural networks, one\nsetting that presents a persistent challenge is that of \"one-shot learning.\"\nTraditional gradient-based networks require a lot of data to learn, often\nthrough extensive iterative training. When new data is encountered, the models\nmust inefficiently relearn their parameters to adequately incorporate the new\ninformation without catastrophic interference. Architectures with augmented\nmemory capacities, such as Neural Turing Machines (NTMs), offer the ability to\nquickly encode and retrieve new information, and hence can potentially obviate\nthe downsides of conventional models. Here, we demonstrate the ability of a\nmemory-augmented neural network to rapidly assimilate new data, and leverage\nthis data to make accurate predictions after only a few samples. We also\nintroduce a new method for accessing an external memory that focuses on memory\ncontent, unlike previous methods that additionally use memory location-based\nfocusing mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 17:44:51 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Santoro", "Adam", ""], ["Bartunov", "Sergey", ""], ["Botvinick", "Matthew", ""], ["Wierstra", "Daan", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1605.06069", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin,\n  Joelle Pineau, Aaron Courville, Yoshua Bengio", "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating\n  Dialogues", "comments": "15 pages, 5 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data often possesses a hierarchical structure with complex\ndependencies between subsequences, such as found between the utterances in a\ndialogue. In an effort to model this kind of generative process, we propose a\nneural network-based generative architecture, with latent stochastic variables\nthat span a variable number of time steps. We apply the proposed model to the\ntask of dialogue response generation and compare it with recent neural network\narchitectures. We evaluate the model performance through automatic evaluation\nmetrics and by carrying out a human evaluation. The experiments demonstrate\nthat our model improves upon recently proposed models and that the latent\nvariables facilitate the generation of long outputs and maintain the context.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 17:59:02 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 16:02:30 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 02:21:04 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sordoni", "Alessandro", ""], ["Lowe", "Ryan", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1605.06076", "submitter": "Prasenjit Karmakar", "authors": "Prasenjit Karmakar, Rajkumar Maity, Shalabh Bhatnagar", "title": "On a convergent off -policy temporal difference learning algorithm in\n  on-line learning environment", "comments": "14 pages. arXiv admin note: text overlap with arXiv:1503.09105", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a rigorous convergence analysis of a \"off\"-policy\ntemporal difference learning algorithm with linear function approximation and\nper time-step linear computational complexity in \"online\" learning environment.\nThe algorithm considered here is TDC with importance weighting introduced by\nMaei et al. We support our theoretical results by providing suitable empirical\nresults for standard off-policy counterexamples.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 18:32:50 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Karmakar", "Prasenjit", ""], ["Maity", "Rajkumar", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1605.06155", "submitter": "Cheng Zhang", "authors": "Cheng Zhang and Hedvig Kjellstrom and Carl Henrik Ek", "title": "Inter-Battery Topic Representation Learning", "comments": "ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the Inter-Battery Topic Model (IBTM). Our approach\nextends traditional topic models by learning a factorized latent variable\nrepresentation. The structured representation leads to a model that marries\nbenefits traditionally associated with a discriminative approach, such as\nfeature selection, with those of a generative model, such as principled\nregularization and ability to handle missing data. The factorization is\nprovided by representing data in terms of aligned pairs of observations as\ndifferent views. This provides means for selecting a representation that\nseparately models topics that exist in both views from the topics that are\nunique to a single view. This structured consolidation allows for efficient and\nrobust inference and provides a compact and efficient representation. Learning\nis performed in a Bayesian fashion by maximizing a rigorous bound on the\nlog-likelihood. Firstly, we illustrate the benefits of the model on a synthetic\ndataset,. The model is then evaluated in both uni- and multi-modality settings\non two different classification tasks with off-the-shelf convolutional neural\nnetwork (CNN) features which generate state-of-the-art results with extremely\ncompact representations.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 21:44:12 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2016 10:08:40 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Zhang", "Cheng", ""], ["Kjellstrom", "Hedvig", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1605.06170", "submitter": "Ian Dewancker", "authors": "Ian Dewancker, Michael McCourt, Scott Clark, Patrick Hayes, Alexandra\n  Johnson, George Ke", "title": "Evaluation System for a Bayesian Optimization Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is an elegant solution to the hyperparameter\noptimization problem in machine learning. Building a reliable and robust\nBayesian optimization service requires careful testing methodology and sound\nstatistical analysis. In this talk we will outline our development of an\nevaluation framework to rigorously test and measure the impact of changes to\nthe SigOpt optimization service. We present an overview of our evaluation\nsystem and discuss how this framework empowers our research engineers to\nconfidently and quickly make changes to our core optimization engine\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 23:10:15 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Dewancker", "Ian", ""], ["McCourt", "Michael", ""], ["Clark", "Scott", ""], ["Hayes", "Patrick", ""], ["Johnson", "Alexandra", ""], ["Ke", "George", ""]]}, {"id": "1605.06181", "submitter": "Yusheng Xie", "authors": "Yusheng Xie, Nan Du, Wei Fan, Jing Zhai, Weicheng Zhu", "title": "Variational hybridization and transformation for large inaccurate\n  noisy-or networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference provides approximations to the computationally\nintractable posterior distribution in Bayesian networks. A prominent medical\napplication of noisy-or Bayesian network is to infer potential diseases given\nobserved symptoms. Previous studies focus on approximating a handful of\ncomplicated pathological cases using variational transformation. Our goal is to\nuse variational transformation as part of a novel hybridized inference for\nserving reliable and real time diagnosis at web scale. We propose a hybridized\ninference that allows variational parameters to be estimated without disease\nposteriors or priors, making the inference faster and much of its computation\nrecyclable. In addition, we propose a transformation ranking algorithm that is\nvery stable to large variances in network prior probabilities, a common issue\nthat arises in medical applications of Bayesian networks. In experiments, we\nperform comparative study on a large real life medical network and scalability\nstudy on a much larger (36,000x) synthesized network.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 00:31:07 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Xie", "Yusheng", ""], ["Du", "Nan", ""], ["Fan", "Wei", ""], ["Zhai", "Jing", ""], ["Zhu", "Weicheng", ""]]}, {"id": "1605.06201", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Kent Quanrud, Amirhossein Taghvaei", "title": "Adversarial Delays in Online Strongly-Convex Optimization", "comments": "We discovered mistakes in the proof of proof of Theorem 3.1. The\n  overall is no longer correct, although the claim is still true", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of strongly-convex online optimization in presence of\nadversarial delays; in a T-iteration online game, the feedback of the player's\nquery at time t is arbitrarily delayed by an adversary for d_t rounds and\ndelivered before the game ends, at iteration t+d_t-1. Specifically for\n\\algo{online-gradient-descent} algorithm we show it has a simple regret bound\nof \\Oh{\\sum_{t=1}^T \\log (1+ \\frac{d_t}{t})}. This gives a clear and simple\nbound without resorting any distributional and limiting assumptions on the\ndelays. We further show how this result encompasses and generalizes several of\nthe existing known results in the literature. Specifically it matches the\ncelebrated logarithmic regret \\Oh{\\log T} when there are no delays (i.e. d_t =\n1) and regret bound of \\Oh{\\tau \\log T} for constant delays d_t = \\tau.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 02:55:59 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 18:41:57 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 18:34:56 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 04:53:49 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Khashabi", "Daniel", ""], ["Quanrud", "Kent", ""], ["Taghvaei", "Amirhossein", ""]]}, {"id": "1605.06203", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "Faster Projection-free Convex Optimization over the Spectrahedron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a convex function over the spectrahedron, i.e., the set of all\npositive semidefinite matrices with unit trace, is an important optimization\ntask with many applications in optimization, machine learning, and signal\nprocessing. It is also notoriously difficult to solve in large-scale since\nstandard techniques require expensive matrix decompositions. An alternative, is\nthe conditional gradient method (aka Frank-Wolfe algorithm) that regained much\ninterest in recent years, mostly due to its application to this specific\nsetting. The key benefit of the CG method is that it avoids expensive matrix\ndecompositions all together, and simply requires a single eigenvector\ncomputation per iteration, which is much more efficient. On the downside, the\nCG method, in general, converges with an inferior rate. The error for\nminimizing a $\\beta$-smooth function after $t$ iterations scales like\n$\\beta/t$. This convergence rate does not improve even if the function is also\nstrongly convex.\n  In this work we present a modification of the CG method tailored for convex\noptimization over the spectrahedron. The per-iteration complexity of the method\nis essentially identical to that of the standard CG method: only a single\neigenvecor computation is required. For minimizing an $\\alpha$-strongly convex\nand $\\beta$-smooth function, the expected approximation error of the method\nafter $t$ iterations is: $$O\\left({\\min\\{\\frac{\\beta{}}{t}\n,\\left({\\frac{\\beta\\sqrt{\\textrm{rank}(\\textbf{X}^*)}}{\\alpha^{1/4}t}}\\right)^{4/3},\n\\left({\\frac{\\beta}{\\sqrt{\\alpha}\\lambda_{\\min}(\\textbf{X}^*)t}}\\right)^{2}\\}}\\right)\n,$$ where $\\textbf{X}^*$ is the optimal solution. To the best of our knowledge,\nthis is the first result that attains provably faster convergence rates for a\nCG variant for optimization over the spectrahedron. We also present encouraging\npreliminary empirical results.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 03:07:40 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "1605.06220", "submitter": "Bai Jiang", "authors": "Bai Jiang, Tung-yu Wu, Wing H. Wong", "title": "Convergence of Contrastive Divergence with Annealed Learning Rate in\n  Exponential Family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our recent paper, we showed that in exponential family, contrastive\ndivergence (CD) with fixed learning rate will give asymptotically consistent\nestimates \\cite{wu2016convergence}. In this paper, we establish consistency and\nconvergence rate of CD with annealed learning rate $\\eta_t$. Specifically,\nsuppose CD-$m$ generates the sequence of parameters $\\{\\theta_t\\}_{t \\ge 0}$\nusing an i.i.d. data sample $\\mathbf{X}_1^n \\sim p_{\\theta^*}$ of size $n$,\nthen $\\delta_n(\\mathbf{X}_1^n) = \\limsup_{t \\to \\infty} \\Vert \\sum_{s=t_0}^t\n\\eta_s \\theta_s / \\sum_{s=t_0}^t \\eta_s - \\theta^* \\Vert$ converges in\nprobability to 0 at a rate of $1/\\sqrt[3]{n}$. The number ($m$) of MCMC\ntransitions in CD only affects the coefficient factor of convergence rate. Our\nproof is not a simple extension of the one in \\cite{wu2016convergence}. which\ndepends critically on the fact that $\\{\\theta_t\\}_{t \\ge 0}$ is a homogeneous\nMarkov chain conditional on the observed sample $\\mathbf{X}_1^n$. Under\nannealed learning rate, the homogeneous Markov property is not available and we\nhave to develop an alternative approach based on super-martingales. Experiment\nresults of CD on a fully-visible $2\\times 2$ Boltzmann Machine are provided to\ndemonstrate our theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 06:26:38 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Jiang", "Bai", ""], ["Wu", "Tung-yu", ""], ["Wong", "Wing H.", ""]]}, {"id": "1605.06265", "submitter": "Julien Mairal", "authors": "Julien Mairal", "title": "End-to-End Kernel Learning with Supervised Convolutional Kernel Networks", "comments": "to appear in Advances in Neural Information Processing Systems (NIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new image representation based on a multilayer\nkernel machine. Unlike traditional kernel methods where data representation is\ndecoupled from the prediction task, we learn how to shape the kernel with\nsupervision. We proceed by first proposing improvements of the\nrecently-introduced convolutional kernel networks (CKNs) in the context of\nunsupervised learning; then, we derive backpropagation rules to take advantage\nof labeled training data. The resulting model is a new type of convolutional\nneural network, where optimizing the filters at each layer is equivalent to\nlearning a linear subspace in a reproducing kernel Hilbert space (RKHS). We\nshow that our method achieves reasonably competitive performance for image\nclassification on some standard \"deep learning\" datasets such as CIFAR-10 and\nSVHN, and also for image super-resolution, demonstrating the applicability of\nour approach to a large variety of image-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 09:52:14 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 12:52:50 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Mairal", "Julien", ""]]}, {"id": "1605.06276", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, E.M. Mirkes, A. Zinovyev", "title": "Piece-wise quadratic approximations of arbitrary error functions for\n  fast and robust machine learning", "comments": "Edited and extended version with algortihms of regularized regression", "journal-ref": "Neural Networks, Volume 84, December 2016, 28-38", "doi": "10.1016/j.neunet.2016.08.007", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of machine learning approaches have stemmed from the application of\nminimizing the mean squared distance principle, based on the computationally\nefficient quadratic optimization methods. However, when faced with\nhigh-dimensional and noisy data, the quadratic error functionals demonstrated\nmany weaknesses including high sensitivity to contaminating factors and\ndimensionality curse. Therefore, a lot of recent applications in machine\nlearning exploited properties of non-quadratic error functionals based on $L_1$\nnorm or even sub-linear potentials corresponding to quasinorms $L_p$ ($0<p<1$).\nThe back side of these approaches is increase in computational cost for\noptimization. Till so far, no approaches have been suggested to deal with {\\it\narbitrary} error functionals, in a flexible and computationally efficient\nframework. In this paper, we develop a theory and basic universal data\napproximation algorithms ($k$-means, principal components, principal manifolds\nand graphs, regularized and sparse regression), based on piece-wise quadratic\nerror potentials of subquadratic growth (PQSQ potentials). We develop a new and\nuniversal framework to minimize {\\it arbitrary sub-quadratic error potentials}\nusing an algorithm with guaranteed fast convergence to the local or global\nerror minimum. The theory of PQSQ potentials is based on the notion of the cone\nof minorant functions, and represents a natural approximation formalism based\non the application of min-plus algebra. The approach can be applied in most of\nexisting machine learning methods, including methods of data approximation and\nregularized and sparse regression, leading to the improvement in the\ncomputational cost/accuracy trade-off. We demonstrate that on synthetic and\nreal-life datasets PQSQ-based machine learning methods achieve orders of\nmagnitude faster computational performance than the corresponding\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 10:25:47 GMT"}, {"version": "v2", "created": "Sun, 21 Aug 2016 12:44:25 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Gorban", "A. N.", ""], ["Mirkes", "E. M.", ""], ["Zinovyev", "A.", ""]]}, {"id": "1605.06296", "submitter": "Naresh Manwani", "authors": "Aritra Ghosh, Naresh Manwani, P. S. Sastry", "title": "On the Robustness of Decision Tree Learning under Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most practical problems of classifier learning, the training data suffers\nfrom the label noise. Hence, it is important to understand how robust is a\nlearning algorithm to such label noise. This paper presents some theoretical\nanalysis to show that many popular decision tree algorithms are robust to\nsymmetric label noise under large sample size. We also present some sample\ncomplexity results which provide some bounds on the sample size for the\nrobustness to hold with a high probability. Through extensive simulations we\nillustrate this robustness.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 11:31:26 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 08:58:06 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Ghosh", "Aritra", ""], ["Manwani", "Naresh", ""], ["Sastry", "P. S.", ""]]}, {"id": "1605.06336", "submitter": "Aapo Hyvarinen", "authors": "Aapo Hyvarinen and Hiroshi Morioka", "title": "Unsupervised Feature Extraction by Time-Contrastive Learning and\n  Nonlinear ICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear independent component analysis (ICA) provides an appealing\nframework for unsupervised feature learning, but the models proposed so far are\nnot identifiable. Here, we first propose a new intuitive principle of\nunsupervised deep learning from time series which uses the nonstationary\nstructure of the data. Our learning principle, time-contrastive learning (TCL),\nfinds a representation which allows optimal discrimination of time segments\n(windows). Surprisingly, we show how TCL can be related to a nonlinear ICA\nmodel, when ICA is redefined to include temporal nonstationarities. In\nparticular, we show that TCL combined with linear ICA estimates the nonlinear\nICA model up to point-wise transformations of the sources, and this solution is\nunique --- thus providing the first identifiability result for nonlinear ICA\nwhich is rigorous, constructive, as well as very general.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 12:59:22 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Hyvarinen", "Aapo", ""], ["Morioka", "Hiroshi", ""]]}, {"id": "1605.06376", "submitter": "George Papamakarios", "authors": "George Papamakarios, Iain Murray", "title": "Fast $\\epsilon$-free Inference of Simulation Models with Bayesian\n  Conditional Density Estimation", "comments": "Appeared at NIPS 2016. Fixed typo in Eq (37)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical models can be simulated forwards but have intractable\nlikelihoods. Approximate Bayesian Computation (ABC) methods are used to infer\nproperties of these models from data. Traditionally these methods approximate\nthe posterior over parameters by conditioning on data being inside an\n$\\epsilon$-ball around the observed data, which is only correct in the limit\n$\\epsilon\\!\\rightarrow\\!0$. Monte Carlo methods can then draw samples from the\napproximate posterior to approximate predictions or error bars on parameters.\nThese algorithms critically slow down as $\\epsilon\\!\\rightarrow\\!0$, and in\npractice draw samples from a broader distribution than the posterior. We\npropose a new approach to likelihood-free inference based on Bayesian\nconditional density estimation. Preliminary inferences based on limited\nsimulation data are used to guide later simulations. In some cases, learning an\naccurate parametric representation of the entire true posterior distribution\nrequires fewer model simulations than Monte Carlo ABC methods need to produce a\nsingle sample from an approximate posterior.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 14:34:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 14:55:38 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 17:11:50 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2018 16:05:09 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Papamakarios", "George", ""], ["Murray", "Iain", ""]]}, {"id": "1605.06377", "submitter": "Christian Gruhl", "authors": "Dominik Fisch, Christian Gruhl, Edgar Kalkowski, Bernhard Sick, Seppo\n  J. Ovaska", "title": "Towards Automation of Knowledge Understanding: An Approach for\n  Probabilistic Generative Classifiers", "comments": "29 pages with 9 figures and 4 tables. Currently under review for\n  Information Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After data selection, pre-processing, transformation, and feature extraction,\nknowledge extraction is not the final step in a data mining process. It is then\nnecessary to understand this knowledge in order to apply it efficiently and\neffectively. Up to now, there is a lack of appropriate techniques that support\nthis significant step. This is partly due to the fact that the assessment of\nknowledge is often highly subjective, e.g., regarding aspects such as novelty\nor usefulness. These aspects depend on the specific knowledge and requirements\nof the data miner. There are, however, a number of aspects that are objective\nand for which it is possible to provide appropriate measures. In this article\nwe focus on classification problems and use probabilistic generative\nclassifiers based on mixture density models that are quite common in data\nmining applications. We define objective measures to assess the\ninformativeness, uniqueness, importance, discrimination, representativity,\nuncertainty, and distinguishability of rules contained in these classifiers\nnumerically. These measures not only support a data miner in evaluating results\nof a data mining process based on such classifiers. As we will see in\nillustrative case studies, they may also be used to improve the data mining\nprocess itself or to support the later application of the extracted knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 14:34:49 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Fisch", "Dominik", ""], ["Gruhl", "Christian", ""], ["Kalkowski", "Edgar", ""], ["Sick", "Bernhard", ""], ["Ovaska", "Seppo J.", ""]]}, {"id": "1605.06391", "submitter": "Yongxin Yang", "authors": "Yongxin Yang and Timothy Hospedales", "title": "Deep Multi-task Representation Learning: A Tensor Factorisation Approach", "comments": "9 pages, Accepted to ICLR 2017 Conference Track. This is a conference\n  version of the paper. For the multi-domain learning part (not in this\n  version), please refer to https://arxiv.org/pdf/1605.06391v1.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most contemporary multi-task learning methods assume linear models. This\nsetting is considered shallow in the era of deep learning. In this paper, we\npresent a new deep multi-task representation learning framework that learns\ncross-task sharing structure at every layer in a deep network. Our approach is\nbased on generalising the matrix factorisation techniques explicitly or\nimplicitly used by many conventional MTL algorithms to tensor factorisation, to\nrealise automatic learning of end-to-end knowledge sharing in deep networks.\nThis is in contrast to existing deep learning approaches that need a\nuser-defined multi-task sharing strategy. Our approach applies to both\nhomogeneous and heterogeneous MTL. Experiments demonstrate the efficacy of our\ndeep multi-task representation learning in terms of both higher accuracy and\nfewer design choices.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 15:05:58 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 20:40:41 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Yang", "Yongxin", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1605.06394", "submitter": "Julien-Charles Levesque", "authors": "Julien-Charles L\\'evesque, Christian Gagn\\'e and Robert Sabourin", "title": "Bayesian Hyperparameter Optimization for Ensemble Learning", "comments": "To appear in proceedings of UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we bridge the gap between hyperparameter optimization and\nensemble learning by performing Bayesian optimization of an ensemble with\nregards to its hyperparameters. Our method consists in building a fixed-size\nensemble, optimizing the configuration of one classifier of the ensemble at\neach iteration of the hyperparameter optimization algorithm, taking into\nconsideration the interaction with the other models when evaluating potential\nperformances. We also consider the case where the ensemble is to be\nreconstructed at the end of the hyperparameter optimization phase, through a\ngreedy selection over the pool of models generated during the optimization. We\nstudy the performance of our proposed method on three different hyperparameter\nspaces, showing that our approach is better than both the best single model and\na greedy ensemble construction over the models produced by a standard Bayesian\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 15:08:08 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["L\u00e9vesque", "Julien-Charles", ""], ["Gagn\u00e9", "Christian", ""], ["Sabourin", "Robert", ""]]}, {"id": "1605.06398", "submitter": "Francis Bach", "authors": "P Balamurugan (SIERRA, LIENS), Francis Bach (SIERRA, LIENS)", "title": "Stochastic Variance Reduction Methods for Saddle-Point Problems", "comments": "Neural Information Processing Systems (NIPS), 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider convex-concave saddle-point problems where the objective\nfunctions may be split in many components, and extend recent stochastic\nvariance reduction methods (such as SVRG or SAGA) to provide the first\nlarge-scale linearly convergent algorithms for this class of problems which is\ncommon in machine learning. While the algorithmic extension is straightforward,\nit comes with challenges and opportunities: (a) the convex minimization\nanalysis does not apply and we use the notion of monotone operators to prove\nconvergence, showing in particular that the same algorithm applies to a larger\nclass of problems, such as variational inequalities, (b) there are two notions\nof splits, in terms of functions, or in terms of partial derivatives, (c) the\nsplit does need to be done with convex-concave terms, (d) non-uniform sampling\nis key to an efficient algorithm, both in theory and practice, and (e) these\nincremental algorithms can be easily accelerated using a simple extension of\nthe \"catalyst\" framework, leading to an algorithm which is always superior to\naccelerated batch algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 15:16:29 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 10:24:55 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Balamurugan", "P", "", "SIERRA, LIENS"], ["Bach", "Francis", "", "SIERRA, LIENS"]]}, {"id": "1605.06402", "submitter": "Philipp Gysel", "authors": "Philipp Gysel", "title": "Ristretto: Hardware-Oriented Approximation of Convolutional Neural\n  Networks", "comments": "Master's Thesis, University of California, Davis; 73 pages and 29\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have achieved major breakthroughs in\nrecent years. Their performance in computer vision have matched and in some\nareas even surpassed human capabilities. Deep neural networks can capture\ncomplex non-linear features; however this ability comes at the cost of high\ncomputational and memory requirements. State-of-art networks require billions\nof arithmetic operations and millions of parameters. To enable embedded devices\nsuch as smartphones, Google glasses and monitoring cameras with the astonishing\npower of deep learning, dedicated hardware accelerators can be used to decrease\nboth execution time and power consumption. In applications where fast\nconnection to the cloud is not guaranteed or where privacy is important,\ncomputation needs to be done locally. Many hardware accelerators for deep\nneural networks have been proposed recently. A first important step of\naccelerator design is hardware-oriented approximation of deep networks, which\nenables energy-efficient inference. We present Ristretto, a fast and automated\nframework for CNN approximation. Ristretto simulates the hardware arithmetic of\na custom hardware accelerator. The framework reduces the bit-width of network\nparameters and outputs of resource-intense layers, which reduces the chip area\nfor multiplication units significantly. Alternatively, Ristretto can remove the\nneed for multipliers altogether, resulting in an adder-only arithmetic. The\ntool fine-tunes trimmed networks to achieve high classification accuracy. Since\ntraining of deep neural networks can be time-consuming, Ristretto uses highly\noptimized routines which run on the GPU. This enables fast compression of any\ngiven network. Given a maximum tolerance of 1%, Ristretto can successfully\ncondense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 15:22:29 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Gysel", "Philipp", ""]]}, {"id": "1605.06421", "submitter": "Chao Liu", "authors": "Chao Liu, Kin Gwn Lore, Soumik Sarkar", "title": "Data-driven root-cause analysis for distributed system anomalies", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed cyber-physical systems encounter a large variety of\nanomalies and in many cases, they are vulnerable to catastrophic fault\npropagation scenarios due to strong connectivity among the sub-systems. In this\nregard, root-cause analysis becomes highly intractable due to complex fault\npropagation mechanisms in combination with diverse operating modes. This paper\npresents a new data-driven framework for root-cause analysis for addressing\nsuch issues. The framework is based on a spatiotemporal feature extraction\nscheme for distributed cyber-physical systems built on the concept of symbolic\ndynamics for discovering and representing causal interactions among subsystems\nof a complex system. We present two approaches for root-cause analysis, namely\nthe sequential state switching ($S^3$, based on free energy concept of a\nRestricted Boltzmann Machine, RBM) and artificial anomaly association ($A^3$, a\nmulti-class classification framework using deep neural networks, DNN).\nSynthetic data from cases with failed pattern(s) and anomalous node are\nsimulated to validate the proposed approaches, then compared with the\nperformance of vector autoregressive (VAR) model-based root-cause analysis.\nReal dataset based on Tennessee Eastman process (TEP) is also used for\nvalidation. The results show that: (1) $S^3$ and $A^3$ approaches can obtain\nhigh accuracy in root-cause analysis and successfully handle multiple nominal\noperation modes, and (2) the proposed tool-chain is shown to be scalable while\nmaintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:17:59 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 02:10:51 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Liu", "Chao", ""], ["Lore", "Kin Gwn", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1605.06422", "submitter": "Alaa Saade", "authors": "Alaa Saade, Florent Krzakala, Marc Lelarge and Lenka Zdeborov\\'a", "title": "Fast Randomized Semi-Supervised Clustering", "comments": null, "journal-ref": "Journal of Physics: Conf. Series 1036 (2018) 012015", "doi": "10.1088/1742-6596/1036/1/012015", "report-no": null, "categories": "cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of clustering partially labeled data from a minimal\nnumber of randomly chosen pairwise comparisons between the items. We introduce\nan efficient local algorithm based on a power iteration of the non-backtracking\noperator and study its performance on a simple model. For the case of two\nclusters, we give bounds on the classification error and show that a small\nerror can be achieved from $O(n)$ randomly chosen measurements, where $n$ is\nthe number of items in the dataset. Our algorithm is therefore efficient both\nin terms of time and space complexities. We also investigate numerically the\nperformance of the algorithm on synthetic and real world data.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:21:13 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 16:26:16 GMT"}, {"version": "v3", "created": "Sun, 9 Oct 2016 07:45:16 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Saade", "Alaa", ""], ["Krzakala", "Florent", ""], ["Lelarge", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1605.06431", "submitter": "Andreas Veit", "authors": "Andreas Veit, Michael Wilber, Serge Belongie", "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel interpretation of residual networks showing\nthat they can be seen as a collection of many paths of differing length.\nMoreover, residual networks seem to enable very deep networks by leveraging\nonly the short paths during training. To support this observation, we rewrite\nresidual networks as an explicit collection of paths. Unlike traditional\nmodels, paths through residual networks vary in length. Further, a lesion study\nreveals that these paths show ensemble-like behavior in the sense that they do\nnot strongly depend on each other. Finally, and most surprising, most paths are\nshorter than one might expect, and only the short paths are needed during\ntraining, as longer paths do not contribute any gradient. For example, most of\nthe gradient in a residual network with 110 layers comes from paths that are\nonly 10-34 layers deep. Our results reveal one of the key characteristics that\nseem to enable the training of very deep networks: Residual networks avoid the\nvanishing gradient problem by introducing short paths which can carry gradient\nthroughout the extent of very deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:44:03 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 00:43:58 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Veit", "Andreas", ""], ["Wilber", "Michael", ""], ["Belongie", "Serge", ""]]}, {"id": "1605.06432", "submitter": "Maximilian Soelch", "authors": "Maximilian Karl, Maximilian Soelch, Justin Bayer, Patrick van der\n  Smagt", "title": "Deep Variational Bayes Filters: Unsupervised Learning of State Space\n  Models from Raw Data", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Variational Bayes Filters (DVBF), a new method for\nunsupervised learning and identification of latent Markovian state space\nmodels. Leveraging recent advances in Stochastic Gradient Variational Bayes,\nDVBF can overcome intractable inference distributions via variational\ninference. Thus, it can handle highly nonlinear input data with temporal and\nspatial dependencies such as image sequences without domain knowledge. Our\nexperiments show that enabling backpropagation through transitions enforces\nstate space assumptions and significantly improves information content of the\nlatent embedding. This also enables realistic long-term prediction.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:52:22 GMT"}, {"version": "v2", "created": "Sat, 23 Jul 2016 07:33:14 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 18:12:53 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Karl", "Maximilian", ""], ["Soelch", "Maximilian", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1605.06439", "submitter": "Wouter Koolen", "authors": "Wouter M. Koolen and Peter Gr\\\"unwald and Tim van Erven", "title": "Combining Adversarial Guarantees and Stochastic Fast Rates in Online\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online learning algorithms that guarantee worst-case regret rates\nin adversarial environments (so they can be deployed safely and will perform\nrobustly), yet adapt optimally to favorable stochastic environments (so they\nwill perform well in a variety of settings of practical importance). We\nquantify the friendliness of stochastic environments by means of the well-known\nBernstein (a.k.a. generalized Tsybakov margin) condition. For two recent\nalgorithms (Squint for the Hedge setting and MetaGrad for online convex\noptimization) we show that the particular form of their data-dependent\nindividual-sequence regret guarantees implies that they adapt automatically to\nthe Bernstein parameters of the stochastic environment. We prove that these\nalgorithms attain fast rates in their respective settings both in expectation\nand with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 17:05:55 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Koolen", "Wouter M.", ""], ["Gr\u00fcnwald", "Peter", ""], ["van Erven", "Tim", ""]]}, {"id": "1605.06443", "submitter": "Scott Yang", "authors": "Corinna Cortes, Mehryar Mohri, Vitaly Kuznetsov, Scott Yang", "title": "Structured Prediction Theory Based on Factor Graph Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theoretical analysis of structured prediction with a\nseries of new results. We give new data-dependent margin guarantees for\nstructured prediction for a very wide family of loss functions and a general\nfamily of hypotheses, with an arbitrary factor graph decomposition. These are\nthe tightest margin bounds known for both standard multi-class and general\nstructured prediction problems. Our guarantees are expressed in terms of a\ndata-dependent complexity measure, factor graph complexity, which we show can\nbe estimated from data and bounded in terms of familiar quantities. We further\nextend our theory by leveraging the principle of Voted Risk Minimization (VRM)\nand show that learning is possible even with complex factor graphs. We present\nnew learning bounds for this advanced setting, which we use to design two new\nalgorithms, Voted Conditional Random Field (VCRF) and Voted Structured Boosting\n(StructBoost). These algorithms can make use of complex features and factor\ngraphs and yet benefit from favorable learning guarantees. We also report the\nresults of experiments with VCRF on several datasets to validate our theory.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 17:21:17 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 17:02:48 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Kuznetsov", "Vitaly", ""], ["Yang", "Scott", ""]]}, {"id": "1605.06444", "submitter": "Carlo Baldassi", "authors": "Carlo Baldassi, Christian Borgs, Jennifer Chayes, Alessandro Ingrosso,\n  Carlo Lucibello, Luca Saglietti and Riccardo Zecchina", "title": "Unreasonable Effectiveness of Learning Neural Networks: From Accessible\n  States and Robust Ensembles to Basic Algorithmic Schemes", "comments": "31 pages (14 main text, 18 appendix), 12 figures (6 main text, 6\n  appendix)", "journal-ref": "Proc. Natl. Acad. Sci. U.S.A. 113(48):E7655-E7662, 2016", "doi": "10.1073/pnas.1608103113", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In artificial neural networks, learning from data is a computationally\ndemanding task in which a large number of connection weights are iteratively\ntuned through stochastic-gradient-based heuristic processes over a\ncost-function. It is not well understood how learning occurs in these systems,\nin particular how they avoid getting trapped in configurations with poor\ncomputational performance. Here we study the difficult case of networks with\ndiscrete weights, where the optimization landscape is very rough even for\nsimple architectures, and provide theoretical and numerical evidence of the\nexistence of rare - but extremely dense and accessible - regions of\nconfigurations in the network weight space. We define a novel measure, which we\ncall the \"robust ensemble\" (RE), which suppresses trapping by isolated\nconfigurations and amplifies the role of these dense regions. We analytically\ncompute the RE in some exactly solvable models, and also provide a general\nalgorithmic scheme which is straightforward to implement: define a\ncost-function given by a sum of a finite number of replicas of the original\ncost-function, with a constraint centering the replicas around a driving\nassignment. To illustrate this, we derive several powerful new algorithms,\nranging from Markov Chains to message passing to gradient descent processes,\nwhere the algorithms target the robust dense states, resulting in substantial\nimprovements in performance. The weak dependence on the number of precision\nbits of the weights leads us to conjecture that very similar reasoning applies\nto more conventional neural networks. Analogous algorithmic schemes can also be\napplied to other optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 17:27:18 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2016 15:34:46 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 19:05:31 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Baldassi", "Carlo", ""], ["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Ingrosso", "Alessandro", ""], ["Lucibello", "Carlo", ""], ["Saglietti", "Luca", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1605.06450", "submitter": "Jiakai Zhang", "authors": "Jiakai Zhang, Kyunghyun Cho", "title": "Query-Efficient Imitation Learning for End-to-End Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to approach end-to-end autonomous driving is to learn a policy\nfunction that maps from a sensory input, such as an image frame from a\nfront-facing camera, to a driving action, by imitating an expert driver, or a\nreference policy. This can be done by supervised learning, where a policy\nfunction is tuned to minimize the difference between the predicted and\nground-truth actions. A policy function trained in this way however is known to\nsuffer from unexpected behaviours due to the mismatch between the states\nreachable by the reference policy and trained policy functions. More advanced\nalgorithms for imitation learning, such as DAgger, addresses this issue by\niteratively collecting training examples from both reference and trained\npolicies. These algorithms often requires a large number of queries to a\nreference policy, which is undesirable as the reference policy is often\nexpensive. In this paper, we propose an extension of the DAgger, called\nSafeDAgger, that is query-efficient and more suitable for end-to-end autonomous\ndriving. We evaluate the proposed SafeDAgger in a car racing simulator and show\nthat it indeed requires less queries to a reference policy. We observe a\nsignificant speed up in convergence, which we conjecture to be due to the\neffect of automated curriculum learning.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 17:40:16 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Zhang", "Jiakai", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1605.06457", "submitter": "Adrien Gaidon", "authors": "Adrien Gaidon, Qiao Wang, Yohann Cabon, Eleonora Vig", "title": "Virtual Worlds as Proxy for Multi-Object Tracking Analysis", "comments": "CVPR 2016, Virtual KITTI dataset download at\n  http://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer vision algorithms typically require expensive data\nacquisition and accurate manual labeling. In this work, we instead leverage the\nrecent progress in computer graphics to generate fully labeled, dynamic, and\nphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtual\nworld cloning method, and validate our approach by building and publicly\nreleasing a new video dataset, called Virtual KITTI (see\nhttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),\nautomatically labeled with accurate ground truth for object detection,\ntracking, scene and instance segmentation, depth, and optical flow. We provide\nquantitative experimental evidence suggesting that (i) modern deep learning\nalgorithms pre-trained on real data behave similarly in real and virtual\nworlds, and (ii) pre-training on virtual data improves performance. As the gap\nbetween real and virtual worlds is small, virtual worlds enable measuring the\nimpact of various weather and imaging conditions on recognition performance,\nall other things being equal. We show these factors may affect drastically\notherwise high-performing deep models for tracking.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 18:03:07 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Gaidon", "Adrien", ""], ["Wang", "Qiao", ""], ["Cabon", "Yohann", ""], ["Vig", "Eleonora", ""]]}, {"id": "1605.06465", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Derek Hoiem and David Forsyth", "title": "Swapout: Learning an ensemble of deep architectures", "comments": "Submitted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Swapout, a new stochastic training method, that outperforms\nResNets of identical network structure yielding impressive results on CIFAR-10\nand CIFAR-100. Swapout samples from a rich set of architectures including\ndropout, stochastic depth and residual architectures as special cases. When\nviewed as a regularization method swapout not only inhibits co-adaptation of\nunits in a layer, similar to dropout, but also across network layers. We\nconjecture that swapout achieves strong regularization by implicitly tying the\nparameters across layers. When viewed as an ensemble training method, it\nsamples a much richer set of architectures than existing methods such as\ndropout or stochastic depth. We propose a parameterization that reveals\nconnections to exiting architectures and suggests a much richer set of\narchitectures to be explored. We show that our formulation suggests an\nefficient training method and validate our conclusions on CIFAR-10 and\nCIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer wider\nmodel performs similar to a 1001 layer ResNet model.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 18:39:33 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Singh", "Saurabh", ""], ["Hoiem", "Derek", ""], ["Forsyth", "David", ""]]}, {"id": "1605.06477", "submitter": "Marta Soare", "authors": "Marta Soare, Muhammad Ammad-ud-din, Samuel Kaski", "title": "Regression with n$\\to$1 by Expert Knowledge Elicitation", "comments": "In Proceedings of the 15th IEEE International Conference on Machine\n  Learning and Applications (IEEE ICMLA'16)", "journal-ref": null, "doi": "10.1109/ICMLA.2016.0131", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider regression under the \"extremely small $n$ large $p$\" condition,\nwhere the number of samples $n$ is so small compared to the dimensionality $p$\nthat predictors cannot be estimated without prior knowledge. This setup occurs\nin personalized medicine, for instance, when predicting treatment outcomes for\nan individual patient based on noisy high-dimensional genomics data. A\nremaining source of information is expert knowledge, which has received\nrelatively little attention in recent years. We formulate the inference problem\nof asking expert feedback on features on a budget, propose an elicitation\nstrategy for a simple \"small $n$\" setting, and derive conditions under which\nthe elicitation strategy is optimal. Experiments on simulated experts, both on\nsynthetic and genomics data, demonstrate that the proposed strategy can\ndrastically improve prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 19:19:08 GMT"}, {"version": "v2", "created": "Sat, 24 Sep 2016 21:58:12 GMT"}, {"version": "v3", "created": "Tue, 7 Feb 2017 01:39:35 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Soare", "Marta", ""], ["Ammad-ud-din", "Muhammad", ""], ["Kaski", "Samuel", ""]]}, {"id": "1605.06489", "submitter": "Yani Ioannou", "authors": "Yani Ioannou, Duncan Robertson, Roberto Cipolla, Antonio Criminisi", "title": "Deep Roots: Improving CNN Efficiency with Hierarchical Filter Groups", "comments": "Updated full version of paper, in full letter paper two-column paper.\n  Includes many textual changes, updated CIFAR10 results, and new analysis of\n  inter/intra-layer correlation", "journal-ref": null, "doi": "10.1109/CVPR.2017.633", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for creating computationally efficient and compact\nconvolutional neural networks (CNNs) using a novel sparse connection structure\nthat resembles a tree root. This allows a significant reduction in\ncomputational cost and number of parameters compared to state-of-the-art deep\nCNNs, without compromising accuracy, by exploiting the sparsity of inter-layer\nfilter dependencies. We validate our approach by using it to train more\nefficient variants of state-of-the-art CNN architectures, evaluated on the\nCIFAR10 and ILSVRC datasets. Our results show similar or higher accuracy than\nthe baseline architectures with much less computation, as measured by CPU and\nGPU timings. For example, for ResNet 50, our model has 40% fewer parameters,\n45% fewer floating point operations, and is 31% (12%) faster on a CPU (GPU).\nFor the deeper ResNet 200 our model has 25% fewer floating point operations and\n44% fewer parameters, while maintaining state-of-the-art accuracy. For\nGoogLeNet, our model has 7% fewer parameters and is 21% (16%) faster on a CPU\n(GPU).\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 19:51:37 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 17:29:01 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 15:32:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ioannou", "Yani", ""], ["Robertson", "Duncan", ""], ["Cipolla", "Roberto", ""], ["Criminisi", "Antonio", ""]]}, {"id": "1605.06492", "submitter": "Dan Garber", "authors": "Dan Garber and Ofer Meshi", "title": "Linear-memory and Decomposition-invariant Linearly Convergent\n  Conditional Gradient Algorithm for Structured Polytopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several works have shown that natural modifications of the\nclassical conditional gradient method (aka Frank-Wolfe algorithm) for\nconstrained convex optimization, provably converge with a linear rate when: i)\nthe feasible set is a polytope, and ii) the objective is smooth and\nstrongly-convex. However, all of these results suffer from two significant\nshortcomings: large memory requirement due to the need to store an explicit\nconvex decomposition of the current iterate, and as a consequence, large\nrunning-time overhead per iteration, and worst case convergence rate that\ndepends unfavorably on the dimension.\n  In this work we present a new conditional gradient variant and a\ncorresponding analysis that improves on both of the above shortcomings. In\nparticular: both memory and computation overheads are only linear in the\ndimension. Moreover, in case the optimal solution is sparse, the new\nconvergence rate replaces a factor which is at least linear in the dimension in\nprevious works, with a linear dependence on the number of non-zeros in the\noptimal solution.\n  At the heart of our method, and corresponding analysis, is a novel way to\ncompute decomposition-invariant away-steps. While our theoretical guarantees do\nnot apply to any polytope, they apply to several important structured polytopes\nthat capture central concepts such as paths in graphs, perfect matchings in\nbipartite graphs, marginal distributions that arise in structured prediction\ntasks, and more. Our theoretical findings are complemented by empirical\nevidence which shows that our method delivers state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 19:55:48 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Garber", "Dan", ""], ["Meshi", "Ofer", ""]]}, {"id": "1605.06523", "submitter": "William Cohen", "authors": "William W. Cohen", "title": "TensorLog: A Differentiable Deductive Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge bases (KBs) are useful in many tasks, but it is unclear how\nto integrate this sort of knowledge into \"deep\" gradient-based learning\nsystems. To address this problem, we describe a probabilistic deductive\ndatabase, called TensorLog, in which reasoning uses a differentiable process.\nIn TensorLog, each clause in a logical theory is first converted into certain\ntype of factor graph. Then, for each type of query to the factor graph, the\nmessage-passing steps required to perform belief propagation (BP) are\n\"unrolled\" into a function, which is differentiable. We show that these\nfunctions can be composed recursively to perform inference in non-trivial\nlogical theories containing multiple interrelated clauses and predicates. Both\ncompilation and inference in TensorLog are efficient: compilation is linear in\ntheory size and proof depth, and inference is linear in database size and the\nnumber of message-passing steps used in BP. We also present experimental\nresults with TensorLog and discuss its relationship to other first-order\nprobabilistic logics.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 20:10:46 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 21:03:55 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Cohen", "William W.", ""]]}, {"id": "1605.06560", "submitter": "Lei Shi", "authors": "Lei Shi and Shikun Feng and Zhifan Zhu", "title": "Functional Hashing for Compressing Neural Networks", "comments": "submitted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of deep neural networks (DNNs) trend to grow to absorb the\nincreasing sizes of data, memory and energy consumption has been receiving more\nand more attentions for industrial applications, especially on mobile devices.\nThis paper presents a novel structure based on functional hashing to compress\nDNNs, namely FunHashNN. For each entry in a deep net, FunHashNN uses multiple\nlow-cost hash functions to fetch values in the compression space, and then\nemploys a small reconstruction network to recover that entry. The\nreconstruction network is plugged into the whole network and trained jointly.\nFunHashNN includes the recently proposed HashedNets as a degenerated case, and\nbenefits from larger value capacity and less reconstruction loss. We further\ndiscuss extensions with dual space hashing and multi-hops. On several benchmark\ndatasets, FunHashNN demonstrates high compression ratios with little loss on\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 23:44:19 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Shi", "Lei", ""], ["Feng", "Shikun", ""], ["Zhu", "Zhifan", ""]]}, {"id": "1605.06561", "submitter": "Aurelien Lucchi", "authors": "Hadi Daneshmand, Aurelien Lucchi, Thomas Hofmann", "title": "DynaNewton - Accelerating Newton's Method for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newton's method is a fundamental technique in optimization with quadratic\nconvergence within a neighborhood around the optimum. However reaching this\nneighborhood is often slow and dominates the computational costs. We exploit\ntwo properties specific to empirical risk minimization problems to accelerate\nNewton's method, namely, subsampling training data and increasing strong\nconvexity through regularization. We propose a novel continuation method, where\nwe define a family of objectives over increasing sample sizes and with\ndecreasing regularization strength. Solutions on this path are tracked such\nthat the minimizer of the previous objective is guaranteed to be within the\nquadratic convergence region of the next objective to be optimized. Thereby\nevery Newton iteration is guaranteed to achieve super-linear contractions with\nregard to the chosen objective, which becomes a moving target. We provide a\ntheoretical analysis that motivates our algorithm, called DynaNewton, and\ncharacterizes its speed of convergence. Experiments on a wide range of data\nsets and problems consistently confirm the predicted computational savings.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 23:46:58 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Daneshmand", "Hadi", ""], ["Lucchi", "Aurelien", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1605.06593", "submitter": "Zheng Wen", "authors": "Zheng Wen, Branislav Kveton, Michal Valko, Sharan Vaswani", "title": "Online Influence Maximization under Independent Cascade Model with\n  Semi-Bandit Feedback", "comments": "Compared with the previous version, this version has fixed a mistake.\n  This version is also consistent with the NIPS camera-ready version", "journal-ref": "Z. Wen, B. Kveton, M. Valko, and S. Vaswani, \"Online Influence\n  Maximization under Independent Cascade Model with Semi-Bandit Feedback\",\n  Advances in Neural Information Processing Systems 30 Proceedings, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online influence maximization problem in social networks under\nthe independent cascade model. Specifically, we aim to learn the set of \"best\ninfluencers\" in a social network online while repeatedly interacting with it.\nWe address the challenges of (i) combinatorial action space, since the number\nof feasible influencer sets grows exponentially with the maximum number of\ninfluencers, and (ii) limited feedback, since only the influenced portion of\nthe network is observed. Under a stochastic semi-bandit feedback, we propose\nand analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our\nbounds on the cumulative regret are polynomial in all quantities of interest,\nachieve near-optimal dependence on the number of interactions and reflect the\ntopology of the network and the activation probabilities of its edges, thereby\ngiving insights on the problem complexity. To the best of our knowledge, these\nare the first such results. Our experiments show that in several representative\ngraph topologies, the regret of IMLinUCB scales as suggested by our upper\nbounds. IMLinUCB permits linear generalization and thus is both statistically\nand computationally suitable for large-scale problems. Our experiments also\nshow that IMLinUCB with linear generalization can lead to low regret in\nreal-world online influence maximization.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 06:07:53 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 23:36:42 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 05:51:52 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Wen", "Zheng", ""], ["Kveton", "Branislav", ""], ["Valko", "Michal", ""], ["Vaswani", "Sharan", ""]]}, {"id": "1605.06619", "submitter": "Yitan Li", "authors": "Yitan Li, Linli Xu, Xiaowei Zhong, Qing Ling", "title": "Make Workers Work Harder: Decoupled Asynchronous Proximal Stochastic\n  Gradient Descent", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous parallel optimization algorithms for solving large-scale machine\nlearning problems have drawn significant attention from academia to industry\nrecently. This paper proposes a novel algorithm, decoupled asynchronous\nproximal stochastic gradient descent (DAP-SGD), to minimize an objective\nfunction that is the composite of the average of multiple empirical losses and\na regularization term. Unlike the traditional asynchronous proximal stochastic\ngradient descent (TAP-SGD) in which the master carries much of the computation\nload, the proposed algorithm off-loads the majority of computation tasks from\nthe master to workers, and leaves the master to conduct simple addition\noperations. This strategy yields an easy-to-parallelize algorithm, whose\nperformance is justified by theoretical convergence analyses. To be specific,\nDAP-SGD achieves an $O(\\log T/T)$ rate when the step-size is diminishing and an\nergodic $O(1/\\sqrt{T})$ rate when the step-size is constant, where $T$ is the\nnumber of total iterations.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 10:27:50 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Li", "Yitan", ""], ["Xu", "Linli", ""], ["Zhong", "Xiaowei", ""], ["Ling", "Qing", ""]]}, {"id": "1605.06636", "submitter": "Mingsheng Long", "authors": "Mingsheng Long, Han Zhu, Jianmin Wang, Michael I. Jordan", "title": "Deep Transfer Learning with Joint Adaptation Networks", "comments": "34th International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have been successfully applied to learn transferable features\nfor adapting models from a source domain to a different target domain. In this\npaper, we present joint adaptation networks (JAN), which learn a transfer\nnetwork by aligning the joint distributions of multiple domain-specific layers\nacross domains based on a joint maximum mean discrepancy (JMMD) criterion.\nAdversarial training strategy is adopted to maximize JMMD such that the\ndistributions of the source and target domains are made more distinguishable.\nLearning can be performed by stochastic gradient descent with the gradients\ncomputed by back-propagation in linear-time. Experiments testify that our model\nyields state of the art results on standard datasets.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 12:56:14 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 07:35:59 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Long", "Mingsheng", ""], ["Zhu", "Han", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1605.06640", "submitter": "Matko Bo\\v{s}njak", "authors": "Matko Bo\\v{s}njak, Tim Rockt\\\"aschel, Jason Naradowsky, Sebastian\n  Riedel", "title": "Programming with a Differentiable Forth Interpreter", "comments": "34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that in practice training data is scarce for all but a small set of\nproblems, a core question is how to incorporate prior knowledge into a model.\nIn this paper, we consider the case of prior procedural knowledge for neural\nnetworks, such as knowing how a program should traverse a sequence, but not\nwhat local actions should be performed at each step. To this end, we present an\nend-to-end differentiable interpreter for the programming language Forth which\nenables programmers to write program sketches with slots that can be filled\nwith behaviour trained from program input-output data. We can optimise this\nbehaviour directly through gradient descent techniques on user-specified\nobjectives, and also integrate the program into any larger neural computation\ngraph. We show empirically that our interpreter is able to effectively leverage\ndifferent levels of prior program structure and learn complex behaviours such\nas sequence sorting and addition. When connected to outputs of an LSTM and\ntrained jointly, our interpreter achieves state-of-the-art accuracy for\nend-to-end reasoning about quantities expressed in natural language stories.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 13:24:14 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 19:15:44 GMT"}, {"version": "v3", "created": "Sun, 23 Jul 2017 09:20:48 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Bo\u0161njak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Naradowsky", "Jason", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1605.06650", "submitter": "Peixian Chen", "authors": "Peixian Chen, Nevin L. Zhang, Tengfei Liu, Leonard K.M. Poon, Zhourong\n  Chen and Farhan Khawar", "title": "Latent Tree Models for Hierarchical Topic Detection", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for hierarchical topic detection where topics are\nobtained by clustering documents in multiple ways. Specifically, we model\ndocument collections using a class of graphical models called hierarchical\nlatent tree models (HLTMs). The variables at the bottom level of an HLTM are\nobserved binary variables that represent the presence/absence of words in a\ndocument. The variables at other levels are binary latent variables, with those\nat the lowest latent level representing word co-occurrence patterns and those\nat higher levels representing co-occurrence of patterns at the level below.\nEach latent variable gives a soft partition of the documents, and document\nclusters in the partitions are interpreted as topics. Latent variables at high\nlevels of the hierarchy capture long-range word co-occurrence patterns and\nhence give thematically more general topics, while those at low levels of the\nhierarchy capture short-range word co-occurrence patterns and give thematically\nmore specific topics. Unlike LDA-based topic models, HLTMs do not refer to a\ndocument generation process and use word variables instead of token variables.\nThey use a tree structure to model the relationships between topics and words,\nwhich is conducive to the discovery of meaningful topics and topic hierarchies.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 14:36:33 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 08:59:14 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Chen", "Peixian", ""], ["Zhang", "Nevin L.", ""], ["Liu", "Tengfei", ""], ["Poon", "Leonard K. M.", ""], ["Chen", "Zhourong", ""], ["Khawar", "Farhan", ""]]}, {"id": "1605.06651", "submitter": "Nima Akbarzadeh", "authors": "Nima Akbarzadeh, Cem Tekin", "title": "Gambler's Ruin Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new multi-armed bandit problem called the\nGambler's Ruin Bandit Problem (GRBP). In the GRBP, the learner proceeds in a\nsequence of rounds, where each round is a Markov Decision Process (MDP) with\ntwo actions (arms): a continuation action that moves the learner randomly over\nthe state space around the current state; and a terminal action that moves the\nlearner directly into one of the two terminal states (goal and dead-end state).\nThe current round ends when a terminal state is reached, and the learner incurs\na positive reward only when the goal state is reached. The objective of the\nlearner is to maximize its long-term reward (expected number of times the goal\nstate is reached), without having any prior knowledge on the state transition\nprobabilities. We first prove a result on the form of the optimal policy for\nthe GRBP. Then, we define the regret of the learner with respect to an\nomnipotent oracle, which acts optimally in each round, and prove that it\nincreases logarithmically over rounds. We also identify a condition under which\nthe learner's regret is bounded. A potential application of the GRBP is optimal\nmedical treatment assignment, in which the continuation action corresponds to a\nconservative treatment and the terminal action corresponds to a risky treatment\nsuch as surgery.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 14:43:44 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 13:54:20 GMT"}, {"version": "v3", "created": "Thu, 29 Sep 2016 03:51:57 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Akbarzadeh", "Nima", ""], ["Tekin", "Cem", ""]]}, {"id": "1605.06652", "submitter": "Oran Richman", "authors": "Oran Richman, Shie Mannor", "title": "Bending the Curve: Improving the ROC Curve Through Error Redistribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification performance is often not uniform over the data. Some areas in\nthe input space are easier to classify than others. Features that hold\ninformation about the \"difficulty\" of the data may be non-discriminative and\nare therefore disregarded in the classification process. We propose a\nmeta-learning approach where performance may be improved by post-processing.\nThis improvement is done by establishing a dynamic threshold on the\nbase-classifier results. Since the base-classifier is treated as a \"black box\"\nthe method presented can be used on any state of the art classifier in order to\ntry an improve its performance. We focus our attention on how to better control\nthe true-positive/false-positive trade-off known as the ROC curve. We propose\nan algorithm for the derivation of optimal thresholds by redistributing the\nerror depending on features that hold information about difficulty. We\ndemonstrate the resulting benefit on both synthetic and real-life data.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 14:46:23 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Richman", "Oran", ""], ["Mannor", "Shie", ""]]}, {"id": "1605.06673", "submitter": "Anfeng Xu", "authors": "Hongqi Wang, Anfeng Xu, Shanshan Wang, Sunny Chughtai", "title": "Cross Domain Adaptation by Learning Partially Shared Classifiers and\n  Weighting Source Data Points in the Shared Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a problem defined over two domains. These two domains\nshare the same feature space and class label space, but have significantly\ndifferent distributions. One domain has sufficient labels, named as source\ndomain, and the other domain has few labels, named as target do- main. The\nproblem is to learn a effective classifier for the target domain. In this\npaper, we propose a novel transfer learning method for this problem by learning\na partially shared classifier for the target domain, and weighting the source\ndomain data points. We learn some shared subspaces for both the data points of\nthe two domains, and a shared classifier in the shared subspaces. We hope that\nin the shared subspaces, the distributions of two domain can match each other\nwell, and to match the distributions, we weight the source domain data points\nwith different weighting factors. Moreover, we adapt the shared classifier to\neach domain by learning different adaptation functions. To learn the subspace\ntransformation matrices, the classifier parameters, and the adaptation\nparameters, we build a objective function with weighted clas- sification\nerrors, parameter regularization, local reconstruction regularization, and\ndistribution matching. This objective function is minimized by an itera- tive\nalgorithm. Experiments show its effectiveness over benchmark data sets,\nincluding travel destination review data set, face expression data set, spam\nemail data set, etc.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 16:57:37 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Wang", "Hongqi", ""], ["Xu", "Anfeng", ""], ["Wang", "Shanshan", ""], ["Chughtai", "Sunny", ""]]}, {"id": "1605.06676", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, Shimon Whiteson", "title": "Learning to Communicate with Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of multiple agents sensing and acting in environments\nwith the goal of maximising their shared utility. In these environments, agents\nmust learn communication protocols in order to share information that is needed\nto solve the tasks. By embracing deep neural networks, we are able to\ndemonstrate end-to-end learning of protocols in complex environments inspired\nby communication riddles and multi-agent computer vision problems with partial\nobservability. We propose two approaches for learning in these domains:\nReinforced Inter-Agent Learning (RIAL) and Differentiable Inter-Agent Learning\n(DIAL). The former uses deep Q-learning, while the latter exploits the fact\nthat, during learning, agents can backpropagate error derivatives through\n(noisy) communication channels. Hence, this approach uses centralised learning\nbut decentralised execution. Our experiments introduce new environments for\nstudying the learning of communication protocols and present a set of\nengineering innovations that are essential for success in these domains.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 17:20:04 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 18:16:56 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Assael", "Yannis M.", ""], ["de Freitas", "Nando", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1605.06693", "submitter": "Gaurav Singh", "authors": "Gaurav Singh and Benjamin Piwowarski", "title": "Efficient Document Indexing Using Pivot Tree", "comments": "6 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for efficiently searching top-k neighbors for\ndocuments represented in high dimensional space of terms based on the cosine\nsimilarity. Mostly, documents are stored as bag-of-words tf-idf representation.\nOne of the most used ways of computing similarity between a pair of documents\nis cosine similarity between the vector representations, but cosine similarity\nis not a metric distance measure as it doesn't follow triangle inequality,\ntherefore most metric searching methods can not be applied directly. We propose\nan efficient method for indexing documents using a pivot tree that leads to\nefficient retrieval. We also study the relation between precision and\nefficiency for the proposed method and compare it with a state of the art in\nthe area of document searching based on inner product.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 19:55:03 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Singh", "Gaurav", ""], ["Piwowarski", "Benjamin", ""]]}, {"id": "1605.06711", "submitter": "Bo Yang", "authors": "Bo Yang, Xiao Fu and Nicholas D. Sidiropoulos", "title": "Learning From Hidden Traits: Joint Factor Analysis and Latent Clustering", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2614491", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction techniques play an essential role in data analytics,\nsignal processing and machine learning. Dimensionality reduction is usually\nperformed in a preprocessing stage that is separate from subsequent data\nanalysis, such as clustering or classification. Finding reduced-dimension\nrepresentations that are well-suited for the intended task is more appealing.\nThis paper proposes a joint factor analysis and latent clustering framework,\nwhich aims at learning cluster-aware low-dimensional representations of matrix\nand tensor data. The proposed approach leverages matrix and tensor\nfactorization models that produce essentially unique latent representations of\nthe data to unravel latent cluster structure -- which is otherwise obscured\nbecause of the freedom to apply an oblique transformation in latent space. At\nthe same time, latent cluster structure is used as prior information to enhance\nthe performance of factorization. Specific contributions include several\ncustom-built problem formulations, corresponding algorithms, and discussion of\nassociated convergence properties. Besides extensive simulations, real-world\ndatasets such as Reuters document data and MNIST image data are also employed\nto showcase the effectiveness of the proposed approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 23:51:02 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Yang", "Bo", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1605.06715", "submitter": "Jiaming Song", "authors": "Jiaming Song, Zhe Gan, Lawrence Carin", "title": "Factored Temporal Sigmoid Belief Networks for Sequence Learning", "comments": "to appear in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep conditional generative models are developed to simultaneously learn the\ntemporal dependencies of multiple sequences. The model is designed by\nintroducing a three-way weight tensor to capture the multiplicative\ninteractions between side information and sequences. The proposed model builds\non the Temporal Sigmoid Belief Network (TSBN), a sequential stack of Sigmoid\nBelief Networks (SBNs). The transition matrices are further factored to reduce\nthe number of parameters and improve generalization. When side information is\nnot available, a general framework for semi-supervised learning based on the\nproposed model is constituted, allowing robust sequence classification.\nExperimental results show that the proposed approach achieves state-of-the-art\npredictive and classification performance on sequential data, and has the\ncapacity to synthesize sequences, with controlled style transitioning and\nblending.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 00:17:31 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Song", "Jiaming", ""], ["Gan", "Zhe", ""], ["Carin", "Lawrence", ""]]}, {"id": "1605.06742", "submitter": "Wenshuo Wang", "authors": "Wenshuo Wang and Junqiang Xi", "title": "A Rapid Pattern-Recognition Method for Driving Types Using\n  Clustering-Based Support Vector Machines", "comments": "6 pages, 9 figures, 2 tables. To be appear in 2016 American Control\n  Conference, Boston, MA, USA, 2016", "journal-ref": "2017 American Control Conference", "doi": "10.1109/ACC.2016.7526495", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rapid pattern-recognition approach to characterize driver's\ncurve-negotiating behavior is proposed. To shorten the recognition time and\nimprove the recognition of driving styles, a k-means clustering-based support\nvector machine ( kMC-SVM) method is developed and used for classifying drivers\ninto two types: aggressive and moderate. First, vehicle speed and throttle\nopening are treated as the feature parameters to reflect the driving styles.\nSecond, to discriminate driver curve-negotiating behaviors and reduce the\nnumber of support vectors, the k-means clustering method is used to extract and\ngather the two types of driving data and shorten the recognition time. Then,\nbased on the clustering results, a support vector machine approach is utilized\nto generate the hyperplane for judging and predicting to which types the human\ndriver are subject. Lastly, to verify the validity of the kMC-SVM method, a\ncross-validation experiment is designed and conducted. The research results\nshow that the $ k $MC-SVM is an effective method to classify driving styles\nwith a short time, compared with SVM method.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 06:15:11 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Wang", "Wenshuo", ""], ["Xi", "Junqiang", ""]]}, {"id": "1605.06743", "submitter": "Nadav Cohen", "authors": "Nadav Cohen and Amnon Shashua", "title": "Inductive Bias of Deep Convolutional Networks through Pooling Geometry", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our formal understanding of the inductive bias that drives the success of\nconvolutional networks on computer vision tasks is limited. In particular, it\nis unclear what makes hypotheses spaces born from convolution and pooling\noperations so suitable for natural images. In this paper we study the ability\nof convolutional networks to model correlations among regions of their input.\nWe theoretically analyze convolutional arithmetic circuits, and empirically\nvalidate our findings on other types of convolutional networks as well.\nCorrelations are formalized through the notion of separation rank, which for a\ngiven partition of the input, measures how far a function is from being\nseparable. We show that a polynomially sized deep network supports\nexponentially high separation ranks for certain input partitions, while being\nlimited to polynomial separation ranks for others. The network's pooling\ngeometry effectively determines which input partitions are favored, thus serves\nas a means for controlling the inductive bias. Contiguous pooling windows as\ncommonly employed in practice favor interleaved partitions over coarse ones,\norienting the inductive bias towards the statistics of natural images. Other\npooling schemes lead to different preferences, and this allows tailoring the\nnetwork to data that departs from the usual domain of natural imagery. In\naddition to analyzing deep networks, we show that shallow ones support only\nlinear separation ranks, and by this gain insight into the benefit of functions\nbrought forth by depth - they are able to efficiently model strong correlation\nunder favored partitions of the input.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 06:15:31 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 16:06:20 GMT"}, {"version": "v3", "created": "Wed, 14 Dec 2016 10:29:18 GMT"}, {"version": "v4", "created": "Mon, 17 Apr 2017 18:36:08 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Cohen", "Nadav", ""], ["Shashua", "Amnon", ""]]}, {"id": "1605.06792", "submitter": "Sivan Sabato", "authors": "Aryeh Kontorovich, Sivan Sabato, Ruth Urner", "title": "Active Nearest-Neighbor Learning in Metric Spaces", "comments": null, "journal-ref": "A. Kontorovich, S. Sabato, R. Urner, \"Active Nearest-Neighbor\n  Learning in Metric Spaces\", Journal of Machine Learning Research,\n  18(195):1--38, 2018", "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a pool-based non-parametric active learning algorithm for general\nmetric spaces, called MArgin Regularized Metric Active Nearest Neighbor\n(MARMANN), which outputs a nearest-neighbor classifier. We give prediction\nerror guarantees that depend on the noisy-margin properties of the input\nsample, and are competitive with those obtained by previously proposed passive\nlearners. We prove that the label complexity of MARMANN is significantly lower\nthan that of any passive learner with similar error guarantees. MARMANN is\nbased on a generalized sample compression scheme, and a new label-efficient\nactive model-selection procedure.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 14:00:27 GMT"}, {"version": "v2", "created": "Sun, 16 Oct 2016 08:23:18 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2018 13:42:26 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Kontorovich", "Aryeh", ""], ["Sabato", "Sivan", ""], ["Urner", "Ruth", ""]]}, {"id": "1605.06796", "submitter": "Wittawat Jitkrittum", "authors": "Wittawat Jitkrittum, Zoltan Szabo, Kacper Chwialkowski, Arthur Gretton", "title": "Interpretable Distribution Features with Maximum Testing Power", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two semimetrics on probability distributions are proposed, given as the sum\nof differences of expectations of analytic functions evaluated at spatial or\nfrequency locations (i.e, features). The features are chosen so as to maximize\nthe distinguishability of the distributions, by optimizing a lower bound on\ntest power for a statistical test using these features. The result is a\nparsimonious and interpretable indication of how and where two distributions\ndiffer locally. An empirical estimate of the test power criterion converges\nwith increasing sample size, ensuring the quality of the returned features. In\nreal-world benchmarks on high-dimensional text and image data, linear-time\ntests using the proposed semimetrics achieve comparable performance to the\nstate-of-the-art quadratic-time maximum mean discrepancy test, while returning\nhuman-interpretable features that explain the test results.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 14:10:13 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 10:48:05 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Szabo", "Zoltan", ""], ["Chwialkowski", "Kacper", ""], ["Gretton", "Arthur", ""]]}, {"id": "1605.06848", "submitter": "Stefan Kiefer", "authors": "Dmitry Chistikov, Stefan Kiefer, Ines Maru\\v{s}i\\'c, Mahsa\n  Shirmohammadi, James Worrell", "title": "Nonnegative Matrix Factorization Requires Irrationality", "comments": "Journal version, to appear in the SIAM Journal on Applied Algebra and\n  Geometry (SIAGA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is the problem of decomposing a given\nnonnegative $n \\times m$ matrix $M$ into a product of a nonnegative $n \\times\nd$ matrix $W$ and a nonnegative $d \\times m$ matrix $H$. A longstanding open\nquestion, posed by Cohen and Rothblum in 1993, is whether a rational matrix $M$\nalways has an NMF of minimal inner dimension $d$ whose factors $W$ and $H$ are\nalso rational. We answer this question negatively, by exhibiting a matrix for\nwhich $W$ and $H$ require irrational entries.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 20:17:24 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 22:03:17 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Kiefer", "Stefan", ""], ["Maru\u0161i\u0107", "Ines", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1605.06855", "submitter": "Manuel Gomez Rodriguez", "authors": "Mohammad Reza Karimi and Erfan Tavakoli and Mehrdad Farajtabar and Le\n  Song and Manuel Gomez-Rodriguez", "title": "Smart broadcasting: Do you want to be seen?", "comments": "To appear in Proceedings of the 22nd ACM SIGKDD International\n  Conference on Knowledge Discovery and Data Mining (KDD), San Francisco (CA,\n  USA), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many users in online social networks are constantly trying to gain attention\nfrom their followers by broadcasting posts to them. These broadcasters are\nlikely to gain greater attention if their posts can remain visible for a longer\nperiod of time among their followers' most recent feeds. Then when to post? In\nthis paper, we study the problem of smart broadcasting using the framework of\ntemporal point processes, where we model users feeds and posts as discrete\nevents occurring in continuous time. Based on such continuous-time model, then\nchoosing a broadcasting strategy for a user becomes a problem of designing the\nconditional intensity of her posting events. We derive a novel formula which\nlinks this conditional intensity with the visibility of the user in her\nfollowers' feeds. Furthermore, by exploiting this formula, we develop an\nefficient convex optimization framework for the when-to-post problem. Our\nmethod can find broadcasting strategies that reach a desired visibility level\nwith provable guarantees. We experimented with data gathered from Twitter, and\nshow that our framework can consistently make broadcasters' post more visible\nthan alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 21:18:19 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Karimi", "Mohammad Reza", ""], ["Tavakoli", "Erfan", ""], ["Farajtabar", "Mehrdad", ""], ["Song", "Le", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1605.06894", "submitter": "Chao Wang", "authors": "Chao Wang, Qi Yu, Lei Gong, Xi Li, Yuan Xie, Xuehai Zhou", "title": "DLAU: A Scalable Deep Learning Accelerator Unit on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the emerging field of machine learning, deep learning shows excellent\nability in solving complex learning problems. However, the size of the networks\nbecomes increasingly large scale due to the demands of the practical\napplications, which poses significant challenge to construct a high performance\nimplementations of deep learning neural networks. In order to improve the\nperformance as well to maintain the low power cost, in this paper we design\nDLAU, which is a scalable accelerator architecture for large-scale deep\nlearning networks using FPGA as the hardware prototype. The DLAU accelerator\nemploys three pipelined processing units to improve the throughput and utilizes\ntile techniques to explore locality for deep learning applications.\nExperimental results on the state-of-the-art Xilinx FPGA board demonstrate that\nthe DLAU accelerator is able to achieve up to 36.1x speedup comparing to the\nIntel Core2 processors, with the power consumption at 234mW.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 04:56:04 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Wang", "Chao", ""], ["Yu", "Qi", ""], ["Gong", "Lei", ""], ["Li", "Xi", ""], ["Xie", "Yuan", ""], ["Zhou", "Xuehai", ""]]}, {"id": "1605.06900", "submitter": "Sashank J. Reddi", "authors": "Sashank J. Reddi, Suvrit Sra, Barnabas Poczos, Alex Smola", "title": "Fast Stochastic Methods for Nonsmooth Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze stochastic algorithms for optimizing nonconvex, nonsmooth\nfinite-sum problems, where the nonconvex part is smooth and the nonsmooth part\nis convex. Surprisingly, unlike the smooth case, our knowledge of this\nfundamental problem is very limited. For example, it is not known whether the\nproximal stochastic gradient method with constant minibatch converges to a\nstationary point. To tackle this issue, we develop fast stochastic algorithms\nthat provably converge to a stationary point for constant minibatches.\nFurthermore, using a variant of these algorithms, we show provably faster\nconvergence than batch proximal gradient descent. Finally, we prove global\nlinear convergence rate for an interesting subclass of nonsmooth nonconvex\nfunctions, that subsumes several recent works. This paper builds upon our\nrecent series of papers on fast stochastic methods for smooth nonconvex\noptimization [22, 23], with a novel analysis for nonconvex and nonsmooth\nfunctions.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 05:49:00 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Reddi", "Sashank J.", ""], ["Sra", "Suvrit", ""], ["Poczos", "Barnabas", ""], ["Smola", "Alex", ""]]}, {"id": "1605.06921", "submitter": "Luka Crnkovic-Friis", "authors": "Luka Crnkovic-Friis, Louise Crnkovic-Friis", "title": "Generative Choreography using Deep Learning", "comments": "This article will be presented at the 7th International Conference on\n  Computational Creativity, ICCC2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have enabled the extraction of high-level\nfeatures from raw sensor data which has opened up new possibilities in many\ndifferent fields, including computer generated choreography. In this paper we\npresent a system chor-rnn for generating novel choreographic material in the\nnuanced choreographic language and style of an individual choreographer. It\nalso shows promising results in producing a higher level compositional\ncohesion, rather than just generating sequences of movement. At the core of\nchor-rnn is a deep recurrent neural network trained on raw motion capture data\nand that can generate new dance sequences for a solo dancer. Chor-rnn can be\nused for collaborative human-machine choreography or as a creative catalyst,\nserving as inspiration for a choreographer.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 07:36:49 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Crnkovic-Friis", "Luka", ""], ["Crnkovic-Friis", "Louise", ""]]}, {"id": "1605.06931", "submitter": "Oliver Cliff", "authors": "Oliver M. Cliff, Mikhail Prokopenko and Robert Fitch", "title": "An Information Criterion for Inferring Coupling in Distributed Dynamical\n  Systems", "comments": null, "journal-ref": "Front. Robot. AI 3(71), 2016", "doi": "10.3389/frobt.2016.00071", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behaviour of many real-world phenomena can be modelled by nonlinear\ndynamical systems whereby a latent system state is observed through a filter.\nWe are interested in interacting subsystems of this form, which we model by a\nset of coupled maps as a synchronous update graph dynamical systems.\nSpecifically, we study the structure learning problem for spatially distributed\ndynamical systems coupled via a directed acyclic graph. Unlike established\nstructure learning procedures that find locally maximum posterior probabilities\nof a network structure containing latent variables, our work exploits the\nproperties of dynamical systems to compute globally optimal approximations of\nthese distributions. We arrive at this result by the use of time delay\nembedding theorems. Taking an information-theoretic perspective, we show that\nthe log-likelihood has an intuitive interpretation in terms of information\ntransfer.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 08:40:58 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2016 02:45:24 GMT"}, {"version": "v3", "created": "Fri, 11 Nov 2016 06:45:08 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Cliff", "Oliver M.", ""], ["Prokopenko", "Mikhail", ""], ["Fitch", "Robert", ""]]}, {"id": "1605.06950", "submitter": "James Newling", "authors": "James Newling, Fran\\c{c}ois Fleuret", "title": "A Sub-Quadratic Exact Medoid Algorithm", "comments": "Version 2: Added acknowledgements, Version 3: Post-acceptance at\n  AISTATS 2017, Version 4: N-1 -> N denominator correction", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm, trimed, for obtaining the medoid of a set, that\nis the element of the set which minimises the mean distance to all other\nelements. The algorithm is shown to have, under certain assumptions, expected\nrun time O(N^(3/2)) in R^d where N is the set size, making it the first\nsub-quadratic exact medoid algorithm for d>1. Experiments show that it performs\nvery well on spatial network data, frequently requiring two orders of magnitude\nfewer distance calculations than state-of-the-art approximate algorithms. As an\napplication, we show how trimed can be used as a component in an accelerated\nK-medoids algorithm, and then how it can be relaxed to obtain further\ncomputational gains with only a minor loss in cluster quality.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 09:24:59 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 07:44:29 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 07:55:33 GMT"}, {"version": "v4", "created": "Wed, 12 Apr 2017 18:25:34 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Newling", "James", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "1605.06955", "submitter": "Tomoya Sakai", "authors": "Tomoya Sakai, Marthinus Christoffel du Plessis, Gang Niu, Masashi\n  Sugiyama", "title": "Semi-Supervised Classification Based on Classification from Positive and\n  Unlabeled Data", "comments": "Accepted to the 34th International Conference on Machine Learning\n  (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the semi-supervised classification methods developed so far use\nunlabeled data for regularization purposes under particular distributional\nassumptions such as the cluster assumption. In contrast, recently developed\nmethods of classification from positive and unlabeled data (PU classification)\nuse unlabeled data for risk evaluation, i.e., label information is directly\nextracted from unlabeled data. In this paper, we extend PU classification to\nalso incorporate negative data and propose a novel semi-supervised\nclassification approach. We establish generalization error bounds for our novel\nmethods and show that the bounds decrease with respect to the number of\nunlabeled data without the distributional assumptions that are required in\nexisting semi-supervised classification methods. Through experiments, we\ndemonstrate the usefulness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 09:37:48 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 14:04:24 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 11:39:31 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 11:14:36 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Sakai", "Tomoya", ""], ["Plessis", "Marthinus Christoffel du", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1605.06968", "submitter": "Bamdev Mishra", "authors": "Bamdev Mishra, Hiroyuki Kasai, and Atul Saroop", "title": "A Riemannian gossip approach to decentralized matrix completion", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel gossip algorithms for the low-rank\ndecentralized matrix completion problem. The proposed approach is on the\nRiemannian Grassmann manifold that allows local matrix completion by different\nagents while achieving asymptotic consensus on the global low-rank factors. The\nresulting approach is scalable and parallelizable. Our numerical experiments\nshow the good performance of the proposed algorithms on various benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 10:46:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Mishra", "Bamdev", ""], ["Kasai", "Hiroyuki", ""], ["Saroop", "Atul", ""]]}, {"id": "1605.06995", "submitter": "Mijung Park", "authors": "Mijung Park, Jimmy Foulds, Kamalika Chaudhuri, Max Welling", "title": "DP-EM: Differentially Private Expectation Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative nature of the expectation maximization (EM) algorithm presents\na challenge for privacy-preserving estimation, as each iteration increases the\namount of noise needed. We propose a practical private EM algorithm that\novercomes this challenge using two innovations: (1) a novel moment perturbation\nformulation for differentially private EM (DP-EM), and (2) the use of two\nrecently developed composition methods to bound the privacy \"cost\" of multiple\nEM iterations: the moments accountant (MA) and zero-mean concentrated\ndifferential privacy (zCDP). Both MA and zCDP bound the moment generating\nfunction of the privacy loss random variable and achieve a refined tail bound,\nwhich effectively decrease the amount of additive noise. We present empirical\nresults showing the benefits of our approach, as well as similar performance\nbetween these two composition methods in the DP-EM setting for Gaussian mixture\nmodels. Our approach can be readily extended to many iterative learning\nalgorithms, opening up various exciting future directions.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 12:36:55 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 17:17:01 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Park", "Mijung", ""], ["Foulds", "Jimmy", ""], ["Chaudhuri", "Kamalika", ""], ["Welling", "Max", ""]]}, {"id": "1605.07018", "submitter": "Alon Cohen", "authors": "Alon Cohen, Tamir Hazan, Tomer Koren", "title": "Online Learning with Feedback Graphs Without the Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online learning framework introduced by Mannor and Shamir (2011)\nin which the feedback is specified by a graph, in a setting where the graph may\nvary from round to round and is \\emph{never fully revealed} to the learner. We\nshow a large gap between the adversarial and the stochastic cases. In the\nadversarial case, we prove that even for dense feedback graphs, the learner\ncannot improve upon a trivial regret bound obtained by ignoring any additional\nfeedback besides her own loss. In contrast, in the stochastic case we give an\nalgorithm that achieves $\\widetilde \\Theta(\\sqrt{\\alpha T})$ regret over $T$\nrounds, provided that the independence numbers of the hidden feedback graphs\nare at most $\\alpha$. We also extend our results to a more general feedback\nmodel, in which the learner does not necessarily observe her own loss, and show\nthat, even in simple cases, concealing the feedback graphs might render a\nlearnable problem unlearnable.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 14:07:43 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Cohen", "Alon", ""], ["Hazan", "Tamir", ""], ["Koren", "Tomer", ""]]}, {"id": "1605.07025", "submitter": "Hyunjik Kim", "authors": "Hyunjik Kim, Xiaoyu Lu, Seth Flaxman, Yee Whye Teh", "title": "Collaborative Filtering with Side Information: a Gaussian Process\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of collaborative filtering (CF) with side information,\nthrough the lens of Gaussian Process (GP) regression. Driven by the idea of\nusing the kernel to explicitly model user-item similarities, we formulate the\nGP in a way that allows the incorporation of low-rank matrix factorisation,\narriving at our model, the Tucker Gaussian Process (TGP). Consequently, TGP\ngeneralises classical Bayesian matrix factorisation models, and goes beyond\nthem to give a natural and elegant method for incorporating side information,\ngiving enhanced predictive performance for CF problems. Moreover we show that\nit is a novel model for regression, especially well-suited to grid-structured\ndata and problems where the dependence on covariates is close to being\nseparable.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 14:19:02 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 16:19:46 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 11:18:56 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Kim", "Hyunjik", ""], ["Lu", "Xiaoyu", ""], ["Flaxman", "Seth", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1605.07051", "submitter": "Qinqing Zheng", "authors": "Qinqing Zheng, John Lafferty", "title": "Convergence Analysis for Rectangular Matrix Completion Using\n  Burer-Monteiro Factorization and Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the rectangular matrix completion problem by lifting the unknown\nmatrix to a positive semidefinite matrix in higher dimension, and optimizing a\nnonconvex objective over the semidefinite factor using a simple gradient\ndescent scheme. With $O( \\mu r^2 \\kappa^2 n \\max(\\mu, \\log n))$ random\nobservations of a $n_1 \\times n_2$ $\\mu$-incoherent matrix of rank $r$ and\ncondition number $\\kappa$, where $n = \\max(n_1, n_2)$, the algorithm linearly\nconverges to the global optimum with high probability.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 15:14:09 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 03:37:12 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Zheng", "Qinqing", ""], ["Lafferty", "John", ""]]}, {"id": "1605.07057", "submitter": "Xiaoran Yan", "authors": "Xiaoran Yan", "title": "Bayesian Model Selection of Stochastic Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in analyzing networks is partitioning them into modules or\ncommunities. One of the best tools for this is the stochastic block model,\nwhich clusters vertices into blocks with statistically homogeneous pattern of\nlinks. Despite its flexibility and popularity, there has been a lack of\nprincipled statistical model selection criteria for the stochastic block model.\nHere we propose a Bayesian framework for choosing the number of blocks as well\nas comparing it to the more elaborate degree- corrected block models,\nultimately leading to a universal model selection framework capable of\ncomparing multiple modeling combinations. We will also investigate its\nconnection to the minimum description length principle.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 15:16:51 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Yan", "Xiaoran", ""]]}, {"id": "1605.07061", "submitter": "Stefan Kiefer", "authors": "Dmitry Chistikov, Stefan Kiefer, Ines Maru\\v{s}i\\'c, Mahsa\n  Shirmohammadi, James Worrell", "title": "On Restricted Nonnegative Matrix Factorization", "comments": "Full version of an ICALP'16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is the problem of decomposing a given\nnonnegative $n \\times m$ matrix $M$ into a product of a nonnegative $n \\times\nd$ matrix $W$ and a nonnegative $d \\times m$ matrix $H$. Restricted NMF\nrequires in addition that the column spaces of $M$ and $W$ coincide. Finding\nthe minimal inner dimension $d$ is known to be NP-hard, both for NMF and\nrestricted NMF. We show that restricted NMF is closely related to a question\nabout the nature of minimal probabilistic automata, posed by Paz in his seminal\n1971 textbook. We use this connection to answer Paz's question negatively, thus\nfalsifying a positive answer claimed in 1974. Furthermore, we investigate\nwhether a rational matrix $M$ always has a restricted NMF of minimal inner\ndimension whose factors $W$ and $H$ are also rational. We show that this holds\nfor matrices $M$ of rank at most $3$ and we exhibit a rank-$4$ matrix for which\n$W$ and $H$ require irrational entries.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 15:26:26 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Chistikov", "Dmitry", ""], ["Kiefer", "Stefan", ""], ["Maru\u0161i\u0107", "Ines", ""], ["Shirmohammadi", "Mahsa", ""], ["Worrell", "James", ""]]}, {"id": "1605.07066", "submitter": "Thang Bui", "authors": "Thang D. Bui, Josiah Yan, Richard E. Turner", "title": "A Unifying Framework for Gaussian Process Pseudo-Point Approximations\n  using Power Expectation Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are flexible distributions over functions that\nenable high-level assumptions about unknown functions to be encoded in a\nparsimonious, flexible and general way. Although elegant, the application of\nGPs is limited by computational and analytical intractabilities that arise when\ndata are sufficiently numerous or when employing non-Gaussian models.\nConsequently, a wealth of GP approximation schemes have been developed over the\nlast 15 years to address these key limitations. Many of these schemes employ a\nsmall set of pseudo data points to summarise the actual data. In this paper, we\ndevelop a new pseudo-point approximation framework using Power Expectation\nPropagation (Power EP) that unifies a large number of these pseudo-point\napproximations. Unlike much of the previous venerable work in this area, the\nnew framework is built on standard methods for approximate inference\n(variational free-energy, EP and Power EP methods) rather than employing\napproximations to the probabilistic generative model itself. In this way, all\nof approximation is performed at `inference time' rather than at `modelling\ntime' resolving awkward philosophical and empirical questions that trouble\nprevious approaches. Crucially, we demonstrate that the new framework includes\nnew pseudo-point approximation methods that outperform current approaches on\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 15:53:51 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 16:26:54 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 14:58:34 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Bui", "Thang D.", ""], ["Yan", "Josiah", ""], ["Turner", "Richard E.", ""]]}, {"id": "1605.07078", "submitter": "Ayan Chakrabarti", "authors": "Ayan Chakrabarti", "title": "Learning Sensor Multiplexing Design through Back-propagation", "comments": "NIPS 2016. Project page at http://www.ttic.edu/chakrabarti/learncfa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on many imaging and vision tasks has been driven by the use\nof deep feed-forward neural networks, which are trained by propagating\ngradients of a loss defined on the final output, back through the network up to\nthe first layer that operates directly on the image. We propose\nback-propagating one step further---to learn camera sensor designs jointly with\nnetworks that carry out inference on the images they capture. In this paper, we\nspecifically consider the design and inference problems in a typical color\ncamera---where the sensor is able to measure only one color channel at each\npixel location, and computational inference is required to reconstruct a full\ncolor image. We learn the camera sensor's color multiplexing pattern by\nencoding it as layer whose learnable weights determine which color channel,\nfrom among a fixed set, will be measured at each location. These weights are\njointly trained with those of a reconstruction network that operates on the\ncorresponding sensor measurements to produce a full color image. Our network\nachieves significant improvements in accuracy over the traditional Bayer\npattern used in most color cameras. It automatically learns to employ a sparse\ncolor measurement approach similar to that of a recent design, and moreover,\nimproves upon that design by learning an optimal layout for these measurements.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:26:59 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 18:30:57 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Chakrabarti", "Ayan", ""]]}, {"id": "1605.07079", "submitter": "Aaron Klein", "authors": "Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, Frank\n  Hutter", "title": "Fast Bayesian Optimization of Machine Learning Hyperparameters on Large\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization has become a successful tool for hyperparameter\noptimization of machine learning algorithms, such as support vector machines or\ndeep neural networks. Despite its success, for large datasets, training and\nvalidating a single configuration often takes hours, days, or even weeks, which\nlimits the achievable performance. To accelerate hyperparameter optimization,\nwe propose a generative model for the validation error as a function of\ntraining set size, which is learned during the optimization process and allows\nexploration of preliminary configurations on small subsets, by extrapolating to\nthe full dataset. We construct a Bayesian optimization procedure, dubbed\nFabolas, which models loss and training time as a function of dataset size and\nautomatically trades off high information gain about the global optimum against\ncomputational cost. Experiments optimizing support vector machines and deep\nneural networks show that Fabolas often finds high-quality solutions 10 to 100\ntimes faster than other state-of-the-art Bayesian optimization methods or the\nrecently proposed bandit strategy Hyperband.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:29:51 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 14:48:54 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Klein", "Aaron", ""], ["Falkner", "Stefan", ""], ["Bartels", "Simon", ""], ["Hennig", "Philipp", ""], ["Hutter", "Frank", ""]]}, {"id": "1605.07094", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Tatiana Fomina, Bernhard Sch\\\"olkopf, Moritz\n  Grosse-Wentrup", "title": "A note on the expected minimum error probability in equientropic\n  channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the channel capacity reflects a theoretical upper bound on the\nachievable information transmission rate in the limit of infinitely many bits,\nit does not characterise the information transfer of a given encoding routine\nwith finitely many bits. In this note, we characterise the quality of a code\n(i. e. a given encoding routine) by an upper bound on the expected minimum\nerror probability that can be achieved when using this code. We show that for\nequientropic channels this upper bound is minimal for codes with maximal\nmarginal entropy. As an instructive example we show for the additive white\nGaussian noise (AWGN) channel that random coding---also a capacity achieving\ncode---indeed maximises the marginal entropy in the limit of infinite messages.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 17:04:57 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 16:55:42 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Fomina", "Tatiana", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1605.07110", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi", "title": "Deep Learning without Poor Local Minima", "comments": "In NIPS 2016. Selected for NIPS oral presentation (top 2%\n  submissions). ---- The final NIPS 2016 version: the results remain the same", "journal-ref": null, "doi": null, "report-no": "Massachusetts Institute of Technology (MIT), MIT-CSAIL-TR-2016-005", "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we prove a conjecture published in 1989 and also partially\naddress an open problem announced at the Conference on Learning Theory (COLT)\n2015. With no unrealistic assumption, we first prove the following statements\nfor the squared loss function of deep linear neural networks with any depth and\nany widths: 1) the function is non-convex and non-concave, 2) every local\nminimum is a global minimum, 3) every critical point that is not a global\nminimum is a saddle point, and 4) there exist \"bad\" saddle points (where the\nHessian has no negative eigenvalue) for the deeper networks (with more than\nthree layers), whereas there is no bad saddle point for the shallow networks\n(with three layers). Moreover, for deep nonlinear neural networks, we prove the\nsame four statements via a reduction to a deep linear model under the\nindependence assumption adopted from recent work. As a result, we present an\ninstance, for which we can answer the following question: how difficult is it\nto directly train a deep model in theory? It is more difficult than the\nclassical machine learning models (because of the non-convexity), but not too\ndifficult (because of the nonexistence of poor local minima). Furthermore, the\nmathematically proven existence of bad saddle points for deeper models would\nsuggest a possible open problem. We note that even though we have advanced the\ntheoretical foundations of deep learning and non-convex optimization, there is\nstill a gap between theory and practice.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 17:34:20 GMT"}, {"version": "v2", "created": "Mon, 22 Aug 2016 14:26:22 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 22:47:50 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Kawaguchi", "Kenji", ""]]}, {"id": "1605.07127", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Jos\\'e Miguel Hern\\'andez-Lobato, Finale Doshi-Velez,\n  Steffen Udluft", "title": "Learning and Policy Search in Stochastic Dynamical Systems with Bayesian\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for model-based reinforcement learning that combines\nBayesian neural networks (BNNs) with random roll-outs and stochastic\noptimization for policy learning. The BNNs are trained by minimizing\n$\\alpha$-divergences, allowing us to capture complicated statistical patterns\nin the transition dynamics, e.g. multi-modality and heteroskedasticity, which\nare usually missed by other common modeling approaches. We illustrate the\nperformance of our method by solving a challenging benchmark where model-based\napproaches usually fail and by obtaining promising results in a real-world\nscenario for controlling a gas turbine.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 18:28:15 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 07:23:20 GMT"}, {"version": "v3", "created": "Wed, 8 Mar 2017 01:07:15 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Depeweg", "Stefan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Doshi-Velez", "Finale", ""], ["Udluft", "Steffen", ""]]}, {"id": "1605.07133", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Nghia The Pham and Marco Baroni", "title": "Towards Multi-Agent Communication-Based Language Learning", "comments": "9 pages, manuscript under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an interactive multimodal framework for language learning. Instead\nof being passively exposed to large amounts of natural text, our learners\n(implemented as feed-forward neural networks) engage in cooperative referential\ngames starting from a tabula rasa setup, and thus develop their own language\nfrom the need to communicate in order to succeed at the game. Preliminary\nexperiments provide promising results, but also suggest that it is important to\nensure that agents trained in this way do not develop an adhoc communication\ncode only effective for the game they are playing\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 18:46:46 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Pham", "Nghia The", ""], ["Baroni", "Marco", ""]]}, {"id": "1605.07139", "submitter": "Matthew Joseph", "authors": "Matthew Joseph and Michael Kearns and Jamie Morgenstern and Aaron Roth", "title": "Fairness in Learning: Classic and Contextual Bandits", "comments": "A condensed version of this work appears in the 30th Annual\n  Conference on Neural Information Processing Systems (NIPS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the study of fairness in multi-armed bandit problems. Our\nfairness definition can be interpreted as demanding that given a pool of\napplicants (say, for college admission or mortgages), a worse applicant is\nnever favored over a better one, despite a learning algorithm's uncertainty\nover the true payoffs. We prove results of two types.\n  First, in the important special case of the classic stochastic bandits\nproblem (i.e., in which there are no contexts), we provide a provably fair\nalgorithm based on \"chained\" confidence intervals, and provide a cumulative\nregret bound with a cubic dependence on the number of arms. We further show\nthat any fair algorithm must have such a dependence. When combined with regret\nbounds for standard non-fair algorithms such as UCB, this proves a strong\nseparation between fair and unfair learning, which extends to the general\ncontextual case.\n  In the general contextual case, we prove a tight connection between fairness\nand the KWIK (Knows What It Knows) learning model: a KWIK algorithm for a class\nof functions can be transformed into a provably fair contextual bandit\nalgorithm, and conversely any fair contextual bandit algorithm can be\ntransformed into a KWIK learning algorithm. This tight connection allows us to\nprovide a provably fair algorithm for the linear contextual bandit problem with\na polynomial dependence on the dimension, and to show (for a different class of\nfunctions) a worst-case exponential gap in regret between fair and non-fair\nlearning algorithms\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 18:58:24 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 15:49:05 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Joseph", "Matthew", ""], ["Kearns", "Michael", ""], ["Morgenstern", "Jamie", ""], ["Roth", "Aaron", ""]]}, {"id": "1605.07144", "submitter": "Sebastian Tschiatschek", "authors": "Adish Singla, Sebastian Tschiatschek, Andreas Krause", "title": "Actively Learning Hemimetrics with Applications to Eliciting User\n  Preferences", "comments": "Extended version of ICML'16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by an application of eliciting users' preferences, we investigate\nthe problem of learning hemimetrics, i.e., pairwise distances among a set of\n$n$ items that satisfy triangle inequalities and non-negativity constraints. In\nour application, the (asymmetric) distances quantify private costs a user\nincurs when substituting one item by another. We aim to learn these distances\n(costs) by asking the users whether they are willing to switch from one item to\nanother for a given incentive offer. Without exploiting structural constraints\nof the hemimetric polytope, learning the distances between each pair of items\nrequires $\\Theta(n^2)$ queries. We propose an active learning algorithm that\nsubstantially reduces this sample complexity by exploiting the structural\nconstraints on the version space of hemimetrics. Our proposed algorithm\nachieves provably-optimal sample complexity for various instances of the task.\nFor example, when the items are embedded into $K$ tight clusters, the sample\ncomplexity of our algorithm reduces to $O(n K)$. Extensive experiments on a\nrestaurant recommendation data set support the conclusions of our theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:21:35 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 17:45:26 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Singla", "Adish", ""], ["Tschiatschek", "Sebastian", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.07145", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Yingbo Zhou, Hung Q. Ngo, Nils Napp, Venu Govindaraju", "title": "On Optimality Conditions for Auto-Encoder Signal Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-Encoders are unsupervised models that aim to learn patterns from\nobserved data by minimizing a reconstruction cost. The useful representations\nlearned are often found to be sparse and distributed. On the other hand,\ncompressed sensing and sparse coding assume a data generating process, where\nthe observed data is generated from some true latent signal source, and try to\nrecover the corresponding signal from measurements. Looking at auto-encoders\nfrom this \\textit{signal recovery perspective} enables us to have a more\ncoherent view of these techniques. In this paper, in particular, we show that\nthe \\textit{true} hidden representation can be approximately recovered if the\nweight matrices are highly incoherent with unit $ \\ell^{2} $ row length and the\nbias vectors takes the value (approximately) equal to the negative of the data\nmean. The recovery also becomes more and more accurate as the sparsity in\nhidden signals increases. Additionally, we empirically demonstrate that\nauto-encoders are capable of recovering the data generating dictionary when\nonly data samples are given.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:21:53 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 16:25:15 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Arpit", "Devansh", ""], ["Zhou", "Yingbo", ""], ["Ngo", "Hung Q.", ""], ["Napp", "Nils", ""], ["Govindaraju", "Venu", ""]]}, {"id": "1605.07146", "submitter": "Sergey Zagoruyko", "authors": "Sergey Zagoruyko, Nikos Komodakis", "title": "Wide Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks were shown to be able to scale up to thousands of\nlayers and still have improving performance. However, each fraction of a\npercent of improved accuracy costs nearly doubling the number of layers, and so\ntraining very deep residual networks has a problem of diminishing feature\nreuse, which makes these networks very slow to train. To tackle these problems,\nin this paper we conduct a detailed experimental study on the architecture of\nResNet blocks, based on which we propose a novel architecture where we decrease\ndepth and increase width of residual networks. We call the resulting network\nstructures wide residual networks (WRNs) and show that these are far superior\nover their commonly used thin and very deep counterparts. For example, we\ndemonstrate that even a simple 16-layer-deep wide residual network outperforms\nin accuracy and efficiency all previous deep residual networks, including\nthousand-layer-deep networks, achieving new state-of-the-art results on CIFAR,\nSVHN, COCO, and significant improvements on ImageNet. Our code and models are\navailable at https://github.com/szagoruyko/wide-residual-networks\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:27:13 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 19:59:22 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2017 15:35:14 GMT"}, {"version": "v4", "created": "Wed, 14 Jun 2017 06:06:48 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Zagoruyko", "Sergey", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1605.07147", "submitter": "Hongyi Zhang", "authors": "Hongyi Zhang, Sashank J. Reddi, Suvrit Sra", "title": "Riemannian SVRG: Fast Stochastic Optimization on Riemannian Manifolds", "comments": "This is the final version that appeared in NIPS 2016. Our proof of\n  Lemma 2 was incorrect in the previous arXiv version. (9 pages paper + 6 pages\n  appendix)", "journal-ref": "Advances in Neural Information Processing Systems 29 (NIPS 2016)", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study optimization of finite sums of geodesically smooth functions on\nRiemannian manifolds. Although variance reduction techniques for optimizing\nfinite-sums have witnessed tremendous attention in the recent years, existing\nwork is limited to vector space problems. We introduce Riemannian SVRG (RSVRG),\na new variance reduced Riemannian optimization method. We analyze RSVRG for\nboth geodesically convex and nonconvex (smooth) functions. Our analysis reveals\nthat RSVRG inherits advantages of the usual SVRG method, but with factors\ndepending on curvature of the manifold that influence its convergence. To our\nknowledge, RSVRG is the first provably fast stochastic Riemannian method.\nMoreover, our paper presents the first non-asymptotic complexity analysis\n(novel even for the batch setting) for nonconvex Riemannian optimization. Our\nresults have several implications; for instance, they offer a Riemannian\nperspective on variance reduced PCA, which promises a short, transparent\nconvergence analysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:28:05 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 18:13:53 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Zhang", "Hongyi", ""], ["Reddi", "Sashank J.", ""], ["Sra", "Suvrit", ""]]}, {"id": "1605.07148", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Anurag Ajay, Sergey Levine, Pieter Abbeel", "title": "Backprop KF: Learning Discriminative Deterministic State Estimators", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative state estimators based on probabilistic filters and smoothers are\none of the most popular classes of state estimators for robots and autonomous\nvehicles. However, generative models have limited capacity to handle rich\nsensory observations, such as camera images, since they must model the entire\ndistribution over sensor readings. Discriminative models do not suffer from\nthis limitation, but are typically more complex to train as latent variable\nmodels for state estimation. We present an alternative approach where the\nparameters of the latent state distribution are directly optimized as a\ndeterministic computation graph, resulting in a simple and effective gradient\ndescent algorithm for training discriminative state estimators. We show that\nthis procedure can be used to train state estimators that use complex input,\nsuch as raw camera images, which must be processed using expressive nonlinear\nfunction approximators such as convolutional neural networks. Our model can be\nviewed as a type of recurrent neural network, and the connection to\nprobabilistic filtering allows us to design a network architecture that is\nparticularly well suited for state estimation. We evaluate our approach on\nsynthetic tracking task with raw image inputs and on the visual odometry task\nin the KITTI dataset. The results show significant improvement over both\nstandard generative approaches and regular recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:28:21 GMT"}, {"version": "v2", "created": "Sun, 17 Jul 2016 01:43:34 GMT"}, {"version": "v3", "created": "Sun, 30 Oct 2016 05:15:47 GMT"}, {"version": "v4", "created": "Sun, 1 Oct 2017 00:57:20 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Ajay", "Anurag", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1605.07154", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Yuhuai Wu, Ruslan Salakhutdinov, Nathan Srebro", "title": "Path-Normalized Optimization of Recurrent Neural Networks with ReLU\n  Activations", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameter-space geometry of recurrent neural networks\n(RNNs), and develop an adaptation of path-SGD optimization method, attuned to\nthis geometry, that can learn plain RNNs with ReLU activations. On several\ndatasets that require capturing long-term dependency structure, we show that\npath-SGD can significantly improve trainability of ReLU RNNs compared to RNNs\ntrained with SGD, even with various recently suggested initialization schemes.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:40:50 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Wu", "Yuhuai", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1605.07156", "submitter": "Sasha Targ", "authors": "Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye", "title": "Genetic Architect: Discovering Genomic Structure with Learned Neural\n  Architectures", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each human genome is a 3 billion base pair set of encoding instructions.\nDecoding the genome using deep learning fundamentally differs from most tasks,\nas we do not know the full structure of the data and therefore cannot design\narchitectures to suit it. As such, architectures that fit the structure of\ngenomics should be learned not prescribed. Here, we develop a novel search\nalgorithm, applicable across domains, that discovers an optimal architecture\nwhich simultaneously learns general genomic patterns and identifies the most\nimportant sequence motifs in predicting functional genomic outcomes. The\narchitectures we find using this algorithm succeed at using only RNA expression\ndata to predict gene regulatory structure, learn human-interpretable\nvisualizations of key sequence motifs, and surpass state-of-the-art results on\nbenchmark genomics challenges.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:43:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Deming", "Laura", ""], ["Targ", "Sasha", ""], ["Sauder", "Nate", ""], ["Almeida", "Diogo", ""], ["Ye", "Chun Jimmie", ""]]}, {"id": "1605.07157", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Ian Goodfellow, Sergey Levine", "title": "Unsupervised Learning for Physical Interaction through Video Prediction", "comments": "To appear in NIPS '16; Video results, code, and data available at:\n  http://www.sites.google.com/site/robotprediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge for an agent learning to interact with the world is to\npredict how its actions affect objects in its environment. Many existing\nmethods for learning the dynamics of physical interactions require labeled\nobject information. However, to scale real-world interaction learning to a\nvariety of scenes and objects, acquiring labeled data becomes increasingly\nimpractical. To learn about physical object motion without labels, we develop\nan action-conditioned video prediction model that explicitly models pixel\nmotion, by predicting a distribution over pixel motion from previous frames.\nBecause our model explicitly predicts motion, it is partially invariant to\nobject appearance, enabling it to generalize to previously unseen objects. To\nexplore video prediction for real-world interactive agents, we also introduce a\ndataset of 59,000 robot interactions involving pushing motions, including a\ntest set with novel objects. In this dataset, accurate prediction of videos\nconditioned on the robot's future actions amounts to learning a \"visual\nimagination\" of different futures based on different courses of action. Our\nexperiments show that our proposed method produces more accurate video\npredictions both quantitatively and qualitatively, when compared to prior\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:45:55 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 19:33:23 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 00:29:37 GMT"}, {"version": "v4", "created": "Mon, 17 Oct 2016 20:09:56 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Finn", "Chelsea", ""], ["Goodfellow", "Ian", ""], ["Levine", "Sergey", ""]]}, {"id": "1605.07162", "submitter": "Lijie Chen", "authors": "Lijie Chen, Anupam Gupta, Jian Li", "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints", "comments": "Accepted for presentation at Conference on Learning Theory (COLT)\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the pure exploration problem subject to a matroid constraint\n(Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance,\nwe are given $n$ stochastic arms with unknown reward distributions, as well as\na matroid $\\mathcal{M}$ over the arms. Let the weight of an arm be the mean of\nits reward distribution. Our goal is to identify a basis of $\\mathcal{M}$ with\nthe maximum total weight, using as few samples as possible.\n  The problem is a significant generalization of the best arm identification\nproblem and the top-$k$ arm identification problem, which have attracted\nsignificant attentions in recent years. We study both the exact and PAC\nversions of Best-Basis, and provide algorithms with nearly-optimal sample\ncomplexities for these versions. Our results generalize and/or improve on\nseveral previous results for the top-$k$ arm identification problem and the\ncombinatorial pure exploration problem when the combinatorial constraint is a\nmatroid.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:51:42 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 19:20:41 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 16:03:23 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Chen", "Lijie", ""], ["Gupta", "Anupam", ""], ["Li", "Jian", ""]]}, {"id": "1605.07174", "submitter": "Daniel Romero", "authors": "Daniel Romero, Meng Ma, Georgios B. Giannakis", "title": "Kernel-based Reconstruction of Graph Signals", "comments": "Submitted May 2016", "journal-ref": null, "doi": "10.1109/TSP.2016.2620116", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of applications in engineering, social sciences, physics, and\nbiology involve inference over networks. In this context, graph signals are\nwidely encountered as descriptors of vertex attributes or features in\ngraph-structured data. Estimating such signals in all vertices given noisy\nobservations of their values on a subset of vertices has been extensively\nanalyzed in the literature of signal processing on graphs (SPoG). This paper\nadvocates kernel regression as a framework generalizing popular SPoG modeling\nand reconstruction and expanding their capabilities. Formulating signal\nreconstruction as a regression task on reproducing kernel Hilbert spaces of\ngraph signals permeates benefits from statistical learning, offers fresh\ninsights, and allows for estimators to leverage richer forms of prior\ninformation than existing alternatives. A number of SPoG notions such as\nbandlimitedness, graph filters, and the graph Fourier transform are naturally\naccommodated in the kernel framework. Additionally, this paper capitalizes on\nthe so-called representer theorem to devise simpler versions of existing\nThikhonov regularized estimators, and offers a novel probabilistic\ninterpretation of kernel methods on graphs based on graphical models. Motivated\nby the challenges of selecting the bandwidth parameter in SPoG estimators or\nthe kernel map in kernel-based methods, the present paper further proposes two\nmulti-kernel approaches with complementary strengths. Whereas the first enables\nestimation of the unknown bandwidth of bandlimited signals, the second allows\nfor efficient graph filter selection. Numerical tests with synthetic as well as\nreal data demonstrate the merits of the proposed methods relative to\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:47:18 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Romero", "Daniel", ""], ["Ma", "Meng", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1605.07221", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Behnam Neyshabur, Nathan Srebro", "title": "Global Optimality of Local Search for Low Rank Matrix Recovery", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there are no spurious local minima in the non-convex factorized\nparametrization of low-rank matrix recovery from incoherent linear\nmeasurements. With noisy measurements we show all local minima are very close\nto a global optimum. Together with a curvature bound at saddle points, this\nyields a polynomial time global convergence guarantee for stochastic gradient\ndescent {\\em from random initialization}.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 22:05:42 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 00:54:17 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Neyshabur", "Behnam", ""], ["Srebro", "Nathan", ""]]}, {"id": "1605.07230", "submitter": "Jan Hendrik Witte", "authors": "J. B. Heaton, N. G. Polson, J. H. Witte", "title": "Deep Portfolio Theory", "comments": "17 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a deep portfolio theory. By building on Markowitz's classic\nrisk-return trade-off, we develop a self-contained four-step routine of encode,\ncalibrate, validate and verify to formulate an automated and general portfolio\nselection process. At the heart of our algorithm are deep hierarchical\ncompositions of portfolios constructed in the encoding step. The calibration\nstep then provides multivariate payouts in the form of deep hierarchical\nportfolios that are designed to target a variety of objective functions. The\nvalidate step trades-off the amount of regularization used in the encode and\ncalibrate steps. The verification step uses a cross validation approach to\ntrace out an ex post deep portfolio efficient frontier. We demonstrate all four\nsteps of our portfolio theory numerically.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 22:32:05 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 14:24:42 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Heaton", "J. B.", ""], ["Polson", "N. G.", ""], ["Witte", "J. H.", ""]]}, {"id": "1605.07246", "submitter": "Zheng Xu", "authors": "Zheng Xu, Mario A. T. Figueiredo, Tom Goldstein", "title": "Adaptive ADMM with Spectral Penalty Parameter Selection", "comments": "AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) is a versatile tool\nfor solving a wide range of constrained optimization problems, with\ndifferentiable or non-differentiable objective functions. Unfortunately, its\nperformance is highly sensitive to a penalty parameter, which makes ADMM often\nunreliable and hard to automate for a non-expert user. We tackle this weakness\nof ADMM by proposing a method to adaptively tune the penalty parameters to\nachieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm,\ninspired by the successful Barzilai-Borwein spectral method for gradient\ndescent, yields fast convergence and relative insensitivity to the initial\nstepsize and problem scaling.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 00:48:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 19:21:26 GMT"}, {"version": "v3", "created": "Fri, 9 Sep 2016 19:51:17 GMT"}, {"version": "v4", "created": "Wed, 25 Jan 2017 18:49:04 GMT"}, {"version": "v5", "created": "Wed, 19 Jul 2017 16:23:11 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Xu", "Zheng", ""], ["Figueiredo", "Mario A. T.", ""], ["Goldstein", "Tom", ""]]}, {"id": "1605.07252", "submitter": "Marc Vuffray", "authors": "Marc Vuffray, Sidhant Misra, Andrey Y. Lokhov and Michael Chertkov", "title": "Interaction Screening: Efficient and Sample-Optimal Learning of Ising\n  Models", "comments": "To be published in Advances in Neural Information Processing Systems\n  30", "journal-ref": "Advances in Neural Information Processing Systems, 2595--2603,\n  2016", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the underlying graph of an unknown Ising\nmodel on p spins from a collection of i.i.d. samples generated from the model.\nWe suggest a new estimator that is computationally efficient and requires a\nnumber of samples that is near-optimal with respect to previously established\ninformation-theoretic lower-bound. Our statistical estimator has a physical\ninterpretation in terms of \"interaction screening\". The estimator is consistent\nand is efficiently implemented using convex optimization. We prove that with\nappropriate regularization, the estimator recovers the underlying graph using a\nnumber of samples that is logarithmic in the system size p and exponential in\nthe maximum coupling-intensity and maximum node-degree.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 01:36:48 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 03:00:29 GMT"}, {"version": "v3", "created": "Mon, 19 Dec 2016 13:32:25 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Vuffray", "Marc", ""], ["Misra", "Sidhant", ""], ["Lokhov", "Andrey Y.", ""], ["Chertkov", "Michael", ""]]}, {"id": "1605.07262", "submitter": "Osbert Bastani", "authors": "Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios\n  Vytiniotis, Aditya Nori, Antonio Criminisi", "title": "Measuring Neural Net Robustness with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite having high accuracy, neural nets have been shown to be susceptible\nto adversarial examples, where a small perturbation to an input can cause it to\nbecome mislabeled. We propose metrics for measuring the robustness of a neural\nnet and devise a novel algorithm for approximating these metrics based on an\nencoding of robustness as a linear program. We show how our metrics can be used\nto evaluate the robustness of deep neural nets with experiments on the MNIST\nand CIFAR-10 datasets. Our algorithm generates more informative estimates of\nrobustness metrics compared to estimates based on existing algorithms.\nFurthermore, we show how existing approaches to improving robustness \"overfit\"\nto adversarial examples generated using a specific algorithm. Finally, we show\nthat our techniques can be used to additionally improve neural net robustness\nboth according to the metrics that we propose, but also according to previously\nproposed metrics.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 02:18:21 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 11:58:51 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bastani", "Osbert", ""], ["Ioannou", "Yani", ""], ["Lampropoulos", "Leonidas", ""], ["Vytiniotis", "Dimitrios", ""], ["Nori", "Aditya", ""], ["Criminisi", "Antonio", ""]]}, {"id": "1605.07272", "submitter": "Tengyu Ma", "authors": "Rong Ge, Jason D. Lee, Tengyu Ma", "title": "Matrix Completion has No Spurious Local Minimum", "comments": "NIPS'16 best student paper. fixed Theorem 2.3 in preliminary section\n  in the previous version. The results are not affected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is a basic machine learning problem that has wide\napplications, especially in collaborative filtering and recommender systems.\nSimple non-convex optimization algorithms are popular and effective in\npractice. Despite recent progress in proving various non-convex algorithms\nconverge from a good initial point, it remains unclear why random or arbitrary\ninitialization suffices in practice. We prove that the commonly used non-convex\nobjective function for \\textit{positive semidefinite} matrix completion has no\nspurious local minima --- all local minima must also be global. Therefore, many\npopular optimization algorithms such as (stochastic) gradient descent can\nprovably solve positive semidefinite matrix completion with \\textit{arbitrary}\ninitialization in polynomial time. The result can be generalized to the setting\nwhen the observed entries contain noise. We believe that our main proof\nstrategy can be useful for understanding geometric properties of other\nstatistical problems involving partial or noisy observations.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 02:53:27 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2016 19:58:48 GMT"}, {"version": "v3", "created": "Sun, 29 Jan 2017 18:45:48 GMT"}, {"version": "v4", "created": "Sun, 22 Jul 2018 05:20:12 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ge", "Rong", ""], ["Lee", "Jason D.", ""], ["Ma", "Tengyu", ""]]}, {"id": "1605.07277", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Ian Goodfellow", "title": "Transferability in Machine Learning: from Phenomena to Black-Box Attacks\n  using Adversarial Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models are vulnerable to adversarial examples: inputs\nthat are specially crafted to cause a machine learning model to produce an\nincorrect output. Adversarial examples that affect one model often affect\nanother model, even if the two models have different architectures or were\ntrained on different training sets, so long as both models were trained to\nperform the same task. An attacker may therefore train their own substitute\nmodel, craft adversarial examples against the substitute, and transfer them to\na victim model, with very little information about the victim. Recent work has\nfurther developed a technique that uses the victim model as an oracle to label\na synthetic training set for the substitute, so the attacker need not even\ncollect a training set to mount the attack. We extend these recent techniques\nusing reservoir sampling to greatly enhance the efficiency of the training\nprocedure for the substitute model. We introduce new transferability attacks\nbetween previously unexplored (substitute, victim) pairs of machine learning\nmodel classes, most notably SVMs and decision trees. We demonstrate our attacks\non two commercial machine learning classification systems from Amazon (96.19%\nmisclassification rate) and Google (88.94%) using only 800 queries of the\nvictim model, thereby showing that existing machine learning approaches are in\ngeneral vulnerable to systematic black-box attacks regardless of their\nstructure.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 03:27:48 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1605.07334", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, S. Hamed Hassani, Andreas Krause", "title": "Near-optimal Bayesian Active Learning with Correlated and Noisy Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Bayesian active learning and experimental design problem,\nwhere the goal is to learn the value of some unknown target variable through a\nsequence of informative, noisy tests. In contrast to prior work, we focus on\nthe challenging, yet practically relevant setting where test outcomes can be\nconditionally dependent given the hidden target variable. Under such\nassumptions, common heuristics, such as greedily performing tests that maximize\nthe reduction in uncertainty of the target, often perform poorly. In this\npaper, we propose ECED, a novel, computationally efficient active learning\nalgorithm, and prove strong theoretical guarantees that hold with correlated,\nnoisy tests. Rather than directly optimizing the prediction error, at each\nstep, ECED picks the test that maximizes the gain in a surrogate objective,\nwhich takes into account the dependencies between tests. Our analysis relies on\nan information-theoretic auxiliary function to track the progress of ECED, and\nutilizes adaptive submodularity to attain the near-optimal bound. We\ndemonstrate strong empirical performance of ECED on two problem instances,\nincluding a Bayesian experimental design task intended to distinguish among\neconomic theories of how people make risky decisions, and an active preference\nlearning task via pairwise comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 08:25:27 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 06:47:19 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Chen", "Yuxin", ""], ["Hassani", "S. Hamed", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.07367", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai, Hiroyuki Sato, and Bamdev Mishra", "title": "Riemannian stochastic variance reduced gradient on Grassmann manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance reduction algorithms have recently become popular for\nminimizing the average of a large, but finite, number of loss functions. In\nthis paper, we propose a novel Riemannian extension of the Euclidean stochastic\nvariance reduced gradient algorithm (R-SVRG) to a compact manifold search\nspace. To this end, we show the developments on the Grassmann manifold. The key\nchallenges of averaging, addition, and subtraction of multiple gradients are\naddressed with notions like logarithm mapping and parallel translation of\nvectors on the Grassmann manifold. We present a global convergence analysis of\nthe proposed algorithm with decay step-sizes and a local convergence rate\nanalysis under fixed step-size with some natural assumptions. The proposed\nalgorithm is applied on a number of problems on the Grassmann manifold like\nprincipal components analysis, low-rank matrix completion, and the Karcher mean\ncomputation. In all these cases, the proposed algorithm outperforms the\nstandard Riemannian stochastic gradient descent algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 10:36:32 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 12:55:11 GMT"}, {"version": "v3", "created": "Sun, 9 Apr 2017 06:17:52 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Sato", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1605.07416", "submitter": "Sebastien Gerchinovitz", "authors": "S\\'ebastien Gerchinovitz (IMT, AOC), Tor Lattimore", "title": "Refined Lower Bounds for Adversarial Bandits", "comments": null, "journal-ref": "D. D. Lee; M. Sugiyama; U. V. Luxburg; I. Guyon; R. Garnett. NIPS\n  2016, Dec 2016, Barcelona, Spain. Curran Associates, Inc., pp.1198--1206,\n  Advances in Neural Information Processing Systems 29", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide new lower bounds on the regret that must be suffered by\nadversarial bandit algorithms. The new results show that recent upper bounds\nthat either (a) hold with high-probability or (b) depend on the total lossof\nthe best arm or (c) depend on the quadratic variation of the losses, are close\nto tight. Besides this we prove two impossibility results. First, the existence\nof a single arm that is optimal in every round cannot improve the regret in the\nworst case. Second, the regret cannot scale with the effective range of the\nlosses. In contrast, both results are possible in the full-information setting.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 12:36:47 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 13:48:10 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Gerchinovitz", "S\u00e9bastien", "", "IMT, AOC"], ["Lattimore", "Tor", ""]]}, {"id": "1605.07422", "submitter": "Rolf Jagerman", "authors": "Rolf Jagerman, Carsten Eickhoff and Maarten de Rijke", "title": "Computing Web-scale Topic Models using an Asynchronous Parameter Server", "comments": "To appear in SIGIR 2017", "journal-ref": null, "doi": "10.1145/3077136.3084135", "report-no": null, "categories": "cs.DC cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models such as Latent Dirichlet Allocation (LDA) have been widely used\nin information retrieval for tasks ranging from smoothing and feedback methods\nto tools for exploratory search and discovery. However, classical methods for\ninferring topic models do not scale up to the massive size of today's publicly\navailable Web-scale data sets. The state-of-the-art approaches rely on custom\nstrategies, implementations and hardware to facilitate their asynchronous,\ncommunication-intensive workloads.\n  We present APS-LDA, which integrates state-of-the-art topic modeling with\ncluster computing frameworks such as Spark using a novel asynchronous parameter\nserver. Advantages of this integration include convenient usage of existing\ndata processing pipelines and eliminating the need for disk writes as data can\nbe kept in memory from start to finish. Our goal is not to outperform highly\ncustomized implementations, but to propose a general high-performance topic\nmodeling framework that can easily be used in today's data processing\npipelines. We compare APS-LDA to the existing Spark LDA implementations and\nshow that our system can, on a 480-core cluster, process up to 135 times more\ndata and 10 times more topics without sacrificing model quality.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 12:40:29 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 08:43:56 GMT"}, {"version": "v3", "created": "Sun, 18 Jun 2017 22:37:23 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Jagerman", "Rolf", ""], ["Eickhoff", "Carsten", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1605.07427", "submitter": "Sarath Chandar", "authors": "Sarath Chandar, Sungjin Ahn, Hugo Larochelle, Pascal Vincent, Gerald\n  Tesauro, Yoshua Bengio", "title": "Hierarchical Memory Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory networks are neural networks with an explicit memory component that\ncan be both read and written to by the network. The memory is often addressed\nin a soft way using a softmax function, making end-to-end training with\nbackpropagation possible. However, this is not computationally scalable for\napplications which require the network to read from extremely large memories.\nOn the other hand, it is well known that hard attention mechanisms based on\nreinforcement learning are challenging to train successfully. In this paper, we\nexplore a form of hierarchical memory network, which can be considered as a\nhybrid between hard and soft attention memory networks. The memory is organized\nin a hierarchical structure such that reading from it is done with less\ncomputation than soft attention over a flat memory, while also being easier to\ntrain than hard attention over a flat memory. Specifically, we propose to\nincorporate Maximum Inner Product Search (MIPS) in the training and inference\nprocedures for our hierarchical memory network. We explore the use of various\nstate-of-the art approximate MIPS techniques and report results on\nSimpleQuestions, a challenging large scale factoid question answering task.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 12:48:19 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Chandar", "Sarath", ""], ["Ahn", "Sungjin", ""], ["Larochelle", "Hugo", ""], ["Vincent", "Pascal", ""], ["Tesauro", "Gerald", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1605.07496", "submitter": "Supratik Paul", "authors": "Supratik Paul, Konstantinos Chatzilygeroudis, Kamil Ciosek,\n  Jean-Baptiste Mouret, Michael A. Osborne, Shimon Whiteson", "title": "Alternating Optimisation and Quadrature for Robust Control", "comments": "To appear in AAAI 2018. Video of policy learnt in simulation deployed\n  on a real hexapod see https://youtu.be/ME90xtIPsKk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation has been successfully applied to a variety of\nreinforcement learning problems. However, the traditional approach for learning\noptimal policies in simulators does not utilise the opportunity to improve\nlearning by adjusting certain environment variables: state features that are\nunobservable and randomly determined by the environment in a physical setting\nbut are controllable in a simulator. This paper considers the problem of\nfinding a robust policy while taking into account the impact of environment\nvariables. We present Alternating Optimisation and Quadrature (ALOQ), which\nuses Bayesian optimisation and Bayesian quadrature to address such settings.\nALOQ is robust to the presence of significant rare events, which may not be\nobservable under random sampling, but play a substantial role in determining\nthe optimal policy. Experimental results across different domains show that\nALOQ can learn more efficiently and robustly than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 15:15:57 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 12:39:46 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 10:12:32 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Paul", "Supratik", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Ciosek", "Kamil", ""], ["Mouret", "Jean-Baptiste", ""], ["Osborne", "Michael A.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1605.07498", "submitter": "Valentina Gregori", "authors": "Valentina Gregori", "title": "Leveraging Over Priors for Boosting Control of Prosthetic Hands", "comments": "100 pages, 100 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Electromyography (EMG) signal is the electrical activity produced by\ncells of skeletal muscles in order to provide a movement. The non-invasive\nprosthetic hand works with several electrodes, placed on the stump of an\namputee, that record this signal. In order to favour the control of prosthesis,\nthe EMG signal is analyzed with algorithms based on machine learning theory to\ndecide the movement that the subject is going to do. In order to obtain a\nsignificant control of the prosthesis and avoid mismatch between desired and\nperformed movements, a long training period is needed when we use the\ntraditional algorithm of machine learning (i.e. Support Vector Machines). An\nactual challenge in this field concerns the reduction of the time necessary for\nan amputee to learn how to use the prosthesis. Recently, several algorithms\nthat exploit a form of prior knowledge have been proposed. In general, we refer\nto prior knowledge as a past experience available in the form of models. In our\ncase an amputee, that attempts to perform some movements with the prosthesis,\ncould use experience from different subjects that are already able to perform\nthose movements. The aim of this work is to verify, with a computational\ninvestigation, if for an amputee this kind of previous experience is useful in\norder to reduce the training time and boost the prosthetic control.\nFurthermore, we want to understand if and how the final results change when the\nprevious knowledge of intact or amputated subjects is used for a new amputee.\nOur experiments indicate that: (1) the use of experience, from other subjects\nalready trained to perform a task, makes us able to reduce the training time of\nabout an order of magnitude; (2) it seems that an amputee that tries to learn\nto use the prosthesis doesn't reach different results when he/she exploits\nprevious experience of amputees or intact.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 15:25:14 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Gregori", "Valentina", ""]]}, {"id": "1605.07541", "submitter": "Peter Wittek", "authors": "Alex Monr\\`as, Gael Sent\\'is, Peter Wittek", "title": "Inductive supervised quantum learning", "comments": "6+10 pages", "journal-ref": "Phys. Rev. Lett. 118, 190503 (2017)", "doi": "10.1103/PhysRevLett.118.190503", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning, an inductive learning algorithm extracts general\nrules from observed training instances, then the rules are applied to test\ninstances. We show that this splitting of training and application arises\nnaturally, in the classical setting, from a simple independence requirement\nwith a physical interpretation of being non-signalling. Thus, two seemingly\ndifferent definitions of inductive learning happen to coincide. This follows\nfrom the properties of classical information that break down in the quantum\nsetup. We prove a quantum de Finetti theorem for quantum channels, which shows\nthat in the quantum case, the equivalence holds in the asymptotic setting, that\nis, for large number of test instances. This reveals a natural analogy between\nclassical learning protocols and their quantum counterparts, justifying a\nsimilar treatment, and allowing to inquire about standard elements in\ncomputational learning theory, such as structural risk minimization and sample\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 16:56:46 GMT"}, {"version": "v2", "created": "Sat, 13 May 2017 10:48:23 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Monr\u00e0s", "Alex", ""], ["Sent\u00eds", "Gael", ""], ["Wittek", "Peter", ""]]}, {"id": "1605.07571", "submitter": "Marco Fraccaro", "authors": "Marco Fraccaro, S{\\o}ren Kaae S{\\o}nderby, Ulrich Paquet, Ole Winther", "title": "Sequential Neural Models with Stochastic Layers", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we efficiently propagate uncertainty in a latent state representation\nwith recurrent neural networks? This paper introduces stochastic recurrent\nneural networks which glue a deterministic recurrent neural network and a state\nspace model together to form a stochastic and sequential neural generative\nmodel. The clear separation of deterministic and stochastic layers allows a\nstructured variational inference network to track the factorization of the\nmodel's posterior distribution. By retaining both the nonlinear recursive\nstructure of a recurrent neural network and averaging over the uncertainty in a\nlatent path, like a state space model, we improve the state of the art results\non the Blizzard and TIMIT speech modeling data sets by a large margin, while\nachieving comparable performances to competing methods on polyphonic music\nmodeling.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 18:23:58 GMT"}, {"version": "v2", "created": "Sun, 13 Nov 2016 18:04:41 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Fraccaro", "Marco", ""], ["S\u00f8nderby", "S\u00f8ren Kaae", ""], ["Paquet", "Ulrich", ""], ["Winther", "Ole", ""]]}, {"id": "1605.07583", "submitter": "Cameron Musco", "authors": "Cameron Musco and Christopher Musco", "title": "Recursive Sampling for the Nystr\\\"om Method", "comments": "To appear, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the first algorithm for kernel Nystr\\\"om approximation that runs in\n*linear time in the number of training points* and is provably accurate for all\nkernel matrices, without dependence on regularity or incoherence conditions.\nThe algorithm projects the kernel onto a set of $s$ landmark points sampled by\ntheir *ridge leverage scores*, requiring just $O(ns)$ kernel evaluations and\n$O(ns^2)$ additional runtime. While leverage score sampling has long been known\nto give strong theoretical guarantees for Nystr\\\"om approximation, by employing\na fast recursive sampling scheme, our algorithm is the first to make the\napproach scalable. Empirically we show that it finds more accurate, lower rank\nkernel approximations in less time than popular techniques such as uniformly\nsampled Nystr\\\"om approximation and the random Fourier features method.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 18:56:57 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 19:48:44 GMT"}, {"version": "v3", "created": "Tue, 28 Feb 2017 16:37:17 GMT"}, {"version": "v4", "created": "Thu, 16 Mar 2017 17:58:14 GMT"}, {"version": "v5", "created": "Fri, 3 Nov 2017 14:40:15 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""]]}, {"id": "1605.07588", "submitter": "Carlo Ciliberto", "authors": "Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco", "title": "A Consistent Regularization Approach for Structured Prediction", "comments": "39 pages, 2 Tables, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a regularization approach for structured prediction\nproblems. We characterize a large class of loss functions that allows to\nnaturally embed structured outputs in a linear space. We exploit this fact to\ndesign learning algorithms using a surrogate loss approach and regularization\ntechniques. We prove universal consistency and finite sample bounds\ncharacterizing the generalization properties of the proposed methods.\nExperimental results are provided to demonstrate the practical usefulness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 19:06:43 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 15:55:37 GMT"}, {"version": "v3", "created": "Fri, 28 Jul 2017 09:36:05 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Rudi", "Alessandro", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1605.07659", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Alejandro Ribeiro", "title": "Adaptive Newton Method for Empirical Risk Minimization to Statistical\n  Accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider empirical risk minimization for large-scale datasets. We\nintroduce Ada Newton as an adaptive algorithm that uses Newton's method with\nadaptive sample sizes. The main idea of Ada Newton is to increase the size of\nthe training set by a factor larger than one in a way that the minimization\nvariable for the current training set is in the local neighborhood of the\noptimal argument of the next training set. This allows to exploit the quadratic\nconvergence property of Newton's method and reach the statistical accuracy of\neach training set with only one iteration of Newton's method. We show\ntheoretically and empirically that Ada Newton can double the size of the\ntraining set in each iteration to achieve the statistical accuracy of the full\ntraining set with about two passes over the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 21:02:50 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1605.07669", "submitter": "Pei-Hao Su", "authors": "Pei-Hao Su and Milica Gasic and Nikola Mrksic and Lina Rojas-Barahona\n  and Stefan Ultes and David Vandyke and Tsung-Hsien Wen and Steve Young", "title": "On-line Active Reward Learning for Policy Optimisation in Spoken\n  Dialogue Systems", "comments": "Accepted as a long paper in ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compute an accurate reward function is essential for\noptimising a dialogue policy via reinforcement learning. In real-world\napplications, using explicit user feedback as the reward signal is often\nunreliable and costly to collect. This problem can be mitigated if the user's\nintent is known in advance or data is available to pre-train a task success\npredictor off-line. In practice neither of these apply for most real world\napplications. Here we propose an on-line learning framework whereby the\ndialogue policy is jointly trained alongside the reward model via active\nlearning with a Gaussian process model. This Gaussian process operates on a\ncontinuous space dialogue representation generated in an unsupervised fashion\nusing a recurrent neural network encoder-decoder. The experimental results\ndemonstrate that the proposed framework is able to significantly reduce data\nannotation costs and mitigate noisy user feedback in dialogue policy learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 21:56:08 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 14:01:07 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Su", "Pei-Hao", ""], ["Gasic", "Milica", ""], ["Mrksic", "Nikola", ""], ["Rojas-Barahona", "Lina", ""], ["Ultes", "Stefan", ""], ["Vandyke", "David", ""], ["Wen", "Tsung-Hsien", ""], ["Young", "Steve", ""]]}, {"id": "1605.07689", "submitter": "Jason Lee", "authors": "Michael I. Jordan, Jason D. Lee, Yun Yang", "title": "Communication-Efficient Distributed Statistical Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Communication-efficient Surrogate Likelihood (CSL) framework for\nsolving distributed statistical inference problems. CSL provides a\ncommunication-efficient surrogate to the global likelihood that can be used for\nlow-dimensional estimation, high-dimensional regularized estimation and\nBayesian inference. For low-dimensional estimation, CSL provably improves upon\nnaive averaging schemes and facilitates the construction of confidence\nintervals. For high-dimensional regularized estimation, CSL leads to a\nminimax-optimal estimator with controlled communication cost. For Bayesian\ninference, CSL can be used to form a communication-efficient quasi-posterior\ndistribution that converges to the true posterior. This quasi-posterior\nprocedure significantly improves the computational efficiency of MCMC\nalgorithms even in a non-distributed setting. We present both theoretical\nanalysis and experiments to explore the properties of the CSL approximation.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 00:12:06 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 05:31:41 GMT"}, {"version": "v3", "created": "Sun, 6 Nov 2016 00:37:39 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Jordan", "Michael I.", ""], ["Lee", "Jason D.", ""], ["Yang", "Yun", ""]]}, {"id": "1605.07700", "submitter": "Marlos C. Machado", "authors": "Marlos C. Machado and Michael Bowling", "title": "Learning Purposeful Behaviour in the Absence of Rewards", "comments": "Extended version of the paper presented at the workshop entitled\n  Abstraction in Reinforcement Learning, at the 33rd International Conference\n  on Machine Learning, New York, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence is commonly defined as the ability to achieve goals\nin the world. In the reinforcement learning framework, goals are encoded as\nreward functions that guide agent behaviour, and the sum of observed rewards\nprovide a notion of progress. However, some domains have no such reward signal,\nor have a reward signal so sparse as to appear absent. Without reward feedback,\nagent behaviour is typically random, often dithering aimlessly and lacking\nintentionality. In this paper we present an algorithm capable of learning\npurposeful behaviour in the absence of rewards. The algorithm proceeds by\nconstructing temporally extended actions (options), through the identification\nof purposes that are \"just out of reach\" of the agent's current behaviour.\nThese purposes establish intrinsic goals for the agent to learn, ultimately\nresulting in a suite of behaviours that encourage the agent to visit different\nparts of the state space. Moreover, the approach is particularly suited for\nsettings where rewards are very sparse, and such behaviours can help in the\nexploration of the environment until reward is observed.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 01:33:34 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Machado", "Marlos C.", ""], ["Bowling", "Michael", ""]]}, {"id": "1605.07717", "submitter": "Shuangfei Zhai", "authors": "Shuangfei Zhai, Yu Cheng, Weining Lu, Zhongfei Zhang", "title": "Deep Structured Energy Based Models for Anomaly Detection", "comments": "To appear in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we attack the anomaly detection problem by directly modeling\nthe data distribution with deep architectures. We propose deep structured\nenergy based models (DSEBMs), where the energy function is the output of a\ndeterministic deep neural network with structure. We develop novel model\narchitectures to integrate EBMs with different types of data such as static\ndata, sequential data, and spatial data, and apply appropriate model\narchitectures to adapt to the data structure. Our training algorithm is built\nupon the recent development of score matching \\cite{sm}, which connects an EBM\nwith a regularized autoencoder, eliminating the need for complicated sampling\nmethod. Statistically sound decision criterion can be derived for anomaly\ndetection purpose from the perspective of the energy landscape of the data\ndistribution. We investigate two decision criteria for performing anomaly\ndetection: the energy score and the reconstruction error. Extensive empirical\nstudies on benchmark tasks demonstrate that our proposed model consistently\nmatches or outperforms all the competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 03:40:18 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 02:36:10 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Zhai", "Shuangfei", ""], ["Cheng", "Yu", ""], ["Lu", "Weining", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1605.07719", "submitter": "Huishuai Zhang", "authors": "Huishuai Zhang, Yi Zhou, Yingbin Liang, Yuejie Chi", "title": "Reshaped Wirtinger Flow and Incremental Algorithm for Solving Quadratic\n  System of Equations", "comments": "Part of this draft is accepted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the phase retrieval problem, which solves quadratic system of\nequations, i.e., recovers a vector $\\boldsymbol{x}\\in \\mathbb{R}^n$ from its\nmagnitude measurements $y_i=|\\langle \\boldsymbol{a}_i, \\boldsymbol{x}\\rangle|,\ni=1,..., m$. We develop a gradient-like algorithm (referred to as RWF\nrepresenting reshaped Wirtinger flow) by minimizing a nonconvex nonsmooth loss\nfunction. In comparison with existing nonconvex Wirtinger flow (WF) algorithm\n\\cite{candes2015phase}, although the loss function becomes nonsmooth, it\ninvolves only the second power of variable and hence reduces the complexity. We\nshow that for random Gaussian measurements, RWF enjoys geometric convergence to\na global optimal point as long as the number $m$ of measurements is on the\norder of $n$, the dimension of the unknown $\\boldsymbol{x}$. This improves the\nsample complexity of WF, and achieves the same sample complexity as truncated\nWirtinger flow (TWF) \\cite{chen2015solving}, but without truncation in gradient\nloop. Furthermore, RWF costs less computationally than WF, and runs faster\nnumerically than both WF and TWF. We further develop the incremental\n(stochastic) reshaped Wirtinger flow (IRWF) and show that IRWF converges\nlinearly to the true signal. We further establish performance guarantee of an\nexisting Kaczmarz method for the phase retrieval problem based on its\nconnection to IRWF. We also empirically demonstrate that IRWF outperforms\nexisting ITWF algorithm (stochastic version of TWF) as well as other batch\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 03:45:44 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 01:44:00 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Zhang", "Huishuai", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""], ["Chi", "Yuejie", ""]]}, {"id": "1605.07723", "submitter": "Alexander Ratner", "authors": "Alexander Ratner, Christopher De Sa, Sen Wu, Daniel Selsam,\n  Christopher R\\'e", "title": "Data Programming: Creating Large Training Sets, Quickly", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 29, 2016,\n  3567--3575", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large labeled training sets are the critical building blocks of supervised\nlearning methods and are key enablers of deep learning techniques. For some\napplications, creating labeled training sets is the most time-consuming and\nexpensive part of applying machine learning. We therefore propose a paradigm\nfor the programmatic creation of training sets called data programming in which\nusers express weak supervision strategies or domain heuristics as labeling\nfunctions, which are programs that label subsets of the data, but that are\nnoisy and may conflict. We show that by explicitly representing this training\nset labeling process as a generative model, we can \"denoise\" the generated\ntraining set, and establish theoretically that we can recover the parameters of\nthese generative models in a handful of settings. We then show how to modify a\ndiscriminative loss function to make it noise-aware, and demonstrate our method\nover a range of discriminative models including logistic regression and LSTMs.\nExperimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data\nprogramming would have led to a new winning score, and also show that applying\ndata programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points\nover a state-of-the-art LSTM baseline (and into second place in the\ncompetition). Additionally, in initial user studies we observed that data\nprogramming may be an easier way for non-experts to create machine learning\nmodels when training data is limited or unavailable.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 04:14:59 GMT"}, {"version": "v2", "created": "Sat, 3 Dec 2016 20:03:26 GMT"}, {"version": "v3", "created": "Sun, 8 Jan 2017 19:48:53 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Ratner", "Alexander", ""], ["De Sa", "Christopher", ""], ["Wu", "Sen", ""], ["Selsam", "Daniel", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1605.07725", "submitter": "Takeru Miyato", "authors": "Takeru Miyato, Andrew M. Dai, Ian Goodfellow", "title": "Adversarial Training Methods for Semi-Supervised Text Classification", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training provides a means of regularizing supervised learning\nalgorithms while virtual adversarial training is able to extend supervised\nlearning algorithms to the semi-supervised setting. However, both methods\nrequire making small perturbations to numerous entries of the input vector,\nwhich is inappropriate for sparse high-dimensional inputs such as one-hot word\nrepresentations. We extend adversarial and virtual adversarial training to the\ntext domain by applying perturbations to the word embeddings in a recurrent\nneural network rather than to the original input itself. The proposed method\nachieves state of the art results on multiple benchmark semi-supervised and\npurely supervised tasks. We provide visualizations and analysis showing that\nthe learned word embeddings have improved in quality and that while training,\nthe model is less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 04:25:45 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 15:59:37 GMT"}, {"version": "v3", "created": "Sat, 6 May 2017 20:16:03 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Miyato", "Takeru", ""], ["Dai", "Andrew M.", ""], ["Goodfellow", "Ian", ""]]}, {"id": "1605.07736", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus", "title": "Learning Multiagent Communication with Backpropagation", "comments": "Accepted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in AI require the collaboration of multiple agents. Typically, the\ncommunication protocol between agents is manually specified and not altered\nduring training. In this paper we explore a simple neural model, called\nCommNet, that uses continuous communication for fully cooperative tasks. The\nmodel consists of multiple agents and the communication between them is learned\nalongside their policy. We apply this model to a diverse set of tasks,\ndemonstrating the ability of the agents to learn to communicate amongst\nthemselves, yielding improved performance over non-communicative agents and\nbaselines. In some cases, it is possible to interpret the language devised by\nthe agents, revealing simple but effective strategies for solving the task at\nhand.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 05:33:21 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 17:29:58 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Szlam", "Arthur", ""], ["Fergus", "Rob", ""]]}, {"id": "1605.07747", "submitter": "Davood Hajinezhad", "authors": "Davood Hajinezhad, Mingyi Hong, Tuo Zhao, Zhaoran Wang", "title": "NESTT: A Nonconvex Primal-Dual Splitting Method for Distributed and\n  Stochastic Optimization", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a stochastic and distributed algorithm for nonconvex problems whose\nobjective consists of a sum of $N$ nonconvex $L_i/N$-smooth functions, plus a\nnonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT)\nalgorithm splits the problem into $N$ subproblems, and utilizes an augmented\nLagrangian based primal-dual scheme to solve it in a distributed and stochastic\nmanner. With a special non-uniform sampling, a version of NESTT achieves\n$\\epsilon$-stationary solution using\n$\\mathcal{O}((\\sum_{i=1}^N\\sqrt{L_i/N})^2/\\epsilon)$ gradient evaluations,\nwhich can be up to $\\mathcal{O}(N)$ times better than the (proximal) gradient\ndescent methods. It also achieves Q-linear convergence rate for nonconvex\n$\\ell_1$ penalized quadratic problems with polyhedral constraints. Further, we\nreveal a fundamental connection between primal-dual based methods and a few\nprimal only methods such as IAG/SAG/SAGA.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 06:42:51 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 23:06:57 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Hajinezhad", "Davood", ""], ["Hong", "Mingyi", ""], ["Zhao", "Tuo", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1605.07774", "submitter": "Po-An Chen", "authors": "Po-An Chen, Chi-Jen Lu", "title": "Generalized Mirror Descents in Congestion Games", "comments": "In Artificial Intelligence, Volume 241, Dec 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different types of dynamics have been studied in repeated game play, and one\nof them which has received much attention recently consists of those based on\n\"no-regret\" algorithms from the area of machine learning. It is known that\ndynamics based on generic no-regret algorithms may not converge to Nash\nequilibria in general, but to a larger set of outcomes, namely coarse\ncorrelated equilibria. Moreover, convergence results based on generic no-regret\nalgorithms typically use a weaker notion of convergence: the convergence of the\naverage plays instead of the actual plays. Some work has been done showing that\nwhen using a specific no-regret algorithm, the well-known multiplicative\nupdates algorithm, convergence of actual plays to equilibria can be shown and\nbetter quality of outcomes in terms of the price of anarchy can be reached for\natomic congestion games and load balancing games. Are there more cases of\nnatural no-regret dynamics that perform well in suitable classes of games in\nterms of convergence and quality of outcomes that the dynamics converge to?\n  We answer this question positively in the bulletin-board model by showing\nthat when employing the mirror-descent algorithm, a well-known generic\nno-regret algorithm, the actual plays converge quickly to equilibria in\nnonatomic congestion games. Furthermore, the bandit model considers a probably\nmore realistic and prevalent setting with only partial information, in which at\neach time step each player only knows the cost of her own currently played\nstrategy, but not any costs of unplayed strategies. For the class of atomic\ncongestion games, we propose a family of bandit algorithms based on the\nmirror-descent algorithms previously presented, and show that when each player\nindividually adopts such a bandit algorithm, their joint (mixed) strategy\nprofile quickly converges with implications.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 08:32:48 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 02:51:10 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Chen", "Po-An", ""], ["Lu", "Chi-Jen", ""]]}, {"id": "1605.07779", "submitter": "Taesup Moon", "authors": "Taesup Moon, Seonwoo Min, Byunghan Lee, Sungroh Yoon", "title": "Neural Universal Discrete Denoiser", "comments": "Accepted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new framework of applying deep neural networks (DNN) to devise a\nuniversal discrete denoiser. Unlike other approaches that utilize supervised\nlearning for denoising, we do not require any additional training data. In such\nsetting, while the ground-truth label, i.e., the clean data, is not available,\nwe devise \"pseudo-labels\" and a novel objective function such that DNN can be\ntrained in a same way as supervised learning to become a discrete denoiser. We\nexperimentally show that our resulting algorithm, dubbed as Neural DUDE,\nsignificantly outperforms the previous state-of-the-art in several applications\nwith a systematic rule of choosing the hyperparameter, which is an attractive\nfeature in practice.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 08:50:21 GMT"}, {"version": "v2", "created": "Wed, 24 Aug 2016 01:50:04 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Moon", "Taesup", ""], ["Min", "Seonwoo", ""], ["Lee", "Byunghan", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1605.07784", "submitter": "Xinyang Yi", "authors": "Xinyang Yi, Dohyung Park, Yudong Chen, Constantine Caramanis", "title": "Fast Algorithms for Robust PCA via Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Robust PCA in the fully and partially observed\nsettings. Without corruptions, this is the well-known matrix completion\nproblem. From a statistical standpoint this problem has been recently\nwell-studied, and conditions on when recovery is possible (how many\nobservations do we need, how many corruptions can we tolerate) via\npolynomial-time algorithms is by now understood. This paper presents and\nanalyzes a non-convex optimization approach that greatly reduces the\ncomputational complexity of the above problems, compared to the best available\nalgorithms. In particular, in the fully observed case, with $r$ denoting rank\nand $d$ dimension, we reduce the complexity from\n$\\mathcal{O}(r^2d^2\\log(1/\\varepsilon))$ to\n$\\mathcal{O}(rd^2\\log(1/\\varepsilon))$ -- a big savings when the rank is big.\nFor the partially observed case, we show the complexity of our algorithm is no\nmore than $\\mathcal{O}(r^4d \\log d \\log(1/\\varepsilon))$. Not only is this the\nbest-known run-time for a provable algorithm under partial observation, but in\nthe setting where $r$ is small compared to $d$, it also allows for\nnear-linear-in-$d$ run-time that can be exploited in the fully-observed case as\nwell, by simply running our algorithm on a subset of the observations.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 09:10:07 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 17:28:25 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Yi", "Xinyang", ""], ["Park", "Dohyung", ""], ["Chen", "Yudong", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1605.07785", "submitter": "Inbal Horev", "authors": "Inbal Horev and Florian Yger and Masashi Sugiyama", "title": "Geometry-aware stationary subspace analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world applications data exhibits non-stationarity, i.e., its\ndistribution changes over time. One approach to handling non-stationarity is to\nremove or minimize it before attempting to analyze the data. In the context of\nbrain computer interface (BCI) data analysis this may be done by means of\nstationary subspace analysis (SSA). The classic SSA method finds a matrix that\nprojects the data onto a stationary subspace by optimizing a cost function\nbased on a matrix divergence. In this work we present an alternative method for\nSSA based on a symmetrized version of this matrix divergence. We show that this\nframes the problem in terms of distances between symmetric positive definite\n(SPD) matrices, suggesting a geometric interpretation of the problem. Stemming\nfrom this geometric viewpoint, we introduce and analyze a method which utilizes\nthe geometry of the SPD matrix manifold and the invariance properties of its\nmetrics. Most notably we show that these invariances alleviate the need to\nwhiten the input matrices, a common step in many SSA methods which often\nintroduces errors. We demonstrate the usefulness of our technique in\nexperiments on both synthesized and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 09:11:23 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Horev", "Inbal", ""], ["Yger", "Florian", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1605.07805", "submitter": "Georgios Giantamidis", "authors": "Georgios Giantamidis and Stavros Tripakis", "title": "Learning Moore Machines from Input-Output Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning automata from example traces (but no equivalence or\nmembership queries) is fundamental in automata learning theory and practice. In\nthis paper we study this problem for finite state machines with inputs and\noutputs, and in particular for Moore machines. We develop three algorithms for\nsolving this problem: (1) the PTAP algorithm, which transforms a set of\ninput-output traces into an incomplete Moore machine and then completes the\nmachine with self-loops; (2) the PRPNI algorithm, which uses the well-known\nRPNI algorithm for automata learning to learn a product of automata encoding a\nMoore machine; and (3) the MooreMI algorithm, which directly learns a Moore\nmachine using PTAP extended with state merging. We prove that MooreMI has the\nfundamental identification in the limit property. We also compare the\nalgorithms experimentally in terms of the size of the learned machine and\nseveral notions of accuracy, introduced in this paper. Finally, we compare with\nOSTIA, an algorithm that learns a more general class of transducers, and find\nthat OSTIA generally does not learn a Moore machine, even when fed with a\ncharacteristic sample.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 10:11:03 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 09:27:40 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Giantamidis", "Georgios", ""], ["Tripakis", "Stavros", ""]]}, {"id": "1605.07824", "submitter": "Amir Rosenfeld", "authors": "Amir Rosenfeld, Shimon Ullman", "title": "Action Classification via Concepts and Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classes in natural images tend to follow long tail distributions. This is\nproblematic when there are insufficient training examples for rare classes.\nThis effect is emphasized in compound classes, involving the conjunction of\nseveral concepts, such as those appearing in action-recognition datasets. In\nthis paper, we propose to address this issue by learning how to utilize common\nvisual concepts which are readily available. We detect the presence of\nprominent concepts in images and use them to infer the target labels instead of\nusing visual features directly, combining tools from vision and\nnatural-language processing. We validate our method on the recently introduced\nHICO dataset reaching a mAP of 31.54\\% and on the Stanford-40 Actions dataset,\nwhere the proposed method outperforms that obtained by direct visual features,\nobtaining an accuracy 83.12\\%. Moreover, the method provides for each class a\nsemantically meaningful list of keywords and relevant image regions relating it\nto its constituent concepts.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 11:06:58 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 02:48:27 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Rosenfeld", "Amir", ""], ["Ullman", "Shimon", ""]]}, {"id": "1605.07833", "submitter": "Michele Scarpiniti Dr.", "authors": "Michele Scarpiniti, Simone Scardapane, Danilo Comminiello, Raffaele\n  Parisi, Aurelio Uncini", "title": "Effective Blind Source Separation Based on the Adam Algorithm", "comments": "Revised version after review process. This paper has been presented\n  at the 26-th Italian Workshop on Neural Networks (WIRN2016) May 18-20, Vietri\n  sul Mare, Salerno, Italy. It will be published soon as a chapter in a book of\n  the the Springer Smart Innovation, Systems and Technologies series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a modified InfoMax algorithm for the solution of\nBlind Signal Separation (BSS) problems by using advanced stochastic methods.\nThe proposed approach is based on a novel stochastic optimization approach\nknown as the Adaptive Moment Estimation (Adam) algorithm. The proposed BSS\nsolution can benefit from the excellent properties of the Adam approach. In\norder to derive the new learning rule, the Adam algorithm is introduced in the\nderivation of the cost function maximization in the standard InfoMax algorithm.\nThe natural gradient adaptation is also considered. Finally, some experimental\nresults show the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 11:40:46 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 14:17:27 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Scarpiniti", "Michele", ""], ["Scardapane", "Simone", ""], ["Comminiello", "Danilo", ""], ["Parisi", "Raffaele", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1605.07912", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Ye Yuan, Yuexin Wu, Ruslan Salakhutdinov, William W.\n  Cohen", "title": "Review Networks for Caption Generation", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel extension of the encoder-decoder framework, called a\nreview network. The review network is generic and can enhance any existing\nencoder- decoder model: in this paper, we consider RNN decoders with both CNN\nand RNN encoders. The review network performs a number of review steps with\nattention mechanism on the encoder hidden states, and outputs a thought vector\nafter each review step; the thought vectors are used as the input of the\nattention mechanism in the decoder. We show that conventional encoder-decoders\nare a special case of our framework. Empirically, we show that our framework\nimproves over state-of- the-art encoder-decoder systems on the tasks of image\ncaptioning and source code captioning.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 14:49:58 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 00:47:21 GMT"}, {"version": "v3", "created": "Tue, 7 Jun 2016 01:39:35 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2016 17:50:27 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Yang", "Zhilin", ""], ["Yuan", "Ye", ""], ["Wu", "Yuexin", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "1605.07950", "submitter": "Haoming Jiang", "authors": "Xingguo Li, Haoming Jiang, Jarvis Haupt, Raman Arora, Han Liu, Mingyi\n  Hong, and Tuo Zhao", "title": "On Fast Convergence of Proximal Algorithms for SQRT-Lasso Optimization:\n  Don't Worry About Its Nonsmooth Loss Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning techniques sacrifice convenient computational\nstructures to gain estimation robustness and modeling flexibility. However, by\nexploring the modeling structures, we find these \"sacrifices\" do not always\nrequire more computational efforts. To shed light on such a \"free-lunch\"\nphenomenon, we study the square-root-Lasso (SQRT-Lasso) type regression\nproblem. Specifically, we show that the nonsmooth loss functions of SQRT-Lasso\ntype regression ease tuning effort and gain adaptivity to inhomogeneous noise,\nbut is not necessarily more challenging than Lasso in computation. We can\ndirectly apply proximal algorithms (e.g. proximal gradient descent, proximal\nNewton, and proximal Quasi-Newton algorithms) without worrying the\nnonsmoothness of the loss function. Theoretically, we prove that the proximal\nalgorithms combined with the pathwise optimization scheme enjoy fast\nconvergence guarantees with high probability. Numerical results are provided to\nsupport our theory.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 16:08:08 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 02:10:41 GMT"}, {"version": "v3", "created": "Mon, 2 Jan 2017 18:32:20 GMT"}, {"version": "v4", "created": "Sat, 3 Feb 2018 05:50:46 GMT"}, {"version": "v5", "created": "Wed, 14 Feb 2018 16:06:58 GMT"}, {"version": "v6", "created": "Sun, 14 Apr 2019 01:00:57 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Li", "Xingguo", ""], ["Jiang", "Haoming", ""], ["Haupt", "Jarvis", ""], ["Arora", "Raman", ""], ["Liu", "Han", ""], ["Hong", "Mingyi", ""], ["Zhao", "Tuo", ""]]}, {"id": "1605.07969", "submitter": "Rudy Bunel", "authors": "Rudy Bunel, Alban Desmaison, Pushmeet Kohli, Philip H.S. Torr and M.\n  Pawan Kumar", "title": "Adaptive Neural Compilation", "comments": "Submitted to NIPS 2016, code and supplementary materials will be\n  available on author's page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an adaptive neural-compilation framework to address the\nproblem of efficient program learning. Traditional code optimisation strategies\nused in compilers are based on applying pre-specified set of transformations\nthat make the code faster to execute without changing its semantics. In\ncontrast, our work involves adapting programs to make them more efficient while\nconsidering correctness only on a target input distribution. Our approach is\ninspired by the recent works on differentiable representations of programs. We\nshow that it is possible to compile programs written in a low-level language to\na differentiable representation. We also show how programs in this\nrepresentation can be optimised to make them efficient on a target distribution\nof inputs. Experimental results demonstrate that our approach enables learning\nspecifically-tuned algorithms for given data distributions with a high success\nrate.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 17:17:21 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 15:49:33 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Bunel", "Rudy", ""], ["Desmaison", "Alban", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1605.07991", "submitter": "Jialei Wang", "authors": "Jialei Wang, Mladen Kolar, Nathan Srebro, Tong Zhang", "title": "Efficient Distributed Learning with Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, efficient approach for distributed sparse learning in\nhigh-dimensions, where observations are randomly partitioned across machines.\nComputationally, at each round our method only requires the master machine to\nsolve a shifted ell_1 regularized M-estimation problem, and other workers to\ncompute the gradient. In respect of communication, the proposed approach\nprovably matches the estimation error bound of centralized methods within\nconstant rounds of communications (ignoring logarithmic factors). We conduct\nextensive experiments on both simulated and real world datasets, and\ndemonstrate encouraging performances on high-dimensional regression and\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 18:15:43 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Wang", "Jialei", ""], ["Kolar", "Mladen", ""], ["Srebro", "Nathan", ""], ["Zhang", "Tong", ""]]}, {"id": "1605.07999", "submitter": "Baxter Eaves Jr", "authors": "Baxter S. Eaves Jr and Patrick Shafto", "title": "Toward a general, scaleable framework for Bayesian teaching with\n  applications to topic models", "comments": "7 Pages, 5 Figures, submitted to IJCAI 2016 workshop on Interactive\n  Machine Learning: Connecting Humans and Machines", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines, not humans, are the world's dominant knowledge accumulators but\nhumans remain the dominant decision makers. Interpreting and disseminating the\nknowledge accumulated by machines requires expertise, time, and is prone to\nfailure. The problem of how best to convey accumulated knowledge from computers\nto humans is a critical bottleneck in the broader application of machine\nlearning. We propose an approach based on human teaching where the problem is\nformalized as selecting a small subset of the data that will, with high\nprobability, lead the human user to the correct inference. This approach,\nthough successful for modeling human learning in simple laboratory experiments,\nhas failed to achieve broader relevance due to challenges in formulating\ngeneral and scalable algorithms. We propose general-purpose teaching via\npseudo-marginal sampling and demonstrate the algorithm by teaching topic\nmodels. Simulation results show our sampling-based approach: effectively\napproximates the probability where ground-truth is possible via enumeration,\nresults in data that are markedly different from those expected by random\nsampling, and speeds learning especially for small amounts of data. Application\nto movie synopsis data illustrates differences between teaching and random\nsampling for teaching distributions and specific topics, and demonstrates gains\nin scalability and applicability to real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 18:33:10 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Eaves", "Baxter S.", "Jr"], ["Shafto", "Patrick", ""]]}, {"id": "1605.08003", "submitter": "Blake Woodworth", "authors": "Blake Woodworth and Nathan Srebro", "title": "Tight Complexity Bounds for Optimizing Composite Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide tight upper and lower bounds on the complexity of minimizing the\naverage of $m$ convex functions using gradient and prox oracles of the\ncomponent functions. We show a significant gap between the complexity of\ndeterministic vs randomized optimization. For smooth functions, we show that\naccelerated gradient descent (AGD) and an accelerated variant of SVRG are\noptimal in the deterministic and randomized settings respectively, and that a\ngradient oracle is sufficient for the optimal rate. For non-smooth functions,\nhaving access to prox oracles reduces the complexity and we present optimal\nmethods based on smoothing that improve over methods using just gradient\naccesses.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 18:44:54 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 18:32:55 GMT"}, {"version": "v3", "created": "Thu, 4 Apr 2019 17:14:54 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Woodworth", "Blake", ""], ["Srebro", "Nathan", ""]]}, {"id": "1605.08062", "submitter": "Zhaohan Guo", "authors": "Zhaohan Daniel Guo, Shayan Doroudi, Emma Brunskill", "title": "A PAC RL Algorithm for Episodic POMDPs", "comments": null, "journal-ref": "Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics, pp. 510-518, 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting real world domains involve reinforcement learning (RL) in\npartially observable environments. Efficient learning in such domains is\nimportant, but existing sample complexity bounds for partially observable RL\nare at least exponential in the episode length. We give, to our knowledge, the\nfirst partially observable RL algorithm with a polynomial bound on the number\nof episodes on which the algorithm may not achieve near-optimal performance.\nOur algorithm is suitable for an important class of episodic POMDPs. Our\napproach builds on recent advances in method of moments for latent variable\nmodel estimation.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 20:15:38 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 18:23:04 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Guo", "Zhaohan Daniel", ""], ["Doroudi", "Shayan", ""], ["Brunskill", "Emma", ""]]}, {"id": "1605.08104", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised\n  Learning", "comments": "Code and example video clips can be found here:\n  https://coxlab.github.io/prednet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great strides have been made in using deep learning algorithms to solve\nsupervised learning tasks, the problem of unsupervised learning - leveraging\nunlabeled examples to learn about the structure of a domain - remains a\ndifficult unsolved challenge. Here, we explore prediction of future frames in a\nvideo sequence as an unsupervised learning rule for learning about the\nstructure of the visual world. We describe a predictive neural network\n(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"\nfrom the neuroscience literature. These networks learn to predict future frames\nin a video sequence, with each layer in the network making local predictions\nand only forwarding deviations from those predictions to subsequent network\nlayers. We show that these networks are able to robustly learn to predict the\nmovement of synthetic (rendered) objects, and that in doing so, the networks\nlearn internal representations that are useful for decoding latent object\nparameters (e.g. pose) that support object recognition with fewer training\nviews. We also show that these networks can scale to complex natural image\nstreams (car-mounted camera videos), capturing key aspects of both egocentric\nmovement and the movement of objects in the visual scene, and the\nrepresentation learned in this setting is useful for estimating the steering\nangle. Altogether, these results suggest that prediction represents a powerful\nframework for unsupervised learning, allowing for implicit learning of object\nand scene structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 23:58:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 14:36:09 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 00:08:34 GMT"}, {"version": "v4", "created": "Wed, 31 Aug 2016 16:06:03 GMT"}, {"version": "v5", "created": "Wed, 1 Mar 2017 01:00:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1605.08108", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Farbod Roosta-Khorasani, Stefan Palombo, Peter L.\n  Bartlett and Michael W. Mahoney", "title": "FLAG n' FLARE: Fast Linearly-Coupled Adaptive Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider first order gradient methods for effectively optimizing a\ncomposite objective in the form of a sum of smooth and, potentially, non-smooth\nfunctions. We present accelerated and adaptive gradient methods, called FLAG\nand FLARE, which can offer the best of both worlds. They can achieve the\noptimal convergence rate by attaining the optimal first-order oracle complexity\nfor smooth convex optimization. Additionally, they can adaptively and\nnon-uniformly re-scale the gradient direction to adapt to the limited curvature\navailable and conform to the geometry of the domain. We show theoretically and\nempirically that, through the compounding effects of acceleration and\nadaptivity, FLAG and FLARE can be highly effective for many data fitting and\nmachine learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 00:24:37 GMT"}, {"version": "v2", "created": "Sat, 11 Nov 2017 20:20:17 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Cheng", "Xiang", ""], ["Roosta-Khorasani", "Farbod", ""], ["Palombo", "Stefan", ""], ["Bartlett", "Peter L.", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1605.08110", "submitter": "Ke Zhang", "authors": "Ke Zhang, Wei-Lun Chao, Fei Sha, Kristen Grauman", "title": "Video Summarization with Long Short-term Memory", "comments": "To appear in ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel supervised learning technique for summarizing videos by\nautomatically selecting keyframes or key subshots. Casting the problem as a\nstructured prediction problem on sequential data, our main idea is to use Long\nShort-Term Memory (LSTM), a special type of recurrent neural networks to model\nthe variable-range dependencies entailed in the task of video summarization.\nOur learning models attain the state-of-the-art results on two benchmark video\ndatasets. Detailed analysis justifies the design of the models. In particular,\nwe show that it is crucial to take into consideration the sequential structures\nin videos and model them. Besides advances in modeling techniques, we introduce\ntechniques to address the need of a large number of annotated data for training\ncomplex learning models. There, our main idea is to exploit the existence of\nauxiliary annotated video datasets, albeit heterogeneous in visual styles and\ncontents. Specifically, we show domain adaptation techniques can improve\nsummarization by reducing the discrepancies in statistical properties across\nthose datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 00:46:35 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 07:05:34 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Zhang", "Ke", ""], ["Chao", "Wei-Lun", ""], ["Sha", "Fei", ""], ["Grauman", "Kristen", ""]]}, {"id": "1605.08165", "submitter": "Francis Bach", "authors": "Francis Bach (SIERRA, LIENS), Vianney Perchet (CREST)", "title": "Highly-Smooth Zero-th Order Online Optimization Vianney Perchet", "comments": "Conference on Learning Theory (COLT), Jun 2016, New York, United\n  States. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of convex functions which are only available through partial\nand noisy information is a key methodological problem in many disciplines. In\nthis paper we consider convex optimization with noisy zero-th order\ninformation, that is noisy function evaluations at any desired point. We focus\non problems with high degrees of smoothness, such as logistic regression. We\nshow that as opposed to gradient-based algorithms, high-order smoothness may be\nused to improve estimation rates, with a precise dependence of our upper-bounds\non the degree of smoothness. In particular, we show that for infinitely\ndifferentiable functions, we recover the same dependence on sample size as\ngradient-based algorithms, with an extra dimension-dependent factor. This is\ndone for both convex and strongly-convex functions, with finite horizon and\nanytime algorithms. Finally, we also recover similar results in the online\noptimization setting.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 06:54:55 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Bach", "Francis", "", "SIERRA, LIENS"], ["Perchet", "Vianney", "", "CREST"]]}, {"id": "1605.08174", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Hyungwon Choi, Yung Yi, Jinwoo Shin", "title": "Adiabatic Persistent Contrastive Divergence Learning", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of parameter learning in probabilistic\ngraphical models having latent variables, where the standard approach is the\nexpectation maximization algorithm alternating expectation (E) and maximization\n(M) steps. However, both E and M steps are computationally intractable for high\ndimensional data, while the substitution of one step to a faster surrogate for\ncombating against intractability can often cause failure in convergence. We\npropose a new learning algorithm which is computationally efficient and\nprovably ensures convergence to a correct optimum. Its key idea is to run only\na few cycles of Markov Chains (MC) in both E and M steps. Such an idea of\nrunning incomplete MC has been well studied only for M step in the literature,\ncalled Contrastive Divergence (CD) learning. While such known CD-based schemes\nfind approximated gradients of the log-likelihood via the mean-field approach\nin E step, our proposed algorithm does exact ones via MC algorithms in both\nsteps due to the multi-time-scale stochastic approximation theory. Despite its\ntheoretical guarantee in convergence, the proposed scheme might suffer from the\nslow mixing of MC in E step. To tackle it, we also propose a hybrid approach\napplying both mean-field and MC approximation in E step, where the hybrid\napproach outperforms the bare mean-field CD scheme in our experiments on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 07:26:25 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 10:52:07 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Jang", "Hyeryung", ""], ["Choi", "Hyungwon", ""], ["Yi", "Yung", ""], ["Shin", "Jinwoo", ""]]}, {"id": "1605.08188", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "Learning Multivariate Log-concave Distributions", "comments": "To appear in COLT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating multivariate log-concave probability\ndensity functions. We prove the first sample complexity upper bound for\nlearning log-concave densities on $\\mathbb{R}^d$, for all $d \\geq 1$. Prior to\nour work, no upper bound on the sample complexity of this learning problem was\nknown for the case of $d>3$. In more detail, we give an estimator that, for any\n$d \\ge 1$ and $\\epsilon>0$, draws $\\tilde{O}_d \\left( (1/\\epsilon)^{(d+5)/2}\n\\right)$ samples from an unknown target log-concave density on $\\mathbb{R}^d$,\nand outputs a hypothesis that (with high probability) is $\\epsilon$-close to\nthe target, in total variation distance. Our upper bound on the sample\ncomplexity comes close to the known lower bound of $\\Omega_d \\left(\n(1/\\epsilon)^{(d+1)/2} \\right)$ for this problem.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 08:31:18 GMT"}, {"version": "v2", "created": "Mon, 5 Jun 2017 20:06:28 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1605.08233", "submitter": "Zhiqiang Xu", "authors": "Zhiqiang Xu and Yiping Ke", "title": "Stochastic Variance Reduced Riemannian Eigensolver", "comments": "Under review. Supplementary material included in the paper as well", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic Riemannian gradient algorithm for matrix\neigen-decomposition. The state-of-the-art stochastic Riemannian algorithm\nrequires the learning rate to decay to zero and thus suffers from slow\nconvergence and sub-optimal solutions. In this paper, we address this issue by\ndeploying the variance reduction (VR) technique of stochastic gradient descent\n(SGD). The technique was originally developed to solve convex problems in the\nEuclidean space. We generalize it to Riemannian manifolds and realize it to\nsolve the non-convex eigen-decomposition problem. We are the first to propose\nand analyze the generalization of SVRG to Riemannian manifolds. Specifically,\nwe propose the general variance reduction form, SVRRG, in the framework of the\nstochastic Riemannian gradient optimization. It's then specialized to the\nproblem with eigensolvers and induces the SVRRG-EIGS algorithm. We provide a\nnovel and elegant theoretical analysis on this algorithm. The theory shows that\na fixed learning rate can be used in the Riemannian setting with an exponential\nglobal convergence rate guaranteed. The theoretical results make a significant\nimprovement over existing studies, with the effectiveness empirically verified.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 11:30:45 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 13:29:37 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Xu", "Zhiqiang", ""], ["Ke", "Yiping", ""]]}, {"id": "1605.08242", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, Fabrizio Silvestri, John Shawe-Taylor", "title": "Neighborhood Sensitive Mapping for Zero-Shot Classification using\n  Independently Learned Semantic Embeddings", "comments": "ACML Workshop on Learning on Big Data, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a traditional setting, classifiers are trained to approximate a target\nfunction $f:X \\rightarrow Y$ where at least a sample for each $y \\in Y$ is\npresented to the training algorithm. In a zero-shot setting we have a subset of\nthe labels $\\hat{Y} \\subset Y$ for which we do not observe any corresponding\ntraining instance. Still, the function $f$ that we train must be able to\ncorrectly assign labels also on $\\hat{Y}$. In practice, zero-shot problems are\nvery important especially when the label set is large and the cost of\neditorially label samples for all possible values in the label set might be\nprohibitively high. Most recent approaches to zero-shot learning are based on\nfinding and exploiting relationships between labels using semantic embeddings.\nWe show in this paper that semantic embeddings, despite being very good at\ncapturing relationships between labels, are not very good at capturing the\nrelationships among labels in a data-dependent manner. For this reason, we\npropose a novel two-step process for learning a zero-shot classifier. In the\nfirst step, we learn what we call a \\emph{property embedding space} capturing\nthe \"\\emph{learnable}\" features of the label set. Then, we exploit the learned\nproperties in order to reduce the generalization error for a linear nearest\nneighbor-based classifier.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 11:53:26 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 15:23:08 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 13:40:11 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Singh", "Gaurav", ""], ["Silvestri", "Fabrizio", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1605.08247", "submitter": "Hirokatsu Kataoka", "authors": "Hirokatsu Kataoka and Yudai Miyashita and Tomoaki Yamabe and Soma\n  Shirakabe and Shin'ichi Sato and Hironori Hoshino and Ryo Kato and Kaori Abe\n  and Takaaki Imanari and Naomichi Kobayashi and Shinichiro Morita and Akio\n  Nakamura", "title": "cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey", "comments": "Survey Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"cvpaper.challenge\" is a group composed of members from AIST, Tokyo Denki\nUniv. (TDU), and Univ. of Tsukuba that aims to systematically summarize papers\non computer vision, pattern recognition, and related fields. For this\nparticular review, we focused on reading the ALL 602 conference papers\npresented at the CVPR2015, the premier annual computer vision event held in\nJune 2015, in order to grasp the trends in the field. Further, we are proposing\n\"DeepSurvey\" as a mechanism embodying the entire process from the reading\nthrough all the papers, the generation of ideas, and to the writing of paper.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 12:08:55 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Kataoka", "Hirokatsu", ""], ["Miyashita", "Yudai", ""], ["Yamabe", "Tomoaki", ""], ["Shirakabe", "Soma", ""], ["Sato", "Shin'ichi", ""], ["Hoshino", "Hironori", ""], ["Kato", "Ryo", ""], ["Abe", "Kaori", ""], ["Imanari", "Takaaki", ""], ["Kobayashi", "Naomichi", ""], ["Morita", "Shinichiro", ""], ["Nakamura", "Akio", ""]]}, {"id": "1605.08254", "submitter": "Jure Sokolic", "authors": "Jure Sokolic, Raja Giryes, Guillermo Sapiro, Miguel R. D. Rodrigues", "title": "Robust Large Margin Deep Neural Networks", "comments": "accepted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2017.2708039", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization error of deep neural networks via their classification\nmargin is studied in this work. Our approach is based on the Jacobian matrix of\na deep neural network and can be applied to networks with arbitrary\nnon-linearities and pooling layers, and to networks with different\narchitectures such as feed forward networks and residual networks. Our analysis\nleads to the conclusion that a bounded spectral norm of the network's Jacobian\nmatrix in the neighbourhood of the training samples is crucial for a deep\nneural network of arbitrary depth and width to generalize well. This is a\nsignificant improvement over the current bounds in the literature, which imply\nthat the generalization error grows with either the width or the depth of the\nnetwork. Moreover, it shows that the recently proposed batch normalization and\nweight normalization re-parametrizations enjoy good generalization properties,\nand leads to a novel network regularizer based on the network's Jacobian\nmatrix. The analysis is supported with experimental results on the MNIST,\nCIFAR-10, LaRED and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 12:19:09 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2016 15:54:33 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 11:45:31 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Sokolic", "Jure", ""], ["Giryes", "Raja", ""], ["Sapiro", "Guillermo", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "1605.08257", "submitter": "Hiroyuki Kasai", "authors": "Hiroyuki Kasai and Bamdev Mishra", "title": "Low-rank tensor completion: a Riemannian manifold preconditioning\n  approach", "comments": "The 33rd International Conference on Machine Learning (ICML 2016).\n  arXiv admin note: substantial text overlap with arXiv:1506.02159", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Riemannian manifold preconditioning approach for the\ntensor completion problem with rank constraint. A novel Riemannian metric or\ninner product is proposed that exploits the least-squares structure of the cost\nfunction and takes into account the structured symmetry that exists in Tucker\ndecomposition. The specific metric allows to use the versatile framework of\nRiemannian optimization on quotient manifolds to develop preconditioned\nnonlinear conjugate gradient and stochastic gradient descent algorithms for\nbatch and online setups, respectively. Concrete matrix representations of\nvarious optimization-related ingredients are listed. Numerical comparisons\nsuggest that our proposed algorithms robustly outperform state-of-the-art\nalgorithms across different synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 12:55:02 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Kasai", "Hiroyuki", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1605.08283", "submitter": "Thomas Wiatowski", "authors": "Thomas Wiatowski and Michael Tschannen and Aleksandar Stani\\'c and\n  Philipp Grohs and Helmut B\\\"olcskei", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "comments": "Proc. of International Conference on Machine Learning (ICML), New\n  York, USA, June 2016, to appear", "journal-ref": "Proc. of International Conference on Machine Learning (ICML), New\n  York, USA, pp. 2149-2158, June 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First steps towards a mathematical theory of deep convolutional neural\nnetworks for feature extraction were made---for the continuous-time case---in\nMallat, 2012, and Wiatowski and B\\\"olcskei, 2015. This paper considers the\ndiscrete case, introduces new convolutional neural network architectures, and\nproposes a mathematical framework for their analysis. Specifically, we\nestablish deformation and translation sensitivity results of local and global\nnature, and we investigate how certain structural properties of the input\nsignal are reflected in the corresponding feature vectors. Our theory applies\nto general filters and general Lipschitz-continuous non-linearities and pooling\noperators. Experiments on handwritten digit classification and facial landmark\ndetection---including feature importance evaluation---complement the\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 13:55:07 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Wiatowski", "Thomas", ""], ["Tschannen", "Michael", ""], ["Stani\u0107", "Aleksandar", ""], ["Grohs", "Philipp", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1605.08325", "submitter": "He Ma", "authors": "He Ma, Fei Mao, and Graham W. Taylor", "title": "Theano-MPI: a Theano-based Distributed Training Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a scalable and extendable training framework that can utilize GPUs\nacross nodes in a cluster and accelerate the training of deep learning models\nbased on data parallelism. Both synchronous and asynchronous training are\nimplemented in our framework, where parameter exchange among GPUs is based on\nCUDA-aware MPI. In this report, we analyze the convergence and capability of\nthe framework to reduce training time when scaling the synchronous training of\nAlexNet and GoogLeNet from 2 GPUs to 8 GPUs. In addition, we explore novel ways\nto reduce the communication overhead caused by exchanging parameters. Finally,\nwe release the framework as open-source for further research on distributed\ndeep learning\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 15:13:46 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Ma", "He", ""], ["Mao", "Fei", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1605.08361", "submitter": "Daniel Soudry", "authors": "Daniel Soudry, Yair Carmon", "title": "No bad local minima: Data independent training error guarantees for\n  multilayer neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use smoothed analysis techniques to provide guarantees on the training\nloss of Multilayer Neural Networks (MNNs) at differentiable local minima.\nSpecifically, we examine MNNs with piecewise linear activation functions,\nquadratic loss and a single output, under mild over-parametrization. We prove\nthat for a MNN with one hidden layer, the training error is zero at every\ndifferentiable local minimum, for almost every dataset and dropout-like noise\nrealization. We then extend these results to the case of more than one hidden\nlayer. Our theoretical guarantees assume essentially nothing on the training\ndata, and are verified numerically. These results suggest why the highly\nnon-convex loss of such MNNs can be easily optimized using local updates (e.g.,\nstochastic gradient descent), as observed empirically.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 16:51:05 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 04:33:39 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Soudry", "Daniel", ""], ["Carmon", "Yair", ""]]}, {"id": "1605.08370", "submitter": "Chi Jin", "authors": "Chi Jin, Sham M. Kakade, Praneeth Netrapalli", "title": "Provable Efficient Online Matrix Completion via Non-convex Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion, where we wish to recover a low rank matrix by observing a\nfew entries from it, is a widely studied problem in both theory and practice\nwith wide applications. Most of the provable algorithms so far on this problem\nhave been restricted to the offline setting where they provide an estimate of\nthe unknown matrix using all observations simultaneously. However, in many\napplications, the online version, where we observe one entry at a time and\ndynamically update our estimate, is more appealing. While existing algorithms\nare efficient for the offline setting, they could be highly inefficient for the\nonline setting.\n  In this paper, we propose the first provable, efficient online algorithm for\nmatrix completion. Our algorithm starts from an initial estimate of the matrix\nand then performs non-convex stochastic gradient descent (SGD). After every\nobservation, it performs a fast update involving only one row of two tall\nmatrices, giving near linear total runtime. Our algorithm can be naturally used\nin the offline setting as well, where it gives competitive sample complexity\nand runtime to state of the art algorithms. Our proofs introduce a general\nframework to show that SGD updates tend to stay away from saddle surfaces and\ncould be of broader interests for other non-convex problems to prove tight\nrates.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 17:26:18 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Jin", "Chi", ""], ["Kakade", "Sham M.", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "1605.08374", "submitter": "Zelda Mariet", "authors": "Zelda Mariet and Suvrit Sra", "title": "Kronecker Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Determinantal Point Processes (DPPs) are probabilistic models over all\nsubsets a ground set of $N$ items. They have recently gained prominence in\nseveral applications that rely on \"diverse\" subsets. However, their\napplicability to large problems is still limited due to the $\\mathcal O(N^3)$\ncomplexity of core tasks such as sampling and learning. We enable efficient\nsampling and learning for DPPs by introducing KronDPP, a DPP model whose kernel\nmatrix decomposes as a tensor product of multiple smaller kernel matrices. This\ndecomposition immediately enables fast exact sampling. But contrary to what one\nmay expect, leveraging the Kronecker product structure for speeding up DPP\nlearning turns out to be more difficult. We overcome this challenge, and derive\nbatch and stochastic optimization algorithms for efficiently learning the\nparameters of a KronDPP.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 17:33:31 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Mariet", "Zelda", ""], ["Sra", "Suvrit", ""]]}, {"id": "1605.08375", "submitter": "Junhong Lin", "authors": "Junhong Lin, Raffaello Camoriano, Lorenzo Rosasco", "title": "Generalization Properties and Implicit Regularization for Multiple\n  Passes SGM", "comments": "26 pages, 4 figures. To appear in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalization properties of stochastic gradient methods for\nlearning with convex loss functions and linearly parameterized functions. We\nshow that, in the absence of penalizations or constraints, the stability and\napproximation properties of the algorithm can be controlled by tuning either\nthe step-size or the number of passes over the data. In this view, these\nparameters can be seen to control a form of implicit regularization. Numerical\nresults complement the theoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 17:37:51 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Lin", "Junhong", ""], ["Camoriano", "Raffaello", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1605.08455", "submitter": "Artur Dubrawski", "authors": "P. Tandon (1), P. Huggins (1), A. Dubrawski (1), S. Labov (2), K.\n  Nelson (2) ((1) Auton Lab, Carnegie Mellon University, (2) Lawrence Livermore\n  National Laboratory)", "title": "Suppressing Background Radiation Using Poisson Principal Component\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of nuclear threat detection systems based on gamma-ray\nspectrometry often strongly depends on the ability to identify the part of\nmeasured signal that can be attributed to background radiation. We have\nsuccessfully applied a method based on Principal Component Analysis (PCA) to\nobtain a compact null-space model of background spectra using PCA projection\nresiduals to derive a source detection score. We have shown the method's\nutility in a threat detection system using mobile spectrometers in urban scenes\n(Tandon et al 2012). While it is commonly assumed that measured photon counts\nfollow a Poisson process, standard PCA makes a Gaussian assumption about the\ndata distribution, which may be a poor approximation when photon counts are\nlow. This paper studies whether and in what conditions PCA with a Poisson-based\nloss function (Poisson PCA) can outperform standard Gaussian PCA in modeling\nbackground radiation to enable more sensitive and specific nuclear threat\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 21:27:11 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Tandon", "P.", ""], ["Huggins", "P.", ""], ["Dubrawski", "A.", ""], ["Labov", "S.", ""], ["Nelson", "K.", ""]]}, {"id": "1605.08478", "submitter": "Jonathan Ho", "authors": "Jonathan Ho, Jayesh K. Gupta, Stefano Ermon", "title": "Model-Free Imitation Learning with Policy Optimization", "comments": "In Proceedings of the 33rd International Conference on Machine\n  Learning, 2016", "journal-ref": "JMLR W&CP 48 (2016) 2760-2769", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In imitation learning, an agent learns how to behave in an environment with\nan unknown cost function by mimicking expert demonstrations. Existing imitation\nlearning algorithms typically involve solving a sequence of planning or\nreinforcement learning problems. Such algorithms are therefore not directly\napplicable to large, high-dimensional environments, and their performance can\nsignificantly degrade if the planning problems are not solved to optimality.\nUnder the apprenticeship learning formalism, we develop alternative model-free\nalgorithms for finding a parameterized stochastic policy that performs at least\nas well as an expert policy on an unknown cost function, based on sample\ntrajectories from the expert. Our approach, based on policy gradients, scales\nto large continuous environments with guaranteed convergence to local minima.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 23:43:32 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Ho", "Jonathan", ""], ["Gupta", "Jayesh K.", ""], ["Ermon", "Stefano", ""]]}, {"id": "1605.08481", "submitter": "Lijie Chen", "authors": "Lijie Chen and Jian Li", "title": "Open Problem: Best Arm Identification: Almost Instance-Wise Optimality\n  and the Gap Entropy Conjecture", "comments": "To appear in COLT 2016 Open Problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best arm identification problem (BEST-1-ARM) is the most basic pure\nexploration problem in stochastic multi-armed bandits. The problem has a long\nhistory and attracted significant attention for the last decade. However, we do\nnot yet have a complete understanding of the optimal sample complexity of the\nproblem: The state-of-the-art algorithms achieve a sample complexity of\n$O(\\sum_{i=2}^{n} \\Delta_{i}^{-2}(\\ln\\delta^{-1} + \\ln\\ln\\Delta_i^{-1}))$\n($\\Delta_{i}$ is the difference between the largest mean and the $i^{th}$\nmean), while the best known lower bound is $\\Omega(\\sum_{i=2}^{n}\n\\Delta_{i}^{-2}\\ln\\delta^{-1})$ for general instances and $\\Omega(\\Delta^{-2}\n\\ln\\ln \\Delta^{-1})$ for the two-arm instances. We propose to study the\ninstance-wise optimality for the BEST-1-ARM problem. Previous work has proved\nthat it is impossible to have an instance optimal algorithm for the 2-arm\nproblem. However, we conjecture that modulo the additive term\n$\\Omega(\\Delta_2^{-2} \\ln\\ln \\Delta_2^{-1})$ (which is an upper bound and worst\ncase lower bound for the 2-arm problem), there is an instance optimal algorithm\nfor BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy\nfor a best-arm problem instance, and conjecture that it is the instance-wise\nlower bound. Hence, resolving this conjecture would provide a final answer to\nthe old and basic problem.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 00:23:39 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Chen", "Lijie", ""], ["Li", "Jian", ""]]}, {"id": "1605.08491", "submitter": "Tengyu Ma", "authors": "Sanjeev Arora, Rong Ge, Frederic Koehler, Tengyu Ma, Ankur Moitra", "title": "Provable Algorithms for Inference in Topic Models", "comments": "to appear at ICML'2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been considerable progress on designing algorithms with\nprovable guarantees -- typically using linear algebraic methods -- for\nparameter learning in latent variable models. But designing provable algorithms\nfor inference has proven to be more challenging. Here we take a first step\ntowards provable inference in topic models. We leverage a property of topic\nmodels that enables us to construct simple linear estimators for the unknown\ntopic proportions that have small variance, and consequently can work with\nshort documents. Our estimators also correspond to finding an estimate around\nwhich the posterior is well-concentrated. We show lower bounds that for shorter\ndocuments it can be information theoretically impossible to find the hidden\ntopics. Finally, we give empirical results that demonstrate that our algorithm\nworks on realistic topic models. It yields good solutions on synthetic data and\nruns in time comparable to a {\\em single} iteration of Gibbs sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 02:18:43 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Koehler", "Frederic", ""], ["Ma", "Tengyu", ""], ["Moitra", "Ankur", ""]]}, {"id": "1605.08497", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Vladimir Cherkassky", "title": "Universum Learning for SVM Regression", "comments": "10 pages,11 figures, Thesis:\n  http://conservancy.umn.edu/handle/11299/162636", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the idea of Universum learning [18, 19] to regression\nproblems. We propose new Universum-SVM formulation for regression problems that\nincorporates a priori knowledge in the form of additional data samples. These\nadditional data samples or Universum belong to the same application domain as\nthe training samples, but they follow a different distribution. Several\nempirical comparisons are presented to illustrate the utility of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 03:11:41 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Dhar", "Sauptik", ""], ["Cherkassky", "Vladimir", ""]]}, {"id": "1605.08501", "submitter": "Yao Chen", "authors": "Yao Chen, Xiao Wang, Linglong Kong and Hongtu Zhu", "title": "Local Region Sparse Learning for Image-on-Scalar Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of regions of interest (ROI) associated with certain disease\nhas a great impact on public health. Imposing sparsity of pixel values and\nextracting active regions simultaneously greatly complicate the image analysis.\nWe address these challenges by introducing a novel region-selection penalty in\nthe framework of image-on-scalar regression. Our penalty combines the Smoothly\nClipped Absolute Deviation (SCAD) regularization, enforcing sparsity, and the\nSCAD of total variation (TV) regularization, enforcing spatial contiguity, into\none group, which segments contiguous spatial regions against zero-valued\nbackground. Efficient algorithm is based on the alternative direction method of\nmultipliers (ADMM) which decomposes the non-convex problem into two iterative\noptimization problems with explicit solutions. Another virtue of the proposed\nmethod is that a divide and conquer learning algorithm is developed, thereby\nallowing scaling to large images. Several examples are presented and the\nexperimental results are compared with other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 03:28:41 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Chen", "Yao", ""], ["Wang", "Xiao", ""], ["Kong", "Linglong", ""], ["Zhu", "Hongtu", ""]]}, {"id": "1605.08512", "submitter": "Milad Mohammadi", "authors": "Milad Mohammadi, Subhasis Das", "title": "SNN: Stacked Neural Networks", "comments": "8pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proven that transfer learning provides an easy way to achieve\nstate-of-the-art accuracies on several vision tasks by training a simple\nclassifier on top of features obtained from pre-trained neural networks. The\ngoal of this work is to generate better features for transfer learning from\nmultiple publicly available pre-trained neural networks. To this end, we\npropose a novel architecture called Stacked Neural Networks which leverages the\nfast training time of transfer learning while simultaneously being much more\naccurate. We show that using a stacked NN architecture can result in up to 8%\nimprovements in accuracy over state-of-the-art techniques using only one\npre-trained network for transfer learning. A second aim of this work is to make\nnetwork fine- tuning retain the generalizability of the base network to unseen\ntasks. To this end, we propose a new technique called \"joint fine-tuning\" that\nis able to give accuracies comparable to finetuning the same network\nindividually over two datasets. We also show that a jointly finetuned network\ngeneralizes better to unseen tasks when compared to a network finetuned over a\nsingle task.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 06:02:48 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Mohammadi", "Milad", ""], ["Das", "Subhasis", ""]]}, {"id": "1605.08527", "submitter": "Gabriel Peyre", "authors": "Genevay Aude (MOKAPLAN, CEREMADE), Marco Cuturi, Gabriel Peyr\\'e\n  (MOKAPLAN, CEREMADE), Francis Bach (SIERRA, LIENS)", "title": "Stochastic Optimization for Large-scale Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) defines a powerful framework to compare probability\ndistributions in a geometrically faithful way. However, the practical impact of\nOT is still limited because of its computational burden. We propose a new class\nof stochastic optimization algorithms to cope with large-scale problems\nroutinely encountered in machine learning applications. These methods are able\nto manipulate arbitrary distributions (either discrete or continuous) by simply\nrequiring to be able to draw samples from them, which is the typical setup in\nhigh-dimensional learning problems. This alleviates the need to discretize\nthese densities, while giving access to provably convergent methods that output\nthe correct distance without discretization error. These algorithms rely on two\nmain ideas: (a) the dual OT problem can be re-cast as the maximization of an\nexpectation ; (b) entropic regularization of the primal OT problem results in a\nsmooth dual optimization optimization which can be addressed with algorithms\nthat have a provably faster convergence. We instantiate these ideas in three\ndifferent setups: (i) when comparing a discrete distribution to another, we\nshow that incremental stochastic optimization schemes can beat Sinkhorn's\nalgorithm, the current state-of-the-art finite dimensional OT solver; (ii) when\ncomparing a discrete distribution to a continuous density, a semi-discrete\nreformulation of the dual program is amenable to averaged stochastic gradient\ndescent, leading to better performance than approximately solving the problem\nby discretization ; (iii) when dealing with two continuous densities, we\npropose a stochastic gradient descent over a reproducing kernel Hilbert space\n(RKHS). This is currently the only known method to solve this problem, apart\nfrom computing OT on finite samples. We backup these claims on a set of\ndiscrete, semi-discrete and continuous benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 07:47:30 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Aude", "Genevay", "", "MOKAPLAN, CEREMADE"], ["Cuturi", "Marco", "", "MOKAPLAN, CEREMADE"], ["Peyr\u00e9", "Gabriel", "", "MOKAPLAN, CEREMADE"], ["Bach", "Francis", "", "SIERRA, LIENS"]]}, {"id": "1605.08535", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, Sunghun Kim", "title": "Deep API Learning", "comments": "The paper is accepted at FSE 2016 (the 24th ACM SIGSOFT International\n  Symposium on the Foundations of Software Engineering)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers often wonder how to implement a certain functionality (e.g., how\nto parse XML files) using APIs. Obtaining an API usage sequence based on an\nAPI-related natural language query is very helpful in this regard. Given a\nquery, existing approaches utilize information retrieval models to search for\nmatching API sequences. These approaches treat queries and APIs as bag-of-words\n(i.e., keyword matching or word-to-word alignment) and lack a deep\nunderstanding of the semantics of the query.\n  We propose DeepAPI, a deep learning based approach to generate API usage\nsequences for a given natural language query. Instead of a bags-of-words\nassumption, it learns the sequence of words in a query and the sequence of\nassociated APIs. DeepAPI adapts a neural language model named RNN\nEncoder-Decoder. It encodes a word sequence (user query) into a fixed-length\ncontext vector, and generates an API sequence based on the context vector. We\nalso augment the RNN Encoder-Decoder by considering the importance of\nindividual APIs. We empirically evaluate our approach with more than 7 million\nannotated code snippets collected from GitHub. The results show that our\napproach generates largely accurate API sequences and outperforms the related\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 08:27:18 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 09:38:35 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 01:22:18 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Gu", "Xiaodong", ""], ["Zhang", "Hongyu", ""], ["Zhang", "Dongmei", ""], ["Kim", "Sunghun", ""]]}, {"id": "1605.08618", "submitter": "Christian Gruhl", "authors": "Christian Gruhl, Bernhard Sick", "title": "Variational Bayesian Inference for Hidden Markov Models With\n  Multivariate Gaussian Output Distributions", "comments": "Preliminary version. Contains all necessary equations for\n  implementation. Ongoing research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Models (HMM) have been used for several years in many time\nseries analysis or pattern recognitions tasks. HMM are often trained by means\nof the Baum-Welch algorithm which can be seen as a special variant of an\nexpectation maximization (EM) algorithm. Second-order training techniques such\nas Variational Bayesian Inference (VI) for probabilistic models regard the\nparameters of the probabilistic models as random variables and define\ndistributions over these distribution parameters, hence the name of this\ntechnique. VI can also bee regarded as a special case of an EM algorithm. In\nthis article, we bring both together and train HMM with multivariate Gaussian\noutput distributions with VI. The article defines the new training technique\nfor HMM. An evaluation based on some case studies and a comparison to related\napproaches is part of our ongoing work.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 13:00:31 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Gruhl", "Christian", ""], ["Sick", "Bernhard", ""]]}, {"id": "1605.08636", "submitter": "Pascal Germain", "authors": "Pascal Germain (INRIA Paris), Francis Bach (INRIA Paris), Alexandre\n  Lacoste (Google), Simon Lacoste-Julien (INRIA Paris)", "title": "PAC-Bayesian Theory Meets Bayesian Inference", "comments": "Published at NIPS 2015\n  (http://papers.nips.cc/paper/6569-pac-bayesian-theory-meets-bayesian-inference)", "journal-ref": "Advances in Neural Information Processing Systems 29 (NIPS 2016),\n  p. 1884-1892", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit a strong link between frequentist PAC-Bayesian risk bounds and the\nBayesian marginal likelihood. That is, for the negative log-likelihood loss\nfunction, we show that the minimization of PAC-Bayesian generalization risk\nbounds maximizes the Bayesian marginal likelihood. This provides an alternative\nexplanation to the Bayesian Occam's razor criteria, under the assumption that\nthe data is generated by an i.i.d distribution. Moreover, as the negative\nlog-likelihood is an unbounded loss function, we motivate and propose a\nPAC-Bayesian theorem tailored for the sub-gamma loss family, and we show that\nour approach is sound on classical Bayesian linear regression tasks.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 13:41:33 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 14:49:05 GMT"}, {"version": "v3", "created": "Sat, 3 Dec 2016 22:48:15 GMT"}, {"version": "v4", "created": "Mon, 13 Feb 2017 17:14:52 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Germain", "Pascal", "", "INRIA Paris"], ["Bach", "Francis", "", "INRIA Paris"], ["Lacoste", "Alexandre", "", "Google"], ["Lacoste-Julien", "Simon", "", "INRIA Paris"]]}, {"id": "1605.08671", "submitter": "Andrea Locatelli", "authors": "Andrea Locatelli, Maurilio Gutzeit, and Alexandra Carpentier", "title": "An optimal algorithm for the Thresholding Bandit Problem", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a specific \\textit{combinatorial pure exploration stochastic bandit\nproblem} where the learner aims at finding the set of arms whose means are\nabove a given threshold, up to a given precision, and \\textit{for a fixed time\nhorizon}. We propose a parameter-free algorithm based on an original heuristic,\nand prove that it is optimal for this problem by deriving matching upper and\nlower bounds. To the best of our knowledge, this is the first non-trivial pure\nexploration setting with \\textit{fixed budget} for which optimal strategies are\nconstructed.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 14:35:29 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Locatelli", "Andrea", ""], ["Gutzeit", "Maurilio", ""], ["Carpentier", "Alexandra", ""]]}, {"id": "1605.08722", "submitter": "Peter Auer", "authors": "Peter Auer and Chao-Kai Chiang", "title": "An algorithm with nearly optimal pseudo-regret for both stochastic and\n  adversarial bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that achieves almost optimal pseudo-regret bounds\nagainst adversarial and stochastic bandits. Against adversarial bandits the\npseudo-regret is $O(K\\sqrt{n \\log n})$ and against stochastic bandits the\npseudo-regret is $O(\\sum_i (\\log n)/\\Delta_i)$. We also show that no algorithm\nwith $O(\\log n)$ pseudo-regret against stochastic bandits can achieve\n$\\tilde{O}(\\sqrt{n})$ expected regret against adaptive adversarial bandits.\nThis complements previous results of Bubeck and Slivkins (2012) that show\n$\\tilde{O}(\\sqrt{n})$ expected adversarial regret with $O((\\log n)^2)$\nstochastic pseudo-regret.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 17:28:35 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Auer", "Peter", ""], ["Chiang", "Chao-Kai", ""]]}, {"id": "1605.08754", "submitter": "Cameron Musco", "authors": "Dan Garber, Elad Hazan, Chi Jin, Sham M. Kakade, Cameron Musco,\n  Praneeth Netrapalli, Aaron Sidford", "title": "Faster Eigenvector Computation via Shift-and-Invert Preconditioning", "comments": "Appearing in ICML 2016. Combination of work in arXiv:1509.05647 and\n  arXiv:1510.08896", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give faster algorithms and improved sample complexities for estimating the\ntop eigenvector of a matrix $\\Sigma$ -- i.e. computing a unit vector $x$ such\nthat $x^T \\Sigma x \\ge (1-\\epsilon)\\lambda_1(\\Sigma)$:\n  Offline Eigenvector Estimation: Given an explicit $A \\in \\mathbb{R}^{n \\times\nd}$ with $\\Sigma = A^TA$, we show how to compute an $\\epsilon$ approximate top\neigenvector in time $\\tilde O([nnz(A) + \\frac{d*sr(A)}{gap^2} ]* \\log\n1/\\epsilon )$ and $\\tilde O([\\frac{nnz(A)^{3/4} (d*sr(A))^{1/4}}{\\sqrt{gap}} ]\n* \\log 1/\\epsilon )$. Here $nnz(A)$ is the number of nonzeros in $A$, $sr(A)$\nis the stable rank, $gap$ is the relative eigengap. By separating the $gap$\ndependence from the $nnz(A)$ term, our first runtime improves upon the\nclassical power and Lanczos methods. It also improves prior work using fast\nsubspace embeddings [AC09, CW13] and stochastic optimization [Sha15c], giving\nsignificantly better dependencies on $sr(A)$ and $\\epsilon$. Our second running\ntime improves these further when $nnz(A) \\le \\frac{d*sr(A)}{gap^2}$.\n  Online Eigenvector Estimation: Given a distribution $D$ with covariance\nmatrix $\\Sigma$ and a vector $x_0$ which is an $O(gap)$ approximate top\neigenvector for $\\Sigma$, we show how to refine to an $\\epsilon$ approximation\nusing $ O(\\frac{var(D)}{gap*\\epsilon})$ samples from $D$. Here $var(D)$ is a\nnatural notion of variance. Combining our algorithm with previous work to\ninitialize $x_0$, we obtain improved sample complexity and runtime results\nunder a variety of assumptions on $D$.\n  We achieve our results using a general framework that we believe is of\nindependent interest. We give a robust analysis of the classic method of\nshift-and-invert preconditioning to reduce eigenvector computation to\napproximately solving a sequence of linear systems. We then apply fast\nstochastic variance reduced gradient (SVRG) based system solvers to achieve our\nclaims.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 03:53:00 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Garber", "Dan", ""], ["Hazan", "Elad", ""], ["Jin", "Chi", ""], ["Kakade", "Sham M.", ""], ["Musco", "Cameron", ""], ["Netrapalli", "Praneeth", ""], ["Sidford", "Aaron", ""]]}, {"id": "1605.08764", "submitter": "Nazneen Fatema Rajani", "authors": "Nazneen Fatema Rajani and Raymond J. Mooney", "title": "Stacking With Auxiliary Features", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.04802", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembling methods are well known for improving prediction accuracy. However,\nthey are limited in the sense that they cannot discriminate among component\nmodels effectively. In this paper, we propose stacking with auxiliary features\nthat learns to fuse relevant information from multiple systems to improve\nperformance. Auxiliary features enable the stacker to rely on systems that not\njust agree on an output but also the provenance of the output. We demonstrate\nour approach on three very different and difficult problems -- the Cold Start\nSlot Filling, the Tri-lingual Entity Discovery and Linking and the ImageNet\nobject detection tasks. We obtain new state-of-the-art results on the first two\ntasks and substantial improvements on the detection task, thus verifying the\npower and generality of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 19:31:54 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Rajani", "Nazneen Fatema", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1605.08798", "submitter": "Jamshid Sourati", "authors": "Jamshid Sourati, Murat Akcakaya, Todd K. Leen, Deniz Erdogmus,\n  Jennifer G. Dy", "title": "Asymptotic Analysis of Objectives based on Fisher Information in Active\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining labels can be costly and time-consuming. Active learning allows a\nlearning algorithm to intelligently query samples to be labeled for efficient\nlearning. Fisher information ratio (FIR) has been used as an objective for\nselecting queries in active learning. However, little is known about the theory\nbehind the use of FIR for active learning. There is a gap between the\nunderlying theory and the motivation of its usage in practice. In this paper,\nwe attempt to fill this gap and provide a rigorous framework for analyzing\nexisting FIR-based active learning methods. In particular, we show that FIR can\nbe asymptotically viewed as an upper bound of the expected variance of the\nlog-likelihood ratio. Additionally, our analysis suggests a unifying framework\nthat not only enables us to make theoretical comparisons among the existing\nquerying methods based on FIR, but also allows us to give insight into the\ndevelopment of new active learning approaches based on this objective.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 20:44:28 GMT"}, {"version": "v2", "created": "Fri, 14 Oct 2016 21:09:35 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Sourati", "Jamshid", ""], ["Akcakaya", "Murat", ""], ["Leen", "Todd K.", ""], ["Erdogmus", "Deniz", ""], ["Dy", "Jennifer G.", ""]]}, {"id": "1605.08803", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio", "title": "Density estimation using Real NVP", "comments": "10 pages of main content, 3 pages of bibliography, 18 pages of\n  appendix. Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 21:24:32 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 21:37:10 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 23:21:10 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Dinh", "Laurent", ""], ["Sohl-Dickstein", "Jascha", ""], ["Bengio", "Samy", ""]]}, {"id": "1605.08833", "submitter": "Akshay Balsubramani", "authors": "Akshay Balsubramani, Yoav Freund", "title": "Muffled Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a novel approach to semi-supervised learning. This approach is\ncontrary to the common approach in that the unlabeled examples serve to\n\"muffle,\" rather than enhance, the guidance provided by the labeled examples.\nWe provide several variants of the basic algorithm and show experimentally that\nthey can achieve significantly higher AUC than boosted trees, random forests\nand logistic regression when unlabeled examples are available.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 02:39:24 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Balsubramani", "Akshay", ""], ["Freund", "Yoav", ""]]}, {"id": "1605.08838", "submitter": "Bangrui Chen", "authors": "Bangrui Chen, Peter I. Frazier", "title": "Dueling Bandits with Dependent Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study dueling bandits with weak utility-based regret when preferences over\narms have a total order and carry observable feature vectors. The order is\nassumed to be determined by these feature vectors, an unknown preference\nvector, and a known utility function. This structure introduces dependence\nbetween preferences for pairs of arms, and allows learning about the preference\nover one pair of arms from the preference over another pair of arms. We propose\nan algorithm for this setting called Comparing The Best (CTB), which we show\nhas constant expected cumulative weak utility-based regret. We provide a\nBayesian interpretation for CTB, an implementation appropriate for a small\nnumber of arms, and an alternate implementation for many arms that can be used\nwhen the input parameters satisfy a decomposability condition. We demonstrate\nthrough numerical experiments that CTB with appropriate input parameters\noutperforms all benchmarks considered.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 03:21:44 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 01:30:11 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Chen", "Bangrui", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1605.08872", "submitter": "Chenghao Liu", "authors": "Chenghao Liu, Tao Jin, Steven C.H. Hoi, Peilin Zhao, Jianling Sun", "title": "Online Bayesian Collaborative Topic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Topic Regression (CTR) combines ideas of probabilistic matrix\nfactorization (PMF) and topic modeling (e.g., LDA) for recommender systems,\nwhich has gained increasing successes in many applications. Despite enjoying\nmany advantages, the existing CTR algorithms have some critical limitations.\nFirst of all, they are often designed to work in a batch learning manner,\nmaking them unsuitable to deal with streaming data or big data in real-world\nrecommender systems. Second, the document-specific topic proportions of LDA are\nfed to the downstream PMF, but not reverse, which is sub-optimal as the rating\ninformation is not exploited in discovering the low-dimensional representation\nof documents and thus can result in a sub-optimal representation for\nprediction. In this paper, we propose a novel scheme of Online Bayesian\nCollaborative Topic Regression (OBCTR) which is efficient and scalable for\nlearning from data streams. Particularly, we {\\it jointly} optimize the\ncombined objective function of both PMF and LDA in an online learning fashion,\nin which both PMF and LDA tasks can be reinforced each other during the online\nlearning process. Our encouraging experimental results on real-world data\nvalidate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 10:17:37 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Liu", "Chenghao", ""], ["Jin", "Tao", ""], ["Hoi", "Steven C. H.", ""], ["Zhao", "Peilin", ""], ["Sun", "Jianling", ""]]}, {"id": "1605.08882", "submitter": "Junhong Lin", "authors": "Junhong Lin, Lorenzo Rosasco", "title": "Optimal Rates for Multi-pass Stochastic Gradient Methods", "comments": "Fixed a typo in Eq (66)", "journal-ref": "Journal of Machine Learning Research, 18:1-47, 2017", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the learning properties of the stochastic gradient method when\nmultiple passes over the data and mini-batches are allowed. We study how\nregularization properties are controlled by the step-size, the number of passes\nand the mini-batch size. In particular, we consider the square loss and show\nthat for a universal step-size choice, the number of passes acts as a\nregularization parameter, and optimal finite sample bounds can be achieved by\nearly-stopping. Moreover, we show that larger step-sizes are allowed when\nconsidering mini-batches. Our analysis is based on a unifying approach,\nencompassing both batch and stochastic gradient methods as special cases. As a\nbyproduct, we derive optimal convergence results for batch gradient methods\n(even in the non-attainable cases).\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 12:11:22 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 22:55:48 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2019 02:07:20 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Lin", "Junhong", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1605.08988", "submitter": "Emilie Kaufmann", "authors": "Aur\\'elien Garivier (IMT), Emilie Kaufmann (SEQUEL, CRIStAL, CNRS),\n  Tor Lattimore", "title": "On Explore-Then-Commit Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of minimising regret in two-armed bandit problems with\nGaussian rewards. Our objective is to use this simple setting to illustrate\nthat strategies based on an exploration phase (up to a stopping time) followed\nby exploitation are necessarily suboptimal. The results hold regardless of\nwhether or not the difference in means between the two arms is known. Besides\nthe main message, we also refine existing deviation inequalities, which allow\nus to design fully sequential strategies with finite-time regret guarantees\nthat are (a) asymptotically optimal as the horizon grows and (b) order-optimal\nin the minimax sense. Furthermore we provide empirical evidence that the theory\nalso holds in practice and discuss extensions to non-gaussian and\nmultiple-armed case.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 10:35:33 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 12:40:20 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Garivier", "Aur\u00e9lien", "", "IMT"], ["Kaufmann", "Emilie", "", "SEQUEL, CRIStAL, CNRS"], ["Lattimore", "Tor", ""]]}, {"id": "1605.09004", "submitter": "Andrea Locatelli", "authors": "Alexandra Carpentier and Andrea Locatelli", "title": "Tight (Lower) Bounds for the Fixed Budget Best Arm Identification Bandit\n  Problem", "comments": "COLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of \\textit{best arm identification} with a\n\\textit{fixed budget $T$}, in the $K$-armed stochastic bandit setting, with\narms distribution defined on $[0,1]$. We prove that any bandit strategy, for at\nleast one bandit problem characterized by a complexity $H$, will misidentify\nthe best arm with probability lower bounded by\n$$\\exp\\Big(-\\frac{T}{\\log(K)H}\\Big),$$ where $H$ is the sum for all sub-optimal\narms of the inverse of the squared gaps. Our result disproves formally the\ngeneral belief - coming from results in the fixed confidence setting - that\nthere must exist an algorithm for this problem whose probability of error is\nupper bounded by $\\exp(-T/H)$. This also proves that some existing strategies\nbased on the Successive Rejection of the arms are optimal - closing therefore\nthe current gap between upper and lower bounds for the fixed budget best arm\nidentification problem.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 13:59:48 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Carpentier", "Alexandra", ""], ["Locatelli", "Andrea", ""]]}, {"id": "1605.09046", "submitter": "Krzysztof Choromanski", "authors": "Krzysztof Choromanski, Francois Fagan, Cedric Gouy-Pailler, Anne\n  Morvan, Tamas Sarlos, Jamal Atif", "title": "TripleSpin - a generic compact paradigm for fast machine learning\n  computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic compact computational framework relying on structured\nrandom matrices that can be applied to speed up several machine learning\nalgorithms with almost no loss of accuracy. The applications include new fast\nLSH-based algorithms, efficient kernel computations via random feature maps,\nconvex optimization algorithms, quantization techniques and many more. Certain\nmodels of the presented paradigm are even more compressible since they apply\nonly bit matrices. This makes them suitable for deploying on mobile devices.\nAll our findings come with strong theoretical guarantees. In particular, as a\nbyproduct of the presented techniques and by using relatively new\nBerry-Esseen-type CLT for random vectors, we give the first theoretical\nguarantees for one of the most efficient existing LSH algorithms based on the\n$\\textbf{HD}_{3}\\textbf{HD}_{2}\\textbf{HD}_{1}$ structured matrix (\"Practical\nand Optimal LSH for Angular Distance\"). These guarantees as well as theoretical\nresults for other aforementioned applications follow from the same general\ntheoretical principle that we present in the paper. Our structured family\ncontains as special cases all previously considered structured schemes,\nincluding the recently introduced $P$-model. Experimental evaluation confirms\nthe accuracy and efficiency of TripleSpin matrices.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 19:07:09 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 15:05:31 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Fagan", "Francois", ""], ["Gouy-Pailler", "Cedric", ""], ["Morvan", "Anne", ""], ["Sarlos", "Tamas", ""], ["Atif", "Jamal", ""]]}, {"id": "1605.09049", "submitter": "Krzysztof Choromanski", "authors": "Krzysztof Choromanski, Vikas Sindhwani", "title": "Recycling Randomness with Structure for Sublinear time Kernel Expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for recycling Gaussian random vectors into structured\nmatrices to approximate various kernel functions in sublinear time via random\nembeddings. Our framework includes the Fastfood construction as a special case,\nbut also extends to Circulant, Toeplitz and Hankel matrices, and the broader\nfamily of structured matrices that are characterized by the concept of\nlow-displacement rank. We introduce notions of coherence and graph-theoretic\nstructural constants that control the approximation quality, and prove\nunbiasedness and low-variance properties of random feature maps that arise\nwithin our framework. For the case of low-displacement matrices, we show how\nthe degree of structure and randomness can be controlled to reduce statistical\nvariance at the cost of increased computation and storage requirements.\nEmpirical results strongly support our theory and justify the use of a broader\nfamily of structured matrices for scaling up kernel methods using random\nfeatures.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 19:21:22 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Sindhwani", "Vikas", ""]]}, {"id": "1605.09066", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo and Heng Huang", "title": "Distributed Asynchronous Dual Free Stochastic Dual Coordinate Ascent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primal-dual distributed optimization methods have broad large-scale\nmachine learning applications. Previous primal-dual distributed methods are not\napplicable when the dual formulation is not available, e.g. the\nsum-of-non-convex objectives. Moreover, these algorithms and theoretical\nanalysis are based on the fundamental assumption that the computing speeds of\nmultiple machines in a cluster are similar. However, the straggler problem is\nan unavoidable practical issue in the distributed system because of the\nexistence of slow machines. Therefore, the total computational time of the\ndistributed optimization methods is highly dependent on the slowest machine. In\nthis paper, we address these two issues by proposing distributed asynchronous\ndual free stochastic dual coordinate ascent algorithm for distributed\noptimization. Our method does not need the dual formulation of the target\nproblem in the optimization. We tackle the straggler problem through\nasynchronous communication and the negative effect of slow machines is\nsignificantly alleviated. We also analyze the convergence rate of our method\nand prove the linear convergence rate even if the individual functions in\nobjective are non-convex. Experiments on both convex and non-convex loss\nfunctions are used to validate our statements.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 21:33:07 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2016 03:29:57 GMT"}, {"version": "v3", "created": "Sat, 19 Nov 2016 20:32:35 GMT"}, {"version": "v4", "created": "Fri, 27 Oct 2017 03:06:07 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "1605.09068", "submitter": "Michael Lash", "authors": "Michael T. Lash, Qihang Lin, W. Nick Street and Jennifer G. Robinson", "title": "A budget-constrained inverse classification framework for smooth\n  classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse classification is the process of manipulating an instance such that\nit is more likely to conform to a specific class. Past methods that address\nsuch a problem have shortcomings. Greedy methods make changes that are overly\nradical, often relying on data that is strictly discrete. Other methods rely on\ncertain data points, the presence of which cannot be guaranteed. In this paper\nwe propose a general framework and method that overcomes these and other\nlimitations. The formulation of our method can use any differentiable\nclassification function. We demonstrate the method by using logistic regression\nand Gaussian kernel SVMs. We constrain the inverse classification to occur on\nfeatures that can actually be changed, each of which incurs an individual cost.\nWe further subject such changes to fall within a certain level of cumulative\nchange (budget). Our framework can also accommodate the estimation of\n(indirectly changeable) features whose values change as a consequence of\nactions taken. Furthermore, we propose two methods for specifying feature-value\nranges that result in different algorithmic behavior. We apply our method, and\na proposed sensitivity analysis-based benchmark method, to two freely available\ndatasets: Student Performance from the UCI Machine Learning Repository and a\nreal world cardiovascular disease dataset. The results obtained demonstrate the\nvalidity and benefits of our framework and method.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 21:50:25 GMT"}, {"version": "v2", "created": "Sat, 18 Feb 2017 22:30:53 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 18:27:39 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Lash", "Michael T.", ""], ["Lin", "Qihang", ""], ["Street", "W. Nick", ""], ["Robinson", "Jennifer G.", ""]]}, {"id": "1605.09080", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Animashree Anandkumar", "title": "Spectral Methods for Correlated Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose guaranteed spectral methods for learning a broad\nrange of topic models, which generalize the popular Latent Dirichlet Allocation\n(LDA). We overcome the limitation of LDA to incorporate arbitrary topic\ncorrelations, by assuming that the hidden topic proportions are drawn from a\nflexible class of Normalized Infinitely Divisible (NID) distributions. NID\ndistributions are generated through the process of normalizing a family of\nindependent Infinitely Divisible (ID) random variables. The Dirichlet\ndistribution is a special case obtained by normalizing a set of Gamma random\nvariables. We prove that this flexible topic model class can be learned via\nspectral methods using only moments up to the third order, with (low order)\npolynomial sample and computational complexity. The proof is based on a key new\ntechnique derived here that allows us to diagonalize the moments of the NID\ndistribution through an efficient procedure that requires evaluating only\nunivariate integrals, despite the fact that we are handling high dimensional\nmultivariate moments. In order to assess the performance of our proposed Latent\nNID topic model, we use two real datasets of articles collected from New York\nTimes and Pubmed. Our experiments yield improved perplexity on both datasets\ncompared with the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 00:32:11 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 14:30:11 GMT"}, {"version": "v3", "created": "Sun, 5 Jun 2016 08:27:34 GMT"}, {"version": "v4", "created": "Sat, 20 Aug 2016 01:44:30 GMT"}, {"version": "v5", "created": "Sun, 13 Nov 2016 20:24:02 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Arabshahi", "Forough", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1605.09082", "submitter": "Zhi-Hua Zhou", "authors": "Chenping Hou and Zhi-Hua Zhou", "title": "One-Pass Learning with Incremental and Decremental Features", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2018, 40(11): 2776-2792", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real tasks the features are evolving, with some features being\nvanished and some other features augmented. For example, in environment\nmonitoring some sensors expired whereas some new ones deployed; in mobile game\nrecommendation some games dropped whereas some new ones added. Learning with\nsuch incremental and decremental features is crucial but rarely studied,\nparticularly when the data coming like a stream and thus it is infeasible to\nkeep the whole data for optimization. In this paper, we study this challenging\nproblem and present the OPID approach. Our approach attempts to compress\nimportant information of vanished features into functions of survived features,\nand then expand to include the augmented features. It is the one-pass learning\napproach, which only needs to scan each instance once and does not need to\nstore the whole data, and thus satisfy the evolving streaming data nature. The\neffectiveness of our approach is validated theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 01:18:47 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Hou", "Chenping", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1605.09085", "submitter": "Matthew Blaschko", "authors": "Amal Rannen Triki and Matthew B. Blaschko", "title": "Stochastic Function Norm Regularization of Deep Networks", "comments": "arXiv admin note: text overlap with arXiv:1710.06703", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have had an enormous impact on image analysis.\nState-of-the-art training methods, based on weight decay and DropOut, result in\nimpressive performance when a very large training set is available. However,\nthey tend to have large problems overfitting to small data sets. Indeed, the\navailable regularization methods deal with the complexity of the network\nfunction only indirectly. In this paper, we study the feasibility of directly\nusing the $L_2$ function norm for regularization. Two methods to integrate this\nnew regularization in the stochastic backpropagation are proposed. Moreover,\nthe convergence of these new algorithms is studied. We finally show that they\noutperform the state-of-the-art methods in the low sample regime on benchmark\ndatasets (MNIST and CIFAR10). The obtained results demonstrate very clear\nimprovement, especially in the context of small sample regimes with data laying\nin a low dimensional manifold. Source code of the method can be found at\n\\url{https://github.com/AmalRT/DNN_Reg}.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 01:49:18 GMT"}, {"version": "v2", "created": "Wed, 7 Dec 2016 14:14:30 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 14:38:32 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Triki", "Amal Rannen", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "1605.09088", "submitter": "Bangrui Chen", "authors": "Bangrui Chen, Peter I. Frazier", "title": "The Bayesian Linear Information Filtering Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian sequential decision-making formulation of the\ninformation filtering problem, in which an algorithm presents items (news\narticles, scientific papers, tweets) arriving in a stream, and learns relevance\nfrom user feedback on presented items. We model user preferences using a\nBayesian linear model, similar in spirit to a Bayesian linear bandit. We\ncompute a computational upper bound on the value of the optimal policy, which\nallows computing an optimality gap for implementable policies. We then use this\nanalysis as motivation in introducing a pair of new Decompose-Then-Decide (DTD)\nheuristic policies, DTD-Dynamic-Programming (DTD-DP) and\nDTD-Upper-Confidence-Bound (DTD-UCB). We compare DTD-DP and DTD-UCB against\nseveral benchmarks on real and simulated data, demonstrating significant\nimprovement, and show that the achieved performance is close to the upper\nbound.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 02:35:07 GMT"}, {"version": "v2", "created": "Sat, 22 Oct 2016 18:48:14 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Chen", "Bangrui", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1605.09114", "submitter": "Miguel \\'A. Carreira-Perpi\\~n\\'an", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an and Mehdi Alizadeh", "title": "ParMAC: distributed optimisation of nested functions, with application\n  to learning binary autoencoders", "comments": "40 pages, 13 figures. The abstract appearing here is slightly shorter\n  than the one in the PDF file because of the arXiv's limitation of the\n  abstract field to 1920 characters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many powerful machine learning models are based on the composition of\nmultiple processing layers, such as deep nets, which gives rise to nonconvex\nobjective functions. A general, recent approach to optimise such \"nested\"\nfunctions is the method of auxiliary coordinates (MAC). MAC introduces an\nauxiliary coordinate for each data point in order to decouple the nested model\ninto independent submodels. This decomposes the optimisation into steps that\nalternate between training single layers and updating the coordinates. It has\nthe advantage that it reuses existing single-layer algorithms, introduces\nparallelism, and does not need to use chain-rule gradients, so it works with\nnondifferentiable layers. With large-scale problems, or when distributing the\ncomputation is necessary for faster training, the dataset may not fit in a\nsingle machine. It is then essential to limit the amount of communication\nbetween machines so it does not obliterate the benefit of parallelism. We\ndescribe a general way to achieve this, ParMAC. ParMAC works on a cluster of\nprocessing machines with a circular topology and alternates two steps until\nconvergence: one step trains the submodels in parallel using stochastic\nupdates, and the other trains the coordinates in parallel. Only submodel\nparameters, no data or coordinates, are ever communicated between machines.\nParMAC exhibits high parallelism, low communication overhead, and facilitates\ndata shuffling, load balancing, fault tolerance and streaming data processing.\nWe study the convergence of ParMAC and propose a theoretical model of its\nruntime and parallel speedup. We develop ParMAC to learn binary autoencoders\nfor fast, approximate image retrieval. We implement it in MPI in a distributed\nsystem and demonstrate nearly perfect speedups in a 128-processor cluster with\na training set of 100 million high-dimensional points.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 06:31:14 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Alizadeh", "Mehdi", ""]]}, {"id": "1605.09128", "submitter": "Junhyuk Oh", "authors": "Junhyuk Oh, Valliappa Chockalingam, Satinder Singh, Honglak Lee", "title": "Control of Memory, Active Perception, and Action in Minecraft", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new set of reinforcement learning (RL) tasks in\nMinecraft (a flexible 3D world). We then use these tasks to systematically\ncompare and contrast existing deep reinforcement learning (DRL) architectures\nwith our new memory-based DRL architectures. These tasks are designed to\nemphasize, in a controllable manner, issues that pose challenges for RL methods\nincluding partial observability (due to first-person visual observations),\ndelayed rewards, high-dimensional visual observations, and the need to use\nactive perception in a correct manner so as to perform well in the tasks. While\nthese tasks are conceptually simple to describe, by virtue of having all of\nthese challenges simultaneously they are difficult for current DRL\narchitectures. Additionally, we evaluate the generalization performance of the\narchitectures on environments not used during training. The experimental\nresults show that our new architectures generalize to unseen environments\nbetter than existing DRL architectures.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 07:40:13 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Oh", "Junhyuk", ""], ["Chockalingam", "Valliappa", ""], ["Singh", "Satinder", ""], ["Lee", "Honglak", ""]]}, {"id": "1605.09131", "submitter": "Zhi-Hua Zhou", "authors": "Xin Mu and Kai Ming Ting and Zhi-Hua Zhou", "title": "Classification under Streaming Emerging New Classes: A Solution using\n  Completely Random Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates an important problem in stream mining, i.e.,\nclassification under streaming emerging new classes or SENC. The common\napproach is to treat it as a classification problem and solve it using either a\nsupervised learner or a semi-supervised learner. We propose an alternative\napproach by using unsupervised learning as the basis to solve this problem. The\nSENC problem can be decomposed into three sub problems: detecting emerging new\nclasses, classifying for known classes, and updating models to enable\nclassification of instances of the new class and detection of more emerging new\nclasses. The proposed method employs completely random trees which have been\nshown to work well in unsupervised learning and supervised learning\nindependently in the literature. This is the first time, as far as we know,\nthat completely random trees are used as a single common core to solve all\nthree sub problems: unsupervised learning, supervised learning and model update\nin data streams. We show that the proposed unsupervised-learning-focused method\noften achieves significantly better outcomes than existing\nclassification-focused methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 07:57:41 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Mu", "Xin", ""], ["Ting", "Kai Ming", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1605.09136", "submitter": "Gianni Franchi Gianni Franchi", "authors": "Gianni Franchi, Jesus Angulo, and Dino Sejdinovic", "title": "Hyperspectral Image Classification with Support Vector Machines on\n  Kernel Distribution Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for pixel classification in hyperspectral images,\nleveraging on both the spatial and spectral information in the data. The\nintroduced method relies on a recently proposed framework for learning on\ndistributions -- by representing them with mean elements in reproducing kernel\nHilbert spaces (RKHS) and formulating a classification algorithm therein. In\nparticular, we associate each pixel to an empirical distribution of its\nneighbouring pixels, a judicious representation of which in an RKHS, in\nconjunction with the spectral information contained in the pixel itself, give a\nnew explicit set of features that can be fed into a suite of standard\nclassification techniques -- we opt for a well-established framework of support\nvector machines (SVM). Furthermore, the computational complexity is reduced via\nrandom Fourier features formalism. We study the consistency and the convergence\nrates of the proposed method and the experiments demonstrate strong performance\non hyperspectral data with gains in comparison to the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 08:26:28 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Franchi", "Gianni", ""], ["Angulo", "Jesus", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "1605.09186", "submitter": "Ozan \\c{C}a\\u{g}layan", "authors": "Ozan Caglayan, Walid Aransa, Yaxing Wang, Marc Masana, Mercedes\n  Garc\\'ia-Mart\\'inez, Fethi Bougares, Lo\\\"ic Barrault, Joost van de Weijer", "title": "Does Multimodality Help Human and Machine for Translation and Image\n  Captioning?", "comments": "7 pages, 2 figures, v4: Small clarification in section 4 title and\n  content", "journal-ref": null, "doi": "10.18653/v1/W16-2358", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the systems developed by LIUM and CVC for the WMT16\nMultimodal Machine Translation challenge. We explored various comparative\nmethods, namely phrase-based systems and attentional recurrent neural networks\nmodels trained using monomodal or multimodal data. We also performed a human\nevaluation in order to estimate the usefulness of multimodal data for human\nmachine translation and image description generation. Our systems obtained the\nbest results for both tasks according to the automatic evaluation metrics BLEU\nand METEOR.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 11:47:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 13:52:45 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 15:33:11 GMT"}, {"version": "v4", "created": "Tue, 16 Aug 2016 12:11:29 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Caglayan", "Ozan", ""], ["Aransa", "Walid", ""], ["Wang", "Yaxing", ""], ["Masana", "Marc", ""], ["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Bougares", "Fethi", ""], ["Barrault", "Lo\u00efc", ""], ["van de Weijer", "Joost", ""]]}, {"id": "1605.09196", "submitter": "S{\\o}ren Havelund Welling", "authors": "Soeren H. Welling, Hanne H.F. Refsgaard, Per B. Brockhoff, Line H.\n  Clemmensen", "title": "Forest Floor Visualizations of Random Forests", "comments": "25 pages, 12 figures, supplementary materials. v2->v3: minor\n  proofing, moderated comments on ICE-plots, replaced \\psi-operator with the\n  subset named H in equation 13 and 14 to improve simplicity", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel methodology, forest floor, to visualize and interpret\nrandom forest (RF) models. RF is a popular and useful tool for non-linear\nmulti-variate classification and regression, which yields a good trade-off\nbetween robustness (low variance) and adaptiveness (low bias). Direct\ninterpretation of a RF model is difficult, as the explicit ensemble model of\nhundreds of deep trees is complex. Nonetheless, it is possible to visualize a\nRF model fit by its mapping from feature space to prediction space. Hereby the\nuser is first presented with the overall geometrical shape of the model\nstructure, and when needed one can zoom in on local details. Dimensional\nreduction by projection is used to visualize high dimensional shapes. The\ntraditional method to visualize RF model structure, partial dependence plots,\nachieve this by averaging multiple parallel projections. We suggest to first\nuse feature contributions, a method to decompose trees by splitting features,\nand then subsequently perform projections. The advantages of forest floor over\npartial dependence plots is that interactions are not masked by averaging. As a\nconsequence, it is possible to locate interactions, which are not visualized in\na given projection. Furthermore, we introduce: a goodness-of-visualization\nmeasure, use of colour gradients to identify interactions and an out-of-bag\ncross validated variant of feature contributions.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 12:24:08 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 13:06:46 GMT"}, {"version": "v3", "created": "Mon, 4 Jul 2016 12:53:27 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Welling", "Soeren H.", ""], ["Refsgaard", "Hanne H. F.", ""], ["Brockhoff", "Per B.", ""], ["Clemmensen", "Line H.", ""]]}, {"id": "1605.09221", "submitter": "Timothy O'Shea", "authors": "Timothy J. O'Shea, T. Charles Clancy", "title": "Deep Reinforcement Learning Radio Control and Signal Detection with\n  KeRLym, a Gym RL Agent", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents research in progress investigating the viability and\nadaptation of reinforcement learning using deep neural network based function\napproximation for the task of radio control and signal detection in the\nwireless domain. We demonstrate a successful initial method for radio control\nwhich allows naive learning of search without the need for expert features,\nheuristics, or search strategies. We also introduce Kerlym, an open Keras based\nreinforcement learning agent collection for OpenAI's Gym.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 13:23:04 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["O'Shea", "Timothy J.", ""], ["Clancy", "T. Charles", ""]]}, {"id": "1605.09227", "submitter": "Colin White", "authors": "Maria-Florina Balcan, Ellen Vitercik, Colin White", "title": "Learning Combinatorial Functions from Pairwise Comparisons", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of work in machine learning has focused on the problem of\nlearning a close approximation to an underlying combinatorial function, given a\nsmall set of labeled examples. However, for real-valued functions, cardinal\nlabels might not be accessible, or it may be difficult for an expert to\nconsistently assign real-valued labels over the entire set of examples. For\ninstance, it is notoriously hard for consumers to reliably assign values to\nbundles of merchandise. Instead, it might be much easier for a consumer to\nreport which of two bundles she likes better. With this motivation in mind, we\nconsider an alternative learning model, wherein the algorithm must learn the\nunderlying function up to pairwise comparisons, from pairwise comparisons. In\nthis model, we present a series of novel algorithms that learn over a wide\nvariety of combinatorial function classes. These range from graph functions to\nbroad classes of valuation functions that are fundamentally important in\nmicroeconomic theory, the analysis of social networks, and machine learning,\nsuch as coverage, submodular, XOS, and subadditive functions, as well as\nfunctions with sparse Fourier support.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 13:38:47 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Vitercik", "Ellen", ""], ["White", "Colin", ""]]}, {"id": "1605.09232", "submitter": "Raja Giryes", "authors": "Raja Giryes and Yonina C. Eldar and Alex M. Bronstein and Guillermo\n  Sapiro", "title": "Tradeoffs between Convergence Speed and Reconstruction Accuracy in\n  Inverse Problems", "comments": "To appear in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems with iterative algorithms is popular, especially for\nlarge data. Due to time constraints, the number of possible iterations is\nusually limited, potentially affecting the achievable accuracy. Given an error\none is willing to tolerate, an important question is whether it is possible to\nmodify the original iterations to obtain faster convergence to a minimizer\nachieving the allowed error without increasing the computational cost of each\niteration considerably. Relying on recent recovery techniques developed for\nsettings in which the desired signal belongs to some low-dimensional set, we\nshow that using a coarse estimate of this set may lead to faster convergence at\nthe cost of an additional reconstruction error related to the accuracy of the\nset approximation. Our theory ties to recent advances in sparse recovery,\ncompressed sensing, and deep learning. Particularly, it may provide a possible\nexplanation to the successful approximation of the l1-minimization solution by\nneural networks with layers representing iterations, as practiced in the\nlearned iterative shrinkage-thresholding algorithm (LISTA).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 13:43:59 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 17:43:20 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 10:53:57 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Giryes", "Raja", ""], ["Eldar", "Yonina C.", ""], ["Bronstein", "Alex M.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1605.09293", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber and Chad Brown", "title": "Internal Guidance for Satallax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new internal guidance method for automated theorem provers based\non the given-clause algorithm. Our method influences the choice of unprocessed\nclauses using positive and negative examples from previous proofs. To this end,\nwe present an efficient scheme for Naive Bayesian classification by\ngeneralising label occurrences to types with monoid structure. This makes it\npossible to extend existing fast classifiers, which consider only positive\nexamples, with negative ones. We implement the method in the higher-order logic\nprover Satallax, where we modify the delay with which propositions are\nprocessed. We evaluated our method on a simply-typed higher-order logic version\nof the Flyspeck project, where it solves 26% more problems than Satallax\nwithout internal guidance.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:01:51 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Brown", "Chad", ""]]}, {"id": "1605.09299", "submitter": "Eirikur Agustsson", "authors": "Eirikur Agustsson, Radu Timofte and Luc Van Gool", "title": "k2-means for fast and accurate large scale clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose k^2-means, a new clustering method which efficiently copes with\nlarge numbers of clusters and achieves low energy solutions. k^2-means builds\nupon the standard k-means (Lloyd's algorithm) and combines a new strategy to\naccelerate the convergence with a new low time complexity divisive\ninitialization. The accelerated convergence is achieved through only looking at\nk_n nearest clusters and using triangle inequality bounds in the assignment\nstep while the divisive initialization employs an optimal 2-clustering along a\ndirection. The worst-case time complexity per iteration of our k^2-means is\nO(nk_nd+k^2d), where d is the dimension of the n data points and k is the\nnumber of clusters and usually n << k << k_n. Compared to k-means' O(nkd)\ncomplexity, our k^2-means complexity is significantly lower, at the expense of\nslightly increasing the memory complexity by O(nk_n+k^2). In our extensive\nexperiments k^2-means is order(s) of magnitude faster than standard methods in\ncomputing accurate clusterings on several standard datasets and settings with\nhundreds of clusters and high dimensional data. Moreover, the proposed divisive\ninitialization generally leads to clustering energies comparable to those\nachieved with the standard k-means++ initialization, while being significantly\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:17:45 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Agustsson", "Eirikur", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1605.09304", "submitter": "Anh Nguyen", "authors": "Anh Nguyen, Alexey Dosovitskiy, Jason Yosinski, Thomas Brox, Jeff\n  Clune", "title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks", "comments": "29 pages, 35 figures, NIPS camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:22:54 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 15:52:04 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 17:34:59 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2016 22:16:07 GMT"}, {"version": "v5", "created": "Wed, 23 Nov 2016 18:41:12 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Nguyen", "Anh", ""], ["Dosovitskiy", "Alexey", ""], ["Yosinski", "Jason", ""], ["Brox", "Thomas", ""], ["Clune", "Jeff", ""]]}, {"id": "1605.09332", "submitter": "Ludovic Trottier", "authors": "Ludovic Trottier, Philippe Gigu\\`ere, Brahim Chaib-draa", "title": "Parametric Exponential Linear Unit for Deep Convolutional Neural\n  Networks", "comments": "16th IEEE International Conference On Machine Learning And\n  Applications, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition is an important task for improving the ability of visual\nsystems to perform complex scene understanding. Recently, the Exponential\nLinear Unit (ELU) has been proposed as a key component for managing bias shift\nin Convolutional Neural Networks (CNNs), but defines a parameter that must be\nset by hand. In this paper, we propose learning a parameterization of ELU in\norder to learn the proper activation shape at each layer in the CNNs. Our\nresults on the MNIST, CIFAR-10/100 and ImageNet datasets using the NiN,\nOverfeat, All-CNN and ResNet networks indicate that our proposed Parametric ELU\n(PELU) has better performances than the non-parametric ELU. We have observed as\nmuch as a 7.28% relative error improvement on ImageNet with the NiN network,\nwith only 0.0003% parameter increase. Our visual examination of the non-linear\nbehaviors adopted by Vgg using PELU shows that the network took advantage of\nthe added flexibility by learning different activations at different layers.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 17:16:40 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 19:24:04 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2016 20:26:25 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 15:18:48 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Trottier", "Ludovic", ""], ["Gigu\u00e8re", "Philippe", ""], ["Chaib-draa", "Brahim", ""]]}, {"id": "1605.09346", "submitter": "Jean-Baptiste Alayrac", "authors": "Anton Osokin, Jean-Baptiste Alayrac, Isabella Lukasewitz, Puneet K.\n  Dokania, Simon Lacoste-Julien", "title": "Minding the Gaps for Block Frank-Wolfe Optimization of Structured SVMs", "comments": "Appears in Proceedings of the 33rd International Conference on\n  Machine Learning (ICML 2016). 31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several improvements on the block-coordinate\nFrank-Wolfe (BCFW) algorithm from Lacoste-Julien et al. (2013) recently used to\noptimize the structured support vector machine (SSVM) objective in the context\nof structured prediction, though it has wider applications. The key intuition\nbehind our improvements is that the estimates of block gaps maintained by BCFW\nreveal the block suboptimality that can be used as an adaptive criterion.\nFirst, we sample objects at each iteration of BCFW in an adaptive non-uniform\nway via gapbased sampling. Second, we incorporate pairwise and away-step\nvariants of Frank-Wolfe into the block-coordinate setting. Third, we cache\noracle calls with a cache-hit criterion based on the block gaps. Fourth, we\nprovide the first method to compute an approximate regularization path for\nSSVM. Finally, we provide an exhaustive empirical evaluation of all our methods\non four structured prediction datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 18:15:30 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Osokin", "Anton", ""], ["Alayrac", "Jean-Baptiste", ""], ["Lukasewitz", "Isabella", ""], ["Dokania", "Puneet K.", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1605.09351", "submitter": "Shehroz Khan", "authors": "Shehroz S. Khan, Jesse Hoey", "title": "Review of Fall Detection Techniques: A Data Availability Perspective", "comments": "30 pages, 1 figure, 3 Tables", "journal-ref": "Medical Engineering and Physics, Volume 39, 2017", "doi": "10.1016/j.medengphy.2016.10.014", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fall is an abnormal activity that occurs rarely; however, missing to\nidentify falls can have serious health and safety implications on an\nindividual. Due to the rarity of occurrence of falls, there may be insufficient\nor no training data available for them. Therefore, standard supervised machine\nlearning methods may not be directly applied to handle this problem. In this\npaper, we present a taxonomy for the study of fall detection from the\nperspective of availability of fall data. The proposed taxonomy is independent\nof the type of sensors used and specific feature extraction/selection methods.\nThe taxonomy identifies different categories of classification methods for the\nstudy of fall detection based on the availability of their data during training\nthe classifiers. Then, we present a comprehensive literature review within\nthose categories and identify the approach of treating a fall as an abnormal\nactivity to be a plausible research direction. We conclude our paper by\ndiscussing several open research problems in the field and pointers for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 18:45:06 GMT"}, {"version": "v2", "created": "Fri, 16 Sep 2016 21:17:24 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Khan", "Shehroz S.", ""], ["Hoey", "Jesse", ""]]}, {"id": "1605.09370", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Tobias Bischoff, Pietro Perona, Frederick\n  Eberhardt", "title": "Unsupervised Discovery of El Nino Using Causal Feature Learning on\n  Microlevel Climate Data", "comments": "Accepted for plenary presentation at UAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the climate phenomena of El Nino and La Nina arise naturally as\nstates of macro-variables when our recent causal feature learning framework\n(Chalupka 2015, Chalupka 2016) is applied to micro-level measures of zonal wind\n(ZW) and sea surface temperatures (SST) taken over the equatorial band of the\nPacific Ocean. The method identifies these unusual climate states on the basis\nof the relation between ZW and SST patterns without any input about past\noccurrences of El Nino or La Nina. The simpler alternatives of (i) clustering\nthe SST fields while disregarding their relationship with ZW patterns, or (ii)\nclustering the joint ZW-SST patterns, do not discover El Nino. We discuss the\ndegree to which our method supports a causal interpretation and use a\nlow-dimensional toy example to explain its success over other clustering\napproaches. Finally, we propose a new robust and scalable alternative to our\noriginal algorithm (Chalupka 2016), which circumvents the need for\nhigh-dimensional density learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 19:57:56 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Bischoff", "Tobias", ""], ["Perona", "Pietro", ""], ["Eberhardt", "Frederick", ""]]}, {"id": "1605.09410", "submitter": "Mengye Ren", "authors": "Mengye Ren, Richard S. Zemel", "title": "End-to-End Instance Segmentation with Recurrent Attention", "comments": "CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While convolutional neural networks have gained impressive success recently\nin solving structured prediction problems such as semantic segmentation, it\nremains a challenge to differentiate individual object instances in the scene.\nInstance segmentation is very important in a variety of applications, such as\nautonomous driving, image captioning, and visual question answering. Techniques\nthat combine large graphical models with low-level vision have been proposed to\naddress this problem; however, we propose an end-to-end recurrent neural\nnetwork (RNN) architecture with an attention mechanism to model a human-like\ncounting process, and produce detailed instance segmentations. The network is\njointly trained to sequentially produce regions of interest as well as a\ndominant object segmentation within each region. The proposed model achieves\ncompetitive results on the CVPPP, KITTI, and Cityscapes datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 20:40:20 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 15:09:06 GMT"}, {"version": "v3", "created": "Sun, 27 Nov 2016 17:41:57 GMT"}, {"version": "v4", "created": "Mon, 16 Jan 2017 23:08:35 GMT"}, {"version": "v5", "created": "Thu, 13 Jul 2017 00:53:33 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Ren", "Mengye", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1605.09432", "submitter": "Ramanathan Subramanian", "authors": "Ramanathan Subramanian, Romer Rosales, Glenn Fung, Jennifer Dy", "title": "Evaluating Crowdsourcing Participants in the Absence of Ground-Truth", "comments": "4 pages, 5 figures, Workshop on Human Computation for Science and\n  Computational Sustainability, NIPS 2012, Lake Tahoe, NV. 7 Dec 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a supervised/semi-supervised learning scenario where multiple\nannotators are available, we consider the problem of identification of\nadversarial or unreliable annotators.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 22:05:36 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Subramanian", "Ramanathan", ""], ["Rosales", "Romer", ""], ["Fung", "Glenn", ""], ["Dy", "Jennifer", ""]]}, {"id": "1605.09444", "submitter": "Harishchandra Dubey", "authors": "Harishchandra Dubey, A.K. Tiwari, Nandita, P.K. Ray, S.R. Mohanty and\n  Nand Kishor", "title": "A Novel Fault Classification Scheme Based on Least Square SVM", "comments": "5 Pages, 6 Figures, 3 Tables", "journal-ref": "Harishchandra Dubey etal., \"A novel fault classification scheme\n  based on least square SVM,\" Engineering and Systems (SCES), 2012 Students\n  Conference on, INDIA, 2012, pp. 1-5", "doi": "10.1109/SCES.2012.6199047", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for fault classification and section\nidentification in a series compensated transmission line based on least square\nsupport vector machine. The current signal corresponding to one-fourth of the\npost fault cycle is used as input to proposed modular LS-SVM classifier. The\nproposed scheme uses four binary classifier; three for selection of three\nphases and fourth for ground detection. The proposed classification scheme is\nfound to be accurate and reliable in presence of noise as well. The simulation\nresults validate the efficacy of proposed scheme for accurate classification of\nfault in a series compensated transmission line.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 23:11:00 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Dubey", "Harishchandra", ""], ["Tiwari", "A. K.", ""], ["Nandita", "", ""], ["Ray", "P. K.", ""], ["Mohanty", "S. R.", ""], ["Kishor", "Nand", ""]]}, {"id": "1605.09458", "submitter": "Hui Shen", "authors": "Hui Shen, Dehua Li, Hong Wu, Zhaoxiang Zang", "title": "Training Auto-encoders Effectively via Eliminating Task-irrelevant Input\n  Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoders are often used as building blocks of deep network classifier to\nlearn feature extractors, but task-irrelevant information in the input data may\nlead to bad extractors and result in poor generalization performance of the\nnetwork. In this paper,via dropping the task-irrelevant input variables the\nperformance of auto-encoders can be obviously improved .Specifically, an\nimportance-based variable selection method is proposed to aim at finding the\ntask-irrelevant input variables and dropping them.It firstly estimates\nimportance of each variable,and then drops the variables with importance value\nlower than a threshold. In order to obtain better performance, the method can\nbe employed for each layer of stacked auto-encoders. Experimental results show\nthat when combined with our method the stacked denoising auto-encoders achieves\nsignificantly improved performance on three challenging datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 00:58:47 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Shen", "Hui", ""], ["Li", "Dehua", ""], ["Wu", "Hong", ""], ["Zang", "Zhaoxiang", ""]]}, {"id": "1605.09477", "submitter": "Yin Zheng", "authors": "Yin Zheng, Bangsheng Tang, Wenkui Ding, Hanning Zhou", "title": "A Neural Autoregressive Approach to Collaborative Filtering", "comments": "Accepted by ICML2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes CF-NADE, a neural autoregressive architecture for\ncollaborative filtering (CF) tasks, which is inspired by the Restricted\nBoltzmann Machine (RBM) based CF model and the Neural Autoregressive\nDistribution Estimator (NADE). We first describe the basic CF-NADE model for CF\ntasks. Then we propose to improve the model by sharing parameters between\ndifferent ratings. A factored version of CF-NADE is also proposed for better\nscalability. Furthermore, we take the ordinal nature of the preferences into\nconsideration and propose an ordinal cost to optimize CF-NADE, which shows\nsuperior performance. Finally, CF-NADE can be extended to a deep model, with\nonly moderately increased computational complexity. Experimental results show\nthat CF-NADE with a single hidden layer beats all previous state-of-the-art\nmethods on MovieLens 1M, MovieLens 10M, and Netflix datasets, and adding more\nhidden layers can further improve the performance.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 03:07:06 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Zheng", "Yin", ""], ["Tang", "Bangsheng", ""], ["Ding", "Wenkui", ""], ["Zhou", "Hanning", ""]]}, {"id": "1605.09507", "submitter": "Yoonchang Han", "authors": "Yoonchang Han, Jaehun Kim, Kyogu Lee", "title": "Deep convolutional neural networks for predominant instrument\n  recognition in polyphonic music", "comments": "13 pages, 7 figures, accepted for publication in IEEE/ACM\n  Transactions on Audio, Speech, and Language Processing on 16-Nov-2016. This\n  is initial submission version. Fully edited version is available at\n  http://ieeexplore.ieee.org/document/7755799/", "journal-ref": "Published in: IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing ( Volume: 25, Issue: 1, Jan. 2017 ) Page(s): 208 - 221", "doi": "10.1109/TASLP.2016.2632307", "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying musical instruments in polyphonic music recordings is a\nchallenging but important problem in the field of music information retrieval.\nIt enables music search by instrument, helps recognize musical genres, or can\nmake music transcription easier and more accurate. In this paper, we present a\nconvolutional neural network framework for predominant instrument recognition\nin real-world polyphonic music. We train our network from fixed-length music\nexcerpts with a single-labeled predominant instrument and estimate an arbitrary\nnumber of predominant instruments from an audio signal with a variable length.\nTo obtain the audio-excerpt-wise result, we aggregate multiple outputs from\nsliding windows over the test audio. In doing so, we investigated two different\naggregation methods: one takes the average for each instrument and the other\ntakes the instrument-wise sum followed by normalization. In addition, we\nconducted extensive experiments on several important factors that affect the\nperformance, including analysis window size, identification threshold, and\nactivation functions for neural networks to find the optimal set of parameters.\nUsing a dataset of 10k audio excerpts from 11 instruments for evaluation, we\nfound that convolutional neural networks are more robust than conventional\nmethods that exploit spectral features and source separation with support\nvector machines. Experimental results showed that the proposed convolutional\nnetwork architecture obtained an F1 measure of 0.602 for micro and 0.503 for\nmacro, respectively, achieving 19.6% and 16.4% in performance improvement\ncompared with other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 07:11:18 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 08:54:57 GMT"}, {"version": "v3", "created": "Mon, 26 Dec 2016 12:29:26 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Han", "Yoonchang", ""], ["Kim", "Jaehun", ""], ["Lee", "Kyogu", ""]]}, {"id": "1605.09522", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard\n  Sch\\\"olkopf", "title": "Kernel Mean Embedding of Distributions: A Review and Beyond", "comments": "147 pages; this is the final version", "journal-ref": "Foundations and Trends in Machine Learning: Vol. 10: No. 1-2, pp\n  1-141 (2017)", "doi": "10.1561/2200000060", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Hilbert space embedding of a distribution---in short, a kernel mean\nembedding---has recently emerged as a powerful tool for machine learning and\ninference. The basic idea behind this framework is to map distributions into a\nreproducing kernel Hilbert space (RKHS) in which the whole arsenal of kernel\nmethods can be extended to probability measures. It can be viewed as a\ngeneralization of the original \"feature map\" common to support vector machines\n(SVMs) and other kernel methods. While initially closely associated with the\nlatter, it has meanwhile found application in fields ranging from kernel\nmachines and probabilistic modeling to statistical inference, causal discovery,\nand deep learning. The goal of this survey is to give a comprehensive review of\nexisting work and recent advances in this research area, and to discuss the\nmost challenging issues and open problems that could lead to new research\ndirections. The survey begins with a brief introduction to the RKHS and\npositive definite kernels which forms the backbone of this survey, followed by\na thorough discussion of the Hilbert space embedding of marginal distributions,\ntheoretical guarantees, and a review of its applications. The embedding of\ndistributions enables us to apply RKHS methods to probability measures which\nprompts a wide range of applications such as kernel two-sample testing,\nindependent testing, and learning on distributional data. Next, we discuss the\nHilbert space embedding for conditional distributions, give theoretical\ninsights, and review some applications. The conditional mean embedding enables\nus to perform sum, product, and Bayes' rules---which are ubiquitous in\ngraphical model, probabilistic inference, and reinforcement learning---in a\nnon-parametric way. We then discuss relationships between this framework and\nother related areas. Lastly, we give some suggestions on future research\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 08:23:33 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 04:25:09 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2017 15:05:47 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 12:45:23 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Muandet", "Krikamol", ""], ["Fukumizu", "Kenji", ""], ["Sriperumbudur", "Bharath", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1605.09533", "submitter": "Matthias Limmer", "authors": "Matthias Limmer, Julian Forster, Dennis Baudach, Florian Sch\\\"ule,\n  Roland Schweiger, Hendrik P.A. Lensch", "title": "Robust Deep-Learning-Based Road-Prediction for Augmented Reality\n  Navigation Systems", "comments": "8 pages, 12 figures, submitted to ITSC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an approach that predicts the road course from camera\nsensors leveraging deep learning techniques. Road pixels are identified by\ntraining a multi-scale convolutional neural network on a large number of\nfull-scene-labeled night-time road images including adverse weather conditions.\nA framework is presented that applies the proposed approach to longer distance\nroad course estimation, which is the basis for an augmented reality navigation\napplication. In this framework long range sensor data (radar) and data from a\nmap database are fused with short range sensor data (camera) to produce a\nprecise longitudinal and lateral localization and road course estimation. The\nproposed approach reliably detects roads with and without lane markings and\nthus increases the robustness and availability of road course estimations and\naugmented reality navigation. Evaluations on an extensive set of high precision\nground truth data taken from a differential GPS and an inertial measurement\nunit show that the proposed approach reaches state-of-the-art performance\nwithout the limitation of requiring existing lane markings.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 09:00:33 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Limmer", "Matthias", ""], ["Forster", "Julian", ""], ["Baudach", "Dennis", ""], ["Sch\u00fcle", "Florian", ""], ["Schweiger", "Roland", ""], ["Lensch", "Hendrik P. A.", ""]]}, {"id": "1605.09553", "submitter": "Chenxi Liu", "authors": "Chenxi Liu, Junhua Mao, Fei Sha, Alan Yuille", "title": "Attention Correctness in Neural Image Captioning", "comments": "To appear in AAAI-17. See http://www.cs.jhu.edu/~cxliu/ for\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have recently been introduced in deep learning for\nvarious tasks in natural language processing and computer vision. But despite\ntheir popularity, the \"correctness\" of the implicitly-learned attention maps\nhas only been assessed qualitatively by visualization of several examples. In\nthis paper we focus on evaluating and improving the correctness of attention in\nneural image captioning models. Specifically, we propose a quantitative\nevaluation metric for the consistency between the generated attention maps and\nhuman annotations, using recently released datasets with alignment between\nregions in images and entities in captions. We then propose novel models with\ndifferent levels of explicit supervision for learning attention maps during\ntraining. The supervision can be strong when alignment between regions and\ncaption entities are available, or weak when only object segments and\ncategories are provided. We show on the popular Flickr30k and COCO datasets\nthat introducing supervision of attention maps during training solidly improves\nboth attention correctness and caption quality, showing the promise of making\nmachine perception more human-like.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 10:04:20 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 07:29:46 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Liu", "Chenxi", ""], ["Mao", "Junhua", ""], ["Sha", "Fei", ""], ["Yuille", "Alan", ""]]}, {"id": "1605.09593", "submitter": "Yasutoshi Ida", "authors": "Yasutoshi Ida, Yasuhiro Fujiwara, Sotetsu Iwamura", "title": "Adaptive Learning Rate via Covariance Matrix Based Preconditioning for\n  Deep Neural Networks", "comments": "Accepted at IJCAI 2017", "journal-ref": null, "doi": "10.24963/ijcai.2017/267", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive learning rate algorithms such as RMSProp are widely used for\ntraining deep neural networks. RMSProp offers efficient training since it uses\nfirst order gradients to approximate Hessian-based preconditioning. However,\nsince the first order gradients include noise caused by stochastic\noptimization, the approximation may be inaccurate. In this paper, we propose a\nnovel adaptive learning rate algorithm called SDProp. Its key idea is effective\nhandling of the noise by preconditioning based on covariance matrix. For\nvarious neural networks, our approach is more efficient and effective than\nRMSProp and its variant.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 12:11:51 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 10:24:50 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Ida", "Yasutoshi", ""], ["Fujiwara", "Yasuhiro", ""], ["Iwamura", "Sotetsu", ""]]}, {"id": "1605.09619", "submitter": "Mario Lucic", "authors": "Mario Lucic and Olivier Bachem and Morteza Zadimoghaddam and Andreas\n  Krause", "title": "Horizontally Scalable Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of large-scale machine learning problems can be cast as instances\nof constrained submodular maximization. Existing approaches for distributed\nsubmodular maximization have a critical drawback: The capacity - number of\ninstances that can fit in memory - must grow with the data set size. In\npractice, while one can provision many machines, the capacity of each machine\nis limited by physical constraints. We propose a truly scalable approach for\ndistributed submodular maximization under fixed capacity. The proposed\nframework applies to a broad class of algorithms and constraints and provides\ntheoretical guarantees on the approximation factor for any available capacity.\nWe empirically evaluate the proposed algorithm on a variety of data sets and\ndemonstrate that it achieves performance competitive with the centralized\ngreedy solution.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 13:18:30 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Lucic", "Mario", ""], ["Bachem", "Olivier", ""], ["Zadimoghaddam", "Morteza", ""], ["Krause", "Andreas", ""]]}, {"id": "1605.09646", "submitter": "Quentin Berthet", "authors": "Tengyao Wang, Quentin Berthet, Yaniv Plan", "title": "Average-case Hardness of RIP Certification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted isometry property (RIP) for design matrices gives guarantees\nfor optimal recovery in sparse linear models. It is of high interest in\ncompressed sensing and statistical learning. This property is particularly\nimportant for computationally efficient recovery methods. As a consequence,\neven though it is in general NP-hard to check that RIP holds, there have been\nsubstantial efforts to find tractable proxies for it. These would allow the\nconstruction of RIP matrices and the polynomial-time verification of RIP given\nan arbitrary matrix. We consider the framework of average-case certifiers, that\nnever wrongly declare that a matrix is RIP, while being often correct for\nrandom instances. While there are such functions which are tractable in a\nsuboptimal parameter regime, we show that this is a computationally hard task\nin any better regime. Our results are based on a new, weaker assumption on the\nproblem of detecting dense subgraphs.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 14:38:03 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Wang", "Tengyao", ""], ["Berthet", "Quentin", ""], ["Plan", "Yaniv", ""]]}, {"id": "1605.09673", "submitter": "Xu Jia", "authors": "Bert De Brabandere, Xu Jia, Tinne Tuytelaars, Luc Van Gool", "title": "Dynamic Filter Networks", "comments": "submitted to NIPS16; X. Jia and B. De Brabandere contributed equally\n  to this work and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a traditional convolutional layer, the learned filters stay fixed after\ntraining. In contrast, we introduce a new framework, the Dynamic Filter\nNetwork, where filters are generated dynamically conditioned on an input. We\nshow that this architecture is a powerful one, with increased flexibility\nthanks to its adaptive nature, yet without an excessive increase in the number\nof model parameters. A wide variety of filtering operations can be learned this\nway, including local spatial transformations, but also others like selective\n(de)blurring or adaptive feature extraction. Moreover, multiple such layers can\nbe combined, e.g. in a recurrent architecture. We demonstrate the effectiveness\nof the dynamic filter network on the tasks of video and stereo prediction, and\nreach state-of-the-art performance on the moving MNIST dataset with a much\nsmaller model. By visualizing the learned filters, we illustrate that the\nnetwork has picked up flow information by only looking at unlabelled training\ndata. This suggests that the network can be used to pretrain networks for\nvarious supervised tasks in an unsupervised way, like optical flow and depth\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 15:29:36 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 15:39:10 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["De Brabandere", "Bert", ""], ["Jia", "Xu", ""], ["Tuytelaars", "Tinne", ""], ["Van Gool", "Luc", ""]]}, {"id": "1605.09674", "submitter": "Rein Houthooft", "authors": "Rein Houthooft, Xi Chen, Yan Duan, John Schulman, Filip De Turck,\n  Pieter Abbeel", "title": "VIME: Variational Information Maximizing Exploration", "comments": "Published in Advances in Neural Information Processing Systems 29\n  (NIPS), pages 1109-1117", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable and effective exploration remains a key challenge in reinforcement\nlearning (RL). While there are methods with optimality guarantees in the\nsetting of discrete state and action spaces, these methods cannot be applied in\nhigh-dimensional deep RL scenarios. As such, most contemporary RL relies on\nsimple heuristics such as epsilon-greedy exploration or adding Gaussian noise\nto the controls. This paper introduces Variational Information Maximizing\nExploration (VIME), an exploration strategy based on maximization of\ninformation gain about the agent's belief of environment dynamics. We propose a\npractical implementation, using variational inference in Bayesian neural\nnetworks which efficiently handles continuous state and action spaces. VIME\nmodifies the MDP reward function, and can be applied with several different\nunderlying RL algorithms. We demonstrate that VIME achieves significantly\nbetter performance compared to heuristic exploration methods across a variety\nof continuous control tasks and algorithms, including tasks with very sparse\nrewards.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 15:34:36 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 18:25:42 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 12:58:44 GMT"}, {"version": "v4", "created": "Fri, 27 Jan 2017 09:26:28 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Houthooft", "Rein", ""], ["Chen", "Xi", ""], ["Duan", "Yan", ""], ["Schulman", "John", ""], ["De Turck", "Filip", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1605.09696", "submitter": "Guanqun Cao Mr", "authors": "Guanqun Cao, Alexandros Iosifidis, Ke Chen, Moncef Gabbouj", "title": "Generalized Multi-view Embedding for Visual Recognition and Cross-modal\n  Retrieval", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2017.2742705", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of multi-view embedding from different visual cues\nand modalities is considered. We propose a unified solution for subspace\nlearning methods using the Rayleigh quotient, which is extensible for multiple\nviews, supervised learning, and non-linear embeddings. Numerous methods\nincluding Canonical Correlation Analysis, Partial Least Sqaure regression and\nLinear Discriminant Analysis are studied using specific intrinsic and penalty\ngraphs within the same framework. Non-linear extensions based on kernels and\n(deep) neural networks are derived, achieving better performance than the\nlinear ones. Moreover, a novel Multi-view Modular Discriminant Analysis (MvMDA)\nis proposed by taking the view difference into consideration. We demonstrate\nthe effectiveness of the proposed multi-view embedding methods on visual object\nrecognition and cross-modal image retrieval, and obtain superior results in\nboth applications compared to related methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 16:11:16 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 15:58:20 GMT"}, {"version": "v3", "created": "Thu, 31 Aug 2017 09:17:50 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Cao", "Guanqun", ""], ["Iosifidis", "Alexandros", ""], ["Chen", "Ke", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1605.09721", "submitter": "Dimitris Papailiopoulos", "authors": "Xinghao Pan, Maximilian Lam, Stephen Tu, Dimitris Papailiopoulos, Ce\n  Zhang, Michael I. Jordan, Kannan Ramchandran, Chris Re, Benjamin Recht", "title": "CYCLADES: Conflict-free Asynchronous Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CYCLADES, a general framework for parallelizing stochastic\noptimization algorithms in a shared memory setting. CYCLADES is asynchronous\nduring shared model updates, and requires no memory locking mechanisms, similar\nto HOGWILD!-type algorithms. Unlike HOGWILD!, CYCLADES introduces no conflicts\nduring the parallel execution, and offers a black-box analysis for provable\nspeedups across a large family of algorithms. Due to its inherent conflict-free\nnature and cache locality, our multi-core implementation of CYCLADES\nconsistently outperforms HOGWILD!-type algorithms on sufficiently sparse\ndatasets, leading to up to 40% speedup gains compared to the HOGWILD!\nimplementation of SGD, and up to 5x gains over asynchronous implementations of\nvariance reduction algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 17:15:01 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Pan", "Xinghao", ""], ["Lam", "Maximilian", ""], ["Tu", "Stephen", ""], ["Papailiopoulos", "Dimitris", ""], ["Zhang", "Ce", ""], ["Jordan", "Michael I.", ""], ["Ramchandran", "Kannan", ""], ["Re", "Chris", ""], ["Recht", "Benjamin", ""]]}, {"id": "1605.09774", "submitter": "Ioannis Mitliagkas", "authors": "Ioannis Mitliagkas, Ce Zhang, Stefan Hadjis, Christopher R\\'e", "title": "Asynchrony begets Momentum, with an Application to Deep Learning", "comments": "Full version of a paper published in Annual Allerton Conference on\n  Communication, Control, and Computing (Allerton) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous methods are widely used in deep learning, but have limited\ntheoretical justification when applied to non-convex problems. We show that\nrunning stochastic gradient descent (SGD) in an asynchronous manner can be\nviewed as adding a momentum-like term to the SGD iteration. Our result does not\nassume convexity of the objective function, so it is applicable to deep\nlearning systems. We observe that a standard queuing model of asynchrony\nresults in a form of momentum that is commonly used by deep learning\npractitioners. This forges a link between queuing theory and asynchrony in deep\nlearning systems, which could be useful for systems builders. For convolutional\nneural networks, we experimentally validate that the degree of asynchrony\ndirectly correlates with the momentum, confirming our main result. An important\nimplication is that tuning the momentum parameter is important when considering\ndifferent levels of asynchrony. We assert that properly tuned momentum reduces\nthe number of steps required for convergence. Finally, our theory suggests new\nways of counteracting the adverse effects of asynchrony: a simple mechanism\nlike using negative algorithmic momentum can improve performance under high\nasynchrony. Since asynchronous methods have better hardware efficiency, this\nresult may shed light on when asynchronous execution is more efficient for deep\nlearning systems.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 19:16:56 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2016 12:00:28 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Mitliagkas", "Ioannis", ""], ["Zhang", "Ce", ""], ["Hadjis", "Stefan", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1605.09782", "submitter": "Jeff Donahue", "authors": "Jeff Donahue, Philipp Kr\\\"ahenb\\\"uhl, Trevor Darrell", "title": "Adversarial Feature Learning", "comments": "Published as a conference paper at ICLR 2017. Changelog: (v7) Table 2\n  results improved 1-2% due to averaging predictions over 10 crops at test\n  time, as done in Noroozi & Favaro; Table 3 VOC classification results\n  slightly improved due to minor bugfix. (See v6 changelog for previous\n  versions.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 19:37:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 19:52:42 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2016 03:25:03 GMT"}, {"version": "v4", "created": "Fri, 4 Nov 2016 18:40:47 GMT"}, {"version": "v5", "created": "Fri, 6 Jan 2017 02:49:57 GMT"}, {"version": "v6", "created": "Mon, 9 Jan 2017 05:38:18 GMT"}, {"version": "v7", "created": "Mon, 3 Apr 2017 20:34:36 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Donahue", "Jeff", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Darrell", "Trevor", ""]]}]