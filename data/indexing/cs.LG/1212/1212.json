[{"id": "1212.0139", "submitter": "Alexandre Chotard", "authors": "Alexandre Chotard (INRIA Saclay - Ile de France, LRI), Anne Auger\n  (INRIA Saclay - Ile de France), Nikolaus Hansen (INRIA Saclay - Ile de\n  France)", "title": "Cumulative Step-size Adaptation on Linear Functions", "comments": "arXiv admin note: substantial text overlap with arXiv:1206.1208", "journal-ref": "PPSN 2012 (2012) 72-81", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CSA-ES is an Evolution Strategy with Cumulative Step size Adaptation,\nwhere the step size is adapted measuring the length of a so-called cumulative\npath. The cumulative path is a combination of the previous steps realized by\nthe algorithm, where the importance of each step decreases with time. This\narticle studies the CSA-ES on composites of strictly increasing functions with\naffine linear functions through the investigation of its underlying Markov\nchains. Rigorous results on the change and the variation of the step size are\nderived with and without cumulation. The step-size diverges geometrically fast\nin most cases. Furthermore, the influence of the cumulation parameter is\nstudied.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 17:46:34 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Chotard", "Alexandre", "", "INRIA Saclay - Ile de France, LRI"], ["Auger", "Anne", "", "INRIA Saclay - Ile de France"], ["Hansen", "Nikolaus", "", "INRIA Saclay - Ile de\n  France"]]}, {"id": "1212.0142", "submitter": "Pierre Sermanet", "authors": "Pierre Sermanet and Koray Kavukcuoglu and Soumith Chintala and Yann\n  LeCun", "title": "Pedestrian Detection with Unsupervised Multi-Stage Feature Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian detection is a problem of considerable practical interest. Adding\nto the list of successful applications of deep learning methods to vision, we\nreport state-of-the-art and competitive results on all major pedestrian\ndatasets with a convolutional network model. The model uses a few new twists,\nsuch as multi-stage features, connections that skip layers to integrate global\nshape information with local distinctive motif information, and an unsupervised\nmethod based on convolutional sparse coding to pre-train the filters at each\nstage.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 18:13:03 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2013 18:05:46 GMT"}], "update_date": "2013-04-03", "authors_parsed": [["Sermanet", "Pierre", ""], ["Kavukcuoglu", "Koray", ""], ["Chintala", "Soumith", ""], ["LeCun", "Yann", ""]]}, {"id": "1212.0171", "submitter": "Nicholas Ruozzi", "authors": "Nicholas Ruozzi and Sekhar Tatikonda", "title": "Message-Passing Algorithms for Quadratic Minimization", "comments": null, "journal-ref": "Journal of Machine Learning Research. 14 (Aug) :2287-2314, 2013", "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian belief propagation (GaBP) is an iterative algorithm for computing\nthe mean of a multivariate Gaussian distribution, or equivalently, the minimum\nof a multivariate positive definite quadratic function. Sufficient conditions,\nsuch as walk-summability, that guarantee the convergence and correctness of\nGaBP are known, but GaBP may fail to converge to the correct solution given an\narbitrary positive definite quadratic function. As was observed in previous\nwork, the GaBP algorithm fails to converge if the computation trees produced by\nthe algorithm are not positive definite. In this work, we will show that the\nfailure modes of the GaBP algorithm can be understood via graph covers, and we\nprove that a parameterized generalization of the min-sum algorithm can be used\nto ensure that the computation trees remain positive definite whenever the\ninput matrix is positive definite. We demonstrate that the resulting algorithm\nis closely related to other iterative schemes for quadratic minimization such\nas the Gauss-Seidel and Jacobi algorithms. Finally, we observe, empirically,\nthat there always exists a choice of parameters such that the above\ngeneralization of the GaBP algorithm converges.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 00:34:04 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Ruozzi", "Nicholas", ""], ["Tatikonda", "Sekhar", ""]]}, {"id": "1212.0388", "submitter": "Loc Tran H", "authors": "Loc Tran", "title": "Hypergraph and protein function prediction with gene expression data", "comments": "12 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1211.4289", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most network-based protein (or gene) function prediction methods are based on\nthe assumption that the labels of two adjacent proteins in the network are\nlikely to be the same. However, assuming the pairwise relationship between\nproteins or genes is not complete, the information a group of genes that show\nvery similar patterns of expression and tend to have similar functions (i.e.\nthe functional modules) is missed. The natural way overcoming the information\nloss of the above assumption is to represent the gene expression data as the\nhypergraph. Thus, in this paper, the three un-normalized, random walk, and\nsymmetric normalized hypergraph Laplacian based semi-supervised learning\nmethods applied to hypergraph constructed from the gene expression data in\norder to predict the functions of yeast proteins are introduced. Experiment\nresults show that the average accuracy performance measures of these three\nhypergraph Laplacian based semi-supervised learning methods are the same.\nHowever, their average accuracy performance measures of these three methods are\nmuch greater than the average accuracy performance measures of un-normalized\ngraph Laplacian based semi-supervised learning method (i.e. the baseline method\nof this paper) applied to gene co-expression network created from the gene\nexpression data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 13:53:39 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Tran", "Loc", ""]]}, {"id": "1212.0463", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald and Cosma Rohilla Shalizi and Mark Schervish", "title": "Nonparametric risk bounds for time-series forecasting", "comments": "34 pages, 3 figures", "journal-ref": "Journal of Machine Learning Research. (2017). Vol 18. p. 1-40", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive generalization error bounds for traditional time-series forecasting\nmodels. Our results hold for many standard forecasting tools including\nautoregressive models, moving average models, and, more generally, linear\nstate-space models. These non-asymptotic bounds need only weak assumptions on\nthe data-generating process, yet allow forecasters to select among competing\nmodels and to guarantee, with high probability, that their chosen model will\nperform well. We motivate our techniques with and apply them to standard\neconomic and financial forecasting tools---a GARCH model for predicting equity\nvolatility and a dynamic stochastic general equilibrium model (DSGE), the\nstandard tool in macroeconomic forecasting. We demonstrate in particular how\nour techniques can aid forecasters and policy makers in choosing models which\nbehave well under uncertainty and mis-specification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 17:42:45 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 20:05:05 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["McDonald", "Daniel J.", ""], ["Shalizi", "Cosma Rohilla", ""], ["Schervish", "Mark", ""]]}, {"id": "1212.0467", "submitter": "Praneeth Netrapalli", "authors": "Prateek Jain, Praneeth Netrapalli and Sujay Sanghavi", "title": "Low-rank Matrix Completion using Alternating Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating minimization represents a widely applicable and empirically\nsuccessful approach for finding low-rank matrices that best fit the given data.\nFor example, for the problem of low-rank matrix completion, this method is\nbelieved to be one of the most accurate and efficient, and formed a major\ncomponent of the winning entry in the Netflix Challenge.\n  In the alternating minimization approach, the low-rank target matrix is\nwritten in a bi-linear form, i.e. $X = UV^\\dag$; the algorithm then alternates\nbetween finding the best $U$ and the best $V$. Typically, each alternating step\nin isolation is convex and tractable. However the overall problem becomes\nnon-convex and there has been almost no theoretical understanding of when this\napproach yields a good result.\n  In this paper we present first theoretical analysis of the performance of\nalternating minimization for matrix completion, and the related problem of\nmatrix sensing. For both these problems, celebrated recent results have shown\nthat they become well-posed and tractable once certain (now standard)\nconditions are imposed on the problem. We show that alternating minimization\nalso succeeds under similar conditions. Moreover, compared to existing results,\nour paper shows that alternating minimization guarantees faster (in particular,\ngeometric) convergence to the true matrix, while allowing a simpler analysis.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 17:57:50 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1212.0504", "submitter": "Michael Menden", "authors": "Michael P. Menden, Francesco Iorio, Mathew Garnett, Ultan McDermott,\n  Cyril Benes, Pedro J. Ballester, Julio Saez-Rodriguez", "title": "Machine learning prediction of cancer cell sensitivity to drugs based on\n  genomic and chemical properties", "comments": "26 pages, 7 figures, including supplemental information, presented by\n  Michael Menden at the 5th annual RECOMB Conference on Regulatory and Systems\n  Genomics with DREAM Challenges; accepted in PLOS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0061318", "report-no": null, "categories": "q-bio.GN cs.CE cs.LG q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the response of a specific cancer to a therapy is a major goal in\nmodern oncology that should ultimately lead to a personalised treatment.\nHigh-throughput screenings of potentially active compounds against a panel of\ngenomically heterogeneous cancer cell lines have unveiled multiple\nrelationships between genomic alterations and drug responses. Various\ncomputational approaches have been proposed to predict sensitivity based on\ngenomic features, while others have used the chemical properties of the drugs\nto ascertain their effect. In an effort to integrate these complementary\napproaches, we developed machine learning models to predict the response of\ncancer cell lines to drug treatment, quantified through IC50 values, based on\nboth the genomic features of the cell lines and the chemical properties of the\nconsidered drugs. Models predicted IC50 values in a 8-fold cross-validation and\nan independent blind test with coefficient of determination R2 of 0.72 and 0.64\nrespectively. Furthermore, models were able to predict with comparable accuracy\n(R2 of 0.61) IC50s of cell lines from a tissue not used in the training stage.\nOur in silico models can be used to optimise the experimental design of\ndrug-cell screenings by estimating a large proportion of missing IC50 values\nrather than experimentally measure them. The implications of our results go\nbeyond virtual drug screening design: potentially thousands of drugs could be\nprobed in silico to systematically test their potential efficacy as anti-tumour\nagents based on their structure, thus providing a computational framework to\nidentify new drug repositioning opportunities as well as ultimately be useful\nfor personalized medicine by linking the genomic traits of patients to drug\nsensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 19:38:09 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 15:10:37 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2013 18:07:47 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Menden", "Michael P.", ""], ["Iorio", "Francesco", ""], ["Garnett", "Mathew", ""], ["McDermott", "Ultan", ""], ["Benes", "Cyril", ""], ["Ballester", "Pedro J.", ""], ["Saez-Rodriguez", "Julio", ""]]}, {"id": "1212.0692", "submitter": "Roberto Amadini", "authors": "Roberto Amadini, Maurizio Gabbrielli, Jacopo Mauro", "title": "An Empirical Evaluation of Portfolios Approaches for solving CSPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in areas such as SAT solving and Integer Linear Programming\nhas shown that the performances of a single arbitrarily efficient solver can be\nsignificantly outperformed by a portfolio of possibly slower on-average\nsolvers. We report an empirical evaluation and comparison of portfolio\napproaches applied to Constraint Satisfaction Problems (CSPs). We compared\nmodels developed on top of off-the-shelf machine learning algorithms with\nrespect to approaches used in the SAT field and adapted for CSPs, considering\ndifferent portfolio sizes and using as evaluation metrics the number of solved\nproblems and the time taken to solve them. Results indicate that the best SAT\napproaches have top performances also in the CSP field and are slightly more\ncompetitive than simple models built on top of classification algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 12:00:54 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2014 02:25:04 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Amadini", "Roberto", ""], ["Gabbrielli", "Maurizio", ""], ["Mauro", "Jacopo", ""]]}, {"id": "1212.0695", "submitter": "Emanuele Frandi", "authors": "Emanuele Frandi, Ricardo Nanculef, Maria Grazia Gasparo, Stefano Lodi,\n  Claudio Sartori", "title": "Training Support Vector Machines Using Frank-Wolfe Optimization Methods", "comments": null, "journal-ref": "International Journal on Pattern Recognition and Artificial\n  Intelligence, 27(3), 2013", "doi": "10.1142/S0218001413600033", "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a Support Vector Machine (SVM) requires the solution of a quadratic\nprogramming problem (QP) whose computational complexity becomes prohibitively\nexpensive for large scale datasets. Traditional optimization methods cannot be\ndirectly applied in these cases, mainly due to memory restrictions.\n  By adopting a slightly different objective function and under mild conditions\non the kernel used within the model, efficient algorithms to train SVMs have\nbeen devised under the name of Core Vector Machines (CVMs). This framework\nexploits the equivalence of the resulting learning problem with the task of\nbuilding a Minimal Enclosing Ball (MEB) problem in a feature space, where data\nis implicitly embedded by a kernel function.\n  In this paper, we improve on the CVM approach by proposing two novel methods\nto build SVMs based on the Frank-Wolfe algorithm, recently revisited as a fast\nmethod to approximate the solution of a MEB problem. In contrast to CVMs, our\nalgorithms do not require to compute the solutions of a sequence of\nincreasingly complex QPs and are defined by using only analytic optimization\nsteps. Experiments on a large collection of datasets show that our methods\nscale better than CVMs in most cases, sometimes at the price of a slightly\nlower accuracy. As CVMs, the proposed methods can be easily extended to machine\nlearning problems other than binary classification. However, effective\nclassifiers are also obtained using kernels which do not satisfy the condition\nrequired by CVMs and can thus be used for a wider set of problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 12:05:31 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Frandi", "Emanuele", ""], ["Nanculef", "Ricardo", ""], ["Gasparo", "Maria Grazia", ""], ["Lodi", "Stefano", ""], ["Sartori", "Claudio", ""]]}, {"id": "1212.0763", "submitter": "Modou Gueye M.", "authors": "Modou Gueye, Talel Abdessalem, Hubert Naacke", "title": "Dynamic recommender system : using cluster-based biases to improve the\n  accuracy of the predictions", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is today accepted that matrix factorization models allow a high quality of\nrating prediction in recommender systems. However, a major drawback of matrix\nfactorization is its static nature that results in a progressive declining of\nthe accuracy of the predictions after each factorization. This is due to the\nfact that the new obtained ratings are not taken into account until a new\nfactorization is computed, which can not be done very often because of the high\ncost of matrix factorization.\n  In this paper, aiming at improving the accuracy of recommender systems, we\npropose a cluster-based matrix factorization technique that enables online\nintegration of new ratings. Thus, we significantly enhance the obtained\npredictions between two matrix factorizations. We use finer-grained user biases\nby clustering similar items into groups, and allocating in these groups a bias\nto each user. The experiments we did on large datasets demonstrated the\nefficiency of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 13:00:27 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Gueye", "Modou", ""], ["Abdessalem", "Talel", ""], ["Naacke", "Hubert", ""]]}, {"id": "1212.0901", "submitter": "Razvan Pascanu", "authors": "Yoshua Bengio, Nicolas Boulanger-Lewandowski and Razvan Pascanu", "title": "Advances in Optimizing Recurrent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a more than decade-long period of relatively little research activity\nin the area of recurrent neural networks, several new developments will be\nreviewed here that have allowed substantial progress both in understanding and\nin technical solutions towards more efficient training of recurrent networks.\nThese advances have been motivated by and related to the optimization issues\nsurrounding deep learning. Although recurrent networks are extremely powerful\nin what they can in principle represent in terms of modelling sequences,their\ntraining is plagued by two aspects of the same issue regarding the learning of\nlong-term dependencies. Experiments reported here evaluate the use of clipping\ngradients, spanning longer time ranges with leaky integration, advanced\nmomentum techniques, using more powerful output probability models, and\nencouraging sparser gradients to help symmetry breaking and credit assignment.\nThe experiments are performed on text and music data and show off the combined\neffects of these techniques in generally improving both training and test\nerror.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 23:25:34 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2012 01:44:53 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Bengio", "Yoshua", ""], ["Boulanger-Lewandowski", "Nicolas", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1212.0945", "submitter": "Allon G. Percus", "authors": "Cristina Garcia-Cardona, Arjuna Flenner and Allon G. Percus", "title": "Multiclass Diffuse Interface Models for Semi-Supervised Learning on\n  Graphs", "comments": "9 pages, to appear in Proceedings of the 2nd International Conference\n  on Pattern Recognition Applications and Methods (ICPRAM 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST physics.data-an stat.TH", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present a graph-based variational algorithm for multiclass classification\nof high-dimensional data, motivated by total variation techniques. The energy\nfunctional is based on a diffuse interface model with a periodic potential. We\naugment the model by introducing an alternative measure of smoothness that\npreserves symmetry among the class labels. Through this modification of the\nstandard Laplacian, we construct an efficient multiclass method that allows for\nsharp transitions between classes. The experimental results demonstrate that\nour approach is competitive with the state of the art among other graph-based\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 07:13:54 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Garcia-Cardona", "Cristina", ""], ["Flenner", "Arjuna", ""], ["Percus", "Allon G.", ""]]}, {"id": "1212.0960", "submitter": "Hyun Joon Jung", "authors": "Hyun Joon Jung and Matthew Lease", "title": "Evaluating Classifiers Without Expert Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the challenge of evaluating a set of classifiers, as\ndone in shared task evaluations like the KDD Cup or NIST TREC, without expert\nlabels. While expert labels provide the traditional cornerstone for evaluating\nstatistical learners, limited or expensive access to experts represents a\npractical bottleneck. Instead, we seek methodology for estimating performance\nof the classifiers which is more scalable than expert labeling yet preserves\nhigh correlation with evaluation based on expert labels. We consider both: 1)\nusing only labels automatically generated by the classifiers (blind\nevaluation); and 2) using labels obtained via crowdsourcing. While\ncrowdsourcing methods are lauded for scalability, using such data for\nevaluation raises serious concerns given the prevalence of label noise. In\nregard to blind evaluation, two broad strategies are investigated: combine &\nscore and score & combine methods infer a single pseudo-gold label set by\naggregating classifier labels; classifiers are then evaluated based on this\nsingle pseudo-gold label set. On the other hand, score & combine methods: 1)\nsample multiple label sets from classifier outputs, 2) evaluate classifiers on\neach label set, and 3) average classifier performance across label sets. When\nadditional crowd labels are also collected, we investigate two alternative\navenues for exploiting them: 1) direct evaluation of classifiers; or 2)\nsupervision of combine & score methods. To assess generality of our techniques,\nclassifier performance is measured using four common classification metrics,\nwith statistical significance tests. Finally, we measure both score and rank\ncorrelations between estimated classifier performance vs. actual performance\naccording to expert judgments. Rigorous evaluation of classifiers from the TREC\n2011 Crowdsourcing Track shows reliable evaluation can be achieved without\nreliance on expert labels.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 08:15:36 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Jung", "Hyun Joon", ""], ["Lease", "Matthew", ""]]}, {"id": "1212.0967", "submitter": "Sameer Singh", "authors": "Sameer Singh and Thore Graepel", "title": "Compiling Relational Database Schemata into Probabilistic Graphical\n  Models", "comments": "NIPS 2012 Workshop on Probabilistic Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Instead of requiring a domain expert to specify the probabilistic\ndependencies of the data, in this work we present an approach that uses the\nrelational DB schema to automatically construct a Bayesian graphical model for\na database. This resulting model contains customized distributions for columns,\nlatent variables that cluster the data, and factors that reflect and represent\nthe foreign key links. Experiments demonstrate the accuracy of the model and\nthe scalability of inference on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 08:52:33 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Singh", "Sameer", ""], ["Graepel", "Thore", ""]]}, {"id": "1212.0975", "submitter": "Arya Iranmehr", "authors": "Hamed Masnadi-Shirazi, Nuno Vasconcelos and Arya Iranmehr", "title": "Cost-Sensitive Support Vector Machines", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new procedure for learning cost-sensitive SVM(CS-SVM) classifiers is\nproposed. The SVM hinge loss is extended to the cost sensitive setting, and the\nCS-SVM is derived as the minimizer of the associated risk. The extension of the\nhinge loss draws on recent connections between risk minimization and\nprobability elicitation. These connections are generalized to cost-sensitive\nclassification, in a manner that guarantees consistency with the cost-sensitive\nBayes risk, and associated Bayes decision rule. This ensures that optimal\ndecision rules, under the new hinge loss, implement the Bayes-optimal\ncost-sensitive classification boundary. Minimization of the new hinge loss is\nshown to be a generalization of the classic SVM optimization problem, and can\nbe solved by identical procedures. The dual problem of CS-SVM is carefully\nscrutinized by means of regularization theory and sensitivity analysis and the\nCS-SVM algorithm is substantiated. The proposed algorithm is also extended to\ncost-sensitive learning with example dependent costs. The minimum cost\nsensitive risk is proposed as the performance measure and is connected to ROC\nanalysis through vector optimization. The resulting algorithm avoids the\nshortcomings of previous approaches to cost-sensitive SVM design, and is shown\nto have superior experimental performance on a large number of cost sensitive\nand imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 09:24:11 GMT"}, {"version": "v2", "created": "Sun, 15 Feb 2015 11:17:57 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Masnadi-Shirazi", "Hamed", ""], ["Vasconcelos", "Nuno", ""], ["Iranmehr", "Arya", ""]]}, {"id": "1212.1100", "submitter": "Jim Smith Dr", "authors": "J. E. Smith, P. Caleb-Solly, M. A. Tahir, D. Sannen, H. van-Brussel", "title": "Making Early Predictions of the Accuracy of Machine Learning\n  Applications", "comments": "35 pagers, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of machine learning systems is a widely studied research topic.\nEstablished techniques such as cross-validation predict the accuracy on unseen\ndata of the classifier produced by applying a given learning method to a given\ntraining data set. However, they do not predict whether incurring the cost of\nobtaining more data and undergoing further training will lead to higher\naccuracy. In this paper we investigate techniques for making such early\npredictions. We note that when a machine learning algorithm is presented with a\ntraining set the classifier produced, and hence its error, will depend on the\ncharacteristics of the algorithm, on training set's size, and also on its\nspecific composition. In particular we hypothesise that if a number of\nclassifiers are produced, and their observed error is decomposed into bias and\nvariance terms, then although these components may behave differently, their\nbehaviour may be predictable.\n  We test our hypothesis by building models that, given a measurement taken\nfrom the classifier created from a limited number of samples, predict the\nvalues that would be measured from the classifier produced when the full data\nset is presented. We create separate models for bias, variance and total error.\nOur models are built from the results of applying ten different machine\nlearning algorithms to a range of data sets, and tested with \"unseen\"\nalgorithms and datasets. We analyse the results for various numbers of initial\ntraining samples, and total dataset sizes. Results show that our predictions\nare very highly correlated with the values observed after undertaking the extra\ntraining. Finally we consider the more complex case where an ensemble of\nheterogeneous classifiers is trained, and show how we can accurately estimate\nan upper bound on the accuracy achievable after further training.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 17:07:39 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Smith", "J. E.", ""], ["Caleb-Solly", "P.", ""], ["Tahir", "M. A.", ""], ["Sannen", "D.", ""], ["van-Brussel", "H.", ""]]}, {"id": "1212.1108", "submitter": "Luis Ortiz", "authors": "Joshua Belanich and Luis E. Ortiz", "title": "On the Convergence Properties of Optimal AdaBoost", "comments": "66 pp, 7 figs, 1 table; Change - presentation; dominated and\n  effective weak-classifiers; experiments with dec. stumps in real-world data:\n  reduction in #effective and unique stumps, may explain \"resistance to\n  overfitting;\" log-growth #unique stumps with #rounds -> \"AdaBoost-cycles\n  Conjecture\" likely false in general; and new generalization bounds; submitted\n  to MLJ 4/10/15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AdaBoost is one of the most popular machine-learning algorithms. It is simple\nto implement and often found very effective by practitioners, while still being\nmathematically elegant and theoretically sound. AdaBoost's behavior in\npractice, and in particular the test-error behavior, has puzzled many eminent\nresearchers for over a decade: It seems to defy our general intuition in\nmachine learning regarding the fundamental trade-off between model complexity\nand generalization performance. In this paper, we establish the convergence of\n\"Optimal AdaBoost,\" a term coined by Rudin, Daubechies, and Schapire in 2004.\nWe prove the convergence, with the number of rounds, of the classifier itself,\nits generalization error, and its resulting margins for fixed data sets, under\ncertain reasonable conditions. More generally, we prove that the time/per-round\naverage of almost any function of the example weights converges. Our approach\nis to frame AdaBoost as a dynamical system, to provide sufficient conditions\nfor the existence of an invariant measure, and to employ tools from ergodic\ntheory. Unlike previous work, we do not assume AdaBoost cycles; actually, we\npresent empirical evidence against it on real-world datasets. Our main\ntheoretical results hold under a weaker condition. We show sufficient empirical\nevidence that Optimal AdaBoost always met the condition on every real-world\ndataset we tried. Our results formally ground future convergence-rate analyses,\nand may even provide opportunities for slight algorithmic modifications to\noptimize the generalization ability of AdaBoost classifiers, thus reducing a\npractitioner's burden of deciding how long to run the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 17:29:59 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2015 16:18:43 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Belanich", "Joshua", ""], ["Ortiz", "Luis E.", ""]]}, {"id": "1212.1131", "submitter": "Lior Rokach", "authors": "Gilad Katz, Guy Shani, Bracha Shapira, Lior Rokach", "title": "Using Wikipedia to Boost SVD Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) has been used successfully in recent years\nin the area of recommender systems. In this paper we present how this model can\nbe extended to consider both user ratings and information from Wikipedia. By\nmapping items to Wikipedia pages and quantifying their similarity, we are able\nto use this information in order to improve recommendation accuracy, especially\nwhen the sparsity is high. Another advantage of the proposed approach is the\nfact that it can be easily integrated into any other SVD implementation,\nregardless of additional parameters that may have been added to it. Preliminary\nexperimental results on the MovieLens dataset are encouraging.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 19:03:39 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Katz", "Gilad", ""], ["Shani", "Guy", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1212.1180", "submitter": "Mark Kon", "authors": "Mark A. Kon and Leszek Plaskota", "title": "On Some Integrated Approaches to Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present arguments for the formulation of unified approach to different\nstandard continuous inference methods from partial information. It is claimed\nthat an explicit partition of information into a priori (prior knowledge) and a\nposteriori information (data) is an important way of standardizing inference\napproaches so that they can be compared on a normative scale, and so that\nnotions of optimal algorithms become farther-reaching. The inference methods\nconsidered include neural network approaches, information-based complexity, and\nMonte Carlo, spline, and regularization methods. The model is an extension of\ncurrently used continuous complexity models, with a class of algorithms in the\nform of optimization methods, in which an optimization functional (involving\nthe data) is minimized. This extends the family of current approaches in\ncontinuous complexity theory, which include the use of interpolatory algorithms\nin worst and average case settings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 21:19:35 GMT"}], "update_date": "2012-12-07", "authors_parsed": [["Kon", "Mark A.", ""], ["Plaskota", "Leszek", ""]]}, {"id": "1212.1245", "submitter": "Chunxiao Jiang", "authors": "Chunxiao Jiang and Yan Chen and K. J. Ray Liu", "title": "Distributed Adaptive Networks: A Graphical Evolutionary Game-Theoretic\n  View", "comments": "Accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2013.2280444", "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed adaptive filtering has been considered as an effective approach\nfor data processing and estimation over distributed networks. Most existing\ndistributed adaptive filtering algorithms focus on designing different\ninformation diffusion rules, regardless of the nature evolutionary\ncharacteristic of a distributed network. In this paper, we study the adaptive\nnetwork from the game theoretic perspective and formulate the distributed\nadaptive filtering problem as a graphical evolutionary game. With the proposed\nformulation, the nodes in the network are regarded as players and the local\ncombiner of estimation information from different neighbors is regarded as\ndifferent strategies selection. We show that this graphical evolutionary game\nframework is very general and can unify the existing adaptive network\nalgorithms. Based on this framework, as examples, we further propose two\nerror-aware adaptive filtering algorithms. Moreover, we use graphical\nevolutionary game theory to analyze the information diffusion process over the\nadaptive networks and evolutionarily stable strategy of the system. Finally,\nsimulation results are shown to verify the effectiveness of our analysis and\nproposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 06:47:55 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2013 19:12:25 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Jiang", "Chunxiao", ""], ["Chen", "Yan", ""], ["Liu", "K. J. Ray", ""]]}, {"id": "1212.1496", "submitter": "Massimiliano Pontil", "authors": "Andreas Maurer and Massimiliano Pontil", "title": "Excess risk bounds for multitask learning with trace norm regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trace norm regularization is a popular method of multitask learning. We give\nexcess risk bounds with explicit dependence on the number of tasks, the number\nof examples per task and properties of the data distribution. The bounds are\nindependent of the dimension of the input space, which may be infinite as in\nthe case of reproducing kernel Hilbert spaces. A byproduct of the proof are\nbounds on the expected norm of sums of random positive semidefinite matrices\nwith subexponential moments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2012 23:06:32 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2013 17:55:24 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Maurer", "Andreas", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1212.1524", "submitter": "Ludovic Arnold", "authors": "Ludovic Arnold and Yann Ollivier", "title": "Layer-wise learning of deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using deep, multi-layered architectures to build generative models of\ndata, it is difficult to train all layers at once. We propose a layer-wise\ntraining procedure admitting a performance guarantee compared to the global\noptimum. It is based on an optimistic proxy of future performance, the best\nlatent marginal. We interpret auto-encoders in this setting as generative\nmodels, by showing that they train a lower bound of this criterion. We test the\nnew learning procedure against a state of the art method (stacked RBMs), and\nfind it to improve performance. Both theory and experiments highlight the\nimportance, when training deep architectures, of using an inference model (from\ndata to hidden variables) richer than the generative model (from hidden\nvariables to data).\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 03:14:50 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2013 13:24:46 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Arnold", "Ludovic", ""], ["Ollivier", "Yann", ""]]}, {"id": "1212.1527", "submitter": "Chaitanya Swamy", "authors": "Yuval Rabani, Leonard Schulman, Chaitanya Swamy", "title": "Learning Mixtures of Arbitrary Distributions over Large Discrete Domains", "comments": "Update of previous version with improved aperture and sample-size\n  lower bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for learning a mixture of {\\em unstructured}\ndistributions. This problem arises in various unsupervised learning scenarios,\nfor example in learning {\\em topic models} from a corpus of documents spanning\nseveral topics. We show how to learn the constituents of a mixture of $k$\narbitrary distributions over a large discrete domain $[n]=\\{1,2,\\dots,n\\}$ and\nthe mixture weights, using $O(n\\polylog n)$ samples. (In the topic-model\nlearning setting, the mixture constituents correspond to the topic\ndistributions.) This task is information-theoretically impossible for $k>1$\nunder the usual sampling process from a mixture distribution. However, there\nare situations (such as the above-mentioned topic model case) in which each\nsample point consists of several observations from the same mixture\nconstituent. This number of observations, which we call the {\\em \"sampling\naperture\"}, is a crucial parameter of the problem. We obtain the {\\em first}\nbounds for this mixture-learning problem {\\em without imposing any assumptions\non the mixture constituents.} We show that efficient learning is possible\nexactly at the information-theoretically least-possible aperture of $2k-1$.\nThus, we achieve near-optimal dependence on $n$ and optimal aperture. While the\nsample-size required by our algorithm depends exponentially on $k$, we prove\nthat such a dependence is {\\em unavoidable} when one considers general\nmixtures. A sequence of tools contribute to the algorithm, such as\nconcentration results for random matrices, dimension reduction, moment\nestimations, and sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 04:03:06 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2013 18:41:14 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2013 04:18:49 GMT"}], "update_date": "2013-09-19", "authors_parsed": [["Rabani", "Yuval", ""], ["Schulman", "Leonard", ""], ["Swamy", "Chaitanya", ""]]}, {"id": "1212.1824", "submitter": "Ohad Shamir", "authors": "Ohad Shamir and Tong Zhang", "title": "Stochastic Gradient Descent for Non-smooth Optimization: Convergence\n  Results and Optimal Averaging Schemes", "comments": "To appear in ICML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is one of the simplest and most popular\nstochastic optimization methods. While it has already been theoretically\nstudied for decades, the classical analysis usually required non-trivial\nsmoothness assumptions, which do not apply to many modern applications of SGD\nwith non-smooth objective functions such as support vector machines. In this\npaper, we investigate the performance of SGD without such smoothness\nassumptions, as well as a running average scheme to convert the SGD iterates to\na solution with optimal optimization accuracy. In this framework, we prove that\nafter T rounds, the suboptimality of the last SGD iterate scales as\nO(log(T)/\\sqrt{T}) for non-smooth convex objective functions, and O(log(T)/T)\nin the non-smooth strongly convex case. To the best of our knowledge, these are\nthe first bounds of this kind, and almost match the minimax-optimal rates\nobtainable by appropriate averaging schemes. We also propose a new and simple\naveraging scheme, which not only attains optimal rates, but can also be easily\ncomputed on-the-fly (in contrast, the suffix averaging scheme proposed in\nRakhlin et al. (2011) is not as simple to implement). Finally, we provide some\nexperimental illustrations.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 18:22:42 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2012 10:58:48 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Shamir", "Ohad", ""], ["Zhang", "Tong", ""]]}, {"id": "1212.1936", "submitter": "Nicolas Boulanger-Lewandowski", "authors": "Nicolas Boulanger-Lewandowski, Yoshua Bengio and Pascal Vincent", "title": "High-dimensional sequence transduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of transforming an input sequence into a\nhigh-dimensional output sequence in order to transcribe polyphonic audio music\ninto symbolic notation. We introduce a probabilistic model based on a recurrent\nneural network that is able to learn realistic output distributions given the\ninput and we devise an efficient algorithm to search for the global mode of\nthat distribution. The resulting method produces musically plausible\ntranscriptions even under high levels of noise and drastically outperforms\nprevious state-of-the-art approaches on five datasets of synthesized sounds and\nreal recordings, approximately halving the test error rate.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2012 23:28:02 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Boulanger-Lewandowski", "Nicolas", ""], ["Bengio", "Yoshua", ""], ["Vincent", "Pascal", ""]]}, {"id": "1212.2002", "submitter": "Simon Lacoste-Julien", "authors": "Simon Lacoste-Julien, Mark Schmidt, Francis Bach", "title": "A simpler approach to obtaining an O(1/t) convergence rate for the\n  projected stochastic subgradient method", "comments": "8 pages, 6 figures. Changes with previous version: Added reference to\n  concurrently submitted work arXiv:1212.1824v1; clarifications added; typos\n  corrected; title changed to 'subgradient method' as 'subgradient descent' is\n  misnomer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we present a new averaging technique for the projected\nstochastic subgradient method. By using a weighted average with a weight of t+1\nfor each iterate w_t at iteration t, we obtain the convergence rate of O(1/t)\nwith both an easy proof and an easy implementation. The new scheme is compared\nempirically to existing techniques, with similar performance behavior.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 09:22:06 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2012 20:55:23 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Lacoste-Julien", "Simon", ""], ["Schmidt", "Mark", ""], ["Bach", "Francis", ""]]}, {"id": "1212.2136", "submitter": "Boris Flach", "authors": "Boris Flach", "title": "A class of random fields on complete graphs with tractable partition\n  function", "comments": "accepted for publication in IEEE TPAMI (short paper)", "journal-ref": null, "doi": "10.1109/TPAMI.2013.99", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this short note is to draw attention to a method by which the\npartition function and marginal probabilities for a certain class of random\nfields on complete graphs can be computed in polynomial time. This class\nincludes Ising models with homogeneous pairwise potentials but arbitrary\n(inhomogeneous) unary potentials. Similarly, the partition function and\nmarginal probabilities can be computed in polynomial time for random fields on\ncomplete bipartite graphs, provided they have homogeneous pairwise potentials.\nWe expect that these tractable classes of large scale random fields can be very\nuseful for the evaluation of approximation algorithms by providing exact error\nestimates.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 17:12:51 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2013 12:03:42 GMT"}], "update_date": "2013-06-19", "authors_parsed": [["Flach", "Boris", ""]]}, {"id": "1212.2262", "submitter": "Jin Wang", "authors": "Jin Wang, Ping Liu, Mary F.H.She, Saeid Nahavandi and and Abbas\n  Kouzani", "title": "Bag-of-Words Representation for Biomedical Time Series Classification", "comments": "10 pages, 7 figures. Submitted to IEEE Transaction on Biomedical\n  Engineering", "journal-ref": null, "doi": "10.1016/j.bspc.2013.06.004", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Automatic analysis of biomedical time series such as electroencephalogram\n(EEG) and electrocardiographic (ECG) signals has attracted great interest in\nthe community of biomedical engineering due to its important applications in\nmedicine. In this work, a simple yet effective bag-of-words representation that\nis able to capture both local and global structure similarity information is\nproposed for biomedical time series representation. In particular, similar to\nthe bag-of-words model used in text document domain, the proposed method treats\na time series as a text document and extracts local segments from the time\nseries as words. The biomedical time series is then represented as a histogram\nof codewords, each entry of which is the count of a codeword appeared in the\ntime series. Although the temporal order of the local segments is ignored, the\nbag-of-words representation is able to capture high-level structural\ninformation because both local and global structural information are well\nutilized. The performance of the bag-of-words model is validated on three\ndatasets extracted from real EEG and ECG signals. The experimental results\ndemonstrate that the proposed method is not only insensitive to parameters of\nthe bag-of-words model such as local segment length and codebook size, but also\nrobust to noise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 00:49:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Wang", "Jin", ""], ["Liu", "Ping", ""], ["She", "Mary F. H.", ""], ["Nahavandi", "Saeid", ""], ["Kouzani", "and Abbas", ""]]}, {"id": "1212.2287", "submitter": "Jimmy Lin", "authors": "Nima Asadi, Jimmy Lin, and Arjen P. de Vries", "title": "Runtime Optimizations for Prediction with Tree-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based models have proven to be an effective solution for web ranking as\nwell as other problems in diverse domains. This paper focuses on optimizing the\nruntime performance of applying such models to make predictions, given an\nalready-trained model. Although exceedingly simple conceptually, most\nimplementations of tree-based models do not efficiently utilize modern\nsuperscalar processor architectures. By laying out data structures in memory in\na more cache-conscious fashion, removing branches from the execution flow using\na technique called predication, and micro-batching predictions using a\ntechnique called vectorization, we are able to better exploit modern processor\narchitectures and significantly improve the speed of tree-based models over\nhard-coded if-else blocks. Our work contributes to the exploration of\narchitecture-conscious runtime implementations of machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 03:20:46 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2013 16:33:08 GMT"}], "update_date": "2013-04-29", "authors_parsed": [["Asadi", "Nima", ""], ["Lin", "Jimmy", ""], ["de Vries", "Arjen P.", ""]]}, {"id": "1212.2340", "submitter": "Emilie Morvant", "authors": "Pascal Germain, Amaury Habrard (LAHC), Fran\\c{c}ois Laviolette, Emilie\n  Morvant (LIF)", "title": "PAC-Bayesian Learning and Domain Adaptation", "comments": "https://sites.google.com/site/multitradeoffs2012/", "journal-ref": "Multi-Trade-offs in Machine Learning, NIPS 2012 Workshop, Lake\n  Tahoe : United States (2012)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, Domain Adaptation (DA) arises when the distribution gen-\nerating the test (target) data differs from the one generating the learning\n(source) data. It is well known that DA is an hard task even under strong\nassumptions, among which the covariate-shift where the source and target\ndistributions diverge only in their marginals, i.e. they have the same labeling\nfunction. Another popular approach is to consider an hypothesis class that\nmoves closer the two distributions while implying a low-error for both tasks.\nThis is a VC-dim approach that restricts the complexity of an hypothesis class\nin order to get good generalization. Instead, we propose a PAC-Bayesian\napproach that seeks for suitable weights to be given to each hypothesis in\norder to build a majority vote. We prove a new DA bound in the PAC-Bayesian\ncontext. This leads us to design the first DA-PAC-Bayesian algorithm based on\nthe minimization of the proposed bound. Doing so, we seek for a \\rho-weighted\nmajority vote that takes into account a trade-off between three quantities. The\nfirst two quantities being, as usual in the PAC-Bayesian approach, (a) the\ncomplexity of the majority vote (measured by a Kullback-Leibler divergence) and\n(b) its empirical risk (measured by the \\rho-average errors on the source\nsample). The third quantity is (c) the capacity of the majority vote to\ndistinguish some structural difference between the source and target samples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 09:03:17 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Germain", "Pascal", "", "LAHC"], ["Habrard", "Amaury", "", "LAHC"], ["Laviolette", "Fran\u00e7ois", "", "LIF"], ["Morvant", "Emilie", "", "LIF"]]}, {"id": "1212.2390", "submitter": "Eric  Werner", "authors": "Eric Werner", "title": "On the complexity of learning a language: An improvement of Block's\n  algorithm", "comments": "7 pages. Key Words: Language learning, rules of language, complexity,\n  learning algorithms, evolution of language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language learning is thought to be a highly complex process. One of the\nhurdles in learning a language is to learn the rules of syntax of the language.\nRules of syntax are often ordered in that before one rule can applied one must\napply another. It has been thought that to learn the order of n rules one must\ngo through all n! permutations. Thus to learn the order of 27 rules would\nrequire 27! steps or 1.08889x10^{28} steps. This number is much greater than\nthe number of seconds since the beginning of the universe! In an insightful\nanalysis the linguist Block ([Block 86], pp. 62-63, p.238) showed that with the\nassumption of transitivity this vast number of learning steps reduces to a mere\n377 steps. We present a mathematical analysis of the complexity of Block's\nalgorithm. The algorithm has a complexity of order n^2 given n rules. In\naddition, we improve Block's results exponentially, by introducing an algorithm\nthat has complexity of order less than n log n.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 11:35:30 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Werner", "Eric", ""]]}, {"id": "1212.2414", "submitter": "Maher Salem", "authors": "Maher Salem and Ulrich Buehler", "title": "Mining Techniques in Network Security to Enhance Intrusion Detection\n  Systems", "comments": "16 pages, 7 figures", "journal-ref": "ISSN: 0975-2307 , e-ISSN: 0974-9330, 2012", "doi": "10.5121/ijnsa", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In intrusion detection systems, classifiers still suffer from several\ndrawbacks such as data dimensionality and dominance, different network feature\ntypes, and data impact on the classification. In this paper two significant\nenhancements are presented to solve these drawbacks. The first enhancement is\nan improved feature selection using sequential backward search and information\ngain. This, in turn, extracts valuable features that enhance positively the\ndetection rate and reduce the false positive rate. The second enhancement is\ntransferring nominal network features to numeric ones by exploiting the\ndiscrete random variable and the probability mass function to solve the problem\nof different feature types, the problem of data dominance, and data impact on\nthe classification. The latter is combined to known normalization methods to\nachieve a significant hybrid normalization approach. Finally, an intensive and\ncomparative study approves the efficiency of these enhancements and shows\nbetter performance comparing to other proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 13:14:42 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Salem", "Maher", ""], ["Buehler", "Ulrich", ""]]}, {"id": "1212.2415", "submitter": "Hyonil Kim", "authors": "Song Han, Jinsong Kim, Cholhun Kim, Jongchol Jo, and Sunam Han", "title": "Robust Face Recognition using Local Illumination Normalization and\n  Discriminant Feature Point Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition systems must be robust to the variation of various factors\nsuch as facial expression, illumination, head pose and aging. Especially, the\nrobustness against illumination variation is one of the most important problems\nto be solved for the practical use of face recognition systems. Gabor wavelet\nis widely used in face detection and recognition because it gives the\npossibility to simulate the function of human visual system. In this paper, we\npropose a method for extracting Gabor wavelet features which is stable under\nthe variation of local illumination and show experiment results demonstrating\nits effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 13:19:54 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Han", "Song", ""], ["Kim", "Jinsong", ""], ["Kim", "Cholhun", ""], ["Jo", "Jongchol", ""], ["Han", "Sunam", ""]]}, {"id": "1212.2442", "submitter": "Craig Boutilier", "authors": "Craig Boutilier, Richard S. Zemel, Benjamin Marlin", "title": "Active Collaborative Filtering", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-98-106", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) allows the preferences of multiple users to be\npooled to make recommendations regarding unseen products. We consider in this\npaper the problem of online and interactive CF: given the current ratings\nassociated with a user, what queries (new ratings) would most improve the\nquality of the recommendations made? We cast this terms of expected value of\ninformation (EVOI); but the online computational cost of computing optimal\nqueries is prohibitive. We show how offline prototyping and computation of\nbounds on EVOI can be used to dramatically reduce the required online\ncomputation. The framework we develop is general, but we focus on derivations\nand empirical study in the specific case of the multiple-cause vector\nquantization model.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:12 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Boutilier", "Craig", ""], ["Zemel", "Richard S.", ""], ["Marlin", "Benjamin", ""]]}, {"id": "1212.2447", "submitter": "Christopher M. Bishop", "authors": "Christopher M. Bishop, Markus Svensen", "title": "Bayesian Hierarchical Mixtures of Experts", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-57-64", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Mixture of Experts (HME) is a well-known tree-based model\nfor regression and classification, based on soft probabilistic splits. In its\noriginal formulation it was trained by maximum likelihood, and is therefore\nprone to over-fitting. Furthermore the maximum likelihood framework offers no\nnatural metric for optimizing the complexity and structure of the tree.\nPrevious attempts to provide a Bayesian treatment of the HME model have relied\neither on ad-hoc local Gaussian approximations or have dealt with related\nmodels representing the joint distribution of both input and output variables.\nIn this paper we describe a fully Bayesian treatment of the HME model based on\nvariational inference. By combining local and global variational methods we\nobtain a rigourous lower bound on the marginal probability of the data under\nthe model. This bound is optimized during the training phase, and its resulting\nvalue can be used for model order selection. We present results using this\napproach for a data set describing robot arm kinematics.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:03:51 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Bishop", "Christopher M.", ""], ["Svensen", "Markus", ""]]}, {"id": "1212.2460", "submitter": "Gal Elidan", "authors": "Gal Elidan, Nir Friedman", "title": "The Information Bottleneck EM Algorithm", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-200-208", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with hidden variables is a central challenge in probabilistic\ngraphical models that has important implications for many real-life problems.\nThe classical approach is using the Expectation Maximization (EM) algorithm.\nThis algorithm, however, can get trapped in local maxima. In this paper we\nexplore a new approach that is based on the Information Bottleneck principle.\nIn this approach, we view the learning problem as a tradeoff between two\ninformation theoretic objectives. The first is to make the hidden variables\nuninformative about the identity of specific instances. The second is to make\nthe hidden variables informative about the observed attributes. By exploring\ndifferent tradeoffs between these two objectives, we can gradually converge on\na high-scoring solution. As we show, the resulting, Information Bottleneck\nExpectation Maximization (IB-EM) algorithm, manages to find solutions that are\nsuperior to standard EM methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:02 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Elidan", "Gal", ""], ["Friedman", "Nir", ""]]}, {"id": "1212.2462", "submitter": "Mathias Drton", "authors": "Mathias Drton, Thomas S. Richardson", "title": "A New Algorithm for Maximum Likelihood Estimation in Gaussian Graphical\n  Models for Marginal Independence", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-184-191", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models with bi-directed edges (<->) represent marginal\nindependence: the absence of an edge between two vertices indicates that the\ncorresponding variables are marginally independent. In this paper, we consider\nmaximum likelihood estimation in the case of continuous variables with a\nGaussian joint distribution, sometimes termed a covariance graph model. We\npresent a new fitting algorithm which exploits standard regression techniques\nand establish its convergence properties. Moreover, we contrast our procedure\nto existing estimation methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:52 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Drton", "Mathias", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1212.2464", "submitter": "Denver Dash", "authors": "Denver Dash, Marek J. Druzdzel", "title": "A Robust Independence Test for Constraint-Based Learning of Causal\n  Structure", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-167-174", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint-based (CB) learning is a formalism for learning a causal network\nwith a database D by performing a series of conditional-independence tests to\ninfer structural information. This paper considers a new test of independence\nthat combines ideas from Bayesian learning, Bayesian network inference, and\nclassical hypothesis testing to produce a more reliable and robust test. The\nnew test can be calculated in the same asymptotic time and space required for\nthe standard tests such as the chi-squared test, but it allows the\nspecification of a prior distribution over parameters and can be used when the\ndatabase is incomplete. We prove that the test is correct, and we demonstrate\nempirically that, when used with a CB causal discovery algorithm with\nnoninformative priors, it recovers structural features more reliably and it\nproduces networks with smaller KL-Divergence, especially as the number of nodes\nincreases or the number of records decreases. Another benefit is the dramatic\nreduction in the probability that a CB algorithm will stall during the search,\nproviding a remedy for an annoying problem plaguing CB learning when the\ndatabase is small.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:44 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Dash", "Denver", ""], ["Druzdzel", "Marek J.", ""]]}, {"id": "1212.2466", "submitter": "Adrian Corduneanu", "authors": "Adrian Corduneanu, Tommi S. Jaakkola", "title": "On Information Regularization", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-151-158", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a principle for classification with the knowledge of the\nmarginal distribution over the data points (unlabeled data). The principle is\ncast in terms of Tikhonov style regularization where the regularization penalty\narticulates the way in which the marginal density should constrain otherwise\nunrestricted conditional distributions. Specifically, the regularization\npenalty penalizes any information introduced between the examples and labels\nbeyond what is provided by the available labeled examples. The work extends\nSzummer and Jaakkola's information regularization (NIPS 2002) to multiple\ndimensions, providing a regularizer independent of the covering of the space\nused in the derivation. We show in addition how the information regularizer can\nbe used as a measure of complexity of the classification task with unlabeled\ndata and prove a relevant sample-complexity bound. We illustrate the\nregularization principle in practice by restricting the class of conditional\ndistributions to be logistic regression models and constructing the\nregularization penalty from a finite set of unlabeled examples.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:36 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Corduneanu", "Adrian", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1212.2468", "submitter": "David Maxwell Chickering", "authors": "David Maxwell Chickering, Christopher Meek, David Heckerman", "title": "Large-Sample Learning of Bayesian Networks is NP-Hard", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-124-133", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide new complexity results for algorithms that learn\ndiscrete-variable Bayesian networks from data. Our results apply whenever the\nlearning algorithm uses a scoring criterion that favors the simplest model able\nto represent the generative distribution exactly. Our results therefore hold\nwhenever the learning algorithm uses a consistent scoring criterion and is\napplied to a sufficiently large dataset. We show that identifying high-scoring\nstructures is hard, even when we are given an independence oracle, an inference\noracle, and/or an information oracle. Our negative results also apply to the\nlearning of discrete-variable Bayesian networks in which each node has at most\nk parents, for all k > 3.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:28 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""], ["Heckerman", "David", ""]]}, {"id": "1212.2470", "submitter": "Hei Chan", "authors": "Hei Chan, Adnan Darwiche", "title": "Reasoning about Bayesian Network Classifiers", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-107-115", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian network classifiers are used in many fields, and one common class of\nclassifiers are naive Bayes classifiers. In this paper, we introduce an\napproach for reasoning about Bayesian network classifiers in which we\nexplicitly convert them into Ordered Decision Diagrams (ODDs), which are then\nused to reason about the properties of these classifiers. Specifically, we\npresent an algorithm for converting any naive Bayes classifier into an ODD, and\nwe show theoretically and experimentally that this algorithm can give us an ODD\nthat is tractable in size even given an intractable number of instances. Since\nODDs are tractable representations of classifiers, our algorithm allows us to\nefficiently test the equivalence of two naive Bayes classifiers and\ncharacterize discrepancies between them. We also show a number of additional\nresults including a count of distinct classifiers that can be induced by\nchanging some CPT in a naive Bayes classifier, and the range of allowable\nchanges to a CPT which keeps the current classifier unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:04:17 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Chan", "Hei", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1212.2471", "submitter": "Fletcher Lu", "authors": "Fletcher Lu, Dale Schuurmans", "title": "Monte Carlo Matrix Inversion Policy Evaluation", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-386-393", "categories": "cs.LG cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1950, Forsythe and Leibler (1950) introduced a statistical technique for\nfinding the inverse of a matrix by characterizing the elements of the matrix\ninverse as expected values of a sequence of random walks. Barto and Duff (1994)\nsubsequently showed relations between this technique and standard dynamic\nprogramming and temporal differencing methods. The advantage of the Monte Carlo\nmatrix inversion (MCMI) approach is that it scales better with respect to\nstate-space size than alternative techniques. In this paper, we introduce an\nalgorithm for performing reinforcement learning policy evaluation using MCMI.\nWe demonstrate that MCMI improves on runtime over a maximum likelihood\nmodel-based policy evaluation approach and on both runtime and accuracy over\nthe temporal differencing (TD) policy evaluation approach. We further improve\non MCMI policy evaluation by adding an importance sampling technique to our\nalgorithm to reduce the variance of our estimator. Lastly, we illustrate\ntechniques for scaling up MCMI to large state spaces in order to perform policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:41 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Lu", "Fletcher", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1212.2472", "submitter": "Daniel J. Lizotte", "authors": "Daniel J. Lizotte, Omid Madani, Russell Greiner", "title": "Budgeted Learning of Naive-Bayes Classifiers", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-378-385", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently, acquiring training data has an associated cost. We consider the\nsituation where the learner may purchase data during training, subject TO a\nbudget. IN particular, we examine the CASE WHERE each feature label has an\nassociated cost, AND the total cost OF ALL feature labels acquired during\ntraining must NOT exceed the budget.This paper compares methods FOR choosing\nwhich feature label TO purchase next, given the budget AND the CURRENT belief\nstate OF naive Bayes model parameters.Whereas active learning has traditionally\nfocused ON myopic(greedy) strategies FOR query selection, this paper presents a\ntractable method FOR incorporating knowledge OF the budget INTO the decision\nmaking process, which improves performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:36 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Lizotte", "Daniel J.", ""], ["Madani", "Omid", ""], ["Greiner", "Russell", ""]]}, {"id": "1212.2474", "submitter": "Guy Lebanon", "authors": "Guy Lebanon", "title": "Learning Riemannian Metrics", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-362-369", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a solution to the problem of estimating a Riemannian metric\nassociated with a given differentiable manifold. The metric learning problem is\nbased on minimizing the relative volume of a given set of points. We derive the\ndetails for a family of metrics on the multinomial simplex. The resulting\nmetric has applications in text classification and bears some similarity to\nTFIDF representation of text documents.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:27 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Lebanon", "Guy", ""]]}, {"id": "1212.2475", "submitter": "Gregory Lawrence", "authors": "Gregory Lawrence, Noah Cowan, Stuart Russell", "title": "Efficient Gradient Estimation for Motor Control Learning", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-354-361", "categories": "cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of estimating the gradient of a function in the presence of noise is\ncentral to several forms of reinforcement learning, including policy search\nmethods. We present two techniques for reducing gradient estimation errors in\nthe presence of observable input noise applied to the control signal. The first\nmethod extends the idea of a reinforcement baseline by fitting a local linear\nmodel to the function whose gradient is being estimated; we show how to find\nthe linear model that minimizes the variance of the gradient estimate, and how\nto estimate the model from data. The second method improves this further by\ndiscounting components of the gradient vector that have high variance. These\nmethods are applied to the problem of motor control learning, where actuator\nnoise has a significant influence on behavior. In particular, we apply the\ntechniques to learn locally optimal controllers for a dart-throwing task using\na simulated three-link arm; we demonstrate that proposed methods significantly\nimprove the reward function gradient estimate and, consequently, the learning\ncurve, over existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:23 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Lawrence", "Gregory", ""], ["Cowan", "Noah", ""], ["Russell", "Stuart", ""]]}, {"id": "1212.2480", "submitter": "Tom Heskes", "authors": "Tom Heskes, Kees Albers, Hilbert Kappen", "title": "Approximate Inference and Constrained Optimization", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-313-320", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loopy and generalized belief propagation are popular algorithms for\napproximate inference in Markov random fields and Bayesian networks. Fixed\npoints of these algorithms correspond to extrema of the Bethe and Kikuchi free\nenergy. However, belief propagation does not always converge, which explains\nthe need for approaches that explicitly minimize the Kikuchi/Bethe free energy,\nsuch as CCCP and UPS. Here we describe a class of algorithms that solves this\ntypically nonconvex constrained minimization of the Kikuchi free energy through\na sequence of convex constrained minimizations of upper bounds on the Kikuchi\nfree energy. Intuitively one would expect tighter bounds to lead to faster\nalgorithms, which is indeed convincingly demonstrated in our simulations.\nSeveral ideas are applied to obtain tight convex bounds that yield dramatic\nspeed-ups over CCCP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:00 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Heskes", "Tom", ""], ["Albers", "Kees", ""], ["Kappen", "Hilbert", ""]]}, {"id": "1212.2483", "submitter": "Amir Globerson", "authors": "Amir Globerson, Gal Chechik, Naftali Tishby", "title": "Sufficient Dimensionality Reduction with Irrelevant Statistics", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-281-288", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding a reduced dimensionality representation of categorical\nvariables while preserving their most relevant characteristics is fundamental\nfor the analysis of complex data. Specifically, given a co-occurrence matrix of\ntwo variables, one often seeks a compact representation of one variable which\npreserves information about the other variable. We have recently introduced\n``Sufficient Dimensionality Reduction' [GT-2003], a method that extracts\ncontinuous reduced dimensional features whose measurements (i.e., expectation\nvalues) capture maximal mutual information among the variables. However, such\nmeasurements often capture information that is irrelevant for a given task.\nWidely known examples are illumination conditions, which are irrelevant as\nfeatures for face recognition, writing style which is irrelevant as a feature\nfor content classification, and intonation which is irrelevant as a feature for\nspeech recognition. Such irrelevance cannot be deduced apriori, since it\ndepends on the details of the task, and is thus inherently ill defined in the\npurely unsupervised case. Separating relevant from irrelevant features can be\nachieved using additional side data that contains such irrelevant structures.\nThis approach was taken in [CT-2002], extending the information bottleneck\nmethod, which uses clustering to compress the data. Here we use this\nside-information framework to identify features whose measurements are\nmaximally informative for the original data set, but carry as little\ninformation as possible on a side data set. In statistical terms this can be\nunderstood as extracting statistics which are maximally sufficient for the\noriginal dataset, while simultaneously maximally ancillary for the side\ndataset. We formulate this tradeoff as a constrained optimization problem and\ncharacterize its solutions. We then derive a gradient descent algorithm for\nthis problem, which is based on the Generalized Iterative Scaling method for\nfinding maximum entropy distributions. The method is demonstrated on synthetic\ndata, as well as on real face recognition datasets, and is shown to outperform\nstandard methods such as oriented PCA.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:46 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Globerson", "Amir", ""], ["Chechik", "Gal", ""], ["Tishby", "Naftali", ""]]}, {"id": "1212.2487", "submitter": "Eibe Frank", "authors": "Eibe Frank, Mark Hall, Bernhard Pfahringer", "title": "Locally Weighted Naive Bayes", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-249-256", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its simplicity, the naive Bayes classifier has surprised machine\nlearning researchers by exhibiting good performance on a variety of learning\nproblems. Encouraged by these results, researchers have looked to overcome\nnaive Bayes primary weakness - attribute independence - and improve the\nperformance of the algorithm. This paper presents a locally weighted version of\nnaive Bayes that relaxes the independence assumption by learning local models\nat prediction time. Experimental results show that locally weighted naive Bayes\nrarely degrades accuracy compared to standard naive Bayes and, in many cases,\nimproves accuracy dramatically. The main advantage of this method compared to\nother techniques for enhancing naive Bayes is its conceptual and computational\nsimplicity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:29 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Frank", "Eibe", ""], ["Hall", "Mark", ""], ["Pfahringer", "Bernhard", ""]]}, {"id": "1212.2488", "submitter": "Ari Frank", "authors": "Ari Frank, Dan Geiger, Zohar Yakhini", "title": "A Distance-Based Branch and Bound Feature Selection Algorithm", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-241-248", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no known efficient method for selecting k Gaussian features from n\nwhich achieve the lowest Bayesian classification error. We show an example of\nhow greedy algorithms faced with this task are led to give results that are not\noptimal. This motivates us to propose a more robust approach. We present a\nBranch and Bound algorithm for finding a subset of k independent Gaussian\nfeatures which minimizes the naive Bayesian classification error. Our algorithm\nuses additive monotonic distance measures to produce bounds for the Bayesian\nclassification error in order to exclude many feature subsets from evaluation,\nwhile still returning an optimal solution. We test our method on synthetic data\nas well as data obtained from gene expression profiling.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:05:25 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Frank", "Ari", ""], ["Geiger", "Dan", ""], ["Yakhini", "Zohar", ""]]}, {"id": "1212.2490", "submitter": "Ruslan R Salakhutdinov", "authors": "Ruslan R Salakhutdinov, Sam T Roweis, Zoubin Ghahramani", "title": "On the Convergence of Bound Optimization Algorithms", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-509-516", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practitioners who use the EM algorithm complain that it is sometimes\nslow. When does this happen, and what can be done about it? In this paper, we\nstudy the general class of bound optimization algorithms - including\nExpectation-Maximization, Iterative Scaling and CCCP - and their relationship\nto direct optimization algorithms such as gradient-based methods for parameter\nlearning. We derive a general relationship between the updates performed by\nbound optimization methods and those of gradient and second-order methods and\nidentify analytic conditions under which bound optimization algorithms exhibit\nquasi-Newton behavior, and conditions under which they possess poor,\nfirst-order convergence. Based on this analysis, we consider several specific\nalgorithms, interpret and analyze their convergence properties and provide some\nrecipes for preprocessing input to these algorithms to yield faster convergence\nbehavior. We report empirical results supporting our analysis and showing that\nsimple data preprocessing can result in dramatically improved performance of\nbound optimizers in practice.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:56 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Salakhutdinov", "Ruslan R", ""], ["Roweis", "Sam T", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1212.2491", "submitter": "Dmitry Rusakov", "authors": "Dmitry Rusakov, Dan Geiger", "title": "Automated Analytic Asymptotic Evaluation of the Marginal Likelihood for\n  Latent Models", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-501-508", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and implement two algorithms for analytic asymptotic evaluation of\nthe marginal likelihood of data given a Bayesian network with hidden nodes. As\nshown by previous work, this evaluation is particularly hard for latent\nBayesian network models, namely networks that include hidden variables, where\nasymptotic approximation deviates from the standard BIC score. Our algorithms\nsolve two central difficulties in asymptotic evaluation of marginal likelihood\nintegrals, namely, evaluation of regular dimensionality drop for latent\nBayesian network models and computation of non-standard approximation formulas\nfor singular statistics for these models. The presented algorithms are\nimplemented in Matlab and Maple and their usage is demonstrated for marginal\nlikelihood approximations for Bayesian networks with hidden variables.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:51 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Rusakov", "Dmitry", ""], ["Geiger", "Dan", ""]]}, {"id": "1212.2494", "submitter": "Romer Rosales", "authors": "Romer Rosales, Brendan J. Frey", "title": "Learning Generative Models of Similarity Matrices", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-485-492", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a probabilistic (generative) view of affinity matrices along with\ninference algorithms for a subclass of problems associated with data\nclustering. This probabilistic view is helpful in understanding different\nmodels and algorithms that are based on affinity functions OF the data. IN\nparticular, we show how(greedy) inference FOR a specific probabilistic model IS\nequivalent TO the spectral clustering algorithm.It also provides a framework\nFOR developing new algorithms AND extended models. AS one CASE, we present new\ngenerative data clustering models that allow us TO infer the underlying\ndistance measure suitable for the clustering problem at hand. These models seem\nto perform well in a larger class of problems for which other clustering\nalgorithms (including spectral clustering) usually fail. Experimental\nevaluation was performed in a variety point data sets, showing excellent\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:42 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Rosales", "Romer", ""], ["Frey", "Brendan J.", ""]]}, {"id": "1212.2498", "submitter": "Uri Nodelman", "authors": "Uri Nodelman, Christian R. Shelton, Daphne Koller", "title": "Learning Continuous Time Bayesian Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-451-458", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous time Bayesian networks (CTBNs) describe structured stochastic\nprocesses with finitely many states that evolve over continuous time. A CTBN is\na directed (possibly cyclic) dependency graph over a set of variables, each of\nwhich represents a finite state continuous time Markov process whose transition\nmodel is a function of its parents. We address the problem of learning\nparameters and structure of a CTBN from fully observed data. We define a\nconjugate prior for CTBNs, and show how it can be used both for Bayesian\nparameter estimation and as the basis of a Bayesian score for structure\nlearning. Because acyclicity is not a constraint in CTBNs, we can show that the\nstructure learning problem is significantly easier, both in theory and in\npractice, than structure learning for dynamic Bayesian networks (DBNs).\nFurthermore, as CTBNs can tailor the parameters and dependency structure to the\ndifferent time granularities of the evolution of different variables, they can\nprovide a better fit to continuous-time processes than DBNs with a fixed time\ngranularity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:23 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Nodelman", "Uri", ""], ["Shelton", "Christian R.", ""], ["Koller", "Daphne", ""]]}, {"id": "1212.2500", "submitter": "Jens D. Nielsen", "authors": "Jens D. Nielsen, Tomas Kocka, Jose M. Pena", "title": "On Local Optima in Learning Bayesian Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-435-442", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and evaluates the k-greedy equivalence search algorithm\n(KES) for learning Bayesian networks (BNs) from complete data. The main\ncharacteristic of KES is that it allows a trade-off between greediness and\nrandomness, thus exploring different good local optima. When greediness is set\nat maximum, KES corresponds to the greedy equivalence search algorithm (GES).\nWhen greediness is kept at minimum, we prove that under mild assumptions KES\nasymptotically returns any inclusion optimal BN with nonzero probability.\nExperimental results for both synthetic and real data are reported showing that\nKES often finds a better local optima than GES. Moreover, we use KES to\nexperimentally confirm that the number of different local optima is often huge.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:07:12 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Nielsen", "Jens D.", ""], ["Kocka", "Tomas", ""], ["Pena", "Jose M.", ""]]}, {"id": "1212.2504", "submitter": "Andrew McCallum", "authors": "Andrew McCallum", "title": "Efficiently Inducing Features of Conditional Random Fields", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-403-410", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Random Fields (CRFs) are undirected graphical models, a special\ncase of which correspond to conditionally-trained finite state machines. A key\nadvantage of these models is their great flexibility to include a wide array of\noverlapping, multi-granularity, non-independent features of the input. In face\nof this freedom, an important question that remains is, what features should be\nused? This paper presents a feature induction method for CRFs. Founded on the\nprinciple of constructing only those feature conjunctions that significantly\nincrease log-likelihood, the approach is based on that of Della Pietra et al\n[1997], but altered to work with conditional rather than joint probabilities,\nand with additional modifications for providing tractability specifically for a\nsequence model. In comparison with traditional approaches, automated feature\ninduction offers both improved accuracy and more than an order of magnitude\nreduction in feature count; it enables the use of richer, higher-order Markov\nmodels, and offers more freedom to liberally guess about which atomic features\nmay be relevant to a task. The induction method applies to linear-chain CRFs,\nas well as to more arbitrary CRF structures, also known as Relational Markov\nNetworks [Taskar & Koller, 2002]. We present experimental results on a named\nentity extraction task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:06:52 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["McCallum", "Andrew", ""]]}, {"id": "1212.2508", "submitter": "Kai Yu", "authors": "Kai Yu, Anton Schwaighofer, Volker Tresp, Wei-Ying Ma, HongJiang Zhang", "title": "Collaborative Ensemble Learning: Combining Collaborative and\n  Content-Based Information Filtering via Hierarchical Bayes", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-616-623", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) and content-based filtering (CBF) have widely\nbeen used in information filtering applications. Both approaches have their\nstrengths and weaknesses which is why researchers have developed hybrid\nsystems. This paper proposes a novel approach to unify CF and CBF in a\nprobabilistic framework, named collaborative ensemble learning. It uses\nprobabilistic SVMs to model each user's profile (as CBF does).At the prediction\nphase, it combines a society OF users profiles, represented by their respective\nSVM models, to predict an active users preferences(the CF idea).The combination\nscheme is embedded in a probabilistic framework and retains an intuitive\nexplanation.Moreover, collaborative ensemble learning does not require a global\ntraining stage and thus can incrementally incorporate new data.We report\nresults based on two data sets. For the Reuters-21578 text data set, we\nsimulate user ratings under the assumption that each user is interested in only\none category. In the second experiment, we use users' opinions on a set of 642\nart images that were collected through a web-based survey. For both data sets,\ncollaborative ensemble achieved excellent performance in terms of\nrecommendation accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:51 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Yu", "Kai", ""], ["Schwaighofer", "Anton", ""], ["Tresp", "Volker", ""], ["Ma", "Wei-Ying", ""], ["Zhang", "HongJiang", ""]]}, {"id": "1212.2510", "submitter": "Chen-Hsiang Yeang", "authors": "Chen-Hsiang Yeang, Martin Szummer", "title": "Markov Random Walk Representations with Continuous Distributions", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-600-607", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations based on random walks can exploit discrete data distributions\nfor clustering and classification. We extend such representations from discrete\nto continuous distributions. Transition probabilities are now calculated using\na diffusion equation with a diffusion coefficient that inversely depends on the\ndata density. We relate this diffusion equation to a path integral and derive\nthe corresponding path probability measure. The framework is useful for\nincorporating continuous data densities and prior knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:42 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Yeang", "Chen-Hsiang", ""], ["Szummer", "Martin", ""]]}, {"id": "1212.2511", "submitter": "Keisuke Yamazaki", "authors": "Keisuke Yamazaki, Sumio Watanbe", "title": "Stochastic complexity of Bayesian networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-592-599", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks are now being used in enormous fields, for example,\ndiagnosis of a system, data mining, clustering and so on. In spite of their\nwide range of applications, the statistical properties have not yet been\nclarified, because the models are nonidentifiable and non-regular. In a\nBayesian network, the set of its parameter for a smaller model is an analytic\nset with singularities in the space of large ones. Because of these\nsingularities, the Fisher information matrices are not positive definite. In\nother words, the mathematical foundation for learning was not constructed. In\nrecent years, however, we have developed a method to analyze non-regular models\nusing algebraic geometry. This method revealed the relation between the models\nsingularities and its statistical properties. In this paper, applying this\nmethod to Bayesian networks with latent variables, we clarify the order of the\nstochastic complexities.Our result claims that the upper bound of those is\nsmaller than the dimension of the parameter space. This means that the Bayesian\ngeneralization error is also far smaller than that of regular model, and that\nSchwarzs model selection criterion BIC needs to be improved for Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:38 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Yamazaki", "Keisuke", ""], ["Watanbe", "Sumio", ""]]}, {"id": "1212.2512", "submitter": "Eric P. Xing", "authors": "Eric P. Xing, Michael I. Jordan, Stuart Russell", "title": "A Generalized Mean Field Algorithm for Variational Inference in\n  Exponential Families", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-583-591", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean field methods, which entail approximating intractable probability\ndistributions variationally with distributions from a tractable family, enjoy\nhigh efficiency, guaranteed convergence, and provide lower bounds on the true\nlikelihood. But due to requirement for model-specific derivation of the\noptimization equations and unclear inference quality in various models, it is\nnot widely used as a generic approximate inference algorithm. In this paper, we\ndiscuss a generalized mean field theory on variational approximation to a broad\nclass of intractable distributions using a rich set of tractable distributions\nvia constrained optimization over distribution spaces. We present a class of\ngeneralized mean field (GMF) algorithms for approximate inference in complex\nexponential family models, which entails limiting the optimization over the\nclass of cluster-factorizable distributions. GMF is a generic method requiring\nno model-specific derivations. It factors a complex model into a set of\ndisjoint variable clusters, and uses a set of canonical fix-point equations to\niteratively update the cluster distributions, and converge to locally optimal\ncluster marginals that preserve the original dependency structure within each\ncluster, hence, fully decomposed the overall inference problem. We empirically\nanalyzed the effect of different tractable family (clusters of different\ngranularity) on inference quality, and compared GMF with BP on several\ncanonical models. Possible extension to higher-order MF approximation is also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:33 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Xing", "Eric P.", ""], ["Jordan", "Michael I.", ""], ["Russell", "Stuart", ""]]}, {"id": "1212.2513", "submitter": "Max Welling", "authors": "Max Welling, Richard S. Zemel, Geoffrey E. Hinton", "title": "Efficient Parametric Projection Pursuit Density Estimation", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-575-582", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product models of low dimensional experts are a powerful way to avoid the\ncurse of dimensionality. We present the ``under-complete product of experts'\n(UPoE), where each expert models a one dimensional projection of the data. The\nUPoE is fully tractable and may be interpreted as a parametric probabilistic\nmodel for projection pursuit. Its ML learning rules are identical to the\napproximate learning rules proposed before for under-complete ICA. We also\nderive an efficient sequential learning algorithm and discuss its relationship\nto projection pursuit density estimation and feature induction algorithms for\nadditive random field models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:28 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Welling", "Max", ""], ["Zemel", "Richard S.", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1212.2514", "submitter": "Shaojun Wang", "authors": "Shaojun Wang, Dale Schuurmans, Fuchun Peng, Yunxin Zhao", "title": "Boltzmann Machine Learning with the Latent Maximum Entropy Principle", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-567-574", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new statistical learning paradigm for Boltzmann machines based\non a new inference principle we have proposed: the latent maximum entropy\nprinciple (LME). LME is different both from Jaynes maximum entropy principle\nand from standard maximum likelihood estimation.We demonstrate the LME\nprinciple BY deriving new algorithms for Boltzmann machine parameter\nestimation, and show how robust and fast new variant of the EM algorithm can be\ndeveloped.Our experiments show that estimation based on LME generally yields\nbetter results than maximum likelihood estimation, particularly when inferring\nhidden units from small amounts of data.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:24 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Wang", "Shaojun", ""], ["Schuurmans", "Dale", ""], ["Peng", "Fuchun", ""], ["Zhao", "Yunxin", ""]]}, {"id": "1212.2516", "submitter": "Ricardo Silva", "authors": "Ricardo Silva, Richard Scheines, Clark Glymour, Peter L. Spirtes", "title": "Learning Measurement Models for Unobserved Variables", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-543-550", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observed associations in a database may be due in whole or part to variations\nin unrecorded (latent) variables. Identifying such variables and their causal\nrelationships with one another is a principal goal in many scientific and\npractical domains. Previous work shows that, given a partition of observed\nvariables such that members of a class share only a single latent common cause,\nstandard search algorithms for causal Bayes nets can infer structural relations\nbetween latent variables. We introduce an algorithm for discovering such\npartitions when they exist. Uniquely among available procedures, the algorithm\nis (asymptotically) correct under standard assumptions in causal Bayes net\nsearch algorithms, requires no prior knowledge of the number of latent\nvariables, and does not depend on the mathematical form of the relationships\namong the latent variables. We evaluate the algorithm on a variety of simulated\ndata sets.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:15 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Silva", "Ricardo", ""], ["Scheines", "Richard", ""], ["Glymour", "Clark", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1212.2517", "submitter": "Eran Segal", "authors": "Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman", "title": "Learning Module Networks", "comments": "Appears in Proceedings of the Nineteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2003)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2003-PG-525-534", "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for learning Bayesian network structure can discover dependency\nstructure between observed variables, and have been shown to be useful in many\napplications. However, in domains that involve a large number of variables, the\nspace of possible network structures is enormous, making it difficult, for both\ncomputational and statistical reasons, to identify a good model. In this paper,\nwe consider a solution to this problem, suitable for domains where many\nvariables have similar behavior. Our method is based on a new class of models,\nwhich we call module networks. A module network explicitly represents the\nnotion of a module - a set of variables that have the same parents in the\nnetwork and share the same conditional probability distribution. We define the\nsemantics of module networks, and describe an algorithm that learns a module\nnetwork from data. The algorithm learns both the partitioning of the variables\ninto modules and the dependency structure between the variables. We evaluate\nour algorithm on synthetic data, and on real data in the domains of gene\nexpression and the stock market. Our results show that module networks\ngeneralize better than Bayesian networks, and that the learned module network\nstructure reveals regularities that are obscured in learned Bayesian networks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 15:08:06 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Segal", "Eran", ""], ["Pe'er", "Dana", ""], ["Regev", "Aviv", ""], ["Koller", "Daphne", ""], ["Friedman", "Nir", ""]]}, {"id": "1212.2573", "submitter": "K. S. Sesh Kumar", "authors": "K. S. Sesh Kumar (LIENS, INRIA Paris - Rocquencourt), Francis Bach\n  (LIENS, INRIA Paris - Rocquencourt)", "title": "Convex Relaxations for Learning Bounded Treewidth Decomposable Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the structure of undirected graphical\nmodels with bounded treewidth, within the maximum likelihood framework. This is\nan NP-hard problem and most approaches consider local search techniques. In\nthis paper, we pose it as a combinatorial optimization problem, which is then\nrelaxed to a convex optimization problem that involves searching over the\nforest and hyperforest polytopes with special structures, independently. A\nsupergradient method is used to solve the dual problem, with a run-time\ncomplexity of $O(k^3 n^{k+2} \\log n)$ for each iteration, where $n$ is the\nnumber of variables and $k$ is a bound on the treewidth. We compare our\napproach to state-of-the-art methods on synthetic datasets and classical\nbenchmarks, showing the gains of the novel convex approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 18:22:31 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Kumar", "K. S. Sesh", "", "LIENS, INRIA Paris - Rocquencourt"], ["Bach", "Francis", "", "LIENS, INRIA Paris - Rocquencourt"]]}, {"id": "1212.2617", "submitter": "Peter Richtarik", "authors": "William Hulme, Peter Richt\\'arik, Lynne McGuire and Alison Green", "title": "Optimal diagnostic tests for sporadic Creutzfeldt-Jakob disease based on\n  support vector machine classification of RT-QuIC data", "comments": "32 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study numerical construction of optimal clinical diagnostic\ntests for detecting sporadic Creutzfeldt-Jakob disease (sCJD). A cerebrospinal\nfluid sample (CSF) from a suspected sCJD patient is subjected to a process\nwhich initiates the aggregation of a protein present only in cases of sCJD.\nThis aggregation is indirectly observed in real-time at regular intervals, so\nthat a longitudinal set of data is constructed that is then analysed for\nevidence of this aggregation. The best existing test is based solely on the\nfinal value of this set of data, which is compared against a threshold to\nconclude whether or not aggregation, and thus sCJD, is present. This test\ncriterion was decided upon by analysing data from a total of 108 sCJD and\nnon-sCJD samples, but this was done subjectively and there is no supporting\nmathematical analysis declaring this criterion to be exploiting the available\ndata optimally. This paper addresses this deficiency, seeking to validate or\nimprove the test primarily via support vector machine (SVM) classification.\nBesides this, we address a number of additional issues such as i) early\nstopping of the measurement process, ii) the possibility of detecting the\nparticular type of sCJD and iii) the incorporation of additional patient data\nsuch as age, sex, disease duration and timing of CSF sampling into the\nconstruction of the test.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 20:33:16 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Hulme", "William", ""], ["Richt\u00e1rik", "Peter", ""], ["McGuire", "Lynne", ""], ["Green", "Alison", ""]]}, {"id": "1212.2686", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow, Aaron Courville, Yoshua Bengio", "title": "Joint Training of Deep Boltzmann Machines", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods require an initial learning pass that trains the deep Boltzmann machine\ngreedily, one layer at a time, or do not perform well on classifi- cation\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 01:59:27 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Goodfellow", "Ian", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1212.2767", "submitter": "Ioannis Psorakis", "authors": "Ioannis Psorakis, Iead Rezek, Zach Frankel, Stephen J. Roberts", "title": "Bayesian one-mode projection for dynamic bipartite graphs", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "PARG 12-12(1)", "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian methodology for one-mode projecting a bipartite network\nthat is being observed across a series of discrete time steps. The resulting\none mode network captures the uncertainty over the presence/absence of each\nlink and provides a probability distribution over its possible weight values.\nAdditionally, the incorporation of prior knowledge over previous states makes\nthe resulting network less sensitive to noise and missing observations that\nusually take place during the data collection process. The methodology consists\nof computationally inexpensive update rules and is scalable to large problems,\nvia an appropriate distributed implementation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 10:55:27 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Psorakis", "Ioannis", ""], ["Rezek", "Iead", ""], ["Frankel", "Zach", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1212.2834", "submitter": "Mehrdad Yaghoobi Vaighan", "authors": "Mehrdad Yaghoobi, Laurent Daudet, Michael E. Davies", "title": "Dictionary Subselection Using an Overcomplete Joint Sparsity Model", "comments": "the title previously was \"Optimal Dictionary Selection Using an\n  Overcomplete Joint Sparsity Model\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural signals exhibit a sparse representation, whenever a suitable\ndescribing model is given. Here, a linear generative model is considered, where\nmany sparsity-based signal processing techniques rely on such a simplified\nmodel. As this model is often unknown for many classes of the signals, we need\nto select such a model based on the domain knowledge or using some exemplar\nsignals. This paper presents a new exemplar based approach for the linear model\n(called the dictionary) selection, for such sparse inverse problems. The\nproblem of dictionary selection, which has also been called the dictionary\nlearning in this setting, is first reformulated as a joint sparsity model. The\njoint sparsity model here differs from the standard joint sparsity model as it\nconsiders an overcompleteness in the representation of each signal, within the\nrange of selected subspaces. The new dictionary selection paradigm is examined\nwith some synthetic and realistic simulations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:02:20 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2013 09:31:45 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Yaghoobi", "Mehrdad", ""], ["Daudet", "Laurent", ""], ["Davies", "Michael E.", ""]]}, {"id": "1212.3185", "submitter": "Hong Zhao", "authors": "Hong Zhao, Fan Min and William Zhu", "title": "Cost-Sensitive Feature Selection of Data with Errors", "comments": "This paper has been withdrawn by the author due to an error in Figure\n  4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data mining applications, feature selection is an essential process since\nit reduces a model's complexity. The cost of obtaining the feature values must\nbe taken into consideration in many domains. In this paper, we study the\ncost-sensitive feature selection problem on numerical data with measurement\nerrors, test costs and misclassification costs. The major contributions of this\npaper are four-fold. First, a new data model is built to address test costs and\nmisclassification costs as well as error boundaries. Second, a covering-based\nrough set with measurement errors is constructed. Given a confidence interval,\nthe neighborhood is an ellipse in a two-dimension space, or an ellipsoidal in a\nthree-dimension space, etc. Third, a new cost-sensitive feature selection\nproblem is defined on this covering-based rough set. Fourth, both backtracking\nand heuristic algorithms are proposed to deal with this new problem. The\nalgorithms are tested on six UCI (University of California - Irvine) data sets.\nExperimental results show that (1) the pruning techniques of the backtracking\nalgorithm help reducing the number of operations significantly, and (2) the\nheuristic algorithm usually obtains optimal results. This study is a step\ntoward realistic applications of cost-sensitive learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 14:31:58 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 08:34:38 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2013 02:42:35 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Zhao", "Hong", ""], ["Min", "Fan", ""], ["Zhu", "William", ""]]}, {"id": "1212.3276", "submitter": "Sivan Sabato", "authors": "Sivan Sabato and Shai Shalev-Shwartz and Nathan Srebro and Daniel Hsu\n  and Tong Zhang", "title": "Learning Sparse Low-Threshold Linear Classifiers", "comments": null, "journal-ref": "Journal of Machine Learning Research, 16(Jul):1275-1304, 2015", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a non-negative linear classifier with a\n$1$-norm of at most $k$, and a fixed threshold, under the hinge-loss. This\nproblem generalizes the problem of learning a $k$-monotone disjunction. We\nprove that we can learn efficiently in this setting, at a rate which is linear\nin both $k$ and the size of the threshold, and that this is the best possible\nrate. We provide an efficient online learning algorithm that achieves the\noptimal rate, and show that in the batch case, empirical risk minimization\nachieves this rate as well. The rates we show are tighter than the uniform\nconvergence rate, which grows with $k^2$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 19:20:21 GMT"}, {"version": "v2", "created": "Sun, 6 Jul 2014 02:55:23 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 09:17:36 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Sabato", "Sivan", ""], ["Shalev-Shwartz", "Shai", ""], ["Srebro", "Nathan", ""], ["Hsu", "Daniel", ""], ["Zhang", "Tong", ""]]}, {"id": "1212.3390", "submitter": "A Majumder", "authors": "Anirban Majumder and Nisheeth Shrivastava", "title": "Know Your Personalization: Learning Topic level Personalization in\n  Online Services", "comments": "privacy, personalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online service platforms (OSPs), such as search engines, news-websites,\nad-providers, etc., serve highly pe rsonalized content to the user, based on\nthe profile extracted from his history with the OSP. Although personalization\n(generally) leads to a better user experience, it also raises privacy concerns\nfor the user---he does not know what is present in his profile and more\nimportantly, what is being used to per sonalize content for him. In this paper,\nwe capture OSP's personalization for an user in a new data structure called the\nperson alization vector ($\\eta$), which is a weighted vector over a set of\ntopics, and present techniques to compute it for users of an OSP. Our approach\ntreats OSPs as black-boxes, and extracts $\\eta$ by mining only their output,\nspecifical ly, the personalized (for an user) and vanilla (without any user\ninformation) contents served, and the differences in these content. We\nformulate a new model called Latent Topic Personalization (LTP) that captures\nthe personalization vector into a learning framework and present efficient\ninference algorithms for it. We do extensive experiments for search result\npersonalization using both data from real Google users and synthetic datasets.\nOur results show high accuracy (R-pre = 84%) of LTP in finding personalized\ntopics. For Google data, our qualitative results show how LTP can also\nidentifies evidences---queries for results on a topic with high $\\eta$ value\nwere re-ranked. Finally, we show how our approach can be used to build a new\nPrivacy evaluation framework focused at end-user privacy on commercial OSPs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 04:12:21 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Majumder", "Anirban", ""], ["Shrivastava", "Nisheeth", ""]]}, {"id": "1212.3454", "submitter": "EPTCS", "authors": "Uli Fahrenberg (Irisa / INRIA Rennes, France), Axel Legay (Irisa /\n  INRIA Rennes, France), Claus Thrane (Aalborg University, Denmark)", "title": "Proceedings Quantities in Formal Methods", "comments": null, "journal-ref": "EPTCS 103, 2012", "doi": "10.4204/EPTCS.103", "report-no": null, "categories": "cs.LO cs.FL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Workshop on Quantities in Formal\nMethods, QFM 2012, held in Paris, France on 28 August 2012. The workshop was\naffiliated with the 18th Symposium on Formal Methods, FM 2012. The focus of the\nworkshop was on quantities in modeling, verification, and synthesis. Modern\napplications of formal methods require to reason formally on quantities such as\ntime, resources, or probabilities. Standard formal methods and tools have\ngotten very good at modeling (and verifying) qualitative properties: whether or\nnot certain events will occur. During the last years, these methods and tools\nhave been extended to also cover quantitative aspects, notably leading to tools\nlike e.g. UPPAAL (for real-time systems), PRISM (for probabilistic systems),\nand PHAVer (for hybrid systems). A lot of work remains to be done however\nbefore these tools can be used in the industrial applications at which they are\naiming.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 12:38:37 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Fahrenberg", "Uli", "", "Irisa / INRIA Rennes, France"], ["Legay", "Axel", "", "Irisa /\n  INRIA Rennes, France"], ["Thrane", "Claus", "", "Aalborg University, Denmark"]]}, {"id": "1212.3618", "submitter": "EPTCS", "authors": "Ekaterina Komendantskaya (School of Computing, University of Dundee),\n  J\\'onathan Heras (School of Computing, University of Dundee), Gudmund Grov\n  (School of Mathematical and Computer Sciences, Heriot-Watt University)", "title": "Machine Learning in Proof General: Interfacing Interfaces", "comments": "In Proceedings UITP 2012, arXiv:1307.1528", "journal-ref": "EPTCS 118, 2013, pp. 15-41", "doi": "10.4204/EPTCS.118.2", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ML4PG - a machine learning extension for Proof General. It allows\nusers to gather proof statistics related to shapes of goals, sequences of\napplied tactics, and proof tree structures from the libraries of interactive\nhigher-order proofs written in Coq and SSReflect. The gathered data is\nclustered using the state-of-the-art machine learning algorithms available in\nMATLAB and Weka. ML4PG provides automated interfacing between Proof General and\nMATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints\nin the process of interactive proof development.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 21:06:34 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2013 05:19:38 GMT"}], "update_date": "2013-07-09", "authors_parsed": [["Komendantskaya", "Ekaterina", "", "School of Computing, University of Dundee"], ["Heras", "J\u00f3nathan", "", "School of Computing, University of Dundee"], ["Grov", "Gudmund", "", "School of Mathematical and Computer Sciences, Heriot-Watt University"]]}, {"id": "1212.3631", "submitter": "Pablo Sprechmann", "authors": "Pablo Sprechmann, Alex M. Bronstein and Guillermo Sapiro", "title": "Learning efficient sparse and low rank models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsimony, including sparsity and low rank, has been shown to successfully\nmodel data in numerous machine learning and signal processing tasks.\nTraditionally, such modeling approaches rely on an iterative algorithm that\nminimizes an objective function with parsimony-promoting terms. The inherently\nsequential structure and data-dependent complexity and latency of iterative\noptimization constitute a major limitation in many applications requiring\nreal-time performance or involving large-scale data. Another limitation\nencountered by these modeling techniques is the difficulty of their inclusion\nin discriminative learning scenarios. In this work, we propose to move the\nemphasis from the model to the pursuit algorithm, and develop a process-centric\nview of parsimonious modeling, in which a learned deterministic\nfixed-complexity pursuit process is used in lieu of iterative optimization. We\nshow a principled way to construct learnable pursuit process architectures for\nstructured sparse and robust low rank models, derived from the iteration of\nproximal descent algorithms. These architectures learn to approximate the exact\nparsimonious representation at a fraction of the complexity of the standard\noptimization methods. We also show that appropriate training regimes allow to\nnaturally extend parsimonious models to discriminative settings.\nState-of-the-art results are demonstrated on several challenging problems in\nimage and audio processing with several orders of magnitude speedup compared to\nthe exact optimization algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 22:50:44 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Sprechmann", "Pablo", ""], ["Bronstein", "Alex M.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1212.3669", "submitter": "Gabriele Modena", "authors": "Gabriele Modena", "title": "A metric for software vulnerabilities classification", "comments": "The original version of this paper was written in Feb 2009 to report\n  results of a Machine Learning research project at the University of\n  Amsterdam. At the time this research has been carried out the author was\n  affiliated (Graduate Student) with the University of Amsterdam, The\n  Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability discovery and exploits detection are two wide areas of study in\nsoftware engineering. This preliminary work tries to combine existing methods\nwith machine learning techniques to define a metric classification of\nvulnerable computer programs. First a feature set has been defined and later\ntwo models have been tested against real world vulnerabilities. A relation\nbetween the classifier choice and the features has also been outlined.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2012 09:53:16 GMT"}, {"version": "v2", "created": "Mon, 21 Jul 2014 21:11:36 GMT"}], "update_date": "2014-07-23", "authors_parsed": [["Modena", "Gabriele", ""]]}, {"id": "1212.3765", "submitter": "Mohammad Bavandpour", "authors": "Hamid Soleimani, Arash Ahmadi and Mohammad Bavandpour", "title": "Biologically Inspired Spiking Neurons : Piecewise Linear Models and\n  Digital Implementation", "comments": "14 pages, 16 figures", "journal-ref": "IEEE Transactions On Circuits And Systems I: Regular Papers, Vol.\n  59, NO. 12, December 2012", "doi": "10.1109/TCSI.2012.2206463", "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  There has been a strong push recently to examine biological scale simulations\nof neuromorphic algorithms to achieve stronger inference capabilities. This\npaper presents a set of piecewise linear spiking neuron models, which can\nreproduce different behaviors, similar to the biological neuron, both for a\nsingle neuron as well as a network of neurons. The proposed models are\ninvestigated, in terms of digital implementation feasibility and costs,\ntargeting large scale hardware implementation. Hardware synthesis and physical\nimplementations on FPGA show that the proposed models can produce precise\nneural behaviors with higher performance and considerably lower implementation\ncosts compared with the original model. Accordingly, a compact structure of the\nmodels which can be trained with supervised and unsupervised learning\nalgorithms has been developed. Using this structure and based on a spike rate\ncoding, a character recognition case study has been implemented and tested.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 09:05:02 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Soleimani", "Hamid", ""], ["Ahmadi", "Arash", ""], ["Bavandpour", "Mohammad", ""]]}, {"id": "1212.3850", "submitter": "Nima Noorshams", "authors": "Nima Noorshams and Martin J. Wainwright", "title": "Belief Propagation for Continuous State Spaces: Stochastic\n  Message-Passing with Quantitative Guarantees", "comments": "Portions of the results were presented at the International Symposium\n  on Information Theory 2012. The results were also submitted to the Journal of\n  Machine Learning Research on December 16th 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sum-product or belief propagation (BP) algorithm is a widely used\nmessage-passing technique for computing approximate marginals in graphical\nmodels. We introduce a new technique, called stochastic orthogonal series\nmessage-passing (SOSMP), for computing the BP fixed point in models with\ncontinuous random variables. It is based on a deterministic approximation of\nthe messages via orthogonal series expansion, and a stochastic approximation\nvia Monte Carlo estimates of the integral updates of the basis coefficients. We\nprove that the SOSMP iterates converge to a \\delta-neighborhood of the unique\nBP fixed point for any tree-structured graph, and for any graphs with cycles in\nwhich the BP updates satisfy a contractivity condition. In addition, we\ndemonstrate how to choose the number of basis coefficients as a function of the\ndesired approximation accuracy \\delta and smoothness of the compatibility\nfunctions. We illustrate our theory with both simulated examples and in\napplication to optical flow estimation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 23:22:56 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Noorshams", "Nima", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1212.3873", "submitter": "EPTCS", "authors": "Hua Mao (AAU), Yingke Chen (AAU), Manfred Jaeger (AAU), Thomas D.\n  Nielsen (AAU), Kim G. Larsen (AAU), Brian Nielsen (AAU)", "title": "Learning Markov Decision Processes for Model Checking", "comments": "In Proceedings QFM 2012, arXiv:1212.3454", "journal-ref": "EPTCS 103, 2012, pp. 49-63", "doi": "10.4204/EPTCS.103.6", "report-no": null, "categories": "cs.LG cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing an accurate system model for formal model verification can be\nboth resource demanding and time-consuming. To alleviate this shortcoming,\nalgorithms have been proposed for automatically learning system models based on\nobserved system behaviors. In this paper we extend the algorithm on learning\nprobabilistic automata to reactive systems, where the observed system behavior\nis in the form of alternating sequences of inputs and outputs. We propose an\nalgorithm for automatically learning a deterministic labeled Markov decision\nprocess model from the observed behavior of a reactive system. The proposed\nlearning algorithm is adapted from algorithms for learning deterministic\nprobabilistic finite automata, and extended to include both probabilistic and\nnondeterministic transitions. The algorithm is empirically analyzed and\nevaluated by learning system models of slot machines. The evaluation is\nperformed by analyzing the probabilistic linear temporal logic properties of\nthe system as well as by analyzing the schedulers, in particular the optimal\nschedulers, induced by the learned models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 03:40:47 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Mao", "Hua", "", "AAU"], ["Chen", "Yingke", "", "AAU"], ["Jaeger", "Manfred", "", "AAU"], ["Nielsen", "Thomas D.", "", "AAU"], ["Larsen", "Kim G.", "", "AAU"], ["Nielsen", "Brian", "", "AAU"]]}, {"id": "1212.3900", "submitter": "Liangjie Hong", "authors": "Liangjie Hong", "title": "A Tutorial on Probabilistic Latent Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial, I will discuss the details about how Probabilistic Latent\nSemantic Analysis (PLSA) is formalized and how different learning algorithms\nare proposed to learn the model.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 06:49:14 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2012 19:55:53 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Hong", "Liangjie", ""]]}, {"id": "1212.3913", "submitter": "Guoxu Zhou", "authors": "Guoxu Zhou and Andrzej Cichocki and Yu Zhang and Danilo Mandic", "title": "Group Component Analysis for Multiblock Data: Common and Individual\n  Feature Extraction", "comments": "13 pages,11 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, Volume:\n  27, Issue: 11, Nov. 2016", "doi": "10.1109/TNNLS.2015.2487364", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very often data we encounter in practice is a collection of matrices rather\nthan a single matrix. These multi-block data are naturally linked and hence\noften share some common features and at the same time they have their own\nindividual features, due to the background in which they are measured and\ncollected. In this study we proposed a new scheme of common and individual\nfeature analysis (CIFA) that processes multi-block data in a linked way aiming\nat discovering and separating their common and individual features. According\nto whether the number of common features is given or not, two efficient\nalgorithms were proposed to extract the common basis which is shared by all\ndata. Then feature extraction is performed on the common and the individual\nspaces separately by incorporating the techniques such as dimensionality\nreduction and blind source separation. We also discussed how the proposed CIFA\ncan significantly improve the performance of classification and clustering\ntasks by exploiting common and individual features of samples respectively. Our\nexperimental results show some encouraging features of the proposed methods in\ncomparison to the state-of-the-art methods on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 07:56:15 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2013 02:24:36 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2015 02:20:23 GMT"}, {"version": "v4", "created": "Sun, 12 Mar 2017 08:36:27 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Zhou", "Guoxu", ""], ["Cichocki", "Andrzej", ""], ["Zhang", "Yu", ""], ["Mandic", "Danilo", ""]]}, {"id": "1212.4137", "submitter": "Martin Tak\\'a\\v{c}", "authors": "Peter Richt\\'arik, Majid Jahani, Selin Damla Ahipa\\c{s}ao\\u{g}lu,\n  Martin Tak\\'a\\v{c}", "title": "Alternating Maximization: Unifying Framework for 8 Sparse PCA\n  Formulations and Efficient Parallel Codes", "comments": "29 pages, 9 tables, 7 figures (the paper is accompanied by a release\n  of the open-source code '24am')", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a multivariate data set, sparse principal component analysis (SPCA)\naims to extract several linear combinations of the variables that together\nexplain the variance in the data as much as possible, while controlling the\nnumber of nonzero loadings in these combinations. In this paper we consider 8\ndifferent optimization formulations for computing a single sparse loading\nvector; these are obtained by combining the following factors: we employ two\nnorms for measuring variance (L2, L1) and two sparsity-inducing norms (L0, L1),\nwhich are used in two different ways (constraint, penalty). Three of our\nformulations, notably the one with L0 constraint and L1 variance, have not been\nconsidered in the literature. We give a unifying reformulation which we propose\nto solve via a natural alternating maximization (AM) method. We show the the AM\nmethod is nontrivially equivalent to GPower (Journ\\'{e}e et al; JMLR\n11:517--553, 2010) for all our formulations. Besides this, we provide 24\nefficient parallel SPCA implementations: 3 codes (multi-core, GPU and cluster)\nfor each of the 8 problems. Parallelism in the methods is aimed at i) speeding\nup computations (our GPU code can be 100 times faster than an efficient serial\ncode written in C++), ii) obtaining solutions explaining more variance and iii)\ndealing with big data problems (our cluster code is able to solve a 357 GB\nproblem in about a minute).\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 20:53:35 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 00:50:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Jahani", "Majid", ""], ["Ahipa\u015fao\u011flu", "Selin Damla", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1212.4174", "submitter": "Mahantesh Halappanavar", "authors": "Chad Scherrer, Ambuj Tewari, Mahantesh Halappanavar, David Haglin", "title": "Feature Clustering for Accelerating Parallel Coordinate Descent", "comments": "Accepted for publication in the proceedings of NIPS (Neural\n  Information Processing Systems Foundations) 2012, Lake Tahoe, Nevada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale L1-regularized loss minimization problems arise in\nhigh-dimensional applications such as compressed sensing and high-dimensional\nsupervised learning, including classification and regression problems.\nHigh-performance algorithms and implementations are critical to efficiently\nsolving these problems. Building upon previous work on coordinate descent\nalgorithms for L1-regularized problems, we introduce a novel family of\nalgorithms called block-greedy coordinate descent that includes, as special\ncases, several existing algorithms such as SCD, Greedy CD, Shotgun, and\nThread-Greedy. We give a unified convergence analysis for the family of\nblock-greedy algorithms. The analysis suggests that block-greedy coordinate\ndescent can better exploit parallelism if features are clustered so that the\nmaximum inner product between features in different blocks is small. Our\ntheoretical convergence analysis is supported with experimental re- sults using\ndata from diverse real-world applications. We hope that algorithmic approaches\nand convergence analysis we provide will not only advance the field, but will\nalso encourage researchers to systematically explore the design space of\nalgorithms for solving large-scale L1-regularization problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 21:43:31 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Scherrer", "Chad", ""], ["Tewari", "Ambuj", ""], ["Halappanavar", "Mahantesh", ""], ["Haglin", "David", ""]]}, {"id": "1212.4347", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Alice Oh", "title": "Bayesian Group Nonnegative Matrix Factorization for EEG Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative model of a group EEG analysis, based on appropriate\nkernel assumptions on EEG data. We derive the variational inference update rule\nusing various approximation techniques. The proposed model outperforms the\ncurrent state-of-the-art algorithms in terms of common pattern extraction. The\nvalidity of the proposed model is tested on the BCI competition dataset.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 13:35:38 GMT"}], "update_date": "2012-12-19", "authors_parsed": [["Shin", "Bonggun", ""], ["Oh", "Alice", ""]]}, {"id": "1212.4507", "submitter": "Joe Staines", "authors": "Joe Staines and David Barber", "title": "Variational Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a general technique that can be used to form a differentiable\nbound on the optima of non-differentiable or discrete objective functions. We\nform a unified description of these methods and consider under which\ncircumstances the bound is concave. In particular we consider two concrete\napplications of the method, namely sparse learning and support vector\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 21:06:10 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2012 18:49:18 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Staines", "Joe", ""], ["Barber", "David", ""]]}, {"id": "1212.4522", "submitter": "Yunchao Gong", "authors": "Yunchao Gong and Qifa Ke and Michael Isard and Svetlana Lazebnik", "title": "A Multi-View Embedding Space for Modeling Internet Images, Tags, and\n  their Semantics", "comments": "To Appear: International Journal of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of modeling Internet images and\nassociated text or tags for tasks such as image-to-image search, tag-to-image\nsearch, and image-to-tag search (image annotation). We start with canonical\ncorrelation analysis (CCA), a popular and successful approach for mapping\nvisual and textual features to the same latent space, and incorporate a third\nview capturing high-level image semantics, represented either by a single\ncategory or multiple non-mutually-exclusive concepts. We present two ways to\ntrain the three-view embedding: supervised, with the third view coming from\nground-truth labels or search keywords; and unsupervised, with semantic themes\nautomatically obtained by clustering the tags. To ensure high accuracy for\nretrieval tasks while keeping the learning process scalable, we combine\nmultiple strong visual features and use explicit nonlinear kernel mappings to\nefficiently approximate kernel CCA. To perform retrieval, we use a specially\ndesigned similarity function in the embedded space, which substantially\noutperforms the Euclidean distance. The resulting system produces compelling\nqualitative results and outperforms a number of two-view baselines on retrieval\ntasks on three large-scale Internet image datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 22:02:43 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2013 19:14:58 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Gong", "Yunchao", ""], ["Ke", "Qifa", ""], ["Isard", "Michael", ""], ["Lazebnik", "Svetlana", ""]]}, {"id": "1212.4675", "submitter": "Yufei Han", "authors": "Yufei Han (INRIA Rocquencourt), Fabien Moutarde (CAOR)", "title": "Analysis of Large-scale Traffic Dynamics using Non-negative Tensor\n  Factorization", "comments": "ITS World Congress 2012 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our work on clustering and prediction of temporal\ndynamics of global congestion configurations in large-scale road networks.\nInstead of looking into temporal traffic state variation of individual links,\nor of small areas, we focus on spatial congestion configurations of the whole\nnetwork. In our work, we aim at describing the typical temporal dynamic\npatterns of this network-level traffic state and achieving long-term prediction\nof the large-scale traffic dynamics, in a unified data-mining framework. To\nthis end, we formulate this joint task using Non-negative Tensor Factorization\n(NTF), which has been shown to be a useful decomposition tools for multivariate\ndata sequences. Clustering and prediction are performed based on the compact\ntensor factorization results. Experiments on large-scale simulated data\nillustrate the interest of our method with promising results for long-term\nforecast of traffic evolution.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 20:17:56 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Han", "Yufei", "", "INRIA Rocquencourt"], ["Moutarde", "Fabien", "", "CAOR"]]}, {"id": "1212.4775", "submitter": "Mario Frank", "authors": "Mario Frank, Joachim M. Buhmann, David Basin", "title": "Role Mining with Probabilistic Models", "comments": "accepted for publication at ACM Transactions on Information and\n  System Security (TISSEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role mining tackles the problem of finding a role-based access control (RBAC)\nconfiguration, given an access-control matrix assigning users to access\npermissions as input. Most role mining approaches work by constructing a large\nset of candidate roles and use a greedy selection strategy to iteratively pick\na small subset such that the differences between the resulting RBAC\nconfiguration and the access control matrix are minimized. In this paper, we\nadvocate an alternative approach that recasts role mining as an inference\nproblem rather than a lossy compression problem. Instead of using combinatorial\nalgorithms to minimize the number of roles needed to represent the\naccess-control matrix, we derive probabilistic models to learn the RBAC\nconfiguration that most likely underlies the given matrix.\n  Our models are generative in that they reflect the way that permissions are\nassigned to users in a given RBAC configuration. We additionally model how\nuser-permission assignments that conflict with an RBAC configuration emerge and\nwe investigate the influence of constraints on role hierarchies and on the\nnumber of assignments. In experiments with access-control matrices from\nreal-world enterprises, we compare our proposed models with other role mining\nmethods. Our results show that our probabilistic models infer roles that\ngeneralize well to new system users for a wide variety of data, while other\nmodels' generalization abilities depend on the dataset given.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 18:12:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2013 17:27:55 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2013 22:24:15 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Frank", "Mario", ""], ["Buhmann", "Joachim M.", ""], ["Basin", "David", ""]]}, {"id": "1212.4777", "submitter": "Ankur Moitra", "authors": "Sanjeev Arora, Rong Ge, Yoni Halpern, David Mimno, Ankur Moitra, David\n  Sontag, Yichen Wu, Michael Zhu", "title": "A Practical Algorithm for Topic Modeling with Provable Guarantees", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models provide a useful method for dimensionality reduction and\nexploratory data analysis in large text corpora. Most approaches to topic model\ninference have been based on a maximum likelihood objective. Efficient\nalgorithms exist that approximate this objective, but they have no provable\nguarantees. Recently, algorithms have been introduced that provide provable\nbounds, but these algorithms are not practical because they are inefficient and\nnot robust to violations of model assumptions. In this paper we present an\nalgorithm for topic model inference that is both provable and practical. The\nalgorithm produces results comparable to the best MCMC implementations while\nrunning orders of magnitude faster.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 18:14:51 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Halpern", "Yoni", ""], ["Mimno", "David", ""], ["Moitra", "Ankur", ""], ["Sontag", "David", ""], ["Wu", "Yichen", ""], ["Zhu", "Michael", ""]]}, {"id": "1212.5091", "submitter": "Elaine Tsiang", "authors": "Elaine Tsiang", "title": "Maximally Informative Observables and Categorical Perception", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": "MIMC000", "categories": "cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We formulate the problem of perception in the framework of information\ntheory, and prove that categorical perception is equivalent to the existence of\nan observable that has the maximum possible information on the target of\nperception. We call such an observable maximally informative. Regardless\nwhether categorical perception is real, maximally informative observables can\nform the basis of a theory of perception. We conclude with the implications of\nsuch a theory for the problem of speech perception.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2012 17:40:07 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Tsiang", "Elaine", ""]]}, {"id": "1212.5101", "submitter": "Tamal Ghosh Tamal Ghosh", "authors": "Sourav Sengupta, Tamal Ghosh, Pranab K Dan, Manojit Chattopadhyay", "title": "Hybrid Fuzzy-ART based K-Means Clustering Methodology to Cellular\n  Manufacturing Using Operational Time", "comments": "Proceedings of International Conference on Operational Excellence for\n  Global Competitiveness (ICOEGC 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new hybrid Fuzzy-ART based K-Means Clustering technique\nto solve the part machine grouping problem in cellular manufacturing systems\nconsidering operational time. The performance of the proposed technique is\ntested with problems from open literature and the results are compared to the\nexisting clustering models such as simple K-means algorithm and modified ART1\nalgorithm using an efficient modified performance measure known as modified\ngrouping efficiency (MGE) as found in the literature. The results support the\nbetter performance of the proposed algorithm. The Novelty of this study lies in\nthe simple and efficient methodology to produce quick solutions for shop floor\nmanagers with least computational efforts and time.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 15:53:43 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Sengupta", "Sourav", ""], ["Ghosh", "Tamal", ""], ["Dan", "Pranab K", ""], ["Chattopadhyay", "Manojit", ""]]}, {"id": "1212.5156", "submitter": "Christopher R. Genovese", "authors": "Christopher R. Genovese, Marco Perone-Pacifico, Isabella Verdinelli,\n  Larry Wasserman", "title": "Nonparametric ridge estimation", "comments": "Published in at http://dx.doi.org/10.1214/14-AOS1218 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics, Vol. 42, No. 4, 1511-1545 (2014)", "doi": "10.1214/14-AOS1218", "report-no": "IMS-AOS-AOS1218", "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the ridges of a density function. Ridge\nestimation is an extension of mode finding and is useful for understanding the\nstructure of a density. It can also be used to find hidden structure in point\ncloud data. We show that, under mild regularity conditions, the ridges of the\nkernel density estimator consistently estimate the ridges of the true density.\nWhen the data are noisy measurements of a manifold, we show that the ridges are\nclose and topologically similar to the hidden manifold. To find the estimated\nridges in practice, we adapt the modified mean-shift algorithm proposed by\nOzertem and Erdogmus [J. Mach. Learn. Res. 12 (2011) 1249-1286]. Some numerical\nexperiments verify that the algorithm is accurate.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 17:41:23 GMT"}, {"version": "v2", "created": "Thu, 21 Aug 2014 12:10:31 GMT"}, {"version": "v3", "created": "Thu, 28 Aug 2014 08:28:48 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Genovese", "Christopher R.", ""], ["Perone-Pacifico", "Marco", ""], ["Verdinelli", "Isabella", ""], ["Wasserman", "Larry", ""]]}, {"id": "1212.5359", "submitter": "Hannah Inbarani", "authors": "K. Dhanalakshmi, H. Hannah Inbarani", "title": "Fuzzy soft rough K-Means clustering approach for gene expression data", "comments": "7 pages, IJSER Vol.3 Issue: 10 Oct 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the widely used data mining techniques for medical\ndiagnosis. Clustering can be considered as the most important unsupervised\nlearning technique. Most of the clustering methods group data based on distance\nand few methods cluster data based on similarity. The clustering algorithms\nclassify gene expression data into clusters and the functionally related genes\nare grouped together in an efficient manner. The groupings are constructed such\nthat the degree of relationship is strong among members of the same cluster and\nweak among members of different clusters. In this work, we focus on a\nsimilarity relationship among genes with similar expression patterns so that a\nconsequential and simple analytical decision can be made from the proposed\nFuzzy Soft Rough K-Means algorithm. The algorithm is developed based on Fuzzy\nSoft sets and Rough sets. Comparative analysis of the proposed work is made\nwith bench mark algorithms like K-Means and Rough K-Means and efficiency of the\nproposed algorithm is illustrated in this work by using various cluster\nvalidity measures such as DB index and Xie-Beni index.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 08:43:05 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Dhanalakshmi", "K.", ""], ["Inbarani", "H. Hannah", ""]]}, {"id": "1212.5391", "submitter": "Hannah Inbarani", "authors": "G. Jothi, H. Hannah Inbarani", "title": "Soft Set Based Feature Selection Approach for Lung Cancer Images", "comments": "7 pages, IJSER Vol.3 Issue . 10 Oct 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is the deadliest type of cancer for both men and women. Feature\nselection plays a vital role in cancer classification. This paper investigates\nthe feature selection process in Computed Tomographic (CT) lung cancer images\nusing soft set theory. We propose a new soft set based unsupervised feature\nselection algorithm. Nineteen features are extracted from the segmented lung\nimages using gray level co-occurence matrix (GLCM) and gray level different\nmatrix (GLDM). In this paper, an efficient Unsupervised Soft Set based Quick\nReduct (SSUSQR) algorithm is presented. This method is used to select features\nfrom the data set and compared with existing rough set based unsupervised\nfeature selection methods. Then K-Means and Self Organizing Map (SOM)\nclustering algorithms are used to cluster the data. The performance of the\nfeature selection algorithms is evaluated based on performance of clustering\ntechniques. The results show that the proposed method effectively removes\nredundant features.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 10:46:24 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Jothi", "G.", ""], ["Inbarani", "H. Hannah", ""]]}, {"id": "1212.5524", "submitter": "Gabriel Lopes", "authors": "Olivier Sprangers and Gabriel A. D. Lopes and Robert Babuska", "title": "Reinforcement learning for port-Hamiltonian systems", "comments": "submitted", "journal-ref": "IEEE Transactions on Cybernetics, Volume: 45 , Issue: 5 , May 2015", "doi": "10.1109/TCYB.2014.2343194", "report-no": null, "categories": "cs.SY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passivity-based control (PBC) for port-Hamiltonian systems provides an\nintuitive way of achieving stabilization by rendering a system passive with\nrespect to a desired storage function. However, in most instances the control\nlaw is obtained without any performance considerations and it has to be\ncalculated by solving a complex partial differential equation (PDE). In order\nto address these issues we introduce a reinforcement learning approach into the\nenergy-balancing passivity-based control (EB-PBC) method, which is a form of\nPBC in which the closed-loop energy is equal to the difference between the\nstored and supplied energies. We propose a technique to parameterize EB-PBC\nthat preserves the systems's PDE matching conditions, does not require the\nspecification of a global desired Hamiltonian, includes performance criteria,\nand is robust to extra non-linearities such as control input saturation. The\nparameters of the control law are found using actor-critic reinforcement\nlearning, enabling learning near-optimal control policies satisfying a desired\nclosed-loop energy landscape. The advantages are that near-optimal controllers\ncan be generated using standard energy shaping techniques and that the\nsolutions learned can be interpreted in terms of energy shaping and damping\ninjection, which makes it possible to numerically assess stability using\npassivity theory. From the reinforcement learning perspective, our proposal\nallows for the class of port-Hamiltonian systems to be incorporated in the\nactor-critic framework, speeding up the learning thanks to the resulting\nparameterization of the policy. The method has been successfully applied to the\npendulum swing-up problem in simulations and real-life experiments.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 16:57:28 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2013 16:16:31 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Sprangers", "Olivier", ""], ["Lopes", "Gabriel A. D.", ""], ["Babuska", "Robert", ""]]}, {"id": "1212.5637", "submitter": "Claudio Gentile", "authors": "Nicolo' Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "Random Spanning Trees and the Prediction of Weighted Graphs", "comments": "Appeared in ICML 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of sequentially predicting the binary labels on\nthe nodes of an arbitrary weighted graph. We show that, under a suitable\nparametrization of the problem, the optimal number of prediction mistakes can\nbe characterized (up to logarithmic factors) by the cutsize of a random\nspanning tree of the graph. The cutsize is induced by the unknown adversarial\nlabeling of the graph nodes. In deriving our characterization, we obtain a\nsimple randomized algorithm achieving in expectation the optimal mistake bound\non any polynomially connected weighted graph. Our algorithm draws a random\nspanning tree of the original graph and then predicts the nodes of this tree in\nconstant expected amortized time and linear space. Experiments on real-world\ndatasets show that our method compares well to both global (Perceptron) and\nlocal (label propagation) methods, while being generally faster in practice.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 23:51:21 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Cesa-Bianchi", "Nicolo'", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1212.5701", "submitter": "Matthew Zeiler", "authors": "Matthew D. Zeiler", "title": "ADADELTA: An Adaptive Learning Rate Method", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel per-dimension learning rate method for gradient descent\ncalled ADADELTA. The method dynamically adapts over time using only first order\ninformation and has minimal computational overhead beyond vanilla stochastic\ngradient descent. The method requires no manual tuning of a learning rate and\nappears robust to noisy gradient information, different model architecture\nchoices, various data modalities and selection of hyperparameters. We show\npromising results compared to other methods on the MNIST digit classification\ntask using a single machine and on a large scale voice dataset in a distributed\ncluster environment.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2012 15:46:49 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Zeiler", "Matthew D.", ""]]}, {"id": "1212.5841", "submitter": "Andrei Zinovyev Dr.", "authors": "Andrei Zinovyev and Evgeny Mirkes", "title": "Data complexity measured by principal graphs", "comments": "Computers and Mathematics with Applications, in press", "journal-ref": null, "doi": "10.1016/j.camwa.2012.12.009", "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to measure the complexity of a finite set of vectors embedded in a\nmultidimensional space? This is a non-trivial question which can be approached\nin many different ways. Here we suggest a set of data complexity measures using\nuniversal approximators, principal cubic complexes. Principal cubic complexes\ngeneralise the notion of principal manifolds for datasets with non-trivial\ntopologies. The type of the principal cubic complex is determined by its\ndimension and a grammar of elementary graph transformations. The simplest\ngrammar produces principal trees.\n  We introduce three natural types of data complexity: 1) geometric (deviation\nof the data's approximator from some \"idealized\" configuration, such as\ndeviation from harmonicity); 2) structural (how many elements of a principal\ngraph are needed to approximate the data), and 3) construction complexity (how\nmany applications of elementary graph transformations are needed to construct\nthe principal object starting from the simplest one).\n  We compute these measures for several simulated and real-life data\ndistributions and show them in the \"accuracy-complexity\" plots, helping to\noptimize the accuracy/complexity ratio. We discuss various issues connected\nwith measuring data complexity. Software for computing data complexity measures\nfrom principal cubic complexes is provided as well.\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2012 23:20:14 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2013 00:00:40 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Zinovyev", "Andrei", ""], ["Mirkes", "Evgeny", ""]]}, {"id": "1212.5860", "submitter": "Shenghuo Zhu", "authors": "Shenghuo Zhu", "title": "A short note on the tail bound of Wishart distribution", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the tail bound of the emperical covariance of multivariate normal\ndistribution. Following the work of (Gittens & Tropp, 2011), we provide a tail\nbound with a small constant.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 03:31:15 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Zhu", "Shenghuo", ""]]}, {"id": "1212.5921", "submitter": "Miguel \\'A. Carreira-Perpi\\~n\\'an", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an and Weiran Wang", "title": "Distributed optimization of deeply nested systems", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In science and engineering, intelligent processing of complex signals such as\nimages, sound or language is often performed by a parameterized hierarchy of\nnonlinear processing layers, sometimes biologically inspired. Hierarchical\nsystems (or, more generally, nested systems) offer a way to generate complex\nmappings using simple stages. Each layer performs a different operation and\nachieves an ever more sophisticated representation of the input, as, for\nexample, in an deep artificial neural network, an object recognition cascade in\ncomputer vision or a speech front-end processing. Joint estimation of the\nparameters of all the layers and selection of an optimal architecture is widely\nconsidered to be a difficult numerical nonconvex optimization problem,\ndifficult to parallelize for execution in a distributed computation\nenvironment, and requiring significant human expert effort, which leads to\nsuboptimal systems in practice. We describe a general mathematical strategy to\nlearn the parameters and, to some extent, the architecture of nested systems,\ncalled the method of auxiliary coordinates (MAC). This replaces the original\nproblem involving a deeply nested function with a constrained problem involving\na different function in an augmented space without nesting. The constrained\nproblem may be solved with penalty-based methods using alternating optimization\nover the parameters and the auxiliary coordinates. MAC has provable\nconvergence, is easy to implement reusing existing algorithms for single\nlayers, can be parallelized trivially and massively, applies even when\nparameter derivatives are not available or not desirable, and is competitive\nwith state-of-the-art nonlinear optimizers even in the serial computation\nsetting, often providing reasonable models within a few iterations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 14:45:25 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Wang", "Weiran", ""]]}, {"id": "1212.5932", "submitter": "Leo Lahti", "authors": "Leo Lahti, Aurora Torrente, Laura L. Elo, Alvis Brazma, Johan Rung", "title": "Fully scalable online-preprocessing algorithm for short oligonucleotide\n  microarray atlases", "comments": "20 pages, 3 figures, 1 supplementary PDF", "journal-ref": "Leo Lahti, Aurora Torrente, Laura L. Elo, Alvis Brazma, Johan\n  Rung. A fully scalable online pre-processing algorithm for short\n  oligonucleotide microarray atlases. Nucleic Acids Research, Online April 5,\n  2013", "doi": "10.1093/nar/gkt229", "report-no": null, "categories": "q-bio.QM cs.CE cs.LG q-bio.GN stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Accumulation of standardized data collections is opening up novel\nopportunities for holistic characterization of genome function. The limited\nscalability of current preprocessing techniques has, however, formed a\nbottleneck for full utilization of contemporary microarray collections. While\nshort oligonucleotide arrays constitute a major source of genome-wide profiling\ndata, scalable probe-level preprocessing algorithms have been available only\nfor few measurement platforms based on pre-calculated model parameters from\nrestricted reference training sets. To overcome these key limitations, we\nintroduce a fully scalable online-learning algorithm that provides tools to\nprocess large microarray atlases including tens of thousands of arrays. Unlike\nthe alternatives, the proposed algorithm scales up in linear time with respect\nto sample size and is readily applicable to all short oligonucleotide\nplatforms. This is the only available preprocessing algorithm that can learn\nprobe-level parameters based on sequential hyperparameter updates at small,\nconsecutive batches of data, thus circumventing the extensive memory\nrequirements of the standard approaches and opening up novel opportunities to\ntake full advantage of contemporary microarray data collections. Moreover,\nusing the most comprehensive data collections to estimate probe-level effects\ncan assist in pinpointing individual probes affected by various biases and\nprovide new tools to guide array design and quality control. The implementation\nis freely available in R/Bioconductor at\nhttp://www.bioconductor.org/packages/devel/bioc/html/RPA.html\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 16:41:08 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 11:23:39 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Lahti", "Leo", ""], ["Torrente", "Aurora", ""], ["Elo", "Laura L.", ""], ["Brazma", "Alvis", ""], ["Rung", "Johan", ""]]}, {"id": "1212.6018", "submitter": "Gordon J Ross", "authors": "Gordon J. Ross, Niall M. Adams, Dimitris K. Tasoulis, David J. Hand", "title": "Exponentially Weighted Moving Average Charts for Detecting Concept Drift", "comments": null, "journal-ref": "Pattern Recognition Letters, 33(2) 191-198, 2012", "doi": "10.1016/j.patrec.2011.08.019", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying streaming data requires the development of methods which are\ncomputationally efficient and able to cope with changes in the underlying\ndistribution of the stream, a phenomenon known in the literature as concept\ndrift. We propose a new method for detecting concept drift which uses an\nExponentially Weighted Moving Average (EWMA) chart to monitor the\nmisclassification rate of an streaming classifier. Our approach is modular and\ncan hence be run in parallel with any underlying classifier to provide an\nadditional layer of concept drift detection. Moreover our method is\ncomputationally efficient with overhead O(1) and works in a fully online manner\nwith no need to store data points in memory. Unlike many existing approaches to\nconcept drift detection, our method allows the rate of false positive\ndetections to be controlled and kept constant over time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2012 11:01:48 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Ross", "Gordon J.", ""], ["Adams", "Niall M.", ""], ["Tasoulis", "Dimitris K.", ""], ["Hand", "David J.", ""]]}, {"id": "1212.6031", "submitter": "Alexander Bernstein V.", "authors": "Alexander V. Bernstein and Alexander P. Kuleshov", "title": "Tangent Bundle Manifold Learning via Grassmann&Stiefel Eigenmaps", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the ultimate goals of Manifold Learning (ML) is to reconstruct an\nunknown nonlinear low-dimensional manifold embedded in a high-dimensional\nobservation space by a given set of data points from the manifold. We derive a\nlocal lower bound for the maximum reconstruction error in a small neighborhood\nof an arbitrary point. The lower bound is defined in terms of the distance\nbetween tangent spaces to the original manifold and the estimated manifold at\nthe considered point and reconstructed point, respectively. We propose an\namplification of the ML, called Tangent Bundle ML, in which the proximity not\nonly between the original manifold and its estimator but also between their\ntangent spaces is required. We present a new algorithm that solves this problem\nand gives a new solution for the ML also.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2012 12:12:57 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Bernstein", "Alexander V.", ""], ["Kuleshov", "Alexander P.", ""]]}, {"id": "1212.6110", "submitter": "Makiko Konoshima", "authors": "Makiko Konoshima and Yui Noma", "title": "Hyperplane Arrangements and Locality-Sensitive Hashing with Lift", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locality-sensitive hashing converts high-dimensional feature vectors, such as\nimage and speech, into bit arrays and allows high-speed similarity calculation\nwith the Hamming distance. There is a hashing scheme that maps feature vectors\nto bit arrays depending on the signs of the inner products between feature\nvectors and the normal vectors of hyperplanes placed in the feature space. This\nhashing can be seen as a discretization of the feature space by hyperplanes. If\nlabels for data are given, one can determine the hyperplanes by using learning\nalgorithms. However, many proposed learning methods do not consider the\nhyperplanes' offsets. Not doing so decreases the number of partitioned regions,\nand the correlation between Hamming distances and Euclidean distances becomes\nsmall. In this paper, we propose a lift map that converts learning algorithms\nwithout the offsets to the ones that take into account the offsets. With this\nmethod, the learning methods without the offsets give the discretizations of\nspaces as if it takes into account the offsets. For the proposed method, we\ninput several high-dimensional feature data sets and studied the relationship\nbetween the statistical characteristics of data, the number of hyperplanes, and\nthe effect of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 02:14:41 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Konoshima", "Makiko", ""], ["Noma", "Yui", ""]]}, {"id": "1212.6167", "submitter": "Waad Bouaguel", "authors": "Farid Beninel, Waad Bouaguel, Ghazi Belmufti", "title": "Transfer Learning Using Logistic Regression in Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The credit scoring risk management is a fast growing field due to consumer's\ncredit requests. Credit requests, of new and existing customers, are often\nevaluated by classical discrimination rules based on customers information.\nHowever, these kinds of strategies have serious limits and don't take into\naccount the characteristics difference between current customers and the future\nones. The aim of this paper is to measure credit worthiness for non customers\nborrowers and to model potential risk given a heterogeneous population formed\nby borrowers customers of the bank and others who are not. We hold on previous\nworks done in generalized gaussian discrimination and transpose them into the\nlogistic model to bring out efficient discrimination rules for non customers'\nsubpopulation.\n  Therefore we obtain several simple models of connection between parameters of\nboth logistic models associated respectively to the two subpopulations. The\nGerman credit data set is selected to experiment and to compare these models.\nExperimental results show that the use of links between the two subpopulations\nimprove the classification accuracy for the new loan applicants.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 12:03:26 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Beninel", "Farid", ""], ["Bouaguel", "Waad", ""], ["Belmufti", "Ghazi", ""]]}, {"id": "1212.6246", "submitter": "Radford M. Neal", "authors": "Chunyi Wang and Radford M. Neal", "title": "Gaussian Process Regression with Heteroscedastic or Non-Gaussian\n  Residuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GP) regression models typically assume that residuals are\nGaussian and have the same variance for all observations. However, applications\nwith input-dependent noise (heteroscedastic residuals) frequently arise in\npractice, as do applications in which the residuals do not have a Gaussian\ndistribution. In this paper, we propose a GP Regression model with a latent\nvariable that serves as an additional unobserved covariate for the regression.\nThis model (which we call GPLC) allows for heteroscedasticity since it allows\nthe function to have a changing partial derivative with respect to this\nunobserved covariate. With a suitable covariance function, our GPLC model can\nhandle (a) Gaussian residuals with input-dependent variance, or (b)\nnon-Gaussian residuals with input-dependent variance, or (c) Gaussian residuals\nwith constant variance. We compare our model, using synthetic datasets, with a\nmodel proposed by Goldberg, Williams and Bishop (1998), which we refer to as\nGPLV, which only deals with case (a), as well as a standard GP model which can\nhandle only case (c). Markov Chain Monte Carlo methods are developed for both\nmodelsl. Experiments show that when the data is heteroscedastic, both GPLC and\nGPLV give better results (smaller mean squared error and negative\nlog-probability density) than standard GP regression. In addition, when the\nresidual are Gaussian, our GPLC model is generally nearly as good as GPLV,\nwhile when the residuals are non-Gaussian, our GPLC model is better than GPLV.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 20:45:48 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Wang", "Chunyi", ""], ["Neal", "Radford M.", ""]]}, {"id": "1212.6276", "submitter": "Sebasti\\'an Basterrech", "authors": "Sebasti\\'an Basterrech and Gerardo Rubino", "title": "Echo State Queueing Network: a new reservoir computing learning tool", "comments": "Proceedings of the 10th IEEE Consumer Communications and Networking\n  Conference (CCNC), Las Vegas, USA, 2013", "journal-ref": null, "doi": "10.1109/CCNC.2013.6488435", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a new computational paradigm was introduced in the field\nof Machine Learning, under the name of Reservoir Computing (RC). RC models are\nneural networks which a recurrent part (the reservoir) that does not\nparticipate in the learning process, and the rest of the system where no\nrecurrence (no neural circuit) occurs. This approach has grown rapidly due to\nits success in solving learning tasks and other computational applications.\nSome success was also observed with another recently proposed neural network\ndesigned using Queueing Theory, the Random Neural Network (RandNN). Both\napproaches have good properties and identified drawbacks. In this paper, we\npropose a new RC model called Echo State Queueing Network (ESQN), where we use\nideas coming from RandNNs for the design of the reservoir. ESQNs consist in\nESNs where the reservoir has a new dynamics inspired by recurrent RandNNs. The\npaper positions ESQNs in the global Machine Learning area, and provides\nexamples of their use and performances. We show on largely used benchmarks that\nESQNs are very accurate tools, and we illustrate how they compare with standard\nESNs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 22:31:13 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Basterrech", "Sebasti\u00e1n", ""], ["Rubino", "Gerardo", ""]]}, {"id": "1212.6316", "submitter": "Nathalie Villa-Vialaneix", "authors": "Madalina Olteanu (SAMM), Nathalie Villa-Vialaneix (SAMM), Marie\n  Cottrell (SAMM)", "title": "On-line relational SOM for dissimilarity data", "comments": "WSOM 2012, Santiago : Chile (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some applications and in order to address real world situations better,\ndata may be more complex than simple vectors. In some examples, they can be\nknown through their pairwise dissimilarities only. Several variants of the Self\nOrganizing Map algorithm were introduced to generalize the original algorithm\nto this framework. Whereas median SOM is based on a rough representation of the\nprototypes, relational SOM allows representing these prototypes by a virtual\ncombination of all elements in the data set. However, this latter approach\nsuffers from two main drawbacks. First, its complexity can be large. Second,\nonly a batch version of this algorithm has been studied so far and it often\nprovides results having a bad topographic organization. In this article, an\non-line version of relational SOM is described and justified. The algorithm is\ntested on several datasets, including categorical data and graphs, and compared\nwith the batch version and with other SOM algorithms for non vector data.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2012 07:07:06 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Olteanu", "Madalina", "", "SAMM"], ["Villa-Vialaneix", "Nathalie", "", "SAMM"], ["Cottrell", "Marie", "", "SAMM"]]}, {"id": "1212.6659", "submitter": "Raphael Pelossof", "authors": "Raphael Pelossof and Zhiliang Ying", "title": "Focus of Attention for Linear Predictors", "comments": "9 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1105.0382", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to stop the evaluation of a prediction process when the\nresult of the full evaluation is obvious. This trait is highly desirable in\nprediction tasks where a predictor evaluates all its features for every example\nin large datasets. We observe that some examples are easier to classify than\nothers, a phenomenon which is characterized by the event when most of the\nfeatures agree on the class of an example. By stopping the feature evaluation\nwhen encountering an easy- to-classify example, the predictor can achieve\nsubstantial gains in computation. Our method provides a natural attention\nmechanism for linear predictors where the predictor concentrates most of its\ncomputation on hard-to-classify examples and quickly discards easy-to-classify\nones. By modifying a linear prediction algorithm such as an SVM or AdaBoost to\ninclude our attentive method we prove that the average number of features\ncomputed is O(sqrt(n log 1/sqrt(delta))) where n is the original number of\nfeatures, and delta is the error rate incurred due to early stopping. We\ndemonstrate the effectiveness of Attentive Prediction on MNIST, Real-sim,\nGisette, and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2012 20:23:48 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Pelossof", "Raphael", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1212.6846", "submitter": "Sagar Kale", "authors": "Sagar Kale", "title": "Maximizing a Nonnegative, Monotone, Submodular Function Constrained to\n  Matchings", "comments": "Withdrawn because the main result is implied by a more general result\n  about p-independence-system (which generalize matchings) in the paper by\n  Calinescu, Chekuri, Pal, and Vondrak, Maximizing a Monotone Submodular\n  Function Subject to a Matroid Constraint, SIAM J. Comput., 2011, Vol 40, No\n  6, pp. 1740-1766", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions have many applications. Matchings have many\napplications. The bitext word alignment problem can be modeled as the problem\nof maximizing a nonnegative, monotone, submodular function constrained to\nmatchings in a complete bipartite graph where each vertex corresponds to a word\nin the two input sentences and each edge represents a potential word-to-word\ntranslation. We propose a more general problem of maximizing a nonnegative,\nmonotone, submodular function defined on the edge set of a complete graph\nconstrained to matchings; we call this problem the CSM-Matching problem.\nCSM-Matching also generalizes the maximum-weight matching problem, which has a\npolynomial-time algorithm; however, we show that it is NP-hard to approximate\nCSM-Matching within a factor of e/(e-1) by reducing the max k-cover problem to\nit. Our main result is a simple, greedy, 3-approximation algorithm for\nCSM-Matching. Then we reduce CSM-Matching to maximizing a nonnegative,\nmonotone, submodular function over two matroids, i.e., CSM-2-Matroids.\nCSM-2-Matroids has a (2+epsilon)-approximation algorithm - called LSV2. We show\nthat we can find a (4+epsilon)-approximate solution to CSM-Matching using LSV2.\nWe extend this approach to similar problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 09:32:51 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2013 21:20:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kale", "Sagar", ""]]}, {"id": "1212.6922", "submitter": "Yana Mazwin Mohmad Hassim", "authors": "Yana Mazwin Mohmad Hassim and Rozaida Ghazali", "title": "Training a Functional Link Neural Network Using an Artificial Bee Colony\n  for Solving a Classification Problems", "comments": "6 pages, 3 figures, 4 tables", "journal-ref": "Journal of Computing, Volume 4, Issue 9 (2012), 110-115", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks have emerged as an important tool for\nclassification and have been widely used to classify a non-linear separable\npattern. The most popular artificial neural networks model is a Multilayer\nPerceptron (MLP) as it is able to perform classification task with significant\nsuccess. However due to the complexity of MLP structure and also problems such\nas local minima trapping, over fitting and weight interference have made neural\nnetwork training difficult. Thus, the easy way to avoid these problems is to\nremove the hidden layers. This paper presents the ability of Functional Link\nNeural Network (FLNN) to overcome the complexity structure of MLP by using\nsingle layer architecture and propose an Artificial Bee Colony (ABC)\noptimization for training the FLNN. The proposed technique is expected to\nprovide better learning scheme for a classifier in order to get more accurate\nclassification result\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 16:40:50 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Hassim", "Yana Mazwin Mohmad", ""], ["Ghazali", "Rozaida", ""]]}, {"id": "1212.6958", "submitter": "Geoffrey Gordon", "authors": "Geoffrey J. Gordon", "title": "Fast Solutions to Projective Monotone Linear Complementarity Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new interior-point potential-reduction algorithm for solving\nmonotone linear complementarity problems (LCPs) that have a particular special\nstructure: their matrix $M\\in{\\mathbb R}^{n\\times n}$ can be decomposed as\n$M=\\Phi U + \\Pi_0$, where the rank of $\\Phi$ is $k<n$, and $\\Pi_0$ denotes\nEuclidean projection onto the nullspace of $\\Phi^\\top$. We call such LCPs\nprojective. Our algorithm solves a monotone projective LCP to relative accuracy\n$\\epsilon$ in $O(\\sqrt n \\ln(1/\\epsilon))$ iterations, with each iteration\nrequiring $O(nk^2)$ flops. This complexity compares favorably with\ninterior-point algorithms for general monotone LCPs: these algorithms also\nrequire $O(\\sqrt n \\ln(1/\\epsilon))$ iterations, but each iteration needs to\nsolve an $n\\times n$ system of linear equations, a much higher cost than our\nalgorithm when $k\\ll n$. Our algorithm works even though the solution to a\nprojective LCP is not restricted to lie in any low-rank subspace.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 20:13:23 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Gordon", "Geoffrey J.", ""]]}]