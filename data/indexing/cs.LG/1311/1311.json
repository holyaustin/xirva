[{"id": "1311.0202", "submitter": "Diego Amancio Raphael", "authors": "D. R. Amancio, C. H. Comin, D. Casanova, G. Travieso, O. M. Bruno, F.\n  A. Rodrigues and L. da F. Costa", "title": "A systematic comparison of supervised classifiers", "comments": null, "journal-ref": "PLoS ONE 9 (4): e94137, 2014", "doi": "10.1371/journal.pone.0094137", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern recognition techniques have been employed in a myriad of industrial,\nmedical, commercial and academic applications. To tackle such a diversity of\ndata, many techniques have been devised. However, despite the long tradition of\npattern recognition research, there is no technique that yields the best\nclassification in all scenarios. Therefore, the consideration of as many as\npossible techniques presents itself as an fundamental practice in applications\naiming at high accuracy. Typical works comparing methods either emphasize the\nperformance of a given algorithm in validation tests or systematically compare\nvarious algorithms, assuming that the practical use of these methods is done by\nexperts. In many occasions, however, researchers have to deal with their\npractical classification tasks without an in-depth knowledge about the\nunderlying mechanisms behind parameters. Actually, the adequate choice of\nclassifiers and parameters alike in such practical circumstances constitutes a\nlong-standing problem and is the subject of the current paper. We carried out a\nstudy on the performance of nine well-known classifiers implemented by the Weka\nframework and compared the dependence of the accuracy with their configuration\nparameter configurations. The analysis of performance with default parameters\nrevealed that the k-nearest neighbors method exceeds by a large margin the\nother methods when high dimensional datasets are considered. When other\nconfiguration of parameters were allowed, we found that it is possible to\nimprove the quality of SVM in more than 20% even if parameters are set\nrandomly. Taken together, the investigation conducted in this paper suggests\nthat, apart from the SVM implementation, Weka's default configuration of\nparameters provides an performance close the one achieved with the optimal\nconfiguration.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 03:44:18 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Amancio", "D. R.", ""], ["Comin", "C. H.", ""], ["Casanova", "D.", ""], ["Travieso", "G.", ""], ["Bruno", "O. M.", ""], ["Rodrigues", "F. A.", ""], ["Costa", "L. da F.", ""]]}, {"id": "1311.0222", "submitter": "Julien Audiffren", "authors": "Julien Audiffren (LIF), Hachem Kadri (LIF)", "title": "Online Learning with Multiple Operator-valued Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a vector-valued function f in an online\nlearning setting. The function f is assumed to lie in a reproducing Hilbert\nspace of operator-valued kernels. We describe two online algorithms for\nlearning f while taking into account the output structure. A first contribution\nis an algorithm, ONORMA, that extends the standard kernel-based online learning\nalgorithm NORMA from scalar-valued to operator-valued setting. We report a\ncumulative error bound that holds both for classification and regression. We\nthen define a second algorithm, MONORMA, which addresses the limitation of\npre-defining the output structure in ONORMA by learning sequentially a linear\ncombination of operator-valued kernels. Our experiments show that the proposed\nalgorithms achieve good performance results with low computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 16:51:02 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2013 17:53:10 GMT"}], "update_date": "2013-11-06", "authors_parsed": [["Audiffren", "Julien", "", "LIF"], ["Kadri", "Hachem", "", "LIF"]]}, {"id": "1311.0274", "submitter": "Adel Javanmard", "authors": "Adel Javanmard and Andrea Montanari", "title": "Nearly Optimal Sample Size in Hypothesis Testing for High-Dimensional\n  Regression", "comments": "21 pages, short version appears in Annual Allerton Conference on\n  Communication, Control and Computing, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fitting the parameters of a high-dimensional\nlinear regression model. In the regime where the number of parameters $p$ is\ncomparable to or exceeds the sample size $n$, a successful approach uses an\n$\\ell_1$-penalized least squares estimator, known as Lasso. Unfortunately,\nunlike for linear estimators (e.g., ordinary least squares), no\nwell-established method exists to compute confidence intervals or p-values on\nthe basis of the Lasso estimator. Very recently, a line of work\n\\cite{javanmard2013hypothesis, confidenceJM, GBR-hypothesis} has addressed this\nproblem by constructing a debiased version of the Lasso estimator. In this\npaper, we study this approach for random design model, under the assumption\nthat a good estimator exists for the precision matrix of the design. Our\nanalysis improves over the state of the art in that it establishes nearly\noptimal \\emph{average} testing power if the sample size $n$ asymptotically\ndominates $s_0 (\\log p)^2$, with $s_0$ being the sparsity level (number of\nnon-zero coefficients). Earlier work obtains provable guarantees only for much\nlarger sample size, namely it requires $n$ to asymptotically dominate $(s_0\n\\log p)^2$.\n  In particular, for random designs with a sparse precision matrix we show that\nan estimator thereof having the required properties can be computed\nefficiently. Finally, we evaluate this approach on synthetic data and compare\nit with earlier proposals.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 19:41:42 GMT"}], "update_date": "2013-11-04", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1311.0466", "submitter": "Aditya Gopalan", "authors": "Aditya Gopalan, Shie Mannor and Yishay Mansour", "title": "Thompson Sampling for Complex Bandit Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic multi-armed bandit problems with complex actions over\na set of basic arms, where the decision maker plays a complex action rather\nthan a basic arm in each round. The reward of the complex action is some\nfunction of the basic arms' rewards, and the feedback observed may not\nnecessarily be the reward per-arm. For instance, when the complex actions are\nsubsets of the arms, we may only observe the maximum reward over the chosen\nsubset. Thus, feedback across complex actions may be coupled due to the nature\nof the reward function. We prove a frequentist regret bound for Thompson\nsampling in a very general setting involving parameter, action and observation\nspaces and a likelihood function over them. The bound holds for\ndiscretely-supported priors over the parameter space and without additional\nstructural properties such as closed-form posteriors, conjugate prior structure\nor independence across arms. The regret bound scales logarithmically with time\nbut, more importantly, with an improved constant that non-trivially captures\nthe coupling across complex actions due to the structure of the rewards. As\napplications, we derive improved regret bounds for classes of complex bandit\nproblems involving selecting subsets of arms, including the first nontrivial\nregret bounds for nonlinear MAX reward feedback from subsets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2013 13:51:55 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Gopalan", "Aditya", ""], ["Mannor", "Shie", ""], ["Mansour", "Yishay", ""]]}, {"id": "1311.0468", "submitter": "Aditya Gopalan", "authors": "Aditya Gopalan", "title": "Thompson Sampling for Online Learning with Linear Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we present a version of the Thompson sampling algorithm for the\nproblem of online linear generalization with full information (i.e., the\nexperts setting), studied by Kalai and Vempala, 2005. The algorithm uses a\nGaussian prior and time-varying Gaussian likelihoods, and we show that it\nessentially reduces to Kalai and Vempala's Follow-the-Perturbed-Leader\nstrategy, with exponentially distributed noise replaced by Gaussian noise. This\nimplies sqrt(T) regret bounds for Thompson sampling (with time-varying\nlikelihood) for online learning with full information.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2013 14:18:56 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Gopalan", "Aditya", ""]]}, {"id": "1311.0636", "submitter": "Dhruv Mahajan", "authors": "Dhruv Mahajan, S. Sathiya Keerthi, S. Sundararajan, Leon Bottou", "title": "A Parallel SGD method with Strong Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel parallel stochastic gradient descent (SGD) method\nthat is obtained by applying parallel sets of SGD iterations (each set\noperating on one node using the data residing in it) for finding the direction\nin each iteration of a batch descent method. The method has strong convergence\nproperties. Experiments on datasets with high dimensional feature spaces show\nthe value of this method.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 10:31:11 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Mahajan", "Dhruv", ""], ["Keerthi", "S. Sathiya", ""], ["Sundararajan", "S.", ""], ["Bottou", "Leon", ""]]}, {"id": "1311.0701", "submitter": "Justin Bayer", "authors": "Justin Bayer, Christian Osendorfer, Daniela Korhammer, Nutan Chen,\n  Sebastian Urban, Patrick van der Smagt", "title": "On Fast Dropout and its Applicability to Recurrent Networks", "comments": "The experiments for the Penn Treebank corpus were erroneous and have\n  been stripped from this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are rich models for the processing of\nsequential data. Recent work on advancing the state of the art has been focused\non the optimization or modelling of RNNs, mostly motivated by adressing the\nproblems of the vanishing and exploding gradients. The control of overfitting\nhas seen considerably less attention. This paper contributes to that by\nanalyzing fast dropout, a recent regularization method for generalized linear\nmodels and neural networks from a back-propagation inspired perspective. We\nshow that fast dropout implements a quadratic form of an adaptive,\nper-parameter regularizer, which rewards large weights in the light of\nunderfitting, penalizes them for overconfident predictions and vanishes at\nminima of an unregularized training loss. The derivatives of that regularizer\nare exclusively based on the training error signal. One consequence of this is\nthe absense of a global weight attractor, which is particularly appealing for\nRNNs, since the dynamics are not biased towards a certain regime. We positively\ntest the hypothesis that this improves the performance of RNNs on four musical\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 13:56:23 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2013 09:53:52 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2013 15:28:07 GMT"}, {"version": "v4", "created": "Wed, 1 Jan 2014 20:49:56 GMT"}, {"version": "v5", "created": "Sun, 16 Feb 2014 10:21:01 GMT"}, {"version": "v6", "created": "Mon, 3 Mar 2014 14:48:37 GMT"}, {"version": "v7", "created": "Wed, 5 Mar 2014 19:32:29 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Bayer", "Justin", ""], ["Osendorfer", "Christian", ""], ["Korhammer", "Daniela", ""], ["Chen", "Nutan", ""], ["Urban", "Sebastian", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1311.0707", "submitter": "Niko Br\\\"ummer", "authors": "Niko Br\\\"ummer and Daniel Garcia-Romero", "title": "Generative Modelling for Unsupervised Score Calibration", "comments": "Accepted for ICASSP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score calibration enables automatic speaker recognizers to make\ncost-effective accept / reject decisions. Traditional calibration requires\nsupervised data, which is an expensive resource. We propose a 2-component GMM\nfor unsupervised calibration and demonstrate good performance relative to a\nsupervised baseline on NIST SRE'10 and SRE'12. A Bayesian analysis demonstrates\nthat the uncertainty associated with the unsupervised calibration parameter\nestimates is surprisingly small.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 14:13:27 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2013 07:15:25 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2014 15:15:43 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Br\u00fcmmer", "Niko", ""], ["Garcia-Romero", "Daniel", ""]]}, {"id": "1311.0800", "submitter": "Tomer Koren", "authors": "Eshcar Hillel, Zohar Karnin, Tomer Koren, Ronny Lempel, Oren Somekh", "title": "Distributed Exploration in Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exploration in Multi-Armed Bandits in a setting where $k$ players\ncollaborate in order to identify an $\\epsilon$-optimal arm. Our motivation\ncomes from recent employment of bandit algorithms in computationally intensive,\nlarge-scale applications. Our results demonstrate a non-trivial tradeoff\nbetween the number of arm pulls required by each of the players, and the amount\nof communication between them. In particular, our main result shows that by\nallowing the $k$ players to communicate only once, they are able to learn\n$\\sqrt{k}$ times faster than a single player. That is, distributing learning to\n$k$ players gives rise to a factor $\\sqrt{k}$ parallel speed-up. We complement\nthis result with a lower bound showing this is in general the best possible. On\nthe other extreme, we present an algorithm that achieves the ideal factor $k$\nspeed-up in learning performance, with communication only logarithmic in\n$1/\\epsilon$.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 18:19:25 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Hillel", "Eshcar", ""], ["Karnin", "Zohar", ""], ["Koren", "Tomer", ""], ["Lempel", "Ronny", ""], ["Somekh", "Oren", ""]]}, {"id": "1311.0914", "submitter": "Cho-Jui Hsieh Cho-Jui Hsieh", "authors": "Cho-Jui Hsieh and Si Si and Inderjit S. Dhillon", "title": "A Divide-and-Conquer Solver for Kernel Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel support vector machine (SVM) is one of the most widely used\nclassification methods; however, the amount of computation required becomes the\nbottleneck when facing millions of samples. In this paper, we propose and\nanalyze a novel divide-and-conquer solver for kernel SVMs (DC-SVM). In the\ndivision step, we partition the kernel SVM problem into smaller subproblems by\nclustering the data, so that each subproblem can be solved independently and\nefficiently. We show theoretically that the support vectors identified by the\nsubproblem solution are likely to be support vectors of the entire kernel SVM\nproblem, provided that the problem is partitioned appropriately by kernel\nclustering. In the conquer step, the local solutions from the subproblems are\nused to initialize a global coordinate descent solver, which converges quickly\nas suggested by our analysis. By extending this idea, we develop a multilevel\nDivide-and-Conquer SVM algorithm with adaptive clustering and early prediction\nstrategy, which outperforms state-of-the-art methods in terms of training\nspeed, testing accuracy, and memory usage. As an example, on the covtype\ndataset with half-a-million samples, DC-SVM is 7 times faster than LIBSVM in\nobtaining the exact SVM solution (to within $10^{-6}$ relative error) which\nachieves 96.15% prediction accuracy. Moreover, with our proposed early\nprediction strategy, DC-SVM achieves about 96% accuracy in only 12 minutes,\nwhich is more than 100 times faster than LIBSVM.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 22:06:40 GMT"}], "update_date": "2013-11-06", "authors_parsed": [["Hsieh", "Cho-Jui", ""], ["Si", "Si", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1311.0989", "submitter": "Zhi-Hua Zhou", "authors": "Teng Zhang, Zhi-Hua Zhou", "title": "Large Margin Distribution Machine", "comments": "In: Proceedings of the 20th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'14), New York, NY, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) has been one of the most popular learning\nalgorithms, with the central idea of maximizing the minimum margin, i.e., the\nsmallest distance from the instances to the classification boundary. Recent\ntheoretical results, however, disclosed that maximizing the minimum margin does\nnot necessarily lead to better generalization performances, and instead, the\nmargin distribution has been proven to be more crucial. In this paper, we\npropose the Large margin Distribution Machine (LDM), which tries to achieve a\nbetter generalization performance by optimizing the margin distribution. We\ncharacterize the margin distribution by the first- and second-order statistics,\ni.e., the margin mean and variance. The LDM is a general learning approach\nwhich can be used in any place where SVM can be applied, and its superiority is\nverified both theoretically and empirically in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 08:46:26 GMT"}, {"version": "v2", "created": "Fri, 23 May 2014 12:02:06 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Zhang", "Teng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1311.1040", "submitter": "Xiao-Feng Gong", "authors": "Xiao-Feng Gong, Cheng-Yuan Wang, Ya-Na Hao, and Qiu-Hua Lin", "title": "Combined Independent Component Analysis and Canonical Polyadic\n  Decomposition via Joint Diagonalization", "comments": "IEEE China Summit & International Conference on Signal and\n  Information Processing. IEEE, 2014:804 - 808", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a trend to combine independent component analysis\nand canonical polyadic decomposition (ICA-CPD) for an enhanced robustness for\nthe computation of CPD, and ICA-CPD could be further converted into CPD of a\n5th-order partially symmetric tensor, by calculating the eigenmatrices of the\n4th-order cumulant slices of a trilinear mixture. In this study, we propose a\nnew 5th-order CPD algorithm constrained with partial symmetry based on joint\ndiagonalization. As the main steps involved in the proposed algorithm undergo\nno updating iterations for the loading matrices, it is much faster than the\nexisting algorithm based on alternating least squares and enhanced line search,\nwith competent performances. Simulation results are provided to demonstrate the\nperformance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 13:07:46 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 02:09:17 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Gong", "Xiao-Feng", ""], ["Wang", "Cheng-Yuan", ""], ["Hao", "Ya-Na", ""], ["Lin", "Qiu-Hua", ""]]}, {"id": "1311.1189", "submitter": "Michalis Titsias", "authors": "Michalis K. Titsias, Christopher Yau, Christopher C. Holmes", "title": "Statistical Inference in Hidden Markov Models using $k$-segment\n  Constraints", "comments": "37 pages", "journal-ref": null, "doi": "10.1080/01621459.2014.998762", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov models (HMMs) are one of the most widely used statistical\nmethods for analyzing sequence data. However, the reporting of output from HMMs\nhas largely been restricted to the presentation of the most-probable (MAP)\nhidden state sequence, found via the Viterbi algorithm, or the sequence of most\nprobable marginals using the forward-backward (F-B) algorithm. In this article,\nwe expand the amount of information we could obtain from the posterior\ndistribution of an HMM by introducing linear-time dynamic programming\nalgorithms that, we collectively call $k$-segment algorithms, that allow us to\ni) find MAP sequences, ii) compute posterior probabilities and iii) simulate\nsample paths conditional on a user specified number of segments, i.e.\ncontiguous runs in a hidden state, possibly of a particular type. We illustrate\nthe utility of these methods using simulated and real examples and highlight\nthe application of prospective and retrospective use of these methods for\nfitting HMMs or exploring existing model fits.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 20:41:17 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Titsias", "Michalis K.", ""], ["Yau", "Christopher", ""], ["Holmes", "Christopher C.", ""]]}, {"id": "1311.1354", "submitter": "Jan Melchior", "authors": "Jan Melchior, Asja Fischer, Laurenz Wiskott", "title": "How to Center Binary Deep Boltzmann Machines", "comments": "Author list in meta data corrected - 57 pages, 17 figures, 13 tables", "journal-ref": "Journal of Machine Learning Research, 17(99), 2016, 1:61", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyzes centered binary Restricted Boltzmann Machines (RBMs) and\nbinary Deep Boltzmann Machines (DBMs), where centering is done by subtracting\noffset values from visible and hidden variables. We show analytically that (i)\ncentering results in a different but equivalent parameterization for artificial\nneural networks in general, (ii) the expected performance of centered binary\nRBMs/DBMs is invariant under simultaneous flip of data and offsets, for any\noffset value in the range of zero to one, (iii) centering can be reformulated\nas a different update rule for normal binary RBMs/DBMs, and (iv) using the\nenhanced gradient is equivalent to setting the offset values to the average\nover model and data mean. Furthermore, numerical simulations suggest that (i)\noptimal generative performance is achieved by subtracting mean values from\nvisible as well as hidden variables, (ii) centered RBMs/DBMs reach\nsignificantly higher log-likelihood values than normal binary RBMs/DBMs, (iii)\ncentering variants whose offsets depend on the model mean, like the enhanced\ngradient, suffer from severe divergence problems, (iv) learning is stabilized\nif an exponentially moving average over the batch means is used for the offset\nvalues instead of the current batch mean, which also prevents the enhanced\ngradient from diverging, (v) centered RBMs/DBMs reach higher LL values than\nnormal RBMs/DBMs while having a smaller norm of the weight matrix, (vi)\ncentering leads to an update direction that is closer to the natural gradient\nand that the natural gradient is extremly efficient for training RBMs, (vii)\ncentering dispense the need for greedy layer-wise pre-training of DBMs, (viii)\nfurthermore we show that pre-training often even worsen the results\nindependently whether centering is used or not, and (ix) centering is also\nbeneficial for auto encoders.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 11:25:42 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 08:31:27 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2015 08:37:23 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Melchior", "Jan", ""], ["Fischer", "Asja", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1311.1406", "submitter": "Martin Takac", "authors": "Martin Tak\\'a\\v{c}, Selin Damla Ahipa\\c{s}ao\\u{g}lu, Ngai-Man Cheung,\n  Peter Richt\\'arik", "title": "TOP-SPIN: TOPic discovery via Sparse Principal component INterference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel topic discovery algorithm for unlabeled images based on\nthe bag-of-words (BoW) framework. We first extract a dictionary of visual words\nand subsequently for each image compute a visual word occurrence histogram. We\nview these histograms as rows of a large matrix from which we extract sparse\nprincipal components (PCs). Each PC identifies a sparse combination of visual\nwords which co-occur frequently in some images but seldom appear in others.\nEach sparse PC corresponds to a topic, and images whose interference with the\nPC is high belong to that topic, revealing the common parts possessed by the\nimages. We propose to solve the associated sparse PCA problems using an\nAlternating Maximization (AM) method, which we modify for purpose of\nefficiently extracting multiple PCs in a deflation scheme. Our approach attacks\nthe maximization problem in sparse PCA directly and is scalable to\nhigh-dimensional data. Experiments on automatic topic discovery and category\nprediction demonstrate encouraging performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 19:03:31 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Tak\u00e1\u010d", "Martin", ""], ["Ahipa\u015fao\u011flu", "Selin Damla", ""], ["Cheung", "Ngai-Man", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1311.1422", "submitter": "Feng Zhao", "authors": "Feng Zhao", "title": "Structural Learning for Template-free Protein Folding", "comments": "138 pages, 7 chapters, 18 figures and 28 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thesis is aimed to solve the template-free protein folding problem by\ntackling two important components: efficient sampling in vast conformation\nspace, and design of knowledge-based potentials with high accuracy. We have\nproposed the first-order and second-order CRF-Sampler to sample structures from\nthe continuous local dihedral angles space by modeling the lower and higher\norder conditional dependency between neighboring dihedral angles given the\nprimary sequence information. A framework combining the Conditional Random\nFields and the energy function is introduced to guide the local conformation\nsampling using long range constraints with the energy function.\n  The relationship between the sequence profile and the local dihedral angle\ndistribution is nonlinear. Hence we proposed the CNF-Folder to model this\ncomplex relationship by applying a novel machine learning model Conditional\nNeural Fields which utilizes the structural graphical model with the neural\nnetwork. CRF-Samplers and CNF-Folder perform very well in CASP8 and CASP9.\n  Further, a novel pairwise distance statistical potential (EPAD) is designed\nto capture the dependency of the energy profile on the positions of the\ninteracting amino acids as well as the types of those amino acids, opposing the\ncommon assumption that this energy profile depends only on the types of amino\nacids. EPAD has also been successfully applied in the CASP 10 Free Modeling\nexperiment with CNF-Folder, especially outstanding on some uncommon structured\ntargets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 15:37:27 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 19:17:57 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Zhao", "Feng", ""]]}, {"id": "1311.1539", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette", "title": "Category-Theoretic Quantitative Compositional Distributional Models of\n  Natural Language Semantics", "comments": "DPhil Thesis, University of Oxford, Submitted and accepted in 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG math.CT math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is about the problem of compositionality in distributional\nsemantics. Distributional semantics presupposes that the meanings of words are\na function of their occurrences in textual contexts. It models words as\ndistributions over these contexts and represents them as vectors in high\ndimensional spaces. The problem of compositionality for such models concerns\nitself with how to produce representations for larger units of text by\ncomposing the representations of smaller units of text.\n  This thesis focuses on a particular approach to this compositionality\nproblem, namely using the categorical framework developed by Coecke, Sadrzadeh,\nand Clark, which combines syntactic analysis formalisms with distributional\nsemantic representations of meaning to produce syntactically motivated\ncomposition operations. This thesis shows how this approach can be\ntheoretically extended and practically implemented to produce concrete\ncompositional distributional models of natural language semantics. It\nfurthermore demonstrates that such models can perform on par with, or better\nthan, other competing approaches in the field of natural language processing.\n  There are three principal contributions to computational linguistics in this\nthesis. The first is to extend the DisCoCat framework on the syntactic front\nand semantic front, incorporating a number of syntactic analysis formalisms and\nproviding learning procedures allowing for the generation of concrete\ncompositional distributional models. The second contribution is to evaluate the\nmodels developed from the procedures presented here, showing that they\noutperform other compositional distributional models present in the literature.\nThe third contribution is to show how using category theory to solve linguistic\nproblems forms a sound basis for research, illustrated by examples of work on\nthis topic, that also suggest directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 22:06:15 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Grefenstette", "Edward", ""]]}, {"id": "1311.1644", "submitter": "Matan Gavish", "authors": "Moshe Dubiner, Matan Gavish and Yoram Singer", "title": "The Maximum Entropy Relaxation Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relaxed maximum entropy problem is concerned with finding a probability\ndistribution on a finite set that minimizes the relative entropy to a given\nprior distribution, while satisfying relaxed max-norm constraints with respect\nto a third observed multinomial distribution. We study the entire relaxation\npath for this problem in detail. We show existence and a geometric description\nof the relaxation path. Specifically, we show that the maximum entropy\nrelaxation path admits a planar geometric description as an increasing,\npiecewise linear function in the inverse relaxation parameter. We derive fast\nalgorithms for tracking the path. In various realistic settings, our algorithms\nrequire $O(n\\log(n))$ operations for probability distributions on $n$ points,\nmaking it possible to handle large problems. Once the path has been recovered,\nwe show that given a validation set, the family of admissible models is reduced\nfrom an infinite family to a small, discrete set. We demonstrate the merits of\nour approach in experiments with synthetic data and discuss its potential for\nthe estimation of compact n-gram language models.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 11:33:14 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Dubiner", "Moshe", ""], ["Gavish", "Matan", ""], ["Singer", "Yoram", ""]]}, {"id": "1311.1704", "submitter": "Prem Gopalan", "authors": "Prem Gopalan, Jake M. Hofman, David M. Blei", "title": "Scalable Recommendation with Poisson Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian Poisson matrix factorization model for forming\nrecommendations from sparse user behavior data. These data are large user/item\nmatrices where each user has provided feedback on only a small subset of items,\neither explicitly (e.g., through star ratings) or implicitly (e.g., through\nviews or purchases). In contrast to traditional matrix factorization\napproaches, Poisson factorization implicitly models each user's limited\nattention to consume items. Moreover, because of the mathematical form of the\nPoisson likelihood, the model needs only to explicitly consider the observed\nentries in the matrix, leading to both scalable computation and good predictive\nperformance. We develop a variational inference algorithm for approximate\nposterior inference that scales up to massive data sets. This is an efficient\nalgorithm that iterates over the observed entries and adjusts an approximate\nposterior over the user/item representations. We apply our method to large\nreal-world user data containing users rating movies, users listening to songs,\nand users reading scientific papers. In all these settings, Bayesian Poisson\nfactorization outperforms state-of-the-art matrix factorization methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 14:58:40 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 17:23:05 GMT"}, {"version": "v3", "created": "Tue, 20 May 2014 19:19:30 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Gopalan", "Prem", ""], ["Hofman", "Jake M.", ""], ["Blei", "David M.", ""]]}, {"id": "1311.1731", "submitter": "Edoardo Airoldi", "authors": "Edoardo M Airoldi, Thiago B Costa, Stanley H Chan", "title": "Stochastic blockmodel approximation of a graphon: Theory and consistent\n  estimation", "comments": "20 pages, 4 figures, 2 algorithms. Neural Information Processing\n  Systems (NIPS), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SI physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parametric approaches for analyzing network data based on exchangeable\ngraph models (ExGM) have recently gained interest. The key object that defines\nan ExGM is often referred to as a graphon. This non-parametric perspective on\nnetwork modeling poses challenging questions on how to make inference on the\ngraphon underlying observed network data. In this paper, we propose a\ncomputationally efficient procedure to estimate a graphon from a set of\nobserved networks generated from it. This procedure is based on a stochastic\nblockmodel approximation (SBA) of the graphon. We show that, by approximating\nthe graphon with a stochastic block model, the graphon can be consistently\nestimated, that is, the estimation error vanishes as the size of the graph\napproaches infinity.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 16:20:02 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2013 04:09:51 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Airoldi", "Edoardo M", ""], ["Costa", "Thiago B", ""], ["Chan", "Stanley H", ""]]}, {"id": "1311.1761", "submitter": "Sergey Levine", "authors": "Sergey Levine", "title": "Exploring Deep and Recurrent Architectures for Optimal Control", "comments": "Appears in the Neural Information Processing Systems (NIPS 2013)\n  Workshop on Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophisticated multilayer neural networks have achieved state of the art\nresults on multiple supervised tasks. However, successful applications of such\nmultilayer networks to control have so far been limited largely to the\nperception portion of the control pipeline. In this paper, we explore the\napplication of deep and recurrent neural networks to a continuous,\nhigh-dimensional locomotion task, where the network is used to represent a\ncontrol policy that maps the state of the system (represented by joint angles)\ndirectly to the torques at each joint. By using a recent reinforcement learning\nalgorithm called guided policy search, we can successfully train neural network\ncontrollers with thousands of parameters, allowing us to compare a variety of\narchitectures. We discuss the differences between the locomotion control task\nand previous supervised perception tasks, present experimental results\ncomparing various architectures, and discuss future directions in the\napplication of techniques from deep learning to the problem of optimal control.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 17:39:31 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Levine", "Sergey", ""]]}, {"id": "1311.1780", "submitter": "KyungHyun Cho", "authors": "Caglar Gulcehre, Kyunghyun Cho, Razvan Pascanu and Yoshua Bengio", "title": "Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks", "comments": "ECML/PKDD 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and investigate a novel nonlinear unit, called $L_p$\nunit, for deep neural networks. The proposed $L_p$ unit receives signals from\nseveral projections of a subset of units in the layer below and computes a\nnormalized $L_p$ norm. We notice two interesting interpretations of the $L_p$\nunit. First, the proposed unit can be understood as a generalization of a\nnumber of conventional pooling operators such as average, root-mean-square and\nmax pooling widely used in, for instance, convolutional neural networks (CNN),\nHMAX models and neocognitrons. Furthermore, the $L_p$ unit is, to a certain\ndegree, similar to the recently proposed maxout unit (Goodfellow et al., 2013)\nwhich achieved the state-of-the-art object recognition results on a number of\nbenchmark datasets. Secondly, we provide a geometrical interpretation of the\nactivation function based on which we argue that the $L_p$ unit is more\nefficient at representing complex, nonlinear separating boundaries. Each $L_p$\nunit defines a superelliptic boundary, with its exact shape defined by the\norder $p$. We claim that this makes it possible to model arbitrarily shaped,\ncurved boundaries more efficiently by combining a few $L_p$ units of different\norders. This insight justifies the need for learning different orders for each\nunit in the model. We empirically evaluate the proposed $L_p$ units on a number\nof datasets and show that multilayer perceptrons (MLP) consisting of the $L_p$\nunits achieve the state-of-the-art results on a number of benchmark datasets.\nFurthermore, we evaluate the proposed $L_p$ unit on the recently proposed deep\nrecurrent neural networks (RNN).\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 18:30:37 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2013 03:32:43 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2013 18:32:42 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2014 22:55:24 GMT"}, {"version": "v5", "created": "Sat, 1 Feb 2014 18:17:38 GMT"}, {"version": "v6", "created": "Fri, 7 Feb 2014 18:55:42 GMT"}, {"version": "v7", "created": "Tue, 2 Sep 2014 00:53:40 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Gulcehre", "Caglar", ""], ["Cho", "Kyunghyun", ""], ["Pascanu", "Razvan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1311.1869", "submitter": "Alexander Rakhlin", "authors": "Alexander Rakhlin and Karthik Sridharan", "title": "Optimization, Learning, and Games with Predictable Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide several applications of Optimistic Mirror Descent, an online\nlearning algorithm based on the idea of predictable sequences. First, we\nrecover the Mirror Prox algorithm for offline optimization, prove an extension\nto Holder-smooth functions, and apply the results to saddle-point type\nproblems. Next, we prove that a version of Optimistic Mirror Descent (which has\na close relation to the Exponential Weights algorithm) can be used by two\nstrongly-uncoupled players in a finite zero-sum matrix game to converge to the\nminimax equilibrium at the rate of O((log T)/T). This addresses a question of\nDaskalakis et al 2011. Further, we consider a partial information version of\nthe problem. We then apply the results to convex programming and exhibit a\nsimple algorithm for the approximate Max Flow problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 02:47:40 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Rakhlin", "Alexander", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1311.1903", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky, Sanjoy Dasgupta", "title": "Moment-based Uniform Deviation Bounds for $k$-means and Friends", "comments": "To appear, NIPS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose $k$ centers are fit to $m$ points by heuristically minimizing the\n$k$-means cost; what is the corresponding fit over the source distribution?\nThis question is resolved here for distributions with $p\\geq 4$ bounded\nmoments; in particular, the difference between the sample cost and distribution\ncost decays with $m$ and $p$ as $m^{\\min\\{-1/4, -1/2+2/p\\}}$. The essential\ntechnical contribution is a mechanism to uniformly control deviations in the\nface of unbounded parameter sets, cost functions, and source distributions. To\nfurther demonstrate this mechanism, a soft clustering variant of $k$-means cost\nis also considered, namely the log likelihood of a Gaussian mixture, subject to\nthe constraint that all covariance matrices have bounded spectrum. Lastly, a\nrate with refined constants is provided for $k$-means instances possessing some\ncluster structure.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 08:44:11 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Telgarsky", "Matus", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "1311.1958", "submitter": "Ildar Batyrshin", "authors": "Ildar Batyrshin", "title": "Constructing Time Series Shape Association Measures: Minkowski Distance\n  and Data Standardization", "comments": "Presented at BRICS CCI 2013, Porto de Galinhas, Brasil, 8-11\n  September 2013. Reference on Proceedings of BRICS CCI 2013 is added", "journal-ref": "Published in Proceedings of BRICS CCI 2013, Porto de Galinhas,\n  Brasil, 8-11 September 2013", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is surprising that last two decades many works in time series data mining\nand clustering were concerned with measures of similarity of time series but\nnot with measures of association that can be used for measuring possible direct\nand inverse relationships between time series. Inverse relationships can exist\nbetween dynamics of prices and sell volumes, between growth patterns of\ncompetitive companies, between well production data in oilfields, between wind\nvelocity and air pollution concentration etc. The paper develops a theoretical\nbasis for analysis and construction of time series shape association measures.\nStarting from the axioms of time series shape association measures it studies\nthe methods of construction of measures satisfying these axioms. Several\ngeneral methods of construction of such measures suitable for measuring time\nseries shape similarity and shape association are proposed. Time series shape\nassociation measures based on Minkowski distance and data standardization\nmethods are considered. The cosine similarity and the Pearsons correlation\ncoefficient are obtained as particular cases of the proposed general methods\nthat can be used also for construction of new association measures in data\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 12:14:24 GMT"}, {"version": "v2", "created": "Sat, 3 May 2014 16:44:32 GMT"}, {"version": "v3", "created": "Tue, 20 May 2014 19:14:08 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Batyrshin", "Ildar", ""]]}, {"id": "1311.2097", "submitter": "Yun Shen", "authors": "Yun Shen, Michael J. Tobia, Tobias Sommer, Klaus Obermayer", "title": "Risk-sensitive Reinforcement Learning", "comments": "27 pages, 7 figures", "journal-ref": "Neural Computation, Vol. 26, Nr. 7, pp. 1298--1328, 2014", "doi": "10.1162/NECO_a_00600", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a family of risk-sensitive reinforcement learning methods for\nagents, who face sequential decision-making tasks in uncertain environments. By\napplying a utility function to the temporal difference (TD) error, nonlinear\ntransformations are effectively applied not only to the received rewards but\nalso to the true transition probabilities of the underlying Markov decision\nprocess. When appropriate utility functions are chosen, the agents' behaviors\nexpress key features of human behavior as predicted by prospect theory\n(Kahneman and Tversky, 1979), for example different risk-preferences for gains\nand losses as well as the shape of subjective probability curves. We derive a\nrisk-sensitive Q-learning algorithm, which is necessary for modeling human\nbehavior when transition probabilities are unknown, and prove its convergence.\nAs a proof of principle for the applicability of the new framework we apply it\nto quantify human behavior in a sequential investment task. We find, that the\nrisk-sensitive variant provides a significantly better fit to the behavioral\ndata and that it leads to an interpretation of the subject's responses which is\nindeed consistent with prospect theory. The analysis of simultaneously measured\nfMRI signals show a significant correlation of the risk-sensitive TD error with\nBOLD signal change in the ventral striatum. In addition we find a significant\ncorrelation of the risk-sensitive Q-values with neural activity in the\nstriatum, cingulate cortex and insula, which is not present if standard\nQ-values are used.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 22:25:26 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 10:09:49 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2014 21:18:34 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Shen", "Yun", ""], ["Tobia", "Michael J.", ""], ["Sommer", "Tobias", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1311.2110", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer, Stefanie Jegelka and Jeff Bilmes", "title": "Curvature and Optimal Algorithms for Learning and Minimizing Submodular\n  Functions", "comments": "21 pages. A shorter version appeared in Advances of NIPS-2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate three related and important problems connected to machine\nlearning: approximating a submodular function everywhere, learning a submodular\nfunction (in a PAC-like setting [53]), and constrained minimization of\nsubmodular functions. We show that the complexity of all three problems depends\non the 'curvature' of the submodular function, and provide lower and upper\nbounds that refine and improve previous results [3, 16, 18, 52]. Our proof\ntechniques are fairly generic. We either use a black-box transformation of the\nfunction (for approximation and learning), or a transformation of algorithms to\nuse an appropriate surrogate function (for minimization). Curiously, curvature\nhas been known to influence approximations for submodular maximization [7, 55],\nbut its effect on minimization, approximation and learning has hitherto been\nopen. We complete this picture, and also support our theoretical claims by\nempirical results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 23:42:34 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Iyer", "Rishabh", ""], ["Jegelka", "Stefanie", ""], ["Bilmes", "Jeff", ""]]}, {"id": "1311.2115", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein, Ben Poole, Surya Ganguli", "title": "Fast large-scale optimization by unifying stochastic gradient and\n  quasi-Newton methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for minimizing a sum of functions that combines the\ncomputational efficiency of stochastic gradient descent (SGD) with the second\norder curvature information leveraged by quasi-Newton methods. We unify these\ndisparate approaches by maintaining an independent Hessian approximation for\neach contributing function in the sum. We maintain computational tractability\nand limit memory requirements even for high dimensional optimization problems\nby storing and manipulating these quadratic approximations in a shared, time\nevolving, low dimensional subspace. Each update step requires only a single\ncontributing function or minibatch evaluation (as in SGD), and each step is\nscaled using an approximate inverse Hessian and little to no adjustment of\nhyperparameters is required (as is typical for quasi-Newton methods). This\nalgorithm contrasts with earlier stochastic second order techniques that treat\nthe Hessian of each contributing function as a noisy approximation to the full\nHessian, rather than as a target for direct estimation. We experimentally\ndemonstrate improved convergence on seven diverse optimization problems. The\nalgorithm is released as open source Python and MATLAB packages.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 00:54:37 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 02:10:32 GMT"}, {"version": "v3", "created": "Wed, 26 Mar 2014 06:49:16 GMT"}, {"version": "v4", "created": "Sun, 27 Apr 2014 02:38:28 GMT"}, {"version": "v5", "created": "Tue, 13 May 2014 23:51:41 GMT"}, {"version": "v6", "created": "Thu, 14 Aug 2014 02:27:38 GMT"}, {"version": "v7", "created": "Sun, 30 Nov 2014 01:35:55 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""], ["Poole", "Ben", ""], ["Ganguli", "Surya", ""]]}, {"id": "1311.2137", "submitter": "Sundararajan Sellamanickam", "authors": "Rahul Kidambi, Vinod Nair, Sundararajan Sellamanickam, S. Sathiya\n  Keerthi", "title": "A Structured Prediction Approach for Missing Value Imputation", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing value imputation is an important practical problem. There is a large\nbody of work on it, but there does not exist any work that formulates the\nproblem in a structured output setting. Also, most applications have\nconstraints on the imputed data, for example on the distribution associated\nwith each variable. None of the existing imputation methods use these\nconstraints. In this paper we propose a structured output approach for missing\nvalue imputation that also incorporates domain constraints. We focus on large\nmargin models, but it is easy to extend the ideas to probabilistic models. We\ndeal with the intractable inference step in learning via a piecewise training\ntechnique that is simple, efficient, and effective. Comparison with existing\nstate-of-the-art and baseline imputation methods shows that our method gives\nsignificantly improved performance on the Hamming loss measure.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 06:15:15 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Kidambi", "Rahul", ""], ["Nair", "Vinod", ""], ["Sellamanickam", "Sundararajan", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "1311.2139", "submitter": "Sundararajan Sellamanickam", "authors": "P. Balamurugan, Shirish Shevade, Sundararajan Sellamanickam", "title": "Large Margin Semi-supervised Structured Output Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In structured output learning, obtaining labelled data for real-world\napplications is usually costly, while unlabelled examples are available in\nabundance. Semi-supervised structured classification has been developed to\nhandle large amounts of unlabelled structured data. In this work, we consider\nsemi-supervised structural SVMs with domain constraints. The optimization\nproblem, which in general is not convex, contains the loss terms associated\nwith the labelled and unlabelled examples along with the domain constraints. We\npropose a simple optimization approach, which alternates between solving a\nsupervised learning problem and a constraint matching problem. Solving the\nconstraint matching problem is difficult for structured prediction, and we\npropose an efficient and effective hill-climbing method to solve it. The\nalternating optimization is carried out within a deterministic annealing\nframework, which helps in effective constraint matching, and avoiding local\nminima which are not very useful. The algorithm is simple to implement and\nachieves comparable generalization performance on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 06:47:22 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Balamurugan", "P.", ""], ["Shevade", "Shirish", ""], ["Sellamanickam", "Sundararajan", ""]]}, {"id": "1311.2150", "submitter": "Jun Fang", "authors": "Jun Fang, Yanning Shen, Hongbin Li (IEEE), and Pu Wang", "title": "Pattern-Coupled Sparse Bayesian Learning for Recovery of Block-Sparse\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering block-sparse signals whose structures\nare unknown \\emph{a priori}. Block-sparse signals with nonzero coefficients\noccurring in clusters arise naturally in many practical scenarios. However, the\nknowledge of the block structure is usually unavailable in practice. In this\npaper, we develop a new sparse Bayesian learning method for recovery of\nblock-sparse signals with unknown cluster patterns. Specifically, a\npattern-coupled hierarchical Gaussian prior model is introduced to characterize\nthe statistical dependencies among coefficients, in which a set of\nhyperparameters are employed to control the sparsity of signal coefficients.\nUnlike the conventional sparse Bayesian learning framework in which each\nindividual hyperparameter is associated independently with each coefficient, in\nthis paper, the prior for each coefficient not only involves its own\nhyperparameter, but also the hyperparameters of its immediate neighbors. In\ndoing this way, the sparsity patterns of neighboring coefficients are related\nto each other and the hierarchical model has the potential to encourage\nstructured-sparse solutions. The hyperparameters, along with the sparse signal,\nare learned by maximizing their posterior probability via an\nexpectation-maximization (EM) algorithm. Numerical results show that the\nproposed algorithm presents uniform superiority over other existing methods in\na series of experiments.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 08:28:27 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Fang", "Jun", "", "IEEE"], ["Shen", "Yanning", "", "IEEE"], ["Li", "Hongbin", "", "IEEE"], ["Wang", "Pu", ""]]}, {"id": "1311.2234", "submitter": "Junier Oliva", "authors": "Junier B. Oliva, Barnabas Poczos, Timothy Verstynen, Aarti Singh, Jeff\n  Schneider, Fang-Cheng Yeh, Wen-Yih Tseng", "title": "FuSSO: Functional Shrinkage and Selection Operator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the FuSSO, a functional analogue to the LASSO, that efficiently\nfinds a sparse set of functional input covariates to regress a real-valued\nresponse against. The FuSSO does so in a semi-parametric fashion, making no\nparametric assumptions about the nature of input functional covariates and\nassuming a linear form to the mapping of functional covariates to the response.\nWe provide a statistical backing for use of the FuSSO via proof of asymptotic\nsparsistency under various conditions. Furthermore, we observe good results on\nboth synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 00:44:01 GMT"}, {"version": "v2", "created": "Sun, 9 Mar 2014 02:30:26 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Oliva", "Junier B.", ""], ["Poczos", "Barnabas", ""], ["Verstynen", "Timothy", ""], ["Singh", "Aarti", ""], ["Schneider", "Jeff", ""], ["Yeh", "Fang-Cheng", ""], ["Tseng", "Wen-Yih", ""]]}, {"id": "1311.2236", "submitter": "Junier Oliva", "authors": "Junier B. Oliva, Willie Neiswanger, Barnabas Poczos, Jeff Schneider,\n  Eric Xing", "title": "Fast Distribution To Real Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distribution to real-value regression, where one aims\nto regress a mapping $f$ that takes in a distribution input covariate $P\\in\n\\mathcal{I}$ (for a non-parametric family of distributions $\\mathcal{I}$) and\noutputs a real-valued response $Y=f(P) + \\epsilon$. This setting was recently\nstudied, and a \"Kernel-Kernel\" estimator was introduced and shown to have a\npolynomial rate of convergence. However, evaluating a new prediction with the\nKernel-Kernel estimator scales as $\\Omega(N)$. This causes the difficult\nsituation where a large amount of data may be necessary for a low estimation\nrisk, but the computation cost of estimation becomes infeasible when the\ndata-set is too large. To this end, we propose the Double-Basis estimator,\nwhich looks to alleviate this big data problem in two ways: first, the\nDouble-Basis estimator is shown to have a computation complexity that is\nindependent of the number of of instances $N$ when evaluating new predictions\nafter training; secondly, the Double-Basis estimator is shown to have a fast\nrate of convergence for a general class of mappings $f\\in\\mathcal{F}$.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 01:17:19 GMT"}, {"version": "v2", "created": "Sun, 9 Mar 2014 03:41:35 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Oliva", "Junier B.", ""], ["Neiswanger", "Willie", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""], ["Xing", "Eric", ""]]}, {"id": "1311.2241", "submitter": "Ying Liu", "authors": "Ying Liu and Alan S. Willsky", "title": "Learning Gaussian Graphical Models with Observed or Latent FVSs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Graphical Models (GGMs) or Gauss Markov random fields are widely\nused in many applications, and the trade-off between the modeling capacity and\nthe efficiency of learning and inference has been an important research\nproblem. In this paper, we study the family of GGMs with small feedback vertex\nsets (FVSs), where an FVS is a set of nodes whose removal breaks all the\ncycles. Exact inference such as computing the marginal distributions and the\npartition function has complexity $O(k^{2}n)$ using message-passing algorithms,\nwhere k is the size of the FVS, and n is the total number of nodes. We propose\nefficient structure learning algorithms for two cases: 1) All nodes are\nobserved, which is useful in modeling social or flight networks where the FVS\nnodes often correspond to a small number of high-degree nodes, or hubs, while\nthe rest of the networks is modeled by a tree. Regardless of the maximum\ndegree, without knowing the full graph structure, we can exactly compute the\nmaximum likelihood estimate in $O(kn^2+n^2\\log n)$ if the FVS is known or in\npolynomial time if the FVS is unknown but has bounded size. 2) The FVS nodes\nare latent variables, where structure learning is equivalent to decomposing a\ninverse covariance matrix (exactly or approximately) into the sum of a\ntree-structured matrix and a low-rank matrix. By incorporating efficient\ninference into the learning steps, we can obtain a learning algorithm using\nalternating low-rank correction with complexity $O(kn^{2}+n^{2}\\log n)$ per\niteration. We also perform experiments using both synthetic data as well as\nreal data of flight delays to demonstrate the modeling capacity with FVSs of\nvarious sizes.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 02:39:48 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Liu", "Ying", ""], ["Willsky", "Alan S.", ""]]}, {"id": "1311.2252", "submitter": "David Yanay", "authors": "Ran El-Yaniv and David Yanay", "title": "Semantic Sort: A Supervised Approach to Personalized Semantic\n  Relatedness", "comments": "37 pages, 8 figures A short version of this paper was already\n  published at ECML/PKDD 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a novel supervised approach to learning statistical\nsemantic relatedness models from subjectively annotated training examples. The\nproposed semantic model consists of parameterized co-occurrence statistics\nassociated with textual units of a large background knowledge corpus. We\npresent an efficient algorithm for learning such semantic models from a\ntraining sample of relatedness preferences. Our method is corpus independent\nand can essentially rely on any sufficiently large (unstructured) collection of\ncoherent texts. Moreover, the approach facilitates the fitting of semantic\nmodels for specific users or groups of users. We present the results of\nextensive range of experiments from small to large scale, indicating that the\nproposed method is effective and competitive with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 09:15:16 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["El-Yaniv", "Ran", ""], ["Yanay", "David", ""]]}, {"id": "1311.2271", "submitter": "Amit Daniely", "authors": "Amit Daniely, Nati Linial, Shai Shalev Shwartz", "title": "More data speeds up training time in learning halfspaces over sparse\n  vectors", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability of data in recent years has led several authors to\nask whether it is possible to use data as a {\\em computational} resource. That\nis, if more data is available, beyond the sample complexity limit, is it\npossible to use the extra examples to speed up the computation time required to\nperform the learning task?\n  We give the first positive answer to this question for a {\\em natural\nsupervised learning problem} --- we consider agnostic PAC learning of\nhalfspaces over $3$-sparse vectors in $\\{-1,1,0\\}^n$. This class is\ninefficiently learnable using $O\\left(n/\\epsilon^2\\right)$ examples. Our main\ncontribution is a novel, non-cryptographic, methodology for establishing\ncomputational-statistical gaps, which allows us to show that, under a widely\nbelieved assumption that refuting random $\\mathrm{3CNF}$ formulas is hard, it\nis impossible to efficiently learn this class using only\n$O\\left(n/\\epsilon^2\\right)$ examples. We further show that under stronger\nhardness assumptions, even $O\\left(n^{1.499}/\\epsilon^2\\right)$ examples do not\nsuffice. On the other hand, we show a new algorithm that learns this class\nefficiently using $\\tilde{\\Omega}\\left(n^2/\\epsilon^2\\right)$ examples. This\nformally establishes the tradeoff between sample and computational complexity\nfor a natural supervised learning problem.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 13:28:19 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Daniely", "Amit", ""], ["Linial", "Nati", ""], ["Shwartz", "Shai Shalev", ""]]}, {"id": "1311.2272", "submitter": "Amit Daniely", "authors": "Amit Daniely, Nati Linial, Shai Shalev-Shwartz", "title": "From average case complexity to improper learning complexity", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic problem in the PAC model of computational learning theory is to\ndetermine which hypothesis classes are efficiently learnable. There is\npresently a dearth of results showing hardness of learning problems. Moreover,\nthe existing lower bounds fall short of the best known algorithms.\n  The biggest challenge in proving complexity results is to establish hardness\nof {\\em improper learning} (a.k.a. representation independent learning).The\ndifficulty in proving lower bounds for improper learning is that the standard\nreductions from $\\mathbf{NP}$-hard problems do not seem to apply in this\ncontext. There is essentially only one known approach to proving lower bounds\non improper learning. It was initiated in (Kearns and Valiant 89) and relies on\ncryptographic assumptions.\n  We introduce a new technique for proving hardness of improper learning, based\non reductions from problems that are hard on average. We put forward a (fairly\nstrong) generalization of Feige's assumption (Feige 02) about the complexity of\nrefuting random constraint satisfaction problems. Combining this assumption\nwith our new technique yields far reaching implications. In particular,\n  1. Learning $\\mathrm{DNF}$'s is hard.\n  2. Agnostically learning halfspaces with a constant approximation ratio is\nhard.\n  3. Learning an intersection of $\\omega(1)$ halfspaces is hard.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 13:35:50 GMT"}, {"version": "v2", "created": "Sun, 9 Mar 2014 19:11:40 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Daniely", "Amit", ""], ["Linial", "Nati", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1311.2276", "submitter": "Sundararajan Sellamanickam", "authors": "Vinod Nair, Rahul Kidambi, Sundararajan Sellamanickam, S. Sathiya\n  Keerthi, Johannes Gehrke, Vijay Narayanan", "title": "A Quantitative Evaluation Framework for Missing Value Imputation\n  Algorithms", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of quantitatively evaluating missing value imputation\nalgorithms. Given a dataset with missing values and a choice of several\nimputation algorithms to fill them in, there is currently no principled way to\nrank the algorithms using a quantitative metric. We develop a framework based\non treating imputation evaluation as a problem of comparing two distributions\nand show how it can be used to compute quantitative metrics. We present an\nefficient procedure for applying this framework to practical datasets,\ndemonstrate several metrics derived from the existing literature on comparing\ndistributions, and propose a new metric called Neighborhood-based Dissimilarity\nScore which is fast to compute and provides similar results. Results are shown\non several datasets, metrics, and imputations algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 14:17:47 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Nair", "Vinod", ""], ["Kidambi", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Keerthi", "S. Sathiya", ""], ["Gehrke", "Johannes", ""], ["Narayanan", "Vijay", ""]]}, {"id": "1311.2334", "submitter": "Ahmed Elgohary", "authors": "Ahmed Elgohary, Ahmed K. Farahat, Mohamed S. Kamel, Fakhri Karray", "title": "Embed and Conquer: Scalable Embeddings for Kernel k-Means on MapReduce", "comments": "Appears in Proceedings of the SIAM International Conference on Data\n  Mining (SDM), 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The kernel $k$-means is an effective method for data clustering which extends\nthe commonly-used $k$-means algorithm to work on a similarity matrix over\ncomplex data structures. The kernel $k$-means algorithm is however\ncomputationally very complex as it requires the complete data matrix to be\ncalculated and stored. Further, the kernelized nature of the kernel $k$-means\nalgorithm hinders the parallelization of its computations on modern\ninfrastructures for distributed computing. In this paper, we are defining a\nfamily of kernel-based low-dimensional embeddings that allows for scaling\nkernel $k$-means on MapReduce via an efficient and unified parallelization\nstrategy. Afterwards, we propose two methods for low-dimensional embedding that\nadhere to our definition of the embedding family. Exploiting the proposed\nparallelization strategy, we present two scalable MapReduce algorithms for\nkernel $k$-means. We demonstrate the effectiveness and efficiency of the\nproposed algorithms through an empirical evaluation on benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 02:37:16 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 15:41:40 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2013 03:56:35 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2014 20:08:17 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Elgohary", "Ahmed", ""], ["Farahat", "Ahmed K.", ""], ["Kamel", "Mohamed S.", ""], ["Karray", "Fakhri", ""]]}, {"id": "1311.2378", "submitter": "Balamurugan Palaniappan", "authors": "P. Balamurugan, Shirish Shevade, S. Sundararajan and S. S Keerthi", "title": "An Empirical Evaluation of Sequence-Tagging Trainers", "comments": "18 pages, 5 figures ams.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of assigning label sequences to a set of observed sequences is\ncommon in computational linguistics. Several models for sequence labeling have\nbeen proposed over the last few years. Here, we focus on discriminative models\nfor sequence labeling. Many batch and online (updating model parameters after\nvisiting each example) learning algorithms have been proposed in the\nliterature. On large datasets, online algorithms are preferred as batch\nlearning methods are slow. These online algorithms were designed to solve\neither a primal or a dual problem. However, there has been no systematic\ncomparison of these algorithms in terms of their speed, generalization\nperformance (accuracy/likelihood) and their ability to achieve steady state\ngeneralization performance fast. With this aim, we compare different algorithms\nand make recommendations, useful for a practitioner. We conclude that the\nselection of an algorithm for sequence labeling depends on the evaluation\ncriterion used and its implementation simplicity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 08:26:09 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Balamurugan", "P.", ""], ["Shevade", "Shirish", ""], ["Sundararajan", "S.", ""], ["Keerthi", "S. S", ""]]}, {"id": "1311.2483", "submitter": "Sebastien Da Veiga", "authors": "S\\'ebastien Da Veiga (IFPEN, - M\\'ethodes d'Analyse Stochastique des\n  Codes et Traitements Num\\'eriques)", "title": "Global Sensitivity Analysis with Dependence Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global sensitivity analysis with variance-based measures suffers from several\ntheoretical and practical limitations, since they focus only on the variance of\nthe output and handle multivariate variables in a limited way. In this paper,\nwe introduce a new class of sensitivity indices based on dependence measures\nwhich overcomes these insufficiencies. Our approach originates from the idea to\ncompare the output distribution with its conditional counterpart when one of\nthe input variables is fixed. We establish that this comparison yields\npreviously proposed indices when it is performed with Csiszar f-divergences, as\nwell as sensitivity indices which are well-known dependence measures between\nrandom variables. This leads us to investigate completely new sensitivity\nindices based on recent state-of-the-art dependence measures, such as distance\ncorrelation and the Hilbert-Schmidt independence criterion. We also emphasize\nthe potential of feature selection techniques relying on such dependence\nmeasures as alternatives to screening in high dimension.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 16:30:06 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Da Veiga", "S\u00e9bastien", "", "IFPEN, - M\u00e9thodes d'Analyse Stochastique des\n  Codes et Traitements Num\u00e9riques"]]}, {"id": "1311.2495", "submitter": "Moritz Hardt", "authors": "Moritz Hardt and Eric Price", "title": "The Noisy Power Method: A Meta Algorithm with Applications", "comments": "NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new robust convergence analysis of the well-known power method\nfor computing the dominant singular vectors of a matrix that we call the noisy\npower method. Our result characterizes the convergence behavior of the\nalgorithm when a significant amount noise is introduced after each\nmatrix-vector multiplication. The noisy power method can be seen as a\nmeta-algorithm that has recently found a number of important applications in a\nbroad range of machine learning problems including alternating minimization for\nmatrix completion, streaming principal component analysis (PCA), and\nprivacy-preserving spectral analysis. Our general analysis subsumes several\nexisting ad-hoc convergence bounds and resolves a number of open problems in\nmultiple applications including streaming PCA and privacy-preserving singular\nvector computation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 16:47:25 GMT"}, {"version": "v2", "created": "Mon, 15 Sep 2014 19:17:32 GMT"}, {"version": "v3", "created": "Mon, 8 Dec 2014 21:53:05 GMT"}, {"version": "v4", "created": "Tue, 3 Feb 2015 23:43:37 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Hardt", "Moritz", ""], ["Price", "Eric", ""]]}, {"id": "1311.2503", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "Predictable Feature Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Every organism in an environment, whether biological, robotic or virtual,\nmust be able to predict certain aspects of its environment in order to survive\nor perform whatever task is intended. It needs a model that is capable of\nestimating the consequences of possible actions, so that planning, control, and\ndecision-making become feasible. For scientific purposes, such models are\nusually created in a problem specific manner using differential equations and\nother techniques from control- and system-theory. In contrast to that, we aim\nfor an unsupervised approach that builds up the desired model in a\nself-organized fashion. Inspired by Slow Feature Analysis (SFA), our approach\nis to extract sub-signals from the input, that behave as predictable as\npossible. These \"predictable features\" are highly relevant for modeling,\nbecause predictability is a desired property of the needed\nconsequence-estimating model by definition. In our approach, we measure\npredictability with respect to a certain prediction model. We focus here on the\nsolution of the arising optimization problem and present a tractable algorithm\nbased on algebraic methods which we call Predictable Feature Analysis (PFA). We\nprove that the algorithm finds the globally optimal signal, if this signal can\nbe predicted with low error. To deal with cases where the optimal signal has a\nsignificant prediction error, we provide a robust, heuristically motivated\nvariant of the algorithm and verify it empirically. Additionally, we give\nformal criteria a prediction-model must meet to be suitable for measuring\npredictability in the PFA setting and also provide a suitable default-model\nalong with a formal proof that it meets these criteria.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 17:05:22 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1311.2547", "submitter": "Yuekai Sun", "authors": "Yuekai Sun, Stratis Ioannidis, Andrea Montanari", "title": "Learning Mixtures of Linear Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discriminative learning (regression) problem, whereby the\nregression function is a convex combination of k linear classifiers. Existing\napproaches are based on the EM algorithm, or similar techniques, without\nprovable guarantees. We develop a simple method based on spectral techniques\nand a `mirroring' trick, that discovers the subspace spanned by the\nclassifiers' parameter vectors. Under a probabilistic assumption on the feature\nvector distribution, we prove that this approach has nearly optimal statistical\nefficiency.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 19:50:51 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 18:52:34 GMT"}, {"version": "v3", "created": "Mon, 14 Jul 2014 18:26:20 GMT"}, {"version": "v4", "created": "Wed, 30 Jul 2014 23:40:04 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Sun", "Yuekai", ""], ["Ioannidis", "Stratis", ""], ["Montanari", "Andrea", ""]]}, {"id": "1311.2663", "submitter": "Shandian Zhe", "authors": "Shandian Zhe and Yuan Qi and Youngja Park and Ian Molloy and Suresh\n  Chari", "title": "DinTucker: Scaling up Gaussian process models on multidimensional arrays\n  with billions of elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite Tucker Decomposition (InfTucker) and random function prior models,\nas nonparametric Bayesian models on infinite exchangeable arrays, are more\npowerful models than widely-used multilinear factorization methods including\nTucker and PARAFAC decomposition, (partly) due to their capability of modeling\nnonlinear relationships between array elements. Despite their great predictive\nperformance and sound theoretical foundations, they cannot handle massive data\ndue to a prohibitively high training time. To overcome this limitation, we\npresent Distributed Infinite Tucker (DINTUCKER), a large-scale nonlinear tensor\ndecomposition algorithm on MAPREDUCE. While maintaining the predictive accuracy\nof InfTucker, it is scalable on massive data. DINTUCKER is based on a new\nhierarchical Bayesian model that enables local training of InfTucker on\nsubarrays and information integration from all local training results. We use\ndistributed stochastic gradient descent, coupled with variational inference, to\ntrain this model. We apply DINTUCKER to multidimensional arrays with billions\nof elements from applications in the \"Read the Web\" project (Carlson et al.,\n2010) and in information security and compare it with the state-of-the-art\nlarge-scale tensor decomposition method, GigaTensor. On both datasets,\nDINTUCKER achieves significantly higher prediction accuracy with less\ncomputational time.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 02:36:03 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2013 23:50:57 GMT"}, {"version": "v3", "created": "Sun, 15 Dec 2013 13:56:18 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2014 05:49:44 GMT"}, {"version": "v5", "created": "Sat, 1 Feb 2014 14:35:04 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Zhe", "Shandian", ""], ["Qi", "Yuan", ""], ["Park", "Youngja", ""], ["Molloy", "Ian", ""], ["Chari", "Suresh", ""]]}, {"id": "1311.2677", "submitter": "Raman Singh Mr.", "authors": "Raman Singh, Harish Kumar and R.K. Singla", "title": "Sampling Based Approaches to Handle Imbalances in Network Traffic\n  Dataset for Machine Learning Techniques", "comments": "12 pages", "journal-ref": null, "doi": "10.5121/csit.2013.3704", "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network traffic data is huge, varying and imbalanced because various classes\nare not equally distributed. Machine learning (ML) algorithms for traffic\nanalysis uses the samples from this data to recommend the actions to be taken\nby the network administrators as well as training. Due to imbalances in\ndataset, it is difficult to train machine learning algorithms for traffic\nanalysis and these may give biased or false results leading to serious\ndegradation in performance of these algorithms. Various techniques can be\napplied during sampling to minimize the effect of imbalanced instances. In this\npaper various sampling techniques have been analysed in order to compare the\ndecrease in variation in imbalances of network traffic datasets sampled for\nthese algorithms. Various parameters like missing classes in samples,\nprobability of sampling of the different instances have been considered for\ncomparison.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 05:32:48 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Singh", "Raman", ""], ["Kumar", "Harish", ""], ["Singla", "R. K.", ""]]}, {"id": "1311.2694", "submitter": "Purnamrita Sarkar", "authors": "Peter J. Bickel, Purnamrita Sarkar", "title": "Hypothesis Testing for Automated Community Detection in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST physics.soc-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in networks is a key exploratory tool with applications\nin a diverse set of areas, ranging from finding communities in social and\nbiological networks to identifying link farms in the World Wide Web. The\nproblem of finding communities or clusters in a network has received much\nattention from statistics, physics and computer science. However, most\nclustering algorithms assume knowledge of the number of clusters k. In this\npaper we propose to automatically determine k in a graph generated from a\nStochastic Blockmodel. Our main contribution is twofold; first, we\ntheoretically establish the limiting distribution of the principal eigenvalue\nof the suitably centered and scaled adjacency matrix, and use that distribution\nfor our hypothesis test. Secondly, we use this test to design a recursive\nbipartitioning algorithm. Using quantifiable classification tasks on real world\nnetworks with ground truth, we show that our algorithm outperforms existing\nprobabilistic models for learning overlapping clusters, and on unlabeled\nnetworks, we show that we uncover nested community structure.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 07:00:13 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 05:40:00 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Bickel", "Peter J.", ""], ["Sarkar", "Purnamrita", ""]]}, {"id": "1311.2746", "submitter": "Emad Grais", "authors": "Emad M. Grais, Mehmet Umut Sen, Hakan Erdogan", "title": "Deep neural networks for single channel source separation", "comments": "5 pages, 2 figures, 2 tables, submitted to ICASSP2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel approach for single channel source separation (SCSS)\nusing a deep neural network (DNN) architecture is introduced. Unlike previous\nstudies in which DNN and other classifiers were used for classifying\ntime-frequency bins to obtain hard masks for each source, we use the DNN to\nclassify estimated source spectra to check for their validity during\nseparation. In the training stage, the training data for the source signals are\nused to train a DNN. In the separation stage, the trained DNN is utilized to\naid in estimation of each source in the mixed signal. Single channel source\nseparation problem is formulated as an energy minimization problem where each\nsource spectra estimate is encouraged to fit the trained DNN model and the\nmixed signal spectrum is encouraged to be written as a weighted sum of the\nestimated source spectra. The proposed approach works regardless of the energy\nscale differences between the source signals in the training and separation\nstages. Nonnegative matrix factorization (NMF) is used to initialize the DNN\nestimate for each source. The experimental results show that using DNN\ninitialized by NMF for source separation improves the quality of the separated\nsignal compared with using NMF for source separation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 12:03:40 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Grais", "Emad M.", ""], ["Sen", "Mehmet Umut", ""], ["Erdogan", "Hakan", ""]]}, {"id": "1311.2799", "submitter": "Philippe Rigollet", "authors": "Dong Dai, Philippe Rigollet, Lucy Xia and Tong Zhang", "title": "Aggregation of Affine Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating a general collection of affine\nestimators for fixed design regression. Relevant examples include some commonly\nused statistical estimators such as least squares, ridge and robust least\nsquares estimators. Dalalyan and Salmon (2012) have established that, for this\nproblem, exponentially weighted (EW) model selection aggregation leads to sharp\noracle inequalities in expectation, but similar bounds in deviation were not\npreviously known. While results indicate that the same aggregation scheme may\nnot satisfy sharp oracle inequalities with high probability, we prove that a\nweaker notion of oracle inequality for EW that holds with high probability.\nMoreover, using a generalization of the newly introduced $Q$-aggregation scheme\nwe also prove sharp oracle inequalities that hold with high probability.\nFinally, we apply our results to universal aggregation and show that our\nproposed estimator leads simultaneously to all the best known bounds for\naggregation, including $\\ell_q$-aggregation, $q \\in (0,1)$, with high\nprobability.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 14:53:51 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Dai", "Dong", ""], ["Rigollet", "Philippe", ""], ["Xia", "Lucy", ""], ["Zhang", "Tong", ""]]}, {"id": "1311.2838", "submitter": "Christoph H. Lampert", "authors": "Anastasia Pentina and Christoph H. Lampert", "title": "A PAC-Bayesian bound for Lifelong Learning", "comments": "to appear at ICML 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has received a lot of attention in the machine learning\ncommunity over the last years, and several effective algorithms have been\ndeveloped. However, relatively little is known about their theoretical\nproperties, especially in the setting of lifelong learning, where the goal is\nto transfer information to tasks for which no data have been observed so far.\nIn this work we study lifelong learning from a theoretical perspective. Our\nmain result is a PAC-Bayesian generalization bound that offers a unified view\non existing paradigms for transfer learning, such as the transfer of parameters\nor the transfer of low-dimensional representations. We also use the bound to\nderive two principled lifelong learning algorithms, and we show that these\nyield results comparable with existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 17:05:04 GMT"}, {"version": "v2", "created": "Sat, 10 May 2014 10:45:51 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Pentina", "Anastasia", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1311.2854", "submitter": "Christos Boutsidis", "authors": "Christos Boutsidis and Alex Gittens and Prabhanjan Kambadur", "title": "Spectral Clustering via the Power Method -- Provably", "comments": "ICML 2015, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most important algorithms in data mining\nand machine intelligence; however, its computational complexity limits its\napplication to truly large scale data analysis. The computational bottleneck in\nspectral clustering is computing a few of the top eigenvectors of the\n(normalized) Laplacian matrix corresponding to the graph representing the data\nto be clustered. One way to speed up the computation of these eigenvectors is\nto use the \"power method\" from the numerical linear algebra literature.\nAlthough the power method has been empirically used to speed up spectral\nclustering, the theory behind this approach, to the best of our knowledge,\nremains unexplored. This paper provides the \\emph{first} such rigorous\ntheoretical justification, arguing that a small number of power iterations\nsuffices to obtain near-optimal partitionings using the approximate\neigenvectors. Specifically, we prove that solving the $k$-means clustering\nproblem on the approximate eigenvectors obtained via the power method gives an\nadditive-error approximation to solving the $k$-means problem on the optimal\neigenvectors.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 17:42:34 GMT"}, {"version": "v2", "created": "Sun, 8 Feb 2015 15:55:49 GMT"}, {"version": "v3", "created": "Tue, 12 May 2015 14:39:32 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Boutsidis", "Christos", ""], ["Gittens", "Alex", ""], ["Kambadur", "Prabhanjan", ""]]}, {"id": "1311.2889", "submitter": "Adwaitvedant Mathkar", "authors": "Vivek S. Borkar and Adwaitvedant S. Mathkar", "title": "Reinforcement Learning for Matrix Computations: PageRank as an Example", "comments": "12 pages, 6 figures, invited lecture at ICDIT (International\n  Conference on Distributed Computing and Internet Technologies), 2014, will be\n  published in Lecture notes in Computer Science along with the conference\n  proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has gained wide popularity as a technique for\nsimulation-driven approximate dynamic programming. A less known aspect is that\nthe very reasons that make it effective in dynamic programming can also be\nleveraged for using it for distributed schemes for certain matrix computations\ninvolving non-negative matrices. In this spirit, we propose a reinforcement\nlearning algorithm for PageRank computation that is fashioned after analogous\nschemes for approximate dynamic programming. The algorithm has the advantage of\nease of distributed implementation and more importantly, of being model-free,\ni.e., not dependent on any specific assumptions about the transition\nprobabilities in the random web-surfer model. We analyze its convergence and\nfinite time behavior and present some supporting numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 14:24:32 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Borkar", "Vivek S.", ""], ["Mathkar", "Adwaitvedant S.", ""]]}, {"id": "1311.2891", "submitter": "Joseph Anderson", "authors": "Joseph Anderson, Mikhail Belkin, Navin Goyal, Luis Rademacher, James\n  Voss", "title": "The More, the Merrier: the Blessing of Dimensionality for Learning Large\n  Gaussian Mixtures", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that very large mixtures of Gaussians are efficiently\nlearnable in high dimension. More precisely, we prove that a mixture with known\nidentical covariance matrices whose number of components is a polynomial of any\nfixed degree in the dimension n is polynomially learnable as long as a certain\nnon-degeneracy condition on the means is satisfied. It turns out that this\ncondition is generic in the sense of smoothed complexity, as soon as the\ndimensionality of the space is high enough. Moreover, we prove that no such\ncondition can possibly exist in low dimension and the problem of learning the\nparameters is generically hard. In contrast, much of the existing work on\nGaussian Mixtures relies on low-dimensional projections and thus hits an\nartificial barrier. Our main result on mixture recovery relies on a new\n\"Poissonization\"-based technique, which transforms a mixture of Gaussians to a\nlinear map of a product distribution. The problem of learning this map can be\nefficiently solved using some recent results on tensor decompositions and\nIndependent Component Analysis (ICA), thus giving an algorithm for recovering\nthe mixture. In addition, we combine our low-dimensional hardness results for\nGaussian mixtures with Poissonization to show how to embed difficult instances\nof low-dimensional Gaussian mixtures into the ICA setting, thus establishing\nexponential information-theoretic lower bounds for underdetermined ICA in low\ndimension. To the best of our knowledge, this is the first such result in the\nliterature. In addition to contributing to the problem of Gaussian mixture\nlearning, we believe that this work is among the first steps toward better\nunderstanding the rare phenomenon of the \"blessing of dimensionality\" in the\ncomputational aspects of statistical inference.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 19:21:03 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 20:32:45 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2014 03:34:38 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Anderson", "Joseph", ""], ["Belkin", "Mikhail", ""], ["Goyal", "Navin", ""], ["Rademacher", "Luis", ""], ["Voss", "James", ""]]}, {"id": "1311.2971", "submitter": "Raja Hafiz Affandi", "authors": "Raja Hafiz Affandi, Emily B. Fox, Ben Taskar", "title": "Approximate Inference in Continuous Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are random point processes well-suited\nfor modeling repulsion. In machine learning, the focus of DPP-based models has\nbeen on diverse subset selection from a discrete and finite base set. This\ndiscrete setting admits an efficient sampling algorithm based on the\neigendecomposition of the defining kernel matrix. Recently, there has been\ngrowing interest in using DPPs defined on continuous spaces. While the\ndiscrete-DPP sampler extends formally to the continuous case, computationally,\nthe steps required are not tractable in general. In this paper, we present two\nefficient DPP sampling schemes that apply to a wide range of kernel functions:\none based on low rank approximations via Nystrom and random Fourier feature\ntechniques and another based on Gibbs sampling. We demonstrate the utility of\ncontinuous DPPs in repulsive mixture modeling and synthesizing human poses\nspanning activity spaces.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 22:15:26 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Affandi", "Raja Hafiz", ""], ["Fox", "Emily B.", ""], ["Taskar", "Ben", ""]]}, {"id": "1311.2972", "submitter": "Sewoong Oh", "authors": "Prateek Jain and Sewoong Oh", "title": "Learning Mixtures of Discrete Product Distributions using Spectral\n  Decompositions", "comments": "30 pages no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a distribution from samples, when the\nunderlying distribution is a mixture of product distributions over discrete\ndomains. This problem is motivated by several practical applications such as\ncrowd-sourcing, recommendation systems, and learning Boolean functions. The\nexisting solutions either heavily rely on the fact that the number of\ncomponents in the mixtures is finite or have sample/time complexity that is\nexponential in the number of components. In this paper, we introduce a\npolynomial time/sample complexity method for learning a mixture of $r$ discrete\nproduct distributions over $\\{1, 2, \\dots, \\ell\\}^n$, for general $\\ell$ and\n$r$. We show that our approach is statistically consistent and further provide\nfinite sample guarantees.\n  We use techniques from the recent work on tensor decompositions for\nhigher-order moment matching. A crucial step in these moment matching methods\nis to construct a certain matrix and a certain tensor with low-rank spectral\ndecompositions. These tensors are typically estimated directly from the\nsamples. The main challenge in learning mixtures of discrete product\ndistributions is that these low-rank tensors cannot be obtained directly from\nthe sample moments. Instead, we reduce the tensor estimation problem to: $a$)\nestimating a low-rank matrix using only off-diagonal block elements; and $b$)\nestimating a tensor using a small number of linear measurements. Leveraging on\nrecent developments in matrix completion, we give an alternating minimization\nbased method to estimate the low-rank matrix, and formulate the tensor\ncompletion problem as a least-squares problem.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 22:15:35 GMT"}, {"version": "v2", "created": "Sat, 17 May 2014 19:38:34 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Jain", "Prateek", ""], ["Oh", "Sewoong", ""]]}, {"id": "1311.2987", "submitter": "Hamid Palangi", "authors": "Hamid Palangi, Li Deng, Rabab K Ward", "title": "Learning Input and Recurrent Weight Matrices in Echo State Networks", "comments": "Deep Learning Workshop NIPS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESNs) are a special type of the temporally deep network\nmodel, the Recurrent Neural Network (RNN), where the recurrent matrix is\ncarefully designed and both the recurrent and input matrices are fixed. An ESN\nuses the linearity of the activation function of the output units to simplify\nthe learning of the output matrix. In this paper, we devise a special technique\nthat take advantage of this linearity in the output units of an ESN, to learn\nthe input and recurrent matrices. This has not been done in earlier ESNs due to\ntheir well known difficulty in learning those matrices. Compared to the\ntechnique of BackPropagation Through Time (BPTT) in learning general RNNs, our\nproposed method exploits linearity of activation function in the output units\nto formulate the relationships amongst the various matrices in an RNN. These\nrelationships results in the gradient of the cost function having an analytical\nform and being more accurate. This would enable us to compute the gradients\ninstead of obtaining them by recursion as in BPTT. Experimental results on\nphone state classification show that learning one or both the input and\nrecurrent matrices in an ESN yields superior results compared to traditional\nESNs that do not learn these matrices, especially when longer time steps are\nused.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 00:11:09 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Palangi", "Hamid", ""], ["Deng", "Li", ""], ["Ward", "Rabab K", ""]]}, {"id": "1311.3001", "submitter": "Kevin H. Knuth", "authors": "Kevin H. Knuth", "title": "Informed Source Separation: A Bayesian Tutorial", "comments": "8 pages Knuth K.H. 2005. Informed source separation: A Bayesian\n  tutorial. (Invited paper) B. Sankur, E. Cetin, M. Tekalp, E. Kuruoglu (eds.),\n  Proceedings of the 13th European Signal Processing Conference (EUSIPCO 2005),\n  Antalya, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source separation problems are ubiquitous in the physical sciences; any\nsituation where signals are superimposed calls for source separation to\nestimate the original signals. In this tutorial I will discuss the Bayesian\napproach to the source separation problem. This approach has a specific\nadvantage in that it requires the designer to explicitly describe the signal\nmodel in addition to any other information or assumptions that go into the\nproblem description. This leads naturally to the idea of informed source\nseparation, where the algorithm design incorporates relevant information about\nthe specific problem. This approach promises to enable researchers to design\ntheir own high-quality algorithms that are specifically tailored to the problem\nat hand.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 02:23:34 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Knuth", "Kevin H.", ""]]}, {"id": "1311.3157", "submitter": "Jianbo Ye", "authors": "Jianbo Ye", "title": "Multiple Closed-Form Local Metric Learning for K-Nearest Neighbor\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researches have been devoted to learn a Mahalanobis distance metric,\nwhich can effectively improve the performance of kNN classification. Most\napproaches are iterative and computational expensive and linear rigidity still\ncritically limits metric learning algorithm to perform better. We proposed a\ncomputational economical framework to learn multiple metrics in closed-form.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 17:25:29 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Ye", "Jianbo", ""]]}, {"id": "1311.3287", "submitter": "Le Song", "authors": "Le Song, Animashree Anandkumar, Bo Dai, Bo Xie", "title": "Nonparametric Estimation of Multi-View Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods have greatly advanced the estimation of latent variable\nmodels, generating a sequence of novel and efficient algorithms with strong\ntheoretical guarantees. However, current spectral algorithms are largely\nrestricted to mixtures of discrete or Gaussian distributions. In this paper, we\npropose a kernel method for learning multi-view latent variable models,\nallowing each mixture component to be nonparametric. The key idea of the method\nis to embed the joint distribution of a multi-view latent variable into a\nreproducing kernel Hilbert space, and then the latent parameters are recovered\nusing a robust tensor power method. We establish that the sample complexity for\nthe proposed method is quadratic in the number of latent components and is a\nlow order polynomial in the other relevant parameters. Thus, our non-parametric\ntensor approach to learning latent variable models enjoys good sample and\ncomputational efficiencies. Moreover, the non-parametric tensor power method\ncompares favorably to EM algorithm and other existing spectral algorithms in\nour experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 20:42:21 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2013 01:58:58 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Song", "Le", ""], ["Anandkumar", "Animashree", ""], ["Dai", "Bo", ""], ["Xie", "Bo", ""]]}, {"id": "1311.3315", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Rina Panigrahy", "title": "Sparse Matrix Factorization", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of factorizing a matrix into several sparse\nmatrices and propose an algorithm for this under randomness and sparsity\nassumptions. This problem can be viewed as a simplification of the deep\nlearning problem where finding a factorization corresponds to finding edges in\ndifferent layers and values of hidden units. We prove that under certain\nassumptions for a sparse linear deep network with $n$ nodes in each layer, our\nalgorithm is able to recover the structure of the network and values of top\nlayer hidden units for depths up to $\\tilde O(n^{1/6})$. We further discuss the\nrelation among sparse matrix factorization, deep learning, sparse recovery and\ndictionary learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 21:33:05 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2013 23:53:26 GMT"}, {"version": "v3", "created": "Tue, 13 May 2014 14:24:33 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Panigrahy", "Rina", ""]]}, {"id": "1311.3368", "submitter": "Sameer Singh", "authors": "Sameer Singh and Sebastian Riedel and Andrew McCallum", "title": "Anytime Belief Propagation Using Sparse Domains", "comments": "NIPS 2013 Workshop on Resource-Efficient Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Belief Propagation has been widely used for marginal inference, however it is\nslow on problems with large-domain variables and high-order factors. Previous\nwork provides useful approximations to facilitate inference on such models, but\nlacks important anytime properties such as: 1) providing accurate and\nconsistent marginals when stopped early, 2) improving the approximation when\nrun longer, and 3) converging to the fixed point of BP. To this end, we propose\na message passing algorithm that works on sparse (partially instantiated)\ndomains, and converges to consistent marginals using dynamic message\nscheduling. The algorithm grows the sparse domains incrementally, selecting the\nnext value to add using prioritization schemes based on the gradients of the\nmarginal inference objective. Our experiments demonstrate local anytime\nconsistency and fast convergence, providing significant speedups over BP to\nobtain low-error marginals: up to 25 times on grid models, and up to 6 times on\na real-world natural language processing task.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 02:39:45 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Singh", "Sameer", ""], ["Riedel", "Sebastian", ""], ["McCallum", "Andrew", ""]]}, {"id": "1311.3494", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Fundamental Limits of Online and Distributed Algorithms for Statistical\n  Learning and Estimation", "comments": "Full version of NIPS 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning approaches are characterized by information constraints\non how they interact with the training data. These include memory and\nsequential access constraints (e.g. fast first-order methods to solve\nstochastic optimization problems); communication constraints (e.g. distributed\nlearning); partial access to the underlying data (e.g. missing features and\nmulti-armed bandits) and more. However, currently we have little understanding\nhow such information constraints fundamentally affect our performance,\nindependent of the learning problem semantics. For example, are there learning\nproblems where any algorithm which has small memory footprint (or can use any\nbounded number of bits from each example, or has certain communication\nconstraints) will perform worse than what is possible without such constraints?\nIn this paper, we describe how a single set of results implies positive answers\nto the above, for several different settings.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 13:21:15 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 14:55:06 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2014 06:23:28 GMT"}, {"version": "v4", "created": "Tue, 6 May 2014 10:56:31 GMT"}, {"version": "v5", "created": "Wed, 21 May 2014 18:35:13 GMT"}, {"version": "v6", "created": "Tue, 28 Oct 2014 13:25:09 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1311.3651", "submitter": "Aravindan Vijayaraghavan", "authors": "Aditya Bhaskara, Moses Charikar, Ankur Moitra and Aravindan\n  Vijayaraghavan", "title": "Smoothed Analysis of Tensor Decompositions", "comments": "32 pages (including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank tensor decompositions are a powerful tool for learning generative\nmodels, and uniqueness results give them a significant advantage over matrix\ndecomposition methods. However, tensors pose significant algorithmic challenges\nand tensors analogs of much of the matrix algebra toolkit are unlikely to exist\nbecause of hardness results. Efficient decomposition in the overcomplete case\n(where rank exceeds dimension) is particularly challenging. We introduce a\nsmoothed analysis model for studying these questions and develop an efficient\nalgorithm for tensor decomposition in the highly overcomplete case (rank\npolynomial in the dimension). In this setting, we show that our algorithm is\nrobust to inverse polynomial error -- a crucial property for applications in\nlearning since we are only allowed a polynomial number of samples. While\nalgorithms are known for exact tensor decomposition in some overcomplete\nsettings, our main contribution is in analyzing their stability in the\nframework of smoothed analysis.\n  Our main technical contribution is to show that tensor products of perturbed\nvectors are linearly independent in a robust sense (i.e. the associated matrix\nhas singular values that are at least an inverse polynomial). This key result\npaves the way for applying tensor methods to learning problems in the smoothed\nsetting. In particular, we use it to obtain results for learning multi-view\nmodels and mixtures of axis-aligned Gaussians where there are many more\n\"components\" than dimensions. The assumption here is that the model is not\nadversarially chosen, formalized by a perturbation of model parameters. We\nbelieve this an appealing way to analyze realistic instances of learning\nproblems, since this framework allows us to overcome many of the usual\nlimitations of using tensor methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 20:49:55 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2013 15:28:47 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2014 21:09:31 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2014 06:19:39 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Charikar", "Moses", ""], ["Moitra", "Ankur", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1311.3669", "submitter": "Manuel Gomez Rodriguez", "authors": "Nan Du, Le Song, Manuel Gomez Rodriguez, Hongyuan Zha", "title": "Scalable Influence Estimation in Continuous-Time Diffusion Networks", "comments": "To appear in Advances in Neural Information Processing Systems\n  (NIPS), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If a piece of information is released from a media site, can it spread, in 1\nmonth, to a million web pages? This influence estimation problem is very\nchallenging since both the time-sensitive nature of the problem and the issue\nof scalability need to be addressed simultaneously. In this paper, we propose a\nrandomized algorithm for influence estimation in continuous-time diffusion\nnetworks. Our algorithm can estimate the influence of every node in a network\nwith |V| nodes and |E| edges to an accuracy of $\\varepsilon$ using\n$n=O(1/\\varepsilon^2)$ randomizations and up to logarithmic factors\nO(n|E|+n|V|) computations. When used as a subroutine in a greedy influence\nmaximization algorithm, our proposed method is guaranteed to find a set of\nnodes with an influence of at least (1-1/e)OPT-2$\\varepsilon$, where OPT is the\noptimal value. Experiments on both synthetic and real-world data show that the\nproposed method can easily scale up to networks of millions of nodes while\nsignificantly improves over previous state-of-the-arts in terms of the accuracy\nof the estimated influence and the quality of the selected nodes in maximizing\nthe influence.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 21:01:15 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Du", "Nan", ""], ["Song", "Le", ""], ["Rodriguez", "Manuel Gomez", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1311.3735", "submitter": "Nicola Di Mauro", "authors": "Nicola Di Mauro and Floriana Esposito", "title": "Ensemble Relational Learning based on Selective Propositionalization", "comments": "10 pages. arXiv admin note: text overlap with arXiv:1006.5188", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with structured data needs the use of expressive representation\nformalisms that, however, puts the problem to deal with the computational\ncomplexity of the machine learning process. Furthermore, real world domains\nrequire tools able to manage their typical uncertainty. Many statistical\nrelational learning approaches try to deal with these problems by combining the\nconstruction of relevant relational features with a probabilistic tool. When\nthe combination is static (static propositionalization), the constructed\nfeatures are considered as boolean features and used offline as input to a\nstatistical learner; while, when the combination is dynamic (dynamic\npropositionalization), the feature construction and probabilistic tool are\ncombined into a single process. In this paper we propose a selective\npropositionalization method that search the optimal set of relational features\nto be used by a probabilistic learner in order to minimize a loss function. The\nnew propositionalization approach has been combined with the random subspace\nensemble method. Experiments on real-world datasets shows the validity of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 06:14:15 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Di Mauro", "Nicola", ""], ["Esposito", "Floriana", ""]]}, {"id": "1311.3859", "submitter": "Yannick Schwartz", "authors": "Yannick Schwartz (INRIA Saclay - Ile de France, NEUROSPIN), Bertrand\n  Thirion (INRIA Saclay - Ile de France, NEUROSPIN), Ga\\\"el Varoquaux (INRIA\n  Saclay - Ile de France, LNAO)", "title": "Mapping cognitive ontologies to and from the brain", "comments": "NIPS (Neural Information Processing Systems), United States (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging neuroscience links brain activation maps to behavior and cognition\nvia correlational studies. Due to the nature of the individual experiments,\nbased on eliciting neural response from a small number of stimuli, this link is\nincomplete, and unidirectional from the causal point of view. To come to\nconclusions on the function implied by the activation of brain regions, it is\nnecessary to combine a wide exploration of the various brain functions and some\ninversion of the statistical inference. Here we introduce a methodology for\naccumulating knowledge towards a bidirectional link between observed brain\nactivity and the corresponding function. We rely on a large corpus of imaging\nstudies and a predictive engine. Technically, the challenges are to find\ncommonality between the studies without denaturing the richness of the corpus.\nThe key elements that we contribute are labeling the tasks performed with a\ncognitive ontology, and modeling the long tail of rare paradigms in the corpus.\nTo our knowledge, our approach is the first demonstration of predicting the\ncognitive content of completely new brain images. To that end, we propose a\nmethod that predicts the experimental paradigms across different studies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 14:19:31 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 12:26:50 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Schwartz", "Yannick", "", "INRIA Saclay - Ile de France, NEUROSPIN"], ["Thirion", "Bertrand", "", "INRIA Saclay - Ile de France, NEUROSPIN"], ["Varoquaux", "Ga\u00ebl", "", "INRIA\n  Saclay - Ile de France, LNAO"]]}, {"id": "1311.3959", "submitter": "M M Hassan Mahmud", "authors": "M. M. Hassan Mahmud, Majd Hawasly, Benjamin Rosman, Subramanian\n  Ramamoorthy", "title": "Clustering Markov Decision Processes For Continual Transfer", "comments": "56 pages, Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms to effectively represent a set of Markov decision\nprocesses (MDPs), whose optimal policies have already been learned, by a\nsmaller source subset for lifelong, policy-reuse-based transfer learning in\nreinforcement learning. This is necessary when the number of previous tasks is\nlarge and the cost of measuring similarity counteracts the benefit of transfer.\nThe source subset forms an `$\\epsilon$-net' over the original set of MDPs, in\nthe sense that for each previous MDP $M_p$, there is a source $M^s$ whose\noptimal policy has $<\\epsilon$ regret in $M_p$. Our contributions are as\nfollows. We present EXP-3-Transfer, a principled policy-reuse algorithm that\noptimally reuses a given source policy set when learning for a new MDP. We\npresent a framework to cluster the previous MDPs to extract a source subset.\nThe framework consists of (i) a distance $d_V$ over MDPs to measure\npolicy-based similarity between MDPs; (ii) a cost function $g(\\cdot)$ that uses\n$d_V$ to measure how good a particular clustering is for generating useful\nsource tasks for EXP-3-Transfer and (iii) a provably convergent algorithm,\nMHAV, for finding the optimal clustering. We validate our algorithms through\nexperiments in a surveillance domain.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 19:40:58 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2016 23:26:39 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2016 22:20:37 GMT"}, {"version": "v4", "created": "Sun, 1 May 2016 12:27:39 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Mahmud", "M. M. Hassan", ""], ["Hawasly", "Majd", ""], ["Rosman", "Benjamin", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "1311.4086", "submitter": "Abdelhak Mansoul", "authors": "Abdelhak Mansoul, Baghdad Atmani, Sofia Benbelkacem", "title": "A hybrid decision support system : application on healthcare", "comments": "13 pages, 4 figures, SEAS 2013 Dubai conference, paper id : 16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many systems based on knowledge, especially expert systems for medical\ndecision support have been developed. Only systems are based on production\nrules, and cannot learn and evolve only by updating them. In addition, taking\ninto account several criteria induces an exorbitant number of rules to be\ninjected into the system. It becomes difficult to translate medical knowledge\nor a support decision as a simple rule. Moreover, reasoning based on generic\ncases became classic and can even reduce the range of possible solutions. To\nremedy that, we propose an approach based on using a multi-criteria decision\nguided by a case-based reasoning (CBR) approach.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2013 18:13:42 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Mansoul", "Abdelhak", ""], ["Atmani", "Baghdad", ""], ["Benbelkacem", "Sofia", ""]]}, {"id": "1311.4150", "submitter": "Jian-Feng Yan", "authors": "Jian-Feng Yan, Jia Zeng, Zhi-Qiang Liu, Yang Gao", "title": "Towards Big Topic Modeling", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the big topic modeling problem, we need to reduce both time and\nspace complexities of batch latent Dirichlet allocation (LDA) algorithms.\nAlthough parallel LDA algorithms on the multi-processor architecture have low\ntime and space complexities, their communication costs among processors often\nscale linearly with the vocabulary size and the number of topics, leading to a\nserious scalability problem. To reduce the communication complexity among\nprocessors for a better scalability, we propose a novel communication-efficient\nparallel topic modeling architecture based on power law, which consumes orders\nof magnitude less communication time when the number of topics is large. We\ncombine the proposed communication-efficient parallel architecture with the\nonline belief propagation (OBP) algorithm referred to as POBP for big topic\nmodeling tasks. Extensive empirical results confirm that POBP has the following\nadvantages to solve the big topic modeling problem: 1) high accuracy, 2)\ncommunication-efficient, 3) fast speed, and 4) constant memory usage when\ncompared with recent state-of-the-art parallel LDA algorithms on the\nmulti-processor architecture.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 11:52:42 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Yan", "Jian-Feng", ""], ["Zeng", "Jia", ""], ["Liu", "Zhi-Qiang", ""], ["Gao", "Yang", ""]]}, {"id": "1311.4158", "submitter": "Fabio Anselmi", "authors": "Fabio Anselmi, Joel Z. Leibo, Lorenzo Rosasco, Jim Mutch, Andrea\n  Tacchetti, Tomaso Poggio", "title": "Unsupervised Learning of Invariant Representations in Hierarchical\n  Architectures", "comments": "23 pages, 10 figures. November 21 2013: Added acknowledgment of NSF\n  funding. No other changes. December 18 (2013): Fixed a figure. January 10\n  (2014): Fixed a figure and some math in SI. March 10 2014: modified abstract\n  and implementation section (main and SI); added a paragraph about sample\n  complexity in SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present phase of Machine Learning is characterized by supervised learning\nalgorithms relying on large sets of labeled examples ($n \\to \\infty$). The next\nphase is likely to focus on algorithms capable of learning from very few\nlabeled examples ($n \\to 1$), like humans seem able to do. We propose an\napproach to this problem and describe the underlying theory, based on the\nunsupervised, automatic learning of a ``good'' representation for supervised\nlearning, characterized by small sample complexity ($n$). We consider the case\nof visual object recognition though the theory applies to other domains. The\nstarting point is the conjecture, proved in specific cases, that image\nrepresentations which are invariant to translations, scaling and other\ntransformations can considerably reduce the sample complexity of learning. We\nprove that an invariant and unique (discriminative) signature can be computed\nfor each image patch, $I$, in terms of empirical distributions of the\ndot-products between $I$ and a set of templates stored during unsupervised\nlearning. A module performing filtering and pooling, like the simple and\ncomplex cells described by Hubel and Wiesel, can compute such estimates.\nHierarchical architectures consisting of this basic Hubel-Wiesel moduli inherit\nits properties of invariance, stability, and discriminability while capturing\nthe compositional organization of the visual world in terms of wholes and\nparts. The theory extends existing deep learning convolutional architectures\nfor image and speech recognition. It also suggests that the main computational\ngoal of the ventral stream of visual cortex is to provide a hierarchical\nrepresentation of new objects/images which is invariant to transformations,\nstable, and discriminative for recognition---and that this representation may\nbe continuously learned in an unsupervised way during development and visual\nexperience.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 13:22:44 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2013 10:41:41 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2013 20:57:24 GMT"}, {"version": "v4", "created": "Sun, 12 Jan 2014 04:06:29 GMT"}, {"version": "v5", "created": "Tue, 11 Mar 2014 19:56:59 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Anselmi", "Fabio", ""], ["Leibo", "Joel Z.", ""], ["Rosasco", "Lorenzo", ""], ["Mutch", "Jim", ""], ["Tacchetti", "Andrea", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1311.4235", "submitter": "Jose Hernandez-Orallo", "authors": "Fernando Mart\\'inez-Plumed and C\\`esar Ferri and Jos\\'e\n  Hern\\'andez-Orallo and Mar\\'ia-Jos\\'e Ram\\'irez-Quintana", "title": "On the definition of a general learning system with user-defined\n  operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we push forward the idea of machine learning systems whose\noperators can be modified and fine-tuned for each problem. This allows us to\npropose a learning paradigm where users can write (or adapt) their operators,\naccording to the problem, data representation and the way the information\nshould be navigated. To achieve this goal, data instances, background\nknowledge, rules, programs and operators are all written in the same functional\nlanguage, Erlang. Since changing operators affect how the search space needs to\nbe explored, heuristics are learnt as a result of a decision process based on\nreinforcement learning where each action is defined as a choice of operator and\nrule. As a result, the architecture can be seen as a 'system for writing\nmachine learning systems' or to explore new operators where the policy reuse\n(as a kind of transfer learning) is allowed. States and actions are represented\nin a Q matrix which is actually a table, from which a supervised model is\nlearnt. This makes it possible to have a more flexible mapping between old and\nnew problems, since we work with an abstraction of rules and actions. We\ninclude some examples sharing reuse and the application of the system gErl to\nIQ problems. In order to evaluate gErl, we will test it against some structured\nproblems: a selection of IQ test tasks and some experiments on some structured\nprediction problems (list patterns).\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 00:48:14 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Mart\u00ednez-Plumed", "Fernando", ""], ["Ferri", "C\u00e8sar", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""], ["Ram\u00edrez-Quintana", "Mar\u00eda-Jos\u00e9", ""]]}, {"id": "1311.4296", "submitter": "Francis Bach", "authors": "Stefanie Jegelka, Francis Bach (INRIA Paris - Rocquencourt, LIENS),\n  Suvrit Sra (MPI)", "title": "Reflection methods for user-friendly submodular optimization", "comments": "Neural Information Processing Systems (NIPS), \\'Etats-Unis (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has become evident that submodularity naturally captures widely\noccurring concepts in machine learning, signal processing and computer vision.\nConsequently, there is need for efficient optimization procedures for\nsubmodular functions, especially for minimization problems. While general\nsubmodular minimization is challenging, we propose a new method that exploits\nexisting decomposability of submodular functions. In contrast to previous\napproaches, our method is neither approximate, nor impractical, nor does it\nneed any cumbersome parameter tuning. Moreover, it is easy to implement and\nparallelize. A key component of our method is a formulation of the discrete\nsubmodular minimization problem as a continuous best approximation problem that\nis solved through a sequence of reflections, and its solution can be easily\nthresholded to obtain an optimal discrete solution. This method solves both the\ncontinuous and discrete formulations of the problem, and therefore has\napplications in learning, inference, and reconstruction. In our experiments, we\nillustrate the benefits of our method on two image segmentation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 08:48:13 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Jegelka", "Stefanie", "", "INRIA Paris - Rocquencourt, LIENS"], ["Bach", "Francis", "", "INRIA Paris - Rocquencourt, LIENS"], ["Sra", "Suvrit", "", "MPI"]]}, {"id": "1311.4319", "submitter": "Lars Kotthoff", "authors": "Lars Kotthoff", "title": "Ranking Algorithms by Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common way of doing algorithm selection is to train a machine learning\nmodel and predict the best algorithm from a portfolio to solve a particular\nproblem. While this method has been highly successful, choosing only a single\nalgorithm has inherent limitations -- if the choice was bad, no remedial action\ncan be taken and parallelism cannot be exploited, to name but a few problems.\nIn this paper, we investigate how to predict the ranking of the portfolio\nalgorithms on a particular problem. This information can be used to choose the\nsingle best algorithm, but also to allocate resources to the algorithms\naccording to their rank. We evaluate a range of approaches to predict the\nranking of a set of algorithms on a problem. We furthermore introduce a\nframework for categorizing ranking predictions that allows to judge the\nexpressiveness of the predictive output. Our experimental evaluation\ndemonstrates on a range of data sets from the literature that it is beneficial\nto consider the relationship between algorithms when predicting rankings. We\nfurthermore show that relatively naive approaches deliver rankings of good\nquality already.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 10:22:53 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Kotthoff", "Lars", ""]]}, {"id": "1311.4468", "submitter": "Jan-Peter Calliess", "authors": "Jan-Peter Calliess, Antonis Papachristodoulou and Stephen J. Roberts", "title": "Stochastic processes and feedback-linearisation for online\n  identification and Bayesian adaptive control of fully-actuated mechanical\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a new method for simultaneous probabilistic identification\nand control of an observable, fully-actuated mechanical system. Identification\nis achieved by conditioning stochastic process priors on observations of\nconfigurations and noisy estimates of configuration derivatives. In contrast to\nprevious work that has used stochastic processes for identification, we\nleverage the structural knowledge afforded by Lagrangian mechanics and learn\nthe drift and control input matrix functions of the control-affine system\nseparately. We utilise feedback-linearisation to reduce, in expectation, the\nuncertain nonlinear control problem to one that is easy to regulate in a\ndesired manner. Thereby, our method combines the flexibility of nonparametric\nBayesian learning with epistemological guarantees on the expected closed-loop\ntrajectory. We illustrate our method in the context of torque-actuated pendula\nwhere the dynamics are learned with a combination of normal and log-normal\nprocesses.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 17:31:48 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 23:43:11 GMT"}, {"version": "v3", "created": "Tue, 1 Apr 2014 15:52:02 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Calliess", "Jan-Peter", ""], ["Papachristodoulou", "Antonis", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1311.4472", "submitter": "Rob Tibshirani", "authors": "Nadine Hussami and Robert Tibshirani", "title": "A Component Lasso", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sparse regression method called the component lasso, based\non a simple idea. The method uses the connected-components structure of the\nsample covariance matrix to split the problem into smaller ones. It then solves\nthe subproblems separately, obtaining a coefficient vector for each one. Then,\nit uses non-negative least squares to recombine the different vectors into a\nsingle solution. This step is useful in selecting and reweighting components\nthat are correlated with the response. Simulated and real data examples show\nthat the component lasso can outperform standard regression methods such as the\nlasso and elastic net, achieving a lower mean squared error as well as better\nsupport recovery.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 17:56:28 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2013 22:02:14 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Hussami", "Nadine", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1311.4486", "submitter": "Yun-Qian Miao", "authors": "Yun-Qian Miao, Ahmed K. Farahat, Mohamed S. Kamel", "title": "Discriminative Density-ratio Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The covariate shift is a challenging problem in supervised learning that\nresults from the discrepancy between the training and test distributions. An\neffective approach which recently drew a considerable attention in the research\ncommunity is to reweight the training samples to minimize that discrepancy. In\nspecific, many methods are based on developing Density-ratio (DR) estimation\ntechniques that apply to both regression and classification problems. Although\nthese methods work well for regression problems, their performance on\nclassification problems is not satisfactory. This is due to a key observation\nthat these methods focus on matching the sample marginal distributions without\npaying attention to preserving the separation between classes in the reweighted\nspace. In this paper, we propose a novel method for Discriminative\nDensity-ratio (DDR) estimation that addresses the aforementioned problem and\naims at estimating the density-ratio of joint distributions in a class-wise\nmanner. The proposed algorithm is an iterative procedure that alternates\nbetween estimating the class information for the test data and estimating new\ndensity ratio for each class. To incorporate the estimated class information of\nthe test data, a soft matching technique is proposed. In addition, we employ an\neffective criterion which adopts mutual information as an indicator to stop the\niterative procedure while resulting in a decision boundary that lies in a\nsparse region. Experiments on synthetic and benchmark datasets demonstrate the\nsuperiority of the proposed method in terms of both accuracy and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 18:41:20 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 03:20:56 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Miao", "Yun-Qian", ""], ["Farahat", "Ahmed K.", ""], ["Kamel", "Mohamed S.", ""]]}, {"id": "1311.4639", "submitter": "Katsumi Inoue", "authors": "Katsumi Inoue and Chiaki Sakama (Editors)", "title": "Post-Proceedings of the First International Workshop on Learning and\n  Nonmonotonic Reasoning", "comments": "67 pages, 5 papers, 1 abstract, 1 cover", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Representation and Reasoning and Machine Learning are two important\nfields in AI. Nonmonotonic logic programming (NMLP) and Answer Set Programming\n(ASP) provide formal languages for representing and reasoning with commonsense\nknowledge and realize declarative problem solving in AI. On the other side,\nInductive Logic Programming (ILP) realizes Machine Learning in logic\nprogramming, which provides a formal background to inductive learning and the\ntechniques have been applied to the fields of relational learning and data\nmining. Generally speaking, NMLP and ASP realize nonmonotonic reasoning while\nlack the ability of learning. By contrast, ILP realizes inductive learning\nwhile most techniques have been developed under the classical monotonic logic.\nWith this background, some researchers attempt to combine techniques in the\ncontext of nonmonotonic ILP. Such combination will introduce a learning\nmechanism to programs and would exploit new applications on the NMLP side,\nwhile on the ILP side it will extend the representation language and enable us\nto use existing solvers. Cross-fertilization between learning and nonmonotonic\nreasoning can also occur in such as the use of answer set solvers for ILP,\nspeed-up learning while running answer set solvers, learning action theories,\nlearning transition rules in dynamical systems, abductive learning, learning\nbiological networks with inhibition, and applications involving default and\nnegation. This workshop is the first attempt to provide an open forum for the\nidentification of problems and discussion of possible collaborations among\nresearchers with complementary expertise. The workshop was held on September\n15th of 2013 in Corunna, Spain. This post-proceedings contains five technical\npapers (out of six accepted papers) and the abstract of the invited talk by Luc\nDe Raedt.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 07:39:58 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Inoue", "Katsumi", "", "Editors"], ["Sakama", "Chiaki", "", "Editors"]]}, {"id": "1311.4643", "submitter": "Zohar Karnin", "authors": "Dimitris Achlioptas, Zohar Karnin, Edo Liberty", "title": "Near-Optimal Entrywise Sampling for Data Matrices", "comments": "14 pages, to appear in NIPS' 13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of selecting non-zero entries of a matrix $A$ in\norder to produce a sparse sketch of it, $B$, that minimizes $\\|A-B\\|_2$. For\nlarge $m \\times n$ matrices, such that $n \\gg m$ (for example, representing $n$\nobservations over $m$ attributes) we give sampling distributions that exhibit\nfour important properties. First, they have closed forms computable from\nminimal information regarding $A$. Second, they allow sketching of matrices\nwhose non-zeros are presented to the algorithm in arbitrary order as a stream,\nwith $O(1)$ computation per non-zero. Third, the resulting sketch matrices are\nnot only sparse, but their non-zero entries are highly compressible. Lastly,\nand most importantly, under mild assumptions, our distributions are provably\ncompetitive with the optimal offline distribution. Note that the probabilities\nin the optimal offline distribution may be complex functions of all the entries\nin the matrix. Therefore, regardless of computational complexity, the optimal\ndistribution might be impossible to compute in the streaming model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 08:00:50 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Achlioptas", "Dimitris", ""], ["Karnin", "Zohar", ""], ["Liberty", "Edo", ""]]}, {"id": "1311.4780", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Chong Wang, Eric Xing", "title": "Asymptotically Exact, Embarrassingly Parallel MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication costs, resulting from synchronization requirements during\nlearning, can greatly slow down many parallel machine learning algorithms. In\nthis paper, we present a parallel Markov chain Monte Carlo (MCMC) algorithm in\nwhich subsets of data are processed independently, with very little\ncommunication. First, we arbitrarily partition data onto multiple machines.\nThen, on each machine, any classical MCMC method (e.g., Gibbs sampling) may be\nused to draw samples from a posterior distribution given the data subset.\nFinally, the samples from each machine are combined to form samples from the\nfull posterior. This embarrassingly parallel algorithm allows each machine to\nact independently on a subset of the data (without communication) until the\nfinal combination stage. We prove that our algorithm generates asymptotically\nexact samples and empirically demonstrate its ability to parallelize burn-in\nand sampling in several models.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 15:23:04 GMT"}, {"version": "v2", "created": "Fri, 21 Mar 2014 04:25:50 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["Neiswanger", "Willie", ""], ["Wang", "Chong", ""], ["Xing", "Eric", ""]]}, {"id": "1311.4803", "submitter": "Lijun Zhang", "authors": "Lijun Zhang and Mehrdad Mahdavi and Rong Jin", "title": "Beating the Minimax Rate of Active Learning with Prior Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning refers to the learning protocol where the learner is allowed\nto choose a subset of instances for labeling. Previous studies have shown that,\ncompared with passive learning, active learning is able to reduce the label\ncomplexity exponentially if the data are linearly separable or satisfy the\nTsybakov noise condition with parameter $\\kappa=1$. In this paper, we propose a\nnovel active learning algorithm using a convex surrogate loss, with the goal to\nbroaden the cases for which active learning achieves an exponential\nimprovement. We make use of a convex loss not only because it reduces the\ncomputational cost, but more importantly because it leads to a tight bound for\nthe empirical process (i.e., the difference between the empirical estimation\nand the expectation) when the current solution is close to the optimal one.\nUnder the assumption that the norm of the optimal classifier that minimizes the\nconvex risk is available, our analysis shows that the introduction of the\nconvex surrogate loss yields an exponential reduction in the label complexity\neven when the parameter $\\kappa$ of the Tsybakov noise is larger than $1$. To\nthe best of our knowledge, this is the first work that improves the minimax\nrate of active learning by utilizing certain priori knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 16:56:55 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2014 20:07:49 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Zhang", "Lijun", ""], ["Mahdavi", "Mehrdad", ""], ["Jin", "Rong", ""]]}, {"id": "1311.4825", "submitter": "Emile Contal", "authors": "Emile Contal, Vianney Perchet, Nicolas Vayatis", "title": "Gaussian Process Optimization with Mutual Information", "comments": "Proceedings of The 31st International Conference on Machine Learning\n  (ICML 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze a generic algorithm scheme for sequential global\noptimization using Gaussian processes. The upper bounds we derive on the\ncumulative regret for this generic algorithm improve by an exponential factor\nthe previously known bounds for algorithms like GP-UCB. We also introduce the\nnovel Gaussian Process Mutual Information algorithm (GP-MI), which\nsignificantly improves further these upper bounds for the cumulative regret. We\nconfirm the efficiency of this algorithm on synthetic and real tasks against\nthe natural competitor, GP-UCB, and also the Expected Improvement heuristic.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 18:29:19 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 18:25:19 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2015 13:27:19 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Contal", "Emile", ""], ["Perchet", "Vianney", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1311.4833", "submitter": "Emilie Morvant", "authors": "Emilie Morvant (IST Austria)", "title": "Domain Adaptation of Majority Votes via Perturbed Variation-based Label\n  Transfer", "comments": null, "journal-ref": "Pattern Recognition Letters 2015", "doi": "10.1016/j.patrec.2014.08.013", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the PAC-Bayesian Domain Adaptation (DA) problem. This arrives when\none desires to learn, from a source distribution, a good weighted majority vote\n(over a set of classifiers) on a different target distribution. In this\ncontext, the disagreement between classifiers is known crucial to control. In\nnon-DA supervised setting, a theoretical bound - the C-bound - involves this\ndisagreement and leads to a majority vote learning algorithm: MinCq. In this\nwork, we extend MinCq to DA by taking advantage of an elegant divergence\nbetween distribution called the Perturbed Varation (PV). Firstly, justified by\na new formulation of the C-bound, we provide to MinCq a target sample labeled\nthanks to a PV-based self-labeling focused on regions where the source and\ntarget marginal distributions are closer. Secondly, we propose an original\nprocess for tuning the hyperparameters. Our framework shows very promising\nresults on a toy problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 18:46:59 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Morvant", "Emilie", "", "IST Austria"]]}, {"id": "1311.5022", "submitter": "Shaona Ghosh", "authors": "Shaona Ghosh, Adam Prugel-Bennett", "title": "Extended Formulations for Online Linear Bandit Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-line linear optimization on combinatorial action sets (d-dimensional\nactions) with bandit feedback, is known to have complexity in the order of the\ndimension of the problem. The exponential weighted strategy achieves the best\nknown regret bound that is of the order of $d^{2}\\sqrt{n}$ (where $d$ is the\ndimension of the problem, $n$ is the time horizon). However, such strategies\nare provably suboptimal or computationally inefficient. The complexity is\nattributed to the combinatorial structure of the action set and the dearth of\nefficient exploration strategies of the set. Mirror descent with entropic\nregularization function comes close to solving this problem by enforcing a\nmeticulous projection of weights with an inherent boundary condition. Entropic\nregularization in mirror descent is the only known way of achieving a\nlogarithmic dependence on the dimension. Here, we argue otherwise and recover\nthe original intuition of exponential weighting by borrowing a technique from\ndiscrete optimization and approximation algorithms called `extended\nformulation'. Such formulations appeal to the underlying geometry of the set\nwith a guaranteed logarithmic dependence on the dimension underpinned by an\ninformation theoretic entropic analysis.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 11:39:26 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 12:25:29 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2015 16:43:29 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Ghosh", "Shaona", ""], ["Prugel-Bennett", "Adam", ""]]}, {"id": "1311.5068", "submitter": "Alvaro Martinez", "authors": "A. Mart\\'inez-P\\'erez", "title": "Gromov-Hausdorff stability of linkage-based hierarchical clustering\n  methods", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hierarchical clustering method is stable if small perturbations on the data\nset produce small perturbations in the result. These perturbations are measured\nusing the Gromov-Hausdorff metric. We study the problem of stability on\nlinkage-based hierarchical clustering methods. We obtain that, under some basic\nconditions, standard linkage-based methods are semi-stable. This means that\nthey are stable if the input data is close enough to an ultrametric space. We\nprove that, apart from exotic examples, introducing any unchaining condition in\nthe algorithm always produces unstable methods.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 14:31:00 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Mart\u00ednez-P\u00e9rez", "A.", ""]]}, {"id": "1311.5422", "submitter": "Nikhil Rao", "authors": "Nikhil Rao, Christopher Cox, Robert Nowak, Timothy Rogers", "title": "Sparse Overlapping Sets Lasso for Multitask Learning and its Application\n  to fMRI Analysis", "comments": "To appear in Advances in Neural Information Processing Systems, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning can be effective when features useful in one task are also\nuseful for other tasks, and the group lasso is a standard method for selecting\na common subset of features. In this paper, we are interested in a less\nrestrictive form of multitask learning, wherein (1) the available features can\nbe organized into subsets according to a notion of similarity and (2) features\nuseful in one task are similar, but not necessarily identical, to the features\nbest suited for other tasks. The main contribution of this paper is a new\nprocedure called Sparse Overlapping Sets (SOS) lasso, a convex optimization\nthat automatically selects similar features for related learning tasks. Error\nbounds are derived for SOSlasso and its consistency is established for squared\nerror loss. In particular, SOSlasso is motivated by multi- subject fMRI studies\nin which functional activity is classified using brain voxels as features.\nExperiments with real and synthetic data demonstrate the advantages of SOSlasso\ncompared to the lasso and group lasso.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 16:45:51 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2013 04:49:54 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Rao", "Nikhil", ""], ["Cox", "Christopher", ""], ["Nowak", "Robert", ""], ["Rogers", "Timothy", ""]]}, {"id": "1311.5552", "submitter": "Steven Smith", "authors": "Steven T. Smith, Edward K. Kao, Kenneth D. Senne, Garrett Bernstein,\n  and Scott Philips", "title": "Bayesian Discovery of Threat Networks", "comments": "IEEE Trans. Signal Process., major revision of\n  arxiv.org/abs/1303.5613. arXiv admin note: substantial text overlap with\n  arXiv:1303.5613", "journal-ref": "IEEE Trans. Signal Process., vol. 62, no. 20, pp. 5324-5338,\n  October 2014", "doi": "10.1109/TSP.2014.2336613", "report-no": null, "categories": "cs.SI cs.LG math.ST physics.soc-ph stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel unified Bayesian framework for network detection is developed, under\nwhich a detection algorithm is derived based on random walks on graphs. The\nalgorithm detects threat networks using partial observations of their activity,\nand is proved to be optimum in the Neyman-Pearson sense. The algorithm is\ndefined by a graph, at least one observation, and a diffusion model for threat.\nA link to well-known spectral detection methods is provided, and the\nequivalence of the random walk and harmonic solutions to the Bayesian\nformulation is proven. A general diffusion model is introduced that utilizes\nspatio-temporal relationships between vertices, and is used for a specific\nspace-time formulation that leads to significant performance improvements on\ncoordinated covert networks. This performance is demonstrated using a new\nhybrid mixed-membership blockmodel introduced to simulate random covert\nnetworks with realistic properties.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 20:43:44 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2014 20:07:08 GMT"}, {"version": "v3", "created": "Mon, 8 Sep 2014 17:14:10 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Smith", "Steven T.", ""], ["Kao", "Edward K.", ""], ["Senne", "Kenneth D.", ""], ["Bernstein", "Garrett", ""], ["Philips", "Scott", ""]]}, {"id": "1311.5599", "submitter": "Swayambhoo Jain", "authors": "Swayambhoo Jain, Akshay Soni, and Jarvis Haupt", "title": "Compressive Measurement Designs for Estimating Structured Signals in\n  Structured Clutter: A Bayesian Experimental Design Approach", "comments": "5 pages, 4 figures. Accepted for publication at The Asilomar\n  Conference on Signals, Systems, and Computers 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers an estimation task in compressive sensing, where the goal\nis to estimate an unknown signal from compressive measurements that are\ncorrupted by additive pre-measurement noise (interference, or clutter) as well\nas post-measurement noise, in the specific setting where some (perhaps limited)\nprior knowledge on the signal, interference, and noise is available. The\nspecific aim here is to devise a strategy for incorporating this prior\ninformation into the design of an appropriate compressive measurement strategy.\nHere, the prior information is interpreted as statistics of a prior\ndistribution on the relevant quantities, and an approach based on Bayesian\nExperimental Design is proposed. Experimental results on synthetic data\ndemonstrate that the proposed approach outperforms traditional random\ncompressive measurement designs, which are agnostic to the prior information,\nas well as several other knowledge-enhanced sensing matrix designs based on\nmore heuristic notions.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 22:16:00 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Jain", "Swayambhoo", ""], ["Soni", "Akshay", ""], ["Haupt", "Jarvis", ""]]}, {"id": "1311.5636", "submitter": "Dimitrios Athanasakis Mr", "authors": "Dimitrios Athanasakis, John Shawe-Taylor, Delmiro Fernandez-Reyes", "title": "Learning Non-Linear Feature Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection plays a pivotal role in learning, particularly in areas\nwere parsimonious features can provide insight into the underlying process,\nsuch as biology. Recent approaches for non-linear feature selection employing\ngreedy optimisation of Centred Kernel Target Alignment(KTA), while exhibiting\nstrong results in terms of generalisation accuracy and sparsity, can become\ncomputationally prohibitive for high-dimensional datasets. We propose randSel,\na randomised feature selection algorithm, with attractive scaling properties.\nOur theoretical analysis of randSel provides strong probabilistic guarantees\nfor the correct identification of relevant features. Experimental results on\nreal and artificial data, show that the method successfully identifies\neffective features, performing better than a number of competitive approaches.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 01:49:26 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Athanasakis", "Dimitrios", ""], ["Shawe-Taylor", "John", ""], ["Fernandez-Reyes", "Delmiro", ""]]}, {"id": "1311.5750", "submitter": "Xiaotong Yuan", "authors": "Xiao-Tong Yuan, Ping Li, Tong Zhang", "title": "Gradient Hard Thresholding Pursuit for Sparsity-Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard Thresholding Pursuit (HTP) is an iterative greedy selection procedure\nfor finding sparse solutions of underdetermined linear systems. This method has\nbeen shown to have strong theoretical guarantee and impressive numerical\nperformance. In this paper, we generalize HTP from compressive sensing to a\ngeneric problem setup of sparsity-constrained convex optimization. The proposed\nalgorithm iterates between a standard gradient descent step and a hard\nthresholding step with or without debiasing. We prove that our method enjoys\nthe strong guarantees analogous to HTP in terms of rate of convergence and\nparameter estimation accuracy. Numerical evidences show that our method is\nsuperior to the state-of-the-art greedy selection methods in sparse logistic\nregression and sparse precision matrix estimation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 13:52:07 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 04:19:39 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Yuan", "Xiao-Tong", ""], ["Li", "Ping", ""], ["Zhang", "Tong", ""]]}, {"id": "1311.5871", "submitter": "Fabien Lauer", "authors": "Fabien Lauer (LORIA), Henrik Ohlsson", "title": "Finding sparse solutions of systems of polynomial equations via\n  group-sparsity optimization", "comments": "Journal of Global Optimization (2014) to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with the problem of finding sparse solutions to systems of\npolynomial equations possibly perturbed by noise. In particular, we show how\nthese solutions can be recovered from group-sparse solutions of a derived\nsystem of linear equations. Then, two approaches are considered to find these\ngroup-sparse solutions. The first one is based on a convex relaxation resulting\nin a second-order cone programming formulation which can benefit from efficient\nreweighting techniques for sparsity enhancement. For this approach, sufficient\nconditions for the exact recovery of the sparsest solution to the polynomial\nsystem are derived in the noiseless setting, while stable recovery results are\nobtained for the noisy case. Though lacking a similar analysis, the second\napproach provides a more computationally efficient algorithm based on a greedy\nstrategy adding the groups one-by-one. With respect to previous work, the\nproposed methods recover the sparsest solution in a very short computing time\nwhile remaining at least as accurate in terms of the probability of success.\nThis probability is empirically analyzed to emphasize the relationship between\nthe ability of the methods to solve the polynomial system and the sparsity of\nthe solution.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 20:29:38 GMT"}, {"version": "v2", "created": "Wed, 16 Jul 2014 15:47:44 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Lauer", "Fabien", "", "LORIA"], ["Ohlsson", "Henrik", ""]]}, {"id": "1311.5947", "submitter": "Chunhua Shen", "authors": "Guosheng Lin, Chunhua Shen, Anton van den Hengel, David Suter", "title": "Fast Training of Effective Multi-class Boosting Using Coordinate Descent\n  Optimization", "comments": "Appeared in Proc. Asian Conf. Computer Vision 2012. Code can be\n  downloaded at http://goo.gl/WluhrQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wepresentanovelcolumngenerationbasedboostingmethod for multi-class\nclassification. Our multi-class boosting is formulated in a single optimization\nproblem as in Shen and Hao (2011). Different from most existing multi-class\nboosting methods, which use the same set of weak learners for all the classes,\nwe train class specified weak learners (i.e., each class has a different set of\nweak learners). We show that using separate weak learner sets for each class\nleads to fast convergence, without introducing additional computational\noverhead in the training procedure. To further make the training more efficient\nand scalable, we also propose a fast co- ordinate descent method for solving\nthe optimization problem at each boosting iteration. The proposed coordinate\ndescent method is conceptually simple and easy to implement in that it is a\nclosed-form solution for each coordinate update. Experimental results on a\nvariety of datasets show that, compared to a range of existing multi-class\nboosting meth- ods, the proposed method has much faster convergence rate and\nbetter generalization performance in most cases. We also empirically show that\nthe proposed fast coordinate descent algorithm needs less training time than\nthe MultiBoost algorithm in Shen and Hao (2011).\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2013 02:30:14 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Lin", "Guosheng", ""], ["Shen", "Chunhua", ""], ["Hengel", "Anton van den", ""], ["Suter", "David", ""]]}, {"id": "1311.6041", "submitter": "Loris Serafino", "authors": "Loris Serafino", "title": "No Free Lunch Theorem and Bayesian probability theory: two sides of the\n  same coin. Some implications for black-box optimization and metaheuristics", "comments": "Multiple changes throughout the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging optimization problems, which elude acceptable solution via\nconventional calculus methods, arise commonly in different areas of industrial\ndesign and practice. Hard optimization problems are those who manifest the\nfollowing behavior: a) high number of independent input variables; b) very\ncomplex or irregular multi-modal fitness; c) computational expensive fitness\nevaluation. This paper will focus on some theoretical issues that have strong\nimplications for practice. I will stress how an interpretation of the No Free\nLunch theorem leads naturally to a general Bayesian optimization framework. The\nchoice of a prior over the space of functions is a critical and inevitable step\nin every black-box optimization.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2013 19:19:37 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2013 04:18:38 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2013 06:02:58 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Serafino", "Loris", ""]]}, {"id": "1311.6091", "submitter": "Jianshu Chen", "authors": "Jianshu Chen and Li Deng", "title": "A Primal-Dual Method for Training Recurrent Neural Networks Constrained\n  by the Echo-State Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an architecture of a recurrent neural network (RNN) with a\nfully-connected deep neural network (DNN) as its feature extractor. The RNN is\nequipped with both causal temporal prediction and non-causal look-ahead, via\nauto-regression (AR) and moving-average (MA), respectively. The focus of this\npaper is a primal-dual training method that formulates the learning of the RNN\nas a formal optimization problem with an inequality constraint that provides a\nsufficient condition for the stability of the network dynamics. Experimental\nresults demonstrate the effectiveness of this new method, which achieves 18.86%\nphone recognition error on the TIMIT benchmark for the core test set. The\nresult approaches the best result of 17.7%, which was obtained by using RNN\nwith long short-term memory (LSTM). The results also show that the proposed\nprimal-dual training method produces lower recognition errors than the popular\nRNN methods developed earlier based on the carefully tuned threshold parameter\nthat heuristically prevents the gradient from exploding.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2013 08:04:41 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2013 09:12:55 GMT"}, {"version": "v3", "created": "Thu, 6 Mar 2014 03:06:36 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Chen", "Jianshu", ""], ["Deng", "Li", ""]]}, {"id": "1311.6107", "submitter": "Biao Luo", "authors": "Biao Luo, Huai-Ning Wu, Tingwen Huang", "title": "Off-policy reinforcement learning for $ H_\\infty $ control design", "comments": "Accepted by IEEE Transactions on Cybernetics. IEEE Transactions on\n  Cybernetics, Online Available, 2014", "journal-ref": null, "doi": "10.1109/TCYB.2014.2319577", "report-no": null, "categories": "cs.SY cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $H_\\infty$ control design problem is considered for nonlinear systems\nwith unknown internal system model. It is known that the nonlinear $ H_\\infty $\ncontrol problem can be transformed into solving the so-called\nHamilton-Jacobi-Isaacs (HJI) equation, which is a nonlinear partial\ndifferential equation that is generally impossible to be solved analytically.\nEven worse, model-based approaches cannot be used for approximately solving HJI\nequation, when the accurate system model is unavailable or costly to obtain in\npractice. To overcome these difficulties, an off-policy reinforcement leaning\n(RL) method is introduced to learn the solution of HJI equation from real\nsystem data instead of mathematical system model, and its convergence is\nproved. In the off-policy RL method, the system data can be generated with\narbitrary policies rather than the evaluating policy, which is extremely\nimportant and promising for practical systems. For implementation purpose, a\nneural network (NN) based actor-critic structure is employed and a least-square\nNN weight update algorithm is derived based on the method of weighted\nresiduals. Finally, the developed NN-based off-policy RL method is tested on a\nlinear F16 aircraft plant, and further applied to a rotational/translational\nactuator system.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2013 11:26:07 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2014 16:06:31 GMT"}, {"version": "v3", "created": "Sun, 11 May 2014 07:33:16 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Luo", "Biao", ""], ["Wu", "Huai-Ning", ""], ["Huang", "Tingwen", ""]]}, {"id": "1311.6184", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio, Li Yao and Kyunghyun Cho", "title": "Bounding the Test Log-Likelihood of Generative Models", "comments": "10 pages, 1 figure, 2 tables. International Conference on Learning\n  Representations (ICLR'2014, conference track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several interesting generative learning algorithms involve a complex\nprobability distribution over many random variables, involving intractable\nnormalization constants or latent variable normalization. Some of them may even\nnot have an analytic expression for the unnormalized probability function and\nno tractable approximation. This makes it difficult to estimate the quality of\nthese models, once they have been trained, or to monitor their quality (e.g.\nfor early stopping) while training. A previously proposed method is based on\nconstructing a non-parametric density estimator of the model's probability\nfunction from samples generated by the model. We revisit this idea, propose a\nmore efficient estimator, and prove that it provides a lower bound on the true\ntest log-likelihood, and an unbiased estimator as the number of generated\nsamples goes to infinity, although one that incorporates the effect of poor\nmixing. We further propose a biased variant of the estimator that can be used\nreliably with a finite number of samples for the purpose of model comparison.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2013 23:28:49 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2013 05:47:59 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2013 01:27:50 GMT"}, {"version": "v4", "created": "Fri, 9 May 2014 23:01:46 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Bengio", "Yoshua", ""], ["Yao", "Li", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1311.6211", "submitter": "Qi Lou", "authors": "Qi Lou, Raviv Raich, Forrest Briggs, Xiaoli Z. Fern", "title": "Novelty Detection Under Multi-Instance Multi-Label Framework", "comments": null, "journal-ref": null, "doi": "10.1109/MLSP.2013.6661985", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novelty detection plays an important role in machine learning and signal\nprocessing. This paper studies novelty detection in a new setting where the\ndata object is represented as a bag of instances and associated with multiple\nclass labels, referred to as multi-instance multi-label (MIML) learning.\nContrary to the common assumption in MIML that each instance in a bag belongs\nto one of the known classes, in novelty detection, we focus on the scenario\nwhere bags may contain novel-class instances. The goal is to determine, for any\ngiven instance in a new bag, whether it belongs to a known class or a novel\nclass. Detecting novelty in the MIML setting captures many real-world phenomena\nand has many potential applications. For example, in a collection of tagged\nimages, the tag may only cover a subset of objects existing in the images.\nDiscovering an object whose class has not been previously tagged can be useful\nfor the purpose of soliciting a label for the new object class. To address this\nnovel problem, we present a discriminative framework for detecting new class\ninstances. Experiments demonstrate the effectiveness of our proposed method,\nand reveal that the presence of unlabeled novel instances in training bags is\nhelpful to the detection of such instances in testing stage.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 05:27:41 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Lou", "Qi", ""], ["Raich", "Raviv", ""], ["Briggs", "Forrest", ""], ["Fern", "Xiaoli Z.", ""]]}, {"id": "1311.6334", "submitter": "Charanpal Dhanjal", "authors": "Charanpal Dhanjal (LTCI), St\\'ephan Cl\\'emen\\c{c}on (LTCI)", "title": "Learning Reputation in an Authorship Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of searching for experts in a given academic field is hugely\nimportant in both industry and academia. We study exactly this issue with\nrespect to a database of authors and their publications. The idea is to use\nLatent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA) to perform\ntopic modelling in order to find authors who have worked in a query field. We\nthen construct a coauthorship graph and motivate the use of influence\nmaximisation and a variety of graph centrality measures to obtain a ranked list\nof experts. The ranked lists are further improved using a Markov Chain-based\nrank aggregation approach. The complete method is readily scalable to large\ndatasets. To demonstrate the efficacy of the approach we report on an extensive\nset of computational simulations using the Arnetminer dataset. An improvement\nin mean average precision is demonstrated over the baseline case of simply\nusing the order of authors found by the topic models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 15:25:28 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Dhanjal", "Charanpal", "", "LTCI"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"]]}, {"id": "1311.6355", "submitter": "Xinxi Wang", "authors": "Xinxi Wang, Yi Wang, David Hsu, Ye Wang", "title": "Exploration in Interactive Personalized Music Recommendation: A\n  Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current music recommender systems typically act in a greedy fashion by\nrecommending songs with the highest user ratings. Greedy recommendation,\nhowever, is suboptimal over the long term: it does not actively gather\ninformation on user preferences and fails to recommend novel songs that are\npotentially interesting. A successful recommender system must balance the needs\nto explore user preferences and to exploit this information for recommendation.\nThis paper presents a new approach to music recommendation by formulating this\nexploration-exploitation trade-off as a reinforcement learning task called the\nmulti-armed bandit. To learn user preferences, it uses a Bayesian model, which\naccounts for both audio content and the novelty of recommendations. A\npiecewise-linear approximation to the model and a variational inference\nalgorithm are employed to speed up Bayesian inference. One additional benefit\nof our approach is a single unified model for both music recommendation and\nplaylist generation. Both simulation results and a user study indicate strong\npotential for the new approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 12:20:35 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Wang", "Xinxi", ""], ["Wang", "Yi", ""], ["Hsu", "David", ""], ["Wang", "Ye", ""]]}, {"id": "1311.6371", "submitter": "Antoni Chan", "authors": "Lifeng Shang and Antoni B. Chan", "title": "On Approximate Inference for Generalized Gaussian Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalized Gaussian process model (GGPM) is a unifying framework that\nencompasses many existing Gaussian process (GP) models, such as GP regression,\nclassification, and counting. In the GGPM framework, the observation likelihood\nof the GP model is itself parameterized using the exponential family\ndistribution (EFD). In this paper, we consider efficient algorithms for\napproximate inference on GGPMs using the general form of the EFD. A particular\nGP model and its associated inference algorithms can then be formed by changing\nthe parameters of the EFD, thus greatly simplifying its creation for\ntask-specific output domains. We demonstrate the efficacy of this framework by\ncreating several new GP models for regressing to non-negative reals and to real\nintervals. We also consider a closed-form Taylor approximation for efficient\ninference on GGPMs, and elaborate on its connections with other model-specific\nheuristic closed-form approximations. Finally, we present a comprehensive set\nof experiments to compare approximate inference algorithms on a wide variety of\nGGPMs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 17:22:22 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 04:24:02 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2013 07:43:48 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Shang", "Lifeng", ""], ["Chan", "Antoni B.", ""]]}, {"id": "1311.6392", "submitter": "Nuri Denizcan Vanli", "authors": "N. Denizcan Vanli and Suleyman S. Kozat", "title": "A Comprehensive Approach to Universal Piecewise Nonlinear Regression\n  Based on Trees", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate adaptive nonlinear regression and introduce\ntree based piecewise linear regression algorithms that are highly efficient and\nprovide significantly improved performance with guaranteed upper bounds in an\nindividual sequence manner. We use a tree notion in order to partition the\nspace of regressors in a nested structure. The introduced algorithms adapt not\nonly their regression functions but also the complete tree structure while\nachieving the performance of the \"best\" linear mixture of a doubly exponential\nnumber of partitions, with a computational complexity only polynomial in the\nnumber of nodes of the tree. While constructing these algorithms, we also avoid\nusing any artificial \"weighting\" of models (with highly data dependent\nparameters) and, instead, directly minimize the final regression error, which\nis the ultimate performance goal. The introduced methods are generic such that\nthey can readily incorporate different tree construction methods such as random\ntrees in their framework and can use different regressor or partitioning\nfunctions as demonstrated in the paper.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 18:31:40 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2013 13:21:40 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Vanli", "N. Denizcan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1311.6396", "submitter": "Nuri Denizcan Vanli", "authors": "N. Denizcan Vanli and Suleyman S. Kozat", "title": "A Unified Approach to Universal Prediction: Generalized Upper and Lower\n  Bounds", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sequential prediction of real-valued, arbitrary and unknown\nsequences under the squared error loss as well as the best parametric predictor\nout of a large, continuous class of predictors. Inspired by recent results from\ncomputational learning theory, we refrain from any statistical assumptions and\ndefine the performance with respect to the class of general parametric\npredictors. In particular, we present generic lower and upper bounds on this\nrelative performance by transforming the prediction task into a parameter\nlearning problem. We first introduce the lower bounds on this relative\nperformance in the mixture of experts framework, where we show that for any\nsequential algorithm, there always exists a sequence for which the performance\nof the sequential algorithm is lower bounded by zero. We then introduce a\nsequential learning algorithm to predict such arbitrary and unknown sequences,\nand calculate upper bounds on its total squared prediction error for every\nbounded sequence. We further show that in some scenarios we achieve matching\nlower and upper bounds demonstrating that our algorithms are optimal in a\nstrong minimax sense such that their performances cannot be improved further.\nAs an interesting result we also prove that for the worst case scenario, the\nperformance of randomized algorithms can be achieved by sequential algorithms\nso that randomized algorithms does not improve the performance.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 18:36:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 21:00:52 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Vanli", "N. Denizcan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1311.6425", "submitter": "Marcelo Fiori", "authors": "Marcelo Fiori, Pablo Sprechmann, Joshua Vogelstein, Pablo Mus\\'e,\n  Guillermo Sapiro", "title": "Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching", "comments": "NIPS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching is a challenging problem with very important applications in a\nwide range of fields, from image and video analysis to biological and\nbiomedical problems. We propose a robust graph matching algorithm inspired in\nsparsity-related techniques. We cast the problem, resembling group or\ncollaborative sparsity formulations, as a non-smooth convex optimization\nproblem that can be efficiently solved using augmented Lagrangian techniques.\nThe method can deal with weighted or unweighted graphs, as well as multimodal\ndata, where different graphs represent different types of data. The proposed\napproach is also naturally integrated with collaborative graph inference\ntechniques, solving general network inference problems where the observed\nvariables, possibly coming from different modalities, are not in\ncorrespondence. The algorithm is tested and compared with state-of-the-art\ngraph matching techniques in both synthetic and real graphs. We also present\nresults on multimodal graphs and applications to collaborative inference of\nbrain connectivity from alignment-free functional magnetic resonance imaging\n(fMRI) data. The code is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 19:57:49 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Fiori", "Marcelo", ""], ["Sprechmann", "Pablo", ""], ["Vogelstein", "Joshua", ""], ["Mus\u00e9", "Pablo", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1311.6510", "submitter": "Agata Lapedriza", "authors": "Agata Lapedriza and Hamed Pirsiavash and Zoya Bylinskii and Antonio\n  Torralba", "title": "Are all training examples equally valuable?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning a new concept, not all training examples may prove equally\nuseful for training: some may have higher or lower training value than others.\nThe goal of this paper is to bring to the attention of the vision community the\nfollowing considerations: (1) some examples are better than others for training\ndetectors or classifiers, and (2) in the presence of better examples, some\nexamples may negatively impact performance and removing them may be beneficial.\nIn this paper, we propose an approach for measuring the training value of an\nexample, and use it for ranking and greedily sorting examples. We test our\nmethods on different vision tasks, models, datasets and classifiers. Our\nexperiments show that the performance of current state-of-the-art detectors and\nclassifiers can be improved when training on a subset, rather than the whole\ntraining set.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 22:59:24 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Lapedriza", "Agata", ""], ["Pirsiavash", "Hamed", ""], ["Bylinskii", "Zoya", ""], ["Torralba", "Antonio", ""]]}, {"id": "1311.6536", "submitter": "Wouter Koolen", "authors": "Wouter M. Koolen and Steven de Rooij", "title": "Universal Codes from Switching Strategies", "comments": null, "journal-ref": "IEEE Transactions on Information Theory, 59(11):7168-7185,\n  November 2013", "doi": "10.1109/TIT.2013.2273353", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss algorithms for combining sequential prediction strategies, a task\nwhich can be viewed as a natural generalisation of the concept of universal\ncoding. We describe a graphical language based on Hidden Markov Models for\ndefining prediction strategies, and we provide both existing and new models as\nexamples. The models include efficient, parameterless models for switching\nbetween the input strategies over time, including a model for the case where\nswitches tend to occur in clusters, and finally a new model for the scenario\nwhere the prediction strategies have a known relationship, and where jumps are\ntypically between strongly related ones. This last model is relevant for coding\ntime series data where parameter drift is expected. As theoretical ontributions\nwe introduce an interpolation construction that is useful in the development\nand analysis of new algorithms, and we establish a new sophisticated lemma for\nanalysing the individual sequence regret of parameterised models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 01:23:45 GMT"}], "update_date": "2013-11-27", "authors_parsed": [["Koolen", "Wouter M.", ""], ["de Rooij", "Steven", ""]]}, {"id": "1311.6547", "submitter": "Xiaocheng  Tang", "authors": "Katya Scheinberg and Xiaocheng Tang", "title": "Practical Inexact Proximal Quasi-Newton Method with Global Complexity\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently several methods were proposed for sparse optimization which make\ncareful use of second-order information [10, 28, 16, 3] to improve local\nconvergence rates. These methods construct a composite quadratic approximation\nusing Hessian information, optimize this approximation using a first-order\nmethod, such as coordinate descent and employ a line search to ensure\nsufficient descent. Here we propose a general framework, which includes\nslightly modified versions of existing algorithms and also a new algorithm,\nwhich uses limited memory BFGS Hessian approximations, and provide a novel\nglobal convergence rate analysis, which covers methods that solve subproblems\nvia coordinate descent.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 03:36:21 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2013 23:51:19 GMT"}, {"version": "v3", "created": "Mon, 17 Mar 2014 21:49:04 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2015 16:07:49 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Scheinberg", "Katya", ""], ["Tang", "Xiaocheng", ""]]}, {"id": "1311.6556", "submitter": "Naresh Manwani", "authors": "Naresh Manwani, Kalpit Desai, Sanand Sasidharan, Ramasubramanian\n  Sundararajan", "title": "Double Ramp Loss Based Reject Option Classifier", "comments": null, "journal-ref": "DBLP:conf/pakdd/2017-1", "doi": "10.1007/978-3-319-57454-7_53", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider the problem of learning reject option classifiers. The goodness\nof a reject option classifier is quantified using $0-d-1$ loss function wherein\na loss $d \\in (0,.5)$ is assigned for rejection. In this paper, we propose {\\em\ndouble ramp loss} function which gives a continuous upper bound for $(0-d-1)$\nloss. Our approach is based on minimizing regularized risk under the double\nramp loss using {\\em difference of convex (DC) programming}. We show the\neffectiveness of our approach through experiments on synthetic and benchmark\ndatasets. Our approach performs better than the state of the art reject option\nclassification approaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 05:13:18 GMT"}, {"version": "v2", "created": "Mon, 8 Dec 2014 07:34:34 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Manwani", "Naresh", ""], ["Desai", "Kalpit", ""], ["Sasidharan", "Sanand", ""], ["Sundararajan", "Ramasubramanian", ""]]}, {"id": "1311.6594", "submitter": "\\'Angela Fern\\'andez Pascual", "authors": "\\'Angela Fern\\'andez, Neta Rabin, Dalia Fishelov, Jos\\'e R. Dorronsoro", "title": "Auto-adaptative Laplacian Pyramids for High-dimensional Data Analysis", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear dimensionality reduction techniques such as manifold learning\nalgorithms have become a common way for processing and analyzing\nhigh-dimensional patterns that often have attached a target that corresponds to\nthe value of an unknown function. Their application to new points consists in\ntwo steps: first, embedding the new data point into the low dimensional space\nand then, estimating the function value on the test point from its neighbors in\nthe embedded space.\n  However, finding the low dimension representation of a test point, while easy\nfor simple but often not powerful enough procedures such as PCA, can be much\nmore complicated for methods that rely on some kind of eigenanalysis, such as\nSpectral Clustering (SC) or Diffusion Maps (DM). Similarly, when a target\nfunction is to be evaluated, averaging methods like nearest neighbors may give\nunstable results if the function is noisy. Thus, the smoothing of the target\nfunction with respect to the intrinsic, low-dimensional representation that\ndescribes the geometric structure of the examined data is a challenging task.\n  In this paper we propose Auto-adaptive Laplacian Pyramids (ALP), an extension\nof the standard Laplacian Pyramids model that incorporates a modified LOOCV\nprocedure that avoids the large cost of the standard one and offers the\nfollowing advantages: (i) it selects automatically the optimal function\nresolution (stopping time) adapted to the data and its noise, (ii) it is easy\nto apply as it does not require parameterization, (iii) it does not overfit the\ntraining set and (iv) it adds no extra cost compared to other classical\ninterpolation methods. We illustrate numerically ALP's behavior on a synthetic\nproblem and apply it to the computation of the DM projection of new patterns\nand to the extension to them of target function values on a radiation\nforecasting problem over very high dimensional patterns.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 09:03:10 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 10:17:31 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Fern\u00e1ndez", "\u00c1ngela", ""], ["Rabin", "Neta", ""], ["Fishelov", "Dalia", ""], ["Dorronsoro", "Jos\u00e9 R.", ""]]}, {"id": "1311.6802", "submitter": "Smriti Bhagat", "authors": "Smriti Bhagat, Udi Weinsberg, Stratis Ioannidis, Nina Taft", "title": "Recommending with an Agenda: Active Learning of Private Attributes using\n  Matrix Factorization", "comments": "This is the extended version of a paper that appeared in ACM RecSys\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems leverage user demographic information, such as age,\ngender, etc., to personalize recommendations and better place their targeted\nads. Oftentimes, users do not volunteer this information due to privacy\nconcerns, or due to a lack of initiative in filling out their online profiles.\nWe illustrate a new threat in which a recommender learns private attributes of\nusers who do not voluntarily disclose them. We design both passive and active\nattacks that solicit ratings for strategically selected items, and could thus\nbe used by a recommender system to pursue this hidden agenda. Our methods are\nbased on a novel usage of Bayesian matrix factorization in an active learning\nsetting. Evaluations on multiple datasets illustrate that such attacks are\nindeed feasible and use significantly fewer rated items than static inference\nmethods. Importantly, they succeed without sacrificing the quality of\nrecommendations to users.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 20:48:59 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 23:08:54 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Bhagat", "Smriti", ""], ["Weinsberg", "Udi", ""], ["Ioannidis", "Stratis", ""], ["Taft", "Nina", ""]]}, {"id": "1311.6809", "submitter": "Muhammed Sayin O", "authors": "Muhammed O. Sayin, N. Denizcan Vanli, Suleyman S. Kozat", "title": "A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic\n  Cost", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2014.2333559", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel family of adaptive filtering algorithms based on a\nrelative logarithmic cost. The new family intrinsically combines the higher and\nlower order measures of the error into a single continuous update based on the\nerror amount. We introduce important members of this family of algorithms such\nas the least mean logarithmic square (LMLS) and least logarithmic absolute\ndifference (LLAD) algorithms that improve the convergence performance of the\nconventional algorithms. However, our approach and analysis are generic such\nthat they cover other well-known cost functions as described in the paper. The\nLMLS algorithm achieves comparable convergence performance with the least mean\nfourth (LMF) algorithm and extends the stability bound on the step size. The\nLLAD and least mean square (LMS) algorithms demonstrate similar convergence\nperformance in impulse-free noise environments while the LLAD algorithm is\nrobust against impulsive interferences and outperforms the sign algorithm (SA).\nWe analyze the transient, steady state and tracking performance of the\nintroduced algorithms and demonstrate the match of the theoretical analyzes and\nsimulation results. We show the extended stability bound of the LMLS algorithm\nand analyze the robustness of the LLAD algorithm against impulsive\ninterferences. Finally, we demonstrate the performance of our algorithms in\ndifferent scenarios through numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 10:02:20 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Sayin", "Muhammed O.", ""], ["Vanli", "N. Denizcan", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "1311.6834", "submitter": "Jim Jing-Yan Wang", "authors": "Jim Jing-Yan Wang and Xin Gao", "title": "Semi-Supervised Sparse Coding", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2014.6889449", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding approximates the data sample as a sparse linear combination of\nsome basic codewords and uses the sparse codes as new presentations. In this\npaper, we investigate learning discriminative sparse codes by sparse coding in\na semi-supervised manner, where only a few training samples are labeled. By\nusing the manifold structure spanned by the data set of both labeled and\nunlabeled samples and the constraints provided by the labels of the labeled\nsamples, we learn the variable class labels for all the samples. Furthermore,\nto improve the discriminative ability of the learned sparse codes, we assume\nthat the class labels could be predicted from the sparse codes directly using a\nlinear classifier. By solving the codebook, sparse codes, class labels and\nclassifier parameters simultaneously in a unified objective function, we\ndevelop a semi-supervised sparse coding algorithm. Experiments on two\nreal-world pattern recognition problems demonstrate the advantage of the\nproposed methods over supervised sparse coding methods on partially labeled\ndata sets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 22:13:37 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 18:37:00 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Wang", "Jim Jing-Yan", ""], ["Gao", "Xin", ""]]}, {"id": "1311.6838", "submitter": "Afshin Rostamizadeh", "authors": "Kareem Amin, Afshin Rostamizadeh, Umar Syed", "title": "Learning Prices for Repeated Auctions with Strategic Buyers", "comments": "Neural Information Processing Systems (NIPS 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by real-time ad exchanges for online display advertising, we\nconsider the problem of inferring a buyer's value distribution for a good when\nthe buyer is repeatedly interacting with a seller through a posted-price\nmechanism. We model the buyer as a strategic agent, whose goal is to maximize\nher long-term surplus, and we are interested in mechanisms that maximize the\nseller's long-term revenue. We define the natural notion of strategic regret\n--- the lost revenue as measured against a truthful (non-strategic) buyer. We\npresent seller algorithms that are no-(strategic)-regret when the buyer\ndiscounts her future surplus --- i.e. the buyer prefers showing advertisements\nto users sooner rather than later. We also give a lower bound on strategic\nregret that increases as the buyer's discounting weakens and shows, in\nparticular, that any seller algorithm will suffer linear strategic regret if\nthere is no discounting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2013 22:53:13 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Amin", "Kareem", ""], ["Rostamizadeh", "Afshin", ""], ["Syed", "Umar", ""]]}, {"id": "1311.6881", "submitter": "Abhishek Pandey", "authors": "Abhishek Pandey, Anjna Jayant Deen and Rajeev Pandey (Dept. of CSE,\n  UIT-RGPV)", "title": "Color and Shape Content Based Image Classification using RBF Network and\n  PSO Technique: A Survey", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The improvement of the accuracy of image query retrieval used image\nclassification technique. Image classification is well known technique of\nsupervised learning. The improved method of image classification increases the\nworking efficiency of image query retrieval. For the improvements of\nclassification technique we used RBF neural network function for better\nprediction of feature used in image retrieval.Colour content is represented by\npixel values in image classification using radial base function(RBF) technique.\nThis approach provides better result compare to SVM technique in image\nrepresentation.Image is represented by matrix though RBF using pixel values of\ncolour intensity of image. Firstly we using RGB colour model. In this colour\nmodel we use red, green and blue colour intensity values in matrix.SVM with\npartical swarm optimization for image classification is implemented in content\nof images which provide better Results based on the proposed approach are found\nencouraging in terms of color image classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 07:14:25 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Pandey", "Abhishek", "", "Dept. of CSE,\n  UIT-RGPV"], ["Deen", "Anjna Jayant", "", "Dept. of CSE,\n  UIT-RGPV"], ["Pandey", "Rajeev", "", "Dept. of CSE,\n  UIT-RGPV"]]}, {"id": "1311.6976", "submitter": "Bjarne {\\O}rum Fruergaard", "authors": "Bjarne {\\O}rum Fruergaard, Toke Jansen Hansen, Lars Kai Hansen", "title": "Dimensionality reduction for click-through rate prediction: Dense versus\n  sparse representation", "comments": "Presented at the Probabilistic Models for Big Data workshop at NIPS\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, display ads are increasingly being placed based on\nreal-time auctions where the advertiser who wins gets to serve the ad. This is\ncalled real-time bidding (RTB). In RTB, auctions have very tight time\nconstraints on the order of 100ms. Therefore mechanisms for bidding\nintelligently such as clickthrough rate prediction need to be sufficiently\nfast. In this work, we propose to use dimensionality reduction of the\nuser-website interaction graph in order to produce simplified features of users\nand websites that can be used as predictors of clickthrough rate. We\ndemonstrate that the Infinite Relational Model (IRM) as a dimensionality\nreduction offers comparable predictive performance to conventional\ndimensionality reduction schemes, while achieving the most economical usage of\nfeatures and fastest computations at run-time. For applications such as\nreal-time bidding, where fast database I/O and few computations are key to\nsuccess, we thus recommend using IRM based features as predictors to exploit\nthe recommender effects from bipartite graphs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 14:19:21 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 09:21:28 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Fruergaard", "Bjarne \u00d8rum", ""], ["Hansen", "Toke Jansen", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1311.7071", "submitter": "Zitao Liu", "authors": "Zitao Liu and Milos Hauskrecht", "title": "Sparse Linear Dynamical System with Its Application in Multivariate\n  Clinical Time Series", "comments": "Appear in Neural Information Processing Systems(NIPS) Workshop on\n  Machine Learning for Clinical Data Analysis and Healthcare 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Linear Dynamical System (LDS) is an elegant mathematical framework for\nmodeling and learning multivariate time series. However, in general, it is\ndifficult to set the dimension of its hidden state space. A small number of\nhidden states may not be able to model the complexities of a time series, while\na large number of hidden states can lead to overfitting. In this paper, we\nstudy methods that impose an $\\ell_1$ regularization on the transition matrix\nof an LDS model to alleviate the problem of choosing the optimal number of\nhidden states. We incorporate a generalized gradient descent method into the\nMaximum a Posteriori (MAP) framework and use Expectation Maximization (EM) to\niteratively achieve sparsity on the transition matrix of an LDS model. We show\nthat our Sparse Linear Dynamical System (SLDS) improves the predictive\nperformance when compared to ordinary LDS on a multivariate clinical time\nseries dataset.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 18:58:07 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 20:08:28 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Liu", "Zitao", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "1311.7184", "submitter": "Jason Lee", "authors": "Jason D Lee, Ran Gilad-Bachrach, and Rich Caruana", "title": "Using Multiple Samples to Learn Mixture Models", "comments": "Published in Neural Information Processing Systems (NIPS) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mixture models problem it is assumed that there are $K$ distributions\n$\\theta_{1},\\ldots,\\theta_{K}$ and one gets to observe a sample from a mixture\nof these distributions with unknown coefficients. The goal is to associate\ninstances with their generating distributions, or to identify the parameters of\nthe hidden distributions. In this work we make the assumption that we have\naccess to several samples drawn from the same $K$ underlying distributions, but\nwith different mixing weights. As with topic modeling, having multiple samples\nis often a reasonable assumption. Instead of pooling the data into one sample,\nwe prove that it is possible to use the differences between the samples to\nbetter recover the underlying structure. We present algorithms that recover the\nunderlying structure under milder assumptions than the current state of art\nwhen either the dimensionality or the separation is high. The methods, when\napplied to topic modeling, allow generalization to words not present in the\ntraining data.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 01:36:49 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Lee", "Jason D", ""], ["Gilad-Bachrach", "Ran", ""], ["Caruana", "Rich", ""]]}, {"id": "1311.7198", "submitter": "Karthik Mohan", "authors": "Karthik Mohan", "title": "ADMM Algorithm for Graphical Lasso with an $\\ell_{\\infty}$ Element-wise\n  Norm Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Graphical lasso with an additional $\\ell_{\\infty}$\nelement-wise norm constraint on the precision matrix. This problem has\napplications in high-dimensional covariance decomposition such as in\n\\citep{Janzamin-12}. We propose an ADMM algorithm to solve this problem. We\nalso use a continuation strategy on the penalty parameter to have a fast\nimplemenation of the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 03:59:31 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Mohan", "Karthik", ""]]}, {"id": "1311.7251", "submitter": "Michael Zibulevsky", "authors": "Joseph Shtok, Michael Zibulevsky and Michael Elad", "title": "Spatially-Adaptive Reconstruction in Computed Tomography using Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a supervised machine learning approach for boosting existing\nsignal and image recovery methods and demonstrate its efficacy on example of\nimage reconstruction in computed tomography. Our technique is based on a local\nnonlinear fusion of several image estimates, all obtained by applying a chosen\nreconstruction algorithm with different values of its control parameters.\nUsually such output images have different bias/variance trade-off. The fusion\nof the images is performed by feed-forward neural network trained on a set of\nknown examples. Numerical experiments show an improvement in reconstruction\nquality relatively to existing direct and iterative reconstruction methods.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 09:44:45 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Shtok", "Joseph", ""], ["Zibulevsky", "Michael", ""], ["Elad", "Michael", ""]]}, {"id": "1311.7385", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vitanyi (CWI and University of Amsterdam, NL), Nick Chater\n  (University of Warwick, UK)", "title": "Algorithmic Identification of Probabilities", "comments": "19 pages LaTeX.Corrected errors and rewrote the entire paper. arXiv\n  admin note: text overlap with arXiv:1208.5003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TThe problem is to identify a probability associated with a set of natural\nnumbers, given an infinite data sequence of elements from the set. If the given\nsequence is drawn i.i.d. and the probability mass function involved (the\ntarget) belongs to a computably enumerable (c.e.) or co-computably enumerable\n(co-c.e.) set of computable probability mass functions, then there is an\nalgorithm to almost surely identify the target in the limit. The technical tool\nis the strong law of large numbers. If the set is finite and the elements of\nthe sequence are dependent while the sequence is typical in the sense of\nMartin-L\\\"of for at least one measure belonging to a c.e. or co-c.e. set of\ncomputable measures, then there is an algorithm to identify in the limit a\ncomputable measure for which the sequence is typical (there may be more than\none such measure). The technical tool is the theory of Kolmogorov complexity.\nWe give the algorithms and consider the associated predictions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 17:44:45 GMT"}, {"version": "v2", "created": "Thu, 5 Jun 2014 17:10:33 GMT"}, {"version": "v3", "created": "Fri, 11 Jul 2014 17:10:27 GMT"}], "update_date": "2014-07-14", "authors_parsed": [["Vitanyi", "Paul M. B.", "", "CWI and University of Amsterdam, NL"], ["Chater", "Nick", "", "University of Warwick, UK"]]}, {"id": "1311.7662", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Payman Yadollahpour, Yury Makarychev, Ruslan\n  Salakhutdinov, Nathan Srebro", "title": "The Power of Asymmetry in Binary Hashing", "comments": "Accepted to NIPS 2013, 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When approximating binary similarity using the hamming distance between short\nbinary hashes, we show that even if the similarity is symmetric, we can have\nshorter and more accurate hashes by using two distinct code maps. I.e. by\napproximating the similarity between $x$ and $x'$ as the hamming distance\nbetween $f(x)$ and $g(x')$, for two distinct binary codes $f,g$, rather than as\nthe hamming distance between $f(x)$ and $f(x')$.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 18:53:32 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Yadollahpour", "Payman", ""], ["Makarychev", "Yury", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1311.7679", "submitter": "Bing Xu", "authors": "Xudong Liu, Bing Xu, Yuyu Zhang, Qiang Yan, Liang Pang, Qiang Li,\n  Hanxiao Sun, Bin Wang", "title": "Combination of Diverse Ranking Models for Personalized Expedia Hotel\n  Searches", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ICDM Challenge 2013 is to apply machine learning to the problem of hotel\nranking, aiming to maximize purchases according to given hotel characteristics,\nlocation attractiveness of hotels, user's aggregated purchase history and\ncompetitive online travel agency information for each potential hotel choice.\nThis paper describes the solution of team \"binghsu & MLRush & BrickMover\". We\nconduct simple feature engineering work and train different models by each\nindividual team member. Afterwards, we use listwise ensemble method to combine\neach model's output. Besides describing effective model and features, we will\ndiscuss about the lessons we learned while using deep learning in this\ncompetition.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 20:01:10 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Liu", "Xudong", ""], ["Xu", "Bing", ""], ["Zhang", "Yuyu", ""], ["Yan", "Qiang", ""], ["Pang", "Liang", ""], ["Li", "Qiang", ""], ["Sun", "Hanxiao", ""], ["Wang", "Bin", ""]]}]