[{"id": "2001.00006", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Yoshua Bengio", "title": "Learning from Learning Machines: Optimisation, Rules, and Social Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an analogy between machine learning systems and economic entities in\nthat they are both adaptive, and their behaviour is specified in a more-or-less\nexplicit way. It appears that the area of AI that is most analogous to the\nbehaviour of economic entities is that of morally good decision-making, but it\nis an open question as to how precisely moral behaviour can be achieved in an\nAI system. This paper explores the analogy between these two complex systems,\nand we suggest that a clearer understanding of this apparent analogy may help\nus forward in both the socio-economic domain and the AI domain: known results\nin economics may help inform feasible solutions in AI safety, but also known\nresults in AI may inform economic policy. If this claim is correct, then the\nrecent successes of deep learning for AI suggest that more implicit\nspecifications work better than explicit ones for solving such problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 17:42:06 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["LaCroix", "Travis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.00007", "submitter": "Esteve Del Acebo", "authors": "Esteve del Acebo, Yousef Alizadeh-Q, Sayyed Ali Hossayni", "title": "A generalization of the symmetrical and optimal\n  probability-to-possibility transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Possibility and probability theories are alternative and complementary ways\nto deal with uncertainty, which has motivated over the last years an interest\nfor the study of ways to transform probability distributions into possibility\ndistributions and conversely. This paper studies the advantages and\nshortcomings of two well-known discrete probability to possibility\ntransformations: the optimal transformation and the symmetrical transformation,\nand presents a novel parametric family of probability to possibility\ntransformations which generalizes them and alleviate their shortcomings,\nshowing a big potential for practical application. The paper also introduces a\nnovel fuzzy measure of specificity for probability distributions based on the\nconcept of fuzzy subsethood and presents a empirical validation of the\ngeneralized transformation usefulness applying it to the text authorship\nattribution problem.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 17:43:45 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["del Acebo", "Esteve", ""], ["Alizadeh-Q", "Yousef", ""], ["Hossayni", "Sayyed Ali", ""]]}, {"id": "2001.00008", "submitter": "Maxime Bassenne", "authors": "Maxime Bassenne and Adri\\'an Lozano-Dur\\'an", "title": "Computational model discovery with reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motivation of this study is to leverage recent breakthroughs in\nartificial intelligence research to unlock novel solutions to important\nscientific problems encountered in computational science. To address the human\nintelligence limitations in discovering reduced-order models, we propose to\nsupplement human thinking with artificial intelligence. Our three-pronged\nstrategy consists of learning (i) models expressed in analytical form, (ii)\nwhich are evaluated a posteriori, and iii) using exclusively integral\nquantities from the reference solution as prior knowledge. In point (i), we\npursue interpretable models expressed symbolically as opposed to black-box\nneural networks, the latter only being used during learning to efficiently\nparameterize the large search space of possible models. In point (ii), learned\nmodels are dynamically evaluated a posteriori in the computational solver\ninstead of based on a priori information from preprocessed high-fidelity data,\nthereby accounting for the specificity of the solver at hand such as its\nnumerics. Finally in point (iii), the exploration of new models is solely\nguided by predefined integral quantities, e.g., averaged quantities of\nengineering interest in Reynolds-averaged or large-eddy simulations (LES). We\nuse a coupled deep reinforcement learning framework and computational solver to\nconcurrently achieve these objectives. The combination of reinforcement\nlearning with objectives (i), (ii) and (iii) differentiate our work from\nprevious modeling attempts based on machine learning. In this report, we\nprovide a high-level description of the model discovery framework with\nreinforcement learning. The method is detailed for the application of\ndiscovering missing terms in differential equations. An elementary\ninstantiation of the method is described that discovers missing terms in the\nBurgers' equation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 22:56:40 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Bassenne", "Maxime", ""], ["Lozano-Dur\u00e1n", "Adri\u00e1n", ""]]}, {"id": "2001.00012", "submitter": "Kenneth Choi", "authors": "Kenneth Choi and Tony Lee", "title": "Differentially Private M-band Wavelet-Based Mechanisms in Machine\n  Learning Environments", "comments": "Part-Time Research Assistant/Helper: Tony Lee; 49 pages, 20 figures,\n  1 table, to be published by International Press of Boston", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the post-industrial world, data science and analytics have gained\nparamount importance regarding digital data privacy. Improper methods of\nestablishing privacy for accessible datasets can compromise large amounts of\nuser data even if the adversary has a small amount of preliminary knowledge of\na user. Many researchers have been developing high-level privacy-preserving\nmechanisms that also retain the statistical integrity of the data to apply to\nmachine learning. Recent developments of differential privacy, such as the\nLaplace and Privelet mechanisms, drastically decrease the probability that an\nadversary can distinguish the elements in a data set and thus extract user\ninformation. In this paper, we develop three privacy-preserving mechanisms with\nthe discrete M-band wavelet transform that embed noise into data. The first two\nmethods (LS and LS+) add noise through a Laplace-Sigmoid distribution that\nmultiplies Laplace-distributed values with the sigmoid function, and the third\nmethod utilizes pseudo-quantum steganography to embed noise into the data. We\nthen show that our mechanisms successfully retain both differential privacy and\nlearnability through statistical analysis in various machine learning\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:07:37 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:28:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Choi", "Kenneth", ""], ["Lee", "Tony", ""]]}, {"id": "2001.00051", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Yulong Pei, Katia Sycara", "title": "Simultaneous Identification of Tweet Purpose and Position", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet classification has attracted considerable attention recently. Most of\nthe existing work on tweet classification focuses on topic classification,\nwhich classifies tweets into several predefined categories, and sentiment\nclassification, which classifies tweets into positive, negative and neutral.\nSince tweets are different from conventional text in that they generally are of\nlimited length and contain informal, irregular or new words, so it is difficult\nto determine user intention to publish a tweet and user attitude towards\ncertain topic. In this paper, we aim to simultaneously classify tweet purpose,\ni.e., the intention for user to publish a tweet, and position, i.e.,\nsupporting, opposing or being neutral to a given topic. By transforming this\nproblem to a multi-label classification problem, a multi-label classification\nmethod with post-processing is proposed. Experiments on real-world data sets\ndemonstrate the effectiveness of this method and the results outperform the\nindividual classification methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 17:09:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Pei", "Yulong", ""], ["Sycara", "Katia", ""]]}, {"id": "2001.00053", "submitter": "Kamyar Givaki", "authors": "Kamyar Givaki, Behzad Salami, Reza Hojabr, S. M. Reza Tayaranian,\n  Ahmad Khonsari, Dara Rahmati, Saeid Gorgin, Adrian Cristal, Osman S. Unsal", "title": "On the Resilience of Deep Learning for Reduced-voltage FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are inherently computation-intensive and also\npower-hungry. Hardware accelerators such as Field Programmable Gate Arrays\n(FPGAs) are a promising solution that can satisfy these requirements for both\nembedded and High-Performance Computing (HPC) systems. In FPGAs, as well as\nCPUs and GPUs, aggressive voltage scaling below the nominal level is an\neffective technique for power dissipation minimization. Unfortunately, bit-flip\nfaults start to appear as the voltage is scaled down closer to the transistor\nthreshold due to timing issues, thus creating a resilience issue.\n  This paper experimentally evaluates the resilience of the training phase of\nDNNs in the presence of voltage underscaling related faults of FPGAs,\nespecially in on-chip memories. Toward this goal, we have experimentally\nevaluated the resilience of LeNet-5 and also a specially designed network for\nCIFAR-10 dataset with different activation functions of Rectified Linear Unit\n(Relu) and Hyperbolic Tangent (Tanh). We have found that modern FPGAs are\nrobust enough in extremely low-voltage levels and that low-voltage related\nfaults can be automatically masked within the training iterations, so there is\nno need for costly software- or hardware-oriented fault mitigation techniques\nlike ECC. Approximately 10% more training iterations are needed to fill the gap\nin the accuracy. This observation is the result of the relatively low rate of\nundervolting faults, i.e., <0.1\\%, measured on real FPGA fabrics. We have also\nincreased the fault rate significantly for the LeNet-5 network by randomly\ngenerated fault injection campaigns and observed that the training accuracy\nstarts to degrade. When the fault rate increases, the network with Tanh\nactivation function outperforms the one with Relu in terms of accuracy, e.g.,\nwhen the fault rate is 30% the accuracy difference is 4.92%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 15:08:22 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Givaki", "Kamyar", ""], ["Salami", "Behzad", ""], ["Hojabr", "Reza", ""], ["Tayaranian", "S. M. Reza", ""], ["Khonsari", "Ahmad", ""], ["Rahmati", "Dara", ""], ["Gorgin", "Saeid", ""], ["Cristal", "Adrian", ""], ["Unsal", "Osman S.", ""]]}, {"id": "2001.00056", "submitter": "Dhanajit Brahma", "authors": "Pawan Kumar, Dhanajit Brahma, Harish Karnick, Piyush Rai", "title": "Deep Attentive Ranking Networks for Learning to Order Sentences", "comments": "Accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an attention-based ranking framework for learning to order\nsentences given a paragraph. Our framework is built on a bidirectional sentence\nencoder and a self-attention based transformer network to obtain an input order\ninvariant representation of paragraphs. Moreover, it allows seamless training\nusing a variety of ranking based loss functions, such as pointwise, pairwise,\nand listwise ranking. We apply our framework on two tasks: Sentence Ordering\nand Order Discrimination. Our framework outperforms various state-of-the-art\nmethods on these tasks on a variety of evaluation metrics. We also show that it\nachieves better results when using pairwise and listwise ranking losses, rather\nthan the pointwise ranking loss, which suggests that incorporating relative\npositions of two or more sentences in the loss function contributes to better\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:54:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kumar", "Pawan", ""], ["Brahma", "Dhanajit", ""], ["Karnick", "Harish", ""], ["Rai", "Piyush", ""]]}, {"id": "2001.00057", "submitter": "Bhairav Chidambaram", "authors": "Bhairav Chidambaram, Mason McGill, Pietro Perona", "title": "HMM-guided frame querying for bandwidth-constrained video search", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design an agent to search for frames of interest in video stored on a\nremote server, under bandwidth constraints. Using a convolutional neural\nnetwork to score individual frames and a hidden Markov model to propagate\npredictions across frames, our agent accurately identifies temporal regions of\ninterest based on sparse, strategically sampled frames. On a subset of the\nImageNet-VID dataset, we demonstrate that using a hidden Markov model to\ninterpolate between frame scores allows requests of 98% of frames to be\nomitted, without compromising frame-of-interest classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:54:35 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chidambaram", "Bhairav", ""], ["McGill", "Mason", ""], ["Perona", "Pietro", ""]]}, {"id": "2001.00059", "submitter": "Petros Maniatis", "authors": "Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi", "title": "Learning and Evaluating Contextual Embedding of Source Code", "comments": "Published in ICML 2020. This version (v.3) is the final camera-ready\n  version of the paper. It contains the re-computed results, based on the\n  open-sourced datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has achieved impressive results on understanding and\nimproving source code by building up on machine-learning techniques developed\nfor natural languages. A significant advancement in natural-language\nunderstanding has come with the development of pre-trained contextual\nembeddings, such as BERT, which can be fine-tuned for downstream tasks with\nless labeled data and training budget, while achieving better accuracies.\nHowever, there is no attempt yet to obtain a high-quality contextual embedding\nof source code, and to evaluate it on multiple program-understanding tasks\nsimultaneously; that is the gap that this paper aims to mitigate. Specifically,\nfirst, we curate a massive, deduplicated corpus of 7.4M Python files from\nGitHub, which we use to pre-train CuBERT, an open-sourced code-understanding\nBERT model; and, second, we create an open-sourced benchmark that comprises\nfive classification tasks and one program-repair task, akin to\ncode-understanding tasks proposed in the literature before. We fine-tune CuBERT\non our benchmark tasks, and compare the resulting models to different variants\nof Word2Vec token embeddings, BiLSTM and Transformer models, as well as\npublished state-of-the-art models, showing that CuBERT outperforms them all,\neven with shorter training, and with fewer labeled examples. Future work on\nsource-code embedding can benefit from reusing our benchmark, and from\ncomparing against CuBERT models as a strong baseline.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 05:05:22 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 22:06:21 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 21:40:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kanade", "Aditya", ""], ["Maniatis", "Petros", ""], ["Balakrishnan", "Gogul", ""], ["Shi", "Kensen", ""]]}, {"id": "2001.00060", "submitter": "Issam Hammad", "authors": "Issam Hammad, Kamal El-Sankary, and Jason Gu", "title": "Deep Learning Training with Simulated Approximate Multipliers", "comments": "Presented at: IEEE International Conference on Robotics and\n  Biomimetics (ROBIO) 2019, Dali, China, December 2019. WINNER OF THE MOZI BEST\n  PAPER IN AI AWARD", "journal-ref": "2019 IEEE International Conference on Robotics and Biomimetics\n  (ROBIO)", "doi": "10.1109/ROBIO49542.2019.8961780", "report-no": null, "categories": "cs.LG cs.CV cs.PF eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents by simulation how approximate multipliers can be utilized\nto enhance the training performance of convolutional neural networks (CNNs).\nApproximate multipliers have significantly better performance in terms of\nspeed, power, and area compared to exact multipliers. However, approximate\nmultipliers have an inaccuracy which is defined in terms of the Mean Relative\nError (MRE). To assess the applicability of approximate multipliers in\nenhancing CNN training performance, a simulation for the impact of approximate\nmultipliers error on CNN training is presented. The paper demonstrates that\nusing approximate multipliers for CNN training can significantly enhance the\nperformance in terms of speed, power, and area at the cost of a small negative\nimpact on the achieved accuracy. Additionally, the paper proposes a hybrid\ntraining method which mitigates this negative impact on the accuracy. Using the\nproposed hybrid method, the training can start using approximate multipliers\nthen switches to exact multipliers for the last few epochs. Using this method,\nthe performance benefits of approximate multipliers in terms of speed, power,\nand area can be attained for a large portion of the training stage. On the\nother hand, the negative impact on the accuracy is diminished by using the\nexact multipliers for the last epochs of training.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 12:50:06 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 13:22:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hammad", "Issam", ""], ["El-Sankary", "Kamal", ""], ["Gu", "Jason", ""]]}, {"id": "2001.00062", "submitter": "Hiba Arnout", "authors": "Hiba Arnout and Johannes Kehrer and Johanna Bronner and Thomas Runkler", "title": "Visual Evaluation of Generative Adversarial Networks for Time Series\n  Data", "comments": "To appear in the Proceedings of the Human-Centered AI:\n  Trustworthiness of AI Models & Data (HAI) track at AAAI Fall Symposium, DC,\n  November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial factor to trust Machine Learning (ML) algorithm decisions is a good\nrepresentation of its application field by the training dataset. This is\nparticularly true when parts of the training data have been artificially\ngenerated to overcome common training problems such as lack of data or\nimbalanced dataset. Over the last few years, Generative Adversarial Networks\n(GANs) have shown remarkable results in generating realistic data. However,\nthis ML approach lacks an objective function to evaluate the quality of the\ngenerated data. Numerous GAN applications focus on generating image data mostly\nbecause they can be easily evaluated by a human eye. Less efforts have been\nmade to generate time series data. Assessing their quality is more complicated,\nparticularly for technical data. In this paper, we propose a human-centered\napproach supporting a ML or domain expert to accomplish this task using Visual\nAnalytics (VA) techniques. The presented approach consists of two views, namely\na GAN Iteration View showing similarity metrics between real and generated data\nover the iterations of the generation process and a Detailed Comparative View\nequipped with different time series visualizations such as TimeHistograms, to\ncompare the generated data at different iteration steps. Starting from the GAN\nIteration View, the user can choose suitable iteration steps for detailed\ninspection. We evaluate our approach with a usage scenario that enabled an\nefficient comparison of two different GAN models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 13:59:33 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Arnout", "Hiba", ""], ["Kehrer", "Johannes", ""], ["Bronner", "Johanna", ""], ["Runkler", "Thomas", ""]]}, {"id": "2001.00071", "submitter": "Sumit Mukherjee", "authors": "Sumit Mukherjee, Yixi Xu, Anusua Trivedi, Juan Lavista Ferres", "title": "privGAN: Protecting GANs from membership inference attacks at low cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have made releasing of synthetic\nimages a viable approach to share data without releasing the original dataset.\nIt has been shown that such synthetic data can be used for a variety of\ndownstream tasks such as training classifiers that would otherwise require the\noriginal dataset to be shared. However, recent work has shown that the GAN\nmodels and their synthetically generated data can be used to infer the training\nset membership by an adversary who has access to the entire dataset and some\nauxiliary information. Current approaches to mitigate this problem (such as\nDPGAN) lead to dramatically poorer generated sample quality than the original\nnon--private GANs. Here we develop a new GAN architecture (privGAN), where the\ngenerator is trained not only to cheat the discriminator but also to defend\nmembership inference attacks. The new mechanism provides protection against\nthis mode of attack while leading to negligible loss in downstream\nperformances. In addition, our algorithm has been shown to explicitly prevent\noverfitting to the training set, which explains why our protection is so\neffective. The main contributions of this paper are: i) we propose a novel GAN\narchitecture that can generate synthetic data in a privacy preserving manner\nwithout additional hyperparameter tuning and architecture selection, ii) we\nprovide a theoretical understanding of the optimal solution of the privGAN loss\nfunction, iii) we demonstrate the effectiveness of our model against several\nwhite and black--box attacks on several benchmark datasets, iv) we demonstrate\non three common benchmark datasets that synthetic images generated by privGAN\nlead to negligible loss in downstream performance when compared against\nnon--private GANs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:47:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 17:44:07 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 06:53:47 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2020 18:27:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mukherjee", "Sumit", ""], ["Xu", "Yixi", ""], ["Trivedi", "Anusua", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2001.00076", "submitter": "Ari Kobren", "authors": "Nicholas Monath, Ari Kobren, Akshay Krishnamurthy, Michael Glass,\n  Andrew McCallum", "title": "Scalable Hierarchical Clustering with Tree Grafting", "comments": "23 pages (appendix included), published at KDD 2019", "journal-ref": null, "doi": "10.1145/3292500.3330929", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Grinch, a new algorithm for large-scale, non-greedy hierarchical\nclustering with general linkage functions that compute arbitrary similarity\nbetween two point sets. The key components of Grinch are its rotate and graft\nsubroutines that efficiently reconfigure the hierarchy as new points arrive,\nsupporting discovery of clusters with complex structure. Grinch is motivated by\na new notion of separability for clustering with linkage functions: we prove\nthat when the model is consistent with a ground-truth clustering, Grinch is\nguaranteed to produce a cluster tree containing the ground-truth, independent\nof data arrival order. Our empirical results on benchmark and author\ncoreference datasets (with standard and learned linkage functions) show that\nGrinch is more accurate than other scalable methods, and orders of magnitude\nfaster than hierarchical agglomerative clustering.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:56:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Monath", "Nicholas", ""], ["Kobren", "Ari", ""], ["Krishnamurthy", "Akshay", ""], ["Glass", "Michael", ""], ["McCallum", "Andrew", ""]]}, {"id": "2001.00088", "submitter": "Andrew Perrault", "authors": "Andrew Perrault, Fei Fang, Arunesh Sinha, Milind Tambe", "title": "AI for Social Impact: Learning and Planning in the Data-to-Deployment\n  Pipeline", "comments": "To appear, AI Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the maturing of AI and multiagent systems research, we have a tremendous\nopportunity to direct these advances towards addressing complex societal\nproblems. In pursuit of this goal of AI for Social Impact, we as AI researchers\nmust go beyond improvements in computational methodology; it is important to\nstep out in the field to demonstrate social impact. To this end, we focus on\nthe problems of public safety and security, wildlife conservation, and public\nhealth in low-resource communities, and present research advances in multiagent\nsystems to address one key cross-cutting challenge: how to effectively deploy\nour limited intervention resources in these problem domains. We present case\nstudies from our deployments around the world as well as lessons learned that\nwe hope are of use to researchers who are interested in AI for Social Impact.\nIn pushing this research agenda, we believe AI can indeed play an important\nrole in fighting social injustice and improving society.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:10:56 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Perrault", "Andrew", ""], ["Fang", "Fei", ""], ["Sinha", "Arunesh", ""], ["Tambe", "Milind", ""]]}, {"id": "2001.00089", "submitter": "Candice Schumann", "authors": "Debjani Saha, Candice Schumann, Duncan C. McElfresh, John P.\n  Dickerson, Michelle L. Mazurek, Michael Carl Tschantz", "title": "Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in machine learning has manifested injustice in several areas, such as\nmedicine, hiring, and criminal justice. In response, computer scientists have\ndeveloped myriad definitions of fairness to correct this bias in fielded\nalgorithms. While some definitions are based on established legal and ethical\nnorms, others are largely mathematical. It is unclear whether the general\npublic agrees with these fairness definitions, and perhaps more importantly,\nwhether they understand these definitions. We take initial steps toward\nbridging this gap between ML researchers and the public, by addressing the\nquestion: does a lay audience understand a basic definition of ML fairness? We\ndevelop a metric to measure comprehension of three such\ndefinitions--demographic parity, equal opportunity, and equalized odds. We\nevaluate this metric using an online survey, and investigate the relationship\nbetween comprehension and sentiment, demographics, and the definition itself.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 00:58:54 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 16:23:08 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 21:13:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Saha", "Debjani", ""], ["Schumann", "Candice", ""], ["McElfresh", "Duncan C.", ""], ["Dickerson", "John P.", ""], ["Mazurek", "Michelle L.", ""], ["Tschantz", "Michael Carl", ""]]}, {"id": "2001.00098", "submitter": "Brett Larsen", "authors": "Abbas Kazemipour, Brett W. Larsen and Shaul Druckmann", "title": "Avoiding Spurious Local Minima in Deep Quadratic Networks", "comments": "36 pages; added deep network experiments, results for population loss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their practical success, a theoretical understanding of the loss\nlandscape of neural networks has proven challenging due to the\nhigh-dimensional, non-convex, and highly nonlinear structure of such models. In\nthis paper, we characterize the training landscape of the mean squared error\nloss for neural networks with quadratic activation functions. We prove\nexistence of spurious local minima and saddle points which can be escaped\neasily with probability one when the number of neurons is greater than or equal\nto the input dimension and the norm of the training samples is used as a\nregressor. We prove that deep overparameterized neural networks with quadratic\nactivations benefit from similar nice landscape properties. Our theoretical\nresults are independent of data distribution and fill the existing gap in\ntheory for two-layer quadratic neural networks. Finally, we empirically\ndemonstrate convergence to a global minimum for these problems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:31:11 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:40:15 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Kazemipour", "Abbas", ""], ["Larsen", "Brett W.", ""], ["Druckmann", "Shaul", ""]]}, {"id": "2001.00102", "submitter": "Baoxiang Wang", "authors": "Baoxiang Wang, Shuai Li, Jiajin Li, Siu On Chan", "title": "The Gambler's Problem and Beyond", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Gambler's problem, a simple reinforcement learning problem\nwhere the gambler has the chance to double or lose the bets until the target is\nreached. This is an early example introduced in the reinforcement learning\ntextbook by Sutton and Barto (2018), where they mention an interesting pattern\nof the optimal value function with high-frequency components and repeating\nnon-smooth points. It is however without further investigation. We provide the\nexact formula for the optimal value function for both the discrete and the\ncontinuous cases. Though simple as it might seem, the value function is\npathological: fractal, self-similar, derivative taking either zero or infinity,\nand not written as elementary functions. It is in fact one of the generalized\nCantor functions, where it holds a complexity that has been uncharted thus far.\nOur analyses could provide insights into improving value function\napproximation, gradient-based algorithms, and Q-learning, in real applications\nand implementations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 22:48:15 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 11:44:17 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 12:43:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Wang", "Baoxiang", ""], ["Li", "Shuai", ""], ["Li", "Jiajin", ""], ["Chan", "Siu On", ""]]}, {"id": "2001.00106", "submitter": "Sangdon Park", "authors": "Sangdon Park, Osbert Bastani, Nikolai Matni, Insup Lee", "title": "PAC Confidence Sets for Deep Neural Networks via Calibrated Prediction", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm combining calibrated prediction and generalization\nbounds from learning theory to construct confidence sets for deep neural\nnetworks with PAC guarantees---i.e., the confidence set for a given input\ncontains the true label with high probability. We demonstrate how our approach\ncan be used to construct PAC confidence sets on ResNet for ImageNet, a visual\nobject tracking model, and a dynamics model for the half-cheetah reinforcement\nlearning problem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:02:01 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 19:50:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Park", "Sangdon", ""], ["Bastani", "Osbert", ""], ["Matni", "Nikolai", ""], ["Lee", "Insup", ""]]}, {"id": "2001.00111", "submitter": "Yoh'ichi Mototake", "authors": "Yoh-ichi Mototake", "title": "Interpretable Conservation Law Estimation by Deriving the Symmetries of\n  Dynamics from Trained Deep Neural Networks", "comments": "38 pages, 8 figures", "journal-ref": "Phys. Rev. E 103, 033303 (2021)", "doi": "10.1103/PhysRevE.103.033303", "report-no": null, "categories": "physics.data-an cs.LG nlin.PS physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding complex systems with their reduced model is one of the central\nroles in scientific activities. Although physics has greatly been developed\nwith the physical insights of physicists, it is sometimes challenging to build\na reduced model of such complex systems on the basis of insights alone. We\npropose a novel framework that can infer the hidden conservation laws of a\ncomplex system from deep neural networks (DNNs) that have been trained with\nphysical data of the system. The purpose of the proposed framework is not to\nanalyze physical data with deep learning, but to extract interpretable physical\ninformation from trained DNNs. With Noether's theorem and by an efficient\nsampling method, the proposed framework infers conservation laws by extracting\nsymmetries of dynamics from trained DNNs. The proposed framework is developed\nby deriving the relationship between a manifold structure of time-series\ndataset and the necessary conditions for Noether's theorem. The feasibility of\nthe proposed framework has been verified in some primitive cases for which the\nconservation law is well known. We also apply the proposed framework to\nconservation law estimation for a more practical case that is a large-scale\ncollective motion system in the metastable state, and we obtain a result\nconsistent with that of a previous study.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:55:44 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 00:08:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mototake", "Yoh-ichi", ""]]}, {"id": "2001.00116", "submitter": "Qiang Zeng", "authors": "Fei Zuo, Qiang Zeng", "title": "Exploiting the Sensitivity of $L_2$ Adversarial Examples to\n  Erase-and-Restore", "comments": "Accepted to AsiaCCS'21 on 10/24/2020; 12 pages; the code, datasets,\n  and models will be made publicly available when the paper is presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By adding carefully crafted perturbations to input images, adversarial\nexamples (AEs) can be generated to mislead neural-network-based image\nclassifiers. $L_2$ adversarial perturbations by Carlini and Wagner (CW) are\namong the most effective but difficult-to-detect attacks. While many\ncountermeasures against AEs have been proposed, detection of adaptive CW-$L_2$\nAEs is still an open question. We find that, by randomly erasing some pixels in\nan $L_2$ AE and then restoring it with an inpainting technique, the AE, before\nand after the steps, tends to have different classification results, while a\nbenign sample does not show this symptom. We thus propose a novel AE detection\ntechnique, Erase-and-Restore (E&R), that exploits the intriguing sensitivity of\n$L_2$ attacks. Experiments conducted on two popular image datasets, CIFAR-10\nand ImageNet, show that the proposed technique is able to detect over 98% of\n$L_2$ AEs and has a very low false positive rate on benign images. The\ndetection technique exhibits high transferability: a detection system trained\nusing CW-$L_2$ AEs can accurately detect AEs generated using another $L_2$\nattack method. More importantly, our approach demonstrates strong resilience to\nadaptive $L_2$ attacks, filling a critical gap in AE detection. Finally, we\ninterpret the detection technique through both visualization and\nquantification.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 00:15:07 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 23:48:02 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zuo", "Fei", ""], ["Zeng", "Qiang", ""]]}, {"id": "2001.00119", "submitter": "Simone Parisi", "authors": "Simone Parisi, Davide Tateo, Maximilian Hensel, Carlo D'Eramo, Jan\n  Peters, Joni Pajarinen", "title": "Long-Term Visitation Value for Deep Exploration in Sparse Reward\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with sparse rewards is still an open challenge.\nClassic methods rely on getting feedback via extrinsic rewards to train the\nagent, and in situations where this occurs very rarely the agent learns slowly\nor cannot learn at all. Similarly, if the agent receives also rewards that\ncreate suboptimal modes of the objective function, it will likely prematurely\nstop exploring. More recent methods add auxiliary intrinsic rewards to\nencourage exploration. However, auxiliary rewards lead to a non-stationary\ntarget for the Q-function. In this paper, we present a novel approach that (1)\nplans exploration actions far into the future by using a long-term visitation\ncount, and (2) decouples exploration and exploitation by learning a separate\nfunction assessing the exploration value of the actions. Contrary to existing\nmethods which use models of reward and dynamics, our approach is off-policy and\nmodel-free. We further propose new tabular environments for benchmarking\nexploration in reinforcement learning. Empirical results on classic and novel\nbenchmarks show that the proposed approach outperforms existing methods in\nenvironments with sparse rewards, especially in the presence of rewards that\ncreate suboptimal modes of the objective function. Results also suggest that\nour approach scales gracefully with the size of the environment. Source code is\navailable at https://github.com/sparisi/visit-value-explore\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 01:01:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Parisi", "Simone", ""], ["Tateo", "Davide", ""], ["Hensel", "Maximilian", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2001.00121", "submitter": "Sensong An", "authors": "Sensong An, Bowen Zheng, Mikhail Y. Shalaginov, Hong Tang, Hang Li, Li\n  Zhou, Jun Ding, Anuradha Murthy Agarwal, Clara Rivero-Baleine, Myungkoo Kang,\n  Kathleen A. Richardson, Tian Gu, Juejun Hu, Clayton Fowler and Hualiang Zhang", "title": "A Freeform Dielectric Metasurface Modeling Approach Based on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metasurfaces have shown promising potentials in shaping optical wavefronts\nwhile remaining compact compared to bulky geometric optics devices. Design of\nmeta-atoms, the fundamental building blocks of metasurfaces, relies on\ntrial-and-error method to achieve target electromagnetic responses. This\nprocess includes the characterization of an enormous amount of different\nmeta-atom designs with different physical and geometric parameters, which\nnormally demands huge computational resources. In this paper, a deep\nlearning-based metasurface/meta-atom modeling approach is introduced to\nsignificantly reduce the characterization time while maintaining accuracy.\nBased on a convolutional neural network (CNN) structure, the proposed deep\nlearning network is able to model meta-atoms with free-form 2D patterns and\ndifferent lattice sizes, material refractive indexes and thicknesses. Moreover,\nthe presented approach features the capability to predict meta-atoms' wide\nspectrum responses in the timescale of milliseconds, which makes it attractive\nfor applications such as fast meta-atom/metasurface on-demand designs and\noptimizations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 01:21:36 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["An", "Sensong", ""], ["Zheng", "Bowen", ""], ["Shalaginov", "Mikhail Y.", ""], ["Tang", "Hong", ""], ["Li", "Hang", ""], ["Zhou", "Li", ""], ["Ding", "Jun", ""], ["Agarwal", "Anuradha Murthy", ""], ["Rivero-Baleine", "Clara", ""], ["Kang", "Myungkoo", ""], ["Richardson", "Kathleen A.", ""], ["Gu", "Tian", ""], ["Hu", "Juejun", ""], ["Fowler", "Clayton", ""], ["Zhang", "Hualiang", ""]]}, {"id": "2001.00127", "submitter": "Kai Jiang", "authors": "Kai Jiang, XiaoLong Qin", "title": "Reinforcement Learning with Goal-Distance Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning usually uses the feedback rewards of environmental to\ntrain agents. But the rewards in the actual environment are sparse, and even\nsome environments will not rewards. Most of the current methods are difficult\nto get good performance in sparse reward or non-reward environments. Although\nusing shaped rewards is effective when solving sparse reward tasks, it is\nlimited to specific problems and learning is also susceptible to local optima.\nWe propose a model-free method that does not rely on environmental rewards to\nsolve the problem of sparse rewards in the general environment. Our method use\nthe minimum number of transitions between states as the distance to replace the\nrewards of environmental, and proposes a goal-distance gradient to achieve\npolicy improvement. We also introduce a bridge point planning method based on\nthe characteristics of our method to improve exploration efficiency, thereby\nsolving more complex tasks. Experiments show that our method performs better on\nsparse reward and local optimal problems in complex environments than previous\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 02:37:34 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 12:26:33 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Jiang", "Kai", ""], ["Qin", "XiaoLong", ""]]}, {"id": "2001.00132", "submitter": "Aravind Sankar", "authors": "Aravind Sankar, Xinyang Zhang, Adit Krishnan, Jiawei Han", "title": "Inf-VAE: A Variational Autoencoder Framework to Integrate Homophily and\n  Influence in Diffusion Prediction", "comments": "International Conference on Web Search and Data Mining (WSDM 2020)", "journal-ref": null, "doi": "10.1145/3336191.3371811", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed tremendous interest in understanding and\npredicting information spread on social media platforms such as Twitter,\nFacebook, etc. Existing diffusion prediction methods primarily exploit the\nsequential order of influenced users by projecting diffusion cascades onto\ntheir local social neighborhoods. However, this fails to capture global social\nstructures that do not explicitly manifest in any of the cascades, resulting in\npoor performance for inactive users with limited historical activities.\n  In this paper, we present a novel variational autoencoder framework (Inf-VAE)\nto jointly embed homophily and influence through proximity-preserving social\nand position-encoded temporal latent variables. To model social homophily,\nInf-VAE utilizes powerful graph neural network architectures to learn social\nvariables that selectively exploit the social connections of users. Given a\nsequence of seed user activations, Inf-VAE uses a novel expressive co-attentive\nfusion network that jointly attends over their social and temporal variables to\npredict the set of all influenced users. Our experimental results on multiple\nreal-world social network datasets, including Digg, Weibo, and Stack-Exchanges\ndemonstrate significant gains (22% MAP@10) for Inf-VAE over state-of-the-art\ndiffusion prediction models; we achieve massive gains for users with sparse\nactivities, and users who lack direct social neighbors in seed sets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 03:35:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Sankar", "Aravind", ""], ["Zhang", "Xinyang", ""], ["Krishnan", "Adit", ""], ["Han", "Jiawei", ""]]}, {"id": "2001.00137", "submitter": "Gwenaelle Cunha Sergio", "authors": "Gwenaelle Cunha Sergio and Minho Lee", "title": "Stacked DeBERT: All Attention in Incomplete Data for Text Classification", "comments": "Published (https://doi.org/10.1016/j.neunet.2020.12.018), Code\n  (https://github.com/gcunhase/StackedDeBERT)", "journal-ref": "Neural Networks 136 (2021) 87-96", "doi": "10.1016/j.neunet.2020.12.018", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose Stacked DeBERT, short for Stacked Denoising\nBidirectional Encoder Representations from Transformers. This novel model\nimproves robustness in incomplete data, when compared to existing systems, by\ndesigning a novel encoding scheme in BERT, a powerful language representation\nmodel solely based on attention mechanisms. Incomplete data in natural language\nprocessing refer to text with missing or incorrect words, and its presence can\nhinder the performance of current models that were not implemented to withstand\nsuch noises, but must still perform well even under duress. This is due to the\nfact that current approaches are built for and trained with clean and complete\ndata, and thus are not able to extract features that can adequately represent\nincomplete data. Our proposed approach consists of obtaining intermediate input\nrepresentations by applying an embedding layer to the input tokens followed by\nvanilla transformers. These intermediate features are given as input to novel\ndenoising transformers which are responsible for obtaining richer input\nrepresentations. The proposed approach takes advantage of stacks of multilayer\nperceptrons for the reconstruction of missing words' embeddings by extracting\nmore abstract and meaningful hidden feature vectors, and bidirectional\ntransformers for improved embedding representation. We consider two datasets\nfor training and evaluation: the Chatbot Natural Language Understanding\nEvaluation Corpus and Kaggle's Twitter Sentiment Corpus. Our model shows\nimproved F1-scores and better robustness in informal/incorrect texts present in\ntweets and in texts with Speech-to-Text error in the sentiment and intent\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 04:49:23 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:13:49 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sergio", "Gwenaelle Cunha", ""], ["Lee", "Minho", ""]]}, {"id": "2001.00138", "submitter": "Xiaolong Ma", "authors": "Wei Niu, Xiaolong Ma, Sheng Lin, Shihao Wang, Xuehai Qian, Xue Lin,\n  Yanzhi Wang, Bin Ren", "title": "PatDNN: Achieving Real-Time DNN Execution on Mobile Devices with\n  Pattern-based Weight Pruning", "comments": "To be published in the Proceedings of Twenty-Fifth International\n  Conference on Architectural Support for Programming Languages and Operating\n  Systems (ASPLOS 20)", "journal-ref": null, "doi": "10.1145/3373376.3378534", "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of a spectrum of high-end mobile devices, many\napplications that formerly required desktop-level computation capability are\nbeing transferred to these devices. However, executing the inference of Deep\nNeural Networks (DNNs) is still challenging considering high computation and\nstorage demands, specifically, if real-time performance with high accuracy is\nneeded. Weight pruning of DNNs is proposed, but existing schemes represent two\nextremes in the design space: non-structured pruning is fine-grained, accurate,\nbut not hardware friendly; structured pruning is coarse-grained,\nhardware-efficient, but with higher accuracy loss. In this paper, we introduce\na new dimension, fine-grained pruning patterns inside the coarse-grained\nstructures, revealing a previously unknown point in design space. With the\nhigher accuracy enabled by fine-grained pruning patterns, the unique insight is\nto use the compiler to re-gain and guarantee high hardware efficiency. In other\nwords, our method achieves the best of both worlds, and is desirable across\ntheory/algorithm, compiler, and hardware levels. The proposed PatDNN is an\nend-to-end framework to efficiently execute DNN on mobile devices with the help\nof a novel model compression technique (pattern-based pruning based on extended\nADMM solution framework) and a set of thorough architecture-aware compiler- and\ncode generation-based optimizations (filter kernel reordering, compressed\nweight storage, register load redundancy elimination, and parameter\nauto-tuning). Evaluation results demonstrate that PatDNN outperforms three\nstate-of-the-art end-to-end DNN frameworks, TensorFlow Lite, TVM, and Alibaba\nMobile Neural Network with speedup up to 44.5x, 11.4x, and 7.1x, respectively,\nwith no accuracy compromise. Real-time inference of representative large-scale\nDNNs (e.g., VGG-16, ResNet-50) can be achieved using mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 04:52:07 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 00:27:57 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 04:32:38 GMT"}, {"version": "v4", "created": "Wed, 22 Jan 2020 04:13:06 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Niu", "Wei", ""], ["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Wang", "Shihao", ""], ["Qian", "Xuehai", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""], ["Ren", "Bin", ""]]}, {"id": "2001.00139", "submitter": "Rizwan Ahmed Khan", "authors": "Jamshed Memon, Maira Sami, Rizwan Ahmed Khan", "title": "Handwritten Optical Character Recognition (OCR): A Comprehensive\n  Systematic Literature Review (SLR)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the ubiquity of handwritten documents in human transactions, Optical\nCharacter Recognition (OCR) of documents have invaluable practical worth.\nOptical character recognition is a science that enables to translate various\ntypes of documents or images into analyzable, editable and searchable data.\nDuring last decade, researchers have used artificial intelligence / machine\nlearning tools to automatically analyze handwritten and printed documents in\norder to convert them into electronic format. The objective of this review\npaper is to summarize research that has been conducted on character recognition\nof handwritten documents and to provide research directions. In this Systematic\nLiterature Review (SLR) we collected, synthesized and analyzed research\narticles on the topic of handwritten OCR (and closely related topics) which\nwere published between year 2000 to 2018. We followed widely used electronic\ndatabases by following pre-defined review protocol. Articles were searched\nusing keywords, forward reference searching and backward reference searching in\norder to search all the articles related to the topic. After carefully\nfollowing study selection process 142 articles were selected for this SLR. This\nreview article serves the purpose of presenting state of the art results and\ntechniques on OCR and also provide research directions by highlighting research\ngaps.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 04:55:04 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Memon", "Jamshed", ""], ["Sami", "Maira", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "2001.00153", "submitter": "Yuntao Du", "authors": "Yuntao Du, Zhiwen Tan, Qian Chen, Xiaowen Zhang, Yirong Yao, Chongjun\n  Wang", "title": "Dual Adversarial Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Unsupervised domain adaptation aims at transferring knowledge from the\nlabeled source domain to the unlabeled target domain. Previous adversarial\ndomain adaptation methods mostly adopt the discriminator with binary or\n$K$-dimensional output to perform marginal or conditional alignment\nindependently. Recent experiments have shown that when the discriminator is\nprovided with domain information in both domains and label information in the\nsource domain, it is able to preserve the complex multimodal information and\nhigh semantic information in both domains. Following this idea, we adopt a\ndiscriminator with $2K$-dimensional output to perform both domain-level and\nclass-level alignments simultaneously in a single discriminator. However, a\nsingle discriminator can not capture all the useful information across domains\nand the relationships between the examples and the decision boundary are rarely\nexplored before. Inspired by multi-view learning and latest advances in domain\nadaptation, besides the adversarial process between the discriminator and the\nfeature extractor, we also design a novel mechanism to make two discriminators\npit against each other, so that they can provide diverse information for each\nother and avoid generating target features outside the support of the source\ndomain. To the best of our knowledge, it is the first time to explore a dual\nadversarial strategy in domain adaptation. Moreover, we also use the\nsemi-supervised learning regularization to make the representations more\ndiscriminative. Comprehensive experiments on two real-world datasets verify\nthat our method outperforms several state-of-the-art domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:10:09 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Du", "Yuntao", ""], ["Tan", "Zhiwen", ""], ["Chen", "Qian", ""], ["Zhang", "Xiaowen", ""], ["Yao", "Yirong", ""], ["Wang", "Chongjun", ""]]}, {"id": "2001.00155", "submitter": "Jessica Torres Soto", "authors": "Jessica Torres Soto, Euan Ashley", "title": "DeepBeat: A multi-task deep learning approach to assess signal quality\n  and arrhythmia detection in wearable devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices enable theoretically continuous, longitudinal monitoring of\nphysiological measurements like step count, energy expenditure, and heart rate.\nAlthough the classification of abnormal cardiac rhythms such as atrial\nfibrillation from wearable devices has great potential, commercial algorithms\nremain proprietary and tend to focus on heart rate variability derived from\ngreen spectrum LED sensors placed on the wrist where noise remains an unsolved\nproblem. Here, we develop a multi-task deep learning method to assess signal\nquality and arrhythmia event detection in wearable photoplethysmography devices\nfor real-time detection of atrial fibrillation (AF). We train our algorithm on\nover one million simulated unlabeled physiological signals and fine-tune on a\ncurated dataset of over 500K labeled signals from over 100 individuals from 3\ndifferent wearable devices. We demonstrate that in comparison with a\ntraditional random forest-based approach (precision:0.24, recall:0.58, f1:0.34,\nauPRC:0.44) and a single task CNN (precision:0.59, recall:0.69, f1:0.64,\nauPRC:0.68) our architecture using unsupervised transfer learning through\nconvolutional denoising autoencoders dramatically improves the performance of\nAF detection in participants at rest (pr:0.94, rc:0.98, f1:0.96, auPRC:0.96).\nIn addition, we validate algorithm performance on a prospectively derived\nreplication cohort of ambulatory subjects using data derived from an\nindependently engineered device. We show that two-stage training can help\naddress the unbalanced data problem common to biomedical applications where\nlarge well-annotated datasets are scarce. In conclusion, though a combination\nof simulation and transfer learning and we develop and apply a multitask\narchitecture to the problem of AF detection from wearable wrist sensors\ndemonstrating high levels of accuracy and a solution for the vexing challenge\nof mechanical noise.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:41:28 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 05:02:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Soto", "Jessica Torres", ""], ["Ashley", "Euan", ""]]}, {"id": "2001.00191", "submitter": "Jing Zhang", "authors": "Jing Zhang, Yong Zhang, Suhua Zhan, Cheng Cheng", "title": "Ensemble emotion recognizing with multiple modal physiological signals", "comments": "under review for Multimedia tools and applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physiological signals that provide the objective repression of human\naffective states are attracted increasing attention in the emotion recognition\nfield. However, the single signal is difficult to obtain completely and\naccurately description for emotion. Multiple physiological signals fusing\nmodels, building the uniform classification model by means of consistent and\ncomplementary information from different emotions to improve recognition\nperformance. Original fusing models usually choose the particular\nclassification method to recognition, which is ignoring different distribution\nof multiple signals. Aiming above problems, in this work, we propose an emotion\nclassification model through multiple modal physiological signals for different\nemotions. Features are extracted from EEG, EMG, EOG signals for characterizing\nemotional state on valence and arousal levels. For characterization, four bands\nfiltering theta, beta, alpha, gamma for signal preprocessing are adopted and\nthree Hjorth parameters are computing as features. To improve classification\nperformance, an ensemble classifier is built. Experiments are conducted on the\nbenchmark DEAP datasets. For the two-class task, the best result on arousal is\n94.42\\%, the best result on valence is 94.02\\%, respectively. For the\nfour-class task, the highest average classification accuracy is 90.74, and it\nshows good stability. The influence of different peripheral physiological\nsignals for results is also analyzed in this paper.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 11:44:43 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zhang", "Jing", ""], ["Zhang", "Yong", ""], ["Zhan", "Suhua", ""], ["Cheng", "Cheng", ""]]}, {"id": "2001.00215", "submitter": "Joshua Peeples", "authors": "Joshua Peeples, Weihuang Xu, and Alina Zare", "title": "Histogram Layers for Texture Analysis", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a histogram layer for artificial neural networks (ANNs). An\nessential aspect of texture analysis is the extraction of features that\ndescribe the distribution of values in local spatial regions. The proposed\nhistogram layer directly computes the spatial distribution of features for\ntexture analysis and parameters for the layer are estimated during\nbackpropagation. We compare our method with state-of-the-art texture encoding\nmethods such as the Deep Encoding Network Pooling (DEP), Deep Texture Encoding\nNetwork (DeepTEN), Fisher Vector convolutional neural network (FV-CNN), and\nMulti-level Texture Encoding and Representation (MuLTER) on three\nmaterial/texture datasets: (1) the Describable Texture Dataset (DTD); (2) an\nextension of the ground terrain in outdoor scenes (GTOS-mobile); (3) and a\nsubset of the Materials in Context (MINC-2500) dataset. Results indicate that\nthe inclusion of the proposed histogram layer improves performance. The source\ncode for the histogram layer is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 14:41:54 GMT"}, {"version": "v10", "created": "Thu, 22 Apr 2021 21:24:34 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:05:44 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 19:59:16 GMT"}, {"version": "v4", "created": "Wed, 25 Mar 2020 00:09:51 GMT"}, {"version": "v5", "created": "Fri, 27 Mar 2020 16:56:22 GMT"}, {"version": "v6", "created": "Mon, 30 Mar 2020 17:03:11 GMT"}, {"version": "v7", "created": "Fri, 17 Apr 2020 14:20:41 GMT"}, {"version": "v8", "created": "Wed, 22 Apr 2020 15:45:35 GMT"}, {"version": "v9", "created": "Wed, 6 Jan 2021 01:40:47 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Peeples", "Joshua", ""], ["Xu", "Weihuang", ""], ["Zare", "Alina", ""]]}, {"id": "2001.00218", "submitter": "Thiago Serra", "authors": "Thiago Serra, Abhinav Kumar, Srikumar Ramalingam", "title": "Lossless Compression of Deep Neural Networks", "comments": "CPAIOR 2020 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been successful in many predictive modeling tasks,\nsuch as image and language recognition, where large neural networks are often\nused to obtain good accuracy. Consequently, it is challenging to deploy these\nnetworks under limited computational resources, such as in mobile devices. In\nthis work, we introduce an algorithm that removes units and layers of a neural\nnetwork while not changing the output that is produced, which thus implies a\nlossless compression. This algorithm, which we denote as LEO (Lossless\nExpressiveness Optimization), relies on Mixed-Integer Linear Programming (MILP)\nto identify Rectified Linear Units (ReLUs) with linear behavior over the input\ndomain. By using L1 regularization to induce such behavior, we can benefit from\ntraining over a larger architecture than we would later use in the environment\nwhere the trained neural network is deployed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 15:04:43 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:19:36 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 16:09:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Serra", "Thiago", ""], ["Kumar", "Abhinav", ""], ["Ramalingam", "Srikumar", ""]]}, {"id": "2001.00234", "submitter": "Ramin Ayanzadeh", "authors": "Ramin Ayanzadeh, Milton Halem and Tim Finin", "title": "Reinforcement Quantum Annealing: A Quantum-Assisted Learning Automata\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the reinforcement quantum annealing (RQA) scheme in which an\nintelligent agent interacts with a quantum annealer that plays the stochastic\nenvironment role of learning automata and tries to iteratively find better\nIsing Hamiltonians for the given problem of interest. As a proof-of-concept, we\npropose a novel approach for reducing the NP-complete problem of Boolean\nsatisfiability (SAT) to minimizing Ising Hamiltonians and show how to apply the\nRQA for increasing the probability of finding the global optimum. Our\nexperimental results on two different benchmark SAT problems (namely factoring\npseudo-prime numbers and random SAT with phase transitions), using a D-Wave\n2000Q quantum processor, demonstrated that RQA finds notably better solutions\nwith fewer samples, compared to state-of-the-art techniques in the realm of\nquantum annealing.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 16:41:58 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ayanzadeh", "Ramin", ""], ["Halem", "Milton", ""], ["Finin", "Tim", ""]]}, {"id": "2001.00236", "submitter": "Shubham Goswami", "authors": "Donghoon Chang (1), Vinjohn Chirakkal (2), Shubham Goswami (3),\n  Munawar Hasan (1), Taekwon Jung (2), Jinkeon Kang (1,3), Seok-Cheol Kee (4),\n  Dongkyu Lee (5), Ajit Pratap Singh (1) ((1) Department of Computer Science,\n  IIIT-Delhi, India, (2) Springcloud Inc., Korea, (3) Center for Information\n  Security Technologies (CIST), Korea University, Korea, (4) Smart Car Research\n  Center, Chungbuk National University, Korea, (5) Department of Smart Car\n  Engineering, Chungbuk National University, Korea)", "title": "Multi-lane Detection Using Instance Segmentation and Attentive Voting", "comments": "Accepted in ICCAS 2019 - The 19th International Conference on\n  Control, Automation and Systems, Corresponding Author: Shubham Goswami", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous driving is becoming one of the leading industrial research areas.\nTherefore many automobile companies are coming up with semi to fully autonomous\ndriving solutions. Among these solutions, lane detection is one of the vital\ndriver-assist features that play a crucial role in the decision-making process\nof the autonomous vehicle. A variety of solutions have been proposed to detect\nlanes on the road, which ranges from using hand-crafted features to the\nstate-of-the-art end-to-end trainable deep learning architectures. Most of\nthese architectures are trained in a traffic constrained environment. In this\npaper, we propose a novel solution to multi-lane detection, which outperforms\nstate of the art methods in terms of both accuracy and speed. To achieve this,\nwe also offer a dataset with a more intuitive labeling scheme as compared to\nother benchmark datasets. Using our approach, we are able to obtain a lane\nsegmentation accuracy of 99.87% running at 54.53 fps (average).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 16:48:42 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chang", "Donghoon", ""], ["Chirakkal", "Vinjohn", ""], ["Goswami", "Shubham", ""], ["Hasan", "Munawar", ""], ["Jung", "Taekwon", ""], ["Kang", "Jinkeon", ""], ["Kee", "Seok-Cheol", ""], ["Lee", "Dongkyu", ""], ["Singh", "Ajit Pratap", ""]]}, {"id": "2001.00248", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Hyunjae Woo, Jongwook Choi, Honglak Lee", "title": "Meta Reinforcement Learning with Autonomous Inference of Subtask\n  Dependencies", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and address a novel few-shot RL problem, where a task is\ncharacterized by a subtask graph which describes a set of subtasks and their\ndependencies that are unknown to the agent. The agent needs to quickly adapt to\nthe task over few episodes during adaptation phase to maximize the return in\nthe test phase. Instead of directly learning a meta-policy, we develop a\nMeta-learner with Subtask Graph Inference(MSGI), which infers the latent\nparameter of the task by interacting with the environment and maximizes the\nreturn given the latent parameter. To facilitate learning, we adopt an\nintrinsic reward inspired by upper confidence bound (UCB) that encourages\nefficient exploration. Our experiment results on two grid-world domains and\nStarCraft II environments show that the proposed method is able to accurately\ninfer the latent task parameter, and to adapt more efficiently than existing\nmeta RL and hierarchical RL methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:34:00 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 01:44:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sohn", "Sungryull", ""], ["Woo", "Hyunjae", ""], ["Choi", "Jongwook", ""], ["Lee", "Honglak", ""]]}, {"id": "2001.00254", "submitter": "Zhaodong Chen", "authors": "Zhaodong Chen, Lei Deng, Bangyan Wang, Guoqi Li, Yuan Xie", "title": "A Comprehensive and Modularized Statistical Framework for Gradient Norm\n  Equality in Deep Neural Networks", "comments": "Under review as a regular paper in TPAMI", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  2020", "doi": "10.1109/TPAMI.2020.3010201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, plenty of metrics have been proposed to identify networks\nthat are free of gradient explosion and vanishing. However, due to the\ndiversity of network components and complex serial-parallel hybrid connections\nin modern DNNs, the evaluation of existing metrics usually requires strong\nassumptions, complex statistical analysis, or has limited application fields,\nwhich constraints their spread in the community. In this paper, inspired by the\nGradient Norm Equality and dynamical isometry, we first propose a novel metric\ncalled Block Dynamical Isometry, which measures the change of gradient norm in\nindividual block. Because our Block Dynamical Isometry is norm-based, its\nevaluation needs weaker assumptions compared with the original dynamical\nisometry. To mitigate the challenging derivation, we propose a highly\nmodularized statistical framework based on free probability. Our framework\nincludes several key theorems to handle complex serial-parallel hybrid\nconnections and a library to cover the diversity of network components.\nBesides, several sufficient prerequisites are provided. Powered by our metric\nand framework, we analyze extensive initialization, normalization, and network\nstructures. We find that Gradient Norm Equality is a universal philosophy\nbehind them. Then, we improve some existing methods based on our analysis,\nincluding an activation function selection strategy for initialization\ntechniques, a new configuration for weight normalization, and a depth-aware way\nto derive coefficients in SeLU. Moreover, we propose a novel normalization\ntechnique named second moment normalization, which is theoretically 30% faster\nthan batch normalization without accuracy loss. Last but not least, our\nconclusions and methods are evidenced by extensive experiments on multiple\nmodels over CIFAR10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:56:49 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Zhaodong", ""], ["Deng", "Lei", ""], ["Wang", "Bangyan", ""], ["Li", "Guoqi", ""], ["Xie", "Yuan", ""]]}, {"id": "2001.00258", "submitter": "Avinash Kori", "authors": "Mahendra Khened, Avinash Kori, Haran Rajkumar, Balaji Srinivasan,\n  Ganapathy Krishnamurthi", "title": "A Generalized Deep Learning Framework for Whole-Slide Image Segmentation\n  and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.TO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Histopathology tissue analysis is considered the gold standard in cancer\ndiagnosis and prognosis. Given the large size of these images and the increase\nin the number of potential cancer cases, an automated solution as an aid to\nhistopathologists is highly desirable. In the recent past, deep learning-based\ntechniques have provided state of the art results in a wide variety of image\nanalysis tasks, including analysis of digitized slides. However, the size of\nimages and variability in histopathology tasks makes it a challenge to develop\nan integrated framework for histopathology image analysis. We propose a deep\nlearning-based framework for histopathology tissue analysis. We demonstrate the\ngeneralizability of our framework, including training and inference, on several\nopen-source datasets, which include CAMELYON (breast cancer metastases),\nDigestPath (colon cancer), and PAIP (liver cancer) datasets. We discuss\nmultiple types of uncertainties pertaining to data and model, namely aleatoric\nand epistemic, respectively. Simultaneously, we demonstrate our model\ngeneralization across different data distribution by evaluating some samples on\nTCGA data. On CAMELYON16 test data (n=139) for the task of lesion detection,\nthe FROC score achieved was 0.86 and in the CAMELYON17 test-data (n=500) for\nthe task of pN-staging the Cohen's kappa score achieved was 0.9090 (third in\nthe open leaderboard). On DigestPath test data (n=212) for the task of tumor\nsegmentation, a Dice score of 0.782 was achieved (fourth in the challenge). On\nPAIP test data (n=40) for the task of viable tumor segmentation, a Jaccard\nIndex of 0.75 (third in the challenge) was achieved, and for viable tumor\nburden, a score of 0.633 was achieved (second in the challenge). Our entire\nframework and related documentation are freely available at GitHub and PyPi.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 18:05:44 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 08:29:35 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Khened", "Mahendra", ""], ["Kori", "Avinash", ""], ["Rajkumar", "Haran", ""], ["Srinivasan", "Balaji", ""], ["Krishnamurthi", "Ganapathy", ""]]}, {"id": "2001.00265", "submitter": "Kan Li PhD", "authors": "Kan Li and Jose C. Principe", "title": "Fast Estimation of Information Theoretic Learning Descriptors using\n  Explicit Inner Product Spaces", "comments": "10 pages, 3 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:1912.04530", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods form a theoretically-grounded, powerful and versatile\nframework to solve nonlinear problems in signal processing and machine\nlearning. The standard approach relies on the \\emph{kernel trick} to perform\npairwise evaluations of a kernel function, leading to scalability issues for\nlarge datasets due to its linear and superlinear growth with respect to the\ntraining data. Recently, we proposed \\emph{no-trick} (NT) kernel adaptive\nfiltering (KAF) that leverages explicit feature space mappings using\ndata-independent basis with constant complexity. The inner product defined by\nthe feature mapping corresponds to a positive-definite finite-rank kernel that\ninduces a finite-dimensional reproducing kernel Hilbert space (RKHS).\nInformation theoretic learning (ITL) is a framework where information theory\ndescriptors based on non-parametric estimator of Renyi entropy replace\nconventional second-order statistics for the design of adaptive systems. An\nRKHS for ITL defined on a space of probability density functions simplifies\nstatistical inference for supervised or unsupervised learning. ITL criteria\ntake into account the higher-order statistical behavior of the systems and\nsignals as desired. However, this comes at a cost of increased computational\ncomplexity. In this paper, we extend the NT kernel concept to ITL for improved\ninformation extraction from the signal without compromising scalability.\nSpecifically, we focus on a family of fast, scalable, and accurate estimators\nfor ITL using explicit inner product space (EIPS) kernels. We demonstrate the\nsuperior performance of EIPS-ITL estimators and combined NT-KAF using EIPS-ITL\ncost functions through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 20:21:12 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Li", "Kan", ""], ["Principe", "Jose C.", ""]]}, {"id": "2001.00271", "submitter": "Khimya Khetarpal", "authors": "Khimya Khetarpal, Martin Klissarov, Maxime Chevalier-Boisvert,\n  Pierre-Luc Bacon, Doina Precup", "title": "Options of Interest: Temporal Abstraction with Interest Functions", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstraction refers to the ability of an agent to use behaviours of\ncontrollers which act for a limited, variable amount of time. The options\nframework describes such behaviours as consisting of a subset of states in\nwhich they can initiate, an internal policy and a stochastic termination\ncondition. However, much of the subsequent work on option discovery has ignored\nthe initiation set, because of difficulty in learning it from data. We provide\na generalization of initiation sets suitable for general function\napproximation, by defining an interest function associated with an option. We\nderive a gradient-based learning algorithm for interest functions, leading to a\nnew interest-option-critic architecture. We investigate how interest functions\ncan be leveraged to learn interpretable and reusable temporal abstractions. We\ndemonstrate the efficacy of the proposed approach through quantitative and\nqualitative results, in both discrete and continuous environments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 21:24:39 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Khetarpal", "Khimya", ""], ["Klissarov", "Martin", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bacon", "Pierre-Luc", ""], ["Precup", "Doina", ""]]}, {"id": "2001.00278", "submitter": "Guilherme Vituri Fernandes Pinto", "authors": "Facundo M\\'emoli, Guilherme Vituri F. Pinto", "title": "Motivic clustering schemes for directed graphs", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the concept of network motifs we construct certain clustering\nmethods (functors) which are parametrized by a given collection of motifs (or\nrepresenters).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 23:30:00 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 16:37:03 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["M\u00e9moli", "Facundo", ""], ["Pinto", "Guilherme Vituri F.", ""]]}, {"id": "2001.00279", "submitter": "Alberto Iess", "authors": "Alberto Iess, Elena Cuoco, Filip Morawski and Jade Powell", "title": "Core-Collapse Supernova Gravitational-Wave Search and Deep Learning\n  Classification", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a search and classification procedure for gravitational waves\nemitted by core-collapse supernova (CCSN) explosions, using a convolutional\nneural network (CNN) combined with an event trigger generator known as Wavelet\nDetection Filter (WDF). We employ both a 1-D CNN search using time series\ngravitational-wave data as input, and a 2-D CNN search with time-frequency\nrepresentation of the data as input. To test the accuracies of our 1-D and 2-D\nCNN classification, we add CCSN waveforms from the most recent hydrodynamical\nsimulations of neutrino-driven core-collapse to simulated Gaussian colored\nnoise with the Virgo interferometer and the planned Einstein Telescope\nsensitivity curve. We find classification accuracies, for a single detector, of\nover 95% for both 1-D and 2-D CNN pipelines. For the first time in machine\nlearning CCSN studies, we add short duration detector noise transients to our\ndata to test the robustness of our method against false alarms created by\ndetector noise artifacts. Further to this, we show that the CNN can distinguish\nbetween different types of CCSN waveform models.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 23:32:55 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Iess", "Alberto", ""], ["Cuoco", "Elena", ""], ["Morawski", "Filip", ""], ["Powell", "Jade", ""]]}, {"id": "2001.00288", "submitter": "Chandresh Maurya", "authors": "Chandresh Kumar Maurya, Neelamadhav Gantayat, Sampath Dechu, Tomas\n  Horvath", "title": "Online Similarity Learning with Feedback for Invoice Line Item Matching", "comments": null, "journal-ref": "published as workshop paper in AAAI workshop on intelligent\n  processing automation, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The procure to pay process (P2P) in large enterprises is a back-end business\nprocess which deals with the procurement of products and services for\nenterprise operations. Procurement is done by issuing purchase orders to\nimpaneled vendors and invoices submitted by vendors are paid after they go\nthrough a rigorous validation process. Agents orchestrating P2P process often\nencounter the problem of matching a product or service descriptions in the\ninvoice to those in purchase order and verify if the ordered items are what\nhave been supplied or serviced. For example, the description in the invoice and\npurchase order could be TRES 739mL CD KER Smooth and TRES 0.739L CD KER Smth\nwhich look different at word level but refer to the same item. In a typical P2P\nprocess, agents are asked to manually select the products which are similar\nbefore invoices are posted for payment. This step in the business process is\nmanual, repetitive, cumbersome, and costly. Since descriptions are not\nwell-formed sentences, we cannot apply existing semantic and syntactic text\nsimilarity approaches directly. In this paper, we present two approaches to\nsolve the above problem using various types of available agent's recorded\nfeedback data. If the agent's feedback is in the form of a relative ranking\nbetween descriptions, we use similarity ranking algorithm. If the agent's\nfeedback is absolute such as match or no-match, we use classification\nsimilarity algorithm. We also present the threats to the validity of our\napproach and present a possible remedy making use of product taxonomy and\ncatalog. We showcase the comparative effectiveness and efficiency of the\nproposed approaches over many benchmarks and real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 01:28:56 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:26:30 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Maurya", "Chandresh Kumar", ""], ["Gantayat", "Neelamadhav", ""], ["Dechu", "Sampath", ""], ["Horvath", "Tomas", ""]]}, {"id": "2001.00293", "submitter": "Xin Wang", "authors": "Wenwu Zhu, Xin Wang, Peng Cui", "title": "Deep Learning for Learning Graph Representations", "comments": "51 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-31756-0_6", "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining graph data has become a popular research topic in computer science and\nhas been widely studied in both academia and industry given the increasing\namount of network data in the recent years. However, the huge amount of network\ndata has posed great challenges for efficient analysis. This motivates the\nadvent of graph representation which maps the graph into a low-dimension vector\nspace, keeping original graph structure and supporting graph inference. The\ninvestigation on efficient representation of a graph has profound theoretical\nsignificance and important realistic meaning, we therefore introduce some basic\nideas in graph representation/network embedding as well as some representative\nmodels in this chapter.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 02:13:28 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zhu", "Wenwu", ""], ["Wang", "Xin", ""], ["Cui", "Peng", ""]]}, {"id": "2001.00308", "submitter": "Pooyan Jamshidi", "authors": "Ying Meng, Jianhai Su, Jason O'Kane, Pooyan Jamshidi", "title": "ATHENA: A Framework based on Diverse Weak Defenses for Building\n  Adversarial Defense", "comments": "18 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been extensive research on developing defense techniques against\nadversarial attacks; however, they have been mainly designed for specific model\nfamilies or application domains, therefore, they cannot be easily extended.\nBased on the design philosophy of ensemble of diverse weak defenses, we propose\nATHENA---a flexible and extensible framework for building generic yet effective\ndefenses against adversarial attacks. We have conducted a comprehensive\nempirical study to evaluate several realizations of ATHENA with four threat\nmodels including zero-knowledge, black-box, gray-box, and white-box. We also\nexplain (i) why diversity matters, (ii) the generality of the defense\nframework, and (iii) the overhead costs incurred by ATHENA.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 03:20:57 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:11:24 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Meng", "Ying", ""], ["Su", "Jianhai", ""], ["O'Kane", "Jason", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2001.00329", "submitter": "Dallas Card", "authors": "Dallas Card and Noah A. Smith", "title": "On Consequentialism and Fairness", "comments": "Updating to published version", "journal-ref": "Front. Artif. Intell., 08 May 2020", "doi": "10.3389/frai.2020.00034", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on fairness in machine learning has primarily emphasized how to\ndefine, quantify, and encourage \"fair\" outcomes. Less attention has been paid,\nhowever, to the ethical foundations which underlie such efforts. Among the\nethical perspectives that should be taken into consideration is\nconsequentialism, the position that, roughly speaking, outcomes are all that\nmatter. Although consequentialism is not free from difficulties, and although\nit does not necessarily provide a tractable way of choosing actions (because of\nthe combined problems of uncertainty, subjectivity, and aggregation), it\nnevertheless provides a powerful foundation from which to critique the existing\nliterature on machine learning fairness. Moreover, it brings to the fore some\nof the tradeoffs involved, including the problem of who counts, the pros and\ncons of using a policy, and the relative value of the distant future. In this\npaper we provide a consequentialist critique of common definitions of fairness\nwithin machine learning, as well as a machine learning perspective on\nconsequentialism. We conclude with a broader discussion of the issues of\nlearning and randomization, which have important implications for the ethics of\nautomated decision making systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 05:39:48 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 04:36:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Card", "Dallas", ""], ["Smith", "Noah A.", ""]]}, {"id": "2001.00342", "submitter": "Kyungchun Lee Prof.", "authors": "Doyeon Weon and Kyungchun Lee", "title": "Learning-Aided Deep Path Prediction for Sphere Decoding in Large MIMO\n  Systems", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel learning-aided sphere decoding (SD) scheme\nfor large multiple-input--multiple-output systems, namely, deep path\nprediction-based sphere decoding (DPP-SD). In this scheme, we employ a neural\nnetwork (NN) to predict the minimum metrics of the ``deep'' paths in sub-trees\nbefore commencing the tree search in SD. To reduce the complexity of the NN, we\nemploy the input vector with a reduced dimension rather than using the original\nreceived signals and full channel matrix. The outputs of the NN, i.e., the\npredicted minimum path metrics, are exploited to determine the search order\nbetween the sub-trees, as well as to optimize the initial search radius, which\nmay reduce the computational complexity of SD. For further complexity\nreduction, an early termination scheme based on the predicted minimum path\nmetrics is also proposed. Our simulation results show that the proposed DPP-SD\nscheme provides a significant reduction in computational complexity compared\nwith the conventional SD algorithm, despite achieving near-optimal performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:05:40 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Weon", "Doyeon", ""], ["Lee", "Kyungchun", ""]]}, {"id": "2001.00345", "submitter": "Kisor Sahu Dr.", "authors": "Raj Kishore, S. Swayamjyoti, Shreeja Das, Ajay K. Gogineni, Zohar\n  Nussinov, D. Solenov, Kisor K. Sahu", "title": "Visual Machine Learning: Insight through Eigenvectors, Chladni patterns\n  and community detection in 2D particulate structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.soft stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is quickly emerging as a powerful tool with diverse\napplications across an extremely broad spectrum of disciplines and commercial\nendeavors. Typically, ML is used as a black box that provides little\nilluminating rationalization of its output. In the current work, we aim to\nbetter understand the generic intuition underlying unsupervised ML with a focus\non physical systems. The systems that are studied here as test cases comprise\nof six different 2-dimensional (2-D) particulate systems of different\ncomplexities. It is noted that the findings of this study are generic to any\nunsupervised ML problem and are not restricted to materials systems alone.\nThree rudimentary unsupervised ML techniques are employed on the adjacency\n(connectivity) matrix of the six studied systems: (i) using principal\neigenvalue and eigenvectors of the adjacency matrix, (ii) spectral\ndecomposition, and (iii) a Potts model based community detection technique in\nwhich a modularity function is maximized. We demonstrate that, while solving a\ncompletely classical problem, ML technique produces features that are\ndistinctly connected to quantum mechanical solutions. Dissecting these features\nhelp us to understand the deep connection between the classical non-linear\nworld and the quantum mechanical linear world through the kaleidoscope of ML\ntechnique, which might have far reaching consequences both in the arena of\nphysical sciences and ML.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:20:28 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kishore", "Raj", ""], ["Swayamjyoti", "S.", ""], ["Das", "Shreeja", ""], ["Gogineni", "Ajay K.", ""], ["Nussinov", "Zohar", ""], ["Solenov", "D.", ""], ["Sahu", "Kisor K.", ""]]}, {"id": "2001.00360", "submitter": "Cong Chen", "authors": "Cong Chen, Kim Batselier, Wenjian Yu, Ngai Wong", "title": "Kernelized Support Tensor Train Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor, a multi-dimensional data structure, has been exploited recently in\nthe machine learning community. Traditional machine learning approaches are\nvector- or matrix-based, and cannot handle tensorial data directly. In this\npaper, we propose a tensor train (TT)-based kernel technique for the first\ntime, and apply it to the conventional support vector machine (SVM) for image\nclassification. Specifically, we propose a kernelized support tensor train\nmachine that accepts tensorial input and preserves the intrinsic kernel\nproperty. The main contributions are threefold. First, we propose a TT-based\nfeature mapping procedure that maintains the TT structure in the feature space.\nSecond, we demonstrate two ways to construct the TT-based kernel function while\nconsidering consistency with the TT inner product and preservation of\ninformation. Third, we show that it is possible to apply different kernel\nfunctions on different data modes. In principle, our method tensorizes the\nstandard SVM on its input structure and kernel mapping scheme. Extensive\nexperiments are performed on real-world tensor data, which demonstrates the\nsuperiority of the proposed scheme under few-sample high-dimensional inputs.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 08:40:15 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chen", "Cong", ""], ["Batselier", "Kim", ""], ["Yu", "Wenjian", ""], ["Wong", "Ngai", ""]]}, {"id": "2001.00378", "submitter": "Siddique Latif", "authors": "Siddique Latif, Rajib Rana, Sara Khalifa, Raja Jurdak, Junaid Qadir,\n  and Bj\\\"orn W. Schuller", "title": "Deep Representation Learning in Speech Processing: Challenges, Recent\n  Advances, and Future Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on speech processing has traditionally considered the task of\ndesigning hand-engineered acoustic features (feature engineering) as a separate\ndistinct problem from the task of designing efficient machine learning (ML)\nmodels to make prediction and classification decisions. There are two main\ndrawbacks to this approach: firstly, the feature engineering being manual is\ncumbersome and requires human knowledge; and secondly, the designed features\nmight not be best for the objective at hand. This has motivated the adoption of\na recent trend in speech community towards utilisation of representation\nlearning techniques, which can learn an intermediate representation of the\ninput signal automatically that better suits the task at hand and hence lead to\nimproved performance. The significance of representation learning has increased\nwith advances in deep learning (DL), where the representations are more useful\nand less dependent on human knowledge, making it very conducive for tasks like\nclassification, prediction, etc. The main contribution of this paper is to\npresent an up-to-date and comprehensive survey on different techniques of\nspeech representation learning by bringing together the scattered research\nacross three distinct research areas including Automatic Speech Recognition\n(ASR), Speaker Recognition (SR), and Speaker Emotion Recognition (SER). Recent\nreviews in speech have been conducted for ASR, SR, and SER, however, none of\nthese has focused on the representation learning from speech---a gap that our\nsurvey aims to bridge.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 10:12:23 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Latif", "Siddique", ""], ["Rana", "Rajib", ""], ["Khalifa", "Sara", ""], ["Jurdak", "Raja", ""], ["Qadir", "Junaid", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2001.00391", "submitter": "Rongzhi Gu", "authors": "Rongzhi Gu and Yuexian Zou", "title": "Temporal-Spatial Neural Filter: Direction Informed End-to-End\n  Multi-channel Target Speech Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target speech separation refers to extracting the target speaker's speech\nfrom mixed signals. Despite the recent advances in deep learning based\nclose-talk speech separation, the applications to real-world are still an open\nissue. Two main challenges are the complex acoustic environment and the\nreal-time processing requirement. To address these challenges, we propose a\ntemporal-spatial neural filter, which directly estimates the target speech\nwaveform from multi-speaker mixture in reverberant environments, assisted with\ndirectional information of the speaker(s). Firstly, against variations brought\nby complex environment, the key idea is to increase the acoustic representation\ncompleteness through the jointly modeling of temporal, spectral and spatial\ndiscriminability between the target and interference source. Specifically,\ntemporal, spectral, spatial along with the designed directional features are\nintegrated to create a joint acoustic representation. Secondly, to reduce the\nlatency, we design a fully-convolutional autoencoder framework, which is purely\nend-to-end and single-pass. All the feature computation is implemented by the\nnetwork layers and operations to speed up the separation procedure. Evaluation\nis conducted on simulated reverberant dataset WSJ0-2mix and WSJ0-3mix under\nspeaker-independent scenario. Experimental results demonstrate that the\nproposed method outperforms state-of-the-art deep learning based multi-channel\napproaches with fewer parameters and faster processing speed. Furthermore, the\nproposed temporal-spatial neural filter can handle mixtures with varying and\nunknown number of speakers and exhibits persistent performance even when\nexisting a direction estimation error. Codes and models will be released soon.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 11:12:50 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Gu", "Rongzhi", ""], ["Zou", "Yuexian", ""]]}, {"id": "2001.00396", "submitter": "Leon Sixt", "authors": "Karl Schulz, Leon Sixt, Federico Tombari, Tim Landgraf", "title": "Restricting the Flow: Information Bottlenecks for Attribution", "comments": "18 pages, 12 figures, accepted at ICLR 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods provide insights into the decision-making of machine\nlearning models like artificial neural networks. For a given input sample, they\nassign a relevance score to each individual input variable, such as the pixels\nof an image. In this work we adapt the information bottleneck concept for\nattribution. By adding noise to intermediate feature maps we restrict the flow\nof information and can quantify (in bits) how much information image regions\nprovide. We compare our method against ten baselines using three different\nmetrics on VGG-16 and ResNet-50, and find that our methods outperform all\nbaselines in five out of six settings. The method's information-theoretic\nfoundation provides an absolute frame of reference for attribution values\n(bits) and a guarantee that regions scored close to zero are not necessary for\nthe network's decision. For reviews: https://openreview.net/forum?id=S1xWh1rYwB\nFor code: https://github.com/BioroboticsLab/IBA\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 11:24:35 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 18:37:23 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 17:31:52 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 14:21:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Schulz", "Karl", ""], ["Sixt", "Leon", ""], ["Tombari", "Federico", ""], ["Landgraf", "Tim", ""]]}, {"id": "2001.00426", "submitter": "Ljubisa Stankovic", "authors": "Ljubisa Stankovic, Danilo Mandic, Milos Dakovic, Milos Brajovic, Bruno\n  Scalzo, Shengxi Li, Anthony G. Constantinides", "title": "Graph Signal Processing -- Part III: Machine Learning on Graphs, from\n  Graph Topology to Applications", "comments": "61 pages, 55 figures, 40 examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern data analytics applications on graphs operate on domains where\ngraph topology is not known a priori, and hence its determination becomes part\nof the problem definition, rather than serving as prior knowledge which aids\nthe problem solution. Part III of this monograph starts by addressing ways to\nlearn graph topology, from the case where the physics of the problem already\nsuggest a possible topology, through to most general cases where the graph\ntopology is learned from the data. A particular emphasis is on graph topology\ndefinition based on the correlation and precision matrices of the observed\ndata, combined with additional prior knowledge and structural conditions, such\nas the smoothness or sparsity of graph connections. For learning sparse graphs\n(with small number of edges), the least absolute shrinkage and selection\noperator, known as LASSO is employed, along with its graph specific variant,\ngraphical LASSO. For completeness, both variants of LASSO are derived in an\nintuitive way, and explained. An in-depth elaboration of the graph topology\nlearning paradigm is provided through several examples on physically well\ndefined graphs, such as electric circuits, linear heat transfer, social and\ncomputer networks, and spring-mass systems. As many graph neural networks (GNN)\nand convolutional graph networks (GCN) are emerging, we have also reviewed the\nmain trends in GNNs and GCNs, from the perspective of graph signal filtering.\nTensor representation of lattice-structured graphs is next considered, and it\nis shown that tensors (multidimensional data arrays) are a special class of\ngraph signals, whereby the graph vertices reside on a high-dimensional regular\nlattice structure. This part of monograph concludes with two emerging\napplications in financial data processing and underground transportation\nnetworks modeling.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 13:14:27 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Stankovic", "Ljubisa", ""], ["Mandic", "Danilo", ""], ["Dakovic", "Milos", ""], ["Brajovic", "Milos", ""], ["Scalzo", "Bruno", ""], ["Li", "Shengxi", ""], ["Constantinides", "Anthony G.", ""]]}, {"id": "2001.00448", "submitter": "Nishai Kooverjee", "authors": "Nishai Kooverjee, Steven James, Terence van Zyl", "title": "Inter- and Intra-domain Knowledge Transfer for Related Tasks in Deep\n  Character Recognition", "comments": "To be published in SAUPEC/RobMech/PRASA 2020. Consists of 6 pages,\n  with 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training a deep neural network on the ImageNet dataset is a common\npractice for training deep learning models, and generally yields improved\nperformance and faster training times. The technique of pre-training on one\ntask and then retraining on a new one is called transfer learning. In this\npaper we analyse the effectiveness of using deep transfer learning for\ncharacter recognition tasks. We perform three sets of experiments with varying\nlevels of similarity between source and target tasks to investigate the\nbehaviour of different types of knowledge transfer. We transfer both parameters\nand features and analyse their behaviour. Our results demonstrate that no\nsignificant advantage is gained by using a transfer learning approach over a\ntraditional machine learning approach for our character recognition tasks. This\nsuggests that using transfer learning does not necessarily presuppose a better\nperforming model in all cases.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:18:25 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kooverjee", "Nishai", ""], ["James", "Steven", ""], ["van Zyl", "Terence", ""]]}, {"id": "2001.00449", "submitter": "Michael Neunert", "authors": "Michael Neunert, Abbas Abdolmaleki, Markus Wulfmeier, Thomas Lampe,\n  Jost Tobias Springenberg, Roland Hafner, Francesco Romano, Jonas Buchli,\n  Nicolas Heess, Martin Riedmiller", "title": "Continuous-Discrete Reinforcement Learning for Hybrid Control in\n  Robotics", "comments": "Presented at the 3rd Conference on Robot Learning (CoRL 2019), Osaka,\n  Japan. Video: https://youtu.be/eUqQDLQXb7I", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world control problems involve both discrete decision variables -\nsuch as the choice of control modes, gear switching or digital outputs - as\nwell as continuous decision variables - such as velocity setpoints, control\ngains or analogue outputs. However, when defining the corresponding optimal\ncontrol or reinforcement learning problem, it is commonly approximated with\nfully continuous or fully discrete action spaces. These simplifications aim at\ntailoring the problem to a particular algorithm or solver which may only\nsupport one type of action space. Alternatively, expert heuristics are used to\nremove discrete actions from an otherwise continuous space. In contrast, we\npropose to treat hybrid problems in their 'native' form by solving them with\nhybrid reinforcement learning, which optimizes for discrete and continuous\nactions simultaneously. In our experiments, we first demonstrate that the\nproposed approach efficiently solves such natively hybrid reinforcement\nlearning problems. We then show, both in simulation and on robotic hardware,\nthe benefits of removing possibly imperfect expert-designed heuristics. Lastly,\nhybrid reinforcement learning encourages us to rethink problem definitions. We\npropose reformulating control problems, e.g. by adding meta actions, to improve\nexploration or reduce mechanical wear and tear.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:19:33 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Neunert", "Michael", ""], ["Abdolmaleki", "Abbas", ""], ["Wulfmeier", "Markus", ""], ["Lampe", "Thomas", ""], ["Springenberg", "Jost Tobias", ""], ["Hafner", "Roland", ""], ["Romano", "Francesco", ""], ["Buchli", "Jonas", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2001.00461", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Reasoning on Knowledge Graphs with Debate Dynamics", "comments": "AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for automatic reasoning on knowledge graphs based\non debate dynamics. The main idea is to frame the task of triple classification\nas a debate game between two reinforcement learning agents which extract\narguments -- paths in the knowledge graph -- with the goal to promote the fact\nbeing true (thesis) or the fact being false (antithesis), respectively. Based\non these arguments, a binary classifier, called the judge, decides whether the\nfact is true or false. The two agents can be considered as sparse, adversarial\nfeature generators that present interpretable evidence for either the thesis or\nthe antithesis. In contrast to other black-box methods, the arguments allow\nusers to get an understanding of the decision of the judge. Since the focus of\nthis work is to create an explainable method that maintains a competitive\npredictive accuracy, we benchmark our method on the triple classification and\nlink prediction task. Thereby, we find that our method outperforms several\nbaselines on the benchmark datasets FB15k-237, WN18RR, and Hetionet. We also\nconduct a survey and find that the extracted arguments are informative for\nusers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 14:44:23 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.00479", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli and Lenka Zdeborova", "title": "Thresholds of descending algorithms in inference problems", "comments": "8 pages, 4 figures", "journal-ref": "J. Stat. Mech. (2020) 034004", "doi": "10.1088/1742-5468/ab7123", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review recent works on analyzing the dynamics of gradient-based algorithms\nin a prototypical statistical inference problem. Using methods and insights\nfrom the physics of glassy systems, these works showed how to understand\nquantitatively and qualitatively the performance of gradient-based algorithms.\nHere we review the key results and their interpretation in non-technical terms\naccessible to a wide audience of physicists in the context of related works.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:08:40 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 08:53:20 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Zdeborova", "Lenka", ""]]}, {"id": "2001.00483", "submitter": "Xin Wang", "authors": "Xin Wang", "title": "Reject Illegal Inputs with Generative Classifier Derived from Any\n  Discriminative Classifier", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative classifiers have been shown promising to detect illegal inputs\nincluding adversarial examples and out-of-distribution samples. Supervised Deep\nInfomax~(SDIM) is a scalable end-to-end framework to learn generative\nclassifiers. In this paper, we propose a modification of SDIM termed\nSDIM-\\emph{logit}. Instead of training generative classifier from scratch,\nSDIM-\\emph{logit} first takes as input the logits produced any given\ndiscriminative classifier, and generate logit representations; then a\ngenerative classifier is derived by imposing statistical constraints on logit\nrepresentations. SDIM-\\emph{logit} could inherit the performance of the\ndiscriminative classifier without loss. SDIM-\\emph{logit} incurs a negligible\nnumber of additional parameters, and can be efficiently trained with base\nclassifiers fixed. We perform \\emph{classification with rejection}, where test\nsamples whose class conditionals are smaller than pre-chosen thresholds will be\nrejected without predictions. Experiments on illegal inputs, including\nadversarial examples, samples with common corruptions, and\nout-of-distribution~(OOD) samples show that allowed to reject a portion of test\nsamples, SDIM-\\emph{logit} significantly improves the performance on the left\ntest sets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:11:58 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Wang", "Xin", ""]]}, {"id": "2001.00493", "submitter": "Ruiyuan Gao", "authors": "Ruiyuan Gao, Ming Dun, Hailong Yang, Zhongzhi Luan, Depei Qian", "title": "Privacy for Rescue: A New Testimony Why Privacy is Vulnerable In Deep\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge computation demand of deep learning models and limited computation\nresources on the edge devices calls for the cooperation between edge device and\ncloud service by splitting the deep models into two halves. However,\ntransferring the intermediates results from the partial models between edge\ndevice and cloud service makes the user privacy vulnerable since the attacker\ncan intercept the intermediate results and extract privacy information from\nthem. Existing research works rely on metrics that are either impractical or\ninsufficient to measure the effectiveness of privacy protection methods in the\nabove scenario, especially from the aspect of a single user. In this paper, we\nfirst present a formal definition of the privacy protection problem in the\nedge-cloud system running DNN models. Then, we analyze the-state-of-the-art\nmethods and point out the drawbacks of their methods, especially the evaluation\nmetrics such as the Mutual Information (MI). In addition, we perform several\nexperiments to demonstrate that although existing methods perform well under\nMI, they are not effective enough to protect the privacy of a single user. To\naddress the drawbacks of the evaluation metrics, we propose two new metrics\nthat are more accurate to measure the effectiveness of privacy protection\nmethods. Finally, we highlight several potential research directions to\nencourage future efforts addressing the privacy protection problem.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 15:55:03 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Gao", "Ruiyuan", ""], ["Dun", "Ming", ""], ["Yang", "Hailong", ""], ["Luan", "Zhongzhi", ""], ["Qian", "Depei", ""]]}, {"id": "2001.00496", "submitter": "Andreas Sedlmeier", "authors": "Andreas Sedlmeier, Thomas Gabor, Thomy Phan, Lenz Belzner, Claudia\n  Linnhoff-Popien", "title": "Uncertainty-Based Out-of-Distribution Classification in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1901.02219", "journal-ref": "Proceedings of the 12th International Conference on Agents and\n  Artificial Intelligence - Volume 2: ICAART, 2020, ISBN 978-989-758-395-7,\n  pages 522-529", "doi": "10.5220/0008949905220529", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to out-of-distribution (OOD) data is an important goal in building\nreliable machine learning systems. Especially in autonomous systems, wrong\npredictions for OOD inputs can cause safety critical situations. As a first\nstep towards a solution, we consider the problem of detecting such data in a\nvalue-based deep reinforcement learning (RL) setting. Modelling this problem as\na one-class classification problem, we propose a framework for\nuncertainty-based OOD classification: UBOOD. It is based on the effect that an\nagent's epistemic uncertainty is reduced for situations encountered during\ntraining (in-distribution), and thus lower than for unencountered (OOD)\nsituations. Being agnostic towards the approach used for estimating epistemic\nuncertainty, combinations with different uncertainty estimation methods, e.g.\napproximate Bayesian inference methods or ensembling techniques are possible.\nWe further present a first viable solution for calculating a dynamic\nclassification threshold, based on the uncertainty distribution of the training\ndata. Evaluation shows that the framework produces reliable classification\nresults when combined with ensemble-based estimators, while the combination\nwith concrete dropout-based estimators fails to reliably detect OOD situations.\nIn summary, UBOOD presents a viable approach for OOD classification in deep RL\nsettings by leveraging the epistemic uncertainty of the agent's value function.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 09:52:49 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Sedlmeier", "Andreas", ""], ["Gabor", "Thomas", ""], ["Phan", "Thomy", ""], ["Belzner", "Lenz", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "2001.00501", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed H Tewfik", "title": "EEG based Continuous Speech Recognition using Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate continuous speech recognition using\nelectroencephalography (EEG) features using recently introduced end-to-end\ntransformer based automatic speech recognition (ASR) model. Our results\ndemonstrate that transformer based model demonstrate faster training compared\nto recurrent neural network (RNN) based sequence-to-sequence EEG models and\nbetter performance during inference time for smaller test set vocabulary but as\nwe increase the vocabulary size, the performance of the RNN based models were\nbetter than transformer based model on a limited English vocabulary.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 08:36:59 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 17:09:18 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 05:50:08 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed H", ""]]}, {"id": "2001.00503", "submitter": "Letian Chen", "authors": "Letian Chen, Rohan Paleja, Muyleng Ghuy, Matthew Gombolay", "title": "Joint Goal and Strategy Inference across Heterogeneous Demonstrators via\n  Reward Network Distillation", "comments": "In Proceedings of the 2020 ACM/IEEE In-ternational Conference on\n  Human-Robot Interaction (HRI '20), March 23 to 26, 2020, Cambridge, United\n  Kingdom.ACM, New York, NY, USA, 10 pages", "journal-ref": null, "doi": "10.1145/3319502.3374791", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has achieved tremendous success as a general\nframework for learning how to make decisions. However, this success relies on\nthe interactive hand-tuning of a reward function by RL experts. On the other\nhand, inverse reinforcement learning (IRL) seeks to learn a reward function\nfrom readily-obtained human demonstrations. Yet, IRL suffers from two major\nlimitations: 1) reward ambiguity - there are an infinite number of possible\nreward functions that could explain an expert's demonstration and 2)\nheterogeneity - human experts adopt varying strategies and preferences, which\nmakes learning from multiple demonstrators difficult due to the common\nassumption that demonstrators seeks to maximize the same reward. In this work,\nwe propose a method to jointly infer a task goal and humans' strategic\npreferences via network distillation. This approach enables us to distill a\nrobust task reward (addressing reward ambiguity) and to model each strategy's\nobjective (handling heterogeneity). We demonstrate our algorithm can better\nrecover task reward and strategy rewards and imitate the strategies in two\nsimulated tasks and a real-world table tennis task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 16:04:21 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 18:45:39 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 16:04:47 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Letian", ""], ["Paleja", "Rohan", ""], ["Ghuy", "Muyleng", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2001.00526", "submitter": "Fahimeh Fooladgar", "authors": "Fahimeh Fooladgar and Shohreh Kasaei", "title": "Lightweight Residual Densely Connected Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": "10.1007/s11042-020-09223-8", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extremely efficient convolutional neural network architectures are one of the\nmost important requirements for limited-resource devices (such as embedded and\nmobile devices). The computing power and memory size are two important\nconstraints of these devices. Recently, some architectures have been proposed\nto overcome these limitations by considering specific hardware-software\nequipment. In this paper, the lightweight residual densely connected blocks are\nproposed to guaranty the deep supervision, efficient gradient flow, and feature\nreuse abilities of convolutional neural network. The proposed method decreases\nthe cost of training and inference processes without using any special\nhardware-software equipment by just reducing the number of parameters and\ncomputational operations while achieving a feasible accuracy. Extensive\nexperimental results demonstrate that the proposed architecture is more\nefficient than the AlexNet and VGGNet in terms of model size, required\nparameters, and even accuracy. The proposed model has been evaluated on the\nImageNet, MNIST, Fashion MNIST, SVHN, CIFAR-10, and CIFAR-100. It achieves\nstate-of-the-art results on Fashion MNIST dataset and reasonable results on the\nothers. The obtained results show the superiority of the proposed method to\nefficient models such as the SqueezNet. It is also comparable with\nstate-of-the-art efficient models such as CondenseNet and ShuffleNet.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 17:15:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:18:58 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Fooladgar", "Fahimeh", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2001.00528", "submitter": "Devendra Singh Dhami", "authors": "Devendra Singh Dhami, Siwen Yan, Gautam Kunapuli, Sriraam Natarajan", "title": "Non-Parametric Learning of Gaifman Models", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of structure learning for Gaifman models and learn\nrelational features that can be used to derive feature representations from a\nknowledge base. These relational features are first-order rules that are then\npartially grounded and counted over local neighborhoods of a Gaifman model to\nobtain the feature representations. We propose a method for learning these\nrelational features for a Gaifman model by using relational tree distances. Our\nempirical evaluation on real data sets demonstrates the superiority of our\napproach over classical rule-learning.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 17:20:53 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 19:01:20 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Dhami", "Devendra Singh", ""], ["Yan", "Siwen", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2001.00543", "submitter": "S. Rasoul Etesami", "authors": "S. Rasoul Etesami, Negar Kiyavash, Vincent Leon, H. Vincent Poor", "title": "Toward Optimal Adversarial Policies in the Multiplicative Learning\n  System with a Malicious Expert", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a learning system based on the conventional multiplicative weight\n(MW) rule that combines experts' advice to predict a sequence of true outcomes.\nIt is assumed that one of the experts is malicious and aims to impose the\nmaximum loss on the system. The loss of the system is naturally defined to be\nthe aggregate absolute difference between the sequence of predicted outcomes\nand the true outcomes. We consider this problem under both offline and online\nsettings. In the offline setting where the malicious expert must choose its\nentire sequence of decisions a priori, we show somewhat surprisingly that a\nsimple greedy policy of always reporting false prediction is asymptotically\noptimal with an approximation ratio of $1+O(\\sqrt{\\frac{\\ln N}{N}})$, where $N$\nis the total number of prediction stages. In particular, we describe a policy\nthat closely resembles the structure of the optimal offline policy. For the\nonline setting where the malicious expert can adaptively make its decisions, we\nshow that the optimal online policy can be efficiently computed by solving a\ndynamic program in $O(N^3)$. Our results provide a new direction for\nvulnerability assessment of commonly used learning algorithms to adversarial\nattacks where the threat is an integral part of the system.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:04:46 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 02:43:53 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Etesami", "S. Rasoul", ""], ["Kiyavash", "Negar", ""], ["Leon", "Vincent", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.00550", "submitter": "Marco Cerezo Ph.D", "authors": "M. Cerezo, Akira Sone, Tyler Volkoff, Lukasz Cincio, Patrick J. Coles", "title": "Cost Function Dependent Barren Plateaus in Shallow Parametrized Quantum\n  Circuits", "comments": "14 + 25 pages, 8 + 2 figures. Updated to published version. Changed\n  title", "journal-ref": "Nature Communications 12, 1791 (2021)", "doi": "10.1038/s41467-021-21728-w", "report-no": "LA-UR-19-32681", "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational quantum algorithms (VQAs) optimize the parameters $\\vec{\\theta}$\nof a parametrized quantum circuit $V(\\vec{\\theta})$ to minimize a cost function\n$C$. While VQAs may enable practical applications of noisy quantum computers,\nthey are nevertheless heuristic methods with unproven scaling. Here, we\nrigorously prove two results, assuming $V(\\vec{\\theta})$ is an alternating\nlayered ansatz composed of blocks forming local 2-designs. Our first result\nstates that defining $C$ in terms of global observables leads to exponentially\nvanishing gradients (i.e., barren plateaus) even when $V(\\vec{\\theta})$ is\nshallow. Hence, several VQAs in the literature must revise their proposed\ncosts. On the other hand, our second result states that defining $C$ with local\nobservables leads to at worst a polynomially vanishing gradient, so long as the\ndepth of $V(\\vec{\\theta})$ is $\\mathcal{O}(\\log n)$. Our results establish a\nconnection between locality and trainability. We illustrate these ideas with\nlarge-scale simulations, up to 100 qubits, of a quantum autoencoder\nimplementation.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:18:25 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 18:11:33 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 18:55:39 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Cerezo", "M.", ""], ["Sone", "Akira", ""], ["Volkoff", "Tyler", ""], ["Cincio", "Lukasz", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2001.00559", "submitter": "Changwei Hu", "authors": "Changwei Hu, Yifan Hu, Sungyong Seo", "title": "A Deep Structural Model for Analyzing Correlated Multivariate Time\n  Series", "comments": null, "journal-ref": "IEEE ICMLA 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series are routinely encountered in real-world\napplications, and in many cases, these time series are strongly correlated. In\nthis paper, we present a deep learning structural time series model which can\n(i) handle correlated multivariate time series input, and (ii) forecast the\ntargeted temporal sequence by explicitly learning/extracting the trend,\nseasonality, and event components. The trend is learned via a 1D and 2D\ntemporal CNN and LSTM hierarchical neural net. The CNN-LSTM architecture can\n(i) seamlessly leverage the dependency among multiple correlated time series in\na natural way, (ii) extract the weighted differencing feature for better trend\nlearning, and (iii) memorize the long-term sequential pattern. The seasonality\ncomponent is approximated via a non-liner function of a set of Fourier terms,\nand the event components are learned by a simple linear function of regressor\nencoding the event dates. We compare our model with several state-of-the-art\nmethods through a comprehensive set of experiments on a variety of time series\ndata sets, such as forecasts of Amazon AWS Simple Storage Service (S3) and\nElastic Compute Cloud (EC2) billings, and the closing prices for corporate\nstocks in the same category.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:48:29 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Hu", "Changwei", ""], ["Hu", "Yifan", ""], ["Seo", "Sungyong", ""]]}, {"id": "2001.00561", "submitter": "Vahid Mirjalili Dr", "authors": "Vahid Mirjalili, Sebastian Raschka, Arun Ross", "title": "PrivacyNet: Semi-Adversarial Networks for Multi-attribute Face Privacy", "comments": "13 pages, 9 figures", "journal-ref": "IEEE Transactions on Image Processing, 2020", "doi": "10.1109/TIP.2020.3024026", "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has established the possibility of deducing soft-biometric\nattributes such as age, gender and race from an individual's face image with\nhigh accuracy. However, this raises privacy concerns, especially when face\nimages collected for biometric recognition purposes are used for attribute\nanalysis without the person's consent. To address this problem, we develop a\ntechnique for imparting soft biometric privacy to face images via an image\nperturbation methodology. The image perturbation is undertaken using a\nGAN-based Semi-Adversarial Network (SAN) - referred to as PrivacyNet - that\nmodifies an input face image such that it can be used by a face matcher for\nmatching purposes but cannot be reliably used by an attribute classifier.\nFurther, PrivacyNet allows a person to choose specific attributes that have to\nbe obfuscated in the input face images (e.g., age and race), while allowing for\nother types of attributes to be extracted (e.g., gender). Extensive experiments\nusing multiple face matchers, multiple age/gender/race classifiers, and\nmultiple face datasets demonstrate the generalizability of the proposed\nmulti-attribute privacy enhancing method across multiple face and attribute\nclassifiers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:53:31 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 00:10:11 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 00:13:02 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Mirjalili", "Vahid", ""], ["Raschka", "Sebastian", ""], ["Ross", "Arun", ""]]}, {"id": "2001.00564", "submitter": "Yuting Ng", "authors": "Yuting Ng (1), Jo\\~ao M. Pereira (1), Denis Garagic (2), Vahid Tarokh\n  (1) ((1) Duke University, (2) BAE Systems FAST Labs)", "title": "Robust Marine Buoy Placement for Ship Detection Using Dropout K-Means", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marine buoys aid in the battle against Illegal, Unreported and Unregulated\n(IUU) fishing by detecting fishing vessels in their vicinity. Marine buoys,\nhowever, may be disrupted by natural causes and buoy vandalism. In this paper,\nwe formulate marine buoy placement as a clustering problem, and propose dropout\nk-means and dropout k-median to improve placement robustness to buoy\ndisruption.\n  We simulated the passage of ships in the Gabonese waters near West Africa\nusing historical Automatic Identification System (AIS) data, then compared the\nship detection probability of dropout k-means to classic k-means and dropout\nk-median to classic k-median. With 5 buoys, the buoy arrangement computed by\nclassic k-means, dropout k-means, classic k-median and dropout k-median have\nship detection probabilities of 38%, 45%, 48% and 52%.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:55:56 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 19:44:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ng", "Yuting", "", "Duke University"], ["Pereira", "Jo\u00e3o M.", "", "Duke University"], ["Garagic", "Denis", "", "BAE Systems FAST Labs"], ["Tarokh", "Vahid", "", "Duke University"]]}, {"id": "2001.00570", "submitter": "Yaoshiang Ho", "authors": "Yaoshiang Ho, Samuel Wookey", "title": "The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of\n  Mislabeling", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2962617", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new metric to measure goodness-of-fit for\nclassifiers, the Real World Cost function. This metric factors in information\nabout a real world problem, such as financial impact, that other measures like\naccuracy or F1 do not. This metric is also more directly interpretable for\nusers. To optimize for this metric, we introduce the Real-World- Weight\nCrossentropy loss function, in both binary and single-label classification\nvariants. Both variants allow direct input of real world costs as weights. For\nsingle-label, multicategory classification, our loss function also allows\ndirect penalization of probabilistic false positives, weighted by label, during\nthe training of a machine learning model. We compare the design of our loss\nfunction to the binary crossentropy and categorical crossentropy functions, as\nwell as their weighted variants, to discuss the potential for improvement in\nhandling a variety of known shortcomings of machine learning, ranging from\nimbalanced classes to medical diagnostic error to reinforcement of social bias.\nWe create scenarios that emulate those issues using the MNIST data set and\ndemonstrate empirical results of our new loss function. Finally, we sketch a\nproof of this function based on Maximum Likelihood Estimation and discuss\nfuture directions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 08:54:42 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ho", "Yaoshiang", ""], ["Wookey", "Samuel", ""]]}, {"id": "2001.00571", "submitter": "Tamirlan Seidakhmetov", "authors": "Tamirlan Seidakhmetov", "title": "Question Type Classification Methods Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a comparative study of state-of-the-art approaches for\nquestion classification task: Logistic Regression, Convolutional Neural\nNetworks (CNN), Long Short-Term Memory Network (LSTM) and Quasi-Recurrent\nNeural Networks (QRNN). All models use pre-trained GLoVe word embeddings and\ntrained on human-labeled data. The best accuracy is achieved using CNN model\nwith five convolutional layers and various kernel sizes stacked in parallel,\nfollowed by one fully connected layer. The model reached 90.7% accuracy on TREC\n10 test set. All the model architectures in this paper were developed from\nscratch on PyTorch, in few cases based on reliable open-source implementation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 00:16:46 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Seidakhmetov", "Tamirlan", ""]]}, {"id": "2001.00573", "submitter": "Sucheta Ghosh", "authors": "Sucheta Ghosh", "title": "A Hybrid Framework for Topic Structure using Laughter Occurrences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conversational discourse coherence depends on both linguistic and\nparalinguistic phenomena. In this work we combine both paralinguistic and\nlinguistic knowledge into a hybrid framework through a multi-level hierarchy.\nThus it outputs the discourse-level topic structures. The laughter occurrences\nare used as paralinguistic information from the multiparty meeting transcripts\nof ICSI database. A clustering-based algorithm is proposed that chose the best\ntopic-segment cluster from two independent, optimized clusters, namely,\nhierarchical agglomerative clustering and $K$-medoids. Then it is iteratively\nhybridized with an existing lexical cohesion based Bayesian topic segmentation\nframework. The hybrid approach improves the performance of both of the\nstand-alone approaches. This leads to the brief study of interactions between\ntopic structures with discourse relational structure. This training-free topic\nstructuring approach can be applicable to online understanding of spoken\ndialogs.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 23:31:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ghosh", "Sucheta", ""]]}, {"id": "2001.00576", "submitter": "Weixin Liang", "authors": "Weixin Liang, Zixuan Liu and Can Liu", "title": "DAWSON: A Domain Adaptive Few Shot Generation Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a Generative Adversarial Networks (GAN) for a new domain from\nscratch requires an enormous amount of training data and days of training time.\nTo this end, we propose DAWSON, a Domain Adaptive FewShot Generation\nFrameworkFor GANs based on meta-learning. A major challenge of applying\nmeta-learning GANs is to obtain gradients for the generator from evaluating it\non development sets due to the likelihood-free nature of GANs. To address this\nchallenge, we propose an alternative GAN training procedure that naturally\ncombines the two-step training procedure of GANs and the two-step training\nprocedure of meta-learning algorithms. DAWSON is a plug-and-play framework that\nsupports a broad family of meta-learning algorithms and various GANs with\narchitectural-variants. Based on DAWSON, We also propose MUSIC MATINEE, which\nis the first few-shot music generation model. Our experiments show that MUSIC\nMATINEE could quickly adapt to new domains with only tens of songs from the\ntarget domains. We also show that DAWSON can learn to generate new digits with\nonly four samples in the MNIST dataset. We release source codes implementation\nof DAWSON in both PyTorch and Tensorflow, generated music samples on two genres\nand the lightning video.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 00:59:10 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Liang", "Weixin", ""], ["Liu", "Zixuan", ""], ["Liu", "Can", ""]]}, {"id": "2001.00577", "submitter": "Chanwoo Kim", "authors": "Kwangyoun Kim, Kyungmin Lee, Dhananjaya Gowda, Junmo Park, Sungsoo\n  Kim, Sichen Jin, Young-Yoon Lee, Jinsu Yeo, Daehyun Kim, Seokyeong Jung,\n  Jungin Lee, Myoungji Han, Chanwoo Kim", "title": "Attention based on-device streaming speech recognition with large speech\n  corpus", "comments": "Accepted and presented at the ASRU 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new on-device automatic speech recognition (ASR)\nsystem based on monotonic chunk-wise attention (MoChA) models trained with\nlarge (> 10K hours) corpus. We attained around 90% of a word recognition rate\nfor general domain mainly by using joint training of connectionist temporal\nclassifier (CTC) and cross entropy (CE) losses, minimum word error rate (MWER)\ntraining, layer-wise pre-training and data augmentation methods. In addition,\nwe compressed our models by more than 3.4 times smaller using an iterative\nhyper low-rank approximation (LRA) method while minimizing the degradation in\nrecognition accuracy. The memory footprint was further reduced with 8-bit\nquantization to bring down the final model size to lower than 39 MB. For\non-demand adaptation, we fused the MoChA models with statistical n-gram models,\nand we could achieve a relatively 36% improvement on average in word error rate\n(WER) for target domains including the general domain.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 04:24:44 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Kim", "Kwangyoun", ""], ["Lee", "Kyungmin", ""], ["Gowda", "Dhananjaya", ""], ["Park", "Junmo", ""], ["Kim", "Sungsoo", ""], ["Jin", "Sichen", ""], ["Lee", "Young-Yoon", ""], ["Yeo", "Jinsu", ""], ["Kim", "Daehyun", ""], ["Jung", "Seokyeong", ""], ["Lee", "Jungin", ""], ["Han", "Myoungji", ""], ["Kim", "Chanwoo", ""]]}, {"id": "2001.00585", "submitter": "Masoud Mohseni", "authors": "Gavin S. Hartnett, Masoud Mohseni", "title": "Self-Supervised Learning of Generative Spin-Glasses with Normalizing\n  Flows", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-glasses are universal models that can capture complex behavior of\nmany-body systems at the interface of statistical physics and computer science\nincluding discrete optimization, inference in graphical models, and automated\nreasoning. Computing the underlying structure and dynamics of such complex\nsystems is extremely difficult due to the combinatorial explosion of their\nstate space. Here, we develop deep generative continuous spin-glass\ndistributions with normalizing flows to model correlations in generic discrete\nproblems. We use a self-supervised learning paradigm by automatically\ngenerating the data from the spin-glass itself. We demonstrate that key\nphysical and computational properties of the spin-glass phase can be\nsuccessfully learned, including multi-modal steady-state distributions and\ntopological structures among metastable states. Remarkably, we observe that the\nlearning itself corresponds to a spin-glass phase transition within the layers\nof the trained normalizing flows. The inverse normalizing flows learns to\nperform reversible multi-scale coarse-graining operations which are very\ndifferent from the typical irreversible renormalization group techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:00:01 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 19:00:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hartnett", "Gavin S.", ""], ["Mohseni", "Masoud", ""]]}, {"id": "2001.00593", "submitter": "Hendrik Poulsen Nautrup", "authors": "Hendrik Poulsen Nautrup, Tony Metger, Raban Iten, Sofiene Jerbi, Lea\n  M. Trenkwalder, Henrik Wilming, Hans J. Briegel, Renato Renner", "title": "Operationally meaningful representations of physical systems in neural\n  networks", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make progress in science, we often build abstract representations of\nphysical systems that meaningfully encode information about the systems. The\nrepresentations learnt by most current machine learning techniques reflect\nstatistical structure present in the training data; however, these methods do\nnot allow us to specify explicit and operationally meaningful requirements on\nthe representation. Here, we present a neural network architecture based on the\nnotion that agents dealing with different aspects of a physical system should\nbe able to communicate relevant information as efficiently as possible to one\nanother. This produces representations that separate different parameters which\nare useful for making statements about the physical system in different\nexperimental settings. We present examples involving both classical and quantum\nphysics. For instance, our architecture finds a compact representation of an\narbitrary two-qubit system that separates local parameters from parameters\ndescribing quantum correlations. We further show that this method can be\ncombined with reinforcement learning to enable representation learning within\ninteractive scenarios where agents need to explore experimental settings to\nidentify relevant variables.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:01:31 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Nautrup", "Hendrik Poulsen", ""], ["Metger", "Tony", ""], ["Iten", "Raban", ""], ["Jerbi", "Sofiene", ""], ["Trenkwalder", "Lea M.", ""], ["Wilming", "Henrik", ""], ["Briegel", "Hans J.", ""], ["Renner", "Renato", ""]]}, {"id": "2001.00594", "submitter": "Changwei Hu", "authors": "Yao Zhan, Changwei Hu, Yifan Hu, Tejaswi Kasturi, Shanmugam Ramasamy,\n  Matt Gillingham, Keith Yamamoto", "title": "Large-scale Gender/Age Prediction of Tumblr Users", "comments": null, "journal-ref": "IEEE ICMLA 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tumblr, as a leading content provider and social media, attracts 371 million\nmonthly visits, 280 million blogs and 53.3 million daily posts. The popularity\nof Tumblr provides great opportunities for advertisers to promote their\nproducts through sponsored posts. However, it is a challenging task to target\nspecific demographic groups for ads, since Tumblr does not require user\ninformation like gender and ages during their registration. Hence, to promote\nad targeting, it is essential to predict user's demography using rich content\nsuch as posts, images and social connections. In this paper, we propose graph\nbased and deep learning models for age and gender predictions, which take into\naccount user activities and content features. For graph based models, we come\nup with two approaches, network embedding and label propagation, to generate\nconnection features as well as directly infer user's demography. For deep\nlearning models, we leverage convolutional neural network (CNN) and multilayer\nperceptron (MLP) to prediction users' age and gender. Experimental results on\nreal Tumblr daily dataset, with hundreds of millions of active users and\nbillions of following relations, demonstrate that our approaches significantly\noutperform the baseline model, by improving the accuracy relatively by 81% for\nage, and the AUC and accuracy by 5\\% for gender.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:01:45 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Zhan", "Yao", ""], ["Hu", "Changwei", ""], ["Hu", "Yifan", ""], ["Kasturi", "Tejaswi", ""], ["Ramasamy", "Shanmugam", ""], ["Gillingham", "Matt", ""], ["Yamamoto", "Keith", ""]]}, {"id": "2001.00602", "submitter": "Wa\\\"iss Azizian", "authors": "Wa\\\"iss Azizian, Damien Scieur, Ioannis Mitliagkas, Simon\n  Lacoste-Julien, Gauthier Gidel", "title": "Accelerating Smooth Games by Manipulating Spectral Shapes", "comments": "Appears in: Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020). 34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use matrix iteration theory to characterize acceleration in smooth games.\nWe define the spectral shape of a family of games as the set containing all\neigenvalues of the Jacobians of standard gradient dynamics in the family.\nShapes restricted to the real line represent well-understood classes of\nproblems, like minimization. Shapes spanning the complex plane capture the\nadded numerical challenges in solving smooth games. In this framework, we\ndescribe gradient-based methods, such as extragradient, as transformations on\nthe spectral shape. Using this perspective, we propose an optimal algorithm for\nbilinear games. For smooth and strongly monotone operators, we identify a\ncontinuum between convex minimization, where acceleration is possible using\nPolyak's momentum, and the worst case where gradient descent is optimal.\nFinally, going beyond first-order methods, we propose an accelerated version of\nconsensus optimization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:21:48 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 14:51:46 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Azizian", "Wa\u00efss", ""], ["Scieur", "Damien", ""], ["Mitliagkas", "Ioannis", ""], ["Lacoste-Julien", "Simon", ""], ["Gidel", "Gauthier", ""]]}, {"id": "2001.00605", "submitter": "Sahika Genc", "authors": "Sahika Genc, Sunil Mallya, Sravan Bodapati, Tao Sun, Yunzhe Tao", "title": "Zero-Shot Reinforcement Learning with Deep Attention Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation-to-simulation and simulation-to-real world transfer of neural\nnetwork models have been a difficult problem. To close the reality gap, prior\nmethods to simulation-to-real world transfer focused on domain adaptation,\ndecoupling perception and dynamics and solving each problem separately, and\nrandomization of agent parameters and environment conditions to expose the\nlearning agent to a variety of conditions. While these methods provide\nacceptable performance, the computational complexity required to capture a\nlarge variation of parameters for comprehensive scenarios on a given task such\nas autonomous driving or robotic manipulation is high. Our key contribution is\nto theoretically prove and empirically demonstrate that a deep attention\nconvolutional neural network (DACNN) with specific visual sensor configuration\nperforms as well as training on a dataset with high domain and parameter\nvariation at lower computational complexity. Specifically, the attention\nnetwork weights are learned through policy optimization to focus on local\ndependencies that lead to optimal actions, and does not require tuning in\nreal-world for generalization. Our new architecture adapts perception with\nrespect to the control objective, resulting in zero-shot learning without\npre-training a perception network. To measure the impact of our new deep\nnetwork architecture on domain adaptation, we consider autonomous driving as a\nuse case. We perform an extensive set of experiments in\nsimulation-to-simulation and simulation-to-real scenarios to compare our\napproach to several baselines including the current state-of-art models.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:41:58 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Genc", "Sahika", ""], ["Mallya", "Sunil", ""], ["Bodapati", "Sravan", ""], ["Sun", "Tao", ""], ["Tao", "Yunzhe", ""]]}, {"id": "2001.00610", "submitter": "Justin DeBenedetto", "authors": "Justin DeBenedetto, David Chiang", "title": "Representing Unordered Data Using Complex-Weighted Multiset Automata", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unordered, variable-sized inputs arise in many settings across multiple\nfields. The ability for set- and multiset-oriented neural networks to handle\nthis type of input has been the focus of much work in recent years. We propose\nto represent multisets using complex-weighted multiset automata and show how\nthe multiset representations of certain existing neural architectures can be\nviewed as special cases of ours. Namely, (1) we provide a new theoretical and\nintuitive justification for the Transformer model's representation of positions\nusing sinusoidal functions, and (2) we extend the DeepSets model to use complex\nnumbers, enabling it to outperform the existing model on an extension of one of\ntheir tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 20:04:45 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 21:01:06 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 14:11:26 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["DeBenedetto", "Justin", ""], ["Chiang", "David", ""]]}, {"id": "2001.00621", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker, Alan Colman, Jun Han, Asif Irshad Khan, Yoosef B.\n  Abushark and Khaled Salah", "title": "BehavDT: A Behavioral Decision Tree Learning to Build User-Centric\n  Context-Aware Predictive Model", "comments": null, "journal-ref": "Journal: Mobile Networks and Applications, Springer, 2019", "doi": "10.1007/s11036-019-01443-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper formulates the problem of building a context-aware predictive\nmodel based on user diverse behavioral activities with smartphones. In the area\nof machine learning and data science, a tree-like model as that of decision\ntree is considered as one of the most popular classification techniques, which\ncan be used to build a data-driven predictive model. The traditional decision\ntree model typically creates a number of leaf nodes as decision nodes that\nrepresent context-specific rigid decisions, and consequently may cause\noverfitting problem in behavior modeling. However, in many practical scenarios\nwithin the context-aware environment, the generalized outcomes could play an\nimportant role to effectively capture user behavior. In this paper, we propose\na behavioral decision tree, \"BehavDT\" context-aware model that takes into\naccount user behavior-oriented generalization according to individual\npreference level. The BehavDT model outputs not only the generalized decisions\nbut also the context-specific decisions in relevant exceptional cases. The\neffectiveness of our BehavDT model is studied by conducting experiments on\nindividual user real smartphone datasets. Our experimental results show that\nthe proposed BehavDT context-aware model is more effective when compared with\nthe traditional machine learning approaches, in predicting user diverse\nbehaviors considering multi-dimensional contexts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 08:58:24 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Sarker", "Iqbal H.", ""], ["Colman", "Alan", ""], ["Han", "Jun", ""], ["Khan", "Asif Irshad", ""], ["Abushark", "Yoosef B.", ""], ["Salah", "Khaled", ""]]}, {"id": "2001.00624", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato and Haoyuan Sun and Mohammad Nazmul Haque", "title": "Analytic Continued Fractions for Regression: A Memetic Algorithm\n  Approach", "comments": "Submitted to Expert Systems with Applications", "journal-ref": "Expert Systems with Applications 179 (2021): 115018", "doi": "10.1016/j.eswa.2021.115018", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for regression problems that employs analytic\ncontinued fractions as a novel representation. Comparative computational\nresults using a memetic algorithm are reported in this work. Our experiments\nincluded fifteen other different machine learning approaches including five\ngenetic programming methods for symbolic regression and ten machine learning\nmethods. The comparison on training and test generalization was performed using\n94 datasets of the Penn State Machine Learning Benchmark. The statistical tests\nshowed that the generalization results using analytic continued fractions\nprovides a powerful and interesting new alternative in the quest for compact\nand interpretable mathematical models for artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 00:09:01 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Moscato", "Pablo", ""], ["Sun", "Haoyuan", ""], ["Haque", "Mohammad Nazmul", ""]]}, {"id": "2001.00626", "submitter": "Arun Verma Mr.", "authors": "Arun Verma, Manjesh K. Hanawal, and Nandyala Hemachandra", "title": "Unsupervised Online Feature Selection for Cost-Sensitive Medical\n  Diagnosis", "comments": "Accepted to NetHealth Workshop at COMSNETS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In medical diagnosis, physicians predict the state of a patient by checking\nmeasurements (features) obtained from a sequence of tests, e.g., blood test,\nurine test, followed by invasive tests. As tests are often costly, one would\nlike to obtain only those features (tests) that can establish the presence or\nabsence of the state conclusively. Another aspect of medical diagnosis is that\nwe are often faced with unsupervised prediction tasks as the true state of the\npatients may not be known. Motivated by such medical diagnosis problems, we\nconsider a {\\it Cost-Sensitive Medical Diagnosis} (CSMD) problem, where the\ntrue state of patients is unknown. We formulate the CSMD problem as a feature\nselection problem where each test gives a feature that can be used in a\nprediction model. Our objective is to learn strategies for selecting the\nfeatures that give the best trade-off between accuracy and costs. We exploit\nthe `Weak Dominance' property of problem to develop online algorithms that\nidentify a set of features which provides an `optimal' trade-off between cost\nand accuracy of prediction without requiring to know the true state of the\nmedical condition. Our empirical results validate the performance of our\nalgorithms on problem instances generated from real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 14:15:29 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""], ["Hemachandra", "Nandyala", ""]]}, {"id": "2001.00629", "submitter": "I-Sheng Yang", "authors": "I-Sheng Yang", "title": "A Loss-Function for Causal Machine-Learning", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal machine-learning is about predicting the net-effect (true-lift) of\ntreatments. Given the data of a treatment group and a control group, it is\nsimilar to a standard supervised-learning problem. Unfortunately, there is no\nsimilarly well-defined loss function due to the lack of point-wise true values\nin the data. Many advances in modern machine-learning are not directly\napplicable due to the absence of such loss function.\n  We propose a novel method to define a loss function in this context, which is\nequal to mean-square-error (MSE) in a standard regression problem. Our loss\nfunction is universally applicable, thus providing a general standard to\nevaluate the quality of any model/strategy that predicts the true-lift. We\ndemonstrate that despite its novel definition, one can still perform gradient\ndescent directly on this loss function to find the best fit. This leads to a\nnew way to train any parameter-based model, such as deep neural networks, to\nsolve causal machine-learning problems without going through the meta-learner\nstrategy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:22:18 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yang", "I-Sheng", ""]]}, {"id": "2001.00631", "submitter": "Elena Sizikova", "authors": "Miju Ahn, Nicole Eikmeier, Jamie Haddock, Lara Kassab, Alona\n  Kryshchenko, Kathryn Leonard, Deanna Needell, R. W. M. A. Madushani, Elena\n  Sizikova, Chuntian Wang", "title": "On Large-Scale Dynamic Topic Modeling with Nonnegative CP Tensor\n  Decomposition", "comments": "23 pages, 29 figures, submitted to Women in Data Science and\n  Mathematics (WiSDM) Workshop Proceedings, \"Advances in Data Science\",\n  AWM-Springer series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is currently an unprecedented demand for large-scale temporal data\nanalysis due to the explosive growth of data. Dynamic topic modeling has been\nwidely used in social and data sciences with the goal of learning latent topics\nthat emerge, evolve, and fade over time. Previous work on dynamic topic\nmodeling primarily employ the method of nonnegative matrix factorization (NMF),\nwhere slices of the data tensor are each factorized into the product of\nlower-dimensional nonnegative matrices. With this approach, however,\ninformation contained in the temporal dimension of the data is often neglected\nor underutilized. To overcome this issue, we propose instead adopting the\nmethod of nonnegative CANDECOMP/PARAPAC (CP) tensor decomposition (NNCPD),\nwhere the data tensor is directly decomposed into a minimal sum of outer\nproducts of nonnegative vectors, thereby preserving the temporal information.\nThe viability of NNCPD is demonstrated through application to both synthetic\nand real data, where significantly improved results are obtained compared to\nthose of typical NMF-based methods. The advantages of NNCPD over such\napproaches are studied and discussed. To the best of our knowledge, this is the\nfirst time that NNCPD has been utilized for the purpose of dynamic topic\nmodeling, and our findings will be transformative for both applications and\nfurther developments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:28:10 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 00:02:25 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ahn", "Miju", ""], ["Eikmeier", "Nicole", ""], ["Haddock", "Jamie", ""], ["Kassab", "Lara", ""], ["Kryshchenko", "Alona", ""], ["Leonard", "Kathryn", ""], ["Needell", "Deanna", ""], ["Madushani", "R. W. M. A.", ""], ["Sizikova", "Elena", ""], ["Wang", "Chuntian", ""]]}, {"id": "2001.00632", "submitter": "Qian Hu", "authors": "Qian Hu, Huzefa Rangwala", "title": "Academic Performance Estimation with Attention-based Graph Convolutional\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's academic performance prediction empowers educational technologies\nincluding academic trajectory and degree planning, course recommender systems,\nearly warning and advising systems. Given a student's past data (such as grades\nin prior courses), the task of student's performance prediction is to predict a\nstudent's grades in future courses. Academic programs are structured in a way\nthat prior courses lay the foundation for future courses. The knowledge\nrequired by courses is obtained by taking multiple prior courses, which\nexhibits complex relationships modeled by graph structures. Traditional methods\nfor student's performance prediction usually neglect the underlying\nrelationships between multiple courses; and how students acquire knowledge\nacross them. In addition, traditional methods do not provide interpretation for\npredictions needed for decision making. In this work, we propose a novel\nattention-based graph convolutional networks model for student's performance\nprediction. We conduct extensive experiments on a real-world dataset obtained\nfrom a large public university. The experimental results show that our proposed\nmodel outperforms state-of-the-art approaches in terms of grade prediction. The\nproposed model also shows strong accuracy in identifying students who are\nat-risk of failing or dropping out so that timely intervention and feedback can\nbe provided to the student.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 23:11:27 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Hu", "Qian", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2001.00635", "submitter": "Yoshiro Suzuki", "authors": "Yusuke Takahashi, Yoshiro Suzuki, Akira Todoroki", "title": "Convolutional Neural Network-based Topology Optimization (CNN-TO) By\n  Estimating Sensitivity of Compliance from Material Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new topology optimization method that applies a\nconvolutional neural network (CNN), which is one deep learning technique for\ntopology optimization problems. Using this method, we acquire a structure with\na little higher performance that could not be obtained by the previous topology\noptimization method. In particular, in this paper, we solve a topology\noptimization problem aimed at maximizing stiffness with a mass constraint,\nwhich is a common type of topology optimization. In this paper, we first\nformulate the conventional topology optimization by the solid isotropic\nmaterial with penalization method. Next, we formulate the topology optimization\nusing CNN. Finally, we show the effectiveness of the proposed topology\noptimization method by solving a verification example, namely a topology\noptimization problem aimed at maximizing stiffness. In this research, as a\nresult of solving the verification example for a small design area of 16x32\nelement, we obtain the solution different from the previous topology\noptimization method. This result suggests that stiffness information of\nstructure can be extracted and analyzed for structural design by analyzing the\ndensity distribution using CNN like an image. This suggests that CNN technology\ncan be utilized in the structural design and topology optimization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 07:17:23 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Takahashi", "Yusuke", ""], ["Suzuki", "Yoshiro", ""], ["Todoroki", "Akira", ""]]}, {"id": "2001.00636", "submitter": "David Cortes", "authors": "David Cortes", "title": "Explainable outlier detection through decision tree conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes an outlier detection procedure (named \"OutlierTree\")\nloosely based on the GritBot software developed by RuleQuest research, which\nworks by evaluating and following supervised decision tree splits on variables,\nin whose branches 1-d confidence intervals are constructed for the target\nvariable and potential outliers flagged according to these confidence\nintervals. Under this logic, it's possible to produce human-readable\nexplanations for why a given value of a variable in an observation can be\nconsidered as outlier, by considering the decision tree branch conditions along\nwith general distribution statistics among the non-outlier observations that\nfell into the same branch, which can then be contrasted against the value which\nlies outside the CI. The supervised splits help to ensure that the generated\nconditions are not spurious, but rather related to the target variable and\nhaving logical breakpoints.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:45:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Cortes", "David", ""]]}, {"id": "2001.00637", "submitter": "Steven Atkinson", "authors": "Steven Atkinson and Sayan Ghosh and Natarajan Chennimalai-Kumar and\n  Genghis Khan and Liping Wang", "title": "Bayesian task embedding for few-shot Bayesian optimization", "comments": "To appear in proceedings of the AIAA SciTech 2020 Forum. 17 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for Bayesian optimization by which one may incorporate\ndata from multiple systems whose quantitative interrelationships are unknown a\npriori. All general (nonreal-valued) features of the systems are associated\nwith continuous latent variables that enter as inputs into a single metamodel\nthat simultaneously learns the response surfaces of all of the systems.\nBayesian inference is used to determine appropriate beliefs regarding the\nlatent variables. We explain how the resulting probabilistic metamodel may be\nused for Bayesian optimization tasks and demonstrate its implementation on a\nvariety of synthetic and real-world examples, comparing its performance under\nzero-, one-, and few-shot settings against traditional Bayesian optimization,\nwhich usually requires substantially more data from the system of interest.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 21:46:48 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Atkinson", "Steven", ""], ["Ghosh", "Sayan", ""], ["Chennimalai-Kumar", "Natarajan", ""], ["Khan", "Genghis", ""], ["Wang", "Liping", ""]]}, {"id": "2001.00666", "submitter": "Nil Stolt Ans\\'o", "authors": "Nil Stolt Ans\\'o", "title": "Synthetic vascular structure generation for unsupervised pre-training in\n  CTA segmentation tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large enough computed tomography (CT) data sets to train supervised deep\nmodels are often hard to come by. One contributing issue is the amount of\nmanual labor that goes into creating ground truth labels, specially for\nvolumetric data. In this research, we train a U-net architecture at a vessel\nsegmentation task that can be used to provide insights when treating stroke\npatients. We create a computational model that generates synthetic vascular\nstructures which can be blended into unlabeled CT scans of the head. This\nunsupervised approached to labelling is used to pre-train deep segmentation\nmodels, which are later fine-tuned on real examples to achieve an increase in\naccuracy compared to models trained exclusively on a hand-labeled data set.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 23:21:22 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ans\u00f3", "Nil Stolt", ""]]}, {"id": "2001.00677", "submitter": "Huan Song", "authors": "Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, Liu Ren", "title": "Improve Unsupervised Domain Adaptation with Mixup Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation studies the problem of utilizing a relevant\nsource domain with abundant labels to build predictive modeling for an\nunannotated target domain. Recent work observe that the popular adversarial\napproach of learning domain-invariant features is insufficient to achieve\ndesirable target domain performance and thus introduce additional training\nconstraints, e.g. cluster assumption. However, these approaches impose the\nconstraints on source and target domains individually, ignoring the important\ninterplay between them. In this work, we propose to enforce training\nconstraints across domains using mixup formulation to directly address the\ngeneralization performance for target data. In order to tackle potentially huge\ndomain discrepancy, we further propose a feature-level consistency regularizer\nto facilitate the inter-domain constraint. When adding intra-domain mixup and\ndomain adversarial learning, our general framework significantly improves\nstate-of-the-art performance on several important tasks from both image\nclassification and human activity recognition.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:21:27 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yan", "Shen", ""], ["Song", "Huan", ""], ["Li", "Nanxiang", ""], ["Zou", "Lincan", ""], ["Ren", "Liu", ""]]}, {"id": "2001.00682", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh and Dianne P. O'Leary", "title": "Auditing and Debugging Deep Learning Models via Decision Boundaries:\n  Individual-level and Group-level Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been criticized for their lack of easy\ninterpretation, which undermines confidence in their use for important\napplications. Nevertheless, they are consistently utilized in many\napplications, consequential to humans' lives, mostly because of their better\nperformance. Therefore, there is a great need for computational methods that\ncan explain, audit, and debug such models. Here, we use flip points to\naccomplish these goals for deep learning models with continuous output scores\n(e.g., computed by softmax), used in social applications. A flip point is any\npoint that lies on the boundary between two output classes: e.g. for a model\nwith a binary yes/no output, a flip point is any input that generates equal\nscores for \"yes\" and \"no\". The flip point closest to a given input is of\nparticular importance because it reveals the least changes in the input that\nwould change a model's classification, and we show that it is the solution to a\nwell-posed optimization problem. Flip points also enable us to systematically\nstudy the decision boundaries of a deep learning classifier. The resulting\ninsight into the decision boundaries of a deep model can clearly explain the\nmodel's output on the individual-level, via an explanation report that is\nunderstandable by non-experts. We also develop a procedure to understand and\naudit model behavior towards groups of people. Flip points can also be used to\nalter the decision boundaries in order to improve undesirable behaviors. We\ndemonstrate our methods by investigating several models trained on standard\ndatasets used in social applications of machine learning. We also identify the\nfeatures that are most responsible for particular classifications and\nmisclassifications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:45:36 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P.", ""]]}, {"id": "2001.00686", "submitter": "Jacky Chow", "authors": "Jacky C.K. Chow, Steven K. Boyd, Derek D. Lichti and Janet L. Ronsky", "title": "Robust Self-Supervised Learning of Deterministic Errors in Single-Plane\n  (Monoplanar) and Dual-Plane (Biplanar) X-ray Fluoroscopy", "comments": null, "journal-ref": null, "doi": "10.1109/TMI.2019.2963446", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fluoroscopic imaging that captures X-ray images at video framerates is\nadvantageous for guiding catheter insertions by vascular surgeons and\ninterventional radiologists. Visualizing the dynamical movements non-invasively\nallows complex surgical procedures to be performed with less trauma to the\npatient. To improve surgical precision, endovascular procedures can benefit\nfrom more accurate fluoroscopy data via calibration. This paper presents a\nrobust self-calibration algorithm suitable for single-plane and dual-plane\nfluoroscopy. A three-dimensional (3D) target field was imaged by the\nfluoroscope in a strong geometric network configuration. The unknown 3D\npositions of targets and the fluoroscope pose were estimated simultaneously by\nmaximizing the likelihood of the Student-t probability distribution function. A\nsmoothed k-nearest neighbour (kNN) regression is then used to model the\ndeterministic component of the image reprojection error of the robust bundle\nadjustment. The Maximum Likelihood Estimation step and the kNN regression step\nare then repeated iteratively until convergence. Four different error modeling\nschemes were compared while varying the quantity of training images. It was\nfound that using a smoothed kNN regression can automatically model the\nsystematic errors in fluoroscopy with similar accuracy as a human expert using\na small training dataset. When all training images were used, the 3D mapping\nerror was reduced from 0.61-0.83 mm to 0.04 mm post-calibration (94.2-95.7%\nimprovement), and the 2D reprojection error was reduced from 1.17-1.31 to\n0.20-0.21 pixels (83.2-83.8% improvement). When using biplanar fluoroscopy, the\n3D measurement accuracy of the system improved from 0.60 mm to 0.32 mm (47.2%\nimprovement).\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 01:56:21 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Chow", "Jacky C. K.", ""], ["Boyd", "Steven K.", ""], ["Lichti", "Derek D.", ""], ["Ronsky", "Janet L.", ""]]}, {"id": "2001.00689", "submitter": "Soochan Lee", "authors": "Soochan Lee, Junsoo Ha, Dongsu Zhang, Gunhee Kim", "title": "A Neural Dirichlet Process Mixture Model for Task-Free Continual\n  Learning", "comments": "Accepted as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest in continual learning, most of its contemporary\nworks have been studied in a rather restricted setting where tasks are clearly\ndistinguishable, and task boundaries are known during training. However, if our\ngoal is to develop an algorithm that learns as humans do, this setting is far\nfrom realistic, and it is essential to develop a methodology that works in a\ntask-free manner. Meanwhile, among several branches of continual learning,\nexpansion-based methods have the advantage of eliminating catastrophic\nforgetting by allocating new resources to learn new data. In this work, we\npropose an expansion-based approach for task-free continual learning. Our\nmodel, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a\nset of neural network experts that are in charge of a subset of the data.\nCN-DPM expands the number of experts in a principled way under the Bayesian\nnonparametric framework. With extensive experiments, we show that our model\nsuccessfully performs task-free continual learning for both discriminative and\ngenerative tasks such as image classification and image generation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 02:07:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 23:32:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lee", "Soochan", ""], ["Ha", "Junsoo", ""], ["Zhang", "Dongsu", ""], ["Kim", "Gunhee", ""]]}, {"id": "2001.00705", "submitter": "Jianghao Shen", "authors": "Jianghao Shen, Yonggan Fu, Yue Wang, Pengfei Xu, Zhangyang Wang,\n  Yingyan Lin", "title": "Fractional Skipping: Towards Finer-Grained Dynamic CNN Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While increasingly deep networks are still in general desired for achieving\nstate-of-the-art performance, for many specific inputs a simpler network might\nalready suffice. Existing works exploited this observation by learning to skip\nconvolutional layers in an input-dependent manner. However, we argue their\nbinary decision scheme, i.e., either fully executing or completely bypassing\none layer for a specific input, can be enhanced by introducing finer-grained,\n\"softer\" decisions. We therefore propose a Dynamic Fractional Skipping (DFS)\nframework. The core idea of DFS is to hypothesize layer-wise quantization (to\ndifferent bitwidths) as intermediate \"soft\" choices to be made between fully\nutilizing and skipping a layer. For each input, DFS dynamically assigns a\nbitwidth to both weights and activations of each layer, where fully executing\nand skipping could be viewed as two \"extremes\" (i.e., full bitwidth and zero\nbitwidth). In this way, DFS can \"fractionally\" exploit a layer's expressive\npower during input-adaptive inference, enabling finer-grained\naccuracy-computational cost trade-offs. It presents a unified view to link\ninput-adaptive layer skipping and input-adaptive hybrid quantization. Extensive\nexperimental results demonstrate the superior tradeoff between computational\ncost and model expressive power (accuracy) achieved by DFS. More visualizations\nalso indicate a smooth and consistent transition in the DFS behaviors,\nespecially the learned choices between layer skipping and different\nquantizations when the total computational budgets vary, validating our\nhypothesis that layer quantization could be viewed as intermediate variants of\nlayer skipping. Our source code and supplementary material are available at\n\\link{https://github.com/Torment123/DFS}.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:12:17 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Shen", "Jianghao", ""], ["Fu", "Yonggan", ""], ["Wang", "Yue", ""], ["Xu", "Pengfei", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2001.00706", "submitter": "Patrick Kidger", "authors": "Patrick Kidger, Terry Lyons", "title": "Signatory: differentiable computations of the signature and logsignature\n  transforms, on both CPU and GPU", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signatory is a library for calculating and performing functionality related\nto the signature and logsignature transforms. The focus is on machine learning,\nand as such includes features such as CPU parallelism, GPU support, and\nbackpropagation. To our knowledge it is the first GPU-capable library for these\noperations. Signatory implements new features not available in previous\nlibraries, such as efficient precomputation strategies. Furthermore, several\nnovel algorithmic improvements are introduced, producing substantial real-world\nspeedups even on the CPU without parallelism. The library operates as a Python\nwrapper around C++, and is compatible with the PyTorch ecosystem. It may be\ninstalled directly via \\texttt{pip}. Source code, documentation, examples,\nbenchmarks and tests may be found at\n\\texttt{\\url{https://github.com/patrick-kidger/signatory}}. The license is\nApache-2.0.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 03:15:58 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 19:28:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kidger", "Patrick", ""], ["Lyons", "Terry", ""]]}, {"id": "2001.00742", "submitter": "George Monta\\~nez", "authors": "Tyler Sam, Jake Williams, Abel Tadesse, Huey Sun, George Montanez", "title": "Decomposable Probability-of-Success Metrics in Algorithmic Search", "comments": "Accepted to 12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have used a specific success metric within an algorithmic\nsearch framework to prove machine learning impossibility results. However, this\nspecific success metric prevents us from applying these results on other forms\nof machine learning, e.g. transfer learning. We define decomposable metrics as\na category of success metrics for search problems which can be expressed as a\nlinear operation on a probability distribution to solve this issue. Using an\narbitrary decomposable metric to measure the success of a search, we\ndemonstrate theorems which bound success in various ways, generalizing several\nexisting results in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 06:26:57 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Sam", "Tyler", ""], ["Williams", "Jake", ""], ["Tadesse", "Abel", ""], ["Sun", "Huey", ""], ["Montanez", "George", ""]]}, {"id": "2001.00745", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Xian Wu, Zhiqiang Tao, Yaliang Li, Bolin Ding, Ruirui Li,\n  Zhenhui Li", "title": "Automated Relational Meta-learning", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to efficiently learn with small amount of data on new tasks,\nmeta-learning transfers knowledge learned from previous tasks to the new ones.\nHowever, a critical challenge in meta-learning is the task heterogeneity which\ncannot be well handled by traditional globally shared meta-learning methods. In\naddition, current task-specific meta-learning methods may either suffer from\nhand-crafted structure design or lack the capability to capture complex\nrelations between tasks. In this paper, motivated by the way of knowledge\norganization in knowledge bases, we propose an automated relational\nmeta-learning (ARML) framework that automatically extracts the cross-task\nrelations and constructs the meta-knowledge graph. When a new task arrives, it\ncan quickly find the most relevant structure and tailor the learned structure\nknowledge to the meta-learner. As a result, the proposed framework not only\naddresses the challenge of task heterogeneity by a learned meta-knowledge\ngraph, but also increases the model interpretability. We conduct extensive\nexperiments on 2D toy regression and few-shot image classification and the\nresults demonstrate the superiority of ARML over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 07:02:25 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Yao", "Huaxiu", ""], ["Wu", "Xian", ""], ["Tao", "Zhiqiang", ""], ["Li", "Yaliang", ""], ["Ding", "Bolin", ""], ["Li", "Ruirui", ""], ["Li", "Zhenhui", ""]]}, {"id": "2001.00766", "submitter": "G Manjunath", "authors": "G Manjunath", "title": "Stability and Memory-loss go Hand-in-Hand: Three Results in Dynamics &\n  Computation", "comments": "To appear in the Proceedings of the Royal Society of London, Series A", "journal-ref": null, "doi": "10.1098/rspa.2020.0563", "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for universal laws that help establish a relationship between\ndynamics and computation is driven by recent expansionist initiatives in\nbiologically inspired computing. A general setting to understand both such\ndynamics and computation is a driven dynamical system that responds to a\ntemporal input. Surprisingly, we find memory-loss a feature of driven systems\nto forget their internal states helps provide unambiguous answers to the\nfollowing fundamental stability questions that have been unanswered for\ndecades: what is necessary and sufficient so that slightly different inputs\nstill lead to mostly similar responses? How does changing the driven system's\nparameters affect stability? What is the mathematical definition of the\nedge-of-criticality? We anticipate our results to be timely in understanding\nand designing biologically inspired computers that are entering an era of\ndedicated hardware implementations for neuromorphic computing and\nstate-of-the-art reservoir computing applications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 09:28:00 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 12:24:10 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Manjunath", "G", ""]]}, {"id": "2001.00781", "submitter": "Matthias A{\\ss}enmacher", "authors": "Matthias A{\\ss}enmacher, Christian Heumann", "title": "On the comparability of Pre-trained Language Models", "comments": null, "journal-ref": "Proceedings of the 5th Swiss Text Analytics Conference (SwissText)\n  & 16th Conference on Natural Language Processing (KONVENS), Zurich,\n  Switzerland, June 23-25, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in unsupervised representation learning have successfully\nestablished the concept of transfer learning in NLP. Mainly three forces are\ndriving the improvements in this area of research: More elaborated\narchitectures are making better use of contextual information. Instead of\nsimply plugging in static pre-trained representations, these are learned based\non surrounding context in end-to-end trainable models with more intelligently\ndesigned language modelling objectives. Along with this, larger corpora are\nused as resources for pre-training large language models in a self-supervised\nfashion which are afterwards fine-tuned on supervised tasks. Advances in\nparallel computing as well as in cloud computing, made it possible to train\nthese models with growing capacities in the same or even in shorter time than\npreviously established models. These three developments agglomerate in new\nstate-of-the-art (SOTA) results being revealed in a higher and higher\nfrequency. It is not always obvious where these improvements originate from, as\nit is not possible to completely disentangle the contributions of the three\ndriving forces. We set ourselves to providing a clear and concise overview on\nseveral large pre-trained language models, which achieved SOTA results in the\nlast two years, with respect to their use of new architectures and resources.\nWe want to clarify for the reader where the differences between the models are\nand we furthermore attempt to gain some insight into the single contributions\nof lexical/computational improvements as well as of architectural changes. We\nexplicitly do not intend to quantify these contributions, but rather see our\nwork as an overview in order to identify potential starting points for\nbenchmark comparisons. Furthermore, we tentatively want to point at potential\npossibilities for improvement in the field of open-sourcing and reproducible\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 10:53:35 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["A\u00dfenmacher", "Matthias", ""], ["Heumann", "Christian", ""]]}, {"id": "2001.00784", "submitter": "Dong Liu", "authors": "Dong Liu, Chengjian Sun, Chenyang Yang, Lajos Hanzo", "title": "Optimizing Wireless Systems Using Unsupervised and\n  Reinforced-Unsupervised Deep Learning", "comments": "To appear in IEEE Network Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource allocation and transceivers in wireless networks are usually\ndesigned by solving optimization problems subject to specific constraints,\nwhich can be formulated as variable or functional optimization. If the\nobjective and constraint functions of a variable optimization problem can be\nderived, standard numerical algorithms can be applied for finding the optimal\nsolution, which however incur high computational cost when the dimension of the\nvariable is high. To reduce the on-line computational complexity, learning the\noptimal solution as a function of the environment's status by deep neural\nnetworks (DNNs) is an effective approach. DNNs can be trained under the\nsupervision of optimal solutions, which however, is not applicable to the\nscenarios without models or for functional optimization where the optimal\nsolutions are hard to obtain. If the objective and constraint functions are\nunavailable, reinforcement learning can be applied to find the solution of a\nfunctional optimization problem, which is however not tailored to optimization\nproblems in wireless networks. In this article, we introduce unsupervised and\nreinforced-unsupervised learning frameworks for solving both variable and\nfunctional optimization problems without the supervision of the optimal\nsolutions. When the mathematical model of the environment is completely known\nand the distribution of environment's status is known or unknown, we can invoke\nunsupervised learning algorithm. When the mathematical model of the environment\nis incomplete, we introduce reinforced-unsupervised learning algorithms that\nlearn the model by interacting with the environment. Our simulation results\nconfirm the applicability of these learning frameworks by taking a user\nassociation problem as an example.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:01:52 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Liu", "Dong", ""], ["Sun", "Chengjian", ""], ["Yang", "Chenyang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2001.00786", "submitter": "Alessandro Paolo Capasso", "authors": "Alessandro Paolo Capasso, Giulio Bacchiani, Daniele Molinari", "title": "Intelligent Roundabout Insertion using Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of ICAART 2020, ISBN: 978-989-758-395-7", "doi": "10.5220/0008915003780385", "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important topic in the autonomous driving research is the development of\nmaneuver planning systems. Vehicles have to interact and negotiate with each\nother so that optimal choices, in terms of time and safety, are taken. For this\npurpose, we present a maneuver planning module able to negotiate the entering\nin busy roundabouts. The proposed module is based on a neural network trained\nto predict when and how entering the roundabout throughout the whole duration\nof the maneuver. Our model is trained with a novel implementation of A3C, which\nwe will call Delayed A3C (D-A3C), in a synthetic environment where vehicles\nmove in a realistic manner with interaction capabilities. In addition, the\nsystem is trained such that agents feature a unique tunable behavior, emulating\nreal world scenarios where drivers have their own driving styles. Similarly,\nthe maneuver can be performed using different aggressiveness levels, which is\nparticularly useful to manage busy scenarios where conservative rule-based\npolicies would result in undefined waits.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:16:41 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 11:24:33 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 09:22:53 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Capasso", "Alessandro Paolo", ""], ["Bacchiani", "Giulio", ""], ["Molinari", "Daniele", ""]]}, {"id": "2001.00805", "submitter": "Brendan O'Donoghue", "authors": "Brendan O'Donoghue, Ian Osband, Catalin Ionescu", "title": "Making Sense of Reinforcement Learning and Probabilistic Inference", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) combines a control problem with statistical\nestimation: The system dynamics are not known to the agent, but can be learned\nthrough experience. A recent line of research casts `RL as inference' and\nsuggests a particular framework to generalize the RL problem as probabilistic\ninference. Our paper surfaces a key shortcoming in that approach, and clarifies\nthe sense in which RL can be coherently cast as an inference problem. In\nparticular, an RL agent must consider the effects of its actions upon future\nrewards and observations: The exploration-exploitation tradeoff. In all but the\nmost simple settings, the resulting inference is computationally intractable so\nthat practical RL algorithms must resort to approximation. We demonstrate that\nthe popular `RL as inference' approximation can perform poorly in even very\nbasic problems. However, we show that with a small modification the framework\ndoes yield algorithms that can provably perform well, and we show that the\nresulting algorithm is equivalent to the recently proposed K-learning, which we\nfurther connect with Thompson sampling.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 12:50:42 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:32:36 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 18:12:05 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["O'Donoghue", "Brendan", ""], ["Osband", "Ian", ""], ["Ionescu", "Catalin", ""]]}, {"id": "2001.00811", "submitter": "Georgia Papacharalampous", "authors": "Georgia Papacharalampous, Hristos Tyralis", "title": "Hydrological time series forecasting using simple combinations: Big data\n  testing and investigations on one-year ahead river flow predictability", "comments": null, "journal-ref": "Journal of Hydrology 590 (2020) 125205", "doi": "10.1016/j.jhydrol.2020.125205", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delivering useful hydrological forecasts is critical for urban and\nagricultural water management, hydropower generation, flood protection and\nmanagement, drought mitigation and alleviation, and river basin planning and\nmanagement, among others. In this work, we present and appraise a new simple\nand flexible methodology for hydrological time series forecasting. This\nmethodology relies on (a) at least two individual forecasting methods and (b)\nthe median combiner of forecasts. The appraisal is made by using a big dataset\nconsisted of 90-year-long mean annual river flow time series from approximately\n600 stations. Covering large parts of North America and Europe, these stations\nrepresent various climate and catchment characteristics, and thus can\ncollectively support benchmarking. Five individual forecasting methods and 26\nvariants of the introduced methodology are applied to each time series. The\napplication is made in one-step ahead forecasting mode. The individual methods\nare the last-observation benchmark, simple exponential smoothing, complex\nexponential smoothing, automatic autoregressive fractionally integrated moving\naverage (ARFIMA) and Facebook's Prophet, while the 26 variants are defined by\nall the possible combinations (per two, three, four or five) of the five\nafore-mentioned methods. The new methodology is identified as well-performing\nin the long run, especially when more than two individual forecasting methods\nare combined within its framework. Moreover, the possibility of case-informed\nintegrations of diverse hydrological forecasting methods within systematic\nframeworks is algorithmically investigated and discussed. The related\ninvestigations encompass linear regression analyses, which aim at finding\ninterpretable relationships between the values of a representative forecasting\nperformance metric and the values of selected river flow statistics...\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:45:43 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 16:58:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Papacharalampous", "Georgia", ""], ["Tyralis", "Hristos", ""]]}, {"id": "2001.00813", "submitter": "Ian Barrodale", "authors": "Ian Barrodale", "title": "Computing L1 Straight-Line Fits to Data (Part 1)", "comments": "The report is 25 pages long and contains more than two dozen figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The initial remarks in this technical report are primarily for those not\nfamiliar with the properties of L1 approximation, but the remainder of the\nreport should also interest readers who are already acquainted with the inner\nworkings of L1 algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 02:29:49 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Barrodale", "Ian", ""]]}, {"id": "2001.00817", "submitter": "Marc Walton", "authors": "Lindsay Oakley, Stephanie Zaleski, Billie Males, Ollie Cossairt, Marc\n  Walton", "title": "Improved Spectral Imaging Microscopy for Cultural Heritage through\n  Oblique Illumination", "comments": null, "journal-ref": null, "doi": "10.1186/s40494-020-00369-0", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.optics", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work presents the development of a flexible microscopic chemical imaging\nplatform for cultural heritage that utilizes wavelength-tunable oblique\nillumination from a point source to obtain per-pixel reflectance spectra in the\nVIS-NIR range. The microscope light source can be adjusted on two axes allowing\nfor a hemisphere of possible illumination directions. The synthesis of multiple\nillumination angles allows for the calculation of surface normal vectors,\nsimilar to phase gradients, and axial optical sectioning. The extraction of\nspectral reflectance images with high spatial resolutions from these data is\ndemonstrated through the analysis of a replica cross-section, created from\nknown painting reference materials, as well as a sample extracted from a\npainting by Pablo Picasso entitled La Mis\\'ereuse accroupie (1902). These case\nstudies show the rich microscale molecular information that may be obtained\nusing this microscope and how the instrument overcomes challenges for spectral\nanalysis commonly encountered on works of art with complex matrices composed of\nboth inorganic minerals and organic lakes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:00:49 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Oakley", "Lindsay", ""], ["Zaleski", "Stephanie", ""], ["Males", "Billie", ""], ["Cossairt", "Ollie", ""], ["Walton", "Marc", ""]]}, {"id": "2001.00818", "submitter": "Soma Dhavala", "authors": "Shakkeel Ahmed, Ravi S. Mula, Soma S. Dhavala", "title": "A Framework for Democratizing AI", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning and Artificial Intelligence are considered an integral part\nof the Fourth Industrial Revolution. Their impact, and far-reaching\nconsequences, while acknowledged, are yet to be comprehended. These\ntechnologies are very specialized, and few organizations and select highly\ntrained professionals have the wherewithal, in terms of money, manpower, and\nmight, to chart the future. However, concentration of power can lead to\nmarginalization, causing severe inequalities. Regulatory agencies and\ngovernments across the globe are creating national policies, and laws around\nthese technologies to protect the rights of the digital citizens, as well as to\nempower them. Even private, not-for-profit organizations are also contributing\nto democratizing the technologies by making them \\emph{accessible} and\n\\emph{affordable}. However, accessibility and affordability are all but a few\nof the facets of democratizing the field. Others include, but not limited to,\n\\emph{portability}, \\emph{explainability}, \\emph{credibility}, \\emph{fairness},\namong others. As one can imagine, democratizing AI is a multi-faceted problem,\nand it requires advancements in science, technology and policy. At\n\\texttt{mlsquare}, we are developing scientific tools in this space.\nSpecifically, we introduce an opinionated, extensible, \\texttt{Python}\nframework that provides a single point of interface to a variety of solutions\nin each of the categories mentioned above. We present the design details, APIs\nof the framework, reference implementations, road map for development, and\nguidelines for contributions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:30:14 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Ahmed", "Shakkeel", ""], ["Mula", "Ravi S.", ""], ["Dhavala", "Soma S.", ""]]}, {"id": "2001.00846", "submitter": "Diego Antognini", "authors": "Nikola Milojkovic, Diego Antognini, Giancarlo Bergamin, Boi Faltings\n  and Claudiu Musat", "title": "Multi-Gradient Descent for Multi-Objective Recommender Systems", "comments": "9 pages, 4 figures, Accepted at AAAI 2020 - Workshop on Interactive\n  and Conversational Recommendation Systems (WICRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems need to mirror the complexity of the environment they are\napplied in. The more we know about what might benefit the user, the more\nobjectives the recommender system has. In addition there may be multiple\nstakeholders - sellers, buyers, shareholders - in addition to legal and ethical\nconstraints. Simultaneously optimizing for a multitude of objectives,\ncorrelated and not correlated, having the same scale or not, has proven\ndifficult so far.\n  We introduce a stochastic multi-gradient descent approach to recommender\nsystems (MGDRec) to solve this problem. We show that this exceeds\nstate-of-the-art methods in traditional objective mixtures, like revenue and\nrecall. Not only that, but through gradient normalization we can combine\nfundamentally different objectives, having diverse scales, into a single\ncoherent framework. We show that uncorrelated objectives, like the proportion\nof quality products, can be improved alongside accuracy. Through the use of\nstochasticity, we avoid the pitfalls of calculating full gradients and provide\na clear setting for its applicability.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 19:56:08 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:04:23 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:35:21 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Milojkovic", "Nikola", ""], ["Antognini", "Diego", ""], ["Bergamin", "Giancarlo", ""], ["Faltings", "Boi", ""], ["Musat", "Claudiu", ""]]}, {"id": "2001.00861", "submitter": "Kishaloy Halder", "authors": "Kishaloy Halder, Heng-Tze Cheng, Ellie Ka In Chio, Georgios Roumpos,\n  Tao Wu, Ritesh Agarwal", "title": "Modeling Information Need of Users in Search Sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users issue queries to Search Engines, and try to find the desired\ninformation in the results produced. They repeat this process if their\ninformation need is not met at the first place. It is crucial to identify the\nimportant words in a query that depict the actual information need of the user\nand will determine the course of a search session. To this end, we propose a\nsequence-to-sequence based neural architecture that leverages the set of past\nqueries issued by users, and results that were explored by them. Firstly, we\nemploy our model for predicting the words in the current query that are\nimportant and would be retained in the next query. Additionally, as a\ndownstream application of our model, we evaluate it on the widely popular task\nof next query suggestion. We show that our intuitive strategy of capturing\ninformation need can yield superior performance at these tasks on two large\nreal-world search log datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 15:25:45 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Halder", "Kishaloy", ""], ["Cheng", "Heng-Tze", ""], ["Chio", "Ellie Ka In", ""], ["Roumpos", "Georgios", ""], ["Wu", "Tao", ""], ["Agarwal", "Ritesh", ""]]}, {"id": "2001.00893", "submitter": "Eyke H\\\"ullermeier", "authors": "Mohammad Hossein Shaker and Eyke H\\\"ullermeier", "title": "Aleatoric and Epistemic Uncertainty with Random Forests", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the steadily increasing relevance of machine learning for practical\napplications, many of which are coming with safety requirements, the notion of\nuncertainty has received increasing attention in machine learning research in\nthe last couple of years. In particular, the idea of distinguishing between two\nimportant types of uncertainty, often refereed to as aleatoric and epistemic,\nhas recently been studied in the setting of supervised learning. In this paper,\nwe propose to quantify these uncertainties with random forests. More\nspecifically, we show how two general approaches for measuring the learner's\naleatoric and epistemic uncertainty in a prediction can be instantiated with\ndecision trees and random forests as learning algorithms in a classification\nsetting. In this regard, we also compare random forests with deep neural\nnetworks, which have been used for a similar purpose.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:08:44 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Shaker", "Mohammad Hossein", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2001.00916", "submitter": "Zakaria El Mrabet", "authors": "Zakaria El Mrabet, Mehdi Ezzari, Hassan Elghazi, Badr Abou El Majd", "title": "Deep Learning-Based Intrusion Detection System for Advanced Metering\n  Infrastructure", "comments": "7 pages, 6 figures. 2019 NISS19: Proceedings of the 2nd International\n  Conference on Networking, Information Systems & Security", "journal-ref": null, "doi": "10.1145/3320326.3320391", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid is an alternative solution of the conventional power grid which\nharnesses the power of the information technology to save the energy and meet\ntoday's environment requirements. Due to the inherent vulnerabilities in the\ninformation technology, the smart grid is exposed to a wide variety of threats\nthat could be translated into cyber-attacks. In this paper, we develop a deep\nlearning-based intrusion detection system to defend against cyber-attacks in\nthe advanced metering infrastructure network. The proposed machine learning\napproach is trained and tested extensively on an empirical industrial dataset\nwhich is composed of several attack categories including the scanning, buffer\noverflow, and denial of service attacks. Then, an experimental comparison in\nterms of detection accuracy is conducted to evaluate the performance of the\nproposed approach with Naive Bayes, Support Vector Machine, and Random Forest.\nThe obtained results suggest that the proposed approaches produce optimal\nresults comparing to the other algorithms. Finally, we propose a network\narchitecture to deploy the proposed anomaly-based intrusion detection system\nacross the Advanced Metering Infrastructure network. In addition, we propose a\nnetwork security architecture composed of two types of Intrusion detection\nsystem types, Host and Network-based, deployed across the Advanced Metering\nInfrastructure network to inspect the traffic and detect the malicious one at\nall the levels.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 21:06:20 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mrabet", "Zakaria El", ""], ["Ezzari", "Mehdi", ""], ["Elghazi", "Hassan", ""], ["Majd", "Badr Abou El", ""]]}, {"id": "2001.00917", "submitter": "Zakaria El Mrabet", "authors": "Zakaria El Mrabet, Hassan El Ghazi, Naima Kaabouch", "title": "A Performance Comparison of Data Mining Algorithms Based Intrusion\n  Detection System for Smart Grid", "comments": "6 pages, 6 Figures", "journal-ref": "2019 IEEE International Conference on Electro Information\n  Technology (EIT)", "doi": "10.1109/EIT.2019.8834255", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart grid is an emerging and promising technology. It uses the power of\ninformation technologies to deliver intelligently the electrical power to\ncustomers, and it allows the integration of the green technology to meet the\nenvironmental requirements. Unfortunately, information technologies have its\ninherent vulnerabilities and weaknesses that expose the smart grid to a wide\nvariety of security risks. The Intrusion detection system (IDS) plays an\nimportant role in securing smart grid networks and detecting malicious\nactivity, yet it suffers from several limitations. Many research papers have\nbeen published to address these issues using several algorithms and techniques.\nTherefore, a detailed comparison between these algorithms is needed. This paper\npresents an overview of four data mining algorithms used by IDS in Smart Grid.\nAn evaluation of performance of these algorithms is conducted based on several\nmetrics including the probability of detection, probability of false alarm,\nprobability of miss detection, efficiency, and processing time. Results show\nthat Random Forest outperforms the other three algorithms in detecting attacks\nwith higher probability of detection, lower probability of false alarm, lower\nprobability of miss detection, and higher accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 20:48:13 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mrabet", "Zakaria El", ""], ["Ghazi", "Hassan El", ""], ["Kaabouch", "Naima", ""]]}, {"id": "2001.00918", "submitter": "Wenhang Bao", "authors": "Wenhang Bao", "title": "Fairness in Multi-agent Reinforcement Learning for Stock Trading", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.11046;\n  text overlap with arXiv:1907.10323 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG cs.MA q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unfair stock trading strategies have been shown to be one of the most\nnegative perceptions that customers can have concerning trading and may result\nin long-term losses for a company. Investment banks usually place trading\norders for multiple clients with the same target assets but different order\nsizes and diverse requirements such as time frame and risk aversion level,\nthereby total earning and individual earning cannot be optimized at the same\ntime. Orders executed earlier would affect the market price level, so late\nexecution usually means additional implementation cost. In this paper, we\npropose a novel scheme that utilizes multi-agent reinforcement learning systems\nto derive stock trading strategies for all clients which keep a balance between\nrevenue and fairness. First, we demonstrate that Reinforcement learning (RL) is\nable to learn from experience and adapt the trading strategies to the complex\nmarket environment. Secondly, we show that the Multi-agent RL system allows\ndeveloping trading strategies for all clients individually, thus optimizing\nindividual revenue. Thirdly, we use the Generalized Gini Index (GGI)\naggregation function to control the fairness level of the revenue across all\nclients. Lastly, we empirically demonstrate the superiority of the novel scheme\nin improving fairness meanwhile maintaining optimization of revenue.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 16:58:51 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Bao", "Wenhang", ""]]}, {"id": "2001.00920", "submitter": "Javier Trejos", "authors": "Andres Quiros-Granados, JAvier Trejos-Zelaya", "title": "Estimation of the yield curve for Costa Rica using combinatorial\n  optimization metaheuristics applied to nonlinear regression", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The term structure of interest rates or yield curve is a function relating\nthe interest rate with its own term. Nonlinear regression models of\nNelson-Siegel and Svensson were used to estimate the yield curve using a sample\nof historical data supplied by the National Stock Exchange of Costa Rica. The\noptimization problem involved in the estimation process of model parameters is\naddressed by the use of four well known combinatorial optimization\nmetaheuristics: Ant colony optimization, Genetic algorithm, Particle swarm\noptimization and Simulated annealing. The aim of the study is to improve the\nlocal minima obtained by a classical quasi-Newton optimization method using a\ndescent direction. Good results with at least two metaheuristics are achieved,\nParticle swarm optimization and Simulated annealing. Keywords: Yield curve,\nnonlinear regression, Nelson-\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:55:44 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Quiros-Granados", "Andres", ""], ["Trejos-Zelaya", "JAvier", ""]]}, {"id": "2001.00921", "submitter": "Theodore Papamarkou", "authors": "Devanshu Agrawal, Theodore Papamarkou, Jacob Hinkle", "title": "Wide Neural Networks with Bottlenecks are Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been much work on the \"wide limit\" of neural networks,\nwhere Bayesian neural networks (BNNs) are shown to converge to a Gaussian\nprocess (GP) as all hidden layers are sent to infinite width. However, these\nresults do not apply to architectures that require one or more of the hidden\nlayers to remain narrow. In this paper, we consider the wide limit of BNNs\nwhere some hidden layers, called \"bottlenecks\", are held at finite width. The\nresult is a composition of GPs that we term a \"bottleneck neural network\nGaussian process\" (bottleneck NNGP). Although intuitive, the subtlety of the\nproof is in showing that the wide limit of a composition of networks is in fact\nthe composition of the limiting GPs. We also analyze theoretically a\nsingle-bottleneck NNGP, finding that the bottleneck induces dependence between\nthe outputs of a multi-output network that persists through extreme\npost-bottleneck depths, and prevents the kernel of the network from losing\ndiscriminative power at extreme post-bottleneck depths.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:13:45 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:12:18 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 16:17:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Agrawal", "Devanshu", ""], ["Papamarkou", "Theodore", ""], ["Hinkle", "Jacob", ""]]}, {"id": "2001.00926", "submitter": "Ephrem Wu", "authors": "Ephrem Wu", "title": "Learning Accurate Integer Transformer Machine-Translation Models", "comments": null, "journal-ref": null, "doi": "10.1007/s42979-021-00688-4", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for training accurate Transformer machine-translation\nmodels to run inference using 8-bit integer (INT8) hardware matrix multipliers,\nas opposed to the more costly single-precision floating-point (FP32) hardware.\nUnlike previous work, which converted only 85 Transformer matrix\nmultiplications to INT8, leaving 48 out of 133 of them in FP32 because of\nunacceptable accuracy loss, we convert them all to INT8 without compromising\naccuracy. Tested on the newstest2014 English-to-German translation task, our\nINT8 Transformer Base and Transformer Big models yield BLEU scores that are\n99.3% to 100% relative to those of the corresponding FP32 models. Our approach\nconverts all matrix-multiplication tensors from an existing FP32 model into\nINT8 tensors by automatically making range-precision trade-offs during\ntraining. To demonstrate the robustness of this approach, we also include\nresults from INT6 Transformer models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:40:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wu", "Ephrem", ""]]}, {"id": "2001.00927", "submitter": "Masoud Mohseni", "authors": "Gavin S. Hartnett, Masoud Mohseni", "title": "A Probability Density Theory for Spin-Glass Systems", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spin-glass systems are universal models for representing many-body phenomena\nin statistical physics and computer science. High quality solutions of NP-hard\ncombinatorial optimization problems can be encoded into low energy states of\nspin-glass systems. In general, evaluating the relevant physical and\ncomputational properties of such models is difficult due to critical slowing\ndown near a phase transition. Ideally, one could use recent advances in deep\nlearning for characterizing the low-energy properties of these complex systems.\nUnfortunately, many of the most promising machine learning approaches are only\nvalid for distributions over continuous variables and thus cannot be directly\napplied to discrete spin-glass models. To this end, we develop a continuous\nprobability density theory for spin-glass systems with arbitrary dimensions,\ninteractions, and local fields. We show how our formulation geometrically\nencodes key physical and computational properties of the spin-glass in an\ninstance-wise fashion without the need for quenched disorder averaging. We show\nthat our approach is beyond the mean-field theory and identify a transition\nfrom a convex to non-convex energy landscape as the temperature is lowered past\na critical temperature. We apply our formalism to a number of spin-glass models\nincluding the Sherrington-Kirkpatrick (SK) model, spins on random\nErd\\H{o}s-R\\'enyi graphs, and random restricted Boltzmann machines.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:43:35 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 19:00:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hartnett", "Gavin S.", ""], ["Mohseni", "Masoud", ""]]}, {"id": "2001.00939", "submitter": "Henning Petzka", "authors": "Henning Petzka, Michael Kamp, Linara Adilova, Mario Boley, Cristian\n  Sminchisescu", "title": "Relative Flatness and Generalization in the Interpolation Regime", "comments": "arXiv admin note: substantial text overlap with arXiv:1912.00058", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional generalization bounds are based on analyzing the limits of the\nmodel capacity. Therefore, they become vacuous in the \\emph{interpolation}\n(over-parameterized) regime of modern machine learning models where training\ndata can be fitted perfectly. This paper proposes a new approach to meaningful\ngeneralization bounds in the interpolation regime by decomposing the\ngeneralization gap into a notion of \\emph{representativeness} and \\emph{feature\nrobustness}. Representativeness captures properties of the data distribution\nand mitigates the dependence on the data dimension by exploiting the\nlow-dimensional feature representation used implicitly by the model, and\nfeature robustness captures the expected change in loss resulting from\nperturbations of these implicit features. We show that feature robustness can\nbe bounded by a relative flatness measure of the empirical loss surface for\nmodels that locally minimize the training loss. This yields an\nalgorithm-agnostic bound potentially explaining the abundance of empirical\nobservations that flatness of the loss surface is correlated with\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:39:03 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:06:48 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 08:56:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Petzka", "Henning", ""], ["Kamp", "Michael", ""], ["Adilova", "Linara", ""], ["Boley", "Mario", ""], ["Sminchisescu", "Cristian", ""]]}, {"id": "2001.00991", "submitter": "Marc Killpack", "authors": "Erich Mielke, Eric Townsend, David Wingate, and Marc D. Killpack", "title": "Human-robot co-manipulation of extended objects: Data-driven models and\n  control from analysis of human-human dyads", "comments": "Paper has been in submission to IJRR since November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human teams are able to easily perform collaborative manipulation tasks.\nHowever, for a robot and human to simultaneously manipulate an extended object\nis a difficult task using existing methods from the literature. Our approach in\nthis paper is to use data from human-human dyad experiments to determine motion\nintent which we use for a physical human-robot co-manipulation task. We first\npresent and analyze data from human-human dyads performing co-manipulation\ntasks. We show that our human-human dyad data has interesting trends including\nthat interaction forces are non-negligible compared to the force required to\naccelerate an object and that the beginning of a lateral movement is\ncharacterized by distinct torque triggers from the leader of the dyad. We also\nexamine different metrics to quantify performance of different dyads. We also\ndevelop a deep neural network based on motion data from human-human trials to\npredict human intent based on past motion. We then show how force and motion\ndata can be used as a basis for robot control in a human-robot dyad. Finally,\nwe compare the performance of two controllers for human-robot co-manipulation\nto human-human dyad performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 21:23:12 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Mielke", "Erich", ""], ["Townsend", "Eric", ""], ["Wingate", "David", ""], ["Killpack", "Marc D.", ""]]}, {"id": "2001.00994", "submitter": "Guruprasad Nayak", "authors": "Guruprasad Nayak, Rahul Ghosh, Xiaowei Jia, Varun Mithal, Vipin Kumar", "title": "Semi-supervised Classification using Attention-based Regularization on\n  Coarse-resolution Data", "comments": "To appear in the proceedings of the SIAM International Conference on\n  Data Mining (SDM20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world phenomena are observed at multiple resolutions. Predictive\nmodels designed to predict these phenomena typically consider different\nresolutions separately. This approach might be limiting in applications where\npredictions are desired at fine resolutions but available training data is\nscarce. In this paper, we propose classification algorithms that leverage\nsupervision from coarser resolutions to help train models on finer resolutions.\nThe different resolutions are modeled as different views of the data in a\nmulti-view framework that exploits the complementarity of features across\ndifferent views to improve models on both views. Unlike traditional multi-view\nlearning problems, the key challenge in our case is that there is no one-to-one\ncorrespondence between instances across different views in our case, which\nrequires explicit modeling of the correspondence of instances across\nresolutions. We propose to use the features of instances at different\nresolutions to learn the correspondence between instances across resolutions\nusing an attention mechanism.Experiments on the real-world application of\nmapping urban areas using satellite observations and sentiment classification\non text data show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 21:29:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nayak", "Guruprasad", ""], ["Ghosh", "Rahul", ""], ["Jia", "Xiaowei", ""], ["Mithal", "Varun", ""], ["Kumar", "Vipin", ""]]}, {"id": "2001.01006", "submitter": "Shixiong Zhang", "authors": "Shixiong Zhang, Xiangtao Li, Qiuzhen Lin, and Ka-Chun Wong", "title": "Review of Single-cell RNA-seq Data Clustering for Cell Type\n  Identification and Characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the advances in single-cell RNA-seq techniques have enabled\nus to perform large-scale transcriptomic profiling at single-cell resolution in\na high-throughput manner. Unsupervised learning such as data clustering has\nbecome the central component to identify and characterize novel cell types and\ngene expression patterns. In this study, we review the existing single-cell\nRNA-seq data clustering methods with critical insights into the related\nadvantages and limitations. In addition, we also review the upstream\nsingle-cell RNA-seq data processing techniques such as quality control,\nnormalization, and dimension reduction. We conduct performance comparison\nexperiments to evaluate several popular single-cell RNA-seq clustering\napproaches on two single-cell transcriptomic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 22:48:10 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Shixiong", ""], ["Li", "Xiangtao", ""], ["Lin", "Qiuzhen", ""], ["Wong", "Ka-Chun", ""]]}, {"id": "2001.01015", "submitter": "Ghazaleh Beigi", "authors": "Ghazaleh Beigi, Jiliang Tang, Huan Liu", "title": "Social Science Guided Feature Engineering: A Novel Approach to Signed\n  Link Analysis", "comments": "This worked is published at ACM Transactions on Intelligent Systems\n  and Technology(ACM TIST), 2019", "journal-ref": null, "doi": "10.1145/3364222", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world relations can be represented by signed networks with positive\nlinks (e.g., friendships and trust) and negative links (e.g., foes and\ndistrust). Link prediction helps advance tasks in social network analysis such\nas recommendation systems. Most existing work on link analysis focuses on\nunsigned social networks. The existence of negative links piques research\ninterests in investigating whether properties and principles of signed networks\ndiffer from those of unsigned networks, and mandates dedicated efforts on link\nanalysis for signed social networks. Recent findings suggest that properties of\nsigned networks substantially differ from those of unsigned networks and\nnegative links can be of significant help in signed link analysis in\ncomplementary ways. In this article, we center our discussion on a challenging\nproblem of signed link analysis. Signed link analysis faces the problem of data\nsparsity, i.e. only a small percentage of signed links are given. This problem\ncan even get worse when negative links are much sparser than positive ones as\nusers are inclined more towards positive disposition rather than negative. We\ninvestigate how we can take advantage of other sources of information for\nsigned link analysis. This research is mainly guided by three social science\ntheories, Emotional Information, Diffusion of Innovations, and Individual\nPersonality. Guided by these, we extract three categories of related features\nand leverage them for signed link analysis. Experiments show the significance\nof the features gleaned from social theories for signed link prediction and\naddressing the data sparsity challenge.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 00:26:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Beigi", "Ghazaleh", ""], ["Tang", "Jiliang", ""], ["Liu", "Huan", ""]]}, {"id": "2001.01017", "submitter": "Waheed Bajwa", "authors": "Haroon Raja and Waheed U. Bajwa", "title": "Distributed Stochastic Algorithms for High-rate Streaming Principal\n  Component Analysis", "comments": "37 pages, 11 figures; preprint of a journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating the principal eigenvector of a\ncovariance matrix from independent and identically distributed data samples in\nstreaming settings. The streaming rate of data in many contemporary\napplications can be high enough that a single processor cannot finish an\niteration of existing methods for eigenvector estimation before a new sample\narrives. This paper formulates and analyzes a distributed variant of the\nclassical Krasulina's method (D-Krasulina) that can keep up with the high\nstreaming rate of data by distributing the computational load across multiple\nprocessing nodes. The analysis shows that---under appropriate\nconditions---D-Krasulina converges to the principal eigenvector in an\norder-wise optimal manner; i.e., after receiving $M$ samples across all nodes,\nits estimation error can be $O(1/M)$. In order to reduce the network\ncommunication overhead, the paper also develops and analyzes a mini-batch\nextension of D-Krasulina, which is termed DM-Krasulina. The analysis of\nDM-Krasulina shows that it can also achieve order-optimal estimation error\nrates under appropriate conditions, even when some samples have to be discarded\nwithin the network due to communication latency. Finally, experiments are\nperformed over synthetic and real-world data to validate the convergence\nbehaviors of D-Krasulina and DM-Krasulina in high-rate streaming settings.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 00:46:47 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raja", "Haroon", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2001.01037", "submitter": "Jiamei Sun", "authors": "Jiamei Sun, Sebastian Lapuschkin, Wojciech Samek, Alexander Binder", "title": "Understanding Image Captioning Models beyond Visualizing Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper interprets the predictions of image captioning models with\nattention mechanisms beyond visualizing the attention itself. In this paper, we\ndevelop variants of layer-wise relevance propagation (LRP) and gradient-based\nexplanation methods, tailored to image captioning models with attention\nmechanisms. We compare the interpretability of attention heatmaps\nsystematically against the explanations computed with explanation methods such\nas LRP, Grad-CAM, and Guided Grad-CAM. We show that explanation methods provide\nsimultaneously pixel-wise image explanation (supporting and opposing pixels of\nthe input image) and linguistic explanation (supporting and opposing words of\nthe preceding sequence) for each word in the predicted captions. We demonstrate\nwith extensive experiments that explanation methods can 1) reveal more related\nevidence used by the model to make decisions than attention; 2) correlate to\nobject locations with high precision; 3) is helpful to `debug' the model such\nas analyzing the reasons for hallucinated object words. With the observed\nproperties of explanations, we further design an LRP-inference fine-tuning\nstrategy that can alleviate the object hallucination of image captioning\nmodels, meanwhile, maintain the sentence fluency. We conduct experiments with\ntwo widely used attention mechanisms: the adaptive attention mechanism\ncalculated with the additive attention and the multi-head attention calculated\nwith the scaled dot product.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 05:15:11 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 02:09:36 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 02:41:41 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 01:41:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Sun", "Jiamei", ""], ["Lapuschkin", "Sebastian", ""], ["Samek", "Wojciech", ""], ["Binder", "Alexander", ""]]}, {"id": "2001.01046", "submitter": "Minghao Chen", "authors": "Minghao Chen, Shuai Zhao, Haifeng Liu, Deng Cai", "title": "Adversarial-Learned Loss for Domain Adaptation", "comments": "Published in 34th AAAI Conference on Artificial Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, remarkable progress has been made in learning transferable\nrepresentation across domains. Previous works in domain adaptation are majorly\nbased on two techniques: domain-adversarial learning and self-training.\nHowever, domain-adversarial learning only aligns feature distributions between\ndomains but does not consider whether the target features are discriminative.\nOn the other hand, self-training utilizes the model predictions to enhance the\ndiscrimination of target features, but it is unable to explicitly align domain\ndistributions. In order to combine the strengths of these two methods, we\npropose a novel method called Adversarial-Learned Loss for Domain Adaptation\n(ALDA). We first analyze the pseudo-label method, a typical self-training\nmethod. Nevertheless, there is a gap between pseudo-labels and the ground\ntruth, which can cause incorrect training. Thus we introduce the confusion\nmatrix, which is learned through an adversarial manner in ALDA, to reduce the\ngap and align the feature distributions. Finally, a new loss function is\nauto-constructed from the learned confusion matrix, which serves as the loss\nfor unlabeled target samples. Our ALDA outperforms state-of-the-art approaches\nin four standard domain adaptation datasets. Our code is available at\nhttps://github.com/ZJULearning/ALDA.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 06:24:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chen", "Minghao", ""], ["Zhao", "Shuai", ""], ["Liu", "Haifeng", ""], ["Cai", "Deng", ""]]}, {"id": "2001.01051", "submitter": "Yuya Ong", "authors": "Yuya Jeremy Ong, Mu Qiao and Divyesh Jadav", "title": "Temporal Tensor Transformation Network for Multivariate Time Series\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series prediction has applications in a wide variety of\ndomains and is considered to be a very challenging task, especially when the\nvariables have correlations and exhibit complex temporal patterns, such as\nseasonality and trend. Many existing methods suffer from strong statistical\nassumptions, numerical issues with high dimensionality, manual feature\nengineering efforts, and scalability. In this work, we present a novel deep\nlearning architecture, known as Temporal Tensor Transformation Network, which\ntransforms the original multivariate time series into a higher order of tensor\nthrough the proposed Temporal-Slicing Stack Transformation. This yields a new\nrepresentation of the original multivariate time series, which enables the\nconvolution kernel to extract complex and non-linear features as well as\nvariable interactional signals from a relatively large temporal region.\nExperimental results show that Temporal Tensor Transformation Network\noutperforms several state-of-the-art methods on window-based predictions across\nvarious tasks. The proposed architecture also demonstrates robust prediction\nperformance through an extensive sensitivity analysis.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 07:28:55 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ong", "Yuya Jeremy", ""], ["Qiao", "Mu", ""], ["Jadav", "Divyesh", ""]]}, {"id": "2001.01056", "submitter": "Sayan Chakraborty", "authors": "Sayan Chakraborty, Smit Shah, Kiumars Soltani, Anna Swigart", "title": "Root Cause Detection Among Anomalous Time Series Using Temporal State\n  Alignment", "comments": "6 pages, 7 figures, 2019 18th IEEE International Conference on\n  Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent increase in the scale and complexity of software systems has\nintroduced new challenges to the time series monitoring and anomaly detection\nprocess. A major drawback of existing anomaly detection methods is that they\nlack contextual information to help stakeholders identify the cause of\nanomalies. This problem, known as root cause detection, is particularly\nchallenging to undertake in today's complex distributed software systems since\nthe metrics under consideration generally have multiple internal and external\ndependencies. Significant manual analysis and strong domain expertise is\nrequired to isolate the correct cause of the problem. In this paper, we propose\na method that isolates the root cause of an anomaly by analyzing the patterns\nin time series fluctuations. Our method considers the time series as\nobservations from an underlying process passing through a sequence of\ndiscretized hidden states. The idea is to track the propagation of the effect\nwhen a given problem causes unaligned but homogeneous shifts of the underlying\nstates. We evaluate our approach by finding the root cause of anomalies in\nZillows clickstream data by identifying causal patterns among a set of observed\nfluctuations.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 08:31:34 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chakraborty", "Sayan", ""], ["Shah", "Smit", ""], ["Soltani", "Kiumars", ""], ["Swigart", "Anna", ""]]}, {"id": "2001.01057", "submitter": "Qian Li", "authors": "Qian Li, Nan Guo, Xiaochun Ye, Dongrui Fan, and Zhimin Tang", "title": "Pixel-Semantic Revise of Position Learning A One-Stage Object Detector\n  with A Shared Encoder-Decoder", "comments": "Accepted by ICONIP2020(International Conference on Neural Information\n  Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many methods have been proposed for object detection. They cannot\ndetect objects by semantic features, adaptively. In this work, according to\nchannel and spatial attention mechanisms, we mainly analyze that different\nmethods detect objects adaptively. Some state-of-the-art detectors combine\ndifferent feature pyramids with many mechanisms to enhance multi-level semantic\ninformation. However, they require more cost. This work addresses that by an\nanchor-free detector with shared encoder-decoder with attention mechanism,\nextracting shared features. We consider features of different levels from\nbackbone (e.g., ResNet-50) as the basis features. Then, we feed the features\ninto a simple module, followed by a detector header to detect objects.\nMeantime, we use the semantic features to revise geometric locations, and the\ndetector is a pixel-semantic revising of position. More importantly, this work\nanalyzes the impact of different pooling strategies (e.g., mean, maximum or\nminimum) on multi-scale objects, and finds the minimum pooling improve\ndetection performance on small objects better. Compared with state-of-the-art\nMNC based on ResNet-101 for the standard MSCOCO 2014 baseline, our method\nimproves detection AP of 3.8%.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 08:55:00 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 02:28:34 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Qian", ""], ["Guo", "Nan", ""], ["Ye", "Xiaochun", ""], ["Fan", "Dongrui", ""], ["Tang", "Zhimin", ""]]}, {"id": "2001.01072", "submitter": "Dongrui Wu", "authors": "Xiao Zhang and Dongrui Wu", "title": "Empirical Studies on the Properties of Linear Regions in Deep Neural\n  Networks", "comments": "Int'l. Conf. on Learning Representations (ICLR), Addis Ababa,\n  Ethiopia, April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) with piecewise linear activations can partition\nthe input space into numerous small linear regions, where different linear\nfunctions are fitted. It is believed that the number of these regions\nrepresents the expressivity of the DNN. This paper provides a novel and\nmeticulous perspective to look into DNNs: Instead of just counting the number\nof the linear regions, we study their local properties, such as the inspheres,\nthe directions of the corresponding hyperplanes, the decision boundaries, and\nthe relevance of the surrounding regions. We empirically observed that\ndifferent optimization techniques lead to completely different linear regions,\neven though they result in similar classification accuracies. We hope our study\ncan inspire the design of novel optimization techniques, and help discover and\nanalyze the behaviors of DNNs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 12:47:58 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 08:06:47 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 19:08:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""]]}, {"id": "2001.01077", "submitter": "Yunpu Ma", "authors": "Yunpu Ma and Volker Tresp", "title": "Quantum Machine Learning Algorithm for Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic knowledge graphs are large-scale triple-oriented databases for\nknowledge representation and reasoning. Implicit knowledge can be inferred by\nmodeling and reconstructing the tensor representations generated from knowledge\ngraphs. However, as the sizes of knowledge graphs continue to grow, classical\nmodeling becomes increasingly computational resource intensive. This paper\ninvestigates how quantum resources can be capitalized to accelerate the\nmodeling of knowledge graphs. In particular, we propose the first quantum\nmachine learning algorithm for making inference on tensorized data, e.g., on\nknowledge graphs. Since most tensor problems are NP-hard, it is challenging to\ndevise quantum algorithms to support that task. We simplify the problem by\nmaking a plausible assumption that the tensor representation of a knowledge\ngraph can be approximated by its low-rank tensor singular value decomposition,\nwhich is verified by our experiments. The proposed sampling-based quantum\nalgorithm achieves exponential speedup with a runtime that is polylogarithmic\nin the dimension of knowledge graph tensor.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 13:26:29 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 19:52:43 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.01083", "submitter": "Naina Dhingra", "authors": "Naina Dhingra and Andreas Kunz", "title": "Res3ATN -- Deep 3D Residual Attention Network for Hand Gesture\n  Recognition in Videos", "comments": "10 pages, 4 figures, International Conference on 3D Vision (3DV\n  2019), Quebec City, Canada, September 16-19, 2019", "journal-ref": "2019 International Conference on 3D Vision (3DV), 491--501, 2019", "doi": "10.1109/3DV.2019.00061", "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand gesture recognition is a strenuous task to solve in videos. In this\npaper, we use a 3D residual attention network which is trained end to end for\nhand gesture recognition. Based on the stacked multiple attention blocks, we\nbuild a 3D network which generates different features at each attention block.\nOur 3D attention based residual network (Res3ATN) can be built and extended to\nvery deep layers. Using this network, an extensive analysis is performed on\nother 3D networks based on three publicly available datasets. The Res3ATN\nnetwork performance is compared to C3D, ResNet-10, and ResNext-101 networks. We\nalso study and evaluate our baseline network with different number of attention\nblocks. The comparison shows that the 3D residual attention network with 3\nattention blocks is robust in attention learning and is able to classify the\ngestures with better accuracy, thus outperforming existing networks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 14:36:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dhingra", "Naina", ""], ["Kunz", "Andreas", ""]]}, {"id": "2001.01095", "submitter": "Cencheng Shen", "authors": "Cencheng Shen", "title": "High-Dimensional Independence Testing and Maximum Marginal Correlation", "comments": "20 pages, 5 page appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of universally consistent dependence measures have been recently\nproposed for testing independence, such as distance correlation, kernel\ncorrelation, multiscale graph correlation, etc. They provide a satisfactory\nsolution for dependence testing in low-dimensions, but often exhibit decreasing\npower for high-dimensional data, a phenomenon that has been recognized but\nremains mostly unchartered. In this paper, we aim to better understand the\nhigh-dimensional testing scenarios and explore a procedure that is robust\nagainst increasing dimension. To that end, we propose the maximum marginal\ncorrelation method and characterize high-dimensional dependence structures via\nthe notion of dependent dimensions. We prove that the maximum method can be\nvalid and universally consistent for testing high-dimensional dependence under\nregularity conditions, and demonstrate when and how the maximum method may\noutperform other methods. The methodology can be implemented by most existing\ndependence measures, has a superior testing power in a variety of common\nhigh-dimensional settings, and is computationally efficient for big data\nanalysis when using the distance correlation chi-square test.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 16:21:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shen", "Cencheng", ""]]}, {"id": "2001.01096", "submitter": "Weiya Ren", "authors": "Weiya Ren", "title": "Represented Value Function Approach for Large Scale Multi Agent\n  Reinforcement Learning", "comments": "9 pages the code is published and the result is reproducible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of large scale multi agent\nreinforcement learning. Firstly, we studied the representation problem of the\npairwise value function to reduce the complexity of the interactions among\nagents. Secondly, we adopt a l2-norm trick to ensure the trivial term of the\napproximated value function is bounded. Thirdly, experimental results on battle\ngame demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 16:29:13 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 01:57:34 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ren", "Weiya", ""]]}, {"id": "2001.01102", "submitter": "Carlo D'Eramo", "authors": "Carlo D'Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli and\n  Jan Peters", "title": "MushroomRL: Simplifying Reinforcement Learning Research", "comments": "Under revision to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  MushroomRL is an open-source Python library developed to simplify the process\nof implementing and running Reinforcement Learning (RL) experiments. Compared\nto other available libraries, MushroomRL has been created with the purpose of\nproviding a comprehensive and flexible framework to minimize the effort in\nimplementing and testing novel RL methodologies. Indeed, the architecture of\nMushroomRL is built in such a way that every component of an RL problem is\nalready provided, and most of the time users can only focus on the\nimplementation of their own algorithms and experiments. The result is a library\nfrom which RL researchers can significantly benefit in the critical phase of\nthe empirical analysis of their works. MushroomRL stable code, tutorials and\ndocumentation can be found at https://github.com/MushroomRL/mushroom-rl.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 17:23:34 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 15:11:21 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["D'Eramo", "Carlo", ""], ["Tateo", "Davide", ""], ["Bonarini", "Andrea", ""], ["Restelli", "Marcello", ""], ["Peters", "Jan", ""]]}, {"id": "2001.01115", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre, Chenhui Chu, Anoop Kunchukuttan", "title": "A Comprehensive Survey of Multilingual Neural Machine Translation", "comments": "This is an extended version of our survey paper on multilingual NMT.\n  The previous version [arXiv:1905.05395] is rather condensed and is useful for\n  speed-reading whereas this version is more beginner friendly. Under review at\n  the computing surveys journal. We have intentionally decided to maintain both\n  short and long versions of our survey paper for different reader groups", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a survey on multilingual neural machine translation (MNMT), which\nhas gained a lot of traction in the recent years. MNMT has been useful in\nimproving translation quality as a result of translation knowledge transfer\n(transfer learning). MNMT is more promising and interesting than its\nstatistical machine translation counterpart because end-to-end modeling and\ndistributed representations open new avenues for research on machine\ntranslation. Many approaches have been proposed in order to exploit\nmultilingual parallel corpora for improving translation quality. However, the\nlack of a comprehensive survey makes it difficult to determine which approaches\nare promising and hence deserve further exploration. In this paper, we present\nan in-depth survey of existing literature on MNMT. We first categorize various\napproaches based on their central use-case and then further categorize them\nbased on resource scenarios, underlying modeling principles, core-issues and\nchallenges. Wherever possible we address the strengths and weaknesses of\nseveral techniques by comparing them with each other. We also discuss the\nfuture directions that MNMT research might take. This paper is aimed towards\nboth, beginners and experts in NMT. We hope this paper will serve as a starting\npoint as well as a source of new ideas for researchers and engineers interested\nin MNMT.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 19:38:00 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 16:54:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Dabre", "Raj", ""], ["Chu", "Chenhui", ""], ["Kunchukuttan", "Anoop", ""]]}, {"id": "2001.01121", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Biologically-Motivated Deep Learning Method using Hierarchical\n  Competitive Learning", "comments": "Appeared at NIPS 2019 Workshop: Shared Visual Representations in\n  Human and Machine Intelligence (SVRHM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel biologically-motivated learning method for deep\nconvolutional neural networks (CNNs). The combination of CNNs and back\npropagation (BP) learning is the most powerful method in recent machine\nlearning regimes. However, it requires large labeled data for training, and\nthis requirement can occasionally become a barrier for real world applications.\nTo address this problem and utilize unlabeled data, I propose to introduce\nunsupervised competitive learning which only requires forward propagating\nsignals as a pre-training method for CNNs. The method was evaluated by image\ndiscrimination tasks using MNIST, CIFAR-10, and ImageNet datasets, and it\nachieved a state-of-the-art performance as a biologically-motivated method in\nthe ImageNet experiment. The results suggested that the method enables\nhigher-level learning representations solely from forward propagating signals\nwithout a backward error signal for the learning of convolutional layers. The\nproposed method could be useful for a variety of poorly labeled data, for\nexample, time series or medical data.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:07:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "2001.01126", "submitter": "Alexander Ruch", "authors": "Alexander Ruch", "title": "Can x2vec Save Lives? Integrating Graph and Language Embeddings for\n  Automatic Mental Health Classification", "comments": "25 pages (23 body, 2 supplemental material), 12 figures (10 body, 2\n  supplemental material), 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph and language embedding models are becoming commonplace in large scale\nanalyses given their ability to represent complex sparse data densely in\nlow-dimensional space. Integrating these models' complementary relational and\ncommunicative data may be especially helpful if predicting rare events or\nclassifying members of hidden populations - tasks requiring huge and sparse\ndatasets for generalizable analyses. For example, due to social stigma and\ncomorbidities, mental health support groups often form in amorphous online\ngroups. Predicting suicidality among individuals in these settings using\nstandard network analyses is prohibitive due to resource limits (e.g., memory),\nand adding auxiliary data like text to such models exacerbates complexity- and\nsparsity-related issues. Here, I show how merging graph and language embedding\nmodels (metapath2vec and doc2vec) avoids these limits and extracts unsupervised\nclustering data without domain expertise or feature engineering. Graph and\nlanguage distances to a suicide support group have little correlation (\\r{ho} <\n0.23), implying the two models are not embedding redundant information. When\nused separately to predict suicidality among individuals, graph and language\ndata generate relatively accurate results (69% and 76%, respectively); however,\nwhen integrated, both data produce highly accurate predictions (90%, with 10%\nfalse-positives and 12% false-negatives). Visualizing graph embeddings\nannotated with predictions of potentially suicidal individuals shows the\nintegrated model could classify such individuals even if they are positioned\nfar from the support group. These results extend research on the importance of\nsimultaneously analyzing behavior and language in massive networks and efforts\nto integrate embedding models for different kinds of data when predicting and\nclassifying, particularly when they involve rare events.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:56:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ruch", "Alexander", ""]]}, {"id": "2001.01127", "submitter": "Roberto Tonelli", "authors": "Nicola Uras and Lodovica Marchesi and Michele Marchesi and Roberto\n  Tonelli", "title": "Forecasting Bitcoin closing price series using linear regression and\n  neural networks models", "comments": "25 pages, 4 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to forecast daily closing price series of Bitcoin,\nusing data on prices and volumes of prior days. Bitcoin price behaviour is\nstill largely unexplored, presenting new opportunities. We compared our results\nwith two modern works on Bitcoin prices forecasting and with a well-known\nrecent paper that uses Intel, National Bank shares and Microsoft daily NASDAQ\nclosing prices spanning a 3-year interval. We followed different approaches in\nparallel, implementing both statistical techniques and machine learning\nalgorithms. The SLR model for univariate series forecast uses only closing\nprices, whereas the MLR model for multivariate series uses both price and\nvolume data. We applied the ADF -Test to these series, which resulted to be\nindistinguishable from a random walk. We also used two artificial neural\nnetworks: MLP and LSTM. We then partitioned the dataset into shorter sequences,\nrepresenting different price regimes, obtaining best result using more than one\nprevious price, thus confirming our regime hypothesis. All the models were\nevaluated in terms of MAPE and relativeRMSE. They performed well, and were\noverall better than those obtained in the benchmarks. Based on the results, it\nwas possible to demonstrate the efficacy of the proposed methodology and its\ncontribution to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 21:04:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Uras", "Nicola", ""], ["Marchesi", "Lodovica", ""], ["Marchesi", "Michele", ""], ["Tonelli", "Roberto", ""]]}, {"id": "2001.01128", "submitter": "Ilan Ben-Bassat", "authors": "Ilan Ben-Bassat and Erez Rokah", "title": "Locality-Sensitive Hashing for Efficient Web Application Security\n  Testing", "comments": null, "journal-ref": "In Proceedings of the 5th International Conference on Information\n  Systems Security and Privacy (ICISSP), pages 193-204 (2019)", "doi": "10.5220/0007255301930204", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web application security has become a major concern in recent years, as more\nand more content and services are available online. A useful method for\nidentifying security vulnerabilities is black-box testing, which relies on an\nautomated crawling of web applications. However, crawling Rich Internet\nApplications (RIAs) is a very challenging task. One of the key obstacles\ncrawlers face is the state similarity problem: how to determine if two\nclient-side states are equivalent. As current methods do not completely solve\nthis problem, a successful scan of many real-world RIAs is still not possible.\nWe present a novel approach to detect redundant content for security testing\npurposes. The algorithm applies locality-sensitive hashing using MinHash\nsketches in order to analyze the Document Object Model (DOM) structure of web\npages, and to efficiently estimate similarity between them. Our experimental\nresults show that this approach allows a successful scan of RIAs that cannot be\ncrawled otherwise.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 21:05:15 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Ben-Bassat", "Ilan", ""], ["Rokah", "Erez", ""]]}, {"id": "2001.01140", "submitter": "Kareem Nassar", "authors": "Kareem Nassar", "title": "Transformer-based language modeling and decoding for conversational\n  speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a way to use a transformer-based language model in conversational\nspeech recognition. Specifically, we focus on decoding efficiently in a\nweighted finite-state transducer framework. We showcase an approach to lattice\nre-scoring that allows for longer range history captured by a transfomer-based\nlanguage model and takes advantage of a transformer's ability to avoid\ncomputing sequentially.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 23:27:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nassar", "Kareem", ""]]}, {"id": "2001.01172", "submitter": "Yaoshiang Ho", "authors": "Yaoshiang Ho, Samuel Wookey", "title": "The Human Visual System and Adversarial AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies theories about the Human Visual System to make Adversarial\nAI more effective. To date, Adversarial AI has modeled perceptual distances\nbetween clean and adversarial examples of images using Lp norms. These norms\nhave the benefit of simple mathematical description and reasonable\neffectiveness in approximating perceptual distance. However, in prior decades,\nother areas of image processing have moved beyond simpler models like Mean\nSquared Error (MSE) towards more complex models that better approximate the\nHuman Visual System (HVS). We demonstrate a proof of concept of incorporating\nHVS models into Adversarial AI.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 05:47:48 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 21:15:45 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ho", "Yaoshiang", ""], ["Wookey", "Samuel", ""]]}, {"id": "2001.01177", "submitter": "Golnoosh Farnadi", "authors": "Golnoosh Farnadi, Lise Getoor, Marie-Francine Moens, Martine De Cock", "title": "User Profiling Using Hinge-loss Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of approaches have been proposed to automatically infer the\nprofiles of users from their digital footprint in social media. Most of the\nproposed approaches focus on mining a single type of information, while\nignoring other sources of available user-generated content (UGC). In this\npaper, we propose a mechanism to infer a variety of user characteristics, such\nas, age, gender and personality traits, which can then be compiled into a user\nprofile. To this end, we model social media users by incorporating and\nreasoning over multiple sources of UGC as well as social relations. Our model\nis based on a statistical relational learning framework using Hinge-loss Markov\nRandom Fields (HL-MRFs), a class of probabilistic graphical models that can be\ndefined using a set of first-order logical rules. We validate our approach on\ndata from Facebook with more than 5k users and almost 725k relations. We show\nhow HL-MRFs can be used to develop a generic and extensible user profiling\nframework by leveraging textual, visual, and relational content in the form of\nstatus updates, profile pictures and Facebook page likes. Our experimental\nresults demonstrate that our proposed model successfully incorporates multiple\nsources of information and outperforms competing methods that use only one\nsource of information or an ensemble method across the different sources for\nmodeling of users in social media.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 06:55:51 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farnadi", "Golnoosh", ""], ["Getoor", "Lise", ""], ["Moens", "Marie-Francine", ""], ["De Cock", "Martine", ""]]}, {"id": "2001.01185", "submitter": "Xucheng Luo", "authors": "Xucheng Luo, Shengyang Li, Yuxiang Peng", "title": "CNNTOP: a CNN-based Trajectory Owner Prediction Method", "comments": "9pages, 11figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory owner prediction is the basis for many applications such as\npersonalized recommendation, urban planning. Although much effort has been put\non this topic, the results archived are still not good enough. Existing methods\nmainly employ RNNs to model trajectories semantically due to the inherent\nsequential attribute of trajectories. However, these approaches are weak at\nPoint of Interest (POI) representation learning and trajectory feature\ndetection. Thus, the performance of existing solutions is far from the\nrequirements of practical applications. In this paper, we propose a novel\nCNN-based Trajectory Owner Prediction (CNNTOP) method. Firstly, we connect all\nPOI according to trajectories from all users. The result is a connected graph\nthat can be used to generate more informative POI sequences than other\napproaches. Secondly, we employ the Node2Vec algorithm to encode each POI into\na low-dimensional real value vector. Then, we transform each trajectory into a\nfixed-dimensional matrix, which is similar to an image. Finally, a CNN is\ndesigned to detect features and predict the owner of a given trajectory. The\nCNN can extract informative features from the matrix representations of\ntrajectories by convolutional operations, Batch normalization, and $K$-max\npooling operations. Extensive experiments on real datasets demonstrate that\nCNNTOP substantially outperforms existing solutions in terms of\nmacro-Precision, macro-Recall, macro-F1, and accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 07:58:28 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Luo", "Xucheng", ""], ["Li", "Shengyang", ""], ["Peng", "Yuxiang", ""]]}, {"id": "2001.01199", "submitter": "Vrettos Moulos", "authors": "Vrettos Moulos", "title": "A Hoeffding Inequality for Finite State Markov Chains and its\n  Applications to Markovian Bandits", "comments": "International Symposium on Information Theory (ISIT), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Hoeffding inequality for the partial sums $\\sum_{k=1}^n\nf (X_k)$, where $\\{X_k\\}_{k \\in \\mathbb{Z}_{> 0}}$ is an irreducible Markov\nchain on a finite state space $S$, and $f : S \\to [a, b]$ is a real-valued\nfunction. Our bound is simple, general, since it only assumes irreducibility\nand finiteness of the state space, and powerful. In order to demonstrate its\nusefulness we provide two applications in multi-armed bandit problems. The\nfirst is about identifying an approximately best Markovian arm, while the\nsecond is concerned with regret minimization in the context of Markovian\nbandits.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 09:28:10 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 16:56:28 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Moulos", "Vrettos", ""]]}, {"id": "2001.01213", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Lea Pfl\\\"uger, Andreas Maier", "title": "Prediction of MRI Hardware Failures based on Image Features using\n  Ensemble Learning", "comments": null, "journal-ref": "Bildverarbeitung f\\\"ur die Medizin 2020. Springer Vieweg,\n  Wiesbaden, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to ensure trouble-free operation, prediction of hardware failures is\nessential. This applies especially to medical systems. Our goal is to determine\nhardware which needs to be exchanged before failing. In this work, we focus on\npredicting failures of 20-channel Head/Neck coils using image-related\nmeasurements. Thus, we aim to solve a classification problem with two classes,\nnormal and broken coil. To solve this problem, we use data of two different\nlevels. One level refers to one-dimensional features per individual coil\nchannel on which we found a fully connected neural network to perform best. The\nother data level uses matrices which represent the overall coil condition and\nfeeds a different neural network. We stack the predictions of those two\nnetworks and train a Random Forest classifier as the ensemble learner. Thus,\ncombining insights of both trained models improves the prediction results and\nallows us to determine the coil's condition with an F-score of 94.14% and an\naccuracy of 99.09%.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:21:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Pfl\u00fcger", "Lea", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.01215", "submitter": "Shital Shah", "authors": "Shital Shah, Roland Fernandez, Steven Drucker", "title": "A System for Real-Time Interactive Analysis of Deep Learning Training", "comments": "Accepted at ACM SIGCHI Symposium on Engineering Interactive Computing\n  Systems (EICS 2019). Code available as TensorWatch project at\n  https://github.com/microsoft/tensorwatch", "journal-ref": null, "doi": "10.1145/3319499.3328231", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing diagnosis or exploratory analysis during the training of deep\nlearning models is challenging but often necessary for making a sequence of\ndecisions guided by the incremental observations. Currently available systems\nfor this purpose are limited to monitoring only the logged data that must be\nspecified before the training process starts. Each time a new information is\ndesired, a cycle of stop-change-restart is required in the training process.\nThese limitations make interactive exploration and diagnosis tasks difficult,\nimposing long tedious iterations during the model development. We present a new\nsystem that enables users to perform interactive queries on live processes\ngenerating real-time information that can be rendered in multiple formats on\nmultiple surfaces in the form of several desired visualizations simultaneously.\nTo achieve this, we model various exploratory inspection and diagnostic tasks\nfor deep learning training processes as specifications for streams using a\nmap-reduce paradigm with which many data scientists are already familiar. Our\ndesign achieves generality and extensibility by defining composable primitives\nwhich is a fundamentally different approach than is used by currently available\nsystems. The open source implementation of our system is available as\nTensorWatch project at https://github.com/microsoft/tensorwatch.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:33:31 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:57:16 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Shah", "Shital", ""], ["Fernandez", "Roland", ""], ["Drucker", "Steven", ""]]}, {"id": "2001.01216", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Andreas Maier", "title": "Flexible Log File Parsing using Hidden Markov Models", "comments": null, "journal-ref": "Computer Science Conference Proceedings in Computer Science &\n  Information Technology (CS & IT) 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to model unknown file processing. As the content of log files often\nevolves over time, we established a dynamic statistical model which learns and\nadapts processing and parsing rules. First, we limit the amount of unstructured\ntext by focusing only on those frequent patterns which lead to the desired\noutput table similar to Vaarandi [10]. Second, we transform the found frequent\npatterns and the output stating the parsed table into a Hidden Markov Model\n(HMM). We use this HMM as a specific, however, flexible representation of a\npattern for log file processing. With changes in the raw log file distorting\nlearned patterns, we aim the model to adapt automatically in order to maintain\nhigh quality output. After training our model on one system type, applying the\nmodel and the resulting parsing rule to a different system with slightly\ndifferent log file patterns, we achieve an accuracy over 99%.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:44:09 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.01227", "submitter": "Sangwoo Park", "authors": "Osvaldo Simeone, Sangwoo Park, Joonhyuk Kang", "title": "From Learning to Meta-Learning: Reduced Training Overhead and Complexity\n  for Communication Systems", "comments": "Invited to the 6G Wireless Summit 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods adapt the parameters of a model, constrained to lie\nin a given model class, by using a fixed learning procedure based on data or\nactive observations. Adaptation is done on a per-task basis, and retraining is\nneeded when the system configuration changes. The resulting inefficiency in\nterms of data and training time requirements can be mitigated, if domain\nknowledge is available, by selecting a suitable model class and learning\nprocedure, collectively known as inductive bias. However, it is generally\ndifficult to encode prior knowledge into an inductive bias, particularly with\nblack-box model classes such as neural networks. Meta-learning provides a way\nto automatize the selection of an inductive bias. Meta-learning leverages data\nor active observations from tasks that are expected to be related to future,\nand a priori unknown, tasks of interest. With a meta-trained inductive bias,\ntraining of a machine learning model can be potentially carried out with\nreduced training data and/or time complexity. This paper provides a high-level\nintroduction to meta-learning with applications to communication systems.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 12:54:41 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Simeone", "Osvaldo", ""], ["Park", "Sangwoo", ""], ["Kang", "Joonhyuk", ""]]}, {"id": "2001.01233", "submitter": "Wenwei Zhang", "authors": "Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi,\n  Xuesen Zhang, Wanli Ouyang", "title": "EcoNAS: Finding Proxies for Economical Neural Architecture Search", "comments": "CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) achieves significant progress in many\ncomputer vision tasks. While many methods have been proposed to improve the\nefficiency of NAS, the search progress is still laborious because training and\nevaluating plausible architectures over large search space is time-consuming.\nAssessing network candidates under a proxy (i.e., computationally reduced\nsetting) thus becomes inevitable. In this paper, we observe that most existing\nproxies exhibit different behaviors in maintaining the rank consistency among\nnetwork candidates. In particular, some proxies can be more reliable -- the\nrank of candidates does not differ much comparing their reduced setting\nperformance and final performance. In this paper, we systematically investigate\nsome widely adopted reduction factors and report our observations. Inspired by\nthese observations, we present a reliable proxy and further formulate a\nhierarchical proxy strategy. The strategy spends more computations on candidate\nnetworks that are potentially more accurate, while discards unpromising ones in\nearly stage with a fast proxy. This leads to an economical evolutionary-based\nNAS (EcoNAS), which achieves an impressive 400x search time reduction in\ncomparison to the evolutionary-based state of the art (8 vs. 3150 GPU days).\nSome new proxies led by our observations can also be applied to accelerate\nother NAS methods while still able to discover good candidate networks with\nperformance matching those found by previous proxy strategies.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 13:29:02 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:42:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhou", "Dongzhan", ""], ["Zhou", "Xinchi", ""], ["Zhang", "Wenwei", ""], ["Loy", "Chen Change", ""], ["Yi", "Shuai", ""], ["Zhang", "Xuesen", ""], ["Ouyang", "Wanli", ""]]}, {"id": "2001.01240", "submitter": "Pravendra Singh", "authors": "Pravendra Singh, Munender Varshney, Vinay P. Namboodiri", "title": "Cooperative Initialization based Deep Neural Network Training", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed various activation functions. These activation\nfunctions help the deep network to learn non-linear behavior with a significant\neffect on training dynamics and task performance. The performance of these\nactivations also depends on the initial state of the weight parameters, i.e.,\ndifferent initial state leads to a difference in the performance of a network.\nIn this paper, we have proposed a cooperative initialization for training the\ndeep network using ReLU activation function to improve the network performance.\nOur approach uses multiple activation functions in the initial few epochs for\nthe update of all sets of weight parameters while training the network. These\nactivation functions cooperate to overcome their drawbacks in the update of\nweight parameters, which in effect learn better \"feature representation\" and\nboost the network performance later. Cooperative initialization based training\nalso helps in reducing the overfitting problem and does not increase the number\nof parameters, inference (test) time in the final model while improving the\nperformance. Experiments show that our approach outperforms various baselines\nand, at the same time, performs well over various tasks such as classification\nand detection. The Top-1 classification accuracy of the model trained using our\napproach improves by 2.8% for VGG-16 and 2.1% for ResNet-56 on CIFAR-100\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:08:46 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Singh", "Pravendra", ""], ["Varshney", "Munender", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.01243", "submitter": "Xue Han", "authors": "Xue Han, Lianxue Hu, Yabin Dang, Shivali Agarwal, Lijun Mei, Shaochun\n  Li, Xin Zhou", "title": "Automatic Business Process Structure Discovery using Ordered Neurons\n  LSTM: A Preliminary Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic process discovery from textual process documentations is highly\ndesirable to reduce time and cost of Business Process Management (BPM)\nimplementation in organizations. However, existing automatic process discovery\napproaches mainly focus on identifying activities out of the documentations.\nDeriving the structural relationships between activities, which is important in\nthe whole process discovery scope, is still a challenge. In fact, a business\nprocess has latent semantic hierarchical structure which defines different\nlevels of detail to reflect the complex business logic. Recent findings in\nneural machine learning area show that the meaningful linguistic structure can\nbe induced by joint language modeling and structure learning. Inspired by these\nfindings, we propose to retrieve the latent hierarchical structure present in\nthe textual business process documents by building a neural network that\nleverages a novel recurrent architecture, Ordered Neurons LSTM (ON-LSTM), with\nprocess-level language model objective. We tested the proposed approach on data\nset of Process Description Documents (PDD) from our practical Robotic Process\nAutomation (RPA) projects. Preliminary experiments showed promising results.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:19:11 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Han", "Xue", ""], ["Hu", "Lianxue", ""], ["Dang", "Yabin", ""], ["Agarwal", "Shivali", ""], ["Mei", "Lijun", ""], ["Li", "Shaochun", ""], ["Zhou", "Xin", ""]]}, {"id": "2001.01248", "submitter": "Marco Monforte", "authors": "Marco Monforte, Ander Arriandiaga, Arren Glover and Chiara Bartolozzi", "title": "Exploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing\n  Trajectories", "comments": "5 pages, 5 figures, 1 table, paper accepted for presentation at the\n  2nd IEEE International Conference on Artificial Intelligence Circuits and\n  Systems (AICAS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates trajectory prediction for robotics, to improve the\ninteraction of robots with moving targets, such as catching a bouncing ball.\nUnexpected, highly-non-linear trajectories cannot easily be predicted with\nregression-based fitting procedures, therefore we apply state of the art\nmachine learning, specifically based on Long-Short Term Memory (LSTM)\narchitectures. In addition, fast moving targets are better sensed using event\ncameras, which produce an asynchronous output triggered by spatial change,\nrather than at fixed temporal intervals as with traditional cameras. We\ninvestigate how LSTM models can be adapted for event camera data, and in\nparticular look at the benefit of using asynchronously sampled data.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:37:28 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 13:13:02 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Monforte", "Marco", ""], ["Arriandiaga", "Ander", ""], ["Glover", "Arren", ""], ["Bartolozzi", "Chiara", ""]]}, {"id": "2001.01249", "submitter": "Eleni Nisioti", "authors": "Eleni Nisioti and Nikolaos Thomos", "title": "Design of Capacity-Approaching Low-Density Parity-Check Codes using\n  Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we model Density Evolution (DE) using Recurrent Neural\nNetworks (RNNs) with the aim of designing capacity-approaching Irregular\nLow-Density Parity-Check (LDPC) codes for binary erasure channels. In\nparticular, we present a method for determining the coefficients of the degree\ndistributions, characterizing the structure of an LDPC code. We refer to our\nRNN architecture as Neural Density Evolution (NDE) and determine the weights of\nthe RNN that correspond to optimal designs by minimizing a loss function that\nenforces the properties of asymptotically optimal design, as well as the\ndesired structural characteristics of the code. This renders the LDPC design\nprocess highly configurable, as constraints can be added to meet applications'\nrequirements by means of modifying the loss function. In order to train the\nRNN, we generate data corresponding to the expected channel noise. We analyze\nthe complexity and optimality of NDE theoretically, and compare it with\ntraditional design methods that employ differential evolution. Simulations\nillustrate that NDE improves upon differential evolution both in terms of\nasymptotic performance and complexity. Although we focus on asymptotic\nsettings, we evaluate designs found by NDE for finite codeword lengths and\nobserve that performance remains satisfactory across a variety of channels.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 14:46:47 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Nisioti", "Eleni", ""], ["Thomos", "Nikolaos", ""]]}, {"id": "2001.01258", "submitter": "Vegard Antun", "authors": "Nina M. Gottschling, Vegard Antun, Ben Adcock and Anders C. Hansen", "title": "The troublesome kernel: why deep learning for inverse problems is\n  typically unstable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is overwhelming empirical evidence that Deep Learning (DL) leads to\nunstable methods in applications ranging from image classification and computer\nvision to voice recognition and automated diagnosis in medicine. Recently, a\nsimilar instability phenomenon has been discovered when DL is used to solve\ncertain problems in computational science, namely, inverse problems in imaging.\nIn this paper we present a comprehensive mathematical analysis explaining the\nmany facets of the instability phenomenon in DL for inverse problems. Our main\nresults not only explain why this phenomenon occurs, they also shed light as to\nwhy finding a cure for instabilities is so difficult in practice. Additionally,\nthese theorems show that instabilities are typically not rare events - rather,\nthey can occur even when the measurements are subject to completely random\nnoise - and consequently how easy it can be to destablise certain trained\nneural networks. We also examine the delicate balance between reconstruction\nperformance and stability, and in particular, how DL methods may outperform\nstate-of-the-art sparse regularization methods, but at the cost of instability.\nFinally, we demonstrate a counterintuitive phenomenon: training a neural\nnetwork may generically not yield an optimal reconstruction method for an\ninverse problem.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 15:30:23 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Gottschling", "Nina M.", ""], ["Antun", "Vegard", ""], ["Adcock", "Ben", ""], ["Hansen", "Anders C.", ""]]}, {"id": "2001.01259", "submitter": "Arnab Karmakar", "authors": "Arnab Karmakar, Deepak Mishra", "title": "A Robust Pose Transformational GAN for Pose Guided Person Image\n  Synthesis", "comments": "Accepted in 7th National Conference on Computer Vision, Pattern\n  Recognition, Image Processing and Graphics (NCVPRIPG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating photorealistic images of human subjects in any unseen pose have\ncrucial applications in generating a complete appearance model of the subject.\nHowever, from a computer vision perspective, this task becomes significantly\nchallenging due to the inability of modelling the data distribution conditioned\non pose. Existing works use a complicated pose transformation model with\nvarious additional features such as foreground segmentation, human body parsing\netc. to achieve robustness that leads to computational overhead. In this work,\nwe propose a simple yet effective pose transformation GAN by utilizing the\nResidual Learning method without any additional feature learning to generate a\ngiven human image in any arbitrary pose. Using effective data augmentation\ntechniques and cleverly tuning the model, we achieve robustness in terms of\nillumination, occlusion, distortion and scale. We present a detailed study,\nboth qualitative and quantitative, to demonstrate the superiority of our model\nover the existing methods on two large datasets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 15:32:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Karmakar", "Arnab", ""], ["Mishra", "Deepak", ""]]}, {"id": "2001.01279", "submitter": "Xie Tingli", "authors": "Xufeng Huang, Qiang Lei, Tingli Xie, Yahui Zhang, Zhen Hu, Qi Zhou", "title": "Deep Transfer Convolutional Neural Network and Extreme Learning Machine\n  for Lung Nodule Diagnosis on CT images", "comments": "Some content of the article needs to be kept secret", "journal-ref": "Knowledge-Based Systems (2020) 106230", "doi": "10.1016/j.knosys.2020.106230.", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some content of the article needs to be kept secret\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 17:49:38 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:36:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Huang", "Xufeng", ""], ["Lei", "Qiang", ""], ["Xie", "Tingli", ""], ["Zhang", "Yahui", ""], ["Hu", "Zhen", ""], ["Zhou", "Qi", ""]]}, {"id": "2001.01306", "submitter": "Honghui Shi", "authors": "Mang Tik Chiu, Xingqian Xu, Yunchao Wei, Zilong Huang, Alexander\n  Schwing, Robert Brunner, Hrant Khachatrian, Hovnatan Karapetyan, Ivan Dozier,\n  Greg Rose, David Wilson, Adrian Tudor, Naira Hovakimyan, Thomas S. Huang,\n  Honghui Shi", "title": "Agriculture-Vision: A Large Aerial Image Database for Agricultural\n  Pattern Analysis", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in visual recognition tasks has driven\nadvancements in multiple fields of research. Particularly, increasing attention\nhas been drawn towards its application in agriculture. Nevertheless, while\nvisual pattern recognition on farmlands carries enormous economic values,\nlittle progress has been made to merge computer vision and crop sciences due to\nthe lack of suitable agricultural image datasets. Meanwhile, problems in\nagriculture also pose new challenges in computer vision. For example, semantic\nsegmentation of aerial farmland images requires inference over extremely\nlarge-size images with extreme annotation sparsity. These challenges are not\npresent in most of the common object datasets, and we show that they are more\nchallenging than many other aerial image datasets. To encourage research in\ncomputer vision for agriculture, we present Agriculture-Vision: a large-scale\naerial farmland image dataset for semantic segmentation of agricultural\npatterns. We collected 94,986 high-quality aerial images from 3,432 farmlands\nacross the US, where each image consists of RGB and Near-infrared (NIR)\nchannels with resolution as high as 10 cm per pixel. We annotate nine types of\nfield anomaly patterns that are most important to farmers. As a pilot study of\naerial agricultural semantic segmentation, we perform comprehensive experiments\nusing popular semantic segmentation models; we also propose an effective model\ndesigned for aerial agricultural pattern recognition. Our experiments\ndemonstrate several challenges Agriculture-Vision poses to both the computer\nvision and agriculture communities. Future versions of this dataset will\ninclude even more aerial images, anomaly patterns and image channels. More\ninformation at https://www.agriculture-vision.com.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 04:13:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chiu", "Mang Tik", ""], ["Xu", "Xingqian", ""], ["Wei", "Yunchao", ""], ["Huang", "Zilong", ""], ["Schwing", "Alexander", ""], ["Brunner", "Robert", ""], ["Khachatrian", "Hrant", ""], ["Karapetyan", "Hovnatan", ""], ["Dozier", "Ivan", ""], ["Rose", "Greg", ""], ["Wilson", "David", ""], ["Tudor", "Adrian", ""], ["Hovakimyan", "Naira", ""], ["Huang", "Thomas S.", ""], ["Shi", "Honghui", ""]]}, {"id": "2001.01323", "submitter": "Jishnu Ray Chowdhury", "authors": "Jishnu Ray Chowdhury, Cornelia Caragea, Doina Caragea", "title": "On Identifying Hashtags in Disaster Twitter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet hashtags have the potential to improve the search for information\nduring disaster events. However, there is a large number of disaster-related\ntweets that do not have any user-provided hashtags. Moreover, only a small\nnumber of tweets that contain actionable hashtags are useful for disaster\nresponse. To facilitate progress on automatic identification (or extraction) of\ndisaster hashtags for Twitter data, we construct a unique dataset of\ndisaster-related tweets annotated with hashtags useful for filtering actionable\ninformation. Using this dataset, we further investigate Long Short Term\nMemory-based models within a Multi-Task Learning framework. The best performing\nmodel achieves an F1-score as high as 92.22%. The dataset, code, and other\nresources are available on Github.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 22:37:17 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Chowdhury", "Jishnu Ray", ""], ["Caragea", "Cornelia", ""], ["Caragea", "Doina", ""]]}, {"id": "2001.01328", "submitter": "Xuechen Li", "authors": "Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud", "title": "Scalable Gradients for Stochastic Differential Equations", "comments": "AISTATS 2020; 25 pages, 6 figures in main text; clarify notation in\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adjoint sensitivity method scalably computes gradients of solutions to\nordinary differential equations. We generalize this method to stochastic\ndifferential equations, allowing time-efficient and constant-memory computation\nof gradients with high-order adaptive solvers. Specifically, we derive a\nstochastic differential equation whose solution is the gradient, a\nmemory-efficient algorithm for caching noise, and conditions under which\nnumerical solutions converge. In addition, we combine our method with\ngradient-based stochastic variational inference for latent stochastic\ndifferential equations. We use our method to fit stochastic dynamics defined by\nneural networks, achieving competitive performance on a 50-dimensional motion\ncapture dataset.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:05:55 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 07:00:00 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 18:15:19 GMT"}, {"version": "v4", "created": "Mon, 24 Feb 2020 17:27:17 GMT"}, {"version": "v5", "created": "Tue, 7 Jul 2020 05:40:07 GMT"}, {"version": "v6", "created": "Sun, 18 Oct 2020 21:16:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Li", "Xuechen", ""], ["Wong", "Ting-Kam Leonard", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""]]}, {"id": "2001.01330", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae Verga", "title": "Convolutional Neural Networks with Intermediate Loss for 3D\n  Super-Resolution of CT and MRI Scans", "comments": "Accepted in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2980266", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  CT scanners that are commonly-used in hospitals nowadays produce\nlow-resolution images, up to 512 pixels in size. One pixel in the image\ncorresponds to a one millimeter piece of tissue. In order to accurately segment\ntumors and make treatment plans, doctors need CT scans of higher resolution.\nThe same problem appears in MRI. In this paper, we propose an approach for the\nsingle-image super-resolution of 3D CT or MRI scans. Our method is based on\ndeep convolutional neural networks (CNNs) composed of 10 convolutional layers\nand an intermediate upscaling layer that is placed after the first 6\nconvolutional layers. Our first CNN, which increases the resolution on two axes\n(width and height), is followed by a second CNN, which increases the resolution\non the third axis (depth). Different from other methods, we compute the loss\nwith respect to the ground-truth high-resolution output right after the\nupscaling layer, in addition to computing the loss after the last convolutional\nlayer. The intermediate loss forces our network to produce a better output,\ncloser to the ground-truth. A widely-used approach to obtain sharp results is\nto add Gaussian blur using a fixed standard deviation. In order to avoid\noverfitting to a fixed standard deviation, we apply Gaussian smoothing with\nvarious standard deviations, unlike other approaches. We evaluate our method in\nthe context of 2D and 3D super-resolution of CT and MRI scans from two\ndatabases, comparing it to relevant related works from the literature and\nbaselines based on various interpolation schemes, using 2x and 4x scaling\nfactors. The empirical results show that our approach attains superior results\nto all other methods. Moreover, our human annotation study reveals that both\ndoctors and regular annotators chose our method in favor of Lanczos\ninterpolation in 97.55% cases for 2x upscaling factor and in 96.69% cases for\n4x upscaling factor.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:21:40 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 18:13:14 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 14:19:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""], ["Verga", "Nicolae", ""]]}, {"id": "2001.01331", "submitter": "Andrew Lensen", "authors": "Andrew Lensen, Mengjie Zhang, Bing Xue", "title": "Multi-Objective Genetic Programming for Manifold Learning: Balancing\n  Quality and Dimensionality", "comments": "31 pages, pre-print accepted by Genetic Programming and Evolvable\n  Machines journal", "journal-ref": null, "doi": "10.1007/s10710-020-09375-4", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning techniques have become increasingly valuable as data\ncontinues to grow in size. By discovering a lower-dimensional representation\n(embedding) of the structure of a dataset, manifold learning algorithms can\nsubstantially reduce the dimensionality of a dataset while preserving as much\ninformation as possible. However, state-of-the-art manifold learning algorithms\nare opaque in how they perform this transformation. Understanding the way in\nwhich the embedding relates to the original high-dimensional space is critical\nin exploratory data analysis. We previously proposed a Genetic Programming\nmethod that performed manifold learning by evolving mappings that are\ntransparent and interpretable. This method required the dimensionality of the\nembedding to be known a priori, which makes it hard to use when little is known\nabout a dataset. In this paper, we substantially extend our previous work, by\nintroducing a multi-objective approach that automatically balances the\ncompeting objectives of manifold quality and dimensionality. Our proposed\napproach is competitive with a range of baseline and state-of-the-art manifold\nlearning methods, while also providing a range (front) of solutions that give\ndifferent trade-offs between quality and dimensionality. Furthermore, the\nlearned models are shown to often be simple and efficient, utilising only a\nsmall number of features in an interpretable manner.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:24:33 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Lensen", "Andrew", ""], ["Zhang", "Mengjie", ""], ["Xue", "Bing", ""]]}, {"id": "2001.01347", "submitter": "Xing Zhao", "authors": "Xing Zhao, Manos Papagelis, Aijun An, Bao Xin Chen, Junfeng Liu,\n  Yonggang Hu", "title": "Elastic Bulk Synchronous Parallel Model for Distributed Deep Learning", "comments": "The paper was accepted in the proceedings of the IEEE International\n  Conference on Data Mining 2019 (ICDM'19), 1504-1509", "journal-ref": "ICDM 2019, 1504-1509", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bulk synchronous parallel (BSP) is a celebrated synchronization model for\ngeneral-purpose parallel computing that has successfully been employed for\ndistributed training of machine learning models. A prevalent shortcoming of the\nBSP is that it requires workers to wait for the straggler at every iteration.\nTo ameliorate this shortcoming of classic BSP, we propose ELASTICBSP a model\nthat aims to relax its strict synchronization requirement. The proposed model\noffers more flexibility and adaptability during the training phase, without\nsacrificing on the accuracy of the trained model. We also propose an efficient\nmethod that materializes the model, named ZIPLINE. The algorithm is tunable and\ncan effectively balance the trade-off between quality of convergence and\niteration throughput, in order to accommodate different environments or\napplications. A thorough experimental evaluation demonstrates that our proposed\nELASTICBSP model converges faster and to a higher accuracy than the classic\nBSP. It also achieves comparable (if not higher) accuracy than the other\nsensible synchronization models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 01:05:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhao", "Xing", ""], ["Papagelis", "Manos", ""], ["An", "Aijun", ""], ["Chen", "Bao Xin", ""], ["Liu", "Junfeng", ""], ["Hu", "Yonggang", ""]]}, {"id": "2001.01377", "submitter": "Peide Cai", "authors": "Peide Cai, Xiaodong Mei, Lei Tai, Yuxiang Sun, Ming Liu", "title": "High-speed Autonomous Drifting with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1109/LRA.2020.2967299", "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drifting is a complicated task for autonomous vehicle control. Most\ntraditional methods in this area are based on motion equations derived by the\nunderstanding of vehicle dynamics, which is difficult to be modeled precisely.\nWe propose a robust drift controller without explicit motion equations, which\nis based on the latest model-free deep reinforcement learning algorithm soft\nactor-critic. The drift control problem is formulated as a trajectory following\ntask, where the errorbased state and reward are designed. After being trained\non tracks with different levels of difficulty, our controller is capable of\nmaking the vehicle drift through various sharp corners quickly and stably in\nthe unseen map. The proposed controller is further shown to have excellent\ngeneralization ability, which can directly handle unseen vehicle types with\ndifferent physical properties, such as mass, tire friction, etc.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:05:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Cai", "Peide", ""], ["Mei", "Xiaodong", ""], ["Tai", "Lei", ""], ["Sun", "Yuxiang", ""], ["Liu", "Ming", ""]]}, {"id": "2001.01383", "submitter": "Xueyan Liu", "authors": "Xueyan Liu, Bo Yang, Wenzhuo Song, Katarzyna Musial, Wanli Zuo, Hongxu\n  Chen, Hongzhi Yin", "title": "A Block-based Generative Model for Attributed Networks Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributed network embedding has attracted plenty of interest in recent\nyears. It aims to learn task-independent, low-dimensional, and continuous\nvectors for nodes preserving both topology and attribute information. Most of\nthe existing methods, such as random-walk based methods and GCNs, mainly focus\non the local information, i.e., the attributes of the neighbours. Thus, they\nhave been well studied for assortative networks (i.e., networks with\ncommunities) but ignored disassortative networks (i.e., networks with\nmultipartite, hubs, and hybrid structures), which are common in the real world.\nTo enable model both assortative and disassortative networks, we propose a\nblock-based generative model for attributed network embedding from a\nprobability perspective. Specifically, the nodes are assigned to several blocks\nwherein the nodes in the same block share the similar linkage patterns. These\npatterns can define assortative networks containing communities or\ndisassortative networks with the multipartite, hub, or any hybrid structures.\nTo preserve the attribute information, we assume that each node has a hidden\nembedding related to its assigned block. We use a neural network to\ncharacterize the nonlinearity between node embeddings and node attributes. We\nperform extensive experiments on real-world and synthetic attributed networks.\nThe results show that our proposed method consistently outperforms\nstate-of-the-art embedding methods for both clustering and classification\ntasks, especially on disassortative networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:44:15 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 09:57:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Xueyan", ""], ["Yang", "Bo", ""], ["Song", "Wenzhuo", ""], ["Musial", "Katarzyna", ""], ["Zuo", "Wanli", ""], ["Chen", "Hongxu", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2001.01385", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, Hong-You Chen, De-Chuan Zhan, Wei-Lun Chao", "title": "Identifying and Compensating for Feature Deviation in Imbalanced Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate learning a ConvNet classifier with class-imbalanced data. We\nfound that a ConvNet significantly over-fits the minor classes that do not have\nsufficient training instances, which is quite opposite to a traditional machine\nlearning model like logistic regression that often under-fits minor classes. We\nconduct a series of analysis and argue that feature deviation between the\ntraining and test instances serves as the main cause. We propose to incorporate\nclass-dependent temperatures (CDT) in learning a ConvNet: CDT forces the\nminor-class instances to have larger decision values in the training phase, so\nas to compensate for the effect of feature deviation in the test data. We\nvalidate our approach on several benchmark datasets and achieve promising\nperformance. We hope that our insights can inspire new ways of thinking in\nresolving class-imbalanced deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:52:11 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:10:52 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 00:13:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ye", "Han-Jia", ""], ["Chen", "Hong-You", ""], ["Zhan", "De-Chuan", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2001.01394", "submitter": "Geraud Nangue Tasse", "authors": "Geraud Nangue Tasse, Steven James, Benjamin Rosman", "title": "A Boolean Task Algebra for Reinforcement Learning", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to compose learned skills to solve new tasks is an important\nproperty of lifelong-learning agents. In this work, we formalise the logical\ncomposition of tasks as a Boolean algebra. This allows us to formulate new\ntasks in terms of the negation, disjunction and conjunction of a set of base\ntasks. We then show that by learning goal-oriented value functions and\nrestricting the transition dynamics of the tasks, an agent can solve these new\ntasks with no further learning. We prove that by composing these value\nfunctions in specific ways, we immediately recover the optimal policies for all\ntasks expressible under the Boolean algebra. We verify our approach in two\ndomains---including a high-dimensional video game environment requiring\nfunction approximation---where an agent first learns a set of base skills, and\nthen composes them to solve a super-exponential number of new tasks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 04:46:25 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:45:49 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Tasse", "Geraud Nangue", ""], ["James", "Steven", ""], ["Rosman", "Benjamin", ""]]}, {"id": "2001.01395", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng, Ching-Yao Chou, Chun-Hsiang Chen, and An-Yeu Wu", "title": "Accumulated Polar Feature-based Deep Learning for Efficient and\n  Lightweight Automatic Modulation Classification with Channel Compensation\n  Mechanism", "comments": "13 pages, 13 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In next-generation communications, massive machine-type communications (mMTC)\ninduce severe burden on base stations. To address such an issue, automatic\nmodulation classification (AMC) can help to reduce signaling overhead by\nblindly recognizing the modulation types without handshaking. Thus, it plays an\nimportant role in future intelligent modems. The emerging deep learning (DL)\ntechnique stores intelligence in the network, resulting in superior performance\nover traditional approaches. However, conventional DL-based approaches suffer\nfrom heavy training overhead, memory overhead, and computational complexity,\nwhich severely hinder practical applications for resource-limited scenarios,\nsuch as Vehicle-to-Everything (V2X) applications. Furthermore, the overhead of\nonline retraining under time-varying fading channels has not been studied in\nthe prior arts. In this work, an accumulated polar feature-based DL with a\nchannel compensation mechanism is proposed to cope with the aforementioned\nissues. Firstly, the simulation results show that learning features from the\npolar domain with historical data information can approach near-optimal\nperformance while reducing training overhead by 99.8 times. Secondly, the\nproposed neural network-based channel estimator (NN-CE) can learn the channel\nresponse and compensate for the distorted channel with 13% improvement.\nMoreover, in applying this lightweight NN-CE in a time-varying fading channel,\ntwo efficient mechanisms of online retraining are proposed, which can reduce\ntransmission overhead and retraining overhead by 90% and 76%, respectively.\nFinally, the performance of the proposed approach is evaluated and compared\nwith prior arts on a public dataset to demonstrate its great efficiency and\nlightness.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 04:56:56 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 16:19:04 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Chou", "Ching-Yao", ""], ["Chen", "Chun-Hsiang", ""], ["Wu", "An-Yeu", ""]]}, {"id": "2001.01401", "submitter": "Yeongtae Hwang", "authors": "Yeongtae Hwang, Hyemin Cho, Hongsun Yang, Dong-Ok Won, Insoo Oh, and\n  Seong-Whan Lee", "title": "Mel-spectrogram augmentation for sequence to sequence voice conversion", "comments": "5pages, 1 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For training the sequence-to-sequence voice conversion model, we need to\nhandle an issue of insufficient data about the number of speech pairs which\nconsist of the same utterance. This study experimentally investigated the\neffects of Mel-spectrogram augmentation on training the sequence-to-sequence\nvoice conversion (VC) model from scratch. For Mel-spectrogram augmentation, we\nadopted the policies proposed in SpecAugment. In addition, we proposed new\npolicies (i.e., frequency warping, loudness and time length control) for more\ndata variations. Moreover, to find the appropriate hyperparameters of\naugmentation policies without training the VC model, we proposed hyperparameter\nsearch strategy and the new metric for reducing experimental cost, namely\ndeformation per deteriorating ratio. We compared the effect of these\nMel-spectrogram augmentation methods based on various sizes of training set and\naugmentation policies. In the experimental results, the time axis warping based\npolicies (i.e., time length control and time warping.) showed better\nperformance than other policies. These results indicate that the use of the\nMel-spectrogram augmentation is more beneficial for training the VC model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:14:09 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 09:39:47 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Hwang", "Yeongtae", ""], ["Cho", "Hyemin", ""], ["Yang", "Hongsun", ""], ["Won", "Dong-Ok", ""], ["Oh", "Insoo", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2001.01404", "submitter": "Prateek Jaiswal", "authors": "Prateek Jaiswal, Harsha Honnappa and Vinayak A. Rao", "title": "Variational Bayesian Methods for Stochastically Constrained System\n  Design Problems", "comments": null, "journal-ref": "2nd Symposium on Advances in Approximate Bayesian Inference, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study system design problems stated as parameterized stochastic programs\nwith a chance-constraint set. We adopt a Bayesian approach that requires the\ncomputation of a posterior predictive integral which is usually intractable. In\naddition, for the problem to be a well-defined convex program, we must retain\nthe convexity of the feasible set. Consequently, we propose a variational\nBayes-based method to approximately compute the posterior predictive integral\nthat ensures tractability and retains the convexity of the feasible set. Under\ncertain regularity conditions, we also show that the solution set obtained\nusing variational Bayes converges to the true solution set as the number of\nobservations tends to infinity. We also provide bounds on the probability of\nqualifying a true infeasible point (with respect to the true constraints) as\nfeasible under the VB approximation for a given number of samples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:21:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Jaiswal", "Prateek", ""], ["Honnappa", "Harsha", ""], ["Rao", "Vinayak A.", ""]]}, {"id": "2001.01408", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Chengtao Li, Connor W. Coley, Bo Dai, Le Song", "title": "Retrosynthesis Prediction with Conditional Graph Logic Network", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthesis is one of the fundamental problems in organic chemistry. The\ntask is to identify reactants that can be used to synthesize a specified\nproduct molecule. Recently, computer-aided retrosynthesis is finding renewed\ninterest from both chemistry and computer science communities. Most existing\napproaches rely on template-based models that define subgraph matching rules,\nbut whether or not a chemical reaction can proceed is not defined by hard\ndecision rules. In this work, we propose a new approach to this task using the\nConditional Graph Logic Network, a conditional graphical model built upon graph\nneural networks that learns when rules from reaction templates should be\napplied, implicitly considering whether the resulting reaction would be both\nchemically feasible and strategic. We also propose an efficient hierarchical\nsampling to alleviate the computation cost. While achieving a significant\nimprovement of $8.1\\%$ over current state-of-the-art methods on the benchmark\ndataset, our model also offers interpretations for the prediction.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 05:36:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Dai", "Hanjun", ""], ["Li", "Chengtao", ""], ["Coley", "Connor W.", ""], ["Dai", "Bo", ""], ["Song", "Le", ""]]}, {"id": "2001.01426", "submitter": "Chieh-Fang Teng", "authors": "Chieh-Fang Teng and Yen-Liang Chen", "title": "Syndrome-Enabled Unsupervised Learning for Neural Network-Based Polar\n  Decoder and Jointly Optimized Blind Equalizer", "comments": "12 pages, 13 figures, 3 tables. Published in IEEE Journal on Emerging\n  and Selected Topics in Circuits and Systems", "journal-ref": null, "doi": "10.1109/JETCAS.2020.2992593", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the syndrome loss has been proposed to achieve \"unsupervised\nlearning\" for neural network-based BCH/LDPC decoders. However, the design\napproach cannot be applied to polar codes directly and has not been evaluated\nunder varying channels. In this work, we propose two modified syndrome losses\nto facilitate unsupervised learning in the receiver. Then, we first apply it to\na neural network-based belief propagation (BP) polar decoder. With the aid of\nCRC-enabled syndrome loss, the BP decoder can even outperform conventional\nsupervised learning methods in terms of block error rate. Secondly, we propose\na jointly optimized syndrome-enabled blind equalizer, which can avoid the\ntransmission of training sequences and achieve global optimum with 1.3 dB gain\nover non-blind minimum mean square error (MMSE) equalizer.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:24:00 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 05:51:48 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Teng", "Chieh-Fang", ""], ["Chen", "Yen-Liang", ""]]}, {"id": "2001.01431", "submitter": "Yuge Zhang", "authors": "Yuge Zhang, Zejun Lin, Junyang Jiang, Quanlu Zhang, Yujing Wang, Hui\n  Xue, Chen Zhang, Yaming Yang", "title": "Deeper Insights into Weight Sharing in Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep neural networks, Neural Architecture Search (NAS) as\na way of automatic model design has attracted wide attention. As training every\nchild model from scratch is very time-consuming, recent works leverage\nweight-sharing to speed up the model evaluation procedure. These approaches\ngreatly reduce computation by maintaining a single copy of weights on the\nsuper-net and share the weights among every child model. However,\nweight-sharing has no theoretical guarantee and its impact has not been well\nstudied before. In this paper, we conduct comprehensive experiments to reveal\nthe impact of weight-sharing: (1) The best-performing models from different\nruns or even from consecutive epochs within the same run have significant\nvariance; (2) Even with high variance, we can extract valuable information from\ntraining the super-net with shared weights; (3) The interference between child\nmodels is a main factor that induces high variance; (4) Properly reducing the\ndegree of weight sharing could effectively reduce variance and improve\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:50:08 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Zhang", "Yuge", ""], ["Lin", "Zejun", ""], ["Jiang", "Junyang", ""], ["Zhang", "Quanlu", ""], ["Wang", "Yujing", ""], ["Xue", "Hui", ""], ["Zhang", "Chen", ""], ["Yang", "Yaming", ""]]}, {"id": "2001.01432", "submitter": "Chang Min Hyun", "authors": "Chang Min Hyun, Seong Hyeon Baek, Mingyu Lee, Sung Min Lee, and Jin\n  Keun Seo", "title": "Deep Learning-Based Solvability of Underdetermined Inverse Problems in\n  Medical Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the significant developments in deep learning techniques,\nsolving underdetermined inverse problems has become one of the major concerns\nin the medical imaging domain. Typical examples include undersampled magnetic\nresonance imaging, interior tomography, and sparse-view computed tomography,\nwhere deep learning techniques have achieved excellent performances. Although\ndeep learning methods appear to overcome the limitations of existing\nmathematical methods when handling various underdetermined problems, there is a\nlack of rigorous mathematical foundations that would allow us to elucidate the\nreasons for the remarkable performance of deep learning methods. This study\nfocuses on learning the causal relationship regarding the structure of the\ntraining data suitable for deep learning, to solve highly underdetermined\ninverse problems. We observe that a majority of the problems of solving\nunderdetermined linear systems in medical imaging are highly non-linear.\nFurthermore, we analyze if a desired reconstruction map can be learnable from\nthe training data and underdetermined system.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:52:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 02:35:59 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 00:17:55 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Hyun", "Chang Min", ""], ["Baek", "Seong Hyeon", ""], ["Lee", "Mingyu", ""], ["Lee", "Sung Min", ""], ["Seo", "Jin Keun", ""]]}, {"id": "2001.01433", "submitter": "Muneki Yasuda", "authors": "Muneki Yasuda and Yeo Xian En and Seishirou Ueno", "title": "Consistent Batch Normalization for Weighted Loss in Imbalanced-Data\n  Environment", "comments": null, "journal-ref": null, "doi": "10.1587/nolta.11.454", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, classification problems based on feedforward neural networks\nin a data-imbalanced environment are considered. Learning from an imbalanced\ndataset is one of the most important practical problems in the field of machine\nlearning. A weighted loss function (WLF) based on a cost-sensitive approach is\na well-known and effective method for imbalanced datasets. A combination of WLF\nand batch normalization (BN) is considered in this study. BN is considered as a\npowerful standard technique in the recent developments in deep learning. A\nsimple combination of both methods leads to a size-inconsistency problem due to\na mismatch between the interpretations of the effective size of the dataset in\nboth methods. A simple modification to BN, called weighted BN (WBN), is\nproposed to correct the size mismatch. The idea of WBN is simple and natural.\nThe proposed method in a data-imbalanced environment is validated using\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 08:15:58 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 02:06:22 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 02:51:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yasuda", "Muneki", ""], ["En", "Yeo Xian", ""], ["Ueno", "Seishirou", ""]]}, {"id": "2001.01458", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "Express Wavenet -- a low parameter optical neural network with random\n  shift wavelet pattern", "comments": "5 pages,4 figures", "journal-ref": null, "doi": "10.1016/j.optcom.2020.126709", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Express Wavenet is an improved optical diffractive neural network. At each\nlayer, it uses wavelet-like pattern to modulate the phase of optical waves. For\ninput image with n2 pixels, express wavenet reduce parameter number from O(n2)\nto O(n). Only need one percent of the parameters, and the accuracy is still\nvery high. In the MNIST dataset, it only needs 1229 parameters to get accuracy\nof 92%, while the standard optical network needs 125440 parameters. The random\nshift wavelets show the characteristics of optical network more vividly.\nEspecially the vanishing gradient phenomenon in the training process. We\npresent a modified expressway structure for this problem. Experiments verified\nthe effect of random shift wavelet and expressway structure. Our work shows\noptical diffractive network would use much fewer parameters than other neural\nnetworks. The source codes are available at\nhttps://github.com/closest-git/ONNet.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 09:45:20 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2001.01469", "submitter": "Vishwanath D", "authors": "Shubham Paliwal, Vishwanath D, Rohit Rahul, Monika Sharma, Lovekesh\n  Vig", "title": "TableNet: Deep Learning model for end-to-end Table detection and Tabular\n  data extraction from Scanned Document Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of mobile phones and scanners to photograph and\nupload documents, the need for extracting the information trapped in\nunstructured document images such as retail receipts, insurance claim forms and\nfinancial invoices is becoming more acute. A major hurdle to this objective is\nthat these images often contain information in the form of tables and\nextracting data from tabular sub-images presents a unique set of challenges.\nThis includes accurate detection of the tabular region within an image, and\nsubsequently detecting and extracting information from the rows and columns of\nthe detected table. While some progress has been made in table detection,\nextracting the table contents is still a challenge since this involves more\nfine grained table structure(rows & columns) recognition. Prior approaches have\nattempted to solve the table detection and structure recognition problems\nindependently using two separate models. In this paper, we propose TableNet: a\nnovel end-to-end deep learning model for both table detection and structure\nrecognition. The model exploits the interdependence between the twin tasks of\ntable detection and table structure recognition to segment out the table and\ncolumn regions. This is followed by semantic rule-based row extraction from the\nidentified tabular sub-regions. The proposed model and extraction approach was\nevaluated on the publicly available ICDAR 2013 and Marmot Table datasets\nobtaining state of the art results. Additionally, we demonstrate that feeding\nadditional semantic features further improves model performance and that the\nmodel exhibits transfer learning across datasets. Another contribution of this\npaper is to provide additional table structure annotations for the Marmot data,\nwhich currently only has annotations for table detection.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 10:25:32 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Paliwal", "Shubham", ""], ["D", "Vishwanath", ""], ["Rahul", "Rohit", ""], ["Sharma", "Monika", ""], ["Vig", "Lovekesh", ""]]}, {"id": "2001.01520", "submitter": "Julien Brajard", "authors": "Julien Brajard (1 and 2), Alberto Carassi (3 and 4), Marc Bocquet (5),\n  Laurent Bertino (1) ((1) Nansen Center, Bergen, Norway, (2) Sorbonne\n  University, CNRS-IRD-MNHN, LOCEAN, Paris, France, (3) Dept of Meteorology,\n  University of Reading, (4) Mathematical Institute, University of Utrecht, (5)\n  CEREA, joint laboratory \\'Ecole des Ponts ParisTech and EDF R&D, Universit\\'e\n  Paris-Est, Champs-sur-Marne, France)", "title": "Combining data assimilation and machine learning to emulate a dynamical\n  model from sparse and noisy observations: a case study with the Lorenz 96\n  model", "comments": "for associated code, see https://github.com/brajard/GMD-code", "journal-ref": "Journal of Computational Science, Volume 44, 2020", "doi": "10.1016/j.jocs.2020.101171", "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method, based on the combination of data assimilation and machine\nlearning is introduced. The new hybrid approach is designed for a two-fold\nscope: (i) emulating hidden, possibly chaotic, dynamics and (ii) predicting\ntheir future states. The method consists in applying iteratively a data\nassimilation step, here an ensemble Kalman filter, and a neural network. Data\nassimilation is used to optimally combine a surrogate model with sparse noisy\ndata. The output analysis is spatially complete and is used as a training set\nby the neural network to update the surrogate model. The two steps are then\nrepeated iteratively. Numerical experiments have been carried out using the\nchaotic 40-variables Lorenz 96 model, proving both convergence and statistical\nskill of the proposed hybrid approach. The surrogate model shows short-term\nforecast skill up to two Lyapunov times, the retrieval of positive Lyapunov\nexponents as well as the more energetic frequencies of the power density\nspectrum. The sensitivity of the method to critical setup parameters is also\npresented: the forecast skill decreases smoothly with increased observational\nnoise but drops abruptly if less than half of the model domain is observed. The\nsuccessful synergy between data assimilation and machine learning, proven here\nwith a low-dimensional system, encourages further investigation of such hybrids\nwith more sophisticated dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:26:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 13:23:48 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Brajard", "Julien", "", "1 and 2"], ["Carassi", "Alberto", "", "3 and 4"], ["Bocquet", "Marc", ""], ["Bertino", "Laurent", ""]]}, {"id": "2001.01523", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B. Allen, Randy P.\n  Auerbach, David Brent, Ruslan Salakhutdinov, Louis-Philippe Morency", "title": "Think Locally, Act Globally: Federated Learning with Local and Global\n  Representations", "comments": "NeurIPS 2019 Workshop on Federated Learning distinguished student\n  paper award. Code: https://github.com/pliang279/LG-FedAvg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a method of training models on private data distributed\nover multiple devices. To keep device data private, the global model is trained\nby only communicating parameters and updates which poses scalability challenges\nfor large models. To this end, we propose a new federated learning algorithm\nthat jointly learns compact local representations on each device and a global\nmodel across all devices. As a result, the global model can be smaller since it\nonly operates on local representations, reducing the number of communicated\nparameters. Theoretically, we provide a generalization analysis which shows\nthat a combination of local and global models reduces both variance in the data\nas well as variance across device distributions. Empirically, we demonstrate\nthat local models enable communication-efficient training while retaining\nperformance. We also evaluate on the task of personalized mood prediction from\nreal-world mobile data where privacy is key. Finally, local models handle\nheterogeneous data from new devices, and learn fair representations that\nobfuscate protected attributes such as race, age, and gender.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:40:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 07:23:45 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 08:12:35 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Terrance", ""], ["Ziyin", "Liu", ""], ["Allen", "Nicholas B.", ""], ["Auerbach", "Randy P.", ""], ["Brent", "David", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2001.01536", "submitter": "Liuyu Xiang", "authors": "Liuyu Xiang, Guiguang Ding and Jungong Han", "title": "Learning From Multiple Experts: Self-paced Knowledge Distillation for\n  Long-tailed Classification", "comments": "ECCV 2020 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world scenarios, data tends to exhibit a long-tailed distribution,\nwhich increases the difficulty of training deep networks. In this paper, we\npropose a novel self-paced knowledge distillation framework, termed Learning\nFrom Multiple Experts (LFME). Our method is inspired by the observation that\nnetworks trained on less imbalanced subsets of the distribution often yield\nbetter performances than their jointly-trained counterparts. We refer to these\nmodels as 'Experts', and the proposed LFME framework aggregates the knowledge\nfrom multiple 'Experts' to learn a unified student model. Specifically, the\nproposed framework involves two levels of adaptive learning schedules:\nSelf-paced Expert Selection and Curriculum Instance Selection, so that the\nknowledge is adaptively transferred to the 'Student'. We conduct extensive\nexperiments and demonstrate that our method is able to achieve superior\nperformances compared to state-of-the-art methods. We also show that our method\ncan be easily plugged into state-of-the-art long-tailed classification\nalgorithms for further improvements.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:57:36 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 05:21:56 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 02:44:16 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xiang", "Liuyu", ""], ["Ding", "Guiguang", ""], ["Han", "Jungong", ""]]}, {"id": "2001.01550", "submitter": "Shenda Hong", "authors": "Shenda Hong, Yuxi Zhou, Junyuan Shang, Cao Xiao, Jimeng Sun", "title": "Opportunities and Challenges of Deep Learning Methods for\n  Electrocardiogram Data: A Systematic Review", "comments": "Accepted by Computers in Biology and Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background:The electrocardiogram (ECG) is one of the most commonly used\ndiagnostic tools in medicine and healthcare. Deep learning methods have\nachieved promising results on predictive healthcare tasks using ECG signals.\nObjective:This paper presents a systematic review of deep learning methods for\nECG data from both modeling and application perspectives. Methods:We extracted\npapers that applied deep learning (deep neural network) models to ECG data that\nwere published between Jan. 1st of 2010 and Feb. 29th of 2020 from Google\nScholar, PubMed, and the DBLP. We then analyzed each article according to three\nfactors: tasks, models, and data. Finally, we discuss open challenges and\nunsolved problems in this area. Results: The total number of papers extracted\nwas 191. Among these papers, 108 were published after 2019. Different deep\nlearning architectures have been used in various ECG analytics tasks, such as\ndisease detection/classification, annotation/localization, sleep staging,\nbiometric human identification, and denoising. Conclusion: The number of works\non deep learning for ECG data has grown explosively in recent years. Such works\nhave achieved accuracy comparable to that of traditional feature-based\napproaches and ensembles of multiple approaches can achieve even better\nresults. Specifically, we found that a hybrid architecture of a convolutional\nneural network and recurrent neural network ensemble using expert features\nyields the best results. However, there are some new challenges and problems\nrelated to interpretability, scalability, and efficiency that must be\naddressed. Furthermore, it is also worth investigating new applications from\nthe perspectives of datasets and methods. Significance: This paper summarizes\nexisting deep learning research using ECG data from multiple perspectives and\nhighlights existing challenges and problems to identify potential future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 02:44:29 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 19:01:55 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 18:42:49 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Hong", "Shenda", ""], ["Zhou", "Yuxi", ""], ["Shang", "Junyuan", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.01556", "submitter": "Ronny G. Guendel", "authors": "Ronny Gerhard Guendel", "title": "Radar Classification of Contiguous Activities of Daily Living", "comments": "Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider radar classifications of Activities of Daily Living (ADL) which\ncan prove beneficial in fall detection, analysis of daily routines, and\ndiscerning physical and cognitive human conditions. We focus on contiguous\nmotion classifications which follow and commensurate with the human ethogram of\npossible motion sequences. Contiguous motions can be closely connected with no\nclear time gap separations. In the proposed motion classification approach, we\nutilize the Radon transform applied to the radar range-map to detect the\ntranslation motion, whereas an energy detector is used to provide the onset and\noffset times of in-place motions, such as sitting down and standing up. It is\nshown that motion classifications give different results when performed forward\nand backward in time. The number of classes, thereby classification rates,\nconsidered by a classifier, is made variable depending on the current motion\nstate and the possible transitioning activities in and out of the state. Motion\nexamples are provided to delineate the performance of the proposed approach\nunder typical sequences of human motions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 15:11:26 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 21:19:19 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Guendel", "Ronny Gerhard", ""]]}, {"id": "2001.01558", "submitter": "Amir Mosavi Prof", "authors": "Zohreh Sheikh Khozani, Khabat Khosravi, Mohammadamin Torabi, Amir\n  Mosavi, Bahram Rezaei, Timon Rabczuk", "title": "Shear Stress Distribution Prediction in Symmetric Compound Channels\n  Using Data Mining and Machine Learning Models", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shear stress distribution prediction in open channels is of utmost importance\nin hydraulic structural engineering as it directly affects the design of stable\nchannels. In this study, at first, a series of experimental tests were\nconducted to assess the shear stress distribution in prismatic compound\nchannels. The shear stress values around the whole wetted perimeter were\nmeasured in the compound channel with different floodplain widths also in\ndifferent flow depths in subcritical and supercritical conditions. A set of,\ndata mining and machine learning models including Random Forest (RF), M5P,\nRandom Committee (RC), KStar and Additive Regression Model (AR) implemented on\nattained data to predict the shear stress distribution in the compound channel.\nResults indicated among these five models, RF method indicated the most precise\nresults with the highest R2 value of 0.9. Finally, the most powerful data\nmining method which studied in this research (RF) compared with two well-known\nanalytical models of Shiono and Knight Method (SKM) and Shannon method to\nacquire the proposed model functioning in predicting the shear stress\ndistribution. The results showed that the RF model has the best prediction\nperformance compared to SKM and Shannon models.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 08:57:51 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Khozani", "Zohreh Sheikh", ""], ["Khosravi", "Khabat", ""], ["Torabi", "Mohammadamin", ""], ["Mosavi", "Amir", ""], ["Rezaei", "Bahram", ""], ["Rabczuk", "Timon", ""]]}, {"id": "2001.01559", "submitter": "Mehrdad Shafiei Dizaji", "authors": "Mojtaba Farrokh, Mehrdad Shafiei Dizaji, Farzad Shafiei Dizaji,\n  Nazanin Moradinasab", "title": "Universal Hysteresis Identification Using Extended Preisach Neural\n  Network", "comments": "17 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hysteresis phenomena have been observed in different branches of physics and\nengineering sciences. Therefore, several models have been proposed for\nhysteresis simulation in different fields; however, almost neither of them can\nbe utilized universally. In this paper by inspiring of Preisach Neural Network\nwhich was inspired by the Preisach model that basically stemmed from Madelungs\nrules and using the learning capability of the neural networks, an adaptive\nuniversal model for hysteresis is introduced and called Extended Preisach\nNeural Network Model. It is comprised of input, output and, two hidden layers.\nThe input and output layers contain linear neurons while the first hidden layer\nincorporates neurons called Deteriorating Stop neurons, which their activation\nfunction follows Deteriorating Stop operator. Deteriorating Stop operators can\ngenerate non-congruent hysteresis loops. The second hidden layer includes\nSigmoidal neurons. Adding the second hidden layer, helps the neural network\nlearn non-Masing and asymmetric hysteresis loops very smoothly. At the input\nlayer, besides input data the rate at which input data changes, is included as\nwell in order to give the model the capability of learning rate-dependent\nhysteresis loops. Hence, the proposed approach has the capability of the\nsimulation of both rate-independent and rate-dependent hysteresis with either\ncongruent or non-congruent loops as well as symmetric and asymmetric loops. A\nnew hybridized algorithm has been adopted for training the model which is based\non a combination of the Genetic Algorithm and the optimization method of\nsub-gradient with space dilatation. The generality of the proposed model has\nbeen evaluated by applying it to various hysteresis from different areas of\nengineering with different characteristics. The results show that the model is\nsuccessful in the identification of the considered hystereses.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 18:10:48 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farrokh", "Mojtaba", ""], ["Dizaji", "Mehrdad Shafiei", ""], ["Dizaji", "Farzad Shafiei", ""], ["Moradinasab", "Nazanin", ""]]}, {"id": "2001.01560", "submitter": "Rodrigo de Lamare", "authors": "X. Wang, Z. Yang, J. Huang, and R. C. de Lamare", "title": "Study of Robust Two-Stage Reduced-Dimension Sparsity-Aware STAP with\n  Coprime Arrays", "comments": "13 figures, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space-time adaptive processing (STAP) algorithms with coprime arrays can\nprovide good clutter suppression potential with low cost in airborne radar\nsystems as compared with their uniform linear arrays counterparts. However, the\nperformance of these algorithms is limited by the training samples support in\npractical applications. To address this issue, a robust two-stage\nreduced-dimension (RD) sparsity-aware STAP algorithm is proposed in this work.\nIn the first stage, an RD virtual snapshot is constructed using all spatial\nchannels but only $m$ adjacent Doppler channels around the target Doppler\nfrequency to reduce the slow-time dimension of the signal. In the second stage,\nan RD sparse measurement modeling is formulated based on the constructed RD\nvirtual snapshot, where the sparsity of clutter and the prior knowledge of the\nclutter ridge are exploited to formulate an RD overcomplete dictionary.\nMoreover, an orthogonal matching pursuit (OMP)-like method is proposed to\nrecover the clutter subspace. In order to set the stopping parameter of the\nOMP-like method, a robust clutter rank estimation approach is developed.\nCompared with recently developed sparsity-aware STAP algorithms, the size of\nthe proposed sparse representation dictionary is much smaller, resulting in low\ncomplexity. Simulation results show that the proposed algorithm is robust to\nprior knowledge errors and can provide good clutter suppression performance in\nlow sample support.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:14:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Wang", "X.", ""], ["Yang", "Z.", ""], ["Huang", "J.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "2001.01569", "submitter": "Amir Mosavi Prof", "authors": "Alireza Hajipour, Arash Mirabdolah Lavasani, Mohammad Eftekhari Yazdi,\n  Amir Mosavi, Shahaboddin Shamshirband, Kwok-Wing Chau", "title": "Simulation of Turbulent Flow around a Generic High-Speed Train using\n  Hybrid Models of RANS Numerical Method with Machine Learning", "comments": "43 pages, 25 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present paper, an aerodynamic investigation of a high-speed train is\nperformed. In the first section of this article, a generic high-speed train\nagainst a turbulent flow is simulated, numerically. The Reynolds-Averaged\nNavier-Stokes (RANS) equations combined with the turbulence model are applied\nto solve incompressible turbulent flow around a high-speed train. Flow\nstructure, velocity and pressure contours and streamlines at some typical wind\ndirections are the most important results of this simulation. The maximum and\nminimum values are specified and discussed. Also, the pressure coefficient for\nsome critical points on the train surface is evaluated. In the following, the\nwind direction influence the aerodynamic key parameters as drag, lift, and side\nforces at the mentioned wind directions are analyzed and compared. Moreover,\nthe effects of velocity changes (50, 60, 70, 80 and 90 m/s) are estimated and\ncompared on the above flow and aerodynamic parameters. In the second section of\nthe paper, various data-driven methods including Gene Expression Programming\n(GEP), Gaussian Process Regression (GPR), and random forest (RF), are applied\nfor predicting output parameters. So, drag, lift, and side forces and also\nminimum and a maximum of pressure coefficients for mentioned wind directions\nand velocity are predicted and compared using statistical parameters. Obtained\nresults indicated that RF in all coefficients of wind direction and most\ncoefficients of free stream velocity provided the most accurate predictions. As\na conclusion, RF may be recommended for the prediction of aerodynamic\ncoefficients.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 23:34:23 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Hajipour", "Alireza", ""], ["Lavasani", "Arash Mirabdolah", ""], ["Yazdi", "Mohammad Eftekhari", ""], ["Mosavi", "Amir", ""], ["Shamshirband", "Shahaboddin", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.01574", "submitter": "Daoud Burghal", "authors": "Daoud Burghal, Naveed A. Abbasi, and Andreas F. Molisch", "title": "A Machine Learning Solution for Beam Tracking in mmWave Systems", "comments": "Presented in Asilomar 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilizing millimeter-wave (mmWave) frequencies for wireless communication in\n\\emph{mobile} systems is challenging since it requires continuous tracking of\nthe beam direction. Recently, beam tracking techniques based on channel\nsparsity and/or Kalman filter-based techniques were proposed where the\nsolutions use assumptions regarding the environment and device mobility that\nmay not hold in practical scenarios. In this paper, we explore a machine\nlearning-based approach to track the angle of arrival (AoA) for specific paths\nin realistic scenarios. In particular, we use a recurrent neural network (R-NN)\nstructure with a modified cost function to track the AoA. We propose methods to\ntrain the network in sequential data, and study the performance of our proposed\nsolution in comparison to an extended Kalman filter based solution in a\nrealistic mmWave scenario based on stochastic channel model from the QuaDRiGa\nframework. Results show that our proposed solution outperforms an extended\nKalman filter-based method by reducing the AoA outage probability, and thus\nreducing the need for frequent beam search.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 06:18:54 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Burghal", "Daoud", ""], ["Abbasi", "Naveed A.", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "2001.01578", "submitter": "Giang Nguyen", "authors": "Giang Nguyen, Shuan Chen, Thao Do, Tae Joon Jun, Ho-Jin Choi, Daeyoung\n  Kim", "title": "Dissecting Catastrophic Forgetting in Continual Learning by Deep\n  Visualization", "comments": "8 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpreting the behaviors of Deep Neural Networks (usually considered as a\nblack box) is critical especially when they are now being widely adopted over\ndiverse aspects of human life. Taking the advancements from Explainable\nArtificial Intelligent, this paper proposes a novel technique called Auto\nDeepVis to dissect catastrophic forgetting in continual learning. A new method\nto deal with catastrophic forgetting named critical freezing is also introduced\nupon investigating the dilemma by Auto DeepVis. Experiments on a captioning\nmodel meticulously present how catastrophic forgetting happens, particularly\nshowing which components are forgetting or changing. The effectiveness of our\ntechnique is then assessed; and more precisely, critical freezing claims the\nbest performance on both previous and coming tasks over baselines, proving the\ncapability of the investigation. Our techniques could not only be supplementary\nto existing solutions for completely eradicating catastrophic forgetting for\nlife-long learning but also explainable.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:49:32 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 08:07:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Nguyen", "Giang", ""], ["Chen", "Shuan", ""], ["Do", "Thao", ""], ["Jun", "Tae Joon", ""], ["Choi", "Ho-Jin", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2001.01587", "submitter": "Ling Liang", "authors": "Ling Liang, Xing Hu, Lei Deng, Yujie Wu, Guoqi Li, Yufei Ding, Peng\n  Li, Yuan Xie", "title": "Exploring Adversarial Attack in Spiking Neural Networks with\n  Spike-Compatible Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, backpropagation through time inspired learning algorithms are\nwidely introduced into SNNs to improve the performance, which brings the\npossibility to attack the models accurately given Spatio-temporal gradient\nmaps. We propose two approaches to address the challenges of gradient input\nincompatibility and gradient vanishing. Specifically, we design a gradient to\nspike converter to convert continuous gradients to ternary ones compatible with\nspike inputs. Then, we design a gradient trigger to construct ternary gradients\nthat can randomly flip the spike inputs with a controllable turnover rate, when\nmeeting all zero gradients. Putting these methods together, we build an\nadversarial attack methodology for SNNs trained by supervised algorithms.\nMoreover, we analyze the influence of the training loss function and the firing\nthreshold of the penultimate layer, which indicates a \"trap\" region under the\ncross-entropy loss that can be escaped by threshold tuning. Extensive\nexperiments are conducted to validate the effectiveness of our solution.\nBesides the quantitative analysis of the influence factors, we evidence that\nSNNs are more robust against adversarial attack than ANNs. This work can help\nreveal what happens in SNN attack and might stimulate more research on the\nsecurity of SNN models and neuromorphic devices.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 18:14:44 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:56:29 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Liang", "Ling", ""], ["Hu", "Xing", ""], ["Deng", "Lei", ""], ["Wu", "Yujie", ""], ["Li", "Guoqi", ""], ["Ding", "Yufei", ""], ["Li", "Peng", ""], ["Xie", "Yuan", ""]]}, {"id": "2001.01592", "submitter": "Enmei Tu", "authors": "Enmei Tu, Guanghao Zhang, Shangbo Mao, Lily Rachmawati and Guang-Bin\n  Huang", "title": "Modeling Historical AIS Data For Vessel Path Prediction: A Comprehensive\n  Treatment", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosperity of artificial intelligence has aroused intensive interests in\nintelligent/autonomous navigation, in which path prediction is a key\nfunctionality for decision supports, e.g. route planning, collision warning,\nand traffic regulation. For maritime intelligence, Automatic Identification\nSystem (AIS) plays an important role because it recently has been made\ncompulsory for large international commercial vessels and is able to provide\nnearly real-time information of the vessel. Therefore AIS data based vessel\npath prediction is a promising way in future maritime intelligence. However,\nreal-world AIS data collected online are just highly irregular trajectory\nsegments (AIS message sequences) from different types of vessels and\ngeographical regions, with possibly very low data quality. So even there are\nsome works studying how to build a path prediction model using historical AIS\ndata, but still, it is a very challenging problem. In this paper, we propose a\ncomprehensive framework to model massive historical AIS trajectory segments for\naccurate vessel path prediction. Experimental comparisons with existing popular\nmethods are made to validate the proposed approach and results show that our\napproach could outperform the baseline methods by a wide margin.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:16:40 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 02:20:32 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Tu", "Enmei", ""], ["Zhang", "Guanghao", ""], ["Mao", "Shangbo", ""], ["Rachmawati", "Lily", ""], ["Huang", "Guang-Bin", ""]]}, {"id": "2001.01596", "submitter": "Merten Stender", "authors": "Merten Stender, Merten Tiedemann, David Spieler, Daniel Schoepflin,\n  Norbert Hofffmann, Sebastian Oberst", "title": "Deep learning for brake squeal: vibration detection, characterization\n  and prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant advances in modeling of friction-induced vibrations and\nbrake squeal, the majority of industrial research and design is still conducted\nexperimentally, since many aspects of squeal and its mechanisms involved remain\nunknown. We report here for the first time on novel strategies for handling\ndata-intensive vibration testings to gain better insights into friction brake\nsystem vibrations and noise generation mechanisms. Machine learning-based\nmethods to detect and characterize vibrations, to understand sensitivities and\nto predict brake squeal are applied with the aim to illustrate how\ninterdisciplinary approaches can leverage the potential of data science\ntechniques for classical mechanical engineering challenges. In the first part,\na deep learning brake squeal detector is developed to identify several classes\nof typical friction noise recordings. The detection method is rooted in recent\ncomputer vision techniques for object detection based on convolutional neural\nnetworks. It allows to overcome limitations of classical approaches that solely\nrely on instantaneous spectral properties of the recorded noise. Results\nindicate superior detection and characterization quality when compared to a\nstate-of-the-art brake squeal detector. In the second part, a recurrent neural\nnetwork is employed to learn the parametric patterns that determine the dynamic\nstability of an operating brake system. Given a set of multivariate loading\nconditions, the RNN learns to predict the noise generation of the structure.\nThe validated RNN represents a virtual twin model for the squeal behavior of a\nspecific brake system. It is found that this model can predict the occurrence\nand the onset of brake squeal with high accuracy and that it can identify the\ncomplicated patterns and temporal dependencies in the loading conditions that\ndrive the dynamical structure into regimes of instability.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:54:20 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:57:48 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Stender", "Merten", ""], ["Tiedemann", "Merten", ""], ["Spieler", "David", ""], ["Schoepflin", "Daniel", ""], ["Hofffmann", "Norbert", ""], ["Oberst", "Sebastian", ""]]}, {"id": "2001.01599", "submitter": "Noriaki Hashimoto", "authors": "Noriaki Hashimoto, Daisuke Fukushima, Ryoichi Koga, Yusuke Takagi,\n  Kaho Ko, Kei Kohno, Masato Nakaguro, Shigeo Nakamura, Hidekata Hontani and\n  Ichiro Takeuchi", "title": "Multi-scale Domain-adversarial Multiple-instance CNN for Cancer Subtype\n  Classification with Unannotated Histopathological Images", "comments": "Accepted to CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for cancer subtype classification from\nhistopathological images, which can automatically detect tumor-specific\nfeatures in a given whole slide image (WSI). The cancer subtype should be\nclassified by referring to a WSI, i.e., a large-sized image (typically\n40,000x40,000 pixels) of an entire pathological tissue slide, which consists of\ncancer and non-cancer portions. One difficulty arises from the high cost\nassociated with annotating tumor regions in WSIs. Furthermore, both global and\nlocal image features must be extracted from the WSI by changing the\nmagnifications of the image. In addition, the image features should be stably\ndetected against the differences of staining conditions among the\nhospitals/specimens. In this paper, we develop a new CNN-based cancer subtype\nclassification method by effectively combining multiple-instance, domain\nadversarial, and multi-scale learning frameworks in order to overcome these\npractical difficulties. When the proposed method was applied to malignant\nlymphoma subtype classifications of 196 cases collected from multiple\nhospitals, the classification performance was significantly better than the\nstandard CNN or other conventional methods, and the accuracy compared favorably\nwith that of standard pathologists.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 14:09:51 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 08:03:24 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Hashimoto", "Noriaki", ""], ["Fukushima", "Daisuke", ""], ["Koga", "Ryoichi", ""], ["Takagi", "Yusuke", ""], ["Ko", "Kaho", ""], ["Kohno", "Kei", ""], ["Nakaguro", "Masato", ""], ["Nakamura", "Shigeo", ""], ["Hontani", "Hidekata", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2001.01613", "submitter": "Nadine Rueegg", "authors": "Nadine Rueegg, Christoph Lassner, Michael J. Black, Konrad Schindler", "title": "Chained Representation Cycling: Learning to Estimate 3D Human Pose and\n  Shape by Cycling Between Representations", "comments": "To be published in proceedings of Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of many computer vision systems is to transform image pixels into 3D\nrepresentations. Recent popular models use neural networks to regress directly\nfrom pixels to 3D object parameters. Such an approach works well when\nsupervision is available, but in problems like human pose and shape estimation,\nit is difficult to obtain natural images with 3D ground truth. To go one step\nfurther, we propose a new architecture that facilitates unsupervised, or\nlightly supervised, learning. The idea is to break the problem into a series of\ntransformations between increasingly abstract representations. Each step\ninvolves a cycle designed to be learnable without annotated training data, and\nthe chain of cycles delivers the final solution. Specifically, we use 2D body\npart segments as an intermediate representation that contains enough\ninformation to be lifted to 3D, and at the same time is simple enough to be\nlearned in an unsupervised way. We demonstrate the method by learning 3D human\npose and shape from un-paired and un-annotated images. We also explore varying\namounts of paired data and show that cycling greatly alleviates the need for\npaired data. While we present results for modeling humans, our formulation is\ngeneral and can be applied to other vision problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 14:54:00 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Rueegg", "Nadine", ""], ["Lassner", "Christoph", ""], ["Black", "Michael J.", ""], ["Schindler", "Konrad", ""]]}, {"id": "2001.01618", "submitter": "Sudipta Paul Ms.", "authors": "Sudipta Paul and Subhankar Mishra", "title": "ARA : Aggregated RAPPOR and Analysis for Centralized Differential\n  Privacy", "comments": null, "journal-ref": "SN COMPUT. SCI. (2020) 1: 22", "doi": "10.1007/s42979-019-0023-y", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Differential privacy(DP) has now become a standard in case of sensitive\nstatistical data analysis. The two main approaches in DP is local and central.\nBoth the approaches have a clear gap in terms of data storing,amount of data to\nbe analyzed, analysis, speed etc. Local wins on the speed. We have tested the\nstate of the art standard RAPPOR which is a local approach and supported this\ngap. Our work completely focuses on that part too. Here, we propose a model\nwhich initially collects RAPPOR reports from multiple clients which are then\npushed to a Tf-Idf estimation model. The Tf-Idf estimation model then estimates\nthe reports on the basis of the occurrence of \"on bit\" in a particular position\nand its contribution to that position. Thus it generates a centralized\ndifferential privacy analysis from multiple clients. Our model successfully and\nefficiently analyzed the major truth value every time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:03:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Paul", "Sudipta", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2001.01620", "submitter": "Manuel Del Verme", "authors": "Manuel Del Verme, Bruno Castro da Silva, Gianluca Baldassarre", "title": "Optimal Options for Multi-Task Reinforcement Learning Under Time\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning can greatly benefit from the use of options as a way\nof encoding recurring behaviours and to foster exploration. An important open\nproblem is how can an agent autonomously learn useful options when solving\nparticular distributions of related tasks. We investigate some of the\nconditions that influence optimality of options, in settings where agents have\na limited time budget for learning each task and the task distribution might\ninvolve problems with different levels of similarity. We directly search for\noptimal option sets and show that the discovered options significantly differ\ndepending on factors such as the available learning time budget and that the\nfound options outperform popular option-generation heuristics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:08:46 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Del Verme", "Manuel", ""], ["da Silva", "Bruno Castro", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "2001.01647", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Rutuja Patil, Kristin Branson", "title": "Are skip connections necessary for biologically plausible learning\n  rules?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is the workhorse of deep learning, however, several other\nbiologically-motivated learning rules have been introduced, such as random\nfeedback alignment and difference target propagation. None of these methods\nhave produced a competitive performance against backpropagation. In this paper,\nwe show that biologically-motivated learning rules with skip connections\nbetween intermediate layers can perform as well as backpropagation on the MNIST\ndataset and are robust to various sets of hyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:21:16 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Patil", "Rutuja", ""], ["Branson", "Kristin", ""]]}, {"id": "2001.01666", "submitter": "Mathieu Carri\\`ere", "authors": "Andrew J. Blumberg and Mathieu Carriere and Michael A. Mandell and\n  Raul Rabadan and Soledad Villar", "title": "MREC: a fast and versatile framework for aligning and matching point\n  clouds with applications to single cell molecular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing and aligning large datasets is a pervasive problem occurring across\nmany different knowledge domains. We introduce and study MREC, a recursive\ndecomposition algorithm for computing matchings between data sets. The basic\nidea is to partition the data, match the partitions, and then recursively match\nthe points within each pair of identified partitions. The matching itself is\ndone using black box matching procedures that are too expensive to run on the\nentire data set. Using an absolute measure of the quality of a matching, the\nframework supports optimization over parameters including partitioning\nprocedures and matching algorithms. By design, MREC can be applied to extremely\nlarge data sets. We analyze the procedure to describe when we can expect it to\nwork well and demonstrate its flexibility and power by applying it to a number\nof alignment problems arising in the analysis of single cell molecular data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:02:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 06:26:35 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 22:17:02 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Blumberg", "Andrew J.", ""], ["Carriere", "Mathieu", ""], ["Mandell", "Michael A.", ""], ["Rabadan", "Raul", ""], ["Villar", "Soledad", ""]]}, {"id": "2001.01669", "submitter": "Mi Khine Oo", "authors": "Mi Khine Oo and May Aye Khine", "title": "Topic Extraction of Crawled Documents Collection using Correlated Topic\n  Model in MapReduce Framework", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous increase in the amount of available research documents impels\nresearchers to propose topic models to extract the latent semantic themes of a\ndocuments collection. However, how to extract the hidden topics of the\ndocuments collection has become a crucial task for many topic model\napplications. Moreover, conventional topic modeling approaches suffer from the\nscalability problem when the size of documents collection increases. In this\npaper, the Correlated Topic Model with variational Expectation-Maximization\nalgorithm is implemented in MapReduce framework to solve the scalability\nproblem. The proposed approach utilizes the dataset crawled from the public\ndigital library. In addition, the full-texts of the crawled documents are\nanalysed to enhance the accuracy of MapReduce CTM. The experiments are\nconducted to demonstrate the performance of the proposed algorithm. From the\nevaluation, the proposed approach has a comparable performance in terms of\ntopic coherences with LDA implemented in MapReduce framework.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:09:21 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Oo", "Mi Khine", ""], ["Khine", "May Aye", ""]]}, {"id": "2001.01678", "submitter": "Yuhai Tu", "authors": "Yu Feng and Yuhai Tu", "title": "How neural networks find generalizable solutions: Self-tuned annealing\n  in deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.LG nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous success of Stochastic Gradient Descent (SGD) algorithm\nin deep learning, little is known about how SGD finds generalizable solutions\nin the high-dimensional weight space. By analyzing the learning dynamics and\nloss function landscape, we discover a robust inverse relation between the\nweight variance and the landscape flatness (inverse of curvature) for all\nSGD-based learning algorithms. To explain the inverse variance-flatness\nrelation, we develop a random landscape theory, which shows that the SGD noise\nstrength (effective temperature) depends inversely on the landscape flatness.\nOur study indicates that SGD attains a self-tuned landscape-dependent annealing\nstrategy to find generalizable solutions at the flat minima of the landscape.\nFinally, we demonstrate how these new theoretical insights lead to more\nefficient algorithms, e.g., for avoiding catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 17:35:54 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Feng", "Yu", ""], ["Tu", "Yuhai", ""]]}, {"id": "2001.01680", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Lei Bi, Jinman Kim, Shanlin Xiao, and\n  Zhiyi Yu", "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised\n  Feature Learning", "comments": "Published at Neurocomputing", "journal-ref": "Neurocomputing 441(2021), pp. 92-104", "doi": "10.1016/j.neucom.2021.02.027", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:19:17 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 17:53:25 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 14:25:23 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 16:05:09 GMT"}, {"version": "v5", "created": "Tue, 9 Mar 2021 04:00:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Bi", "Lei", ""], ["Kim", "Jinman", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.01682", "submitter": "Wolfgang Maass Prof.", "authors": "Christoph St\\\"ockl and Wolfgang Maass", "title": "Recognizing Images with at most one Spike per Neuron", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to port the performance of trained artificial neural networks (ANNs)\nto spiking neural networks (SNNs), which can be implemented in neuromorphic\nhardware with a drastically reduced energy consumption, an efficient ANN to SNN\nconversion is needed. Previous conversion schemes focused on the representation\nof the analog output of a rectified linear (ReLU) gate in the ANN by the firing\nrate of a spiking neuron. But this is not possible for other commonly used ANN\ngates, and it reduces the throughput even for ReLU gates. We introduce a new\nconversion method where a gate in the ANN, which can basically be of any type,\nis emulated by a small circuit of spiking neurons, with At Most One Spike\n(AMOS) per neuron. We show that this AMOS conversion improves the accuracy of\nSNNs for ImageNet from 74.60% to 80.97%, thereby bringing it within reach of\nthe best available ANN accuracy (85.0%). The Top5 accuracy of SNNs is raised to\n95.82%, getting even closer to the best Top5 performance of 97.2% for ANNs. In\naddition, AMOS conversion improves latency and throughput of spike-based image\nclassification by several orders of magnitude. Hence these results suggest that\nSNNs provide a viable direction for developing highly energy efficient hardware\nfor AI that combines high performance with versatility of applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:28:11 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 10:08:27 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 10:54:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["St\u00f6ckl", "Christoph", ""], ["Maass", "Wolfgang", ""]]}, {"id": "2001.01683", "submitter": "Sebastian Risi", "authors": "Sebastian Risi and Kenneth O. Stanley", "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in\n  Training Heterogeneous Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning approaches have shown impressive results in a\nvariety of different domains, however, more complex heterogeneous architectures\nsuch as world models require the different neural components to be trained\nseparately instead of end-to-end. While a simple genetic algorithm recently\nshowed end-to-end training is possible, it failed to solve a more complex 3D\ntask. This paper presents a method called Deep Innovation Protection (DIP) that\naddresses the credit assignment problem in training complex heterogenous neural\nnetwork models end-to-end for such environments. The main idea behind the\napproach is to employ multiobjective optimization to temporally reduce the\nselection pressure on specific components in multi-component network, allowing\nother components to adapt. We investigate the emergent representations of these\nevolved networks, which learn to predict properties important for the survival\nof the agent, without the need for a specific forward-prediction loss.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 18:35:06 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 11:20:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Risi", "Sebastian", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2001.01684", "submitter": "John Raisbeck", "authors": "John C. Raisbeck (1), Matthew Allen (1), Ralph Weissleder (1),\n  Hyungsoon Im (1), Hakho Lee (1) ((1) Massachusetts General Hospital)", "title": "Evolution Strategies Converges to Finite Differences", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the debut of Evolution Strategies (ES) as a tool for Reinforcement\nLearning by Salimans et al. 2017, there has been interest in determining the\nexact relationship between the Evolution Strategies gradient and the gradient\nof a similar class of algorithms, Finite Differences (FD).(Zhang et al. 2017,\nLehman et al. 2018) Several investigations into the subject have been\nperformed, investigating the formal motivational differences(Lehman et al.\n2018) between ES and FD, as well as the differences in a standard benchmark\nproblem in Machine Learning, the MNIST classification problem(Zhang et al.\n2017). This paper proves that while the gradients are different, they converge\nas the dimension of the vector under optimization increases.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:24:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raisbeck", "John C.", "", "Massachusetts General Hospital"], ["Allen", "Matthew", "", "Massachusetts General Hospital"], ["Weissleder", "Ralph", "", "Massachusetts General Hospital"], ["Im", "Hyungsoon", "", "Massachusetts General Hospital"], ["Lee", "Hakho", "", "Massachusetts General Hospital"]]}, {"id": "2001.01685", "submitter": "Yaodong He", "authors": "Yaodong He and Shiu Yin Yuen", "title": "Black Box Algorithm Selection by Convolutional Neural Network", "comments": "9 pages, 4 figures, 5 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a large number of optimization algorithms have been proposed for\nblack box optimization problems, the no free lunch theorems inform us that no\nalgorithm can beat others on all types of problems. Different types of\noptimization problems need different optimization algorithms. To deal with this\nissue, researchers propose algorithm selection to suggest the best optimization\nalgorithm from the algorithm set for a given unknown optimization problem.\nUsually, algorithm selection is treated as a classification or regression task.\nDeep learning, which has been shown to perform well on various classification\nand regression tasks, is applied to the algorithm selection problem in this\npaper. Our deep learning architecture is based on convolutional neural network\nand follows the main architecture of visual geometry group. This architecture\nhas been applied to many different types of 2-D data. Moreover, we also propose\na novel method to extract landscape information from the optimization problems\nand save the information as 2-D images. In the experimental section, we conduct\nthree experiments to investigate the classification and optimization capability\nof our approach on the BBOB functions. The results indicate that our new\napproach can effectively solve the algorithm selection problem.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 12:58:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["He", "Yaodong", ""], ["Yuen", "Shiu Yin", ""]]}, {"id": "2001.01686", "submitter": "Omolbanin Yazdanbakhsh", "authors": "Omolbanin Yazdanbakhsh and Scott Dick", "title": "A Deep Neuro-Fuzzy Network for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of neural network and fuzzy systems into neuro-fuzzy systems\nintegrates fuzzy reasoning rules into the connectionist networks. However, the\nexisting neuro-fuzzy systems are developed under shallow structures having\nlower generalization capacity. We propose the first end-to-end deep neuro-fuzzy\nnetwork and investigate its application for image classification. Two new\noperations are developed based on definitions of Takagi-Sugeno-Kang (TSK) fuzzy\nmodel namely fuzzy inference operation and fuzzy pooling operations; stacks of\nthese operations comprise the layers in this network. We evaluate the network\non MNIST, CIFAR-10 and CIFAR-100 datasets, finding that the network has a\nreasonable accuracy in these benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 03:28:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Yazdanbakhsh", "Omolbanin", ""], ["Dick", "Scott", ""]]}, {"id": "2001.01687", "submitter": "Rafi Qumsieh", "authors": "Rafi Qumsieh", "title": "A Supervised Modified Hebbian Learning Method On Feed-forward Neural\n  Networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a new supervised learning algorithm that is based\non the Hebbian learning algorithm in an attempt to offer a substitute for back\npropagation along with the gradient descent for a more biologically plausible\nmethod. The best performance for the algorithm was achieved when it was run on\na feed-forward neural network with the MNIST handwritten digits data set\nreaching an accuracy of 70.4% on the test data set and 71.48% on the validation\ndata set.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:12:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Qumsieh", "Rafi", ""]]}, {"id": "2001.01697", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Rupak Sarkar, Hirak Sarkar, Sayantan Mahinder, Ashiqur R. KhudaBukhsh", "title": "Social Media Attributions in the Context of Water Crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution of natural disasters/collective misfortune is a widely-studied\npolitical science problem. However, such studies are typically survey-centric\nor rely on a handful of experts to weigh in on the matter. In this paper, we\nexplore how can we use social media data and an AI-driven approach to\ncomplement traditional surveys and automatically extract attribution factors.\nWe focus on the most-recent Chennai water crisis which started off as a\nregional issue but rapidly escalated into a discussion topic with global\nimportance following alarming water-crisis statistics. Specifically, we present\na novel prediction task of attribution tie detection which identifies the\nfactors held responsible for the crisis (e.g., poor city planning, exploding\npopulation etc.). On a challenging data set constructed from YouTube comments\n(72,098 comments posted by 43,859 users on 623 relevant videos to the crisis),\nwe present a neural classifier to extract attribution ties that achieved a\nreasonable performance (Accuracy: 81.34\\% on attribution detection and 71.19\\%\non attribution resolution).\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:20:09 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Sarkar", "Rupak", ""], ["Sarkar", "Hirak", ""], ["Mahinder", "Sayantan", ""], ["KhudaBukhsh", "Ashiqur R.", ""]]}, {"id": "2001.01699", "submitter": "Pavel Bochev B", "authors": "K. Aadithya, P. Kuberry, B. Paskaleva, P. Bochev, K. Leeson, A. Mar,\n  T. Mei, E. Keiter", "title": "Development, Demonstration, and Validation of Data-driven Compact Diode\n  Models for Circuit Simulation and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2019-15303 R", "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact semiconductor device models are essential for efficiently designing\nand analyzing large circuits. However, traditional compact model development\nrequires a large amount of manual effort and can span many years. Moreover,\ninclusion of new physics (eg, radiation effects) into an existing compact model\nis not trivial and may require redevelopment from scratch. Machine Learning\n(ML) techniques have the potential to automate and significantly speed up the\ndevelopment of compact models. In addition, ML provides a range of modeling\noptions that can be used to develop hierarchies of compact models tailored to\nspecific circuit design stages. In this paper, we explore three such options:\n(1) table-based interpolation, (2)Generalized Moving Least-Squares, and (3)\nfeed-forward Deep Neural Networks, to develop compact models for a p-n junction\ndiode. We evaluate the performance of these \"data-driven\" compact models by (1)\ncomparing their voltage-current characteristics against laboratory data, and\n(2) building a bridge rectifier circuit using these devices, predicting the\ncircuit's behavior using SPICE-like circuit simulations, and then comparing\nthese predictions against laboratory measurements of the same circuit.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:25:32 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Aadithya", "K.", ""], ["Kuberry", "P.", ""], ["Paskaleva", "B.", ""], ["Bochev", "P.", ""], ["Leeson", "K.", ""], ["Mar", "A.", ""], ["Mei", "T.", ""], ["Keiter", "E.", ""]]}, {"id": "2001.01707", "submitter": "Haleh Falakshahi", "authors": "Haleh Falakshahi, Victor M. Vergara, Jingyu Liu, Daniel H. Mathalon,\n  Judith M. Ford, James Voyvodic, Bryon A. Mueller, Aysenil Belger, Sarah\n  McEwen, Steven G. Potkin, Adrian Preda, Hooman Rokham, Jing Sui, Jessica A.\n  Turner, Sergey Plis, and Vince D. Calhoun", "title": "Meta-modal Information Flow: A Method for Capturing Multimodal Modular\n  Disconnectivity in Schizophrenia", "comments": null, "journal-ref": "IEEE Transactions on Biomedical Engineering, 2019", "doi": "10.1109/TBME.2020.2964724", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Multimodal measurements of the same phenomena provide\ncomplementary information and highlight different perspectives, albeit each\nwith their own limitations. A focus on a single modality may lead to incorrect\ninferences, which is especially important when a studied phenomenon is a\ndisease. In this paper, we introduce a method that takes advantage of\nmultimodal data in addressing the hypotheses of disconnectivity and dysfunction\nwithin schizophrenia (SZ). Methods: We start with estimating and visualizing\nlinks within and among extracted multimodal data features using a Gaussian\ngraphical model (GGM). We then propose a modularity-based method that can be\napplied to the GGM to identify links that are associated with mental illness\nacross a multimodal data set. Through simulation and real data, we show our\napproach reveals important information about disease-related network\ndisruptions that are missed with a focus on a single modality. We use\nfunctional MRI (fMRI), diffusion MRI (dMRI), and structural MRI (sMRI) to\ncompute the fractional amplitude of low frequency fluctuations (fALFF),\nfractional anisotropy (FA), and gray matter (GM) concentration maps. These\nthree modalities are analyzed using our modularity method. Results: Our results\nshow missing links that are only captured by the cross-modal information that\nmay play an important role in disconnectivity between the components.\nConclusion: We identified multimodal (fALFF, FA and GM) disconnectivity in the\ndefault mode network area in patients with SZ, which would not have been\ndetectable in a single modality. Significance: The proposed approach provides\nan important new tool for capturing information that is distributed among\nmultiple imaging modalities.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:46:41 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Falakshahi", "Haleh", ""], ["Vergara", "Victor M.", ""], ["Liu", "Jingyu", ""], ["Mathalon", "Daniel H.", ""], ["Ford", "Judith M.", ""], ["Voyvodic", "James", ""], ["Mueller", "Bryon A.", ""], ["Belger", "Aysenil", ""], ["McEwen", "Sarah", ""], ["Potkin", "Steven G.", ""], ["Preda", "Adrian", ""], ["Rokham", "Hooman", ""], ["Sui", "Jing", ""], ["Turner", "Jessica A.", ""], ["Plis", "Sergey", ""], ["Calhoun", "Vince D.", ""]]}, {"id": "2001.01717", "submitter": "Faisal Ghaffar", "authors": "Faisal Ghaffar, Sarwar Khan, Gaddisa O., Chen Yu-jhen", "title": "Macromolecule Classification Based on the Amino-acid Sequence", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.03532", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is playing a vital role in every field which involves data. It\nhas emerged as a strong and efficient framework that can be applied to a broad\nspectrum of complex learning problems which were difficult to solve using\ntraditional machine learning techniques in the past. In this study we focused\non classification of protein sequences with deep learning techniques. The study\nof amino acid sequence is vital in life sciences. We used different word\nembedding techniques from Natural Language processing to represent the amino\nacid sequence as vectors. Our main goal was to classify sequences to four group\nof classes, that are DNA, RNA, Protein and hybrid. After several tests we have\nachieved almost 99% of train and test accuracy. We have experimented on CNN,\nLSTM, Bidirectional LSTM, and GRU.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 08:33:50 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ghaffar", "Faisal", ""], ["Khan", "Sarwar", ""], ["O.", "Gaddisa", ""], ["Yu-jhen", "Chen", ""]]}, {"id": "2001.01720", "submitter": "Stefan Lattner", "authors": "Stefan Lattner", "title": "Modeling Musical Structure with Artificial Neural Networks", "comments": "152 pages, 28 figures, 10 tables. PhD thesis, Johannes Kepler\n  University Linz, October 2019. Includes results from\n  https://www.ijcai.org/Proceedings/15/Papers/348.pdf, arXiv:1612.04742,\n  arXiv:1708.05325, arXiv:1806.08236, and arXiv:1806.08686 (see Section 1.2 for\n  detailed information)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, artificial neural networks (ANNs) have become a universal\ntool for tackling real-world problems. ANNs have also shown great success in\nmusic-related tasks including music summarization and classification,\nsimilarity estimation, computer-aided or autonomous composition, and automatic\nmusic analysis. As structure is a fundamental characteristic of Western music,\nit plays a role in all these tasks. Some structural aspects are particularly\nchallenging to learn with current ANN architectures. This is especially true\nfor mid- and high-level self-similarity, tonal and rhythmic relationships. In\nthis thesis, I explore the application of ANNs to different aspects of musical\nstructure modeling, identify some challenges involved and propose strategies to\naddress them. First, using probability estimations of a Restricted Boltzmann\nMachine (RBM), a probabilistic bottom-up approach to melody segmentation is\nstudied. Then, a top-down method for imposing a high-level structural template\nin music generation is presented, which combines Gibbs sampling using a\nconvolutional RBM with gradient-descent optimization on the intermediate\nsolutions. Furthermore, I motivate the relevance of musical transformations in\nstructure modeling and show how a connectionist model, the Gated Autoencoder\n(GAE), can be employed to learn transformations between musical fragments. For\nlearning transformations in sequences, I propose a special predictive training\nof the GAE, which yields a representation of polyphonic music as a sequence of\nintervals. Furthermore, the applicability of these interval representations to\na top-down discovery of repeated musical sections is shown. Finally, a\nrecurrent variant of the GAE is proposed, and its efficacy in music prediction\nand modeling of low-level repetition structure is demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:35:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Lattner", "Stefan", ""]]}, {"id": "2001.01755", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra and Horacio Franco", "title": "Investigation and Analysis of Hyper and Hypo neuron pruning to\n  selectively update neurons during Unsupervised Adaptation", "comments": "DSP, 29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen or out-of-domain data can seriously degrade the performance of a\nneural network model, indicating the model's failure to generalize to unseen\ndata. Neural net pruning can not only help to reduce a model's size but can\nimprove the model's generalization capacity as well. Pruning approaches look\nfor low-salient neurons that are less contributive to a model's decision and\nhence can be removed from the model. This work investigates if pruning\napproaches are successful in detecting neurons that are either high-salient\n(mostly active or hyper) or low-salient (barely active or hypo), and whether\nremoval of such neurons can help to improve the model's generalization\ncapacity. Traditional blind adaptation techniques update either the whole or a\nsubset of layers, but have never explored selectively updating individual\nneurons across one or more layers. Focusing on the fully connected layers of a\nconvolutional neural network (CNN), this work shows that it may be possible to\nselectively adapt certain neurons (consisting of the hyper and the hypo\nneurons) first, followed by a full-network fine tuning. Using the task of\nautomatic speech recognition, this work demonstrates how the removal of hyper\nand hypo neurons from a model can improve the model's performance on\nout-of-domain speech data and how selective neuron adaptation can ensure\nimproved performance when compared to traditional blind model adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 19:46:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Franco", "Horacio", ""]]}, {"id": "2001.01765", "submitter": "Rendani Mbuvha", "authors": "Rendani Mbuvha, Illyes Boulkaibet and Tshilidzi Marwala", "title": "An Automatic Relevance Determination Prior Bayesian Neural Network for\n  Controlled Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an Automatic Relevance Determination prior Bayesian Neural\nNetwork(BNN-ARD) weight l2-norm measure as a feature importance statistic for\nthe model-x knockoff filter. We show on both simulated data and the Norwegian\nwind farm dataset that the proposed feature importance statistic yields\nstatistically significant improvements relative to similar feature importance\nmeasures in both variable selection power and predictive performance on a real\nworld dataset.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:12:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mbuvha", "Rendani", ""], ["Boulkaibet", "Illyes", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "2001.01786", "submitter": "Richard Wang", "authors": "Usman Sajid and Guanghui Wang", "title": "Plug-and-Play Rescaling Based Crowd Counting in Static Images", "comments": "10 pages, 6 figures, WACV conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd counting is a challenging problem especially in the presence of huge\ncrowd diversity across images and complex cluttered crowd-like background\nregions, where most previous approaches do not generalize well and consequently\nproduce either huge crowd underestimation or overestimation. To address these\nchallenges, we propose a new image patch rescaling module (PRM) and three\nindependent PRM employed crowd counting methods. The proposed frameworks use\nthe PRM module to rescale the image regions (patches) that require special\ntreatment, whereas the classification process helps in recognizing and\ndiscarding any cluttered crowd-like background regions which may result in\noverestimation. Experiments on three standard benchmarks and cross-dataset\nevaluation show that our approach outperforms the state-of-the-art models in\nthe RMSE evaluation metric with an improvement up to 10.4%, and possesses\nsuperior generalization ability to new datasets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 21:43:25 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Sajid", "Usman", ""], ["Wang", "Guanghui", ""]]}, {"id": "2001.01793", "submitter": "Ian Char", "authors": "Youngseog Chung, Ian Char, Willie Neiswanger, Kirthevasan Kandasamy,\n  Andrew Oakleigh Nelson, Mark D Boyer, Egemen Kolemen, Jeff Schneider", "title": "Offline Contextual Bayesian Optimization for Nuclear Fusion", "comments": "6 pages, 2 figures, Machine Learning and Physical Sciences workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear fusion is regarded as the energy of the future since it presents the\npossibility of unlimited clean energy. One obstacle in utilizing fusion as a\nfeasible energy source is the stability of the reaction. Ideally, one would\nhave a controller for the reactor that makes actions in response to the current\nstate of the plasma in order to prolong the reaction as long as possible. In\nthis work, we make preliminary steps to learning such a controller. Since\nlearning on a real world reactor is infeasible, we tackle this problem by\nattempting to learn optimal controls offline via a simulator, where the state\nof the plasma can be explicitly set. In particular, we introduce a\ntheoretically grounded Bayesian optimization algorithm that recommends a state\nand action pair to evaluate at every iteration and show that this results in\nmore efficient use of the simulator.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:12:18 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Chung", "Youngseog", ""], ["Char", "Ian", ""], ["Neiswanger", "Willie", ""], ["Kandasamy", "Kirthevasan", ""], ["Nelson", "Andrew Oakleigh", ""], ["Boyer", "Mark D", ""], ["Kolemen", "Egemen", ""], ["Schneider", "Jeff", ""]]}, {"id": "2001.01795", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yashesh Gaur, Jinyu Li, Yifan Gong", "title": "Character-Aware Attention-Based End-to-End Speech Recognition", "comments": "7 pages, 3 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting words and subword units (WSUs) as the output has shown to be\neffective for the attention-based encoder-decoder (AED) model in end-to-end\nspeech recognition. However, as one input to the decoder recurrent neural\nnetwork (RNN), each WSU embedding is learned independently through context and\nacoustic information in a purely data-driven fashion. Little effort has been\nmade to explicitly model the morphological relationships among WSUs. In this\nwork, we propose a novel character-aware (CA) AED model in which each WSU\nembedding is computed by summarizing the embeddings of its constituent\ncharacters using a CA-RNN. This WSU-independent CA-RNN is jointly trained with\nthe encoder, the decoder and the attention network of a conventional AED to\npredict WSUs. With CA-AED, the embeddings of morphologically similar WSUs are\nnaturally and directly correlated through the CA-RNN in addition to the\nsemantic and acoustic relations modeled by a traditional AED. Moreover, CA-AED\nsignificantly reduces the model parameters in a traditional AED by replacing\nthe large pool of WSU embeddings with a much smaller set of character\nembeddings. On a 3400 hours Microsoft Cortana dataset, CA-AED achieves up to\n11.9% relative WER improvement over a strong AED baseline with 27.1% fewer\nmodel parameters.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:19:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Gaur", "Yashesh", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01796", "submitter": "Hadis Anahideh", "authors": "Hadis Anahideh and Abolfazl Asudeh and Saravanan Thirumuruganathan", "title": "Fair Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is increasingly being used in high-stakes applications\nimpacting society. Therefore, it is of critical importance that ML models do\nnot propagate discrimination. Collecting accurate labeled data in societal\napplications is challenging and costly. Active learning is a promising approach\nto build an accurate classifier by interactively querying an oracle within a\nlabeling budget. We design algorithms for fair active learning that carefully\nselects data points to be labeled so as to balance model accuracy and fairness.\nWe demonstrate the effectiveness and efficiency of our proposed algorithms over\nwidely used benchmark datasets using demographic parity and equalized odds\nnotions of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:20:02 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 04:03:05 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 23:53:05 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 12:06:48 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 14:39:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Anahideh", "Hadis", ""], ["Asudeh", "Abolfazl", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "2001.01798", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yashesh Gaur, Yifan Gong", "title": "Domain Adaptation via Teacher-Student Learning for End-to-End Speech\n  Recognition", "comments": "8 pages, 2 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teacher-student (T/S) has shown to be effective for domain adaptation of deep\nneural network acoustic models in hybrid speech recognition systems. In this\nwork, we extend the T/S learning to large-scale unsupervised domain adaptation\nof an attention-based end-to-end (E2E) model through two levels of knowledge\ntransfer: teacher's token posteriors as soft labels and one-best predictions as\ndecoder guidance. To further improve T/S learning with the help of ground-truth\nlabels, we propose adaptive T/S (AT/S) learning. Instead of conditionally\nchoosing from either the teacher's soft token posteriors or the one-hot\nground-truth label, in AT/S, the student always learns from both the teacher\nand the ground truth with a pair of adaptive weights assigned to the soft and\none-hot labels quantifying the confidence on each of the knowledge sources. The\nconfidence scores are dynamically estimated at each decoder step as a function\nof the soft and one-hot labels. With 3400 hours parallel close-talk and\nfar-field Microsoft Cortana data for domain adaptation, T/S and AT/S achieve\n6.3% and 10.3% relative word error rate improvement over a strong E2E model\ntrained with the same amount of far-field data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:30:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Gaur", "Yashesh", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01799", "submitter": "Charles Thornton", "authors": "Charles E. Thornton, R. Michael Buehrer, Anthony F. Martone, Kelly D.\n  Sherbondy", "title": "Experimental Analysis of Reinforcement Learning Techniques for Spectrum\n  Sharing Radar", "comments": "Accepted for publication at IEEE Intl. Radar Conference, Washington\n  DC, Apr. 2020. This is the author's version of the work", "journal-ref": null, "doi": "10.1109/RADAR42522.2020.9114698", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first describe a framework for the application of\nReinforcement Learning (RL) control to a radar system that operates in a\ncongested spectral setting. We then compare the utility of several RL\nalgorithms through a discussion of experiments performed on Commercial\noff-the-shelf (COTS) hardware. Each RL technique is evaluated in terms of\nconvergence, radar detection performance achieved in a congested spectral\nenvironment, and the ability to share 100MHz spectrum with an uncooperative\ncommunications system. We examine policy iteration, which solves an environment\nposed as a Markov Decision Process (MDP) by directly solving for a stochastic\nmapping between environmental states and radar waveforms, as well as Deep RL\ntechniques, which utilize a form of Q-Learning to approximate a parameterized\nfunction that is used by the radar to select optimal actions. We show that RL\ntechniques are beneficial over a Sense-and-Avoid (SAA) scheme and discuss the\nconditions under which each approach is most effective.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:32:32 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 23:24:44 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Thornton", "Charles E.", ""], ["Buehrer", "R. Michael", ""], ["Martone", "Anthony F.", ""], ["Sherbondy", "Kelly D.", ""]]}, {"id": "2001.01809", "submitter": "Javier Trejos", "authors": "Javier Trejos-Zelaya, Luis Eduardo Amaya-Brice\\~no, Alejandra\n  Jim\\'enez-Romero, Alex Murillo-Fern\\'andez, Eduardo Piza-Volio, Mario\n  Villalobos-Arias", "title": "Clustering Binary Data by Application of Combinatorial Optimization\n  Heuristics", "comments": "9 pages. Submitted to Springer Series \"Studies in Classification,\n  Data Analysis, and Knowledge Organization\". Presented in Conference of the\n  International Federation of Classification Societies (IFCS), Thessaloniki,\n  August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study clustering methods for binary data, first defining aggregation\ncriteria that measure the compactness of clusters. Five new and original\nmethods are introduced, using neighborhoods and population behavior\ncombinatorial optimization metaheuristics: first ones are simulated annealing,\nthreshold accepting and tabu search, and the others are a genetic algorithm and\nant colony optimization. The methods are implemented, performing the proper\ncalibration of parameters in the case of heuristics, to ensure good results.\nFrom a set of 16 data tables generated by a quasi-Monte Carlo experiment, a\ncomparison is performed for one of the aggregations using L1 dissimilarity,\nwith hierarchical clustering, and a version of k-means: partitioning around\nmedoids or PAM. Simulated annealing perform very well, especially compared to\nclassical methods.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:33:31 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Trejos-Zelaya", "Javier", ""], ["Amaya-Brice\u00f1o", "Luis Eduardo", ""], ["Jim\u00e9nez-Romero", "Alejandra", ""], ["Murillo-Fern\u00e1ndez", "Alex", ""], ["Piza-Volio", "Eduardo", ""], ["Villalobos-Arias", "Mario", ""]]}, {"id": "2001.01819", "submitter": "Austin Wright", "authors": "Austin P. Wright, Omar Shaikh, Haekyu Park, Will Epperson, Muhammed\n  Ahmed, Stephane Pinel, Diyi Yang, Duen Horng Chau", "title": "RECAST: Interactive Auditing of Automatic Toxicity Detection Models", "comments": "8 Pages, 3 figures, The eighth International Workshop of Chinese CHI\n  Proceedings", "journal-ref": null, "doi": "10.1145/3403676.3403691", "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As toxic language becomes nearly pervasive online, there has been increasing\ninterest in leveraging the advancements in natural language processing (NLP),\nfrom very large transformer models to automatically detecting and removing\ntoxic comments. Despite the fairness concerns, lack of adversarial robustness,\nand limited prediction explainability for deep learning systems, there is\ncurrently little work for auditing these systems and understanding how they\nwork for both developers and users. We present our ongoing work, RECAST, an\ninteractive tool for examining toxicity detection models by visualizing\nexplanations for predictions and providing alternative wordings for detected\ntoxic speech.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:17:52 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 15:36:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wright", "Austin P.", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Epperson", "Will", ""], ["Ahmed", "Muhammed", ""], ["Pinel", "Stephane", ""], ["Yang", "Diyi", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.01828", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Diego Klabjan", "title": "Listwise Learning to Rank by Exploring Unique Ratings", "comments": null, "journal-ref": "WSDM 2020", "doi": "10.1145/3336191.3371814", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose new listwise learning-to-rank models that mitigate\nthe shortcomings of existing ones. Existing listwise learning-to-rank models\nare generally derived from the classical Plackett-Luce model, which has three\nmajor limitations. (1) Its permutation probabilities overlook ties, i.e., a\nsituation when more than one document has the same rating with respect to a\nquery. This can lead to imprecise permutation probabilities and inefficient\ntraining because of selecting documents one by one. (2) It does not favor\ndocuments having high relevance. (3) It has a loose assumption that sampling\ndocuments at different steps is independent. To overcome the first two\nlimitations, we model ranking as selecting documents from a candidate set based\non unique rating levels in decreasing order. The number of steps in training is\ndetermined by the number of unique rating levels. We propose a new loss\nfunction and associated four models for the entire sequence of weighted\nclassification tasks by assigning high weights to the selected documents with\nhigh ratings for optimizing Normalized Discounted Cumulative Gain (NDCG). To\novercome the final limitation, we further propose a novel and efficient way of\nrefining prediction scores by combining an adapted Vanilla Recurrent Neural\nNetwork (RNN) model with pooling given selected documents at previous steps. We\nencode all of the documents already selected by an RNN model. In a single step,\nwe rank all of the documents with the same ratings using the last cell of the\nRNN multiple times. We have implemented our models using three settings: neural\nnetworks, neural networks with gradient boosting, and regression trees with\ngradient boosting. We have conducted experiments on four public datasets. The\nexperiments demonstrate that the models notably outperform state-of-the-art\nlearning-to-rank models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:50:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 03:51:49 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 01:55:15 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Klabjan", "Diego", ""]]}, {"id": "2001.01829", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Feng Liu, Goce Trajcevski, Dingding Wang", "title": "Frosting Weights for Better Continual Training", "comments": null, "journal-ref": "ICMLA 2019", "doi": "10.1109/ICMLA.2019.00094", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network model can be a lifelong learning process and is a\ncomputationally intensive one. A severe adverse effect that may occur in deep\nneural network models is that they can suffer from catastrophic forgetting\nduring retraining on new data. To avoid such disruptions in the continuous\nlearning, one appealing property is the additive nature of ensemble models. In\nthis paper, we propose two generic ensemble approaches, gradient boosting and\nmeta-learning, to solve the catastrophic forgetting problem in tuning\npre-trained neural network models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:53:46 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Liu", "Feng", ""], ["Trajcevski", "Goce", ""], ["Wang", "Dingding", ""]]}, {"id": "2001.01861", "submitter": "Subru Krishnan", "authors": "Mohammad Hossein Namaki, Avrilia Floratou, Fotis Psallidas, Subru\n  Krishnan, Ashvin Agrawal, Yinghui Wu, Yiwen Zhu and Markus Weimer", "title": "Vamsa: Automated Provenance Tracking in Data Science Scripts", "comments": null, "journal-ref": null, "doi": "10.1145/3394486.3403205", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has recently been a lot of ongoing research in the areas of fairness,\nbias and explainability of machine learning (ML) models due to the self-evident\nor regulatory requirements of various ML applications. We make the following\nobservation: All of these approaches require a robust understanding of the\nrelationship between ML models and the data used to train them. In this work,\nwe introduce the ML provenance tracking problem: the fundamental idea is to\nautomatically track which columns in a dataset have been used to derive the\nfeatures/labels of an ML model. We discuss the challenges in capturing such\ninformation in the context of Python, the most common language used by data\nscientists. We then present Vamsa, a modular system that extracts provenance\nfrom Python scripts without requiring any changes to the users' code. Using 26K\nreal data science scripts, we verify the effectiveness of Vamsa in terms of\ncoverage, and performance. We also evaluate Vamsa's accuracy on a smaller\nsubset of manually labeled data. Our analysis shows that Vamsa's precision and\nrecall range from 90.4% to 99.1% and its latency is in the order of\nmilliseconds for average size scripts. Drawing from our experience in deploying\nML models in production, we also present an example in which Vamsa helps\nautomatically identify models that are affected by data corruption issues.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:39:02 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 16:58:22 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Namaki", "Mohammad Hossein", ""], ["Floratou", "Avrilia", ""], ["Psallidas", "Fotis", ""], ["Krishnan", "Subru", ""], ["Agrawal", "Ashvin", ""], ["Wu", "Yinghui", ""], ["Zhu", "Yiwen", ""], ["Weimer", "Markus", ""]]}, {"id": "2001.01866", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Bo Dai", "title": "Reinforcement Learning via Fenchel-Rockafellar Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review basic concepts of convex duality, focusing on the very general and\nsupremely useful Fenchel-Rockafellar duality. We summarize how this duality may\nbe applied to a variety of reinforcement learning (RL) settings, including\npolicy evaluation or optimization, online or offline learning, and discounted\nor undiscounted rewards. The derivations yield a number of intriguing results,\nincluding the ability to perform policy evaluation and on-policy policy\ngradient with behavior-agnostic offline data and methods to learn a policy via\nmax-likelihood optimization. Although many of these results have appeared\npreviously in various forms, we provide a unified treatment and perspective on\nthese results, which we hope will enable researchers to better use and apply\nthe tools of convex duality to make further progress in RL.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:59:59 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:08:09 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Nachum", "Ofir", ""], ["Dai", "Bo", ""]]}, {"id": "2001.01870", "submitter": "Haodi Hou", "authors": "Haodi Hou, Jing Huo, Jing Wu, Yu-Kun Lai, and Yang Gao", "title": "MW-GAN: Multi-Warping GAN for Caricature Generation with Multi-Style\n  Geometric Exaggeration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an input face photo, the goal of caricature generation is to produce\nstylized, exaggerated caricatures that share the same identity as the photo. It\nrequires simultaneous style transfer and shape exaggeration with rich\ndiversity, and meanwhile preserving the identity of the input. To address this\nchallenging problem, we propose a novel framework called Multi-Warping GAN\n(MW-GAN), including a style network and a geometric network that are designed\nto conduct style transfer and geometric exaggeration respectively. We bridge\nthe gap between the style and landmarks of an image with corresponding latent\ncode spaces by a dual way design, so as to generate caricatures with arbitrary\nstyles and geometric exaggeration, which can be specified either through random\nsampling of latent code or from a given caricature sample. Besides, we apply\nidentity preserving loss to both image space and landmark space, leading to a\ngreat improvement in quality of generated caricatures. Experiments show that\ncaricatures generated by MW-GAN have better quality than existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:08:30 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Hou", "Haodi", ""], ["Huo", "Jing", ""], ["Wu", "Jing", ""], ["Lai", "Yu-Kun", ""], ["Gao", "Yang", ""]]}, {"id": "2001.01871", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, Jamin Shin, Pascale\n  Fung", "title": "Attention over Parameters for Dialogue Systems", "comments": "NeurIPS Conversational AI Workshops (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems require a great deal of different but complementary\nexpertise to assist, inform, and entertain humans. For example, different\ndomains (e.g., restaurant reservation, train ticket booking) of goal-oriented\ndialogue systems can be viewed as different skills, and so does ordinary\nchatting abilities of chit-chat dialogue systems. In this paper, we propose to\nlearn a dialogue system that independently parameterizes different dialogue\nskills, and learns to select and combine each of them through Attention over\nParameters (AoP). The experimental results show that this approach achieves\ncompetitive performance on a combined dataset of MultiWOZ, In-Car Assistant,\nand Persona-Chat. Finally, we demonstrate that each dialogue skill is\neffectively learned and can be combined with other skills to produce selective\nresponses.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:10:42 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:02:14 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Wu", "Chien-Sheng", ""], ["Shin", "Jamin", ""], ["Fung", "Pascale", ""]]}, {"id": "2001.01878", "submitter": "Tailin Wu", "authors": "Tailin Wu and Ian Fischer", "title": "Phase Transitions for the Information Bottleneck in Representation\n  Learning", "comments": "ICLR 2020; 27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Information Bottleneck (IB), when tuning the relative strength between\ncompression and prediction terms, how do the two terms behave, and what's their\nrelationship with the dataset and the learned representation? In this paper, we\nset out to answer these questions by studying multiple phase transitions in the\nIB objective: $\\text{IB}_\\beta[p(z|x)] = I(X; Z) - \\beta I(Y; Z)$ defined on\nthe encoding distribution p(z|x) for input $X$, target $Y$ and representation\n$Z$, where sudden jumps of $dI(Y; Z)/d \\beta$ and prediction accuracy are\nobserved with increasing $\\beta$. We introduce a definition for IB phase\ntransitions as a qualitative change of the IB loss landscape, and show that the\ntransitions correspond to the onset of learning new classes. Using second-order\ncalculus of variations, we derive a formula that provides a practical condition\nfor IB phase transitions, and draw its connection with the Fisher information\nmatrix for parameterized models. We provide two perspectives to understand the\nformula, revealing that each IB phase transition is finding a component of\nmaximum (nonlinear) correlation between $X$ and $Y$ orthogonal to the learned\nrepresentation, in close analogy with canonical-correlation analysis (CCA) in\nlinear settings. Based on the theory, we present an algorithm for discovering\nphase transition points. Finally, we verify that our theory and algorithm\naccurately predict phase transitions in categorical datasets, predict the onset\nof learning new classes and class difficulty in MNIST, and predict prominent\nphase transitions in CIFAR10.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 03:55:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Tailin", ""], ["Fischer", "Ian", ""]]}, {"id": "2001.01885", "submitter": "Tailin Wu", "authors": "Tailin Wu, Thomas Breuel, Michael Skuhersky and Jan Kautz", "title": "Discovering Nonlinear Relations with Minimum Predictive Information\n  Regularization", "comments": "26 pages, 11 figures; ICML'19 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the underlying directional relations from observational time\nseries with nonlinear interactions and complex relational structures is key to\na wide range of applications, yet remains a hard problem. In this work, we\nintroduce a novel minimum predictive information regularization method to infer\ndirectional relations from time series, allowing deep learning models to\ndiscover nonlinear relations. Our method substantially outperforms other\nmethods for learning nonlinear relations in synthetic datasets, and discovers\nthe directional relations in a video game environment and a heart-rate vs.\nbreath-rate dataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 04:28:00 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wu", "Tailin", ""], ["Breuel", "Thomas", ""], ["Skuhersky", "Michael", ""], ["Kautz", "Jan", ""]]}, {"id": "2001.01891", "submitter": "Bishwamittra Ghosh", "authors": "Bishwamittra Ghosh and Kuldeep S. Meel", "title": "IMLI: An Incremental Framework for MaxSAT-Based Learning of\n  Interpretable Classification Rules", "comments": "10 pages, published in the proceedings of AAAI/ACM Conference on AI,\n  Ethics, and Society (AIES 2019)", "journal-ref": "AIES-19: AAAI/ACM conference on Artificial Intelligence, Ethics,\n  and SocietyAt: Honolulu, HI, United States, January 27-28, 2019", "doi": "10.1145/3306618.3314283", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of machine learning in the critical domains such as medical\ndiagnosis, law, education had propelled the need for interpretable techniques\ndue to the need for end users to understand the reasoning behind decisions due\nto learning systems. The computational intractability of interpretable learning\nled practitioners to design heuristic techniques, which fail to provide sound\nhandles to tradeoff accuracy and interpretability.\n  Motivated by the success of MaxSAT solvers over the past decade, recently\nMaxSAT-based approach, called MLIC, was proposed that seeks to reduce the\nproblem of learning interpretable rules expressed in Conjunctive Normal Form\n(CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to\nthat of other state of the art black-box classifiers while generating small\ninterpretable CNF formulas, the runtime performance of MLIC is significantly\nlagging and renders approach unusable in practice. In this context, authors\nraised the question: Is it possible to achieve the best of both worlds, i.e., a\nsound framework for interpretable learning that can take advantage of MaxSAT\nsolvers while scaling to real-world instances?\n  In this paper, we take a step towards answering the above question in\naffirmation. We propose IMLI: an incremental approach to MaxSAT based framework\nthat achieves scalable runtime performance via partition-based training\nmethodology. Extensive experiments on benchmarks arising from UCI repository\ndemonstrate that IMLI achieves up to three orders of magnitude runtime\nimprovement without loss of accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:03:53 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ghosh", "Bishwamittra", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2001.01893", "submitter": "Toshimitsu Aritake", "authors": "Toshimitsu Aritake, Hideitsu Hino, Shigeyuki Namiki, Daisuke Asanuma,\n  Kenzo Hirose, Noboru Murata", "title": "Fast and robust multiplane single molecule localization microscopy using\n  deep neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single molecule localization microscopy is widely used in biological research\nfor measuring the nanostructures of samples smaller than the diffraction limit.\nThis study uses multifocal plane microscopy and addresses the 3D single\nmolecule localization problem, where lateral and axial locations of molecules\nare estimated. However, when we multifocal plane microscopy is used, the\nestimation accuracy of 3D localization is easily deteriorated by the small\nlateral drifts of camera positions. We formulate a 3D molecule localization\nproblem along with the estimation of the lateral drifts as a compressed sensing\nproblem, A deep neural network was applied to accurately and efficiently solve\nthis problem. The proposed method is robust to the lateral drifts and achieves\nan accuracy of 20 nm laterally and 50 nm axially without an explicit drift\ncorrection.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:12:14 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Aritake", "Toshimitsu", ""], ["Hino", "Hideitsu", ""], ["Namiki", "Shigeyuki", ""], ["Asanuma", "Daisuke", ""], ["Hirose", "Kenzo", ""], ["Murata", "Noboru", ""]]}, {"id": "2001.01894", "submitter": "Pengzhou Wu", "authors": "Pengzhou Wu and Kenji Fukumizu", "title": "Causal Mosaic: Cause-Effect Inference via Nonlinear ICA and Ensemble\n  Method", "comments": "Accepted to AISTATS 2020. Camera-ready version in preparation", "journal-ref": "An updated version at AISTATS 2020:\n  http://proceedings.mlr.press/v108/wu20b/wu20b.pdf. Main changes: a correction\n  in Theorem 3 and additional explanations in Sec. 4", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of distinguishing cause from effect in bivariate\nsetting. Based on recent developments in nonlinear independent component\nanalysis (ICA), we train nonparametrically general nonlinear causal models that\nallow non-additive noise. Further, we build an ensemble framework, namely\nCausal Mosaic, which models a causal pair by a mixture of nonlinear models. We\ncompare this method with other recent methods on artificial and real world\nbenchmark datasets, and our method shows state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:16:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Wu", "Pengzhou", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2001.01898", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yi Zhou, Yingbin Liang", "title": "Reanalysis of Variance Reduced Temporal Difference Learning", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference (TD) learning is a popular algorithm for policy\nevaluation in reinforcement learning, but the vanilla TD can substantially\nsuffer from the inherent optimization variance. A variance reduced TD (VRTD)\nalgorithm was proposed by Korda and La (2015), which applies the variance\nreduction technique directly to the online TD learning with Markovian samples.\nIn this work, we first point out the technical errors in the analysis of VRTD\nin Korda and La (2015), and then provide a mathematically solid analysis of the\nnon-asymptotic convergence of VRTD and its variance reduction performance. We\nshow that VRTD is guaranteed to converge to a neighborhood of the fixed-point\nsolution of TD at a linear convergence rate. Furthermore, the variance error\n(for both i.i.d.\\ and Markovian sampling) and the bias error (for Markovian\nsampling) of VRTD are significantly reduced by the batch size of variance\nreduction in comparison to those of vanilla TD. As a result, the overall\ncomputational complexity of VRTD to attain a given accurate solution\noutperforms that of TD under Markov sampling and outperforms that of TD under\ni.i.d.\\ sampling for a sufficiently small conditional number.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:32:43 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 07:22:15 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Zhou", "Yi", ""], ["Liang", "Yingbin", ""]]}, {"id": "2001.01900", "submitter": "Weizhi Li", "authors": "Weizhi Li, Gautam Dasarathy and Visar Berisha", "title": "Regularization via Structural Label Smoothing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is an effective way to promote the generalization performance\nof machine learning models. In this paper, we focus on label smoothing, a form\nof output distribution regularization that prevents overfitting of a neural\nnetwork by softening the ground-truth labels in the training data in an attempt\nto penalize overconfident outputs. Existing approaches typically use\ncross-validation to impose this smoothing, which is uniform across all training\ndata. In this paper, we show that such label smoothing imposes a quantifiable\nbias in the Bayes error rate of the training data, with regions of the feature\nspace with high overlap and low marginal likelihood having a lower bias and\nregions of low overlap and high marginal likelihood having a higher bias. These\ntheoretical results motivate a simple objective function for data-dependent\nsmoothing to mitigate the potential negative consequences of the operation\nwhile maintaining its desirable properties as a regularizer. We call this\napproach Structural Label Smoothing (SLS). We implement SLS and empirically\nvalidate on synthetic, Higgs, SVHN, CIFAR-10, and CIFAR-100 datasets. The\nresults confirm our theoretical insights and demonstrate the effectiveness of\nthe proposed method in comparison to traditional label smoothing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 05:45:18 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 23:22:56 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Weizhi", ""], ["Dasarathy", "Gautam", ""], ["Berisha", "Visar", ""]]}, {"id": "2001.01911", "submitter": "Bekir Sait Ciftler", "authors": "Bekir Sait Ciftler, Abdullatif Albaseer, Noureddine Lasla, Mohamed\n  Abdallah", "title": "Federated Learning for Localization: A Privacy-Preserving Crowdsourcing\n  Method", "comments": "6 pages, An improved version of this manuscript in review for IEEE\n  ICC ANLN Workshops 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Received Signal Strength (RSS) fingerprint-based localization has attracted a\nlot of research effort and cultivated many commercial applications of\nlocation-based services due to its low cost and ease of implementation. Many\nstudies are exploring the use of deep learning (DL) algorithms for\nlocalization. DL's ability to extract features and to classify autonomously\nmakes it an attractive solution for fingerprint-based localization. These\nsolutions require frequent retraining of DL models with vast amounts of\nmeasurements. Although crowdsourcing is an excellent way to gather immense\namounts of data, it jeopardizes the privacy of participants, as it requires to\ncollect labeled data at a centralized server. Recently, federated learning has\nemerged as a practical concept in solving the privacy preservation issue of\ncrowdsourcing participants by performing model training at the edge devices in\na decentralized manner; the participants do not expose their data anymore to a\ncentralized server. This paper presents a novel method utilizing federated\nlearning to improve the accuracy of RSS fingerprint-based localization while\npreserving the privacy of the crowdsourcing participants. Employing federated\nlearning allows ensuring \\emph{preserving the privacy of user data} while\nenabling an adequate localization performance with experimental data captured\nin real-world settings. The proposed method improved localization accuracy by\n1.8 meters when used as a booster for centralized learning and achieved\nsatisfactory localization accuracy when used standalone.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:02:32 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 10:17:12 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ciftler", "Bekir Sait", ""], ["Albaseer", "Abdullatif", ""], ["Lasla", "Noureddine", ""], ["Abdallah", "Mohamed", ""]]}, {"id": "2001.01917", "submitter": "Yohan Jung", "authors": "Yohan Jung, Jinkyoo Park", "title": "Scalable Hybrid HMM with Gaussian Process Emission for Sequential\n  Time-series Data Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Model (HMM) combined with Gaussian Process (GP) emission can be\neffectively used to estimate the hidden state with a sequence of complex\ninput-output relational observations. Especially when the spectral mixture (SM)\nkernel is used for GP emission, we call this model as a hybrid HMM-GPSM. This\nmodel can effectively model the sequence of time-series data. However, because\nof a large number of parameters for the SM kernel, this model can not\neffectively be trained with a large volume of data having (1) long sequence for\nstate transition and 2) a large number of time-series dataset in each sequence.\nThis paper proposes a scalable learning method for HMM-GPSM. To effectively\ntrain the model with a long sequence, the proposed method employs a Stochastic\nVariational Inference (SVI) approach. Also, to effectively process a large\nnumber of data point each time-series data, we approximate the SM kernel using\nReparametrized Random Fourier Feature (R-RFF). The combination of these two\ntechniques significantly reduces the training time. We validate the proposed\nlearning method in terms of its hidden-sate estimation accuracy and computation\ntime using large-scale synthetic and real data sets with missing values.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:28:21 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Jung", "Yohan", ""], ["Park", "Jinkyoo", ""]]}, {"id": "2001.01918", "submitter": "Qun Liu", "authors": "Supratik Mukhopadhyay, Qun Liu, Edward Collier, Yimin Zhu, Ravindra\n  Gudishala, Chanachok Chokwitthaya, Robert DiBiano, Alimire Nabijiang, Sanaz\n  Saeidi, Subhajit Sidhanta, Arnab Ganguly", "title": "Context-Aware Design of Cyber-Physical Human Systems (CPHS)", "comments": "Paper was accepted at the 12th International Conference on\n  Communication Systems and Networks (COMSNETS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been widely accepted by the research community that\ninteractions between humans and cyber-physical infrastructures have played a\nsignificant role in determining the performance of the latter. The existing\nparadigm for designing cyber-physical systems for optimal performance focuses\non developing models based on historical data. The impacts of context factors\ndriving human system interaction are challenging and are difficult to capture\nand replicate in existing design models. As a result, many existing models do\nnot or only partially address those context factors of a new design owing to\nthe lack of capabilities to capture the context factors. This limitation in\nmany existing models often causes performance gaps between predicted and\nmeasured results. We envision a new design environment, a cyber-physical human\nsystem (CPHS) where decision-making processes for physical infrastructures\nunder design are intelligently connected to distributed resources over\ncyberinfrastructure such as experiments on design features and empirical\nevidence from operations of existing instances. The framework combines existing\ndesign models with context-aware design-specific data involving\nhuman-infrastructure interactions in new designs, using a machine learning\napproach to create augmented design models with improved predictive powers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:31:36 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Mukhopadhyay", "Supratik", ""], ["Liu", "Qun", ""], ["Collier", "Edward", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Chokwitthaya", "Chanachok", ""], ["DiBiano", "Robert", ""], ["Nabijiang", "Alimire", ""], ["Saeidi", "Sanaz", ""], ["Sidhanta", "Subhajit", ""], ["Ganguly", "Arnab", ""]]}, {"id": "2001.01920", "submitter": "Tian Li", "authors": "Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet\n  Talwalkar, Virginia Smith", "title": "FedDANE: A Federated Newton-Type Method", "comments": "Asilomar Conference on Signals, Systems, and Computers 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning aims to jointly learn statistical models over massively\ndistributed remote devices. In this work, we propose FedDANE, an optimization\nmethod that we adapt from DANE, a method for classical distributed\noptimization, to handle the practical constraints of federated learning. We\nprovide convergence guarantees for this method when learning over both convex\nand non-convex functions. Despite encouraging theoretical results, we find that\nthe method has underwhelming performance empirically. In particular, through\nempirical simulations on both synthetic and real-world datasets, FedDANE\nconsistently underperforms baselines of FedAvg and FedProx in realistic\nfederated settings. We identify low device participation and statistical device\nheterogeneity as two underlying causes of this underwhelming performance, and\nconclude by suggesting several directions of future work.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 07:44:41 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Li", "Tian", ""], ["Sahu", "Anit Kumar", ""], ["Zaheer", "Manzil", ""], ["Sanjabi", "Maziar", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "2001.01941", "submitter": "Yao Fu", "authors": "Yao Fu, Yansong Feng and John P. Cunningham", "title": "Paraphrase Generation with Latent Bag of Words", "comments": "NeurIPS 19 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase generation is a longstanding important problem in natural language\nprocessing.\n  In addition, recent progress in deep generative models has shown promising\nresults on discrete latent variables for text generation.\n  Inspired by variational autoencoders with discrete latent structures, in this\nwork, we propose a latent bag of words (BOW) model for paraphrase generation.\n  We ground the semantics of a discrete latent variable by the BOW from the\ntarget sentences.\n  We use this latent variable to build a fully differentiable content planning\nand surface realization model.\n  Specifically, we use source words to predict their neighbors and model the\ntarget BOW with a mixture of softmax.\n  We use Gumbel top-k reparameterization to perform differentiable subset\nsampling from the predicted BOW distribution.\n  We retrieve the sampled word embeddings and use them to augment the decoder\nand guide its generation search space.\n  Our latent BOW model not only enhances the decoder, but also exhibits clear\ninterpretability.\n  We show the model interpretability with regard to \\emph{(i)} unsupervised\nlearning of word neighbors \\emph{(ii)} the step-by-step generation procedure.\n  Extensive experiments demonstrate the transparent and effective generation\nprocess of this model.\\footnote{Our code can be found at\n\\url{https://github.com/FranxYao/dgm_latent_bow}}\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 09:22:58 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Fu", "Yao", ""], ["Feng", "Yansong", ""], ["Cunningham", "John P.", ""]]}, {"id": "2001.01958", "submitter": "Pedro D\\'iez", "authors": "Alberto Garc\\'ia-Gonz\\'alez, Antonio Huerta, Sergio Zlotnik and Pedro\n  D\\'iez", "title": "A kernel Principal Component Analysis (kPCA) digest with a new backward\n  mapping (pre-image reconstruction) strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methodologies for multidimensionality reduction aim at discovering\nlow-dimensional manifolds where data ranges. Principal Component Analysis (PCA)\nis very effective if data have linear structure. But fails in identifying a\npossible dimensionality reduction if data belong to a nonlinear low-dimensional\nmanifold. For nonlinear dimensionality reduction, kernel Principal Component\nAnalysis (kPCA) is appreciated because of its simplicity and ease\nimplementation. The paper provides a concise review of PCA and kPCA main ideas,\ntrying to collect in a single document aspects that are often dispersed.\nMoreover, a strategy to map back the reduced dimension into the original high\ndimensional space is also devised, based on the minimization of a discrepancy\nfunctional.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 10:30:16 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 18:28:20 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Garc\u00eda-Gonz\u00e1lez", "Alberto", ""], ["Huerta", "Antonio", ""], ["Zlotnik", "Sergio", ""], ["D\u00edez", "Pedro", ""]]}, {"id": "2001.01969", "submitter": "Md Aamir Raihan", "authors": "Md Aamir Raihan, Tor M. Aamodt", "title": "Sparse Weight Activation Training", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training is computationally and memory intensive. Sparse\ntraining can reduce the burden on emerging hardware platforms designed to\naccelerate sparse computations, but it can affect network convergence. In this\nwork, we propose a novel CNN training algorithm Sparse Weight Activation\nTraining (SWAT). SWAT is more computation and memory-efficient than\nconventional training. SWAT modifies back-propagation based on the empirical\ninsight that convergence during training tends to be robust to the elimination\nof (i) small magnitude weights during the forward pass and (ii) both small\nmagnitude weights and activations during the backward pass. We evaluate SWAT on\nrecent CNN architectures such as ResNet, VGG, DenseNet and WideResNet using\nCIFAR-10, CIFAR-100 and ImageNet datasets. For ResNet-50 on ImageNet SWAT\nreduces total floating-point operations (FLOPS) during training by 80%\nresulting in a 3.3$\\times$ training speedup when run on a simulated sparse\nlearning accelerator representative of emerging platforms while incurring only\n1.63% reduction in validation accuracy. Moreover, SWAT reduces memory footprint\nduring the backward pass by 23% to 50% for activations and 50% to 90% for\nweights.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:08:13 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 00:10:27 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 21:51:29 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Raihan", "Md Aamir", ""], ["Aamodt", "Tor M.", ""]]}, {"id": "2001.01982", "submitter": "Guido Schillaci", "authors": "Guido Schillaci, Antonio Pico Villalpando, Verena Vanessa Hafner,\n  Peter Hanappe, David Colliaux, Timoth\\'ee Wintz", "title": "Intrinsic Motivation and Episodic Memories for Robot Exploration of\n  High-Dimensional Sensory Spaces", "comments": "This manuscript has been submitted for consideration for publication\n  in the Adaptive Behaviour Sage Journal, edited by Tom Froese", "journal-ref": "Adaptive behaviour 2020", "doi": "10.1177/1059712320922916", "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents an architecture that generates curiosity-driven\ngoal-directed exploration behaviours for an image sensor of a microfarming\nrobot. A combination of deep neural networks for offline unsupervised learning\nof low-dimensional features from images, and of online learning of shallow\nneural networks representing the inverse and forward kinematics of the system\nhave been used. The artificial curiosity system assigns interest values to a\nset of pre-defined goals, and drives the exploration towards those that are\nexpected to maximise the learning progress. We propose the integration of an\nepisodic memory in intrinsic motivation systems to face catastrophic forgetting\nissues, typically experienced when performing online updates of artificial\nneural networks. Our results show that adopting an episodic memory system not\nonly prevents the computational models from quickly forgetting knowledge that\nhas been previously acquired, but also provides new avenues for modulating the\nbalance between plasticity and stability of the models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:39:20 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schillaci", "Guido", ""], ["Villalpando", "Antonio Pico", ""], ["Hafner", "Verena Vanessa", ""], ["Hanappe", "Peter", ""], ["Colliaux", "David", ""], ["Wintz", "Timoth\u00e9e", ""]]}, {"id": "2001.01986", "submitter": "Ke Ding", "authors": "Ke Ding and Xuanji He and Guanglu Wan", "title": "Learning Speaker Embedding with Momentum Contrast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification can be formulated as a representation learning task,\nwhere speaker-discriminative embeddings are extracted from utterances of\nvariable lengths. Momentum Contrast (MoCo) is a recently proposed unsupervised\nrepresentation learning framework, and has shown its effectiveness for learning\ngood feature representation for downstream vision tasks. In this work, we apply\nMoCo to learn speaker embedding from speech segments. We explore MoCo for both\nunsupervised learning and pretraining settings. In the unsupervised scenario,\nembedding is learned by MoCo from audio data without using any speaker specific\ninformation. On a large scale dataset with $2,500$ speakers, MoCo can achieve\nEER $4.275\\%$ trained unsupervisedly, and the EER can decrease further to\n$3.58\\%$ if extra unlabelled data are used. In the pretraining scenario,\nencoder trained by MoCo is used to initialize the downstream supervised\ntraining. With finetuning on the MoCo trained model, the equal error rate (EER)\nreduces $13.7\\%$ relative ($1.44\\%$ to $1.242\\%$) compared to a carefully tuned\nbaseline training from scratch. Comparative study confirms the effectiveness of\nMoCo learning good speaker embedding.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:47:05 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 08:00:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ding", "Ke", ""], ["He", "Xuanji", ""], ["Wan", "Guanglu", ""]]}, {"id": "2001.01987", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn, Decebal Mocanu", "title": "Softmax-based Classification is k-means Clustering: Formal Proof,\n  Consequences for Adversarial Attacks, and Improvement through Centroid Based\n  Tailoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally prove the connection between k-means clustering and the\npredictions of neural networks based on the softmax activation layer. In\nexisting work, this connection has been analyzed empirically, but it has never\nbefore been mathematically derived. The softmax function partitions the\ntransformed input space into cones, each of which encompasses a class. This is\nequivalent to putting a number of centroids in this transformed space at equal\ndistance from the origin, and k-means clustering the data points by proximity\nto these centroids. Softmax only cares in which cone a data point falls, and\nnot how far from the centroid it is within that cone. We formally prove that\nnetworks with a small Lipschitz modulus (which corresponds to a low\nsusceptibility to adversarial attacks) map data points closer to the cluster\ncentroids, which results in a mapping to a k-means-friendly space. To leverage\nthis knowledge, we propose Centroid Based Tailoring as an alternative to the\nsoftmax function in the last layer of a neural network. The resulting Gauss\nnetwork has similar predictive accuracy as traditional networks, but is less\nsusceptible to one-pixel attacks; while the main contribution of this paper is\ntheoretical in nature, the Gauss network contributes empirical auxiliary\nbenefits.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 11:47:45 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""], ["Mocanu", "Decebal", ""]]}, {"id": "2001.01997", "submitter": "Mehmet Tan", "authors": "I\\c{s}{\\i}ksu Ek\\c{s}io\\u{g}lu, Mehmet Tan", "title": "Prediction of Drug Synergy by Ensemble Learning", "comments": "Appeared in Computational Intelligence Methods for Bioinformatics and\n  Biostatistics (CIBB) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the promising methods for the treatment of complex diseases such as\ncancer is combinational therapy. Due to the combinatorial complexity, machine\nlearning models can be useful in this field, where significant improvements\nhave recently been achieved in determination of synergistic combinations. In\nthis study, we investigate the effectiveness of different compound\nrepresentations in predicting the drug synergy. On a large drug combination\nscreen dataset, we first demonstrate the use of a promising representation that\nhas not been used for this problem before, then we propose an ensemble on\nrepresentation-model combinations that outperform each of the baseline models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:21:37 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ek\u015fio\u011flu", "I\u015f\u0131ksu", ""], ["Tan", "Mehmet", ""]]}, {"id": "2001.02002", "submitter": "Hanhe Lin", "authors": "Hanhe Lin, Vlad Hosu, Chunling Fan, Yun Zhang, Yuchen Mu, Raouf\n  Hamzaoui, Dietmar Saupe", "title": "SUR-FeatNet: Predicting the Satisfied User Ratio Curvefor Image\n  Compression with Deep Feature Learning", "comments": null, "journal-ref": "Quality and User Experience (2020) 5:5", "doi": "10.1007/s41233-020-00034-1", "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The satisfied user ratio (SUR) curve for a lossy image compression scheme,\ne.g., JPEG, characterizes the complementary cumulative distribution function of\nthe just noticeable difference (JND), the smallest distortion level that can be\nperceived by a subject when a reference image is compared to a distorted one. A\nsequence of JNDs can be defined with a suitable successive choice of reference\nimages. We propose the first deep learning approach to predict SUR curves. We\nshow how to apply maximum likelihood estimation and the Anderson-Darling test\nto select a suitable parametric model for the distribution function. We then\nuse deep feature learning to predict samples of the SUR curve and apply the\nmethod of least squares to fit the parametric model to the predicted samples.\nOur deep learning approach relies on a siamese convolutional neural network,\ntransfer learning, and deep feature learning, using pairs consisting of a\nreference image and a compressed image for training. Experiments on the MCL-JCI\ndataset showed state-of-the-art performance. For example, the mean\nBhattacharyya distances between the predicted and ground truth first, second,\nand third JND distributions were 0.0810, 0.0702, and 0.0522, respectively, and\nthe corresponding average absolute differences of the peak signal-to-noise\nratio at a median of the first JND distribution were 0.58, 0.69, and 0.58 dB.\nFurther experiments on the JND-Pano dataset showed that the method transfers\nwell to high resolution panoramic images viewed on head-mounted displays.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:37:07 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 08:55:22 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lin", "Hanhe", ""], ["Hosu", "Vlad", ""], ["Fan", "Chunling", ""], ["Zhang", "Yun", ""], ["Mu", "Yuchen", ""], ["Hamzaoui", "Raouf", ""], ["Saupe", "Dietmar", ""]]}, {"id": "2001.02004", "submitter": "Zijie Wang", "authors": "Zijie J. Wang, Robert Turko, Omar Shaikh, Haekyu Park, Nilaksh Das,\n  Fred Hohman, Minsuk Kahng, Duen Horng Chau", "title": "CNN 101: Interactive Visual Learning for Convolutional Neural Networks", "comments": "CHI'20 Late-Breaking Work (April 25-30, 2020), 7 pages, 3 figures", "journal-ref": null, "doi": "10.1145/3334480.3382899", "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning solving previously-thought hard problems has\ninspired many non-experts to learn and understand this exciting technology.\nHowever, it is often challenging for learners to take the first steps due to\nthe complexity of deep learning models. We present our ongoing work, CNN 101,\nan interactive visualization system for explaining and teaching convolutional\nneural networks. Through tightly integrated interactive views, CNN 101 offers\nboth overview and detailed descriptions of how a model works. Built using\nmodern web technologies, CNN 101 runs locally in users' web browsers without\nrequiring specialized hardware, broadening the public's education access to\nmodern deep learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:46:41 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:16:57 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 16:38:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wang", "Zijie J.", ""], ["Turko", "Robert", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Das", "Nilaksh", ""], ["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.02005", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Backtracking Gradient Descent allowing unbounded learning rates", "comments": "Convergence for Two-way Backtracking GD can be proven under more\n  general assumptions, in particular valid for C^2 functions. In statement of\n  Theorem 0.3, need to add the assumption that {f(x_n}) is non-increasing. Some\n  typos corrected. 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unconstrained optimisation on an Euclidean space, to prove convergence in\nGradient Descent processes (GD) $x_{n+1}=x_n-\\delta _n \\nabla f(x_n)$ it\nusually is required that the learning rates $\\delta _n$'s are bounded: $\\delta\n_n\\leq \\delta $ for some positive $\\delta $. Under this assumption, if the\nsequence $x_n$ converges to a critical point $z$, then with large values of $n$\nthe update will be small because $||x_{n+1}-x_n||\\lesssim ||\\nabla f(x_n)||$.\nThis may also force the sequence to converge to a bad minimum. If we can allow,\nat least theoretically, that the learning rates $\\delta _n$'s are not bounded,\nthen we may have better convergence to better minima.\n  A previous joint paper by the author showed convergence for the usual version\nof Backtracking GD under very general assumptions on the cost function $f$. In\nthis paper, we allow the learning rates $\\delta _n$ to be unbounded, in the\nsense that there is a function $h:(0,\\infty)\\rightarrow (0,\\infty )$ such that\n$\\lim _{t\\rightarrow 0}th(t)=0$ and $\\delta _n\\lesssim \\max \\{h(x_n),\\delta \\}$\nsatisfies Armijo's condition for all $n$, and prove convergence under the same\nassumptions as in the mentioned paper. It will be shown that this growth rate\nof $h$ is best possible if one wants convergence of the sequence $\\{x_n\\}$.\n  A specific way for choosing $\\delta _n$ in a discrete way connects to Two-way\nBacktracking GD defined in the mentioned paper. We provide some results which\neither improve or are implicitly contained in those in the mentioned paper and\nanother recent paper on avoidance of saddle points.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 12:52:00 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 16:50:06 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2001.02015", "submitter": "Qin Wang", "authors": "Qin Wang, Gabriel Michau, Olga Fink", "title": "Missing-Class-Robust Domain Adaptation by Unilateral Alignment for Fault\n  Diagnosis", "comments": null, "journal-ref": null, "doi": "10.1109/TIE.2019.2962438", "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims at improving model performance by leveraging the\nlearned knowledge in the source domain and transferring it to the target\ndomain. Recently, domain adversarial methods have been particularly successful\nin alleviating the distribution shift between the source and the target\ndomains. However, these methods assume an identical label space between the two\ndomains. This assumption imposes a significant limitation for real applications\nsince the target training set may not contain the complete set of classes. We\ndemonstrate in this paper that the performance of domain adversarial methods\ncan be vulnerable to an incomplete target label space during training. To\novercome this issue, we propose a two-stage unilateral alignment approach. The\nproposed methodology makes use of the inter-class relationships of the source\ndomain and aligns unilaterally the target to the source domain. The benefits of\nthe proposed methodology are first evaluated on the MNIST$\\rightarrow$MNIST-M\nadaptation task. The proposed methodology is also evaluated on a fault\ndiagnosis task, where the problem of missing fault types in the target training\ndataset is common in practice. Both experiments demonstrate the effectiveness\nof the proposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 13:19:04 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Wang", "Qin", ""], ["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "2001.02040", "submitter": "Ali Hatamizadeh", "authors": "Andriy Myronenko and Ali Hatamizadeh", "title": "Robust Semantic Segmentation of Brain Tumor Regions from 3D MRIs", "comments": "Accepted to 2019 International MICCAI Brainlesion Workshop --\n  Multimodal Brain Tumor Segmentation Challenge (BraTS) 2019. arXiv admin note:\n  substantial text overlap with arXiv:1810.11654", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal brain tumor segmentation challenge (BraTS) brings together\nresearchers to improve automated methods for 3D MRI brain tumor segmentation.\nTumor segmentation is one of the fundamental vision tasks necessary for\ndiagnosis and treatment planning of the disease. Previous years winning methods\nwere all deep-learning based, thanks to the advent of modern GPUs, which allow\nfast optimization of deep convolutional neural network architectures. In this\nwork, we explore best practices of 3D semantic segmentation, including\nconventional encoder-decoder architecture, as well combined loss functions, in\nattempt to further improve the segmentation accuracy. We evaluate the method on\nBraTS 2019 challenge.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 07:47:42 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Myronenko", "Andriy", ""], ["Hatamizadeh", "Ali", ""]]}, {"id": "2001.02050", "submitter": "Reza Rashetnia", "authors": "Reza Rashetnia and Mohammad Pour-Ghaz", "title": "Deep learning surrogate interacting Markov chain Monte Carlo based full\n  wave inversion scheme for properties of materials quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full Wave Inversion (FWI) imaging scheme has many applications in\nengineering, geoscience and medical sciences. In this paper, a surrogate deep\nlearning FWI approach is presented to quantify properties of materials using\nstress waves. Such inverse problems, in general, are ill-posed and nonconvex,\nespecially in cases where the solutions exhibit shocks, heterogeneity,\ndiscontinuities, or large gradients. The proposed approach is proven efficient\nto obtain global minima responses in these cases. This approach is trained\nbased on random sampled set of material properties and sampled trials around\nlocal minima, therefore, it requires a forward simulation can handle high\nheterogeneity, discontinuities and large gradients. High resolution\nKurganov-Tadmor (KT) central finite volume method is used as forward wave\npropagation operator. Using the proposed framework, material properties of 2D\nmedia are quantified for several different situations. The results demonstrate\nthe feasibility of the proposed method for estimating mechanical properties of\nmaterials with high accuracy using deep learning approaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:43:51 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Rashetnia", "Reza", ""], ["Pour-Ghaz", "Mohammad", ""]]}, {"id": "2001.02101", "submitter": "Homayoun Valafar", "authors": "Chrisogonas O. Odhiambo, Casey A. Cole, Alaleh Torkjazi, Homayoun\n  Valafar", "title": "State Transition Modeling of the Smoking Behavior using LSTM Recurrent\n  Neural Networks", "comments": "8 pages, CSCI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of sensors has pervaded everyday life in several applications\nincluding human activity monitoring, healthcare, and social networks. In this\nstudy, we focus on the use of smartwatch sensors to recognize smoking activity.\nMore specifically, we have reformulated the previous work in detection of\nsmoking to include in-context recognition of smoking. Our presented\nreformulation of the smoking gesture as a state-transition model that consists\nof the mini-gestures hand-to-lip, hand-on-lip, and hand-off-lip, has\ndemonstrated improvement in detection rates nearing 100% using conventional\nneural networks. In addition, we have begun the utilization of Long-Short-Term\nMemory (LSTM) neural networks to allow for in-context detection of gestures\nwith accuracy nearing 97%.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:06:28 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Odhiambo", "Chrisogonas O.", ""], ["Cole", "Casey A.", ""], ["Torkjazi", "Alaleh", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2001.02103", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Chikita Nangia, Chetan Kumar", "title": "Self learning robot using real-time neural networks", "comments": "8 pages, 14 figures", "journal-ref": "International Journal of Research in Engineering and Technology.\n  Vol 07 Issue 10 (2018)", "doi": "10.15623/ijret.2018.0710009", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancements in high volume, low precision computational technology\nand applied research on cognitive artificially intelligent heuristic systems,\nmachine learning solutions through neural networks with real-time learning has\nseen an immense interest in the research community as well the industry. This\npaper involves research, development and experimental analysis of a neural\nnetwork implemented on a robot with an arm through which evolves to learn to\nwalk in a straight line or as required. The neural network learns using the\nalgorithms of Gradient Descent and Backpropagation. Both the implementation and\ntraining of the neural network is done locally on the robot on a raspberry pi 3\nso that its learning process is completely independent. The neural network is\nfirst tested on a custom simulator developed on MATLAB and then implemented on\nthe raspberry computer. Data at each generation of the evolving network is\nstored, and analysis both mathematical and graphical is done on the data.\nImpact of factors like the learning rate and error tolerance on the learning\nprocess and final output is analyzed.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 13:13:21 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Gupta", "Chirag", ""], ["Nangia", "Chikita", ""], ["Kumar", "Chetan", ""]]}, {"id": "2001.02112", "submitter": "Roula Nassif", "authors": "Roula Nassif, Stefan Vlaski, Cedric Richard, Jie Chen, and Ali H.\n  Sayed", "title": "Multitask learning over graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning simultaneously several related tasks has received\nconsiderable attention in several domains, especially in machine learning with\nthe so-called multitask learning problem or learning to learn problem [1], [2].\nMultitask learning is an approach to inductive transfer learning (using what is\nlearned for one problem to assist in another problem) and helps improve\ngeneralization performance relative to learning each task separately by using\nthe domain information contained in the training signals of related tasks as an\ninductive bias. Several strategies have been derived within this community\nunder the assumption that all data are available beforehand at a fusion center.\nHowever, recent years have witnessed an increasing ability to collect data in a\ndistributed and streaming manner. This requires the design of new strategies\nfor learning jointly multiple tasks from streaming data over distributed (or\nnetworked) systems. This article provides an overview of multitask strategies\nfor learning and adaptation over networks. The working hypothesis for these\nstrategies is that agents are allowed to cooperate with each other in order to\nlearn distinct, though related tasks. The article shows how cooperation steers\nthe network limiting point and how different cooperation rules allow to promote\ndifferent task relatedness models. It also explains how and when cooperation\nover multitask networks outperforms non-cooperative strategies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:32:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Nassif", "Roula", ""], ["Vlaski", "Stefan", ""], ["Richard", "Cedric", ""], ["Chen", "Jie", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2001.02121", "submitter": "Alexander M\\\"arz", "authors": "Alexander M\\\"arz", "title": "CatBoostLSS -- An extension of CatBoost to probabilistic forecasting", "comments": "CatBoost, Distributional Modelling, Expectile Regression, GAMLSS,\n  Probabilistic Forecast, Statistical Machine Learning, Uncertainty\n  Quantification. arXiv admin note: substantial text overlap with\n  arXiv:1907.03178", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of CatBoost that predicts the entire conditional\ndistribution of a univariate response variable. In particular, CatBoostLSS\nmodels all moments of a parametric distribution (i.e., mean, location, scale\nand shape [LSS]) instead of the conditional mean only. Choosing from a wide\nrange of continuous, discrete and mixed discrete-continuous distributions,\nmodelling and predicting the entire conditional distribution greatly enhances\nthe flexibility of CatBoost, as it allows to gain insight into the data\ngenerating process, as well as to create probabilistic forecasts from which\nprediction intervals and quantiles of interest can be derived. We present both\na simulation study and real-world examples that demonstrate the benefits of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:42:44 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["M\u00e4rz", "Alexander", ""]]}, {"id": "2001.02127", "submitter": "Nadine Kuhnert", "authors": "Nadine Kuhnert, Lea Pfl\\\"uger, Andreas Maier", "title": "Prediction of MRI Hardware Failures based on Image Features using Time\n  Series Classification", "comments": null, "journal-ref": "Bildverarbeitung f\\\"ur die Medizin 2020. Springer Vieweg,\n  Wiesbaden, 2020", "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Already before systems malfunction one has to know if hardware components\nwill fail in near future in order to counteract in time. Thus, unplanned\ndowntime is ought to be avoided. In medical imaging, maximizing the system's\nuptime is crucial for patients' health and healthcare provider's daily\nbusiness. We aim to predict failures of Head/Neck coils used in Magnetic\nResonance Imaging (MRI) by training a statistical model on sequential data\ncollected over time. As image features depend on the coil's condition, their\ndeviations from the normal range already hint to future failure. Thus, we used\nimage features and their variation over time to predict coil damage. After\ncomparison of different time series classification methods we found Long Short\nTerm Memorys (LSTMs) to achieve the highest F-score of 86.43% and to tell with\n98.33% accuracy if hardware should be replaced.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:25:53 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kuhnert", "Nadine", ""], ["Pfl\u00fcger", "Lea", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.02152", "submitter": "Iain Whiteside", "authors": "Edward Ayers, Francisco Eiras, Majd Hawasly, Iain Whiteside", "title": "PaRoT: A Practical Framework for Robust Deep Neural Network Training", "comments": "Accepted at 12th NASA Formal Methods Symposium, NFM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are finding important applications in\nsafety-critical systems such as Autonomous Vehicles (AVs), where perceiving the\nenvironment correctly and robustly is necessary for safe operation. Raising\nunique challenges for assurance due to their black-box nature, DNNs pose a\nfundamental problem for regulatory acceptance of these types of systems. Robust\ntraining --- training to minimize excessive sensitivity to small changes in\ninput --- has emerged as one promising technique to address this challenge.\nHowever, existing robust training tools are inconvenient to use or apply to\nexisting codebases and models: they typically only support a small subset of\nmodel elements and require users to extensively rewrite the training code. In\nthis paper we introduce a novel framework, PaRoT, developed on the popular\nTensorFlow platform, that greatly reduces the barrier to entry. Our framework\nenables robust training to be performed on arbitrary DNNs without any rewrites\nto the model. We demonstrate that our framework's performance is comparable to\nprior art, and exemplify its ease of use on off-the-shelf, trained models and\nits testing capabilities on a real-world industrial application: a traffic\nlight detection network.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:21:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 13:31:50 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 11:17:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ayers", "Edward", ""], ["Eiras", "Francisco", ""], ["Hawasly", "Majd", ""], ["Whiteside", "Iain", ""]]}, {"id": "2001.02153", "submitter": "Mohak Bhardwaj", "authors": "Mohak Bhardwaj, Ankur Handa, Dieter Fox, Byron Boots", "title": "Information Theoretic Model Predictive Q-Learning", "comments": "Extended version (15 pages) of paper accepted at the 2nd Learning for\n  Dynamics and Control (L4DC) Conference, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free Reinforcement Learning (RL) works well when experience can be\ncollected cheaply and model-based RL is effective when system dynamics can be\nmodeled accurately. However, both assumptions can be violated in real world\nproblems such as robotics, where querying the system can be expensive and\nreal-world dynamics can be difficult to model. In contrast to RL, Model\nPredictive Control (MPC) algorithms use a simulator to optimize a simple policy\nclass online, constructing a closed-loop controller that can effectively\ncontend with real-world dynamics. MPC performance is usually limited by factors\nsuch as model bias and the limited horizon of optimization. In this work, we\npresent a novel theoretical connection between information theoretic MPC and\nentropy regularized RL and develop a Q-learning algorithm that can leverage\nbiased models. We validate the proposed algorithm on sim-to-sim control tasks\nto demonstrate the improvements over optimal control and reinforcement learning\nfrom scratch. Our approach paves the way for deploying reinforcement learning\nalgorithms on real systems in a systematic manner.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 00:29:22 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 21:49:55 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bhardwaj", "Mohak", ""], ["Handa", "Ankur", ""], ["Fox", "Dieter", ""], ["Boots", "Byron", ""]]}, {"id": "2001.02160", "submitter": "Duc Hoang", "authors": "Duc Hoang (1), Jesse Hamer (2), Gabriel N. Perdue (3), Steven R. Young\n  (4), Jonathan Miller (5), Anushree Ghosh (5) ((1) Rhodes College, (2) The\n  University of Iowa, (3) Fermi National Accelerator Laboratory, (4) Oak Ridge\n  National Laboratory, (5) Universidad T\\'ecnica Federico Santa Mar\\'ia)", "title": "Inferring Convolutional Neural Networks' accuracies from their\n  architectural characterizations", "comments": "6 pages, 5 figures, 5 tables, to appear in proceedings of the 18th\n  International Conference on Machine Learning and Applications - ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have shown strong promise for analyzing\nscientific data from many domains including particle imaging detectors.\nHowever, the challenge of choosing the appropriate network architecture (depth,\nkernel shapes, activation functions, etc.) for specific applications and\ndifferent data sets is still poorly understood. In this paper, we study the\nrelationships between a CNN's architecture and its performance by proposing a\nsystematic language that is useful for comparison between different CNN's\narchitectures before training time. We characterize CNN's architecture by\ndifferent attributes, and demonstrate that the attributes can be predictive of\nthe networks' performance in two specific computer vision-based physics\nproblems -- event vertex finding and hadron multiplicity classification in the\nMINERvA experiment at Fermi National Accelerator Laboratory. In doing so, we\nextract several architectural attributes from optimized networks' architecture\nfor the physics problems, which are outputs of a model selection algorithm\ncalled Multi-node Evolutionary Neural Networks for Deep Learning (MENNDL). We\nuse machine learning models to predict whether a network can perform better\nthan a certain threshold accuracy before training. The models perform 16-20%\nbetter than random guessing. Additionally, we found an coefficient of\ndetermination of 0.966 for an Ordinary Least Squares model in a regression on\naccuracy over a large population of networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:41:58 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 03:52:48 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hoang", "Duc", ""], ["Hamer", "Jesse", ""], ["Perdue", "Gabriel N.", ""], ["Young", "Steven R.", ""], ["Miller", "Jonathan", ""], ["Ghosh", "Anushree", ""]]}, {"id": "2001.02165", "submitter": "Axel Barrau", "authors": "S\\'ebastien Razakarivony and Axel Barrau", "title": "Generalized mean shift with triangular kernel profile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean shift algorithm is a popular way to find modes of some probability\ndensity functions taking a specific kernel-based shape, used for clustering or\nvisual tracking. Since its introduction, it underwent several practical\nimprovements and generalizations, as well as deep theoretical analysis mainly\nfocused on its convergence properties. In spite of encouraging results, this\nquestion has not received a clear general answer yet. In this paper we focus on\na specific class of kernels, adapted in particular to the distributions\nclustering applications which motivated this work. We show that a novel Mean\nShift variant adapted to them can be derived, and proved to converge after a\nfinite number of iterations. In order to situate this new class of methods in\nthe general picture of the Mean Shift theory, we alo give a synthetic exposure\nof existing results of this field.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 16:46:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Razakarivony", "S\u00e9bastien", ""], ["Barrau", "Axel", ""]]}, {"id": "2001.02201", "submitter": "Markus Lill", "authors": "Ahmadreza Ghanbarpour, Amr H. Mahmoud, Markus A. Lill", "title": "On-the-fly Prediction of Protein Hydration Densities and Free Energies\n  using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The calculation of thermodynamic properties of biochemical systems typically\nrequires the use of resource-intensive molecular simulation methods. One\nexample thereof is the thermodynamic profiling of hydration sites, i.e.\nhigh-probability locations for water molecules on the protein surface, which\nplay an essential role in protein-ligand associations and must therefore be\nincorporated in the prediction of binding poses and affinities. To replace\ntime-consuming simulations in hydration site predictions, we developed two\ndifferent types of deep neural-network models aiming to predict hydration site\ndata. In the first approach, meshed 3D images are generated representing the\ninteractions between certain molecular probes placed on regular 3D grids,\nencompassing the binding pocket, with the static protein. These molecular\ninteraction fields are mapped to the corresponding 3D image of hydration\noccupancy using a neural network based on an U-Net architecture. In a second\napproach, hydration occupancy and thermodynamics were predicted point-wise\nusing a neural network based on fully-connected layers. In addition to direct\nprotein interaction fields, the environment of each grid point was represented\nusing moments of a spherical harmonics expansion of the interaction properties\nof nearby grid points. Application to structure-activity relationship analysis\nand protein-ligand pose scoring demonstrates the utility of the predicted\nhydration information.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 18:06:30 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Ghanbarpour", "Ahmadreza", ""], ["Mahmoud", "Amr H.", ""], ["Lill", "Markus A.", ""]]}, {"id": "2001.02205", "submitter": "David Wolpert", "authors": "David H Wolpert", "title": "Minimal entropy production due to constraints on rate matrix\n  dependencies in multipartite processes", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I consider multipartite processes in which there are constraints on each\nsubsystem's rate matrix, restricting which other subsystems can directly affect\nits dynamics. I derive a strictly nonzero lower bound on the minimal achievable\nentropy production rate of the process in terms of these constraints on the\nrate matrices of its subsystems. The bound is based on constructing\ncounterfactual rate matrices, in which some subsystems are held fixed while the\nothers are allowed to evolve. This bound is related to the \"learning rate\" of\nstationary bipartite systems, and more generally to the \"information flow\" in\nbipartite systems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 18:17:42 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 16:56:14 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 16:17:26 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Wolpert", "David H", ""]]}, {"id": "2001.02223", "submitter": "Senthil Yogamani", "authors": "Isabelle Leang, Ganesh Sistu, Fabian Burger, Andrei Bursuc and Senthil\n  Yogamani", "title": "Dynamic Task Weighting Methods for Multi-task Networks in Autonomous\n  Driving Systems", "comments": "Accepted for Oral Presentation at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multi-task networks are of particular interest for autonomous driving\nsystems. They can potentially strike an excellent trade-off between predictive\nperformance, hardware constraints and efficient use of information from\nmultiple types of annotations and modalities. However, training such models is\nnon-trivial and requires balancing learning over all tasks as their respective\nlosses display different scales, ranges and dynamics across training. Multiple\ntask weighting methods that adjust the losses in an adaptive way have been\nproposed recently on different datasets and combinations of tasks, making it\ndifficult to compare them. In this work, we review and systematically evaluate\nnine task weighting strategies on common grounds on three automotive datasets\n(KITTI, Cityscapes and WoodScape). We then propose a novel method combining\nevolutionary meta-learning and task-based selective backpropagation, for\ncomputing task weights leading to reliable network training. Our method\noutperforms state-of-the-art methods by a significant margin on a two-task\napplication.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 18:54:21 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:01:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Leang", "Isabelle", ""], ["Sistu", "Ganesh", ""], ["Burger", "Fabian", ""], ["Bursuc", "Andrei", ""], ["Yogamani", "Senthil", ""]]}, {"id": "2001.02244", "submitter": "Sebastian East", "authors": "Sebastian East, Marco Gallieri, Jonathan Masci, Jan Koutnik, Mark\n  Cannon", "title": "Infinite-Horizon Differentiable Model Predictive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a differentiable linear quadratic Model Predictive\nControl (MPC) framework for safe imitation learning. The infinite-horizon cost\nis enforced using a terminal cost function obtained from the discrete-time\nalgebraic Riccati equation (DARE), so that the learned controller can be proven\nto be stabilizing in closed-loop. A central contribution is the derivation of\nthe analytical derivative of the solution of the DARE, thereby allowing the use\nof differentiation-based learning methods. A further contribution is the\nstructure of the MPC optimization problem: an augmented Lagrangian method\nensures that the MPC optimization is feasible throughout training whilst\nenforcing hard constraints on state and input, and a pre-stabilizing controller\nensures that the MPC solution and derivatives are accurate at each iteration.\nThe learning capabilities of the framework are demonstrated in a set of\nnumerical studies.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 19:00:39 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["East", "Sebastian", ""], ["Gallieri", "Marco", ""], ["Masci", "Jonathan", ""], ["Koutnik", "Jan", ""], ["Cannon", "Mark", ""]]}, {"id": "2001.02246", "submitter": "Dionissios Hristopulos Prof.", "authors": "Dionissios T. Hristopulos, Andreas Pavlides, Vasiliki D. Agou, and\n  Panagiota Gkafa", "title": "Stochastic Local Interaction Model: Geostatistics without Kriging", "comments": "42 pages, 15 figures", "journal-ref": "Mathematical Geosciences, pp.1-43 (2021)", "doi": "10.1007/s11004-021-09957-7", "report-no": null, "categories": "math.ST cs.LG physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical geostatistical methods face serious computational challenges if\nthey are confronted with large sets of spatially distributed data. We present a\nsimplified stochastic local interaction (SLI) model for computationally\nefficient spatial prediction that can handle large data. The SLI method\nconstructs a spatial interaction matrix (precision matrix) that accounts for\nthe data values, their locations, and the sampling density variations without\nuser input. We show that this precision matrix is strictly positive definite.\nThe SLI approach does not require matrix inversion for parameter estimation,\nspatial prediction, and uncertainty estimation, leading to computational\nprocedures that are significantly less intensive computationally than kriging.\nThe precision matrix involves compact kernel functions (spherical, quadratic,\netc.) which enable the application of sparse matrix methods, thus improving\ncomputational time and memory requirements. We investigate the proposed SLI\nmethod with a data set that includes approximately 11500 drill-hole data of\ncoal thickness from Campbell County (Wyoming, USA). We also compare SLI with\nordinary kriging (OK) in terms of estimation performance, using cross\nvalidation analysis, and computational time. According to the validation\nmeasures used, SLI performs slightly better in estimating seam thickness than\nOK in terms of cross-validation measures. In terms of computation time, SLI\nprediction is 3 to 25 times (depending on the size of the kriging neighborhood)\nfaster than OK for the same grid size.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 19:03:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hristopulos", "Dionissios T.", ""], ["Pavlides", "Andreas", ""], ["Agou", "Vasiliki D.", ""], ["Gkafa", "Panagiota", ""]]}, {"id": "2001.02254", "submitter": "Kirill Polzounov", "authors": "Kirill Polzounov, Ramitha Sundar, Lee Redden", "title": "Blue River Controls: A toolkit for Reinforcement Learning Control\n  Systems on Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a simple hardware wrapper around the Quanser's\nhardware-in-the-loop software development kit (HIL SDK) to allow for easy\ndevelopment of new Quanser hardware. To connect to the hardware we use a module\nwritten in Cython. The internal QuanserWrapper class handles most of the\ndifficult aspects of interacting with hardware, including the timing (using a\nhardware timer), and ensuring the data sent to hardware is safe and correct,\nwhere safety corresponds to safe operating voltage and current for the\nspecified hardware. Much of the recent success of Reinforcement learning (RL)\nhas been made possible with training and testing tools like OpenAI Gym and\nDeepmind Control Suite. Unfortunately, tools for quickly testing and\ntransferring high-frequency RL algorithms from simulation to real hardware\nenvironment remain mostly absent. We present Blue River Controls, a tool that\nallows to train and test reinforcement learning algorithms on real-world\nhardware. It features a simple interface based on OpenAI Gym, that works\ndirectly on both simulation and hardware. We use Quanser's Qube Servo2-USB\nplatform, an underactuated rotary pendulum as an initial testing device. We\nalso provide tools to simplify training RL algorithms on other hardware.\nSeveral baselines, from both classical controllers and pretrained RL agents are\nincluded to compare performance across tasks. Blue River Controls is available\nat this https URL: https://github.com/BlueRiverTech/quanser-openai-driver\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 19:24:29 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Polzounov", "Kirill", ""], ["Sundar", "Ramitha", ""], ["Redden", "Lee", ""]]}, {"id": "2001.02297", "submitter": "Shuo Wang", "authors": "Shuo Wang, Shangyu Chen, Tianle Chen, Surya Nepal, Carsten Rudolph,\n  Marthie Grobler", "title": "Generating Semantic Adversarial Examples via Feature Manipulation", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.09064 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks to adversarial attacks has been\nwidely demonstrated (e.g., adversarial example attacks). Traditional attacks\nperform unstructured pixel-wise perturbation to fool the classifier. An\nalternative approach is to have perturbations in the latent space. However,\nsuch perturbations are hard to control due to the lack of interpretability and\ndisentanglement. In this paper, we propose a more practical adversarial attack\nby designing structured perturbation with semantic meanings. Our proposed\ntechnique manipulates the semantic attributes of images via the disentangled\nlatent codes. The intuition behind our technique is that images in similar\ndomains have some commonly shared but theme-independent semantic attributes,\ne.g. thickness of lines in handwritten digits, that can be bidirectionally\nmapped to disentangled latent codes. We generate adversarial perturbation by\nmanipulating a single or a combination of these latent codes and propose two\nunsupervised semantic manipulation approaches: vector-based disentangled\nrepresentation and feature map-based disentangled representation, in terms of\nthe complexity of the latent codes and smoothness of the reconstructed images.\nWe conduct extensive experimental evaluations on real-world image data to\ndemonstrate the power of our attacks for black-box classifiers. We further\ndemonstrate the existence of a universal, image-agnostic semantic adversarial\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 06:28:31 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Shangyu", ""], ["Chen", "Tianle", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""]]}, {"id": "2001.02302", "submitter": "Zhijun Liang", "authors": "Zhijun Liang, Juan Rojas, Junfa Liu, Yisheng Guan", "title": "Visual-Semantic Graph Attention Networks for Human-Object Interaction\n  Detection", "comments": "7 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scene understanding, robotics benefit from not only detecting individual\nscene instances but also from learning their possible interactions.\nHuman-Object Interaction (HOI) Detection infers the action predicate on a\n<human, predicate, object> triplet. Contextual information has been found\ncritical in inferring interactions. However, most works only use local features\nfrom single human-object pair for inference. Few works have studied the\ndisambiguating contribution of subsidiary relations made available via graph\nnetworks. Similarly, few have learned to effectively leverage visual cues along\nwith the intrinsic semantic regularities contained in HOIs. We contribute a\ndual-graph attention network that effectively aggregates contextual visual,\nspatial, and semantic information dynamically from primary human-object\nrelations as well as subsidiary relations through attention mechanisms for\nstrong disambiguating power. We achieve comparable results on two benchmarks:\nV-COCO and HICO-DET. Code is available at\n\\url{https://github.com/birlrobotics/vs-gats}.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 22:22:46 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 03:43:59 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 15:11:24 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 14:53:18 GMT"}, {"version": "v5", "created": "Mon, 19 Oct 2020 10:07:28 GMT"}, {"version": "v6", "created": "Sat, 6 Mar 2021 05:42:22 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Liang", "Zhijun", ""], ["Rojas", "Juan", ""], ["Liu", "Junfa", ""], ["Guan", "Yisheng", ""]]}, {"id": "2001.02307", "submitter": "Keuntaek Lee", "authors": "Keuntaek Lee, Jason Gibson, Evangelos A. Theodorou", "title": "Aggressive Perception-Aware Navigation using Deep Optical Flow Dynamics\n  and PixelMPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, vision-based control has gained traction by leveraging the power of\nmachine learning. In this work, we couple a model predictive control (MPC)\nframework to a visual pipeline. We introduce deep optical flow (DOF) dynamics,\nwhich is a combination of optical flow and robot dynamics. Using the DOF\ndynamics, MPC explicitly incorporates the predicted movement of relevant pixels\ninto the planned trajectory of a robot. Our implementation of DOF is\nmemory-efficient, data-efficient, and computationally cheap so that it can be\ncomputed in real-time for use in an MPC framework. The suggested Pixel Model\nPredictive Control (PixelMPC) algorithm controls the robot to accomplish a\nhigh-speed racing task while maintaining visibility of the important features\n(gates). This improves the reliability of vision-based estimators for\nlocalization and can eventually lead to safe autonomous flight. The proposed\nalgorithm is tested in a photorealistic simulation with a high-speed drone\nracing task.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 22:33:12 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Lee", "Keuntaek", ""], ["Gibson", "Jason", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2001.02309", "submitter": "Bj{\\o}rn Kjos-Hanssen", "authors": "Bj{\\o}rn Kjos-Hanssen, Clyde James Felix, Sun Young Kim, Ethan Lamb,\n  Davin Takahashi", "title": "VC-dimensions of nondeterministic finite automata for words of equal\n  length", "comments": "ISAIM 2020 (International Symposium on Artificial Intelligence and\n  Mathematics), Fort Lauderdale, FL. January 6--8, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ishigami and Tani studied VC-dimensions of deterministic finite automata. We\nobtain analogous results for the nondeterministic case by extending a result of\nChamparnaud and Pin, who proved that the maximal deterministic state complexity\nof a set of binary words of length $n$ is \\[\n  \\sum_{i=0}^n\\min(2^i,2^{2^{n-i}}-1). \\] We show that for the nondeterministic\ncase, if we fully restrict attention to words of length $n$, then we at most\nneed the strictly increasing initial terms in this sum.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 22:49:55 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Kjos-Hanssen", "Bj\u00f8rn", ""], ["Felix", "Clyde James", ""], ["Kim", "Sun Young", ""], ["Lamb", "Ethan", ""], ["Takahashi", "Davin", ""]]}, {"id": "2001.02312", "submitter": "Santiago Akle Serrano", "authors": "Vipul Gupta, Santiago Akle Serrano, Dennis DeCoste", "title": "Stochastic Weight Averaging in Parallel: Large-Batch Training that\n  Generalizes Well", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Stochastic Weight Averaging in Parallel (SWAP), an algorithm to\naccelerate DNN training. Our algorithm uses large mini-batches to compute an\napproximate solution quickly and then refines it by averaging the weights of\nmultiple models computed independently and in parallel. The resulting models\ngeneralize equally well as those trained with small mini-batches but are\nproduced in a substantially shorter time. We demonstrate the reduction in\ntraining time and the good generalization performance of the resulting models\non the computer vision datasets CIFAR10, CIFAR100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 23:13:35 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Gupta", "Vipul", ""], ["Serrano", "Santiago Akle", ""], ["DeCoste", "Dennis", ""]]}, {"id": "2001.02323", "submitter": "James Grant", "authors": "James A. Grant and David S. Leslie", "title": "On Thompson Sampling for Smoother-than-Lipschitz Bandits", "comments": "Accepted to AISTATS 2020. 26 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling is a well established approach to bandit and reinforcement\nlearning problems. However its use in continuum armed bandit problems has\nreceived relatively little attention. We provide the first bounds on the regret\nof Thompson Sampling for continuum armed bandits under weak conditions on the\nfunction class containing the true function and sub-exponential observation\nnoise. Our bounds are realised by analysis of the eluder dimension, a recently\nproposed measure of the complexity of a function class, which has been\ndemonstrated to be useful in bounding the Bayesian regret of Thompson Sampling\nfor simpler bandit problems under sub-Gaussian observation noise. We derive a\nnew bound on the eluder dimension for classes of functions with Lipschitz\nderivatives, and generalise previous analyses in multiple regards.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 00:46:13 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 12:06:42 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Grant", "James A.", ""], ["Leslie", "David S.", ""]]}, {"id": "2001.02328", "submitter": "Nishanth Kumar", "authors": "Nishanth Kumar", "title": "The Past and Present of Imitation Learning: A Citation Chain Study", "comments": "This report was originally submitted as a Final Project for 'CSCI\n  1951M: The Great Ideas in Computer Science', offered at Brown University in\n  Fall 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning is a promising area of active research. Over the last 30\nyears, Imitation Learning has advanced significantly and been used to solve\ndifficult tasks ranging from Autonomous Driving to playing Atari games. In the\ncourse of this development, different methods for performing Imitation Learning\nhave fallen into and out of favor. In this paper, I explore the development of\nthese different methods and attempt to examine how the field has progressed. I\nfocus my analysis on surveying 4 landmark papers that sequentially build upon\neach other to develop increasingly impressive Imitation Learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 00:58:31 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Kumar", "Nishanth", ""]]}, {"id": "2001.02330", "submitter": "Krittaphat Pugdeethosapol", "authors": "Amar Shrestha, Krittaphat Pugdeethosapol, Haowen Fang, Qinru Qiu", "title": "High-Level Plan for Behavioral Robot Navigation with Natural Language\n  Directions and R-NET", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the navigational environment is known, it can be represented as a graph\nwhere landmarks are nodes, the robot behaviors that move from node to node are\nedges, and the route is a set of behavioral instructions. The route path from\nsource to destination can be viewed as a class of combinatorial optimization\nproblems where the path is a sequential subset from a set of discrete items.\nThe pointer network is an attention-based recurrent network that is suitable\nfor such a task. In this paper, we utilize a modified R-NET with gated\nattention and self-matching attention translating natural language instructions\nto a high-level plan for behavioral robot navigation by developing an\nunderstanding of the behavioral navigational graph to enable the pointer\nnetwork to produce a sequence of behaviors representing the path. Tests on the\nnavigation graph dataset show that our model outperforms the state-of-the-art\napproach for both known and unknown environments.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 01:14:11 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Shrestha", "Amar", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Fang", "Haowen", ""], ["Qiu", "Qinru", ""]]}, {"id": "2001.02334", "submitter": "Zhen Li", "authors": "Deqing Zou, Sujuan Wang, Shouhuai Xu, Zhen Li, Hai Jin", "title": "$\\mu$VulDeePecker: A Deep Learning-Based System for Multiclass\n  Vulnerability Detection", "comments": "To be published in IEEE Transactions on Dependable and Secure\n  Computing", "journal-ref": null, "doi": "10.1109/TDSC.2019.2942930", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained software vulnerability detection is an important and challenging\nproblem. Ideally, a detection system (or detector) not only should be able to\ndetect whether or not a program contains vulnerabilities, but also should be\nable to pinpoint the type of a vulnerability in question. Existing\nvulnerability detection methods based on deep learning can detect the presence\nof vulnerabilities (i.e., addressing the binary classification or detection\nproblem), but cannot pinpoint types of vulnerabilities (i.e., incapable of\naddressing multiclass classification). In this paper, we propose the first deep\nlearning-based system for multiclass vulnerability detection, dubbed\n$\\mu$VulDeePecker. The key insight underlying $\\mu$VulDeePecker is the concept\nof code attention, which can capture information that can help pinpoint types\nof vulnerabilities, even when the samples are small. For this purpose, we\ncreate a dataset from scratch and use it to evaluate the effectiveness of\n$\\mu$VulDeePecker. Experimental results show that $\\mu$VulDeePecker is\neffective for multiclass vulnerability detection and that accommodating\ncontrol-dependence (other than data-dependence) can lead to higher detection\ncapabilities.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 01:47:22 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zou", "Deqing", ""], ["Wang", "Sujuan", ""], ["Xu", "Shouhuai", ""], ["Li", "Zhen", ""], ["Jin", "Hai", ""]]}, {"id": "2001.02337", "submitter": "Dohyun Kwon", "authors": "Dohyun Kwon and Joongheon Kim", "title": "Multi-Agent Deep Reinforcement Learning for Cooperative Connected\n  Vehicles", "comments": "6 pages, 4 figures, conference paper (GLOBECOM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmWave) base station can offer abundant high capacity\nchannel resources toward connected vehicles so that quality-of-service (QoS) of\nthem in terms of downlink throughput can be highly improved. The mmWave base\nstation can operate among existing base stations (e.g., macro-cell base\nstation) on non-overlapped channels among them and the vehicles can make\ndecision what base station to associate, and what channel to utilize on\nheterogeneous networks. Furthermore, because of the non-omni property of mmWave\ncommunication, the vehicles decide how to align the beam direction toward\nmmWave base station to associate with it. However, such joint problem requires\nhigh computational cost, which is NP-hard and has combinatorial features. In\nthis paper, we solve the problem in 3-tier heterogeneous vehicular network\n(HetVNet) with multi-agent deep reinforcement learning (DRL) in a way that\nmaximizes expected total reward (i.e., downlink throughput) of vehicles. The\nmulti-agent deep deterministic policy gradient (MADDPG) approach is introduced\nto achieve optimal policy in continuous action domain.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 02:01:01 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Kwon", "Dohyun", ""], ["Kim", "Joongheon", ""]]}, {"id": "2001.02338", "submitter": "Richard Liaw", "authors": "Richard Liaw, Romil Bhardwaj, Lisa Dunlap, Yitian Zou, Joseph\n  Gonzalez, Ion Stoica, Alexey Tumanov", "title": "HyperSched: Dynamic Resource Reallocation for Model Development on a\n  Deadline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior research in resource scheduling for machine learning training workloads\nhas largely focused on minimizing job completion times. Commonly, these model\ntraining workloads collectively search over a large number of parameter values\nthat control the learning process in a hyperparameter search. It is preferable\nto identify and maximally provision the best-performing hyperparameter\nconfiguration (trial) to achieve the highest accuracy result as soon as\npossible.\n  To optimally trade-off evaluating multiple configurations and training the\nmost promising ones by a fixed deadline, we design and build HyperSched -- a\ndynamic application-level resource scheduler to track, identify, and\npreferentially allocate resources to the best performing trials to maximize\naccuracy by the deadline. HyperSched leverages three properties of a\nhyperparameter search workload over-looked in prior work - trial disposability,\nprogressively identifiable rankings among different configurations, and\nspace-time constraints - to outperform standard hyperparameter search\nalgorithms across a variety of benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 02:01:50 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Liaw", "Richard", ""], ["Bhardwaj", "Romil", ""], ["Dunlap", "Lisa", ""], ["Zou", "Yitian", ""], ["Gonzalez", "Joseph", ""], ["Stoica", "Ion", ""], ["Tumanov", "Alexey", ""]]}, {"id": "2001.02354", "submitter": "Deheng Qian", "authors": "Yanliang Zhu, Deheng Qian, Dongchun Ren, Huaxia Xia", "title": "VisionNet: A Drivable-space-based Interactive Motion Prediction Network\n  for Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comprehension of environmental traffic situation largely ensures the\ndriving safety of autonomous vehicles. Recently, the mission has been\ninvestigated by plenty of researches, while it is hard to be well addressed due\nto the limitation of collective influence in complex scenarios. These\napproaches model the interactions through the spatial relations between the\ntarget obstacle and its neighbors. However, they oversimplify the challenge\nsince the training stage of the interactions lacks effective supervision. As a\nresult, these models are far from promising. More intuitively, we transform the\nproblem into calculating the interaction-aware drivable spaces and propose the\nCNN-based VisionNet for trajectory prediction. The VisionNet accepts a sequence\nof motion states, i.e., location, velocity, and acceleration, to estimate the\nfuture drivable spaces. The reified interactions significantly increase the\ninterpretation ability of the VisionNet and refine the prediction. To further\nadvance the performance, we propose an interactive loss to guide the generation\nof the drivable spaces. Experiments on multiple public datasets demonstrate the\neffectiveness of the proposed VisionNet.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:29:53 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhu", "Yanliang", ""], ["Qian", "Deheng", ""], ["Ren", "Dongchun", ""], ["Xia", "Huaxia", ""]]}, {"id": "2001.02360", "submitter": "Yin-Cheng Yeh", "authors": "Yin-Cheng Yeh, Wen-Yi Hsiao, Satoru Fukayama, Tetsuro Kitahara,\n  Benjamin Genchel, Hao-Min Liu, Hao-Wen Dong, Yian Chen, Terence Leong, and\n  Yi-Hsuan Yang", "title": "Automatic Melody Harmonization with Triad Chords: A Comparative Study", "comments": "20 pages, 6 figures, published in Journal of New Music Research\n  (JNMR), Volume 50 Issue 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several prior works have proposed various methods for the task of automatic\nmelody harmonization, in which a model aims to generate a sequence of chords to\nserve as the harmonic accompaniment of a given multiple-bar melody sequence. In\nthis paper, we present a comparative study evaluating and comparing the\nperformance of a set of canonical approaches to this task, including a template\nmatching based model, a hidden Markov based model, a genetic algorithm based\nmodel, and two deep learning based models. The evaluation is conducted on a\ndataset of 9,226 melody/chord pairs we newly collect for this study,\nconsidering up to 48 triad chords, using a standardized training/test split. We\nreport the result of an objective evaluation using six different metrics and a\nsubjective study with 202 participants.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:47:33 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 08:48:22 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 10:03:07 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Yeh", "Yin-Cheng", ""], ["Hsiao", "Wen-Yi", ""], ["Fukayama", "Satoru", ""], ["Kitahara", "Tetsuro", ""], ["Genchel", "Benjamin", ""], ["Liu", "Hao-Min", ""], ["Dong", "Hao-Wen", ""], ["Chen", "Yian", ""], ["Leong", "Terence", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2001.02372", "submitter": "Bernhard Bermeitinger", "authors": "Simon Donig, Maria Christoforaki, Bernhard Bermeitinger, Siegfried\n  Handschuh", "title": "Multimodal Semantic Transfer from Text to Image. Fine-Grained Image\n  Classification by Distributional Semantics", "comments": "19 pages, second half in German as published in DHd2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last years, image classification processes like neural networks in the\narea of art-history and Heritage Informatics have experienced a broad\ndistribution (Lang and Ommer 2018). These methods face several challenges,\nincluding the handling of comparatively small amounts of data as well as\nhigh-dimensional data in the Digital Humanities. Here, a Convolutional Neural\nNetwork (CNN) is used that output is not, as usual, a series of flat text\nlabels but a series of semantically loaded vectors. These vectors result from a\nDistributional Semantic Model (DSM) which is generated from an in-domain text\ncorpus.\n  -----\n  In den letzten Jahren hat die Verwendung von Bildklassifizierungsverfahren\nwie neuronalen Netzwerken auch im Bereich der historischen Bildwissenschaften\nund der Heritage Informatics weite Verbreitung gefunden (Lang und Ommer 2018).\nDiese Verfahren stehen dabei vor einer Reihe von Herausforderungen, darunter\ndem Umgangmit den vergleichsweise kleinen Datenmengen sowie zugleich\nhochdimensionalen Da-tenr\\\"aumen in den digitalen Geisteswissenschaften. Meist\nbilden diese Methoden dieKlassifizierung auf einen vergleichsweise flachen Raum\nab. Dieser flache Zugang verliert im Bem\\\"uhen um ontologische Eindeutigkeit\neine Reihe von relevanten Dimensionen, darunter taxonomische, mereologische und\nassoziative Beziehungen zwischenden Klassen beziehungsweise dem nicht\nformalisierten Kontext. Dabei wird ein Convolutional Neural Network (CNN)\ngenutzt, dessen Ausgabe im Trainingsprozess, anders als herk\\\"ommlich, nicht\nauf einer Serie flacher Textlabel beruht, sondern auf einer Serie von Vektoren.\nDiese Vektoren resultieren aus einem Distributional Semantic Model (DSM),\nwelches aus einem Dom\\\"ane-Textkorpus generiert wird.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 14:26:06 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Donig", "Simon", ""], ["Christoforaki", "Maria", ""], ["Bermeitinger", "Bernhard", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "2001.02378", "submitter": "Runtian Zhai", "authors": "Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep\n  Ravikumar, Cho-Jui Hsieh, Liwei Wang", "title": "MACER: Attack-free and Scalable Robust Training via Maximizing Certified\n  Radius", "comments": "In ICLR 2020. 20 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is one of the most popular ways to learn robust models\nbut is usually attack-dependent and time costly. In this paper, we propose the\nMACER algorithm, which learns robust models without using adversarial training\nbut performs better than all existing provable l2-defenses. Recent work shows\nthat randomized smoothing can be used to provide a certified l2 radius to\nsmoothed classifiers, and our algorithm trains provably robust smoothed\nclassifiers via MAximizing the CErtified Radius (MACER). The attack-free\ncharacteristic makes MACER faster to train and easier to optimize. In our\nexperiments, we show that our method can be applied to modern deep neural\nnetworks on a wide range of datasets, including Cifar-10, ImageNet, MNIST, and\nSVHN. For all tasks, MACER spends less training time than state-of-the-art\nadversarial training algorithms, and the learned models achieve larger average\ncertified radius.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 05:08:56 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:28:05 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 03:02:26 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhai", "Runtian", ""], ["Dan", "Chen", ""], ["He", "Di", ""], ["Zhang", "Huan", ""], ["Gong", "Boqing", ""], ["Ravikumar", "Pradeep", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Liwei", ""]]}, {"id": "2001.02390", "submitter": "Corey Lammie", "authors": "Corey Lammie, Wei Xiang, Mostafa Rahimi Azghadi", "title": "Training Progressively Binarizing Deep Networks Using FPGAs", "comments": "Accepted at 2020 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": "2020 IEEE International Symposium on Circuits and Systems (ISCAS)", "doi": "10.1109/ISCAS45731.2020.9181099", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While hardware implementations of inference routines for Binarized Neural\nNetworks (BNNs) are plentiful, current realizations of efficient BNN hardware\ntraining accelerators, suitable for Internet of Things (IoT) edge devices,\nleave much to be desired. Conventional BNN hardware training accelerators\nperform forward and backward propagations with parameters adopting binary\nrepresentations, and optimization using parameters adopting floating or\nfixed-point real-valued representations--requiring two distinct sets of network\nparameters. In this paper, we propose a hardware-friendly training method that,\ncontrary to conventional methods, progressively binarizes a singular set of\nfixed-point network parameters, yielding notable reductions in power and\nresource utilizations. We use the Intel FPGA SDK for OpenCL development\nenvironment to train our progressively binarizing DNNs on an OpenVINO FPGA. We\nbenchmark our training approach on both GPUs and FPGAs using CIFAR-10 and\ncompare it to conventional BNNs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 06:01:13 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lammie", "Corey", ""], ["Xiang", "Wei", ""], ["Azghadi", "Mostafa Rahimi", ""]]}, {"id": "2001.02391", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Fang Chen, Bogdan Gabrys", "title": "An improved online learning algorithm for general fuzzy min-max neural\n  network", "comments": "9 pages, 8 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes an improved version of the current online learning\nalgorithm for a general fuzzy min-max neural network (GFMM) to tackle existing\nissues concerning expansion and contraction steps as well as the way of dealing\nwith unseen data located on decision boundaries. These drawbacks lower its\nclassification performance, so an improved algorithm is proposed in this study\nto address the above limitations. The proposed approach does not use the\ncontraction process for overlapping hyperboxes, which is more likely to\nincrease the error rate as shown in the literature. The empirical results\nindicated the improvement in the classification accuracy and stability of the\nproposed method compared to the original version and other fuzzy min-max\nclassifiers. In order to reduce the sensitivity to the training samples\npresentation order of this new on-line learning algorithm, a simple ensemble\nmethod is also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 06:24:40 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Chen", "Fang", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2001.02394", "submitter": "Gao Huang", "authors": "Gao Huang and Zhuang Liu and Geoff Pleiss and Laurens van der Maaten\n  and Kilian Q. Weinberger", "title": "Convolutional Networks with Dense Connectivity", "comments": "Journal(PAMI) version of DenseNet(CVPR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that convolutional networks can be substantially\ndeeper, more accurate, and efficient to train if they contain shorter\nconnections between layers close to the input and those close to the output. In\nthis paper, we embrace this observation and introduce the Dense Convolutional\nNetwork (DenseNet), which connects each layer to every other layer in a\nfeed-forward fashion.Whereas traditional convolutional networks with L layers\nhave L connections - one between each layer and its subsequent layer - our\nnetwork has L(L+1)/2 direct connections. For each layer, the feature-maps of\nall preceding layers are used as inputs, and its own feature-maps are used as\ninputs into all subsequent layers. DenseNets have several compelling\nadvantages: they alleviate the vanishing-gradient problem, encourage feature\nreuse and substantially improve parameter efficiency. We evaluate our proposed\narchitecture on four highly competitive object recognition benchmark tasks\n(CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant\nimprovements over the state-of-the-art on most of them, whilst requiring less\nparameters and computation to achieve high performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 06:54:53 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Huang", "Gao", ""], ["Liu", "Zhuang", ""], ["Pleiss", "Geoff", ""], ["van der Maaten", "Laurens", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2001.02399", "submitter": "Yurui Ming", "authors": "Yurui Ming, Dongrui Wu, Yu-Kai Wang, Yuhui Shi, Chin-Teng Lin", "title": "EEG-based Drowsiness Estimation for Driving Safety using Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fatigue is the most vital factor of road fatalities and one manifestation of\nfatigue during driving is drowsiness. In this paper, we propose using deep\nQ-learning to analyze an electroencephalogram (EEG) dataset captured during a\nsimulated endurance driving test. By measuring the correlation between\ndrowsiness and driving performance, this experiment represents an important\nbrain-computer interface (BCI) paradigm especially from an application\nperspective. We adapt the terminologies in the driving test to fit the\nreinforcement learning framework, thus formulate the drowsiness estimation\nproblem as an optimization of a Q-learning task. By referring to the latest\ndeep Q-Learning technologies and attending to the characteristics of EEG data,\nwe tailor a deep Q-network for action proposition that can indirectly estimate\ndrowsiness. Our results show that the trained model can trace the variations of\nmind state in a satisfactory way against the testing EEG data, which\ndemonstrates the feasibility and practicability of this new computation\nparadigm. We also show that our method outperforms the supervised learning\ncounterpart and is superior for real applications. To the best of our\nknowledge, we are the first to introduce the deep reinforcement learning method\nto this BCI scenario, and our method can be potentially generalized to other\nBCI cases.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:10:03 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 12:37:46 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ming", "Yurui", ""], ["Wu", "Dongrui", ""], ["Wang", "Yu-Kai", ""], ["Shi", "Yuhui", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2001.02400", "submitter": "Minh Tu Hoang", "authors": "Minh Tu Hoang, Brosnan Yuen, Xiaodai Dong, Tao Lu, Robert Westendorp,\n  and Kishore Reddy", "title": "Semi-Sequential Probabilistic Model For Indoor Localization Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a semi-sequential probabilistic model (SSP) that applies\nan additional short term memory to enhance the performance of the probabilistic\nindoor localization. The conventional probabilistic methods normally treat the\nlocations in the database indiscriminately. In contrast, SSP leverages the\ninformation of the previous position to determine the probable location since\nthe user's speed in an indoor environment is bounded and locations near the\nprevious one have higher probability than the other locations. Although the SSP\nutilizes the previous location information, it does not require the exact\nmoving speed and direction of the user. On-site experiments using the received\nsignal strength indicator (RSSI) and channel state information (CSI)\nfingerprints for localization demonstrate that SSP reduces the maximum error\nand boosts the performance of existing probabilistic approaches by 25% - 30%.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:22:02 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Hoang", "Minh Tu", ""], ["Yuen", "Brosnan", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""], ["Westendorp", "Robert", ""], ["Reddy", "Kishore", ""]]}, {"id": "2001.02407", "submitter": "Yi-Fu Wu", "authors": "Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam\n  Singh, Fei Deng, Jindong Jiang, Sungjin Ahn", "title": "SPACE: Unsupervised Object-Oriented Scene Representation via Spatial\n  Attention and Decomposition", "comments": "Accepted in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to decompose complex multi-object scenes into meaningful\nabstractions like objects is fundamental to achieve higher-level cognition.\nPrevious approaches for unsupervised object-oriented scene representation\nlearning are either based on spatial-attention or scene-mixture approaches and\nlimited in scalability which is a main obstacle towards modeling real-world\nscenes. In this paper, we propose a generative latent variable model, called\nSPACE, that provides a unified probabilistic modeling framework that combines\nthe best of spatial-attention and scene-mixture approaches. SPACE can\nexplicitly provide factorized object representations for foreground objects\nwhile also decomposing background segments of complex morphology. Previous\nmodels are good at either of these, but not both. SPACE also resolves the\nscalability problems of previous methods by incorporating parallel\nspatial-attention and thus is applicable to scenes with a large number of\nobjects without performance degradations. We show through experiments on Atari\nand 3D-Rooms that SPACE achieves the above properties consistently in\ncomparison to SPAIR, IODINE, and GENESIS. Results of our experiments can be\nfound on our project website: https://sites.google.com/view/space-project-page\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 07:44:32 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 19:09:05 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 20:21:38 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lin", "Zhixuan", ""], ["Wu", "Yi-Fu", ""], ["Peri", "Skand Vishwanath", ""], ["Sun", "Weihao", ""], ["Singh", "Gautam", ""], ["Deng", "Fei", ""], ["Jiang", "Jindong", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2001.02431", "submitter": "Marco Mamprin Mr.", "authors": "Marco Mamprin, Jo M. Zelis, Pim A.L. Tonino, Svitlana Zinger, Peter\n  H.N. de With", "title": "Gradient Boosting on Decision Trees for Mortality Prediction in\n  Transcatheter Aortic Valve Implantation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current prognostic risk scores in cardiac surgery are based on statistics and\ndo not yet benefit from machine learning. Statistical predictors are not robust\nenough to correctly identify patients who would benefit from Transcatheter\nAortic Valve Implantation (TAVI). This research aims to create a machine\nlearning model to predict one-year mortality of a patient after TAVI. We adopt\na modern gradient boosting on decision trees algorithm, specifically designed\nfor categorical features. In combination with a recent technique for model\ninterpretations, we developed a feature analysis and selection stage, enabling\nto identify the most important features for the prediction. We base our\nprediction model on the most relevant features, after interpreting and\ndiscussing the feature analysis results with clinical experts. We validated our\nmodel on 270 TAVI cases, reaching an AUC of 0.83. Our approach outperforms\nseveral widespread prognostic risk scores, such as logistic EuroSCORE II, the\nSTS risk score and the TAVI2-score, which are broadly adopted by cardiologists\nworldwide.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:04:42 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Mamprin", "Marco", ""], ["Zelis", "Jo M.", ""], ["Tonino", "Pim A. L.", ""], ["Zinger", "Svitlana", ""], ["de With", "Peter H. N.", ""]]}, {"id": "2001.02435", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Joao Carvalho, Hany Abdulsamad, Jan Peters", "title": "A Nonparametric Off-Policy Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms still suffer from high sample\ncomplexity despite outstanding recent successes. The need for intensive\ninteractions with the environment is especially observed in many widely popular\npolicy gradient algorithms that perform updates using on-policy samples. The\nprice of such inefficiency becomes evident in real-world scenarios such as\ninteraction-driven robot learning, where the success of RL has been rather\nlimited. We address this issue by building on the general sample efficiency of\noff-policy algorithms. With nonparametric regression and density estimation\nmethods we construct a nonparametric Bellman equation in a principled manner,\nwhich allows us to obtain closed-form estimates of the value function, and to\nanalytically express the full policy gradient. We provide a theoretical\nanalysis of our estimate to show that it is consistent under mild smoothness\nassumptions and empirically show that our approach has better sample efficiency\nthan state-of-the-art policy gradient methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:13:08 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 15:03:39 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 11:30:38 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tosatto", "Samuele", ""], ["Carvalho", "Joao", ""], ["Abdulsamad", "Hany", ""], ["Peters", "Jan", ""]]}, {"id": "2001.02438", "submitter": "Shruti Tople", "authors": "Bijeeta Pal and Shruti Tople", "title": "To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, \"can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?\" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:26:55 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Pal", "Bijeeta", ""], ["Tople", "Shruti", ""]]}, {"id": "2001.02444", "submitter": "Ajitha Rajan", "authors": "Foivos Tsimpourlas, Ajitha Rajan, Miltiadis Allamanis", "title": "Learning to Encode and Classify Test Executions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of automatically determining the correctness of test executions\nis referred to as the test oracle problem and is one of the key remaining\nissues for automated testing. The goal in this paper is to solve the test\noracle problem in a way that is general, scalable and accurate.\n  To achieve this, we use supervised learning over test execution traces. We\nlabel a small fraction of the execution traces with their verdict of pass or\nfail. We use the labelled traces to train a neural network (NN) model to learn\nto distinguish runtime patterns for passing versus failing executions for a\ngiven program. Our approach for building this NN model involves the following\nsteps, 1. Instrument the program to record execution traces as sequences of\nmethod invocations and global state, 2. Label a small fraction of the execution\ntraces with their verdicts, 3. Designing a NN component that embeds information\nin execution traces to fixed length vectors, 4. Design a NN model that uses the\ntrace information for classification, 5. Evaluate the inferred classification\nmodel on unseen execution traces from the program.\n  We evaluate our approach using case studies from different application\ndomains: 1. Module from Ethereum Blockchain, 2. Module from PyTorch deep\nlearning framework, 3. Microsoft SEAL encryption library components, 4. Sed\nstream editor, 5. Value pointer library and 6. Nine network protocols from\nLinux packet identifier, L7-Filter. We found the classification models for all\nsubject programs resulted in high precision, recall and specificity, over 95%,\nwhile only training with an average 9% of the total traces. Our experiments\nshow that the proposed neural network model is highly effective as a test\noracle and is able to learn runtime patterns to distinguish passing and failing\ntest executions for systems and tests from different application domains.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:53:45 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Tsimpourlas", "Foivos", ""], ["Rajan", "Ajitha", ""], ["Allamanis", "Miltiadis", ""]]}, {"id": "2001.02463", "submitter": "Hyun-Suk Lee", "authors": "Hyun-Suk Lee, Cong Shen, James Jordon, Mihaela van der Schaar", "title": "Contextual Constrained Learning for Dose-Finding Clinical Trials", "comments": "18 pages, 5 figures, in Proceedings of the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020, Palermo,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials in the medical domain are constrained by budgets. The number\nof patients that can be recruited is therefore limited. When a patient\npopulation is heterogeneous, this creates difficulties in learning subgroup\nspecific responses to a particular drug and especially for a variety of\ndosages. In addition, patient recruitment can be difficult by the fact that\nclinical trials do not aim to provide a benefit to any given patient in the\ntrial. In this paper, we propose C3T-Budget, a contextual constrained clinical\ntrial algorithm for dose-finding under both budget and safety constraints. The\nalgorithm aims to maximize drug efficacy within the clinical trial while also\nlearning about the drug being tested. C3T-Budget recruits patients with\nconsideration of the remaining budget, the remaining time, and the\ncharacteristics of each group, such as the population distribution, estimated\nexpected efficacy, and estimation credibility. In addition, the algorithm aims\nto avoid unsafe dosages. These characteristics are further illustrated in a\nsimulated clinical trial study, which corroborates the theoretical analysis and\ndemonstrates an efficient budget usage as well as a balanced learning-treatment\ntrade-off.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 11:46:48 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 00:24:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lee", "Hyun-Suk", ""], ["Shen", "Cong", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.02469", "submitter": "Yixing Huang", "authors": "Yixing Huang, Shengxiang Wang, Yong Guan, Andreas Maier", "title": "Limited Angle Tomography for Transmission X-Ray Microscopy Using Deep\n  Learning", "comments": null, "journal-ref": "Journal of Synchrotron Radiation 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In transmission X-ray microscopy (TXM) systems, the rotation of a scanned\nsample might be restricted to a limited angular range to avoid collision to\nother system parts or high attenuation at certain tilting angles. Image\nreconstruction from such limited angle data suffers from artifacts due to\nmissing data. In this work, deep learning is applied to limited angle\nreconstruction in TXMs for the first time. With the challenge to obtain\nsufficient real data for training, training a deep neural network from\nsynthetic data is investigated. Particularly, the U-Net, the state-of-the-art\nneural network in biomedical imaging, is trained from synthetic ellipsoid data\nand multi-category data to reduce artifacts in filtered back-projection (FBP)\nreconstruction images. The proposed method is evaluated on synthetic data and\nreal scanned chlorella data in $100^\\circ$ limited angle tomography. For\nsynthetic test data, the U-Net significantly reduces root-mean-square error\n(RMSE) from $2.55 \\times 10^{-3}$ {\\mu}m$^{-1}$ in the FBP reconstruction to\n$1.21 \\times 10^{-3}$ {\\mu}m$^{-1}$ in the U-Net reconstruction, and also\nimproves structural similarity (SSIM) index from 0.625 to 0.920. With penalized\nweighted least square denoising of measured projections, the RMSE and SSIM are\nfurther improved to $1.16 \\times 10^{-3}$ {\\mu}m$^{-1}$ and 0.932,\nrespectively. For real test data, the proposed method remarkably improves the\n3-D visualization of the subcellular structures in the chlorella cell, which\nindicates its important value for nano-scale imaging in biology, nanoscience\nand materials science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:11:19 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Huang", "Yixing", ""], ["Wang", "Shengxiang", ""], ["Guan", "Yong", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.02472", "submitter": "Xi He", "authors": "Xi He", "title": "Quantum subspace alignment for domain adaptation", "comments": "8 pages, 1 figures", "journal-ref": null, "doi": "10.1103/PhysRevA.102.062403", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) is used for adaptively obtaining labels of an\nunprocessed data set with a given related, but different labelled data set.\nSubspace alignment (SA), a representative DA algorithm, attempts to find a\nlinear transformation to align the subspaces of the two different data sets.\nThe classifier trained on the aligned labelled data set can be transferred to\nthe unlabelled data set to predict the target labels. In this paper, two\nquantum versions of the SA are proposed to implement the DA procedure on\nquantum devices. One method, the quantum subspace alignment algorithm (QSA),\nachieves quadratic speedup in the number and dimension of given samples. The\nother method, the variational quantum subspace alignment algorithm (VQSA), can\nbe implemented on the near term quantum devices through a variational hybrid\nquantum-classical procedure. The results of the numerical experiments on\ndifferent types of datasets demonstrate that the VQSA can achieve competitive\nperformance compared with the corresponding classical algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:15:19 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 02:51:22 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["He", "Xi", ""]]}, {"id": "2001.02478", "submitter": "Q.Vera Liao", "authors": "Q. Vera Liao, Daniel Gruen, Sarah Miller", "title": "Questioning the AI: Informing Design Practices for Explainable AI User\n  Experiences", "comments": "Working draft. To appear in the ACM CHI Conference on Human Factors\n  in Computing Systems (CHI 2020)", "journal-ref": null, "doi": "10.1145/3313831.3376590", "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surge of interest in explainable AI (XAI) has led to a vast collection of\nalgorithmic work on the topic. While many recognize the necessity to\nincorporate explainability features in AI systems, how to address real-world\nuser needs for understanding AI remains an open question. By interviewing 20 UX\nand design practitioners working on various AI products, we seek to identify\ngaps between the current XAI algorithmic work and practices to create\nexplainable AI products. To do so, we develop an algorithm-informed XAI\nquestion bank in which user needs for explainability are represented as\nprototypical questions users might ask about the AI, and use it as a study\nprobe. Our work contributes insights into the design space of XAI, informs\nefforts to support design practices in this space, and identifies opportunities\nfor future XAI work. We also provide an extended XAI question bank and discuss\nhow it can be used for creating user-centered XAI.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:34:51 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 21:44:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liao", "Q. Vera", ""], ["Gruen", "Daniel", ""], ["Miller", "Sarah", ""]]}, {"id": "2001.02492", "submitter": "Saif Jabari", "authors": "Wenqing Li, Chuhan Yang, and Saif Eddin Jabari", "title": "Nonlinear Traffic Prediction as a Matrix Completion Problem with\n  Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of short-term traffic prediction for\nsignalized traffic operations management. Specifically, we focus on predicting\nsensor states in high-resolution (second-by-second). This contrasts with\ntraditional traffic forecasting problems, which have focused on predicting\naggregated traffic variables, typically over intervals that are no shorter than\n5 minutes. Our contributions can be summarized as offering three insights:\nfirst, we show how the prediction problem can be modeled as a matrix completion\nproblem. Second, we employ a block-coordinate descent algorithm and demonstrate\nthat the algorithm converges in sub-linear time to a block coordinate-wise\noptimizer. This allows us to capitalize on the \"bigness\" of high-resolution\ndata in a computationally feasible way. Third, we develop an ensemble learning\n(or adaptive boosting) approach to reduce the training error to within any\narbitrary error threshold. The latter utilizes past days so that the boosting\ncan be interpreted as capturing periodic patterns in the data. The performance\nof the proposed method is analyzed theoretically and tested empirically using\nboth simulated data and a real-world high-resolution traffic dataset from Abu\nDhabi, UAE. Our experimental results show that the proposed method outperforms\nother state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:10:40 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 07:08:15 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 19:09:52 GMT"}, {"version": "v4", "created": "Sat, 10 Jul 2021 12:30:38 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Li", "Wenqing", ""], ["Yang", "Chuhan", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2001.02498", "submitter": "Hanqing Zeng", "authors": "Hanqing Zeng, Viktor Prasanna", "title": "GraphACT: Accelerating GCN Training on CPU-FPGA Heterogeneous Platforms", "comments": "Published in ACM/SIGDA FPGA '20", "journal-ref": null, "doi": "10.1145/3373087.3375312", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art deep\nlearning model for representation learning on graphs. It is challenging to\naccelerate training of GCNs, due to (1) substantial and irregular data\ncommunication to propagate information within the graph, and (2) intensive\ncomputation to propagate information along the neural network layers. To\naddress these challenges, we design a novel accelerator for training GCNs on\nCPU-FPGA heterogeneous systems, by incorporating multiple\nalgorithm-architecture co-optimizations. We first analyze the computation and\ncommunication characteristics of various GCN training algorithms, and select a\nsubgraph-based algorithm that is well suited for hardware execution. To\noptimize the feature propagation within subgraphs, we propose a lightweight\npre-processing step based on a graph theoretic approach. Such pre-processing\nperformed on the CPU significantly reduces the memory access requirements and\nthe computation to be performed on the FPGA. To accelerate the weight update in\nGCN layers, we propose a systolic array based design for efficient\nparallelization. We integrate the above optimizations into a complete hardware\npipeline, and analyze its load-balance and resource utilization by accurate\nperformance modeling. We evaluate our design on a Xilinx Alveo U200 board\nhosted by a 40-core Xeon server. On three large graphs, we achieve an order of\nmagnitude training speedup with negligible accuracy loss, compared with\nstate-of-the-art implementation on a multi-core platform.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 21:19:01 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zeng", "Hanqing", ""], ["Prasanna", "Viktor", ""]]}, {"id": "2001.02520", "submitter": "Azam Rabiee", "authors": "Marzieh Pourhojjati-Sabet and Azam Rabiee", "title": "A Soft Recommender System for Social Networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent social recommender systems benefit from friendship graph to make an\naccurate recommendation, believing that friends in a social network have\nexactly the same interests and preferences. Some studies have benefited from\nhard clustering algorithms (such as K-means) to determine the similarity\nbetween users and consequently to define degree of friendships. In this paper,\nwe went a step further to identify true friends for making even more realistic\nrecommendations. we calculated the similarity between users, as well as the\ndependency between a user and an item. Our hypothesis is that due to the\nuncertainties in user preferences, the fuzzy clustering, instead of the\nclassical hard clustering, is beneficial in accurate recommendations. We\nincorporated the C-means algorithm to get different membership degrees of soft\nusers' clusters. Then, the users' similarity metric is defined according to the\nsoft clusters. Later, in a training scheme we determined the latent\nrepresentations of users and items, extracting from the huge and sparse\nuser-item-tag matrix using matrix factorization. In the parameter tuning, we\nfound the optimum coefficients for the influence of our soft social\nregularization and the user-item dependency terms. Our experimental results\nconvinced that the proposed fuzzy similarity metric improves the\nrecommendations in real data compared to the baseline social recommender system\nwith the hard clustering.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:38:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Pourhojjati-Sabet", "Marzieh", ""], ["Rabiee", "Azam", ""]]}, {"id": "2001.02522", "submitter": "Fenglei Fan", "authors": "Fenglei Fan, Jinjun Xiong, Mengzhou Li, and Ge Wang", "title": "On Interpretability of Artificial Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as represented by the artificial deep neural networks (DNNs)\nhas achieved great success in many important areas that deal with text, images,\nvideos, graphs, and so on. However, the black-box nature of DNNs has become one\nof the primary obstacles for their wide acceptance in mission-critical\napplications such as medical diagnosis and therapy. Due to the huge potential\nof deep learning, interpreting neural networks has recently attracted much\nresearch attention. In this paper, based on our comprehensive taxonomy, we\nsystematically review recent studies in understanding the mechanism of neural\nnetworks, describe applications of interpretability especially in medicine, and\ndiscuss future directions of interpretability research, such as in relation to\nfuzzy logic and brain science.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:40:42 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 22:55:52 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 15:59:45 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Fenglei", ""], ["Xiong", "Jinjun", ""], ["Li", "Mengzhou", ""], ["Wang", "Ge", ""]]}, {"id": "2001.02539", "submitter": "Seungwoong Ha", "authors": "Seungwoong Ha, Hawoong Jeong", "title": "Deep learning reveals hidden interactions in complex systems", "comments": "17 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Rich phenomena from complex systems have long intrigued researchers, and yet\nmodeling system micro-dynamics and inferring the forms of interaction remain\nchallenging for conventional data-driven approaches, being generally\nestablished by human scientists. In this study, we propose AgentNet, a\nmodel-free data-driven framework consisting of deep neural networks to reveal\nand analyze the hidden interactions in complex systems from observed data\nalone. AgentNet utilizes a graph attention network with novel variable-wise\nattention to model the interaction between individual agents, and employs\nvarious encoders and decoders that can be selectively applied to any desired\nsystem. Our model successfully captured a wide variety of simulated complex\nsystems, namely cellular automata (discrete), the Vicsek model (continuous),\nand active Ornstein--Uhlenbeck particles (non-Markovian) in which, notably,\nAgentNet's visualized attention values coincided with the true interaction\nstrength and exhibited collective behavior that was absent in the training\ndata. A demonstration with empirical data from a flock of birds showed that\nAgentNet could identify hidden interaction ranges exhibited by real birds,\nwhich cannot be detected by conventional velocity correlation analysis. We\nexpect our framework to open a novel path to investigating complex systems and\nto provide insight into general process-driven modeling.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 02:25:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 01:20:21 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 16:07:10 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 08:33:30 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ha", "Seungwoong", ""], ["Jeong", "Hawoong", ""]]}, {"id": "2001.02568", "submitter": "Xishun Wang", "authors": "Xishun Wang and Zhouwang Yang and Xingye Yue and Hui Wang", "title": "A Group Norm Regularized Factorization Model for Subspace Segmentation", "comments": null, "journal-ref": "IEEE ACCESS,8:106601-106613,2020", "doi": "10.1109/ACCESS.2020.3000816", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace segmentation assumes that data comes from the union of different\nsubspaces and the purpose of segmentation is to partition the data into the\ncorresponding subspace. Low-rank representation (LRR) is a classic\nspectral-type method for solving subspace segmentation problems, that is, one\nfirst obtains an affinity matrix by solving a LRR model and then performs\nspectral clustering for segmentation. This paper proposes a group norm\nregularized factorization model (GNRFM) inspired by the LRR model for subspace\nsegmentation and then designs an Accelerated Augmented Lagrangian Method (AALM)\nalgorithm to solve this model. Specifically, we adopt group norm regularization\nto make the columns of the factor matrix sparse, thereby achieving a purpose of\nlow rank, which means no Singular Value Decompositions (SVD) are required and\nthe computational complexity of each step is greatly reduced. We obtain\naffinity matrices by using different LRR models and then performing cluster\ntesting on different sets of synthetic noisy data and real data, respectively.\nCompared with traditional models and algorithms, the proposed method is faster\nand more robust to noise, so the final clustering results are better. Moreover,\nthe numerical results show that our algorithm converges fast and only requires\napproximately ten iterations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:20:51 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 09:13:40 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Wang", "Xishun", ""], ["Yang", "Zhouwang", ""], ["Yue", "Xingye", ""], ["Wang", "Hui", ""]]}, {"id": "2001.02585", "submitter": "Zhaozhi Qian", "authors": "Zhaozhi Qian, Ahmed M. Alaa, Alexis Bellot, Jem Rashbass, Mihaela van\n  der Schaar", "title": "Learning Dynamic and Personalized Comorbidity Networks from Event Data\n  using Deep Diffusion Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comorbid diseases co-occur and progress via complex temporal patterns that\nvary among individuals. In electronic health records we can observe the\ndifferent diseases a patient has, but can only infer the temporal relationship\nbetween each co-morbid condition. Learning such temporal patterns from event\ndata is crucial for understanding disease pathology and predicting prognoses.\nTo this end, we develop deep diffusion processes (DDP) to model \"dynamic\ncomorbidity networks\", i.e., the temporal relationships between comorbid\ndisease onsets expressed through a dynamic graph. A DDP comprises events\nmodelled as a multi-dimensional point process, with an intensity function\nparameterized by the edges of a dynamic weighted graph. The graph structure is\nmodulated by a neural network that maps patient history to edge weights,\nenabling rich temporal representations for disease trajectories. The DDP\nparameters decouple into clinically meaningful components, which enables\nserving the dual purpose of accurate risk prediction and intelligible\nrepresentation of disease pathology. We illustrate these features in\nexperiments using cancer registry data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:47:08 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 14:44:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qian", "Zhaozhi", ""], ["Alaa", "Ahmed M.", ""], ["Bellot", "Alexis", ""], ["Rashbass", "Jem", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.02589", "submitter": "Dominic Lennon", "authors": "H. Moon, D.T. Lennon, J. Kirkpatrick, N.M. van Esbroeck, L.C.\n  Camenzind, Liuqi Yu, F. Vigneau, D.M. Zumb\\\"uhl, G.A.D. Briggs, M.A Osborne,\n  D. Sejdinovic, E.A. Laird, and N. Ares", "title": "Machine learning enables completely automatic tuning of a quantum device\n  faster than human experts", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-17835-9", "report-no": null, "categories": "cond-mat.mes-hall cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Device variability is a bottleneck for the scalability of semiconductor\nquantum devices. Increasing device control comes at the cost of a large\nparameter space that has to be explored in order to find the optimal operating\nconditions. We demonstrate a statistical tuning algorithm that navigates this\nentire parameter space, using just a few modelling assumptions, in the search\nfor specific electron transport features. We focused on gate-defined quantum\ndot devices, demonstrating fully automated tuning of two different devices to\ndouble quantum dot regimes in an up to eight-dimensional gate voltage space. We\nconsidered a parameter space defined by the maximum range of each gate voltage\nin these devices, demonstrating expected tuning in under 70 minutes. This\nperformance exceeded a human benchmark, although we recognise that there is\nroom for improvement in the performance of both humans and machines. Our\napproach is approximately 180 times faster than a pure random search of the\nparameter space, and it is readily applicable to different material systems and\ndevice architectures. With an efficient navigation of the gate voltage space we\nare able to give a quantitative measurement of device variability, from one\ndevice to another and after a thermal cycle of a device. This is a key\ndemonstration of the use of machine learning techniques to explore and optimise\nthe parameter space of quantum devices and overcome the challenge of device\nvariability.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:58:59 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Moon", "H.", ""], ["Lennon", "D. T.", ""], ["Kirkpatrick", "J.", ""], ["van Esbroeck", "N. M.", ""], ["Camenzind", "L. C.", ""], ["Yu", "Liuqi", ""], ["Vigneau", "F.", ""], ["Zumb\u00fchl", "D. M.", ""], ["Briggs", "G. A. D.", ""], ["Osborne", "M. A", ""], ["Sejdinovic", "D.", ""], ["Laird", "E. A.", ""], ["Ares", "N.", ""]]}, {"id": "2001.02600", "submitter": "Peng Xu", "authors": "Peng Xu, Timothy M. Hospedales, Qiyue Yin, Yi-Zhe Song, Tao Xiang,\n  Liang Wang", "title": "Deep Learning for Free-Hand Sketch: A Survey and A Toolbox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free-hand sketches are highly illustrative, and have been widely used by\nhumans to depict objects or stories from ancient times to the present. The\nrecent prevalence of touchscreen devices has made sketch creation a much easier\ntask than ever and consequently made sketch-oriented applications increasingly\npopular. The progress of deep learning has immensely benefited free-hand sketch\nresearch and applications. This paper presents a comprehensive survey of the\ndeep learning techniques oriented at free-hand sketch data, and the\napplications that they enable. The main contents of this survey include: (i) A\ndiscussion of the intrinsic traits and unique challenges of free-hand sketch,\nto highlight the essential differences between sketch data and other data\nmodalities, e.g., natural photos. (ii) A review of the developments of\nfree-hand sketch research in the deep learning era, by surveying existing\ndatasets, research topics, and the state-of-the-art methods through a detailed\ntaxonomy and experimental evaluation. (iii) Promotion of future work via a\ndiscussion of bottlenecks, open problems, and potential research directions for\nthe community. Finally, to support future sketch research and applications, we\ncontribute TorchSketch -- the first sketch-oriented open-source deep learning\nlibrary, which is built on PyTorch and available at\nhttps://github.com/PengBoXiangShang/torchsketch/.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:23:56 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 14:23:27 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xu", "Peng", ""], ["Hospedales", "Timothy M.", ""], ["Yin", "Qiyue", ""], ["Song", "Yi-Zhe", ""], ["Xiang", "Tao", ""], ["Wang", "Liang", ""]]}, {"id": "2001.02610", "submitter": "Bo Zhao", "authors": "Bo Zhao, Konda Reddy Mopuri, Hakan Bilen", "title": "iDLG: Improved Deep Leakage from Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that sharing gradients will not leak private training\ndata in distributed learning systems such as Collaborative Learning and\nFederated Learning, etc. Recently, Zhu et al. presented an approach which shows\nthe possibility to obtain private training data from the publicly shared\ngradients. In their Deep Leakage from Gradient (DLG) method, they synthesize\nthe dummy data and corresponding labels with the supervision of shared\ngradients. However, DLG has difficulty in convergence and discovering the\nground-truth labels consistently. In this paper, we find that sharing gradients\ndefinitely leaks the ground-truth labels. We propose a simple but reliable\napproach to extract accurate data from the gradients. Particularly, our\napproach can certainly extract the ground-truth labels as opposed to DLG, hence\nwe name it Improved DLG (iDLG). Our approach is valid for any differentiable\nmodel trained with cross-entropy loss over one-hot labels. We mathematically\nillustrate how our method can extract ground-truth labels from the gradients\nand empirically demonstrate the advantages over DLG.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:45:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Zhao", "Bo", ""], ["Mopuri", "Konda Reddy", ""], ["Bilen", "Hakan", ""]]}, {"id": "2001.02613", "submitter": "Vaishakh Patil", "authors": "Vaishakh Patil, Wouter Van Gansbeke, Dengxin Dai, Luc Van Gool", "title": "Don't Forget The Past: Recurrent Depth Estimation from Monocular Video", "comments": "Please refer to our webpage for details\n  https://www.trace.ethz.ch/publications/2020/rec_depth_estimation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous cars need continuously updated depth information. Thus far, depth\nis mostly estimated independently for a single frame at a time, even if the\nmethod starts from video input. Our method produces a time series of depth\nmaps, which makes it an ideal candidate for online learning approaches. In\nparticular, we put three different types of depth estimation (supervised depth\nprediction, self-supervised depth prediction, and self-supervised depth\ncompletion) into a common framework. We integrate the corresponding networks\nwith a ConvLSTM such that the spatiotemporal structures of depth across frames\ncan be exploited to yield a more accurate depth estimation. Our method is\nflexible. It can be applied to monocular videos only or be combined with\ndifferent types of sparse depth patterns. We carefully study the architecture\nof the recurrent network and its training strategy. We are first to\nsuccessfully exploit recurrent networks for real-time self-supervised monocular\ndepth estimation and completion. Extensive experiments show that our recurrent\nmethod outperforms its image-based counterpart consistently and significantly\nin both self-supervised scenarios. It also outperforms previous depth\nestimation methods of the three popular groups. Please refer to\nhttps://www.trace.ethz.ch/publications/2020/rec_depth_estimation/ for details.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:50:51 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 10:27:13 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Patil", "Vaishakh", ""], ["Van Gansbeke", "Wouter", ""], ["Dai", "Dengxin", ""], ["Van Gool", "Luc", ""]]}, {"id": "2001.02652", "submitter": "Rahul Singh", "authors": "Rahul Singh, Keuntaek Lee, Yongxin Chen", "title": "Sample-based Distributional Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional reinforcement learning (DRL) is a recent reinforcement\nlearning framework whose success has been supported by various empirical\nstudies. It relies on the key idea of replacing the expected return with the\nreturn distribution, which captures the intrinsic randomness of the long term\nrewards. Most of the existing literature on DRL focuses on problems with\ndiscrete action space and value based methods. In this work, motivated by\napplications in robotics with continuous action space control settings, we\npropose sample-based distributional policy gradient (SDPG) algorithm. It models\nthe return distribution using samples via a reparameterization technique widely\nused in generative modeling and inference. We compare SDPG with the\nstate-of-art policy gradient method in DRL, distributed distributional\ndeterministic policy gradients (D4PG), which has demonstrated state-of-art\nperformance. We apply SDPG and D4PG to multiple OpenAI Gym environments and\nobserve that our algorithm shows better sample efficiency as well as higher\nreward for most tasks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:50:23 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Singh", "Rahul", ""], ["Lee", "Keuntaek", ""], ["Chen", "Yongxin", ""]]}, {"id": "2001.02656", "submitter": "David Tolpin", "authors": "David Tolpin, Tomer Dobkin", "title": "Stochastic Probabilistic Programs", "comments": "7 pages main body, 4 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of a stochastic probabilistic program and present a\nreference implementation of a probabilistic programming facility supporting\nspecification of stochastic probabilistic programs and inference in them.\nStochastic probabilistic programs allow straightforward specification and\nefficient inference in models with nuisance parameters, noise, and\nnondeterminism. We give several examples of stochastic probabilistic programs,\nand compare the programs with corresponding deterministic probabilistic\nprograms in terms of model specification and inference. We conclude with\ndiscussion of open research topics and related work.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:54:40 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 07:14:20 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 16:02:56 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tolpin", "David", ""], ["Dobkin", "Tomer", ""]]}, {"id": "2001.02658", "submitter": "Lucas Fidon", "authors": "Lucas Fidon, Sebastien Ourselin, Tom Vercauteren", "title": "Distributionally Robust Deep Learning using Hardness Weighted Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limiting failures of machine learning systems is vital for safety-critical\napplications. In order to improve the robustness of machine learning systems,\nDistributionally Robust Optimization (DRO) has been proposed as a\ngeneralization of Empirical Risk Minimization (ERM)aiming at addressing this\nneed. However, its use in deep learning has been severely restricted due to the\nrelative inefficiency of the optimizers available for DRO in comparison to the\nwide-spread variants of Stochastic Gradient Descent (SGD) optimizers for ERM.\nWe propose SGD with hardness weighted sampling, a principled and efficient\noptimization method for DRO in machine learning that is particularly suited in\nthe context of deep learning. Similar to a hard example mining strategy in\nessence and in practice, the proposed algorithm is straightforward to implement\nand computationally as efficient as SGD-based optimizers used for deep\nlearning, requiring minimal overhead computation. In contrast to typical ad hoc\nhard mining approaches, and exploiting recent theoretical results in deep\nlearning optimization, we prove the convergence of our DRO algorithm for\nover-parameterized deep learning networks with ReLU activation and finite\nnumber of layers and parameters. Our experiments on brain tumor segmentation in\nMRI demonstrate the feasibility and the usefulness of our approach. Using our\nhardness weighted sampling leads to a decrease of 2% of the interquartile range\nof the Dice scores for the enhanced tumor and the tumor core regions. The code\nfor the proposed hard weighted sampler will be made publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:02:56 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 09:43:22 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Fidon", "Lucas", ""], ["Ourselin", "Sebastien", ""], ["Vercauteren", "Tom", ""]]}, {"id": "2001.02669", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Manish Sharma, Vijaya Saradhi", "title": "A Correspondence Analysis Framework for Author-Conference\n  Recommendations", "comments": "49 pages including references, 6 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many years, achievements and discoveries made by scientists are made\naware through research papers published in appropriate journals or conferences.\nOften, established scientists and especially newbies are caught up in the\ndilemma of choosing an appropriate conference to get their work through. Every\nscientific conference and journal is inclined towards a particular field of\nresearch and there is a vast multitude of them for any particular field.\nChoosing an appropriate venue is vital as it helps in reaching out to the right\naudience and also to further one's chance of getting their paper published. In\nthis work, we address the problem of recommending appropriate conferences to\nthe authors to increase their chances of acceptance. We present three different\napproaches for the same involving the use of social network of the authors and\nthe content of the paper in the settings of dimensionality reduction and topic\nmodeling. In all these approaches, we apply Correspondence Analysis (CA) to\nderive appropriate relationships between the entities in question, such as\nconferences and papers. Our models show promising results when compared with\nexisting methods such as content-based filtering, collaborative filtering and\nhybrid filtering.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:52:39 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Sharma", "Manish", ""], ["Saradhi", "Vijaya", ""]]}, {"id": "2001.02674", "submitter": "Niko Moritz", "authors": "Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Streaming automatic speech recognition with the transformer model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder based sequence-to-sequence models have demonstrated\nstate-of-the-art results in end-to-end automatic speech recognition (ASR).\nRecently, the transformer architecture, which uses self-attention to model\ntemporal context information, has been shown to achieve significantly lower\nword error rates (WERs) compared to recurrent neural network (RNN) based system\narchitectures. Despite its success, the practical usage is limited to offline\nASR tasks, since encoder-decoder architectures typically require an entire\nspeech utterance as input. In this work, we propose a transformer based\nend-to-end ASR system for streaming ASR, where an output must be generated\nshortly after each spoken word. To achieve this, we apply time-restricted\nself-attention for the encoder and triggered attention for the encoder-decoder\nattention mechanism. Our proposed streaming transformer architecture achieves\n2.8% and 7.2% WER for the \"clean\" and \"other\" test data of LibriSpeech, which\nto our knowledge is the best published streaming end-to-end ASR result for this\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:58:02 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 16:08:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 15:10:13 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 21:34:25 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 18:29:07 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2001.02712", "submitter": "Md Mahmudul Hasan", "authors": "Md Mahmudul Hasan, Shuangqing Wei, Ali Moharrer", "title": "Latent Factor Analysis of Gaussian Distributions under Graphical\n  Constraints", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the algebraic structure of the solution space of convex\noptimization problem Constrained Minimum Trace Factor Analysis (CMTFA), when\nthe population covariance matrix $\\Sigma_x$ has an additional latent graphical\nconstraint, namely, a latent star topology. In particular, we have shown that\nCMTFA can have either a rank $ 1 $ or a rank $ n-1 $ solution and nothing in\nbetween. The special case of a rank $ 1 $ solution, corresponds to the case\nwhere just one latent variable captures all the dependencies among the\nobservables, giving rise to a star topology. We found explicit conditions for\nboth rank $ 1 $ and rank $n- 1$ solutions for CMTFA solution of $\\Sigma_x$. As\na basic attempt towards building a more general Gaussian tree, we have found a\nnecessary and a sufficient condition for multiple clusters, each having rank $\n1 $ CMTFA solution, to satisfy a minimum probability to combine together to\nbuild a Gaussian tree. To support our analytical findings we have presented\nsome numerical demonstrating the usefulness of the contributions of our work.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 19:36:44 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 05:13:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hasan", "Md Mahmudul", ""], ["Wei", "Shuangqing", ""], ["Moharrer", "Ali", ""]]}, {"id": "2001.02728", "submitter": "Siavash Bigdeli", "authors": "Siavash A. Bigdeli, Geng Lin, Tiziano Portenier, L. Andrea Dunbar,\n  Matthias Zwicker", "title": "Learning Generative Models using Denoising Density Estimators", "comments": "Code and models available at\n  https://drive.google.com/file/d/1EzKRxnFG1Hd8g6Ggvt-jvKkgpDDwK2bY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning probabilistic models that can estimate the density of a given set of\nsamples, and generate samples from that density, is one of the fundamental\nchallenges in unsupervised machine learning. We introduce a new generative\nmodel based on denoising density estimators (DDEs), which are scalar functions\nparameterized by neural networks, that are efficiently trained to represent\nkernel density estimators of the data. Leveraging DDEs, our main contribution\nis a novel technique to obtain generative models by minimizing the\nKL-divergence directly. We prove that our algorithm for obtaining generative\nmodels is guaranteed to converge to the correct solution. Our approach does not\nrequire specific network architecture as in normalizing flows, nor use ordinary\ndifferential equation solvers as in continuous normalizing flows. Experimental\nresults demonstrate substantial improvement in density estimation and\ncompetitive performance in generative model training.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 20:30:40 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:26:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bigdeli", "Siavash A.", ""], ["Lin", "Geng", ""], ["Portenier", "Tiziano", ""], ["Dunbar", "L. Andrea", ""], ["Zwicker", "Matthias", ""]]}, {"id": "2001.02760", "submitter": "Abhaykumar Kumbhar", "authors": "Abhaykumar Kumbhar, Hamidullah Binol, Simran Singh, Ismail Guvenc,\n  Kemal Akkaya", "title": "Heuristic Approach for Jointly Optimizing FeICIC and UAV Locations in\n  Multi-Tier LTE-Advanced Public Safety HetNet", "comments": "Submitted at IET Cyber-Systems and Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UAV enabled communications and networking can enhance wireless connectivity\nand support emerging services. However, this would require system-level\nunderstanding to modify and extend the existing terrestrial network\ninfrastructure. In this paper, we integrate UAVs both as user equipment and\nbase stations into existing LTE-Advanced heterogeneous network (HetNet) and\nprovide system-level insights of this three-tier LTE-Advanced air-ground HetNet\n(AG-HetNet). This AG-HetNet leverages cell range expansion (CRE), ICIC, 3D\nbeamforming, and enhanced support for UAVs. Using system-level understanding\nand through brute-force technique and heuristics algorithms, we evaluate the\nperformance of AG-HetNet in terms of fifth percentile spectral efficiency\n(5pSE) and coverage probability. We compare 5pSE and coverage probability, when\naerial base-stations (UABS) are deployed on a fixed hexagonal grid and when\ntheir locations are optimized using genetic algorithm (GA) and elitist harmony\nsearch algorithm based on genetic algorithm (eHSGA). Our simulation results\nshow the heuristic algorithms outperform the brute-force technique and achieve\nbetter peak values of coverage probability and 5pSE. Simulation results also\nshow that trade-off exists between peak values and computation time when using\nheuristic algorithms. Furthermore, the three-tier hierarchical structuring of\nFeICIC provides considerably better 5pSE and coverage probability than eICIC.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 14:22:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Kumbhar", "Abhaykumar", ""], ["Binol", "Hamidullah", ""], ["Singh", "Simran", ""], ["Guvenc", "Ismail", ""], ["Akkaya", "Kemal", ""]]}, {"id": "2001.02767", "submitter": "Yun-Cheng Tsai", "authors": "Jun-Hao Chen, Samuel Yen-Chi Chen, Yun-Cheng Tsai, Chih-Shiang Shur", "title": "Explainable Deep Convolutional Candlestick Learner", "comments": "Accepted by The 32nd International Conference on Software Engineering\n  & Knowledge Engineering (SEKE 2020), KSIR Virtual Conference Cener,\n  Pittsburgh, USA, July 9--July 19, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candlesticks are graphical representations of price movements for a given\nperiod. The traders can discovery the trend of the asset by looking at the\ncandlestick patterns. Although deep convolutional neural networks have achieved\ngreat success for recognizing the candlestick patterns, their reasoning hides\ninside a black box. The traders cannot make sure what the model has learned. In\nthis contribution, we provide a framework which is to explain the reasoning of\nthe learned model determining the specific candlestick patterns of time series.\nBased on the local search adversarial attacks, we show that the learned model\nperceives the pattern of the candlesticks in a way similar to the human trader.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 22:11:13 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:12:55 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 09:09:02 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 06:04:54 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Chen", "Jun-Hao", ""], ["Chen", "Samuel Yen-Chi", ""], ["Tsai", "Yun-Cheng", ""], ["Shur", "Chih-Shiang", ""]]}, {"id": "2001.02773", "submitter": "Yuqiao Chen", "authors": "Yuqiao Chen, Yibo Yang, Sriraam Natarajan, Nicholas Ruozzi", "title": "Lifted Hybrid Variational Inference", "comments": "AAAI 2020 Workshop on Statistical Relational AI (StarAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of lifted inference algorithms, which exploit model symmetry to\nreduce computational cost, have been proposed to render inference tractable in\nprobabilistic relational models. Most existing lifted inference algorithms\noperate only over discrete domains or continuous domains with restricted\npotential functions, e.g., Gaussian. We investigate two approximate lifted\nvariational approaches that are applicable to hybrid domains and expressive\nenough to capture multi-modality. We demonstrate that the proposed variational\nmethods are both scalable and can take advantage of approximate model\nsymmetries, even in the presence of a large amount of continuous evidence. We\ndemonstrate that our approach compares favorably against existing\nmessage-passing based approaches in a variety of settings. Finally, we present\na sufficient condition for the Bethe approximation to yield a non-trivial\nestimate over the marginal polytope.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 22:29:07 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 03:13:02 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Yuqiao", ""], ["Yang", "Yibo", ""], ["Natarajan", "Sriraam", ""], ["Ruozzi", "Nicholas", ""]]}, {"id": "2001.02786", "submitter": "Zhucheng Tu", "authors": "Hadi Pouransari, Zhucheng Tu, Oncel Tuzel", "title": "Least squares binary quantization of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantizing weights and activations of deep neural networks results in\nsignificant improvement in inference efficiency at the cost of lower accuracy.\nA source of the accuracy gap between full precision and quantized models is the\nquantization error. In this work, we focus on the binary quantization, in which\nvalues are mapped to -1 and 1. We provide a unified framework to analyze\ndifferent scaling strategies. Inspired by the pareto-optimality of 2-bits\nversus 1-bit quantization, we introduce a novel 2-bits quantization with\nprovably least squares error. Our quantization algorithms can be implemented\nefficiently on the hardware using bitwise operations. We present proofs to show\nthat our proposed methods are optimal, and also provide empirical error\nanalysis. We conduct experiments on the ImageNet dataset and show a reduced\naccuracy gap when using the proposed least squares quantization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 00:01:14 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:33:48 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 07:23:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pouransari", "Hadi", ""], ["Tu", "Zhucheng", ""], ["Tuzel", "Oncel", ""]]}, {"id": "2001.02792", "submitter": "Yizhou Wang", "authors": "Minshuo Chen, Yizhou Wang, Tianyi Liu, Zhuoran Yang, Xingguo Li,\n  Zhaoran Wang, Tuo Zhao", "title": "On Computation and Generalization of Generative Adversarial Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Imitation Learning (GAIL) is a powerful and practical\napproach for learning sequential decision-making policies. Different from\nReinforcement Learning (RL), GAIL takes advantage of demonstration data by\nexperts (e.g., human), and learns both the policy and reward function of the\nunknown environment. Despite the significant empirical progresses, the theory\nbehind GAIL is still largely unknown. The major difficulty comes from the\nunderlying temporal dependency of the demonstration data and the minimax\ncomputational formulation of GAIL without convex-concave structure. To bridge\nsuch a gap between theory and practice, this paper investigates the theoretical\nproperties of GAIL. Specifically, we show: (1) For GAIL with general reward\nparameterization, the generalization can be guaranteed as long as the class of\nthe reward functions is properly controlled; (2) For GAIL, where the reward is\nparameterized as a reproducing kernel function, GAIL can be efficiently solved\nby stochastic first order optimization algorithms, which attain sublinear\nconvergence to a stationary solution. To the best of our knowledge, these are\nthe first results on statistical and computational guarantees of imitation\nlearning with reward/policy function approximation. Numerical experiments are\nprovided to support our analysis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 00:40:19 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 03:31:31 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chen", "Minshuo", ""], ["Wang", "Yizhou", ""], ["Liu", "Tianyi", ""], ["Yang", "Zhuoran", ""], ["Li", "Xingguo", ""], ["Wang", "Zhaoran", ""], ["Zhao", "Tuo", ""]]}, {"id": "2001.02798", "submitter": "Parshan Pakiman", "authors": "Parshan Pakiman, Selvaprabu Nadarajah, Negar Soheili and Qihang Lin", "title": "Self-guided Approximate Linear Programs", "comments": "57 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate linear programs (ALPs) are well-known models based on value\nfunction approximations (VFAs) to obtain heuristic policies and lower bounds on\nthe optimal policy cost of Markov decision processes (MDPs). The ALP VFA is a\nlinear combination of predefined basis functions that are chosen using domain\nknowledge and updated heuristically if the ALP optimality gap is large. We\nside-step the need for such basis function engineering in ALP -- an\nimplementation bottleneck -- by proposing a sequence of ALPs that embed\nincreasing numbers of random basis functions obtained via inexpensive sampling.\nWe provide a sampling guarantee and show that the VFAs from this sequence of\nmodels converge to the exact value function. Nevertheless, the performance of\nthe ALP policy can fluctuate significantly as more basis functions are sampled.\nTo mitigate these fluctuations, we \"self-guide\" our convergent sequence of ALPs\nusing past VFA information such that a worst-case measure of policy performance\nis improved. We perform numerical experiments on perishable inventory control\nand generalized joint replenishment applications, which, respectively, give\nrise to challenging discounted-cost MDPs and average-cost semi-MDPs. We find\nthat self-guided ALPs (i) significantly reduce policy cost fluctuations and\nimprove the optimality gaps from an ALP approach that employs basis functions\ntailored to the former application, and (ii) deliver optimality gaps that are\ncomparable to a known adaptive basis function generation approach targeting the\nlatter application. More broadly, our methodology provides application-agnostic\npolicies and lower bounds to benchmark approaches that exploit application\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:18:54 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Pakiman", "Parshan", ""], ["Nadarajah", "Selvaprabu", ""], ["Soheili", "Negar", ""], ["Lin", "Qihang", ""]]}, {"id": "2001.02799", "submitter": "Xi Yan", "authors": "Xi Yan, David Acuna, Sanja Fidler", "title": "Neural Data Server: A Large-Scale Search Engine for Transfer Learning\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has proven to be a successful technique to train deep\nlearning models in the domains where little training data is available. The\ndominant approach is to pretrain a model on a large generic dataset such as\nImageNet and finetune its weights on the target domain. However, in the new era\nof an ever-increasing number of massive datasets, selecting the relevant data\nfor pretraining is a critical issue. We introduce Neural Data Server (NDS), a\nlarge-scale search engine for finding the most useful transfer learning data to\nthe target domain. NDS consists of a dataserver which indexes several large\npopular image datasets, and aims to recommend data to a client, an end-user\nwith a target application with its own small labeled dataset. The dataserver\nrepresents large datasets with a much more compact mixture-of-experts model,\nand employs it to perform data search in a series of dataserver-client\ntransactions at a low computational cost. We show the effectiveness of NDS in\nvarious transfer learning scenarios, demonstrating state-of-the-art performance\non several target datasets and tasks such as image classification, object\ndetection and instance segmentation. Neural Data Server is available as a\nweb-service at http://aidemos.cs.toronto.edu/nds/.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:21:30 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 23:20:35 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 00:43:03 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yan", "Xi", ""], ["Acuna", "David", ""], ["Fidler", "Sanja", ""]]}, {"id": "2001.02802", "submitter": "Md. Aminur Rab Ratul", "authors": "Md. Aminur Rab Ratul", "title": "A Comparative Study on Crime in Denver City Based on Machine Learning\n  and Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure the security of the general mass, crime prevention is one of the\nmost higher priorities for any government. An accurate crime prediction model\ncan help the government, law enforcement to prevent violence, detect the\ncriminals in advance, allocate the government resources, and recognize problems\ncausing crimes. To construct any future-oriented tools, examine and understand\nthe crime patterns in the earliest possible time is essential. In this paper, I\nanalyzed a real-world crime and accident dataset of Denver county, USA, from\nJanuary 2014 to May 2019, which containing 478,578 incidents. This project aims\nto predict and highlights the trends of occurrence that will, in return,\nsupport the law enforcement agencies and government to discover the preventive\nmeasures from the prediction rates. At first, I apply several statistical\nanalysis supported by several data visualization approaches. Then, I implement\nvarious classification algorithms such as Random Forest, Decision Tree,\nAdaBoost Classifier, Extra Tree Classifier, Linear Discriminant Analysis,\nK-Neighbors Classifiers, and 4 Ensemble Models to classify 15 different classes\nof crimes. The outcomes are captured using two popular test methods: train-test\nsplit, and k-fold cross-validation. Moreover, to evaluate the performance\nflawlessly, I also utilize precision, recall, F1-score, Mean Squared Error\n(MSE), ROC curve, and paired-T-test. Except for the AdaBoost classifier, most\nof the algorithms exhibit satisfactory accuracy. Random Forest, Decision Tree,\nEnsemble Model 1, 3, and 4 even produce me more than 90% accuracy. Among all\nthe approaches, Ensemble Model 4 presented superior results for every\nevaluation basis. This study could be useful to raise the awareness of peoples\nregarding the occurrence locations and to assist security agencies to predict\nfuture outbreaks of violence in a specific area within a particular time.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:36:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ratul", "Md. Aminur Rab", ""]]}, {"id": "2001.02810", "submitter": "Huyan Huang", "authors": "Huyan Huang, Yipeng Liu, Ce Zhu", "title": "A Unified Framework for Coupled Tensor Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coupled tensor decomposition reveals the joint data structure by\nincorporating priori knowledge that come from the latent coupled factors. The\ntensor ring (TR) decomposition is invariant under the permutation of tensors\nwith different mode properties, which ensures the uniformity of decomposed\nfactors and mode attributes. The TR has powerful expression ability and\nachieves success in some multi-dimensional data processing applications. To let\ncoupled tensors help each other for missing component estimation, in this paper\nwe utilize TR for coupled completion by sharing parts of the latent factors.\nThe optimization model for coupled TR completion is developed with a novel\nFrobenius norm. It is solved by the block coordinate descent algorithm which\nefficiently solves a series of quadratic problems resulted from sampling\npattern. The excess risk bound for this optimization model shows the\ntheoretical performance enhancement in comparison with other coupled nuclear\nnorm based methods. The proposed method is validated on numerical experiments\non synthetic data, and experimental results on real-world data demonstrate its\nsuperiority over the state-of-the-art methods in terms of recovery accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:15:46 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 03:57:54 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 06:39:35 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 12:36:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Huang", "Huyan", ""], ["Liu", "Yipeng", ""], ["Zhu", "Ce", ""]]}, {"id": "2001.02811", "submitter": "Jingliang Duan", "authors": "Jingliang Duan, Yang Guan, Shengbo Eben Li, Yangang Ren, Bo Cheng", "title": "Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for\n  Addressing Value Estimation Errors", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2021", "doi": "10.1109/TNNLS.2021.3082568", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), function approximation errors are known to\neasily lead to the Q-value overestimations, thus greatly reducing policy\nperformance. This paper presents a distributional soft actor-critic (DSAC)\nalgorithm, which is an off-policy RL method for continuous control setting, to\nimprove the policy performance by mitigating Q-value overestimations. We first\ndiscover in theory that learning a distribution function of state-action\nreturns can effectively mitigate Q-value overestimations because it is capable\nof adaptively adjusting the update stepsize of the Q-value function. Then, a\ndistributional soft policy iteration (DSPI) framework is developed by embedding\nthe return distribution function into maximum entropy RL. Finally, we present a\ndeep off-policy actor-critic variant of DSPI, called DSAC, which directly\nlearns a continuous return distribution by keeping the variance of the\nstate-action returns within a reasonable range to address exploding and\nvanishing gradient problems. We evaluate DSAC on the suite of MuJoCo continuous\ncontrol tasks, achieving the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:27:18 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 08:39:55 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 15:21:17 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Duan", "Jingliang", ""], ["Guan", "Yang", ""], ["Li", "Shengbo Eben", ""], ["Ren", "Yangang", ""], ["Cheng", "Bo", ""]]}, {"id": "2001.02814", "submitter": "Yuanlong Yu", "authors": "You Huang, Yuanlong Yu", "title": "An Internal Covariate Shift Bounding Algorithm for Deep Neural Networks\n  by Unitizing Layers' Outputs", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) techniques have been proposed to reduce the\nso-called Internal Covariate Shift (ICS) by attempting to keep the\ndistributions of layer outputs unchanged. Experiments have shown their\neffectiveness on training deep neural networks. However, since only the first\ntwo moments are controlled in these BN techniques, it seems that a weak\nconstraint is imposed on layer distributions and furthermore whether such\nconstraint can reduce ICS is unknown. Thus this paper proposes a measure for\nICS by using the Earth Mover (EM) distance and then derives the upper and lower\nbounds for the measure to provide a theoretical analysis of BN. The upper bound\nhas shown that BN techniques can control ICS only for the outputs with low\ndimensions and small noise whereas their control is NOT effective in other\ncases. This paper also proves that such control is just a bounding of ICS\nrather than a reduction of ICS. Meanwhile, the analysis shows that the\nhigh-order moments and noise, which BN cannot control, have great impact on the\nlower bound. Based on such analysis, this paper furthermore proposes an\nalgorithm that unitizes the outputs with an adjustable parameter to further\nbound ICS in order to cope with the problems of BN. The upper bound for the\nproposed unitization is noise-free and only dominated by the parameter. Thus,\nthe parameter can be trained to tune the bound and further to control ICS.\nBesides, the unitization is embedded into the framework of BN to reduce the\ninformation loss. The experiments show that this proposed algorithm outperforms\nexisting BN techniques on CIFAR-10, CIFAR-100 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 02:35:58 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Huang", "You", ""], ["Yu", "Yuanlong", ""]]}, {"id": "2001.02856", "submitter": "Hai Shu", "authors": "Hai Shu, Zhe Qu, Hongtu Zhu", "title": "D-GCCA: Decomposition-based Generalized Canonical Correlation Analysis\n  for Multiple High-dimensional Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern biomedical studies often collect multiple types of high-dimensional\ndata on a common set of objects. A popular model for the joint analysis of\nmulti-type datasets decomposes each data matrix into a low-rank\ncommon-variation matrix generated by latent factors shared across all datasets,\na low-rank distinctive-variation matrix corresponding to each dataset, and an\nadditive noise matrix. We propose decomposition-based generalized canonical\ncorrelation analysis (D-GCCA), a novel decomposition method that appropriately\ndefines those matrices on the L2 space of random variables, whereas most\nexisting methods are developed on its approximation, the Euclidean dot product\nspace. Moreover to well calibrate common latent factors, we impose a desirable\northogonality constraint on distinctive latent factors. Existing methods\ninadequately consider such orthogonality and can thus suffer from substantial\nloss of undetected common variation. Our D-GCCA takes one step further than\nGCCA by separating common and distinctive variations among canonical variables,\nand enjoys an appealing interpretation from the perspective of principal\ncomponent analysis. Consistent estimators of our common-variation and\ndistinctive-variation matrices are established with good finite-sample\nnumerical performance, and have closed-form expressions leading to efficient\ncomputation especially for large-scale datasets. The superiority of D-GCCA over\nstate-of-the-art methods is also corroborated in simulations and real-world\ndata examples.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 06:35:40 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shu", "Hai", ""], ["Qu", "Zhe", ""], ["Zhu", "Hongtu", ""]]}, {"id": "2001.02879", "submitter": "Shao-Bo Lin", "authors": "Xiangyu Chang, Shao-Bo Lin", "title": "Adaptive Stopping Rule for Kernel-based Gradient Descent Algorithms", "comments": "32 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an adaptive stopping rule for kernel-based gradient\ndescent (KGD) algorithms. We introduce the empirical effective dimension to\nquantify the increments of iterations in KGD and derive an implementable early\nstopping strategy. We analyze the performance of the adaptive stopping rule in\nthe framework of learning theory. Using the recently developed integral\noperator approach, we rigorously prove the optimality of the adaptive stopping\nrule in terms of showing the optimal learning rates for KGD equipped with this\nrule. Furthermore, a sharp bound on the number of iterations in KGD equipped\nwith the proposed early stopping rule is also given to demonstrate its\ncomputational advantage.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:12:38 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chang", "Xiangyu", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2001.02894", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Alessandro Selvitella, Liangxiu Han, Daoqiang\n  Zhang", "title": "Supervised Hyperalignment for multi-subject fMRI data alignment", "comments": "IEEE Transactions on Cognitive and Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2020.2965981", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperalignment has been widely employed in Multivariate Pattern (MVP)\nanalysis to discover the cognitive states in the human brains based on\nmulti-subject functional Magnetic Resonance Imaging (fMRI) datasets. Most of\nthe existing HA methods utilized unsupervised approaches, where they only\nmaximized the correlation between the voxels with the same position in the time\nseries. However, these unsupervised solutions may not be optimum for handling\nthe functional alignment in the supervised MVP problems. This paper proposes a\nSupervised Hyperalignment (SHA) method to ensure better functional alignment\nfor MVP analysis, where the proposed method provides a supervised shared space\nthat can maximize the correlation among the stimuli belonging to the same\ncategory and minimize the correlation between distinct categories of stimuli.\nFurther, SHA employs a generalized optimization solution, which generates the\nshared space and calculates the mapped features in a single iteration, hence\nwith optimum time and space complexities for large datasets. Experiments on\nmulti-subject datasets demonstrate that SHA method achieves up to 19% better\nperformance for multi-class problems over the state-of-the-art HA algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 09:17:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Selvitella", "Alessandro", ""], ["Han", "Liangxiu", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2001.02907", "submitter": "Whiyoung Jung", "authors": "Whiyoung Jung, Giseung Park, Youngchul Sung", "title": "Population-Guided Parallel Policy Search for Reinforcement Learning", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new population-guided parallel learning scheme is proposed\nto enhance the performance of off-policy reinforcement learning (RL). In the\nproposed scheme, multiple identical learners with their own value-functions and\npolicies share a common experience replay buffer, and search a good policy in\ncollaboration with the guidance of the best policy information. The key point\nis that the information of the best policy is fused in a soft manner by\nconstructing an augmented loss function for policy update to enlarge the\noverall search region by the multiple learners. The guidance by the previous\nbest policy and the enlarged range enable faster and better policy search.\nMonotone improvement of the expected cumulative return by the proposed scheme\nis proved theoretically. Working algorithms are constructed by applying the\nproposed scheme to the twin delayed deep deterministic (TD3) policy gradient\nalgorithm. Numerical results show that the constructed algorithm outperforms\nmost of the current state-of-the-art RL algorithms, and the gain is significant\nin the case of sparse reward environment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:13:57 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Jung", "Whiyoung", ""], ["Park", "Giseung", ""], ["Sung", "Youngchul", ""]]}, {"id": "2001.02908", "submitter": "Mingxing Xu", "authors": "Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing Gao, Weiyao Lin, Guo-Jun\n  Qi, Hongkai Xiong", "title": "Spatial-Temporal Transformer Networks for Traffic Flow Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting has emerged as a core component of intelligent\ntransportation systems. However, timely accurate traffic forecasting,\nespecially long-term forecasting, still remains an open challenge due to the\nhighly nonlinear and dynamic spatial-temporal dependencies of traffic flows. In\nthis paper, we propose a novel paradigm of Spatial-Temporal Transformer\nNetworks (STTNs) that leverages dynamical directed spatial dependencies and\nlong-range temporal dependencies to improve the accuracy of long-term traffic\nforecasting. Specifically, we present a new variant of graph neural networks,\nnamed spatial transformer, by dynamically modeling directed spatial\ndependencies with self-attention mechanism to capture realtime traffic\nconditions as well as the directionality of traffic flows. Furthermore,\ndifferent spatial dependency patterns can be jointly modeled with multi-heads\nattention mechanism to consider diverse relationships related to different\nfactors (e.g. similarity, connectivity and covariance). On the other hand, the\ntemporal transformer is utilized to model long-range bidirectional temporal\ndependencies across multiple time steps. Finally, they are composed as a block\nto jointly model the spatial-temporal dependencies for accurate traffic\nprediction. Compared to existing works, the proposed model enables fast and\nscalable training over a long range spatial-temporal dependencies. Experiment\nresults demonstrate that the proposed model achieves competitive results\ncompared with the state-of-the-arts, especially forecasting long-term traffic\nflows on real-world PeMS-Bay and PeMSD7(M) datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 10:21:04 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 09:59:36 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Xu", "Mingxing", ""], ["Dai", "Wenrui", ""], ["Liu", "Chunmiao", ""], ["Gao", "Xing", ""], ["Lin", "Weiyao", ""], ["Qi", "Guo-Jun", ""], ["Xiong", "Hongkai", ""]]}, {"id": "2001.02920", "submitter": "Patrick Murer", "authors": "Patrick Murer and Hans-Andrea Loeliger", "title": "Online Memorization of Random Firing Sequences by a Recurrent Neural\n  Network", "comments": "8 pages, 3 figures; submitted to ISIT 2020; with additional proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the capability of a recurrent neural network model to\nmemorize random dynamical firing patterns by a simple local learning rule. Two\nmodes of learning/memorization are considered: The first mode is strictly\nonline, with a single pass through the data, while the second mode uses\nmultiple passes through the data. In both modes, the learning is strictly local\n(quasi-Hebbian): At any given time step, only the weights between the neurons\nfiring (or supposed to be firing) at the previous time step and those firing\n(or supposed to be firing) at the present time step are modified. The main\nresult of the paper is an upper bound on the probability that the single-pass\nmemorization is not perfect. It follows that the memorization capacity in this\nmode asymptotically scales like that of the classical Hopfield model (which, in\ncontrast, memorizes static patterns). However, multiple-rounds memorization is\nshown to achieve a higher capacity (with a nonvanishing number of bits per\nconnection/synapse). These mathematical findings may be helpful for\nunderstanding the functions of short-term memory and long-term memory in\nneuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 11:02:53 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Murer", "Patrick", ""], ["Loeliger", "Hans-Andrea", ""]]}, {"id": "2001.02932", "submitter": "Joohyung Jeon", "authors": "Joohyung Jeon, Junhui Kim, Joongheon Kim, Kwangsoo Kim, Aziz Mohaisen,\n  and Jong-Kook Kim", "title": "Privacy-Preserving Deep Learning Computation for Geo-Distributed Medical\n  Big-Data Platforms", "comments": "2019 IEEE/IFIP International Conference on Dependable Systems and\n  Networks Supplemental", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed deep learning framework for\nprivacy-preserving medical data training. In order to avoid patients' data\nleakage in medical platforms, the hidden layers in the deep learning framework\nare separated and where the first layer is kept in platform and others layers\nare kept in a centralized server. Whereas keeping the original patients' data\nin local platforms maintain their privacy, utilizing the server for subsequent\nlayers improves learning performance by using all data from each platform\nduring training.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 11:46:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Jeon", "Joohyung", ""], ["Kim", "Junhui", ""], ["Kim", "Joongheon", ""], ["Kim", "Kwangsoo", ""], ["Mohaisen", "Aziz", ""], ["Kim", "Jong-Kook", ""]]}, {"id": "2001.02942", "submitter": "Ziyao Zhang Mr.", "authors": "Liang Ma and Ziyao Zhang and Mudhakar Srivatsa", "title": "Neural Network Tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network tomography, a classic research problem in the realm of network\nmonitoring, refers to the methodology of inferring unmeasured network\nattributes using selected end-to-end path measurements. In the research\ncommunity, network tomography is generally investigated under the assumptions\nof known network topology, correlated path measurements, bounded number of\nfaulty nodes/links, or even special network protocol support. The applicability\nof network tomography is considerably constrained by these strong assumptions,\nwhich therefore frequently position it in the theoretical world. In this\nregard, we revisit network tomography from the practical perspective by\nestablishing a generic framework that does not rely on any of these assumptions\nor the types of performance metrics. Given only the end-to-end path performance\nmetrics of sampled node pairs, the proposed framework, NeuTomography, utilizes\ndeep neural network and data augmentation to predict the unmeasured performance\nmetrics via learning non-linear relationships between node pairs and underlying\nunknown topological/routing properties. In addition, NeuTomography can be\nemployed to reconstruct the original network topology, which is critical to\nmost network planning tasks. Extensive experiments using real network data show\nthat comparing to baseline solutions, NeuTomography can predict network\ncharacteristics and reconstruct network topologies with significantly higher\naccuracy and robustness using only limited measurement data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:19:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ma", "Liang", ""], ["Zhang", "Ziyao", ""], ["Srivatsa", "Mudhakar", ""]]}, {"id": "2001.02968", "submitter": "Dan Mikulincer", "authors": "S\\'ebastien Bubeck and Dan Mikulincer", "title": "How to trap a gradient flow", "comments": "25 pages, 5 figures. Added an improved algorithm for dimensions > 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding an $\\varepsilon$-approximate stationary\npoint of a smooth function on a compact domain of $\\mathbb{R}^d$. In contrast\nwith dimension-free approaches such as gradient descent, we focus here on the\ncase where $d$ is finite, and potentially small. This viewpoint was explored in\n1993 by Vavasis, who proposed an algorithm which, for any fixed finite\ndimension $d$, improves upon the $O(1/\\varepsilon^2)$ oracle complexity of\ngradient descent. For example for $d=2$, Vavasis' approach obtains the\ncomplexity $O(1/\\varepsilon)$. Moreover for $d=2$ he also proved a lower bound\nof $\\Omega(1/\\sqrt{\\varepsilon})$ for deterministic algorithms (we extend this\nresult to randomized algorithms).\n  Our main contribution is an algorithm, which we call gradient flow trapping\n(GFT), and the analysis of its oracle complexity. In dimension $d=2$, GFT\ncloses the gap with Vavasis' lower bound (up to a logarithmic factor), as we\nshow that it has complexity\n$O\\left(\\sqrt{\\frac{\\log(1/\\varepsilon)}{\\varepsilon}}\\right)$. In dimension\n$d=3$, we show a complexity of\n$O\\left(\\frac{\\log(1/\\varepsilon)}{\\varepsilon}\\right)$, improving upon\nVavasis' $O\\left(1 / \\varepsilon^{1.2} \\right)$. In higher dimensions, GFT has\nthe remarkable property of being a logarithmic parallel depth strategy, in\nstark contrast with the polynomial depth of gradient descent or Vavasis'\nalgorithm. In this higher dimensional regime, the total work of GFT improves\nquadratically upon the only other known polylogarithmic depth strategy for this\nproblem, namely naive grid search. We augment this result with another\nalgorithm, named \\emph{cut and flow} (CF), which improves upon Vavasis'\nalgorithm in any fixed dimension.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:30:18 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 18:40:48 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 15:36:23 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Mikulincer", "Dan", ""]]}, {"id": "2001.02970", "submitter": "Sama Daryanavard Miss", "authors": "Sama Daryanavard, Bernd Porr", "title": "Closed-loop deep learning: generating forward models with\n  back-propagation", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reflex is a simple closed loop control approach which tries to minimise an\nerror but fails to do so because it will always react too late. An adaptive\nalgorithm can use this error to learn a forward model with the help of\npredictive cues. For example a driver learns to improve their steering by\nlooking ahead to avoid steering in the last minute. In order to process complex\ncues such as the road ahead deep learning is a natural choice. However, this is\nusually only achieved indirectly by employing deep reinforcement learning\nhaving a discrete state space. Here, we show how this can be directly achieved\nby embedding deep learning into a closed loop system and preserving its\ncontinuous processing. We show specifically how error back-propagation can be\nachieved in z-space and in general how gradient based approaches can be\nanalysed in such closed loop scenarios. The performance of this learning\nparadigm is demonstrated using a line-follower both in simulation and on a real\nrobot that show very fast and continuous learning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:36:57 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 11:14:24 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Daryanavard", "Sama", ""], ["Porr", "Bernd", ""]]}, {"id": "2001.02976", "submitter": "Jing Su", "authors": "Andrew Anderson, Jing Su, Rozenn Dahyot and David Gregg", "title": "Performance-Oriented Neural Architecture Search", "comments": "The 2019 International Conference on High Performance Computing &\n  Simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-Software Co-Design is a highly successful strategy for improving\nperformance of domain-specific computing systems. We argue for the application\nof the same methodology to deep learning; specifically, we propose to extend\nneural architecture search with information about the hardware to ensure that\nthe model designs produced are highly efficient in addition to the typical\ncriteria around accuracy. Using the task of keyword spotting in audio on edge\ncomputing devices, we demonstrate that our approach results in neural\narchitecture that is not only highly accurate, but also efficiently mapped to\nthe computing platform which will perform the inference. Using our modified\nneural architecture search, we demonstrate $0.88\\%$ increase in TOP-1 accuracy\nwith $1.85\\times$ reduction in latency for keyword spotting in audio on an\nembedded SoC, and $1.59\\times$ on a high-end GPU.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:47:39 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Anderson", "Andrew", ""], ["Su", "Jing", ""], ["Dahyot", "Rozenn", ""], ["Gregg", "David", ""]]}, {"id": "2001.02982", "submitter": "Luca Magri", "authors": "Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri", "title": "Learning Hidden States in a Chaotic System: A Physics-Informed Echo\n  State Network Approach", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Physics-Informed Echo State Network (PI-ESN) framework to\nreconstruct the evolution of an unmeasured state (hidden state) in a chaotic\nsystem. The PI-ESN is trained by using (i) data, which contains no information\non the unmeasured state, and (ii) the physical equations of a prototypical\nchaotic dynamical system. Non-noisy and noisy datasets are considered. First,\nit is shown that the PI-ESN can accurately reconstruct the unmeasured state.\nSecond, the reconstruction is shown to be robust with respect to noisy data,\nwhich means that the PI-ESN acts as a denoiser. This paper opens up new\npossibilities for leveraging the synergy between physical knowledge and machine\nlearning to enhance the reconstruction and prediction of unmeasured states in\nchaotic dynamical systems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:04:02 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 11:56:40 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Doan", "Nguyen Anh Khoa", ""], ["Polifke", "Wolfgang", ""], ["Magri", "Luca", ""]]}, {"id": "2001.02992", "submitter": "Emmanuel Abbe", "authors": "Emmanuel Abbe and Colin Sandon", "title": "Poly-time universality and limitations of deep learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1812.06369", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to characterize function distributions that deep\nlearning can or cannot learn in poly-time. A universality result is proved for\nSGD-based deep learning and a non-universality result is proved for GD-based\ndeep learning; this also gives a separation between SGD-based deep learning and\nstatistical query algorithms:\n  (1) {\\it Deep learning with SGD is efficiently universal.} Any function\ndistribution that can be learned from samples in poly-time can also be learned\nby a poly-size neural net trained with SGD on a poly-time initialization with\npoly-steps, poly-rate and possibly poly-noise.\n  Therefore deep learning provides a universal learning paradigm: it was known\nthat the approximation and estimation errors could be controlled with poly-size\nneural nets, using ERM that is NP-hard; this new result shows that the\noptimization error can also be controlled with SGD in poly-time. The picture\nchanges for GD with large enough batches:\n  (2) {\\it Result (1) does not hold for GD:} Neural nets of poly-size trained\nwith GD (full gradients or large enough batches) on any initialization with\npoly-steps, poly-range and at least poly-noise cannot learn any function\ndistribution that has super-polynomial {\\it cross-predictability,} where the\ncross-predictability gives a measure of ``average'' function correlation --\nrelations and distinctions to the statistical dimension are discussed. In\nparticular, GD with these constraints can learn efficiently monomials of degree\n$k$ if and only if $k$ is constant.\n  Thus (1) and (2) point to an interesting contrast: SGD is universal even with\nsome poly-noise while full GD or SQ algorithms are not (e.g., parities).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 08:31:50 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Abbe", "Emmanuel", ""], ["Sandon", "Colin", ""]]}, {"id": "2001.02993", "submitter": "Takayuki Hara", "authors": "Takayuki Hara and Tatsuya Harada", "title": "Spherical Image Generation from a Single Normal Field of View Image by\n  Considering Scene Symmetry", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical images taken in all directions (360 degrees) allow representing the\nsurroundings of the subject and the space itself, providing an immersive\nexperience to the viewers. Generating a spherical image from a single\nnormal-field-of-view (NFOV) image is convenient and considerably expands the\nusage scenarios because there is no need to use a specific panoramic camera or\ntake images from multiple directions; however, it is still a challenging and\nunsolved problem. The primary challenge is controlling the high degree of\nfreedom involved in generating a wide area that includes the all directions of\nthe desired plausible spherical image. On the other hand, scene symmetry is a\nbasic property of the global structure of the spherical images, such as\nrotation symmetry, plane symmetry and asymmetry. We propose a method to\ngenerate spherical image from a single NFOV image, and control the degree of\nfreedom of the generated regions using scene symmetry. We incorporate\nscene-symmetry parameters as latent variables into conditional variational\nautoencoders, following which we learn the conditional probability of spherical\nimages for NFOV images and scene symmetry. Furthermore, the probability density\nfunctions are represented using neural networks, and scene symmetry is\nimplemented using both circular shift and flip of the hidden variables. Our\nexperiments show that the proposed method can generate various plausible\nspherical images, controlled from symmetric to asymmetric.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:09:12 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Hara", "Takayuki", ""], ["Harada", "Tatsuya", ""]]}, {"id": "2001.03000", "submitter": "Tom Vander Aa", "authors": "Imen Chakroun and Tom Vander Aa and Thomas J. Ashby", "title": "Guidelines for enhancing data locality in selected machine learning\n  algorithms", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151) This an extended version of arXiv:1904.11203", "journal-ref": "Intelligent Data Analysis, vol. 23, no. 5, pp. 1003-1020, 2019", "doi": "10.3233/IDA-184287", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with the complexity of the new bigger and more complex generation of\ndata, machine learning (ML) techniques are probably the first and foremost\nused. For ML algorithms to produce results in a reasonable amount of time, they\nneed to be implemented efficiently. In this paper, we analyze one of the means\nto increase the performances of machine learning algorithms which is exploiting\ndata locality. Data locality and access patterns are often at the heart of\nperformance issues in computing systems due to the use of certain hardware\ntechniques to improve performance. Altering the access patterns to increase\nlocality can dramatically increase performance of a given algorithm. Besides,\nrepeated data access can be seen as redundancy in data movement. Similarly,\nthere can also be redundancy in the repetition of calculations. This work also\nidentifies some of the opportunities for avoiding these redundancies by\ndirectly reusing computation results. We start by motivating why and how a more\nefficient implementation can be achieved by exploiting reuse in the memory\nhierarchy of modern instruction set processors. Next we document the\npossibilities of such reuse in some selected machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:16:40 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Chakroun", "Imen", ""], ["Aa", "Tom Vander", ""], ["Ashby", "Thomas J.", ""]]}, {"id": "2001.03002", "submitter": "Jawad Ali", "authors": "Jawad Ali, Toqeer Ali, Yazed Alsaawy, Ahmad Shahrafidz Khalid,\n  Shahrulniza Musa", "title": "Blockchain-based Smart-IoT Trust Zone Measurement Architecture", "comments": "6 pages, 5 Figures, International Conference on Omni-Layer\n  Intelligent Systems, COINS May 2019. arXiv admin note: substantial text\n  overlap with arXiv:2001.01841", "journal-ref": "International Conference on Omni-Layer Intelligent Systems, COINS\n  May 2019, Pages 152-157", "doi": "10.1145/3312614.3312646", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With a rapid growth in the IT industry, Internet of Things (IoT) has gained a\ntremendous attention and become a central aspect of our environment. In IoT the\nthings (devices) communicate and exchange the data without the act of human\nintervention. Such autonomy and proliferation of IoT ecosystem make the devices\nmore vulnerable to attacks. In this paper, we propose a behavior monitor in\nIoT-Blockchain setup which can provide trust-confidence to outside networks.\nBehavior monitor extracts the activity of each device and analyzes the behavior\nusing deep auto-encoders. In addition, we also incorporate Trusted Execution\nTechnology (Intel SGX) in order to provide a secure execution environment for\napplications and data on blockchain. Finally, in evaluation we analyze three\nIoT devices data that is infected by mirai attack. The evaluation results\ndemonstrate the ability of our proposed method in terms of accuracy and time\nrequired for detection.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:41:27 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ali", "Jawad", ""], ["Ali", "Toqeer", ""], ["Alsaawy", "Yazed", ""], ["Khalid", "Ahmad Shahrafidz", ""], ["Musa", "Shahrulniza", ""]]}, {"id": "2001.03017", "submitter": "Chirag Gupta", "authors": "Chirag Gupta", "title": "Shallow Encoder Deep Decoder (SEDD) Networks for Image Encryption and\n  Decryption", "comments": "8 pages, 3 figures, preprint manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new framework for lossy image encryption and decryption\nusing a simple shallow encoder neural network E for encryption, and a complex\ndeep decoder neural network D for decryption. E is kept simple so that encoding\ncan be done on low power and portable devices and can in principle be any\nnonlinear function which outputs an encoded vector. D is trained to decode the\nencodings using the dataset of image - encoded vector pairs obtained from E and\nhappens independently of E. As the encodings come from E which while being a\nsimple neural network, still has thousands of random parameters and therefore\nthe encodings would be practically impossible to crack without D. This approach\ndiffers from autoencoders as D is trained completely independently of E,\nalthough the structure may seem similar. Therefore, this paper also explores\nempirically if a deep neural network can learn to reconstruct the original data\nin any useful form given the output of a neural network or any other nonlinear\nfunction, which can have very useful applications in Cryptanalysis. Experiments\ndemonstrate the potential of the framework through qualitative and quantitative\nevaluation of the decoded images from D along with some limitations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:33:38 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 09:59:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gupta", "Chirag", ""]]}, {"id": "2001.03019", "submitter": "Burcu Gungor", "authors": "Hilal Hacilar, O.Ufuk Nalbantoglu, Oya Aran, Burcu Bakir-Gungor", "title": "Inflammatory Bowel Disease Biomarkers of Human Gut Microbiota Selected\n  via Ensemble Feature Selection Methods", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous boost in the next generation sequencing and in the omics\ntechnologies makes it possible to characterize human gut microbiome (the\ncollective genomes of the microbial community that reside in our\ngastrointestinal tract). While some of these microorganisms are considered as\nessential regulators of our immune system, some others can cause several\ndiseases such as Inflammatory Bowel Diseases (IBD), diabetes, and cancer. IBD,\nis a gut related disorder where the deviations from the healthy gut microbiome\nare considered to be associated with IBD. Although existing studies attempt to\nunveal the composition of the gut microbiome in relation to IBD diseases, a\ncomprehensive picture is far from being complete. Due to the complexity of\nmetagenomic studies, the applications of the state of the art machine learning\ntechniques became popular to address a wide range of questions in the field of\nmetagenomic data analysis. In this regard, using IBD associated metagenomics\ndataset, this study utilizes both supervised and unsupervised machine learning\nalgorithms, i) to generate a classification model that aids IBD diagnosis, ii)\nto discover IBD associated biomarkers, iii) to find subgroups of IBD patients\nusing k means and hierarchical clustering. To deal with the high dimensionality\nof features, we applied robust feature selection algorithms such as Conditional\nMutual Information Maximization (CMIM), Fast Correlation Based Filter (FCBF),\nmin redundancy max relevance (mRMR) and Extreme Gradient Boosting (XGBoost). In\nour experiments with 10 fold cross validation, XGBoost had a considerable\neffect in terms of minimizing the microbiota used for the diagnosis of IBD and\nthus reducing the cost and time. We observed that compared to the single\nclassifiers, ensemble methods such as kNN and logitboost resulted in better\nperformance measures for the classification of IBD.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:17:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Hacilar", "Hilal", ""], ["Nalbantoglu", "O. Ufuk", ""], ["Aran", "Oya", ""], ["Bakir-Gungor", "Burcu", ""]]}, {"id": "2001.03024", "submitter": "Liming Jiang", "authors": "Liming Jiang, Ren Li, Wayne Wu, Chen Qian, Chen Change Loy", "title": "DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery\n  Detection", "comments": "CVPR 2020. Project page:\n  https://liming-jiang.com/projects/DrF1/DrF1.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our on-going effort of constructing a large-scale benchmark for\nface forgery detection. The first version of this benchmark,\nDeeperForensics-1.0, represents the largest face forgery detection dataset by\nfar, with 60,000 videos constituted by a total of 17.6 million frames, 10 times\nlarger than existing datasets of the same kind. Extensive real-world\nperturbations are applied to obtain a more challenging benchmark of larger\nscale and higher diversity. All source videos in DeeperForensics-1.0 are\ncarefully collected, and fake videos are generated by a newly proposed\nend-to-end face swapping framework. The quality of generated videos outperforms\nthose in existing datasets, validated by user studies. The benchmark features a\nhidden test set, which contains manipulated videos achieving high deceptive\nscores in human evaluations. We further contribute a comprehensive study that\nevaluates five representative detection baselines and make a thorough analysis\nof different settings.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:37:17 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 11:24:04 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jiang", "Liming", ""], ["Li", "Ren", ""], ["Wu", "Wayne", ""], ["Qian", "Chen", ""], ["Loy", "Chen Change", ""]]}, {"id": "2001.03025", "submitter": "Wenhao Zheng", "authors": "Shu-Ting Shi, Wenhao Zheng, Jun Tang, Qing-Guo Chen, Yao Hu, Jianke\n  Zhu, Ming Li", "title": "Deep Time-Stream Framework for Click-Through Rate Prediction by Tracking\n  Interest Evolution", "comments": "8 pages. arXiv admin note: text overlap with arXiv:1809.03672 by\n  other authors", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is an essential task in industrial\napplications such as video recommendation. Recently, deep learning models have\nbeen proposed to learn the representation of users' overall interests, while\nignoring the fact that interests may dynamically change over time. We argue\nthat it is necessary to consider the continuous-time information in CTR models\nto track user interest trend from rich historical behaviors. In this paper, we\npropose a novel Deep Time-Stream framework (DTS) which introduces the time\ninformation by an ordinary differential equations (ODE). DTS continuously\nmodels the evolution of interests using a neural network, and thus is able to\ntackle the challenge of dynamically representing users' interests based on\ntheir historical behaviors. In addition, our framework can be seamlessly\napplied to any existing deep CTR models by leveraging the additional\nTime-Stream Module, while no changes are made to the original CTR models.\nExperiments on public dataset as well as real industry dataset with billions of\nsamples demonstrate the effectiveness of proposed approaches, which achieve\nsuperior performance compared with existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:33:23 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Shi", "Shu-Ting", ""], ["Zheng", "Wenhao", ""], ["Tang", "Jun", ""], ["Chen", "Qing-Guo", ""], ["Hu", "Yao", ""], ["Zhu", "Jianke", ""], ["Li", "Ming", ""]]}, {"id": "2001.03032", "submitter": "Luca Ciampi", "authors": "Luca Ciampi, Nicola Messina, Fabrizio Falchi, Claudio Gennaro,\n  Giuseppe Amato", "title": "Virtual to Real adaptation of Pedestrian Detectors", "comments": null, "journal-ref": "Sensors 20.18 (2020): 5250", "doi": "10.3390/s20185250", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian detection through Computer Vision is a building block for a\nmultitude of applications. Recently, there was an increasing interest in\nConvolutional Neural Network-based architectures for the execution of such a\ntask. One of these supervised networks' critical goals is to generalize the\nknowledge learned during the training phase to new scenarios with different\ncharacteristics. A suitably labeled dataset is essential to achieve this\npurpose. The main problem is that manually annotating a dataset usually\nrequires a lot of human effort, and it is costly. To this end, we introduce\nViPeD (Virtual Pedestrian Dataset), a new synthetically generated set of images\ncollected with the highly photo-realistic graphical engine of the video game\nGTA V - Grand Theft Auto V, where annotations are automatically acquired.\nHowever, when training solely on the synthetic dataset, the model experiences a\nSynthetic2Real Domain Shift leading to a performance drop when applied to\nreal-world images. To mitigate this gap, we propose two different Domain\nAdaptation techniques suitable for the pedestrian detection task, but possibly\napplicable to general object detection. Experiments show that the network\ntrained with ViPeD can generalize over unseen real-world scenarios better than\nthe detector trained over real-world data, exploiting the variety of our\nsynthetic dataset. Furthermore, we demonstrate that with our Domain Adaptation\ntechniques, we can reduce the Synthetic2Real Domain Shift, making closer the\ntwo domains and obtaining a performance improvement when testing the network\nover the real-world images. The code, the models, and the dataset are made\nfreely available at https://ciampluca.github.io/viped/\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:50:11 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 08:47:12 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 14:14:19 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ciampi", "Luca", ""], ["Messina", "Nicola", ""], ["Falchi", "Fabrizio", ""], ["Gennaro", "Claudio", ""], ["Amato", "Giuseppe", ""]]}, {"id": "2001.03040", "submitter": "Shijun Zhang", "authors": "Jianfeng Lu, Zuowei Shen, Haizhao Yang, Shijun Zhang", "title": "Deep Network Approximation for Smooth Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes the optimal approximation error characterization of\ndeep ReLU networks for smooth functions in terms of both width and depth\nsimultaneously. To that end, we first prove that multivariate polynomials can\nbe approximated by deep ReLU networks of width $\\mathcal{O}(N)$ and depth\n$\\mathcal{O}(L)$ with an approximation error $\\mathcal{O}(N^{-L})$. Through\nlocal Taylor expansions and their deep ReLU network approximations, we show\nthat deep ReLU networks of width $\\mathcal{O}(N\\ln N)$ and depth\n$\\mathcal{O}(L\\ln L)$ can approximate $f\\in C^s([0,1]^d)$ with a nearly optimal\napproximation error $\\mathcal{O}(\\|f\\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our\nestimate is non-asymptotic in the sense that it is valid for arbitrary width\nand depth specified by $N\\in\\mathbb{N}^+$ and $L\\in\\mathbb{N}^+$, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:06:10 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 23:29:20 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 12:25:46 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 16:12:19 GMT"}, {"version": "v5", "created": "Thu, 24 Jun 2021 21:16:45 GMT"}, {"version": "v6", "created": "Wed, 21 Jul 2021 23:59:26 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lu", "Jianfeng", ""], ["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "2001.03048", "submitter": "Wolfgang Roth", "authors": "Wolfgang Roth, G\\\"unther Schindler, Matthias Z\\\"ohrer, Lukas\n  Pfeifenberger, Robert Peharz, Sebastian Tschiatschek, Holger Fr\\\"oning, Franz\n  Pernkopf, Zoubin Ghahramani", "title": "Resource-Efficient Neural Networks for Embedded Systems", "comments": "arXiv admin note: text overlap with arXiv:1812.02240", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning is traditionally a resource intensive task, embedded\nsystems, autonomous navigation, and the vision of the Internet of Things fuel\nthe interest in resource-efficient approaches. These approaches aim for a\ncarefully chosen trade-off between performance and resource consumption in\nterms of computation and energy. The development of such approaches is among\nthe major challenges in current machine learning research and key to ensure a\nsmooth transition of machine learning technology from a scientific environment\nwith virtually unlimited computing resources into every day's applications. In\nthis article, we provide an overview of the current state of the art of machine\nlearning techniques facilitating these real-world requirements. In particular,\nwe focus on deep neural networks (DNNs), the predominant machine learning\nmodels of the past decade. We give a comprehensive overview of the vast\nliterature that can be mainly split into three non-mutually exclusive\ncategories: (i) quantized neural networks, (ii) network pruning, and (iii)\nstructural efficiency. These techniques can be applied during training or as\npost-processing, and they are widely used to reduce the computational demands\nin terms of memory footprint, inference speed, and energy efficiency. We\nsubstantiate our discussion with experiments on well-known benchmark data sets\nto showcase the difficulty of finding good trade-offs between\nresource-efficiency and predictive performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 14:17:09 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Roth", "Wolfgang", ""], ["Schindler", "G\u00fcnther", ""], ["Z\u00f6hrer", "Matthias", ""], ["Pfeifenberger", "Lukas", ""], ["Peharz", "Robert", ""], ["Tschiatschek", "Sebastian", ""], ["Fr\u00f6ning", "Holger", ""], ["Pernkopf", "Franz", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2001.03076", "submitter": "Yilun Zhou", "authors": "Serena Booth, Ankit Shah, Yilun Zhou, Julie Shah", "title": "Sampling Prediction-Matching Examples in Neural Networks: A\n  Probabilistic Programming Approach", "comments": "AAAI 2020 Workshop on Statistical Relational AI (StarAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though neural network models demonstrate impressive performance, we do not\nunderstand exactly how these black-box models make individual predictions. This\ndrawback has led to substantial research devoted to understand these models in\nareas such as robustness, interpretability, and generalization ability. In this\npaper, we consider the problem of exploring the prediction level sets of a\nclassifier using probabilistic programming. We define a prediction level set to\nbe the set of examples for which the predictor has the same specified\nprediction confidence with respect to some arbitrary data distribution.\nNotably, our sampling-based method does not require the classifier to be\ndifferentiable, making it compatible with arbitrary classifiers. As a specific\ninstantiation, if we take the classifier to be a neural network and the data\ndistribution to be that of the training data, we can obtain examples that will\nresult in specified predictions by the neural network. We demonstrate this\ntechnique with experiments on a synthetic dataset and MNIST. Such level sets in\nclassification may facilitate human understanding of classification behaviors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:57:51 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Booth", "Serena", ""], ["Shah", "Ankit", ""], ["Zhou", "Yilun", ""], ["Shah", "Julie", ""]]}, {"id": "2001.03093", "submitter": "Boris Ivanovic", "authors": "Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, Marco Pavone", "title": "Trajectron++: Dynamically-Feasible Trajectory Forecasting With\n  Heterogeneous Data", "comments": "23 pages, 6 figures, 5 tables. All code, models, and data can be\n  found at https://github.com/StanfordASL/Trajectron-plus-plus . European\n  Conference on Computer Vision (ECCV) 2020. Fixed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about human motion is an important prerequisite to safe and\nsocially-aware robotic navigation. As a result, multi-agent behavior prediction\nhas become a core component of modern human-robot interactive systems, such as\nself-driving cars. While there exist many methods for trajectory forecasting,\nmost do not enforce dynamic constraints and do not account for environmental\ninformation (e.g., maps). Towards this end, we present Trajectron++, a modular,\ngraph-structured recurrent model that forecasts the trajectories of a general\nnumber of diverse agents while incorporating agent dynamics and heterogeneous\ndata (e.g., semantic maps). Trajectron++ is designed to be tightly integrated\nwith robotic planning and control frameworks; for example, it can produce\npredictions that are optionally conditioned on ego-agent motion plans. We\ndemonstrate its performance on several challenging real-world trajectory\nforecasting datasets, outperforming a wide array of state-of-the-art\ndeterministic and generative methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 16:47:17 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 21:42:44 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 07:41:13 GMT"}, {"version": "v4", "created": "Sat, 21 Nov 2020 00:14:52 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 18:53:02 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Salzmann", "Tim", ""], ["Ivanovic", "Boris", ""], ["Chakravarty", "Punarjay", ""], ["Pavone", "Marco", ""]]}, {"id": "2001.03103", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Dongrui Wu, Jian Huang, Yu-Kai Wang, Chin-Teng Lin", "title": "Supervised Discriminative Sparse PCA with Adaptive Neighbors for\n  Dimensionality Reduction", "comments": "Int'l Joint Conf. on Neural Networks (IJCNN), Glasgow, UK, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is an important operation in information\nvisualization, feature extraction, clustering, regression, and classification,\nespecially for processing noisy high dimensional data. However, most existing\napproaches preserve either the global or the local structure of the data, but\nnot both. Approaches that preserve only the global data structure, such as\nprincipal component analysis (PCA), are usually sensitive to outliers.\nApproaches that preserve only the local data structure, such as locality\npreserving projections, are usually unsupervised (and hence cannot use label\ninformation) and uses a fixed similarity graph. We propose a novel linear\ndimensionality reduction approach, supervised discriminative sparse PCA with\nadaptive neighbors (SDSPCAAN), to integrate neighborhood-free supervised\ndiscriminative sparse PCA and projected clustering with adaptive neighbors. As\na result, both global and local data structures, as well as the label\ninformation, are used for better dimensionality reduction. Classification\nexperiments on nine high-dimensional datasets validated the effectiveness and\nrobustness of our proposed SDSPCAAN.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:02:26 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 15:38:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Shi", "Zhenhua", ""], ["Wu", "Dongrui", ""], ["Huang", "Jian", ""], ["Wang", "Yu-Kai", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2001.03108", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian\n  Noises: Explicit Bounds and Feedback Coding Design", "comments": "Note that this is an extended version of the original submission \"A\n  Connection between Feedback Capacity and Kalman Filter for Colored Gaussian\n  Noises\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.SY eess.SP eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we relate a feedback channel with any finite-order\nautoregressive moving-average (ARMA) Gaussian noises to a variant of the Kalman\nfilter. In light of this, we obtain relatively explicit lower bounds on the\nfeedback capacity for such colored Gaussian noises, and the bounds are seen to\nbe consistent with various existing results in the literature. Meanwhile, this\nvariant of the Kalman filter also leads to explicit recursive coding schemes\nwith clear structures to achieve the lower bounds. In general, our results\nprovide an alternative perspective while pointing to potentially tighter bounds\nfor the feedback capacity problem.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:11:40 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 19:56:28 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 16:38:29 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 15:41:08 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 15:13:25 GMT"}, {"version": "v6", "created": "Thu, 3 Jun 2021 22:40:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2001.03115", "submitter": "Amelia Averitt", "authors": "Amelia J. Averitt, Natnicha Vanitchanant, Rajesh Ranganath, and Adler\n  J. Perotte", "title": "The Counterfactual $\\chi$-GAN", "comments": "9 pages; 3 figures; See peer-reviewed work at Journal of Biomedical\n  Informatics", "journal-ref": "JBI. 2020. PMID: 32771540", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference often relies on the counterfactual framework, which requires\nthat treatment assignment is independent of the outcome, known as strong\nignorability. Approaches to enforcing strong ignorability in causal analyses of\nobservational data include weighting and matching methods. Effect estimates,\nsuch as the average treatment effect (ATE), are then estimated as expectations\nunder the reweighted or matched distribution, P . The choice of P is important\nand can impact the interpretation of the effect estimate and the variance of\neffect estimates. In this work, instead of specifying P, we learn a\ndistribution that simultaneously maximizes coverage and minimizes variance of\nATE estimates. In order to learn this distribution, this research proposes a\ngenerative adversarial network (GAN)-based model called the Counterfactual\n$\\chi$-GAN (cGAN), which also learns feature-balancing weights and supports\nunbiased causal estimation in the absence of unobserved confounding. Our model\nminimizes the Pearson $\\chi^2$ divergence, which we show simultaneously\nmaximizes coverage and minimizes the variance of importance sampling estimates.\nTo our knowledge, this is the first such application of the Pearson $\\chi^2$\ndivergence. We demonstrate the effectiveness of cGAN in achieving feature\nbalance relative to established weighting methods in simulation and with\nreal-world medical data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:23:13 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 14:14:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Averitt", "Amelia J.", ""], ["Vanitchanant", "Natnicha", ""], ["Ranganath", "Rajesh", ""], ["Perotte", "Adler J.", ""]]}, {"id": "2001.03136", "submitter": "Romit Maulik", "authors": "Romit Maulik, Rajeev Surendran Array, Prasanna Balaprakash", "title": "Site-specific graph neural network for predicting protonation energy of\n  oxygenate molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-oil molecule assessment is essential for the sustainable development of\nchemicals and transportation fuels. These oxygenated molecules have adequate\ncarbon, hydrogen, and oxygen atoms that can be used for developing new\nvalue-added molecules (chemicals or transportation fuels). One motivation for\nour study stems from the fact that a liquid phase upgrading using mineral acid\nis a cost-effective chemical transformation. In this chemical upgrading\nprocess, adding a proton (positively charged atomic hydrogen) to an oxygen atom\nis a central step. The protonation energies of oxygen atoms in a molecule\ndetermine the thermodynamic feasibility of the reaction and likely chemical\nreaction pathway. A quantum chemical model based on coupled cluster theory is\nused to compute accurate thermochemical properties such as the protonation\nenergies of oxygen atoms and the feasibility of protonation-based chemical\ntransformations. However, this method is too computationally expensive to\nexplore a large space of chemical transformations. We develop a graph neural\nnetwork approach for predicting protonation energies of oxygen atoms of\nhundreds of bioxygenate molecules to predict the feasibility of aqueous acidic\nreactions. Our approach relies on an iterative local nonlinear embedding that\ngradually leads to global influence of distant atoms and a output layer that\npredicts the protonation energy. Our approach is geared to site-specific\npredictions for individual oxygen atoms of a molecule in comparison with\ncommonly used graph convolutional networks that focus on a singular molecular\nproperty prediction. We demonstrate that our approach is effective in learning\nthe location and magnitudes of protonation energies of oxygenated molecules.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 21:02:04 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Maulik", "Romit", ""], ["Array", "Rajeev Surendran", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2001.03148", "submitter": "Yufei Zhang", "authors": "Christoph Reisinger, Yufei Zhang", "title": "Regularity and stability of feedback relaxed controls", "comments": "Additional comments have been included, such that the importance of\n  stable feedback controls for reinforcement learning. The manuscript will be\n  published in SIAM Journal on Control and Optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a relaxed control regularization with general exploration\nrewards to design robust feedback controls for multi-dimensional\ncontinuous-time stochastic exit time problems. We establish that the\nregularized control problem admits a H\\\"{o}lder continuous feedback control,\nand demonstrate that both the value function and the feedback control of the\nregularized control problem are Lipschitz stable with respect to parameter\nperturbations. Moreover, we show that a pre-computed feedback relaxed control\nhas a robust performance in a perturbed system, and derive a first-order\nsensitivity equation for both the value function and optimal feedback relaxed\ncontrol. These stability results provide a theoretical justification for recent\nreinforcement learning heuristics that including an exploration reward in the\noptimization objective leads to more robust decision making. We finally prove\nfirst-order monotone convergence of the value functions for relaxed control\nproblems with vanishing exploration parameters, which subsequently enables us\nto construct the pure exploitation strategy of the original control problem\nbased on the feedback relaxed controls.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:24:18 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 14:33:58 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Reisinger", "Christoph", ""], ["Zhang", "Yufei", ""]]}, {"id": "2001.03152", "submitter": "Krishna Kumar Singh", "authors": "Krishna Kumar Singh, Dhruv Mahajan, Kristen Grauman, Yong Jae Lee,\n  Matt Feiszli, Deepti Ghadiyaram", "title": "Don't Judge an Object by Its Context: Learning to Overcome Contextual\n  Bias", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models often leverage co-occurrences between objects and their\ncontext to improve recognition accuracy. However, strongly relying on context\nrisks a model's generalizability, especially when typical co-occurrence\npatterns are absent. This work focuses on addressing such contextual biases to\nimprove the robustness of the learnt feature representations. Our goal is to\naccurately recognize a category in the absence of its context, without\ncompromising on performance when it co-occurs with context. Our key idea is to\ndecorrelate feature representations of a category from its co-occurring\ncontext. We achieve this by learning a feature subspace that explicitly\nrepresents categories occurring in the absence of context along side a joint\nfeature subspace that represents both categories and context. Our very simple\nyet effective method is extensible to two multi-label tasks -- object and\nattribute classification. On 4 challenging datasets, we demonstrate the\neffectiveness of our method in reducing contextual bias.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:31:55 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 23:20:53 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Singh", "Krishna Kumar", ""], ["Mahajan", "Dhruv", ""], ["Grauman", "Kristen", ""], ["Lee", "Yong Jae", ""], ["Feiszli", "Matt", ""], ["Ghadiyaram", "Deepti", ""]]}, {"id": "2001.03192", "submitter": "Mark Tygert", "authors": "Chuan Guo, Awni Hannun, Brian Knott, Laurens van der Maaten, Mark\n  Tygert, and Ruiyu Zhu", "title": "Secure multiparty computations in floating-point arithmetic", "comments": "31 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG cs.NA math.IT math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure multiparty computations enable the distribution of so-called shares of\nsensitive data to multiple parties such that the multiple parties can\neffectively process the data while being unable to glean much information about\nthe data (at least not without collusion among all parties to put back together\nall the shares). Thus, the parties may conspire to send all their processed\nresults to a trusted third party (perhaps the data provider) at the conclusion\nof the computations, with only the trusted third party being able to view the\nfinal results. Secure multiparty computations for privacy-preserving\nmachine-learning turn out to be possible using solely standard floating-point\narithmetic, at least with a carefully controlled leakage of information less\nthan the loss of accuracy due to roundoff, all backed by rigorous mathematical\nproofs of worst-case bounds on information loss and numerical stability in\nfinite-precision arithmetic. Numerical examples illustrate the high performance\nattained on commodity off-the-shelf hardware for generalized linear models,\nincluding ordinary linear least-squares regression, binary and multinomial\nlogistic regression, probit regression, and Poisson regression.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 19:30:14 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Guo", "Chuan", ""], ["Hannun", "Awni", ""], ["Knott", "Brian", ""], ["van der Maaten", "Laurens", ""], ["Tygert", "Mark", ""], ["Zhu", "Ruiyu", ""]]}, {"id": "2001.03203", "submitter": "Jason Radford", "authors": "Jason Radford and Kenneth Joseph", "title": "Theory In, Theory Out: The uses of social theory in machine learning for\n  social science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research at the intersection of machine learning and the social sciences has\nprovided critical new insights into social behavior. At the same time, a\nvariety of critiques have been raised ranging from technical issues with the\ndata used and features constructed, problematic assumptions built into models,\ntheir limited interpretability, and their contribution to bias and inequality.\nWe argue such issues arise primarily because of the lack of social theory at\nvarious stages of the model building and analysis. In the first half of this\npaper, we walk through how social theory can be used to answer the basic\nmethodological and interpretive questions that arise at each stage of the\nmachine learning pipeline. In the second half, we show how theory can be used\nto assess and compare the quality of different social learning models,\nincluding interpreting, generalizing, and assessing the fairness of models. We\nbelieve this paper can act as a guide for computer and social scientists alike\nto navigate the substantive questions involved in applying the tools of machine\nlearning to social data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:04:25 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 17:29:04 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 16:11:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Radford", "Jason", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2001.03205", "submitter": "William Beksi", "authors": "Aditya Rajguru, Christopher Collander, William J. Beksi", "title": "Camera-Based Adaptive Trajectory Guidance via Neural Networks", "comments": "To be published in the 2020 6th International Conference on\n  Mechatronics and Robotics Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel method to capture visual trajectories for\nnavigating an indoor robot in dynamic settings using streaming image data.\nFirst, an image processing pipeline is proposed to accurately segment\ntrajectories from noisy backgrounds. Next, the captured trajectories are used\nto design, train, and compare two neural network architectures for predicting\nacceleration and steering commands for a line following robot over a continuous\nspace in real time. Lastly, experimental results demonstrate the performance of\nthe neural networks versus human teleoperation of the robot and the viability\nof the system in environments with occlusions and/or low-light conditions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:05:25 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Rajguru", "Aditya", ""], ["Collander", "Christopher", ""], ["Beksi", "William J.", ""]]}, {"id": "2001.03224", "submitter": "Joseph Futoma", "authors": "Joseph Futoma, Muhammad A. Masood, Finale Doshi-Velez", "title": "Identifying Distinct, Effective Treatments for Acute Hypotension with\n  SODA-RL: Safely Optimized Diverse Accurate Reinforcement Learning", "comments": "Accepted for publication at the AMIA 2020 Informatics Summit. This\n  version contains an updated appendix with additional figures not found in the\n  page-constrained AMIA version, so treat this version as the most up-to-date", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypotension in critical care settings is a life-threatening emergency that\nmust be recognized and treated early. While fluid bolus therapy and\nvasopressors are common treatments, it is often unclear which interventions to\ngive, in what amounts, and for how long. Observational data in the form of\nelectronic health records can provide a source for helping inform these choices\nfrom past events, but often it is not possible to identify a single best\nstrategy from observational data alone. In such situations, we argue it is\nimportant to expose the collection of plausible options to a provider. To this\nend, we develop SODA-RL: Safely Optimized, Diverse, and Accurate Reinforcement\nLearning, to identify distinct treatment options that are supported in the\ndata. We demonstrate SODA-RL on a cohort of 10,142 ICU stays where hypotension\npresented. Our learned policies perform comparably to the observed physician\nbehaviors, while providing different, plausible alternatives for treatment\ndecisions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 21:10:43 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Futoma", "Joseph", ""], ["Masood", "Muhammad A.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2001.03229", "submitter": "Sen Lin", "authors": "Sen Lin, Guang Yang and Junshan Zhang", "title": "Real-Time Edge Intelligence in the Making: A Collaborative Learning\n  Framework via Federated Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many IoT applications at the network edge demand intelligent decisions in a\nreal-time manner. The edge device alone, however, often cannot achieve\nreal-time edge intelligence due to its constrained computing resources and\nlimited local data. To tackle these challenges, we propose a platform-aided\ncollaborative learning framework where a model is first trained across a set of\nsource edge nodes by a federated meta-learning approach, and then it is rapidly\nadapted to learn a new task at the target edge node, using a few samples only.\nFurther, we investigate the convergence of the proposed federated meta-learning\nalgorithm under mild conditions on node similarity and the adaptation\nperformance at the target edge. To combat against the vulnerability of\nmeta-learning algorithms to possible adversarial attacks, we further propose a\nrobust version of the federated meta-learning algorithm based on\ndistributionally robust optimization, and establish its convergence under mild\nconditions. Experiments on different datasets demonstrate the effectiveness of\nthe proposed Federated Meta-Learning based framework.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 21:37:42 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 23:54:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Lin", "Sen", ""], ["Yang", "Guang", ""], ["Zhang", "Junshan", ""]]}, {"id": "2001.03253", "submitter": "Ardavan Pedram", "authors": "Noah Gamboa, Kais Kudrolli, Anand Dhoot, Ardavan Pedram", "title": "Campfire: Compressible, Regularization-Free, Structured Sparse Training\n  for Hardware Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies structured sparse training of CNNs with a gradual pruning\ntechnique that leads to fixed, sparse weight matrices after a set number of\nepochs. We simplify the structure of the enforced sparsity so that it reduces\noverhead caused by regularization. The proposed training methodology Campfire\nexplores pruning at granularities within a convolutional kernel and filter.\n  We study various tradeoffs with respect to pruning duration, level of\nsparsity, and learning rate configuration. We show that our method creates a\nsparse version of ResNet-50 and ResNet-50 v1.5 on full ImageNet while remaining\nwithin a negligible <1% margin of accuracy loss. To ensure that this type of\nsparse training does not harm the robustness of the network, we also\ndemonstrate how the network behaves in the presence of adversarial attacks. Our\nresults show that with 70% target sparsity, over 75% top-1 accuracy is\nachievable.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:15:43 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 01:35:41 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gamboa", "Noah", ""], ["Kudrolli", "Kais", ""], ["Dhoot", "Anand", ""], ["Pedram", "Ardavan", ""]]}, {"id": "2001.03255", "submitter": "Stefan Horoi", "authors": "Stefan Horoi, Guillaume Lajoie and Guy Wolf", "title": "Internal representation dynamics and geometry in recurrent neural\n  networks", "comments": "Presented as a poster at MAIS 2019: the Montreal AI Symposium,\n  Montreal, Quebec, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of recurrent neural networks (RNNs) in dealing with sequential\ndata has long been established. However, unlike deep, and convolution networks\nwhere we can attribute the recognition of a certain feature to every layer, it\nis unclear what \"sub-task\" a single recurrent step or layer accomplishes. Our\nwork seeks to shed light onto how a vanilla RNN implements a simple\nclassification task by analysing the dynamics of the network and the geometric\nproperties of its hidden states. We find that early internal representations\nare evocative of the real labels of the data but this information is not\ndirectly accessible to the output layer. Furthermore the network's dynamics and\nthe sequence length are both critical to correct classifications even when\nthere is no additional task relevant information provided.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:19:21 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 14:23:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Horoi", "Stefan", ""], ["Lajoie", "Guillaume", ""], ["Wolf", "Guy", ""]]}, {"id": "2001.03260", "submitter": "Hayda Almeida", "authors": "Hayda Almeida, Adrian Tsang, Abdoulaye Banir\\'e Diallo", "title": "Supporting supervised learning in fungal Biosynthetic Gene Cluster\n  discovery: new benchmark datasets", "comments": "Accepted to Machine Learning and Artificial Intelligence in\n  Bioinformatics and Medical Informatics (MABM2019) at IEEE BIBM 2019", "journal-ref": null, "doi": "10.1109/BIBM47256.2019.8983041", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fungal Biosynthetic Gene Clusters (BGCs) of secondary metabolites are\nclusters of genes capable of producing natural products, compounds that play an\nimportant role in the production of a wide variety of bioactive compounds,\nincluding antibiotics and pharmaceuticals. Identifying BGCs can lead to the\ndiscovery of novel natural products to benefit human health. Previous work has\nbeen focused on developing automatic tools to support BGC discovery in plants,\nfungi, and bacteria. Data-driven methods, as well as probabilistic and\nsupervised learning methods have been explored in identifying BGCs. Most\nmethods applied to identify fungal BGCs were data-driven and presented limited\nscope. Supervised learning methods have been shown to perform well at\nidentifying BGCs in bacteria, and could be well suited to perform the same task\nin fungi. But labeled data instances are needed to perform supervised learning.\nOpenly accessible BGC databases contain only a very small portion of previously\ncurated fungal BGCs. Making new fungal BGC datasets available could motivate\nthe development of supervised learning methods for fungal BGCs and potentially\nimprove prediction performance compared to data-driven methods. In this work we\npropose new publicly available fungal BGC datasets to support the BGC discovery\ntask using supervised learning. These datasets are prepared to perform binary\nclassification and predict candidate BGC regions in fungal genomes. In addition\nwe analyse the performance of a well supported supervised learning tool\ndeveloped to predict BGCs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:47:12 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Almeida", "Hayda", ""], ["Tsang", "Adrian", ""], ["Diallo", "Abdoulaye Banir\u00e9", ""]]}, {"id": "2001.03272", "submitter": "Kaushik Chakrabarti", "authors": "Kaushik Chakrabarti, Zhimin Chen, Siamak Shakeri, Guihong Cao", "title": "Open Domain Question Answering Using Web Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables extracted from web documents can be used to directly answer many web\nsearch queries. Previous works on question answering (QA) using web tables have\nfocused on factoid queries, i.e., those answerable with a short string like\nperson name or a number. However, many queries answerable using tables are\nnon-factoid in nature. In this paper, we develop an open-domain QA approach\nusing web tables that works for both factoid and non-factoid queries. Our key\ninsight is to combine deep neural network-based semantic similarity between the\nquery and the table with features that quantify the dominance of the table in\nthe document as well as the quality of the information in the table. Our\nexperiments on real-life web search queries show that our approach\nsignificantly outperforms state-of-the-art baseline approaches. Our solution is\nused in production in a major commercial web search engine and serves direct\nanswers for tens of millions of real user queries per month.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:25:04 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Chakrabarti", "Kaushik", ""], ["Chen", "Zhimin", ""], ["Shakeri", "Siamak", ""], ["Cao", "Guihong", ""]]}, {"id": "2001.03274", "submitter": "Shuo Wang", "authors": "Shuo Wang, Surya Nepal, Carsten Rudolph, Marthie Grobler, Shangyu\n  Chen, Tianle Chen", "title": "Backdoor Attacks against Transfer Learning with Pre-trained Deep\n  Learning Models", "comments": null, "journal-ref": null, "doi": "10.1109/TSC.2020.3000900", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning provides an effective solution for feasibly and fast\ncustomize accurate \\textit{Student} models, by transferring the learned\nknowledge of pre-trained \\textit{Teacher} models over large datasets via\nfine-tuning. Many pre-trained Teacher models used in transfer learning are\npublicly available and maintained by public platforms, increasing their\nvulnerability to backdoor attacks. In this paper, we demonstrate a backdoor\nthreat to transfer learning tasks on both image and time-series data leveraging\nthe knowledge of publicly accessible Teacher models, aimed at defeating three\ncommonly-adopted defenses: \\textit{pruning-based}, \\textit{retraining-based}\nand \\textit{input pre-processing-based defenses}. Specifically, (A)\nranking-based selection mechanism to speed up the backdoor trigger generation\nand perturbation process while defeating \\textit{pruning-based} and/or\n\\textit{retraining-based defenses}. (B) autoencoder-powered trigger generation\nis proposed to produce a robust trigger that can defeat the \\textit{input\npre-processing-based defense}, while guaranteeing that selected neuron(s) can\nbe significantly activated. (C) defense-aware retraining to generate the\nmanipulated model using reverse-engineered model inputs.\n  We launch effective misclassification attacks on Student models over\nreal-world images, brain Magnetic Resonance Imaging (MRI) data and\nElectrocardiography (ECG) learning systems. The experiments reveal that our\nenhanced attack can maintain the $98.4\\%$ and $97.2\\%$ classification accuracy\nas the genuine model on clean image and time series inputs respectively while\nimproving $27.9\\%-100\\%$ and $27.1\\%-56.1\\%$ attack success rate on trojaned\nimage and time series inputs respectively in the presence of pruning-based\nand/or retraining-based defenses.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:31:09 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 10:10:11 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Shuo", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""], ["Chen", "Shangyu", ""], ["Chen", "Tianle", ""]]}, {"id": "2001.03286", "submitter": "Yujian Li", "authors": "Yujian Li, Bowen Liu, Zhaoying Liu, and Ting Zhang", "title": "Probabilistic K-means Clustering via Nonlinear Programming", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means is a classical clustering algorithm with wide applications. However,\nsoft K-means, or fuzzy c-means at m=1, remains unsolved since 1981. To address\nthis challenging open problem, we propose a novel clustering model, i.e.\nProbabilistic K-Means (PKM), which is also a nonlinear programming model\nconstrained on linear equalities and linear inequalities. In theory, we can\nsolve the model by active gradient projection, while inefficiently. Thus, we\nfurther propose maximum-step active gradient projection and fast maximum-step\nactive gradient projection to solve it more efficiently. By experiments, we\nevaluate the performance of PKM and how well the proposed methods solve it in\nfive aspects: initialization robustness, clustering performance, descending\nstability, iteration number, and convergence speed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 02:40:41 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 00:59:26 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Li", "Yujian", ""], ["Liu", "Bowen", ""], ["Liu", "Zhaoying", ""], ["Zhang", "Ting", ""]]}, {"id": "2001.03288", "submitter": "Juhyun Lee", "authors": "Yury Pisarchyk and Juhyun Lee", "title": "Efficient Memory Management for Deep Neural Net Inference", "comments": "6 pages, 6 figures, MLSys 2020 Workshop on Resource-Constrained\n  Machine Learning (ReCoML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural net inference was considered a task for servers only,\nlatest advances in technology allow the task of inference to be moved to mobile\nand embedded devices, desired for various reasons ranging from latency to\nprivacy. These devices are not only limited by their compute power and battery,\nbut also by their inferior physical memory and cache, and thus, an efficient\nmemory manager becomes a crucial component for deep neural net inference at the\nedge. We explore various strategies to smartly share memory buffers among\nintermediate tensors in deep neural nets. Employing these can result in up to\n11% smaller memory footprint than the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 02:45:41 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 01:21:43 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 02:32:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Pisarchyk", "Yury", ""], ["Lee", "Juhyun", ""]]}, {"id": "2001.03294", "submitter": "Gholamreza Haffari", "authors": "Poorya Zaremoodi, Gholamreza Haffari", "title": "Learning to Multi-Task Learn for Better Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of parallel sentence pairs is a major challenge for training high\nquality neural machine translation (NMT) models in bilingually low-resource\nscenarios, as NMT is data-hungry. Multi-task learning is an elegant approach to\ninject linguistic-related inductive biases into NMT, using auxiliary syntactic\nand semantic tasks, to improve generalisation. The challenge, however, is to\ndevise effective training schedules, prescribing when to make use of the\nauxiliary tasks during the training process to fill the knowledge gaps of the\nmain translation task, a setting referred to as biased-MTL. Current approaches\nfor the training schedule are based on hand-engineering heuristics, whose\neffectiveness vary in different MTL settings. We propose a novel framework for\nlearning the training schedule, ie learning to multi-task learn, for the MTL\nsetting of interest. We formulate the training schedule as a Markov decision\nprocess which paves the way to employ policy learning methods to learn the\nscheduling policy. We effectively and efficiently learn the training schedule\npolicy within the imitation learning framework using an oracle policy algorithm\nthat dynamically sets the importance weights of auxiliary tasks based on their\ncontributions to the generalisability of the main NMT task. Experiments on\nlow-resource NMT settings show the resulting automatically learned training\nschedulers are competitive with the best heuristics, and lead to up to +1.1\nBLEU score improvements.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 03:12:28 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zaremoodi", "Poorya", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2001.03305", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde, Pujan Kandel, Concetto Spampinato, Michael B. Wallace,\n  Ulas Bagci", "title": "Diagnosing Colorectal Polyps in the Wild with Capsule Networks", "comments": "Accepted for publication at ISBI 2020 (IEEE International Symposium\n  on Biomedical Imaging). Code is publicly available at\n  https://github.com/lalonderodney/D-Caps", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer, largely arising from precursor lesions called polyps,\nremains one of the leading causes of cancer-related death worldwide. Current\nclinical standards require the resection and histopathological analysis of\npolyps due to test accuracy and sensitivity of optical biopsy methods falling\nsubstantially below recommended levels. In this study, we design a novel\ncapsule network architecture (D-Caps) to improve the viability of optical\nbiopsy of colorectal polyps. Our proposed method introduces several technical\nnovelties including a novel capsule architecture with a capsule-average pooling\n(CAP) method to improve efficiency in large-scale image classification. We\ndemonstrate improved results over the previous state-of-the-art convolutional\nneural network (CNN) approach by as much as 43%. This work provides an\nimportant benchmark on the new Mayo Polyp dataset, a significantly more\nchallenging and larger dataset than previous polyp studies, with results\nstratified across all available categories, imaging devices and modalities, and\nfocus modes to promote future direction into AI-driven colorectal cancer\nscreening systems. Code is publicly available at\nhttps://github.com/lalonderodney/D-Caps .\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 04:55:01 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["LaLonde", "Rodney", ""], ["Kandel", "Pujan", ""], ["Spampinato", "Concetto", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "2001.03311", "submitter": "Bang An", "authors": "Sicheng Zhu, Bang An, Shiyu Niu", "title": "Guess First to Enable Better Compression and Adversarial Robustness", "comments": "Accepted by NeurIPS 2019 workshop on Information Theory and Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are generally vulnerable to adversarial examples,\nwhich is in contrast to the robustness of humans. In this paper, we try to\nleverage one of the mechanisms in human recognition and propose a bio-inspired\nclassification framework in which model inference is conditioned on label\nhypothesis. We provide a class of training objectives for this framework and an\ninformation bottleneck regularizer which utilizes the advantage that label\ninformation can be discarded during inference. This framework enables better\ncompression of the mutual information between inputs and latent representations\nwithout loss of learning capacity, at the cost of tractable inference\ncomplexity. Better compression and elimination of label information further\nbring better adversarial robustness without loss of natural accuracy, which is\ndemonstrated in the experiment.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:12:22 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zhu", "Sicheng", ""], ["An", "Bang", ""], ["Niu", "Shiyu", ""]]}, {"id": "2001.03314", "submitter": "Van Mao Ngo", "authors": "Mao V. Ngo, Hakima Chaouchi, Tie Luo, Tony Q.S. Quek", "title": "Adaptive Anomaly Detection for IoT Data in Hierarchical Edge Computing", "comments": "To be published in the AAAI Workshop on Artificial Intelligence of\n  Things (AIoT), Feb 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNN) greatly bolster real-time detection of\nanomalous IoT data. However, IoT devices can barely afford complex DNN models\ndue to limited computational power and energy supply. While one can offload\nanomaly detection tasks to the cloud, it incurs long delay and requires large\nbandwidth when thousands of IoT devices stream data to the cloud concurrently.\nIn this paper, we propose an adaptive anomaly detection approach for\nhierarchical edge computing (HEC) systems to solve this problem. Specifically,\nwe first construct three anomaly detection DNN models of increasing complexity,\nand associate them with the three layers of HEC from bottom to top, i.e., IoT\ndevices, edge servers, and cloud. Then, we design an adaptive scheme to select\none of the models based on the contextual information extracted from input\ndata, to perform anomaly detection. The selection is formulated as a contextual\nbandit problem and is characterized by a single-step Markov decision process,\nwith an objective of achieving high detection accuracy and low detection delay\nsimultaneously. We evaluate our proposed approach using a real IoT dataset, and\ndemonstrate that it reduces detection delay by 84% while maintaining almost the\nsame accuracy as compared to offloading detection tasks to the cloud. In\naddition, our evaluation also shows that it outperforms other baseline schemes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:29:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ngo", "Mao V.", ""], ["Chaouchi", "Hakima", ""], ["Luo", "Tie", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2001.03316", "submitter": "Vatsal Shah", "authors": "Vatsal Shah, Xiaoxia Wu, Sujay Sanghavi", "title": "Choosing the Sample with Lowest Loss makes SGD Robust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of outliers can potentially significantly skew the parameters of\nmachine learning models trained via stochastic gradient descent (SGD). In this\npaper we propose a simple variant of the simple SGD method: in each step, first\nchoose a set of k samples, then from these choose the one with the smallest\ncurrent loss, and do an SGD-like update with this chosen sample. Vanilla SGD\ncorresponds to k = 1, i.e. no choice; k >= 2 represents a new algorithm that is\nhowever effectively minimizing a non-convex surrogate loss. Our main\ncontribution is a theoretical analysis of the robustness properties of this\nidea for ML problems which are sums of convex losses; these are backed up with\nlinear regression and small-scale neural network experiments\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 05:39:17 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shah", "Vatsal", ""], ["Wu", "Xiaoxia", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "2001.03324", "submitter": "Ibrahim Gashaw", "authors": "Ibrahim Gashaw and H L. Shashirekha", "title": "Machine Learning Approaches for Amharic Parts-of-speech Tagging", "comments": "15th International Conference on Natural Language Processing\n  (ICON-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part-of-speech (POS) tagging is considered as one of the basic but necessary\ntools which are required for many Natural Language Processing (NLP)\napplications such as word sense disambiguation, information retrieval,\ninformation processing, parsing, question answering, and machine translation.\nPerformance of the current POS taggers in Amharic is not as good as that of the\ncontemporary POS taggers available for English and other European languages.\nThe aim of this work is to improve POS tagging performance for the Amharic\nlanguage, which was never above 91%. Usage of morphological knowledge, an\nextension of the existing annotated data, feature extraction, parameter tuning\nby applying grid search and the tagging algorithms have been examined and\nobtained significant performance difference from the previous works. We have\nused three different datasets for POS experiments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 06:40:49 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Gashaw", "Ibrahim", ""], ["Shashirekha", "H L.", ""]]}, {"id": "2001.03333", "submitter": "Zineb Lanbouri", "authors": "Zineb Lanbouri and Saaid Achchab", "title": "A new approach for trading based on Long Short Term Memory technique", "comments": "7 pages, 6 figures", "journal-ref": "IJCSI (International Journal of Computer Science Issues), Volume\n  16, Issue 1, March 2019", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The stock market prediction has always been crucial for stakeholders, traders\nand investors. We developed an ensemble Long Short Term Memory (LSTM) model\nthat includes two-time frequencies (annual and daily parameters) in order to\npredict the next-day Closing price (one step ahead). Based on a four-step\napproach, this methodology is a serial combination of two LSTM algorithms. The\nempirical experiment is applied to 417 NY stock exchange companies. Based on\nOpen High Low Close metrics and other financial ratios, this approach proves\nthat the stock market prediction can be improved.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 07:56:30 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Lanbouri", "Zineb", ""], ["Achchab", "Saaid", ""]]}, {"id": "2001.03340", "submitter": "Matthias Weissenbacher", "authors": "Matthias Weissenbacher", "title": "Temporally Folded Convolutional Neural Networks for Sequence Forecasting", "comments": "8 pages, 4 figures, submitted to IJCAI 2020 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel approach to utilize convolutional neural\nnetworks for time series forecasting. The time direction of the sequential data\nwith spatial dimensions $D=1,2$ is considered democratically as the input of a\nspatiotemporal $(D+1)$-dimensional convolutional neural network. Latter then\nreduces the data stream from $D +1 \\to D$ dimensions followed by an\nincriminator cell which uses this information to forecast the subsequent time\nstep. We empirically compare this strategy to convolutional LSTM's and LSTM's\non their performance on the sequential MNIST and the JSB chorals dataset,\nrespectively. We conclude that temporally folded convolutional neural networks\n(TFC's) may outperform the conventional recurrent strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 08:18:39 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Weissenbacher", "Matthias", ""]]}, {"id": "2001.03346", "submitter": "Koki Yamada", "authors": "Koki Yamada, Yuichi Tanaka, Antonio Ortega", "title": "Time-Varying Graph Learning with Constraints on Graph Temporal Variation", "comments": "13 pages, submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for learning time-varying graphs from\nspatiotemporal measurements. Given an appropriate prior on the temporal\nbehavior of signals, our proposed method can estimate time-varying graphs from\na small number of available measurements. To achieve this, we introduce two\nregularization terms in convex optimization problems that constrain sparseness\nof temporal variations of the time-varying networks. Moreover, a\ncomputationally-scalable algorithm is introduced to efficiently solve the\noptimization problem. The experimental results with synthetic and real datasets\n(point cloud and temperature data) demonstrate our proposed method outperforms\nthe existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 08:33:51 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Yamada", "Koki", ""], ["Tanaka", "Yuichi", ""], ["Ortega", "Antonio", ""]]}, {"id": "2001.03350", "submitter": "Emil Bj\\\"ornson", "authors": "Emil Bj\\\"ornson and Pontus Giselsson", "title": "Two Applications of Deep Learning in the Physical Layer of Communication\n  Systems", "comments": "Published as lecture note in IEEE Signal Processing Magazine, 12\n  pages, 4 figures", "journal-ref": "Emil Bjornson, Pontus Giselsson, \"Two Applications of Deep\n  Learning in the Physical Layer of Communication Systems,\" IEEE Signal\n  Processing Magazine, vol. 37, no. 5, pp. 134-140, September 2020", "doi": "10.1109/MSP.2020.2996545", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has proved itself to be a powerful tool to develop data-driven\nsignal processing algorithms for challenging engineering problems. By learning\nthe key features and characteristics of the input signals, instead of requiring\na human to first identify and model them, learned algorithms can beat many\nman-made algorithms. In particular, deep neural networks are capable of\nlearning the complicated features in nature-made signals, such as photos and\naudio recordings, and use them for classification and decision making.\n  The situation is rather different in communication systems, where the\ninformation signals are man-made, the propagation channels are relatively easy\nto model, and we know how to operate close to the Shannon capacity limits. Does\nthis mean that there is no role for deep learning in the development of future\ncommunication systems?\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 08:52:34 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 08:43:56 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bj\u00f6rnson", "Emil", ""], ["Giselsson", "Pontus", ""]]}, {"id": "2001.03354", "submitter": "Haiping Huang", "authors": "Chan Li and Haiping Huang", "title": "Learning credit assignment", "comments": "5 pages, 4 figures, a generalized BackProp proposed to learn credit\n  assignment from an network ensemble perspective, to appear in Phys Rev Lett\n  (2020)", "journal-ref": "Phys. Rev. Lett. 125, 178301 (2020)", "doi": "10.1103/PhysRevLett.125.178301", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive prediction accuracies in a variety of\nscientific and industrial domains. However, the nested non-linear feature of\ndeep learning makes the learning highly non-transparent, i.e., it is still\nunknown how the learning coordinates a huge number of parameters to achieve a\ndecision making. To explain this hierarchical credit assignment, we propose a\nmean-field learning model by assuming that an ensemble of sub-networks, rather\nthan a single network, are trained for a classification task. Surprisingly, our\nmodel reveals that apart from some deterministic synaptic weights connecting\ntwo neurons at neighboring layers, there exist a large number of connections\nthat can be absent, and other connections can allow for a broad distribution of\ntheir weight values. Therefore, synaptic connections can be classified into\nthree categories: very important ones, unimportant ones, and those of\nvariability that may partially encode nuisance factors. Therefore, our model\nlearns the credit assignment leading to the decision, and predicts an ensemble\nof sub-networks that can accomplish the same task, thereby providing insights\ntoward understanding the macroscopic behavior of deep learning through the lens\nof distinct roles of synaptic weights.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:06:46 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 09:35:22 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Li", "Chan", ""], ["Huang", "Haiping", ""]]}, {"id": "2001.03359", "submitter": "Guangliang Li", "authors": "Qilei Zhang, Jinying Lin, Qixin Sha, Bo He and Guangliang Li", "title": "Deep Interactive Reinforcement Learning for Path Following of Autonomous\n  Underwater Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous underwater vehicle (AUV) plays an increasingly important role in\nocean exploration. Existing AUVs are usually not fully autonomous and generally\nlimited to pre-planning or pre-programming tasks. Reinforcement learning (RL)\nand deep reinforcement learning have been introduced into the AUV design and\nresearch to improve its autonomy. However, these methods are still difficult to\napply directly to the actual AUV system because of the sparse rewards and low\nlearning efficiency. In this paper, we proposed a deep interactive\nreinforcement learning method for path following of AUV by combining the\nadvantages of deep reinforcement learning and interactive RL. In addition,\nsince the human trainer cannot provide human rewards for AUV when it is running\nin the ocean and AUV needs to adapt to a changing environment, we further\npropose a deep reinforcement learning method that learns from both human\nrewards and environmental rewards at the same time. We test our methods in two\npath following tasks---straight line and sinusoids curve following of AUV by\nsimulating in the Gazebo platform. Our experimental results show that with our\nproposed deep interactive RL method, AUV can converge faster than a DQN learner\nfrom only environmental reward. Moreover, AUV learning with our deep RL from\nboth human and environmental rewards can also achieve a similar or even better\nperformance than that with the deep interactive RL method and can adapt to the\nactual environment by further learning from environmental rewards.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:22:39 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Zhang", "Qilei", ""], ["Lin", "Jinying", ""], ["Sha", "Qixin", ""], ["He", "Bo", ""], ["Li", "Guangliang", ""]]}, {"id": "2001.03369", "submitter": "Robin Brochier", "authors": "Robin Brochier, Adrien Guille and Julien Velcin", "title": "Inductive Document Network Embedding with Topic-Word Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document network embedding aims at learning representations for a structured\ntext corpus i.e. when documents are linked to each other. Recent algorithms\nextend network embedding approaches by incorporating the text content\nassociated with the nodes in their formulations. In most cases, it is hard to\ninterpret the learned representations. Moreover, little importance is given to\nthe generalization to new documents that are not observed within the network.\nIn this paper, we propose an interpretable and inductive document network\nembedding method. We introduce a novel mechanism, the Topic-Word Attention\n(TWA), that generates document representations based on the interplay between\nword and topic representations. We train these word and topic vectors through\nour general model, Inductive Document Network Embedding (IDNE), by leveraging\nthe connections in the document network. Quantitative evaluations show that our\napproach achieves state-of-the-art performance on various networks and we\nqualitatively show that our model produces meaningful and interpretable\nrepresentations of the words, topics and documents.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:14:07 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Brochier", "Robin", ""], ["Guille", "Adrien", ""], ["Velcin", "Julien", ""]]}, {"id": "2001.03371", "submitter": "Yuki Yoshida", "authors": "Yuki Yoshida, Masato Okada", "title": "Data-Dependence of Plateau Phenomenon in Learning with Neural Network\n  --- Statistical Mechanical Analysis", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": "10.1088/1742-5468/abc62f", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plateau phenomenon, wherein the loss value stops decreasing during the\nprocess of learning, has been reported by various researchers. The phenomenon\nis actively inspected in the 1990s and found to be due to the fundamental\nhierarchical structure of neural network models. Then the phenomenon has been\nthought as inevitable. However, the phenomenon seldom occurs in the context of\nrecent deep learning. There is a gap between theory and reality. In this paper,\nusing statistical mechanical formulation, we clarified the relationship between\nthe plateau phenomenon and the statistical property of the data learned. It is\nshown that the data whose covariance has small and dispersed eigenvalues tend\nto make the plateau phenomenon inconspicuous.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:17:08 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yoshida", "Yuki", ""], ["Okada", "Masato", ""]]}, {"id": "2001.03376", "submitter": "Gon\\c{c}alo Mordido", "authors": "Gon\\c{c}alo Mordido, Haojin Yang, Christoph Meinel", "title": "microbatchGAN: Stimulating Diversity with Multi-Adversarial\n  Discrimination", "comments": "WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to tackle the mode collapse problem in generative adversarial\nnetworks (GANs) by using multiple discriminators and assigning a different\nportion of each minibatch, called microbatch, to each discriminator. We\ngradually change each discriminator's task from distinguishing between real and\nfake samples to discriminating samples coming from inside or outside its\nassigned microbatch by using a diversity parameter $\\alpha$. The generator is\nthen forced to promote variety in each minibatch to make the microbatch\ndiscrimination harder to achieve by each discriminator. Thus, all models in our\nframework benefit from having variety in the generated set to reduce their\nrespective losses. We show evidence that our solution promotes sample diversity\nsince early training stages on multiple datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:31:27 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Yang", "Haojin", ""], ["Meinel", "Christoph", ""]]}, {"id": "2001.03386", "submitter": "Sahil Manchanda", "authors": "Sahil Manchanda, Arun Rajkumar, Simarjot Kaur, Narayanan Unny", "title": "SUPAID: A Rule mining based method for automatic rollout decision aid\n  for supervisors in fleet management systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision to rollout a vehicle is critical to fleet management companies\nas wrong decisions can lead to additional cost of maintenance and failures\nduring journey. With the availability of large amount of data and advancement\nof machine learning techniques, the rollout decisions of a supervisor can be\neffectively automated and the mistakes in decisions made by the supervisor\nlearnt. In this paper, we propose a novel learning algorithm SUPAID which under\na natural 'one-way efficiency' assumption on the supervisor, uses a rule mining\napproach to rank the vehicles based on their roll-out feasibility thus helping\nprevent the supervisor from makingerroneous decisions. Our experimental results\non real data from a public transit agency from a city in U.S show that the\nproposed method SUPAID can result in significant cost savings.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:06:04 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 05:34:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Manchanda", "Sahil", ""], ["Rajkumar", "Arun", ""], ["Kaur", "Simarjot", ""], ["Unny", "Narayanan", ""]]}, {"id": "2001.03415", "submitter": "Minghuan Liu", "authors": "Minghuan Liu, Ming Zhou, Weinan Zhang, Yuzheng Zhuang, Jun Wang,\n  Wulong Liu, Yong Yu", "title": "Multi-Agent Interactions Modeling with Correlated Policies", "comments": "20 pages (10 pages of supplementary), 5 figures, Accepted by The\n  Eighth International Conference on Learning Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent systems, complex interacting behaviors arise due to the high\ncorrelations among agents. However, previous work on modeling multi-agent\ninteractions from demonstrations is primarily constrained by assuming the\nindependence among policies and their reward structures. In this paper, we cast\nthe multi-agent interactions modeling problem into a multi-agent imitation\nlearning framework with explicit modeling of correlated policies by\napproximating opponents' policies, which can recover agents' policies that can\nregenerate similar interactions. Consequently, we develop a Decentralized\nAdversarial Imitation Learning algorithm with Correlated policies (CoDAIL),\nwhich allows for decentralized training and execution. Various experiments\ndemonstrate that CoDAIL can better regenerate complex interactions close to the\ndemonstrators and outperforms state-of-the-art multi-agent imitation learning\nmethods. Our code is available at \\url{https://github.com/apexrl/CoDAIL}.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 17:31:53 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 01:17:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 11:22:24 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Minghuan", ""], ["Zhou", "Ming", ""], ["Zhang", "Weinan", ""], ["Zhuang", "Yuzheng", ""], ["Wang", "Jun", ""], ["Liu", "Wulong", ""], ["Yu", "Yong", ""]]}, {"id": "2001.03436", "submitter": "Marcel Hildebrandt", "authors": "Marcel Hildebrandt, Jorge Andres Quintero Serna, Yunpu Ma, Martin\n  Ringsquandl, Mitchell Joblin, Volker Tresp", "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "comments": "AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text\n  overlap with arXiv:2001.00461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:19:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hildebrandt", "Marcel", ""], ["Serna", "Jorge Andres Quintero", ""], ["Ma", "Yunpu", ""], ["Ringsquandl", "Martin", ""], ["Joblin", "Mitchell", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.03438", "submitter": "Dengpeng Huang", "authors": "Dengpeng Huang, Jan Niklas Fuhg, Christian Wei{\\ss}enfels, Peter\n  Wriggers", "title": "A machine learning based plasticity model using proper orthogonal\n  decomposition", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Volume 365,\n  2020, 113008, ISSN 0045-7825,", "doi": "10.1016/j.cma.2020.113008", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven material models have many advantages over classical numerical\napproaches, such as the direct utilization of experimental data and the\npossibility to improve performance of predictions when additional data is\navailable. One approach to develop a data-driven material model is to use\nmachine learning tools. These can be trained offline to fit an observed\nmaterial behaviour and then be applied in online applications. However,\nlearning and predicting history dependent material models, such as plasticity,\nis still challenging. In this work, a machine learning based material modelling\nframework is proposed for both elasticity and plasticity. The machine learning\nbased hyperelasticity model is developed with the Feed forward Neural Network\n(FNN) directly whereas the machine learning based plasticity model is developed\nby using of a novel method called Proper Orthogonal Decomposition Feed forward\nNeural Network (PODFNN). In order to account for the loading history, the\naccumulated absolute strain is proposed to be the history variable of the\nplasticity model. Additionally, the strain-stress sequence data for plasticity\nis collected from different loading-unloading paths based on the concept of\nsequence for plasticity. By means of the POD, the multi-dimensional stress\nsequence is decoupled leading to independent one dimensional coefficient\nsequences. In this case, the neural network with multiple output is replaced by\nmultiple independent neural networks each possessing a one-dimensional output,\nwhich leads to less training time and better training performance. To apply the\nmachine learning based material model in finite element analysis, the tangent\nmatrix is derived by the automatic symbolic differentiation tool AceGen. The\neffectiveness and generalization of the presented models are investigated by a\nseries of numerical examples using both 2D and 3D finite element analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:46:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Huang", "Dengpeng", ""], ["Fuhg", "Jan Niklas", ""], ["Wei\u00dfenfels", "Christian", ""], ["Wriggers", "Peter", ""]]}, {"id": "2001.03447", "submitter": "Damien Garreau", "authors": "Damien Garreau, Ulrike von Luxburg", "title": "Explaining the Explainer: A First Theoretical Analysis of LIME", "comments": "Accepted to AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used more and more often for sensitive applications,\nsometimes replacing humans in critical decision-making processes. As such,\ninterpretability of these algorithms is a pressing need. One popular algorithm\nto provide interpretability is LIME (Local Interpretable Model-Agnostic\nExplanation). In this paper, we provide the first theoretical analysis of LIME.\nWe derive closed-form expressions for the coefficients of the interpretable\nmodel when the function to explain is linear. The good news is that these\ncoefficients are proportional to the gradient of the function to explain: LIME\nindeed discovers meaningful features. However, our analysis also reveals that\npoor choices of parameters can lead LIME to miss important features.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 13:51:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 13:09:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Garreau", "Damien", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "2001.03452", "submitter": "Swagatam Das", "authors": "Saptarshi Chakraborty, Debolina Paul, Swagatam Das, Jason Xu", "title": "Entropy Regularized Power k-Means Clustering", "comments": "Accepted (in updated form) for presentation in the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS 2020), Palermo,\n  Italy, June 03, 2020 - June 05, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its well-known shortcomings, $k$-means remains one of the most widely\nused approaches to data clustering. Current research continues to tackle its\nflaws while attempting to preserve its simplicity. Recently, the \\textit{power\n$k$-means} algorithm was proposed to avoid trapping in local minima by\nannealing through a family of smoother surfaces. However, the approach lacks\ntheoretical justification and fails in high dimensions when many features are\nirrelevant. This paper addresses these issues by introducing \\textit{entropy\nregularization} to learn feature relevance while annealing. We prove\nconsistency of the proposed approach and derive a scalable\nmajorization-minimization algorithm that enjoys closed-form updates and\nconvergence guarantees. In particular, our method retains the same\ncomputational complexity of $k$-means and power $k$-means, but yields\nsignificant improvements over both. Its merits are thoroughly assessed on a\nsuite of real and synthetic data experiments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 14:05:44 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Chakraborty", "Saptarshi", ""], ["Paul", "Debolina", ""], ["Das", "Swagatam", ""], ["Xu", "Jason", ""]]}, {"id": "2001.03458", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li and Jelena Bradic", "title": "Censored Quantile Regression Forest", "comments": "arXiv admin note: text overlap with arXiv:1902.03327", "journal-ref": "International Conference on ArtificialIntelligence and Statistics\n  (AISTATS) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests are powerful non-parametric regression method but are severely\nlimited in their usage in the presence of randomly censored observations, and\nnaively applied can exhibit poor predictive performance due to the incurred\nbiases. Based on a local adaptive representation of random forests, we develop\nits regression adjustment for randomly censored regression quantile models.\nRegression adjustment is based on a new estimating equation that adapts to\ncensoring and leads to quantile score whenever the data do not exhibit\ncensoring. The proposed procedure named {\\it censored quantile regression\nforest}, allows us to estimate quantiles of time-to-event without any\nparametric modeling assumption. We establish its consistency under mild model\nspecifications. Numerical studies showcase a clear advantage of the proposed\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 23:20:23 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Bradic", "Jelena", ""]]}, {"id": "2001.03460", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman", "title": "Transferability of Adversarial Examples to Attack Cloud-based Image\n  Classifier Service", "comments": "Accepted by Defcon China 2019. arXiv admin note: substantial text\n  overlap with arXiv:1906.07997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Learning(DL) techniques have been extensively deployed\nfor computer vision tasks, particularly visual classification problems, where\nnew algorithms reported to achieve or even surpass the human performance. While\nmany recent works demonstrated that DL models are vulnerable to adversarial\nexamples. Fortunately, generating adversarial examples usually requires\nwhite-box access to the victim model, and real-world cloud-based image\nclassification services are more complex than white-box classifier,the\narchitecture and parameters of DL models on cloud platforms cannot be obtained\nby the attacker. The attacker can only access the APIs opened by cloud\nplatforms. Thus, keeping models in the cloud can usually give a (false) sense\nof security. In this paper, we mainly focus on studying the security of\nreal-world cloud-based image classification services. Specifically, (1) We\npropose a novel attack method, Fast Featuremap Loss PGD (FFL-PGD) attack based\non Substitution model, which achieves a high bypass rate with a very limited\nnumber of queries. Instead of millions of queries in previous studies, our\nmethod finds the adversarial examples using only two queries per image; and (2)\nwe make the first attempt to conduct an extensive empirical study of black-box\nattacks against real-world cloud-based classification services. Through\nevaluations on four popular cloud platforms including Amazon, Google,\nMicrosoft, Clarifai, we demonstrate that FFL-PGD attack has a success rate over\n90\\% among different classification services. (3) We discuss the possible\ndefenses to address these security challenges in cloud-based classification\nservices. Our defense technology is mainly divided into model training stage\nand image preprocessing stage.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 23:03:35 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 08:24:48 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 02:07:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Goodman", "Dou", ""]]}, {"id": "2001.03464", "submitter": "Netanel Raviv", "authors": "Netanel Raviv, Siddharth Jain, Jehoshua Bruck", "title": "What is the Value of Data? On Mathematical Methods for Data Quality\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is one of the most important assets of the information age, and its\nsocietal impact is undisputed. Yet, rigorous methods of assessing the quality\nof data are lacking. In this paper, we propose a formal definition for the\nquality of a given dataset. We assess a dataset's quality by a quantity we call\nthe expected diameter, which measures the expected disagreement between two\nrandomly chosen hypotheses that explain it, and has recently found applications\nin active learning. We focus on Boolean hyperplanes, and utilize a collection\nof Fourier analytic, algebraic, and probabilistic methods to come up with\ntheoretical guarantees and practical solutions for the computation of the\nexpected diameter. We also study the behaviour of the expected diameter on\nalgebraically structured datasets, conduct experiments that validate this\nnotion of quality, and demonstrate the feasibility of our techniques.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:56:48 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:53:08 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Raviv", "Netanel", ""], ["Jain", "Siddharth", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "2001.03493", "submitter": "Geoffrey Luke", "authors": "Ruibo Shang, Kevin Hoffer-Hawlik, Geoffrey P. Luke", "title": "A Two-step-training Deep Learning Framework for Real-time Computational\n  Imaging without Physics Priors", "comments": "16 pages, 12 figures", "journal-ref": null, "doi": "10.1364/OE.424165", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is a powerful tool in computational imaging for many\napplications. A common strategy is to reconstruct a preliminary image as the\ninput of a neural network to achieve an optimized image. Usually, the\npreliminary image is acquired with the prior knowledge of the imaging model.\nOne outstanding challenge, however, is the degree to which the actual imaging\nmodel deviates from the assumed model. Model mismatches degrade the quality of\nthe preliminary image and therefore affect the DL predictions. Another main\nchallenge is that since most imaging inverse problems are ill-posed and the\nnetworks are over-parameterized, DL networks have flexibility to extract\nfeatures from the data that are not directly related to the imaging model. To\nsolve these challenges, a two-step-training DL (TST-DL) framework is proposed\nfor real-time computational imaging without physics priors. First, a single\nfully-connected layer (FCL) is trained to directly learn the model. Then, this\nFCL is fixed and concatenated with an un-trained U-Net architecture for a\nsecond-step training to improve the output image fidelity, resulting in four\nmain advantages. First, it does not rely on an accurate representation of the\nimaging model since the model is directly learned. Second, real-time imaging\ncan be achieved. Third, the TST-DL network is trained in the desired direction\nand the predictions are improved since the first step is constrained to learn\nthe model and the second step improves the result by learning the optimal\nregularizer. Fourth, the approach accommodates any size and dimensionality of\ndata. We demonstrate this framework using a linear single-pixel camera imaging\nmodel. The results are quantitatively compared with those from other DL\nframeworks and model-based iterative optimization approaches. We further extend\nthis concept to nonlinear models in the application of image\nde-autocorrelation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:05:43 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 15:11:48 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 13:57:55 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Shang", "Ruibo", ""], ["Hoffer-Hawlik", "Kevin", ""], ["Luke", "Geoffrey P.", ""]]}, {"id": "2001.03507", "submitter": "Stamatis Tsianikas", "authors": "S. Tsianikas, N. Yousefi, J. Zhou, M. Rodgers, D. W. Coit", "title": "A storage expansion planning framework using reinforcement learning and\n  simulation-based optimization", "comments": null, "journal-ref": "Applied Energy; Volume 290; 2021; Pages 116778;", "doi": "10.1016/j.apenergy.2021.116778", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the wake of the highly electrified future ahead of us, the role of energy\nstorage is crucial wherever distributed generation is abundant, such as in\nmicrogrid settings. Given the variety of storage options that are becoming more\nand more economical, determining which type of storage technology to invest in,\nalong with the appropriate timing and capacity becomes a critical research\nquestion. It is inevitable that these problems will continue to become\nincreasingly relevant in the future and require strategic planning and holistic\nand modern frameworks in order to be solved. Reinforcement Learning algorithms\nhave already proven to be successful in problems where sequential\ndecision-making is inherent. In the operations planning area, these algorithms\nare already used but mostly in short-term problems with well-defined\nconstraints. On the contrary, we expand and tailor these techniques to\nlong-term planning by utilizing model-free algorithms combined with\nsimulation-based models. A model and expansion plan have been developed to\noptimally determine microgrid designs as they evolve to dynamically react to\nchanging conditions and to exploit energy storage capabilities. We show that it\nis possible to derive better engineering solutions that would point to the\ntypes of energy storage units which could be at the core of future microgrid\napplications. Another key finding is that the optimal storage capacity\nthreshold for a system depends heavily on the price movements of the available\nstorage units. By utilizing the proposed approaches, it is possible to model\ninherent problem uncertainties and optimize the whole streamline of sequential\ninvestment decision-making.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:23:30 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 23:09:51 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2021 18:04:14 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Tsianikas", "S.", ""], ["Yousefi", "N.", ""], ["Zhou", "J.", ""], ["Rodgers", "M.", ""], ["Coit", "D. W.", ""]]}, {"id": "2001.03517", "submitter": "Jeppe Johan Waarkj{\\ae}r Olsen", "authors": "Jeppe Johan Waarkj{\\ae}r Olsen, Peter Ebert Christensen, Martin\n  Hangaard Hansen, and Alexander Rosenberg Johansen", "title": "Autoencoding Undirected Molecular Graphs With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete structure rules for validating molecular structures are usually\nlimited to fulfillment of the octet rule or similar simple deterministic\nheuristics. We propose a model, inspired by language modeling from natural\nlanguage processing, with the ability to learn from a collection of undirected\nmolecular graphs, enabling fitting of any underlying structure rule present in\nthe collection. We introduce an adaption to the popular Transformer model,\nwhich can learn relationships between atoms and bonds. To our knowledge, the\nTransformer adaption is the first model that is trained to solve the\nunsupervised task of recovering partially observed molecules. In this work, we\nassess how different degrees of information impact performance w.r.t. to\nfitting the QM9 dataset, which conforms to the octet rule, and to fitting the\nZINC dataset, which contains hypervalent molecules and ions requiring the model\nto learn a more complex structure rule. More specifically, we test a full\ndiscrete graph with bond order information, a full discrete graph with only\nconnectivity, a bag-of-neighbors, a bag-of-atoms, and a count-based unigram\nstatistics. These results provide encouraging evidence that neural networks,\neven when only connectivity is available, can learn arbitrary molecular\nstructure rules specific to a dataset, as the Transformer adaption surpasses a\nstrong octet rule baseline on the ZINC dataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:35:33 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 17:14:48 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Olsen", "Jeppe Johan Waarkj\u00e6r", ""], ["Christensen", "Peter Ebert", ""], ["Hansen", "Martin Hangaard", ""], ["Johansen", "Alexander Rosenberg", ""]]}, {"id": "2001.03538", "submitter": "Ricard Delgado-Gonzalo", "authors": "Antonino Faraone, Ricard Delgado-Gonzalo", "title": "Convolutional-Recurrent Neural Networks on Low-Power Wearable Platforms\n  for Cardiac Arrhythmia Detection", "comments": "Accepted for presentation in the 2nd IEEE International Conference on\n  Artificial Intelligence Circuits and Systems (AICAS2020)", "journal-ref": null, "doi": "10.1109/AICAS48895.2020.9073950", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-power sensing technologies, such as wearables, have emerged in the\nhealthcare domain since they enable continuous and non-invasive monitoring of\nphysiological signals. In order to endow such devices with clinical value,\nclassical signal processing has encountered numerous challenges. However,\ndata-driven methods, such as machine learning, offer attractive accuracies at\nthe expense of being resource and memory demanding. In this paper, we focus on\nthe inference of neural networks running in microcontrollers and low-power\nprocessors which wearable sensors and devices are generally equipped with. In\nparticular, we adapted an existing convolutional-recurrent neural network,\ndesigned to detect and classify cardiac arrhythmias from a single-lead\nelectrocardiogram, to the low-power embedded System-on-Chip nRF52 from Nordic\nSemiconductor with an ARM's Cortex-M4 processing core. We show our\nimplementation in fixed-point precision, using the CMSIS-NN libraries, yields a\ndrop of $F_1$ score from 0.8 to 0.784, from the original implementation, with a\nmemory footprint of 195.6KB, and a throughput of 33.98MOps/s.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:35:48 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Faraone", "Antonino", ""], ["Delgado-Gonzalo", "Ricard", ""]]}, {"id": "2001.03541", "submitter": "Amir Shaikhha", "authors": "Amir Shaikhha, Maximilian Schleich, Alexandru Ghita, Dan Olteanu", "title": "Multi-layer Optimizations for End-to-End Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training machine learning models over\nmulti-relational data. The mainstream approach is to first construct the\ntraining dataset using a feature extraction query over input database and then\nuse a statistical software package of choice to train the model. In this paper\nwe introduce Iterative Functional Aggregate Queries (IFAQ), a framework that\nrealizes an alternative approach. IFAQ treats the feature extraction query and\nthe learning task as one program given in the IFAQ's domain-specific language,\nwhich captures a subset of Python commonly used in Jupyter notebooks for rapid\nprototyping of machine learning applications. The program is subject to several\nlayers of IFAQ optimizations, such as algebraic transformations, loop\ntransformations, schema specialization, data layout optimizations, and finally\ncompilation into efficient low-level C++ code specialized for the given\nworkload and data.\n  We show that a Scala implementation of IFAQ can outperform mlpack, Scikit,\nand TensorFlow by several orders of magnitude for linear regression and\nregression tree models over several relational datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:14:44 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shaikhha", "Amir", ""], ["Schleich", "Maximilian", ""], ["Ghita", "Alexandru", ""], ["Olteanu", "Dan", ""]]}, {"id": "2001.03554", "submitter": "Mathilde Caron", "authors": "Mathilde Caron, Ari Morcos, Piotr Bojanowski, Julien Mairal and Armand\n  Joulin", "title": "Pruning Convolutional Neural Networks with Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks trained without supervision come close to\nmatching performance with supervised pre-training, but sometimes at the cost of\nan even higher number of parameters. Extracting subnetworks from these large\nunsupervised convnets with preserved performance is of particular interest to\nmake them less computationally intensive. Typical pruning methods operate\nduring training on a task while trying to maintain the performance of the\npruned network on the same task. However, in self-supervised feature learning,\nthe training objective is agnostic on the representation transferability to\ndownstream tasks. Thus, preserving performance for this objective does not\nensure that the pruned subnetwork remains effective for solving downstream\ntasks. In this work, we investigate the use of standard pruning methods,\ndeveloped primarily for supervised learning, for networks trained without\nlabels (i.e. on self-supervised tasks). We show that pruned masks obtained with\nor without labels reach comparable performance when re-trained on labels,\nsuggesting that pruning operates similarly for self-supervised and supervised\nlearning. Interestingly, we also find that pruning preserves the transfer\nperformance of self-supervised subnetwork representations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:44:41 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Caron", "Mathilde", ""], ["Morcos", "Ari", ""], ["Bojanowski", "Piotr", ""], ["Mairal", "Julien", ""], ["Joulin", "Armand", ""]]}, {"id": "2001.03560", "submitter": "Justin Kinney", "authors": "Ammar Tareen, Justin B. Kinney", "title": "Biophysical models of cis-regulation as interpretable neural networks", "comments": "Presented at the 14th conference on Machine Learning in Computational\n  Biology (MLCB 2019), Vancouver, Canada. Revised to add a link to code and to\n  correct a typo in the King-Altman diagrams shown in Figure 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG physics.bio-ph q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The adoption of deep learning techniques in genomics has been hindered by the\ndifficulty of mechanistically interpreting the models that these techniques\nproduce. In recent years, a variety of post-hoc attribution methods have been\nproposed for addressing this neural network interpretability problem in the\ncontext of gene regulation. Here we describe a complementary way of approaching\nthis problem. Our strategy is based on the observation that two large classes\nof biophysical models of cis-regulatory mechanisms can be expressed as deep\nneural networks in which nodes and weights have explicit physiochemical\ninterpretations. We also demonstrate how such biophysical networks can be\nrapidly inferred, using modern deep learning frameworks, from the data produced\nby certain types of massively parallel reporter assays (MPRAs). These results\nsuggest a scalable strategy for using MPRAs to systematically characterize the\nbiophysical basis of gene regulation in a wide range of biological contexts.\nThey also highlight gene regulation as a promising venue for the development of\nscientifically interpretable approaches to deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 14:45:58 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 22:07:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tareen", "Ammar", ""], ["Kinney", "Justin B.", ""]]}, {"id": "2001.03608", "submitter": "Samira Pakravan", "authors": "Samira Pakravan, Pouria A. Mistani, Miguel Angel Aragon-Calvo,\n  Frederic Gibou", "title": "Solving inverse-PDE problems with physics-aware neural networks", "comments": "39 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110414", "report-no": null, "categories": "math.NA cs.LG cs.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel composite framework to find unknown fields in the context\nof inverse problems for partial differential equations (PDEs). We blend the\nhigh expressibility of deep neural networks as universal function estimators\nwith the accuracy and reliability of existing numerical algorithms for partial\ndifferential equations as custom layers in semantic autoencoders. Our design\nbrings together techniques of computational mathematics, machine learning and\npattern recognition under one umbrella to incorporate domain-specific knowledge\nand physical constraints to discover the underlying hidden fields. The network\nis explicitly aware of the governing physics through a hard-coded PDE solver\nlayer in contrast to most existing methods that incorporate the governing\nequations in the loss function or rely on trainable convolutional layers to\ndiscover proper discretizations from data. This subsequently focuses the\ncomputational load to only the discovery of the hidden fields and therefore is\nmore data efficient. We call this architecture Blended inverse-PDE networks\n(hereby dubbed BiPDE networks) and demonstrate its applicability for recovering\nthe variable diffusion coefficient in Poisson problems in one and two spatial\ndimensions, as well as the diffusion coefficient in the time-dependent and\nnonlinear Burgers' equation in one dimension. We also show that this approach\nis robust to noise.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 18:46:50 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 06:16:24 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 21:47:28 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Pakravan", "Samira", ""], ["Mistani", "Pouria A.", ""], ["Aragon-Calvo", "Miguel Angel", ""], ["Gibou", "Frederic", ""]]}, {"id": "2001.03612", "submitter": "Joyjit Chatterjee", "authors": "Joyjit Chatterjee, Nina Dethlefs", "title": "A Deep Learning Approach Towards Prediction of Faults in Wind Turbines", "comments": "Presented at the Northern Lights Deep Learning Workshop (NLDL),\n  Tromso, Norway in January 2019. The workshop program can be found at\n  http://nldl2019.org/program.html page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rising costs of conventional sources of energy, the world is moving\ntowards sustainable energy sources including wind energy. Wind turbines consist\nof several electrical and mechanical components and experience an enormous\namount of irregular loads, making their operational behaviour at times\ninconsistent. Operations and Maintenance (O&M) is a key factor in monitoring\nsuch inconsistent behaviour of the turbines in order to predict and prevent any\nincipient faults which may occur in the near future. Machine learning has been\napplied to the domain of wind energy over the last decade for analysing,\ndiagnosing and predicting wind turbine faults. In particular, we follow the\nidea of modelling a turbine's performance as a power curve where any power\noutputs that fall off the curve can be seen as performance errors. Existing\nwork using this idea has used data from a turbine's Supervisory Control &\nAcquisition (SCADA) system to filter and analyse fault & alarm data using\nregression techniques. In contrast to previous work, we explore how deep\nlearning can be applied to fault prediction from open access meteorological\ndata only.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 00:15:33 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Chatterjee", "Joyjit", ""], ["Dethlefs", "Nina", ""]]}, {"id": "2001.03640", "submitter": "Omry Sendik", "authors": "Omry Sendik, Dani Lischinski, Daniel Cohen-Or", "title": "Unsupervised multi-modal Styled Content Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of deep generative models has recently enabled the automatic\ngeneration of massive amounts of graphical content, both in 2D and in 3D.\nGenerative Adversarial Networks (GANs) and style control mechanisms, such as\nAdaptive Instance Normalization (AdaIN), have proved particularly effective in\nthis context, culminating in the state-of-the-art StyleGAN architecture. While\nsuch models are able to learn diverse distributions, provided a sufficiently\nlarge training set, they are not well-suited for scenarios where the\ndistribution of the training data exhibits a multi-modal behavior. In such\ncases, reshaping a uniform or normal distribution over the latent space into a\ncomplex multi-modal distribution in the data domain is challenging, and the\ngenerator might fail to sample the target distribution well. Furthermore,\nexisting unsupervised generative models are not able to control the mode of the\ngenerated samples independently of the other visual attributes, despite the\nfact that they are typically disentangled in the training data.\n  In this paper, we introduce UMMGAN, a novel architecture designed to better\nmodel multi-modal distributions, in an unsupervised fashion. Building upon the\nStyleGAN architecture, our network learns multiple modes, in a completely\nunsupervised manner, and combines them using a set of learned weights. We\ndemonstrate that this approach is capable of effectively approximating a\ncomplex distribution as a superposition of multiple simple ones. We further\nshow that UMMGAN effectively disentangles between modes and style, thereby\nproviding an independent degree of control over the generated content.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 19:36:08 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 07:14:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sendik", "Omry", ""], ["Lischinski", "Dani", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2001.03653", "submitter": "Ishaan Gulrajani", "authors": "Ishaan Gulrajani, Colin Raffel, Luke Metz", "title": "Towards GAN Benchmarks Which Require Generalization", "comments": "ICLR 2019 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many evaluation metrics commonly used as benchmarks for unconditional\nimage generation, trivially memorizing the training set attains a better score\nthan models which are considered state-of-the-art; we consider this\nproblematic. We clarify a necessary condition for an evaluation metric not to\nbehave this way: estimating the function must require a large sample from the\nmodel. In search of such a metric, we turn to neural network divergences\n(NNDs), which are defined in terms of a neural network trained to distinguish\nbetween distributions. The resulting benchmarks cannot be \"won\" by training set\nmemorization, while still being perceptually correlated and computable only\nfrom samples. We survey past work on using NNDs for evaluation and implement an\nexample black-box metric based on these ideas. Through experimental validation\nwe show that it can effectively measure diversity, sample quality, and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:18:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gulrajani", "Ishaan", ""], ["Raffel", "Colin", ""], ["Metz", "Luke", ""]]}, {"id": "2001.03659", "submitter": "Alex Ter-Sarkisov", "authors": "Aram Ter-Sarkisov", "title": "Network of Steel: Neural Font Style Transfer from Heavy Metal to\n  Corporate Logos", "comments": "Accepted for oral presentation at ICPRAM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for transferring style from the logos of heavy metal\nbands onto corporate logos using a VGG16 network. We establish the contribution\nof different layers and loss coefficients to the learning of style,\nminimization of artefacts and maintenance of readability of corporate logos. We\nfind layers and loss coefficients that produce a good tradeoff between heavy\nmetal style and corporate logo readability. This is the first step both towards\nsparse font style transfer and corporate logo decoration using generative\nnetworks. Heavy metal and corporate logos are very different artistically, in\nthe way they emphasize emotions and readability, therefore training a model to\nfuse the two is an interesting problem.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:41:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ter-Sarkisov", "Aram", ""]]}, {"id": "2001.03662", "submitter": "Brandon Paulsen", "authors": "Brandon Paulsen, Jingbo Wang, Chao Wang", "title": "ReluDiff: Differential Verification of Deep Neural Networks", "comments": "Extended version of ICSE 2020 paper. This version includes an\n  appendix with proofs for some of the content in section 4.3", "journal-ref": null, "doi": "10.1145/3377811.3380337", "report-no": null, "categories": "cs.LG cs.LO cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks are increasingly being deployed in practice, their\nefficiency has become an important issue. While there are compression\ntechniques for reducing the network's size, energy consumption and\ncomputational requirement, they only demonstrate empirically that there is no\nloss of accuracy, but lack formal guarantees of the compressed network, e.g.,\nin the presence of adversarial examples. Existing verification techniques such\nas Reluplex, ReluVal, and DeepPoly provide formal guarantees, but they are\ndesigned for analyzing a single network instead of the relationship between two\nnetworks. To fill the gap, we develop a new method for differential\nverification of two closely related networks. Our method consists of a fast but\napproximate forward interval analysis pass followed by a backward pass that\niteratively refines the approximation until the desired property is verified.\nWe have two main innovations. During the forward pass, we exploit structural\nand behavioral similarities of the two networks to more accurately bound the\ndifference between the output neurons of the two networks. Then in the backward\npass, we leverage the gradient differences to more accurately compute the most\nbeneficial refinement. Our experiments show that, compared to state-of-the-art\nverification tools, our method can achieve orders-of-magnitude speedup and\nprove many more properties than existing tools.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:47:22 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:29:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Paulsen", "Brandon", ""], ["Wang", "Jingbo", ""], ["Wang", "Chao", ""]]}, {"id": "2001.03665", "submitter": "Vahid Shah-Mansouri Dr.", "authors": "Ali Parchekani, Salar Nouri Naghadeh, and Vahid Shah-Mansouri", "title": "Classification of Traffic Using Neural Networks by Rejecting: a Novel\n  Approach in Classifying VPN Traffic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flows are set of packets transferring between a client and a server\nwith the same set of source and destination IP and port numbers. Traffic\nclassification is referred to as the task of categorizing traffic flows into\napplication-aware classes such as chats, streaming, VoIP, etc. Classification\ncan be used for several purposes including policy enforcement and control or\nQoS management. In this paper, we introduce a novel end-to-end traffic\nclassification method to distinguish between traffic classes including VPN\ntraffic. Classification of VPN traffic is not trivial using traditional\nclassification approaches due to its encrypted nature. We utilize two\nwell-known neural networks, namely multi-layer perceptron and recurrent neural\nnetwork focused on two metrics: class scores and distance from the center of\nthe classes. Such approaches combined extraction, selection, and classification\nfunctionality into a single end-to-end system to systematically learn the\nnon-linear relationship between input and predicted performance. Therefore, we\ncould distinguish VPN traffics from Non-VPN traffics by rejecting the unrelated\nfeatures of the VPN class. Moreover, obtain the application of Non-VPN traffics\nat the same time. The approach is evaluated using the general traffic dataset\nISCX VPN-nonVPN and the acquired real dataset. The results of the analysis\ndemonstrate that our proposed model fulfills the realistic project's criterion\nfor precision.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 21:01:22 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Parchekani", "Ali", ""], ["Naghadeh", "Salar Nouri", ""], ["Shah-Mansouri", "Vahid", ""]]}, {"id": "2001.03671", "submitter": "Harsh Mehta", "authors": "Harsh Mehta, Yoav Artzi, Jason Baldridge, Eugene Ie, Piotr Mirowski", "title": "Retouchdown: Adding Touchdown to StreetLearn as a Shareable Resource for\n  Language Grounding Tasks in Street View", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Touchdown dataset (Chen et al., 2019) provides instructions by human\nannotators for navigation through New York City streets and for resolving\nspatial descriptions at a given location. To enable the wider research\ncommunity to work effectively with the Touchdown tasks, we are publicly\nreleasing the 29k raw Street View panoramas needed for Touchdown. We follow the\nprocess used for the StreetLearn data release (Mirowski et al., 2019) to check\npanoramas for personally identifiable information and blur them as necessary.\nThese have been added to the StreetLearn dataset and can be obtained via the\nsame process as used previously for StreetLearn. We also provide a reference\nimplementation for both of the Touchdown tasks: vision and language navigation\n(VLN) and spatial description resolution (SDR). We compare our model results to\nthose given in Chen et al. (2019) and show that the panoramas we have added to\nStreetLearn fully support both Touchdown tasks and can be used effectively for\nfurther research and comparison.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 21:35:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Mehta", "Harsh", ""], ["Artzi", "Yoav", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Mirowski", "Piotr", ""]]}, {"id": "2001.03674", "submitter": "Manpreet Singh Minhas", "authors": "Manpreet Singh Minhas, John Zelek", "title": "Semi-supervised Anomaly Detection using AutoEncoders", "comments": null, "journal-ref": "JCVIS, vol. 5, no. 1, p. 3, Jan. 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection refers to the task of finding unusual instances that stand\nout from the normal data. In several applications, these outliers or anomalous\ninstances are of greater interest compared to the normal ones. Specifically in\nthe case of industrial optical inspection and infrastructure asset management,\nfinding these defects (anomalous regions) is of extreme importance.\nTraditionally and even today this process has been carried out manually. Humans\nrely on the saliency of the defects in comparison to the normal texture to\ndetect the defects. However, manual inspection is slow, tedious, subjective and\nsusceptible to human biases. Therefore, the automation of defect detection is\ndesirable. But for defect detection lack of availability of a large number of\nanomalous instances and labelled data is a problem. In this paper, we present a\nconvolutional auto-encoder architecture for anomaly detection that is trained\nonly on the defect-free (normal) instances. For the test images, residual masks\nthat are obtained by subtracting the original image from the auto-encoder\noutput are thresholded to obtain the defect segmentation masks. The approach\nwas tested on two data-sets and achieved an impressive average F1 score of\n0.885. The network learnt to detect the actual shape of the defects even though\nno defected images were used during the training.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:06:28 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Minhas", "Manpreet Singh", ""], ["Zelek", "John", ""]]}, {"id": "2001.03690", "submitter": "Jong Chul Ye", "authors": "Byung-Hoon Kim and Jong Chul Ye", "title": "Understanding Graph Isomorphism Network for rs-fMRI Functional\n  Connectivity Analysis", "comments": "This paper is accepted for Frontiers in Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNN) rely on graph operations that include neural\nnetwork training for various graph related tasks. Recently, several attempts\nhave been made to apply the GNNs to functional magnetic resonance image (fMRI)\ndata. Despite recent progresses, a common limitation is its difficulty to\nexplain the classification results in a neuroscientifically explainable way.\nHere, we develop a framework for analyzing the fMRI data using the Graph\nIsomorphism Network (GIN), which was recently proposed as a powerful GNN for\ngraph classification. One of the important contributions of this paper is the\nobservation that the GIN is a dual representation of convolutional neural\nnetwork (CNN) in the graph space where the shift operation is defined using the\nadjacency matrix. This understanding enables us to exploit CNN-based saliency\nmap techniques for the GNN, which we tailor to the proposed GIN with one-hot\nencoding, to visualize the important regions of the brain. We validate our\nproposed framework using large-scale resting-state fMRI (rs-fMRI) data for\nclassifying the sex of the subject based on the graph structure of the brain.\nThe experiment was consistent with our expectation such that the obtained\nsaliency map show high correspondence with previous neuroimaging evidences\nrelated to sex differences.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 23:40:09 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 02:53:52 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kim", "Byung-Hoon", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2001.03712", "submitter": "Geondo Park", "authors": "Geondo Park, Chihye Han, Wonjun Yoon, Daeshik Kim", "title": "MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding", "comments": "Accepted by the 2020 IEEE Winter Conference on Applications of\n  Computer Vision (WACV 20), 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual-semantic embedding enables various tasks such as image-text retrieval,\nimage captioning, and visual question answering. The key to successful\nvisual-semantic embedding is to express visual and textual data properly by\naccounting for their intricate relationship. While previous studies have\nachieved much advance by encoding the visual and textual data into a joint\nspace where similar concepts are closely located, they often represent data by\na single vector ignoring the presence of multiple important components in an\nimage or text. Thus, in addition to the joint embedding space, we propose a\nnovel multi-head self-attention network to capture various components of visual\nand textual data by attending to important parts in data. Our approach achieves\nthe new state-of-the-art results in image-text retrieval tasks on MS-COCO and\nFlicker30K datasets. Through the visualization of the attention maps that\ncapture distinct semantic components at multiple positions in the image and the\ntext, we demonstrate that our method achieves an effective and interpretable\nvisual-semantic joint space.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 05:50:19 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Park", "Geondo", ""], ["Han", "Chihye", ""], ["Yoon", "Wonjun", ""], ["Kim", "Daeshik", ""]]}, {"id": "2001.03715", "submitter": "Jun Ohkubo", "authors": "Tomohiro Yokota, Makiko Konoshima, Hirotaka Tamura, Jun Ohkubo", "title": "Derivation of QUBO formulations for sparse estimation", "comments": "5 pages, 2 figures", "journal-ref": "J. Phys. Soc. Jpn. 89, 034801 (2020)", "doi": "10.7566/JPSJ.89.034801", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a quadratic unconstrained binary optimization (QUBO) formulation\nof the l1-norm, which enables us to perform sparse estimation of Ising-type\nannealing methods such as quantum annealing. The QUBO formulation is derived\nusing the Legendre transformation and the Wolfe theorem, which have recently\nbeen employed to derive the QUBO formulations of ReLU-type functions. It is\nshown that a simple application of the derivation method to the l1-norm case\nresults in a redundant variable. Finally a simplified QUBO formulation is\nobtained by removing the redundant variable.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 06:16:26 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 09:37:10 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Yokota", "Tomohiro", ""], ["Konoshima", "Makiko", ""], ["Tamura", "Hirotaka", ""], ["Ohkubo", "Jun", ""]]}, {"id": "2001.03724", "submitter": "Luo Luo", "authors": "Luo Luo, Haishan Ye, Zhichao Huang, Tong Zhang", "title": "Stochastic Recursive Gradient Descent Ascent for Stochastic\n  Nonconvex-Strongly-Concave Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider nonconvex-concave minimax optimization problems of the form\n$\\min_{\\bf x}\\max_{\\bf y\\in{\\mathcal Y}} f({\\bf x},{\\bf y})$, where $f$ is\nstrongly-concave in $\\bf y$ but possibly nonconvex in $\\bf x$ and ${\\mathcal\nY}$ is a convex and compact set. We focus on the stochastic setting, where we\ncan only access an unbiased stochastic gradient estimate of $f$ at each\niteration. This formulation includes many machine learning applications as\nspecial cases such as robust optimization and adversary training. We are\ninterested in finding an ${\\mathcal O}(\\varepsilon)$-stationary point of the\nfunction $\\Phi(\\cdot)=\\max_{\\bf y\\in{\\mathcal Y}} f(\\cdot, {\\bf y})$. The most\npopular algorithm to solve this problem is stochastic gradient decent ascent,\nwhich requires $\\mathcal O(\\kappa^3\\varepsilon^{-4})$ stochastic gradient\nevaluations, where $\\kappa$ is the condition number. In this paper, we propose\na novel method called Stochastic Recursive gradiEnt Descent Ascent (SREDA),\nwhich estimates gradients more efficiently using variance reduction. This\nmethod achieves the best known stochastic gradient complexity of ${\\mathcal\nO}(\\kappa^3\\varepsilon^{-3})$, and its dependency on $\\varepsilon$ is optimal\nfor this problem.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 09:05:03 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 09:37:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Luo", "Luo", ""], ["Ye", "Haishan", ""], ["Huang", "Zhichao", ""], ["Zhang", "Tong", ""]]}, {"id": "2001.03750", "submitter": "Pengzhan Jin", "authors": "Pengzhan Jin, Zhen Zhang, Aiqing Zhu, Yifa Tang and George Em\n  Karniadakis", "title": "SympNets: Intrinsic structure-preserving symplectic networks for\n  identifying Hamiltonian systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new symplectic networks (SympNets) for identifying Hamiltonian\nsystems from data based on a composition of linear, activation and gradient\nmodules. In particular, we define two classes of SympNets: the LA-SympNets\ncomposed of linear and activation modules, and the G-SympNets composed of\ngradient modules. Correspondingly, we prove two new universal approximation\ntheorems that demonstrate that SympNets can approximate arbitrary symplectic\nmaps based on appropriate activation functions. We then perform several\nexperiments including the pendulum, double pendulum and three-body problems to\ninvestigate the expressivity and the generalization ability of SympNets. The\nsimulation results show that even very small size SympNets can generalize well,\nand are able to handle both separable and non-separable Hamiltonian systems\nwith data points resulting from short or long time steps. In all the test\ncases, SympNets outperform the baseline models, and are much faster in training\nand prediction. We also develop an extended version of SympNets to learn the\ndynamics from irregularly sampled data. This extended version of SympNets can\nbe thought of as a universal model representing the solution to an arbitrary\nHamiltonian system.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 13:04:34 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 15:37:10 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 06:14:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Jin", "Pengzhan", ""], ["Zhang", "Zhen", ""], ["Zhu", "Aiqing", ""], ["Tang", "Yifa", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2001.03772", "submitter": "Antonin Berthon", "authors": "Antonin Berthon and Bo Han and Gang Niu and Tongliang Liu and Masashi\n  Sugiyama", "title": "Confidence Scores Make Instance-dependent Label-noise Learning Possible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In learning with noisy labels, for every instance, its label can randomly\nwalk to other classes following a transition distribution which is named a\nnoise model. Well-studied noise models are all instance-independent, namely,\nthe transition depends only on the original label but not the instance itself,\nand thus they are less practical in the wild. Fortunately, methods based on\ninstance-dependent noise have been studied, but most of them have to rely on\nstrong assumptions on the noise models. To alleviate this issue, we introduce\nconfidence-scored instance-dependent noise (CSIDN), where each instance-label\npair is equipped with a confidence score. We find with the help of confidence\nscores, the transition distribution of each instance can be approximately\nestimated. Similarly to the powerful forward correction for\ninstance-independent noise, we propose a novel instance-level forward\ncorrection for CSIDN. We demonstrate the utility and effectiveness of our\nmethod through multiple experiments under synthetic label noise and real-world\nunknown noise.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 16:15:41 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 23:40:07 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Berthon", "Antonin", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Liu", "Tongliang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2001.03779", "submitter": "Alona Baruhov", "authors": "Alona Baruhov and Guy Gilboa", "title": "Unsupervised Enhancement of Real-World Depth Images Using Tri-Cycle GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low quality depth poses a considerable challenge to computer vision\nalgorithms. In this work we aim to enhance highly degraded, real-world depth\nimages acquired by a low-cost sensor, for which an analytical noise model is\nunavailable. In the absence of clean ground-truth, we approach the task as an\nunsupervised domain-translation between the low-quality sensor domain and a\nhigh-quality sensor domain, represented using two unpaired training sets. We\nemploy the highly-successful Cycle-GAN to this task, but find it to perform\npoorly in this case. Identifying the sources of the failure, we introduce\nseveral modifications to the framework, including a larger generator\narchitecture, depth-specific losses that take into account missing pixels, and\na novel Tri-Cycle loss which promotes information-preservation while addressing\nthe asymmetry between the domains. We show that the resulting framework\ndramatically improves over the original Cycle-GAN both visually and\nquantitatively, extending its applicability to more challenging and asymmetric\ntranslation tasks.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 18:19:09 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Baruhov", "Alona", ""], ["Gilboa", "Guy", ""]]}, {"id": "2001.03780", "submitter": "Tailin Wu", "authors": "Tailin Wu", "title": "Intelligence, physics and information -- the tradeoff between accuracy\n  and simplicity in machine learning", "comments": "PhD Thesis, 352 pages. Reference improved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we enable machines to make sense of the world, and become better at\nlearning? To approach this goal, I believe viewing intelligence in terms of\nmany integral aspects, and also a universal two-term tradeoff between task\nperformance and complexity, provides two feasible perspectives. In this thesis,\nI address several key questions in some aspects of intelligence, and study the\nphase transitions in the two-term tradeoff, using strategies and tools from\nphysics and information. Firstly, how can we make the learning models more\nflexible and efficient, so that agents can learn quickly with fewer examples?\nInspired by how physicists model the world, we introduce a paradigm and an AI\nPhysicist agent for simultaneously learning many small specialized models\n(theories) and the domain they are accurate, which can then be simplified,\nunified and stored, facilitating few-shot learning in a continual way.\nSecondly, for representation learning, when can we learn a good representation,\nand how does learning depend on the structure of the dataset? We approach this\nquestion by studying phase transitions when tuning the tradeoff hyperparameter.\nIn the information bottleneck, we theoretically show that these phase\ntransitions are predictable and reveal structure in the relationships between\nthe data, the model, the learned representation and the loss landscape.\nThirdly, how can agents discover causality from observations? We address part\nof this question by introducing an algorithm that combines prediction and\nminimizing information from the input, for exploratory causal discovery from\nobservational time series. Fourthly, to make models more robust to label noise,\nwe introduce Rank Pruning, a robust algorithm for classification with noisy\nlabels. I believe that building on the work of my thesis we will be one step\ncloser to enable more intelligent machines that can make sense of the world.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 18:34:29 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 17:51:09 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Tailin", ""]]}, {"id": "2001.03798", "submitter": "Rui Zhu", "authors": "Rui Zhu, Subhashis Ghosal", "title": "Bayesian Semi-supervised learning under nonparanormality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is a classification method which makes use of both\nlabeled data and unlabeled data for training. In this paper, we propose a\nsemi-supervised learning algorithm using a Bayesian semi-supervised model. We\nmake a general assumption that the observations will follow two multivariate\nnormal distributions depending on their true labels after the same unknown\ntransformation. We use B-splines to put a prior on the transformation function\nfor each component. To use unlabeled data in a semi-supervised setting, we\nassume the labels are missing at random. The posterior distributions can then\nbe described using our assumptions, which we compute by the Gibbs sampling\ntechnique. The proposed method is then compared with several other available\nmethods through an extensive simulation study. Finally we apply the proposed\nmethod in real data contexts for diagnosing breast cancer and classify radar\nreturns. We conclude that the proposed method has better prediction accuracy in\na wide variety of cases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 21:31:25 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhu", "Rui", ""], ["Ghosal", "Subhashis", ""]]}, {"id": "2001.03813", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Fundamental Limits of Prediction, Generalization, and Recursion: An\n  Entropic-Innovations Perspective", "comments": "Note that this is an extended version of the original submission\n  \"Fundamental Limits of Online Learning: An Entropic-Innovations Viewpoint\";\n  arXiv admin note: text overlap with arXiv:1912.05541, arXiv:1912.02628", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the fundamental performance limits of prediction,\nwith or without side information. More specifically, we derive generic lower\nbounds on the $\\mathcal{L}_p$ norms of the prediction errors that are valid for\nany prediction algorithms and for any data distributions. Meanwhile, we combine\nthe entropic analysis from information theory and the innovations approach from\nprediction/estimation theory to characterize the conditions (in terms of, e.g.,\ndirected information or mutual information) to achieve the bounds. We also\ninvestigate the implications of the results in analyzing the fundamental limits\nof generalization in fitting (learning) problems from the perspective of\nprediction with side information, as well as the fundamental limits of\nrecursive algorithms by viewing them as generalized prediction problems.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 00:20:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 20:18:27 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 18:43:15 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 22:25:52 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2001.03814", "submitter": "Kunping Huang", "authors": "Kunping Huang, Paul Siegel, Anxiao (Andrew) Jiang", "title": "Functional Error Correction for Robust Neural Networks", "comments": "24 pages, 22 figures, submitted to JSAIT journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When neural networks (NeuralNets) are implemented in hardware, their weights\nneed to be stored in memory devices. As noise accumulates in the stored\nweights, the NeuralNet's performance will degrade. This paper studies how to\nuse error correcting codes (ECCs) to protect the weights. Different from\nclassic error correction in data storage, the optimization objective is to\noptimize the NeuralNet's performance after error correction, instead of\nminimizing the Uncorrectable Bit Error Rate in the protected bits. That is, by\nseeing the NeuralNet as a function of its input, the error correction scheme is\nfunction-oriented. A main challenge is that a deep NeuralNet often has millions\nto hundreds of millions of weights, causing a large redundancy overhead for\nECCs, and the relationship between the weights and its NeuralNet's performance\ncan be highly complex. To address the challenge, we propose a Selective\nProtection (SP) scheme, which chooses only a subset of important bits for ECC\nprotection. To find such bits and achieve an optimized tradeoff between ECC's\nredundancy and NeuralNet's performance, we present an algorithm based on deep\nreinforcement learning. Experimental results verify that compared to the\nnatural baseline scheme, the proposed algorithm achieves substantially better\nperformance for the functional error correction task.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 00:40:49 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Huang", "Kunping", "", "Andrew"], ["Siegel", "Paul", "", "Andrew"], ["Anxiao", "", "", "Andrew"], ["Jiang", "", ""]]}, {"id": "2001.03836", "submitter": "Xin Zhang", "authors": "Xin Zhang, Minghong Fang, Jia Liu, and Zhengyuan Zhu", "title": "Private and Communication-Efficient Edge Learning: A Sparse Differential\n  Gaussian-Masking Distributed SGD Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rise of machine learning (ML) and the proliferation of smart mobile\ndevices, recent years have witnessed a surge of interest in performing ML in\nwireless edge networks. In this paper, we consider the problem of jointly\nimproving data privacy and communication efficiency of distributed edge\nlearning, both of which are critical performance metrics in wireless edge\nnetwork computing. Toward this end, we propose a new decentralized stochastic\ngradient method with sparse differential Gaussian-masked stochastic gradients\n(SDM-DSGD) for non-convex distributed edge learning. Our main contributions are\nthree-fold: i) We theoretically establish the privacy and communication\nefficiency performance guarantee of our SDM-DSGD method, which outperforms all\nexisting works; ii) We show that SDM-DSGD improves the fundamental\ntraining-privacy trade-off by {\\em two orders of magnitude} compared with the\nstate-of-the-art. iii) We reveal theoretical insights and offer practical\ndesign guidelines for the interactions between privacy preservation and\ncommunication efficiency, two conflicting performance goals. We conduct\nextensive experiments with a variety of learning models on MNIST and CIFAR-10\ndatasets to verify our theoretical findings. Collectively, our results\ncontribute to the theory and algorithm design for distributed edge learning.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 03:04:45 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 01:49:58 GMT"}, {"version": "v3", "created": "Sun, 19 Jan 2020 16:14:42 GMT"}, {"version": "v4", "created": "Sat, 28 Mar 2020 15:20:20 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhang", "Xin", ""], ["Fang", "Minghong", ""], ["Liu", "Jia", ""], ["Zhu", "Zhengyuan", ""]]}, {"id": "2001.03855", "submitter": "G C Nandi", "authors": "Shruti Jaiswal, and Gora Chand Nandi", "title": "Hyperparameters optimization for Deep Learning based emotion prediction\n  for Human Robot Interaction", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable humanoid robots to share our social space we need to develop\ntechnology for easy interaction with the robots using multiple modes such as\nspeech, gestures and share our emotions with them. We have targeted this\nresearch towards addressing the core issue of emotion recognition problem which\nwould require less computation resources and much lesser number of network\nhyperparameters which will be more adaptive to be computed on low resourced\nsocial robots for real time communication. More specifically, here we have\nproposed an Inception module based Convolutional Neural Network Architecture\nwhich has achieved improved accuracy of upto 6% improvement over the existing\nnetwork architecture for emotion classification when combinedly tested over\nmultiple datasets when tried over humanoid robots in real - time. Our proposed\nmodel is reducing the trainable Hyperparameters to an extent of 94% as compared\nto vanilla CNN model which clearly indicates that it can be used in real time\nbased application such as human robot interaction. Rigorous experiments have\nbeen performed to validate our methodology which is sufficiently robust and\ncould achieve high level of accuracy. Finally, the model is implemented in a\nhumanoid robot, NAO in real time and robustness of the model is evaluated.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 05:25:02 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jaiswal", "Shruti", ""], ["Nandi", "Gora Chand", ""]]}, {"id": "2001.03877", "submitter": "Binyamin Manela", "authors": "Binyamin Manela", "title": "Deep Reinforcement Learning for Complex Manipulation Tasks with Sparse\n  Feedback", "comments": "A thesis submitted in fulfillment of the requirements for the degree\n  of Master of Science in the department of Industrial Engineering and\n  Management at Ben-Gurion University of the Negev", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal policies from sparse feedback is a known challenge in\nreinforcement learning. Hindsight Experience Replay (HER) is a multi-goal\nreinforcement learning algorithm that comes to solve such tasks. The algorithm\ntreats every failure as a success for an alternative (virtual) goal that has\nbeen achieved in the episode and then generalizes from that virtual goal to\nreal goals. HER has known flaws and is limited to relatively simple tasks. In\nthis thesis, we present three algorithms based on the existing HER algorithm\nthat improves its performances. First, we prioritize virtual goals from which\nthe agent will learn more valuable information. We call this property the\n\\textit{instructiveness} of the virtual goal and define it by a heuristic\nmeasure, which expresses how well the agent will be able to generalize from\nthat virtual goal to actual goals. Secondly, we designed a filtering process\nthat detects and removes misleading samples that may induce bias throughout the\nlearning process. Lastly, we enable the learning of complex, sequential, tasks\nusing a form of curriculum learning combined with HER. We call this algorithm\n\\textit{Curriculum HER}. To test our algorithms, we built three challenging\nmanipulation environments with sparse reward functions. Each environment has\nthree levels of complexity. Our empirical results show vast improvement in the\nfinal success rate and sample efficiency when compared to the original HER\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 07:22:15 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Manela", "Binyamin", ""]]}, {"id": "2001.03896", "submitter": "Harishchandra Dubey", "authors": "Harishchandra Dubey, Dimitra Emmanouilidou, Ivan J. Tashev", "title": "CURE Dataset: Ladder Networks for Audio Event Classification", "comments": "6 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio event classification is an important task for several applications such\nas surveillance, audio, video and multimedia retrieval etc. There are\napproximately 3M people with hearing loss who can't perceive events happening\naround them. This paper establishes the CURE dataset which contains curated set\nof specific audio events most relevant for people with hearing loss. We propose\na ladder network based audio event classifier that utilizes 5s sound recordings\nderived from the Freesound project. We adopted the state-of-the-art\nconvolutional neural network (CNN) embeddings as audio features for this task.\nWe also investigate extreme learning machine (ELM) for event classification. In\nthis study, proposed classifiers are compared with support vector machine (SVM)\nbaseline. We propose signal and feature normalization that aims to reduce the\nmismatch between different recordings scenarios. Firstly, CNN is trained on\nweakly labeled Audioset data. Next, the pre-trained model is adopted as feature\nextractor for proposed CURE corpus. We incorporate ESC-50 dataset as second\nevaluation set. Results and discussions validate the superiority of Ladder\nnetwork over ELM and SVM classifier in terms of robustness and increased\nclassification accuracy. While Ladder network is robust to data mismatches,\nsimpler SVM and ELM classifiers are sensitive to such mismatches, where the\nproposed normalization techniques can play an important role. Experimental\nstudies with ESC-50 and CURE corpora elucidate the differences in dataset\ncomplexity and robustness offered by proposed approaches.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:35:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Dubey", "Harishchandra", ""], ["Emmanouilidou", "Dimitra", ""], ["Tashev", "Ivan J.", ""]]}, {"id": "2001.03897", "submitter": "Elham Seifossadat", "authors": "Elham Seifossadat and Hossein Sameti", "title": "Stochastic Natural Language Generation Using Dependency Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a stochastic corpus-based model for generating natural\nlanguage text. Our model first encodes dependency relations from training data\nthrough a feature set, then concatenates these features to produce a new\ndependency tree for a given meaning representation, and finally generates a\nnatural language utterance from the produced dependency tree. We test our model\non nine domains from tabular, dialogue act and RDF format. Our model\noutperforms the corpus-based state-of-the-art methods trained on tabular\ndatasets and also achieves comparable results with neural network-based\napproaches trained on dialogue act, E2E and WebNLG datasets for BLEU and ERR\nevaluation metrics. Also, by reporting Human Evaluation results, we show that\nour model produces high-quality utterances in aspects of informativeness and\nnaturalness as well as quality.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:40:11 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Seifossadat", "Elham", ""], ["Sameti", "Hossein", ""]]}, {"id": "2001.03898", "submitter": "Yao Zhang", "authors": "Yao Zhang, Daniel Jarrett, Mihaela van der Schaar", "title": "Stepwise Model Selection for Sequence Prediction via Deep Kernel\n  Learning", "comments": null, "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential problem in automated machine learning (AutoML) is that of model\nselection. A unique challenge in the sequential setting is the fact that the\noptimal model itself may vary over time, depending on the distribution of\nfeatures and labels available up to each point in time. In this paper, we\npropose a novel Bayesian optimization (BO) algorithm to tackle the challenge of\nmodel selection in this setting. This is accomplished by treating the\nperformance at each time step as its own black-box function. In order to solve\nthe resulting multiple black-box function optimization problem jointly and\nefficiently, we exploit potential correlations among black-box functions using\ndeep kernel learning (DKL). To the best of our knowledge, we are the first to\nformulate the problem of stepwise model selection (SMS) for sequence\nprediction, and to design and demonstrate an efficient joint-learning algorithm\nfor this purpose. Using multiple real-world datasets, we verify that our\nproposed method outperforms both standard BO and multi-objective BO algorithms\non a variety of sequence prediction tasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 09:42:19 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:54:16 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 11:46:09 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhang", "Yao", ""], ["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.03923", "submitter": "Changhee Han", "authors": "Changhee Han, Leonardo Rundo, Kohei Murao, Takafumi Nemoto, Hideki\n  Nakayama", "title": "Bridging the gap between AI and Healthcare sides: towards developing\n  clinically relevant AI-powered diagnosis systems", "comments": "13 pages, 2 figure, accepted to AIAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of Convolutional Neural Network-based Computer-Aided\nDiagnosis research, its clinical applications remain challenging. Accordingly,\ndeveloping medical Artificial Intelligence (AI) fitting into a clinical\nenvironment requires identifying/bridging the gap between AI and Healthcare\nsides. Since the biggest problem in Medical Imaging lies in data paucity,\nconfirming the clinical relevance for diagnosis of research-proven image\naugmentation techniques is essential. Therefore, we hold a clinically valuable\nAI-envisioning workshop among Japanese Medical Imaging experts, physicians, and\ngeneralists in Healthcare/Informatics. Then, a questionnaire survey for\nphysicians evaluates our pathology-aware Generative Adversarial Network\n(GAN)-based image augmentation projects in terms of Data Augmentation and\nphysician training. The workshop reveals the intrinsic gap between\nAI/Healthcare sides and solutions on Why (i.e., clinical\nsignificance/interpretation) and How (i.e., data acquisition, commercial\ndeployment, and safety/feeling safe). This analysis confirms our\npathology-aware GANs' clinical relevance as a clinical decision support system\nand non-expert physician training tool. Our findings would play a key role in\nconnecting inter-disciplinary research and clinical applications, not limited\nto the Japanese medical context and pathology-aware GANs.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 12:45:46 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 16:24:51 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Han", "Changhee", ""], ["Rundo", "Leonardo", ""], ["Murao", "Kohei", ""], ["Nemoto", "Takafumi", ""], ["Nakayama", "Hideki", ""]]}, {"id": "2001.03952", "submitter": "Zhaohui Yang", "authors": "Guangyu Jia and Zhaohui Yang and Hak-Keung Lam and Jianfeng Shi and\n  Mohammad Shikh-Bahaei", "title": "Channel Assignment in Uplink Wireless Communication using Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This letter investigates a channel assignment problem in uplink wireless\ncommunication systems. Our goal is to maximize the sum rate of all users\nsubject to integer channel assignment constraints. A convex optimization based\nalgorithm is provided to obtain the optimal channel assignment, where the\nclosed-form solution is obtained in each step. Due to high computational\ncomplexity in the convex optimization based algorithm, machine learning\napproaches are employed to obtain computational efficient solutions. More\nspecifically, the data are generated by using convex optimization based\nalgorithm and the original problem is converted to a regression problem which\nis addressed by the integration of convolutional neural networks (CNNs),\nfeed-forward neural networks (FNNs), random forest and gated recurrent unit\nnetworks (GRUs). The results demonstrate that the machine learning method\nlargely reduces the computation time with slightly compromising of prediction\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 15:54:20 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jia", "Guangyu", ""], ["Yang", "Zhaohui", ""], ["Lam", "Hak-Keung", ""], ["Shi", "Jianfeng", ""], ["Shikh-Bahaei", "Mohammad", ""]]}, {"id": "2001.03955", "submitter": "Masoumeh Soflaei", "authors": "Masoumeh Soflaei, Hongyu Guo, Ali Al-Bashabsheh, Yongyi Mao, Richong\n  Zhang", "title": "Aggregated Learning: A Vector-Quantization Approach to Learning Neural\n  Network Classifiers", "comments": "Proof of theoretical results are provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a neural network classifier. Under the\ninformation bottleneck (IB) principle, we associate with this classification\nproblem a representation learning problem, which we call \"IB learning\". We show\nthat IB learning is, in fact, equivalent to a special class of the quantization\nproblem. The classical results in rate-distortion theory then suggest that IB\nlearning can benefit from a \"vector quantization\" approach, namely,\nsimultaneously learning the representations of multiple input objects. Such an\napproach assisted with some variational techniques, result in a novel learning\nframework, \"Aggregated Learning\", for classification with neural network\nmodels. In this framework, several objects are jointly classified by a single\nneural network. The effectiveness of this framework is verified through\nextensive experiments on standard image recognition and text classification\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 16:22:24 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 01:43:20 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 16:42:00 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Soflaei", "Masoumeh", ""], ["Guo", "Hongyu", ""], ["Al-Bashabsheh", "Ali", ""], ["Mao", "Yongyi", ""], ["Zhang", "Richong", ""]]}, {"id": "2001.03956", "submitter": "Sandhya Tripathi", "authors": "Sandhya Tripathi, N. Hemachandra, Prashant Trivedi", "title": "Interpretable feature subset selection: A Shapley value based approach", "comments": "A shorter version of this work appeared in a special session titled\n  Explainable AI at IEEE BigData'20 conference. More experiments and a new\n  notion of interpretable FSS introduced in this version. Earlier plots for\n  sample bias robustness are corrected and updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For feature selection and related problems, we introduce the notion of\nclassification game, a cooperative game, with features as players and hinge\nloss based characteristic function and relate a feature's contribution to\nShapley value based error apportioning (SVEA) of total training error. Our\nmajor contribution is ($\\star$) to show that for any dataset the threshold 0 on\nSVEA value identifies feature subset whose joint interactions for label\nprediction is significant or those features that span a subspace where the data\nis predominantly lying. In addition, our scheme ($\\star$) identifies the\nfeatures on which Bayes classifier doesn't depend but any surrogate loss\nfunction based finite sample classifier does; this contributes to the excess\n$0$-$1$ risk of such a classifier, ($\\star$) estimates unknown true hinge risk\nof a feature, and ($\\star$) relate the stability property of an allocation and\nnegative valued SVEA by designing the analogue of core of classification game.\nDue to Shapley value's computationally expensive nature, we build on a known\nMonte Carlo based approximation algorithm that computes characteristic function\n(Linear Programs) only when needed. We address the potential sample bias\nproblem in feature selection by providing interval estimates for SVEA values\nobtained from multiple sub-samples. We illustrate all the above aspects on\nvarious synthetic and real datasets and show that our scheme achieves better\nresults than existing recursive feature elimination technique and ReliefF in\nmost cases. Our theoretically grounded classification game in terms of well\ndefined characteristic function offers interpretability (which we formalize in\nterms of final task) and explainability of our framework, including\nidentification of important features.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 16:27:08 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:28:58 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 19:24:45 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tripathi", "Sandhya", ""], ["Hemachandra", "N.", ""], ["Trivedi", "Prashant", ""]]}, {"id": "2001.03985", "submitter": "Luigi Acerbi", "authors": "Bas van Opheusden, Luigi Acerbi and Wei Ji Ma", "title": "Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial\n  Sampling", "comments": "Bas van Opheusden and Luigi Acerbi contributed equally to this work", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008483", "report-no": null, "categories": "cs.LG q-bio.NC q-bio.QM stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fate of scientific hypotheses often relies on the ability of a\ncomputational model to explain the data, quantified in modern statistical\napproaches by the likelihood function. The log-likelihood is the key element\nfor parameter estimation and model evaluation. However, the log-likelihood of\ncomplex models in fields such as computational biology and neuroscience is\noften intractable to compute analytically or numerically. In those cases,\nresearchers can often only estimate the log-likelihood by comparing observed\ndata with synthetic observations generated by model simulations. Standard\ntechniques to approximate the likelihood via simulation either use summary\nstatistics of the data or are at risk of producing severe biases in the\nestimate. Here, we explore another method, inverse binomial sampling (IBS),\nwhich can estimate the log-likelihood of an entire data set efficiently and\nwithout bias. For each observation, IBS draws samples from the simulator model\nuntil one matches the observation. The log-likelihood estimate is then a\nfunction of the number of samples drawn. The variance of this estimator is\nuniformly bounded, achieves the minimum variance for an unbiased estimator, and\nwe can compute calibrated estimates of the variance. We provide theoretical\narguments in favor of IBS and an empirical assessment of the method for\nmaximum-likelihood estimation with simulation-based models. As case studies, we\ntake three model-fitting problems of increasing complexity from computational\nand cognitive neuroscience. In all problems, IBS generally produces lower error\nin the estimated parameters and maximum log-likelihood values than alternative\nsampling methods with the same average number of samples. Our results\ndemonstrate the potential of IBS as a practical, robust, and easy to implement\nmethod for log-likelihood evaluation when exact techniques are not available.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 19:51:35 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 19:24:28 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 20:08:25 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["van Opheusden", "Bas", ""], ["Acerbi", "Luigi", ""], ["Ma", "Wei Ji", ""]]}, {"id": "2001.03988", "submitter": "Meimei Liu", "authors": "Meimei Liu and David B. Dunson", "title": "Domain Adaptive Bootstrap Aggregating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When there is a distributional shift between data used to train a predictive\nalgorithm and current data, performance can suffer. This is known as the domain\nadaptation problem. Bootstrap aggregating, or bagging, is a popular method for\nimproving stability of predictive algorithms, while reducing variance and\nprotecting against over-fitting. This article proposes a domain adaptive\nbagging method coupled with a new iterative nearest neighbor sampler. The key\nidea is to draw bootstrap samples from the training data in such a manner that\ntheir distribution equals that of new testing data. The proposed approach\nprovides a general ensemble framework that can be applied to arbitrary\nclassifiers. We further modify the method to allow anomalous samples in the\ntest data corresponding to outliers in the training data. Theoretical support\nis provided, and the approach is compared to alternatives in simulations and\nreal data applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:02:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 04:51:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Liu", "Meimei", ""], ["Dunson", "David B.", ""]]}, {"id": "2001.03992", "submitter": "Muktabh Mayank Srivastava", "authors": "Muktabh Mayank Srivastava", "title": "Bag of Tricks for Retail Product Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Retail Product Image Classification is an important Computer Vision and\nMachine Learning problem for building real world systems like self-checkout\nstores and automated retail execution evaluation. In this work, we present\nvarious tricks to increase accuracy of Deep Learning models on different types\nof retail product image classification datasets. These tricks enable us to\nincrease the accuracy of fine tuned convnets for retail product image\nclassification by a large margin. As the most prominent trick, we introduce a\nnew neural network layer called Local-Concepts-Accumulation (LCA) layer which\ngives consistent gains across multiple datasets. Two other tricks we find to\nincrease accuracy on retail product identification are using an\ninstagram-pretrained Convnet and using Maximum Entropy as an auxiliary loss for\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:20:07 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Srivastava", "Muktabh Mayank", ""]]}, {"id": "2001.03994", "submitter": "Eric Wong", "authors": "Eric Wong, Leslie Rice, J. Zico Kolter", "title": "Fast is better than free: Revisiting adversarial training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, a method for learning robust deep networks, is\ntypically assumed to be more expensive than traditional training due to the\nnecessity of constructing adversarial examples via a first-order method like\nprojected gradient decent (PGD). In this paper, we make the surprising\ndiscovery that it is possible to train empirically robust models using a much\nweaker and cheaper adversary, an approach that was previously believed to be\nineffective, rendering the method no more costly than standard training in\npractice. Specifically, we show that adversarial training with the fast\ngradient sign method (FGSM), when combined with random initialization, is as\neffective as PGD-based training but has significantly lower cost. Furthermore\nwe show that FGSM adversarial training can be further accelerated by using\nstandard techniques for efficient training of deep networks, allowing us to\nlearn a robust CIFAR10 classifier with 45% robust accuracy to PGD attacks with\n$\\epsilon=8/255$ in 6 minutes, and a robust ImageNet classifier with 43% robust\naccuracy at $\\epsilon=2/255$ in 12 hours, in comparison to past work based on\n\"free\" adversarial training which took 10 and 50 hours to reach the same\nrespective thresholds. Finally, we identify a failure mode referred to as\n\"catastrophic overfitting\" which may have caused previous attempts to use FGSM\nadversarial training to fail. All code for reproducing the experiments in this\npaper as well as pretrained model weights are at\nhttps://github.com/locuslab/fast_adversarial.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:30:22 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wong", "Eric", ""], ["Rice", "Leslie", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2001.04001", "submitter": "Andrea Manzoni", "authors": "Stefania Fresca, Luca Dede, Andrea Manzoni", "title": "A comprehensive deep learning-based approach to reduced order modeling\n  of nonlinear time-dependent parametrized PDEs", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional reduced order modeling techniques such as the reduced basis (RB)\nmethod (relying, e.g., on proper orthogonal decomposition (POD)) suffer from\nsevere limitations when dealing with nonlinear time-dependent parametrized\nPDEs, because of the fundamental assumption of linear superimposition of modes\nthey are based on. For this reason, in the case of problems featuring coherent\nstructures that propagate over time such as transport, wave, or\nconvection-dominated phenomena, the RB method usually yields inefficient\nreduced order models (ROMs) if one aims at obtaining reduced order\napproximations sufficiently accurate compared to the high-fidelity, full order\nmodel (FOM) solution. To overcome these limitations, in this work, we propose a\nnew nonlinear approach to set reduced order models by exploiting deep learning\n(DL) algorithms. In the resulting nonlinear ROM, which we refer to as DL-ROM,\nboth the nonlinear trial manifold (corresponding to the set of basis functions\nin a linear ROM) as well as the nonlinear reduced dynamics (corresponding to\nthe projection stage in a linear ROM) are learned in a non-intrusive way by\nrelying on DL algorithms; the latter are trained on a set of FOM solutions\nobtained for different parameter values. In this paper, we show how to\nconstruct a DL-ROM for both linear and nonlinear time-dependent parametrized\nPDEs; moreover, we assess its accuracy on test cases featuring different\nparametrized PDE problems. Numerical results indicate that DL-ROMs whose\ndimension is equal to the intrinsic dimensionality of the PDE solutions\nmanifold are able to approximate the solution of parametrized PDEs in\nsituations where a huge number of POD modes would be necessary to achieve the\nsame degree of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 21:18:18 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Fresca", "Stefania", ""], ["Dede", "Luca", ""], ["Manzoni", "Andrea", ""]]}, {"id": "2001.04025", "submitter": "Chen Ma", "authors": "Chen Ma, Dylan R. Ashley, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Features for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer in Reinforcement Learning (RL) refers to the idea of applying\nknowledge gained from previous tasks to solving related tasks. Learning a\nuniversal value function (Schaul et al., 2015), which generalizes over goals\nand states, has previously been shown to be useful for transfer. However,\nsuccessor features are believed to be more suitable than values for transfer\n(Dayan, 1993; Barreto et al.,2017), even though they cannot directly generalize\nto new goals. In this paper, we propose (1) Universal Successor Features (USFs)\nto capture the underlying dynamics of the environment while allowing\ngeneralization to unseen goals and (2) a flexible end-to-end model of USFs that\ncan be trained by interacting with the environment. We show that learning USFs\nis compatible with any RL algorithm that learns state values using a temporal\ndifference method. Our experiments in a simple gridworld and with two MuJoCo\nenvironments show that USFs can greatly accelerate training when learning\nmultiple tasks and can effectively transfer knowledge to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 03:41:06 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ma", "Chen", ""], ["Ashley", "Dylan R.", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.04026", "submitter": "Zijian Liu", "authors": "Zijian Liu, Chunbo Luo, Shuai Li, Peng Ren and Geyong Min", "title": "Fractional order graph neural network", "comments": "There are serious mistakes in the article and it needs to be\n  retracted and corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes fractional order graph neural networks (FGNNs), optimized\nby the approximation strategy to address the challenges of local optimum of\nclassic and fractional graph neural networks which are specialised at\naggregating information from the feature and adjacent matrices of connected\nnodes and their neighbours to solve learning tasks on non-Euclidean data such\nas graphs. Meanwhile the approximate calculation of fractional order gradients\nalso overcomes the high computational complexity of fractional order\nderivations. We further prove that such an approximation is feasible and the\nFGNN is unbiased towards global optimization solution. Extensive experiments on\ncitation networks show that FGNN achieves great advantage over baseline models\nwhen selected appropriate fractional order.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 11:55:55 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 08:30:29 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 06:23:18 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Liu", "Zijian", ""], ["Luo", "Chunbo", ""], ["Li", "Shuai", ""], ["Ren", "Peng", ""], ["Min", "Geyong", ""]]}, {"id": "2001.04027", "submitter": "Luca Magri", "authors": "Francisco Huhn, Luca Magri", "title": "Learning ergodic averages in chaotic systems", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-informed machine learning method to predict the time\naverage of a chaotic attractor. The method is based on the hybrid echo state\nnetwork (hESN). We assume that the system is ergodic, so the time average is\nequal to the ergodic average. Compared to conventional echo state networks\n(ESN) (purely data-driven), the hESN uses additional information from an\nincomplete, or imperfect, physical model. We evaluate the performance of the\nhESN and compare it to that of an ESN. This approach is demonstrated on a\nchaotic time-delayed thermoacoustic system, where the inclusion of a physical\nmodel significantly improves the accuracy of the prediction, reducing the\nrelative error from 48% to 7%. This improvement is obtained at the low extra\ncost of solving two ordinary differential equations. This framework shows the\npotential of using machine learning techniques combined with prior physical\nknowledge to improve the prediction of time-averaged quantities in chaotic\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:12:39 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 11:50:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Huhn", "Francisco", ""], ["Magri", "Luca", ""]]}, {"id": "2001.04029", "submitter": "Zhengzhi Sun", "authors": "Zheng-zhi Sun, Shi-ju Ran and Gang Su", "title": "Tangent-Space Gradient Optimization of Tensor Network for Machine\n  Learning", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. E 102, 012152 (2020)", "doi": "10.1103/PhysRevE.102.012152", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gradient-based optimization method for deep machine learning models\nsuffers from gradient vanishing and exploding problems, particularly when the\ncomputational graph becomes deep. In this work, we propose the tangent-space\ngradient optimization (TSGO) for the probabilistic models to keep the gradients\nfrom vanishing or exploding. The central idea is to guarantee the orthogonality\nbetween the variational parameters and the gradients. The optimization is then\nimplemented by rotating parameter vector towards the direction of gradient. We\nexplain and testify TSGO in tensor network (TN) machine learning, where the TN\ndescribes the joint probability distribution as a normalized state $\\left| \\psi\n\\right\\rangle $ in Hilbert space. We show that the gradient can be restricted\nin the tangent space of $\\left\\langle \\psi \\right.\\left| \\psi \\right\\rangle =\n1$ hyper-sphere. Instead of additional adaptive methods to control the learning\nrate in deep learning, the learning rate of TSGO is naturally determined by the\nangle $\\theta $ as $\\eta = \\tan \\theta $. Our numerical results reveal better\nconvergence of TSGO in comparison to the off-the-shelf Adam.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:40:40 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Sun", "Zheng-zhi", ""], ["Ran", "Shi-ju", ""], ["Su", "Gang", ""]]}, {"id": "2001.04030", "submitter": "Abdullatif Albaseer Mr", "authors": "Abdullatif Albaseer, Bekir Sait Ciftler, Mohamed Abdallah, and Ala\n  Al-Fuqaha", "title": "Exploiting Unlabeled Data in Smart Cities using Federated Learning", "comments": "Submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns are considered one of the main challenges in smart cities as\nsharing sensitive data brings threatening problems to people's lives. Federated\nlearning has emerged as an effective technique to avoid privacy infringement as\nwell as increase the utilization of the data. However, there is a scarcity in\nthe amount of labeled data and an abundance of unlabeled data collected in\nsmart cities, hence there is a need to use semi-supervised learning. We propose\na semi-supervised federated learning method called FedSem that exploits\nunlabeled data. The algorithm is divided into two phases where the first phase\ntrains a global model based on the labeled data. In the second phase, we use\nsemi-supervised learning based on the pseudo labeling technique to improve the\nmodel. We conducted several experiments using traffic signs dataset to show\nthat FedSem can improve accuracy up to 8% by utilizing the unlabeled data in\nthe learning process.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 13:25:34 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 23:57:09 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Albaseer", "Abdullatif", ""], ["Ciftler", "Bekir Sait", ""], ["Abdallah", "Mohamed", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2001.04032", "submitter": "Joseph Futoma", "authors": "Joseph Futoma, Michael C. Hughes, Finale Doshi-Velez", "title": "POPCORN: Partially Observed Prediction COnstrained ReiNforcement\n  Learning", "comments": "Accepted to AISTATS 2020, Palermo, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many medical decision-making tasks can be framed as partially observed Markov\ndecision processes (POMDPs). However, prevailing two-stage approaches that\nfirst learn a POMDP and then solve it often fail because the model that best\nfits the data may not be well suited for planning. We introduce a new\noptimization objective that (a) produces both high-performing policies and\nhigh-quality generative models, even when some observations are irrelevant for\nplanning, and (b) does so in batch off-policy settings that are typical in\nhealthcare, when only retrospective data is available. We demonstrate our\napproach on synthetic examples and a challenging medical decision-making\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 01:55:50 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 15:57:08 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Futoma", "Joseph", ""], ["Hughes", "Michael C.", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2001.04045", "submitter": "Aerin Kim", "authors": "Rohit Pandey, Yingnong Dang, Gil Lapid Shafriri, Murali Chintalapati,\n  Aerin Kim", "title": "Breaking hypothesis testing for failure rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the utility of point processes and failure rates and the most\ncommon point process for modeling failure rates, the Poisson point process.\nNext, we describe the uniformly most powerful test for comparing the rates of\ntwo Poisson point processes for a one-sided test (henceforth referred to as the\n\"rate test\"). A common argument against using this test is that real world data\nrarely follows the Poisson point process. We thus investigate what happens when\nthe distributional assumptions of tests like these are violated and the test\nstill applied. We find a non-pathological example (using the rate test on a\nCompound Poisson distribution with Binomial compounding) where violating the\ndistributional assumptions of the rate test make it perform better (lower error\nrates). We also find that if we replace the distribution of the test statistic\nunder the null hypothesis with any other arbitrary distribution, the\nperformance of the test (described in terms of the false negative rate to false\npositive rate trade-off) remains exactly the same. Next, we compare the\nperformance of the rate test to a version of the Wald test customized to the\nNegative Binomial point process and find it to perform very similarly while\nbeing much more general and versatile. Finally, we discuss the applications to\nMicrosoft Azure. The code for all experiments performed is open source and\nlinked in the introduction.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:17:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Pandey", "Rohit", ""], ["Dang", "Yingnong", ""], ["Shafriri", "Gil Lapid", ""], ["Chintalapati", "Murali", ""], ["Kim", "Aerin", ""]]}, {"id": "2001.04050", "submitter": "Ling Chen", "authors": "Fan Yang, Ling Chen, Fan Zhou, Yusong Gao, Wei Cao", "title": "Relational State-Space Model for Stochastic Multi-Object Systems", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world dynamical systems often consist of multiple stochastic subsystems\nthat interact with each other. Modeling and forecasting the behavior of such\ndynamics are generally not easy, due to the inherent hardness in understanding\nthe complicated interactions and evolutions of their constituents. This paper\nintroduces the relational state-space model (R-SSM), a sequential hierarchical\nlatent variable model that makes use of graph neural networks (GNNs) to\nsimulate the joint state transitions of multiple correlated objects. By letting\nGNNs cooperate with SSM, R-SSM provides a flexible way to incorporate\nrelational information into the modeling of multi-object dynamics. We further\nsuggest augmenting the model with normalizing flows instantiated for\nvertex-indexed random variables and propose two auxiliary contrastive\nobjectives to facilitate the learning. The utility of R-SSM is empirically\nevaluated on synthetic and real time-series datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:45:21 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Yang", "Fan", ""], ["Chen", "Ling", ""], ["Zhou", "Fan", ""], ["Gao", "Yusong", ""], ["Cao", "Wei", ""]]}, {"id": "2001.04051", "submitter": "Joseph Janizek", "authors": "Joseph D. Janizek, Gabriel Erion, Alex J. DeGrave, Su-In Lee", "title": "An Adversarial Approach for the Robust Classification of Pneumonia from\n  Chest Radiographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has shown promise in the domain of disease classification\nfrom medical images, models based on state-of-the-art convolutional neural\nnetwork architectures often exhibit performance loss due to dataset shift.\nModels trained using data from one hospital system achieve high predictive\nperformance when tested on data from the same hospital, but perform\nsignificantly worse when they are tested in different hospital systems.\nFurthermore, even within a given hospital system, deep learning models have\nbeen shown to depend on hospital- and patient-level confounders rather than\nmeaningful pathology to make classifications. In order for these models to be\nsafely deployed, we would like to ensure that they do not use confounding\nvariables to make their classification, and that they will work well even when\ntested on images from hospitals that were not included in the training data. We\nattempt to address this problem in the context of pneumonia classification from\nchest radiographs. We propose an approach based on adversarial optimization,\nwhich allows us to learn more robust models that do not depend on confounders.\nSpecifically, we demonstrate improved out-of-hospital generalization\nperformance of a pneumonia classifier by training a model that is invariant to\nthe view position of chest radiographs (anterior-posterior vs.\nposterior-anterior). Our approach leads to better predictive performance on\nexternal hospital data than both a standard baseline and previously proposed\nmethods to handle confounding, and also suggests a method for identifying\nmodels that may rely on confounders. Code available at\nhttps://github.com/suinleelab/cxr_adv.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 03:49:05 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Janizek", "Joseph D.", ""], ["Erion", "Gabriel", ""], ["DeGrave", "Alex J.", ""], ["Lee", "Su-In", ""]]}, {"id": "2001.04056", "submitter": "Benjamin Zi Hao Zhao", "authors": "Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Mohamed Ali Kaafar", "title": "On the Resilience of Biometric Authentication Systems against Random\n  Inputs", "comments": "Accepted by NDSS2020, 18 pages", "journal-ref": null, "doi": "10.14722/ndss.2020.24210", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assess the security of machine learning based biometric authentication\nsystems against an attacker who submits uniform random inputs, either as\nfeature vectors or raw inputs, in order to find an accepting sample of a target\nuser. The average false positive rate (FPR) of the system, i.e., the rate at\nwhich an impostor is incorrectly accepted as the legitimate user, may be\ninterpreted as a measure of the success probability of such an attack. However,\nwe show that the success rate is often higher than the FPR. In particular, for\none reconstructed biometric system with an average FPR of 0.03, the success\nrate was as high as 0.78. This has implications for the security of the system,\nas an attacker with only the knowledge of the length of the feature space can\nimpersonate the user with less than 2 attempts on average. We provide detailed\nanalysis of why the attack is successful, and validate our results using four\ndifferent biometric modalities and four different machine learning classifiers.\nFinally, we propose mitigation techniques that render such attacks ineffective,\nwith little to no effect on the accuracy of the system.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 04:20:08 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 03:00:27 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhao", "Benjamin Zi Hao", ""], ["Asghar", "Hassan Jameel", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2001.04061", "submitter": "Changhao Chen", "authors": "Changhao Chen, Peijun Zhao, Chris Xiaoxuan Lu, Wei Wang, Andrew\n  Markham, Niki Trigoni", "title": "Deep Learning based Pedestrian Inertial Navigation: Methods, Dataset and\n  On-Device Inference", "comments": "Accepted to IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern inertial measurements units (IMUs) are small, cheap, energy efficient,\nand widely employed in smart devices and mobile robots. Exploiting inertial\ndata for accurate and reliable pedestrian navigation supports is a key\ncomponent for emerging Internet-of-Things applications and services. Recently,\nthere has been a growing interest in applying deep neural networks (DNNs) to\nmotion sensing and location estimation. However, the lack of sufficient\nlabelled data for training and evaluating architecture benchmarks has limited\nthe adoption of DNNs in IMU-based tasks. In this paper, we present and release\nthe Oxford Inertial Odometry Dataset (OxIOD), a first-of-its-kind public\ndataset for deep learning based inertial navigation research, with fine-grained\nground-truth on all sequences. Furthermore, to enable more efficient inference\nat the edge, we propose a novel lightweight framework to learn and reconstruct\npedestrian trajectories from raw IMU data. Extensive experiments show the\neffectiveness of our dataset and methods in achieving accurate data-driven\npedestrian inertial navigation on resource-constrained devices.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 04:41:54 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Chen", "Changhao", ""], ["Zhao", "Peijun", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wang", "Wei", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "2001.04066", "submitter": "Richard Wang", "authors": "Feng Cen and Guanghui Wang", "title": "Boosting Occluded Image Classification via Subspace Decomposition Based\n  Estimation of Deep Features", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 2019", "doi": "10.1109/TCYB.2019.2931067", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of partially occluded images is a highly challenging computer\nvision problem even for the cutting edge deep learning technologies. To achieve\na robust image classification for occluded images, this paper proposes a novel\nscheme using subspace decomposition based estimation (SDBE). The proposed\nSDBE-based classification scheme first employs a base convolutional neural\nnetwork to extract the deep feature vector (DFV) and then utilizes the SDBE to\ncompute the DFV of the original occlusion-free image for classification. The\nSDBE is performed by projecting the DFV of the occluded image onto the linear\nspan of a class dictionary (CD) along the linear span of an occlusion error\ndictionary (OED). The CD and OED are constructed respectively by concatenating\nthe DFVs of a training set and the occlusion error vectors of an extra set of\nimage pairs. Two implementations of the SDBE are studied in this paper: the\n$l_1$-norm and the squared $l_2$-norm regularized least-squares estimates. By\nemploying the ResNet-152, pre-trained on the ILSVRC2012 training set, as the\nbase network, the proposed SBDE-based classification scheme is extensively\nevaluated on the Caltech-101 and ILSVRC2012 datasets. Extensive experimental\nresults demonstrate that the proposed SDBE-based scheme dramatically boosts the\nclassification accuracy for occluded images, and achieves around $22.25\\%$\nincrease in classification accuracy under $20\\%$ occlusion on the ILSVRC2012\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 05:36:27 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Cen", "Feng", ""], ["Wang", "Guanghui", ""]]}, {"id": "2001.04072", "submitter": "Alfred Ajay Aureate R", "authors": "Mohith Damarapati, Inavamsi B. Enaganti and Alfred Ajay Aureate\n  Rajakumar", "title": "Numerical Sequence Prediction using Bayesian Concept Learning", "comments": "7 pages, 6 figures. Was done as part of the course project at NYU\n  Courant. To be extended for a conference proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people learn mathematical patterns or sequences, they are able to\nidentify the concepts (or rules) underlying those patterns. Having learned the\nunderlying concepts, humans are also able to generalize those concepts to other\nnumbers, so far as to even identify previously unseen combinations of those\nrules. Current state-of-the art RNN architectures like LSTMs perform well in\npredicting successive elements of sequential data, but require vast amounts of\ntraining examples. Even with extensive data, these models struggle to\ngeneralize concepts. From our behavioral study, we also found that humans are\nable to disregard noise and identify the underlying rules generating the\ncorrupted sequences. We therefore propose a Bayesian model that captures these\nhuman-like learning capabilities to predict next number in a given sequence,\nbetter than traditional LSTMs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 06:02:44 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Damarapati", "Mohith", ""], ["Enaganti", "Inavamsi B.", ""], ["Rajakumar", "Alfred Ajay Aureate", ""]]}, {"id": "2001.04077", "submitter": "Seth Huang", "authors": "Seth H. Huang, Xu Lingjie, Jiang Congwei", "title": "Residual Attention Net for Superior Cross-Domain Time Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel architecture, residual attention net (RAN), which merges a\nsequence architecture, universal transformer, and a computer vision\narchitecture, residual net, with a high-way architecture for cross-domain\nsequence modeling. The architecture aims at addressing the long dependency\nissue often faced by recurrent-neural-net-based structures. This paper serves\nas a proof-of-concept for a new architecture, with RAN aiming at providing the\nmodel a higher level understanding of sequence patterns. To our best knowledge,\nwe are the first to propose such an architecture. Out of the standard 85 UCR\ndata sets, we have achieved 35 state-of-the-art results with 10 results\nmatching current state-of-the-art results without further model fine-tuning.\nThe results indicate that such architecture is promising in complex,\nlong-sequence modeling and may have vast, cross-domain applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 06:14:04 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Huang", "Seth H.", ""], ["Lingjie", "Xu", ""], ["Congwei", "Jiang", ""]]}, {"id": "2001.04092", "submitter": "Tiantian Li", "authors": "Qiuyu Zhu and Tiantian Li", "title": "Semi-supervised learning method based on predefined evenly-distributed\n  class centroids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to supervised learning, semi-supervised learning reduces the\ndependence of deep learning on a large number of labeled samples. In this work,\nwe use a small number of labeled samples and perform data augmentation on\nunlabeled samples to achieve image classification. Our method constrains all\nsamples to the predefined evenly-distributed class centroids (PEDCC) by the\ncorresponding loss function. Specifically, the PEDCC-Loss for labeled samples,\nand the maximum mean discrepancy loss for unlabeled samples are used to make\nthe feature distribution closer to the distribution of PEDCC. Our method\nensures that the inter-class distance is large and the intra-class distance is\nsmall enough to make the classification boundaries between different classes\nclearer. Meanwhile, for unlabeled samples, we also use KL divergence to\nconstrain the consistency of the network predictions between unlabeled and\naugmented samples. Our semi-supervised learning method achieves the\nstate-of-the-art results, with 4000 labeled samples on CIFAR10 and 1000 labeled\nsamples on SVHN, and the accuracy is 95.10% and 97.58% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:03:32 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Zhu", "Qiuyu", ""], ["Li", "Tiantian", ""]]}, {"id": "2001.04107", "submitter": "Suyoung Lee", "authors": "Suyoung Lee, HyungSeok Han, Sang Kil Cha, Sooel Son", "title": "Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer", "comments": "18 pages, accepted at USENIX Security '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JavaScript (JS) engine vulnerabilities pose significant security threats\naffecting billions of web browsers. While fuzzing is a prevalent technique for\nfinding such vulnerabilities, there have been few studies that leverage the\nrecent advances in neural network language models (NNLMs). In this paper, we\npresent Montage, the first NNLM-guided fuzzer for finding JS engine\nvulnerabilities. The key aspect of our technique is to transform a JS abstract\nsyntax tree (AST) into a sequence of AST subtrees that can directly train\nprevailing NNLMs. We demonstrate that Montage is capable of generating valid JS\ntests, and show that it outperforms previous studies in terms of finding\nvulnerabilities. Montage found 37 real-world bugs, including three CVEs, in the\nlatest JS engines, demonstrating its efficacy in finding JS engine bugs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:45:56 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 08:28:37 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Lee", "Suyoung", ""], ["Han", "HyungSeok", ""], ["Cha", "Sang Kil", ""], ["Son", "Sooel", ""]]}, {"id": "2001.04114", "submitter": "Xia Liu", "authors": "Xia Liu", "title": "Approximation smooth and sparse functions by deep neural networks\n  without saturation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing neural networks for function approximation is a classical and\nlongstanding topic in approximation theory. In this paper, we aim at\nconstructing deep neural networks (deep nets for short) with three hidden\nlayers to approximate smooth and sparse functions. In particular, we prove that\nthe constructed deep nets can reach the optimal approximation rate in\napproximating both smooth and sparse functions with controllable magnitude of\nfree parameters. Since the saturation that describes the bottleneck of\napproximate is an insurmountable problem of constructive neural networks, we\nalso prove that deepening the neural network with only one more hidden layer\ncan avoid the saturation. The obtained results underlie advantages of deep nets\nand provide theoretical explanations for deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 09:28:50 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Liu", "Xia", ""]]}, {"id": "2001.04129", "submitter": "Jorge Calvo-Zaragoza", "authors": "Antonio-Javier Gallego, Jorge Calvo-Zaragoza, Robert B. Fisher", "title": "Incremental Unsupervised Domain-Adversarial Training of Neural Networks", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of supervised statistical learning, it is typically assumed\nthat the training set comes from the same distribution that draws the test\nsamples. When this is not the case, the behavior of the learned model is\nunpredictable and becomes dependent upon the degree of similarity between the\ndistribution of the training set and the distribution of the test set. One of\nthe research topics that investigates this scenario is referred to as domain\nadaptation. Deep neural networks brought dramatic advances in pattern\nrecognition and that is why there have been many attempts to provide good\ndomain adaptation algorithms for these models. Here we take a different avenue\nand approach the problem from an incremental point of view, where the model is\nadapted to the new domain iteratively. We make use of an existing unsupervised\ndomain-adaptation algorithm to identify the target samples on which there is\ngreater confidence about their true label. The output of the model is analyzed\nin different ways to determine the candidate samples. The selected set is then\nadded to the source training set by considering the labels provided by the\nnetwork as ground truth, and the process is repeated until all target samples\nare labelled. Our results report a clear improvement with respect to the\nnon-incremental case in several datasets, also outperforming other\nstate-of-the-art domain adaptation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 09:54:35 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gallego", "Antonio-Javier", ""], ["Calvo-Zaragoza", "Jorge", ""], ["Fisher", "Robert B.", ""]]}, {"id": "2001.04147", "submitter": "Przemys{\\l}aw Spurek", "authors": "Andrzej Bedychaj, Przemys{\\l}aw Spurek, Aleksandra Nowak, Jacek Tabor", "title": "WICA: nonlinear weighted ICA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent Component Analysis (ICA) aims to find a coordinate system in\nwhich the components of the data are independent. In this paper we construct a\nnew nonlinear ICA model, called WICA, which obtains better and more stable\nresults than other algorithms. A crucial tool is given by a new efficient\nmethod of verifying nonlinear dependence with the use of computation of\ncorrelation coefficients for normally weighted data. In addition, authors\npropose a new baseline nonlinear mixing to perform comparable experiments, and\na~reliable measure which allows fair comparison of nonlinear models. Our code\nfor WICA is available on Github https://github.com/gmum/wica.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 10:38:03 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 21:37:54 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bedychaj", "Andrzej", ""], ["Spurek", "Przemys\u0142aw", ""], ["Nowak", "Aleksandra", ""], ["Tabor", "Jacek", ""]]}, {"id": "2001.04168", "submitter": "Nikita Benkovich", "authors": "Nikita Benkovich, Roman Dedenok and Dmitry Golubev", "title": "DeepQuarantine for Suspicious Mail", "comments": "8 pages, 3 figures, presented at M3AAWG 47TH Montreal", "journal-ref": "CEUR Workshop Proceedings 2479 (2019) 68-76", "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce DeepQuarantine (DQ), a cloud technology to detect\nand quarantine potential spam messages. Spam attacks are becoming more diverse\nand can potentially be harmful to email users. Despite the high quality and\nperformance of spam filtering systems, detection of a spam campaign can take\nsome time. Unfortunately, in this case some unwanted messages get delivered to\nusers. To solve this problem, we created DQ, which detects potential spam and\nkeeps it in a special Quarantine folder for a while. The time gained allows us\nto double-check the messages to improve the reliability of the anti-spam\nsolution. Due to high precision of the technology, most of the quarantined mail\nis spam, which allows clients to use email without delay. Our solution is based\non applying Convolutional Neural Networks on MIME headers to extract deep\nfeatures from large-scale historical data. We evaluated the proposed method on\nreal-world data and showed that DQ enhances the quality of spam detection.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:32:58 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Benkovich", "Nikita", ""], ["Dedenok", "Roman", ""], ["Golubev", "Dmitry", ""]]}, {"id": "2001.04171", "submitter": "Maarten Bieshaar", "authors": "Silvia Beddar-Wiesing, Maarten Bieshaar", "title": "Multi-Sensor Data and Knowledge Fusion -- A Proposal for a Terminology\n  Definition", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fusion is a common tool for the analysis and utilization of available\ndatasets and so an essential part of data mining and machine learning\nprocesses. However, a clear definition of the type of fusion is not always\nprovided due to inconsistent literature. In the following, the process of\nfusion is defined depending on the fusion components and the abstraction level\non which the fusion occurs. The focus in the first part of the paper at hand is\non the clear definition of the terminology and the development of an\nappropriate ontology of the fusion components and the fusion level. In the\nsecond part, common fusion techniques are presented.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:42:36 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Beddar-Wiesing", "Silvia", ""], ["Bieshaar", "Maarten", ""]]}, {"id": "2001.04197", "submitter": "Takashi Nicholas Maeda", "authors": "Takashi Nicholas Maeda and Shohei Shimizu", "title": "Causal discovery of linear non-Gaussian acyclic models in the presence\n  of latent confounders", "comments": "This is an extended version of the AISTATS 2020 paper entitled \"RCD:\n  Repetitive causal discovery of linear non-Gaussian acyclic models with latent\n  confounders\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from data affected by latent confounders is an important and\ndifficult challenge. Causal functional model-based approaches have not been\nused to present variables whose relationships are affected by latent\nconfounders, while some constraint-based methods can present them. This paper\nproposes a causal functional model-based method called repetitive causal\ndiscovery (RCD) to discover the causal structure of observed variables affected\nby latent confounders. RCD repeats inferring the causal directions between a\nsmall number of observed variables and determines whether the relationships are\naffected by latent confounders. RCD finally produces a causal graph where a\nbi-directed arrow indicates the pair of variables that have the same latent\nconfounders, and a directed arrow indicates the causal direction of a pair of\nvariables that are not affected by the same latent confounder. The results of\nexperimental validation using simulated data and real-world data confirmed that\nRCD is effective in identifying latent confounders and causal directions\nbetween observed variables.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 12:55:47 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 03:25:51 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 01:11:57 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 11:41:54 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maeda", "Takashi Nicholas", ""], ["Shimizu", "Shohei", ""]]}, {"id": "2001.04206", "submitter": "Athanasios Stratikopoulos", "authors": "Athanasios Stratikopoulos, Juan Fumero, Zoran Sevarac and Christos\n  Kotselidis", "title": "Towards High Performance Java-based Deep Learning Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of modern cloud services along with the huge volume of data\nproduced on a daily basis, have set the demand for fast and efficient data\nprocessing. This demand is common among numerous application domains, such as\ndeep learning, data mining, and computer vision. Prior research has focused on\nemploying hardware accelerators as a means to overcome this inefficiency. This\ntrend has driven software development to target heterogeneous execution, and\nseveral modern computing systems have incorporated a mixture of diverse\ncomputing components, including GPUs and FPGAs. However, the specialization of\nthe applications' code for heterogeneous execution is not a trivial task, as it\nrequires developers to have hardware expertise in order to obtain high\nperformance. The vast majority of the existing deep learning frameworks that\nsupport heterogeneous acceleration, rely on the implementation of wrapper calls\nfrom a high-level programming language to a low-level accelerator backend, such\nas OpenCL, CUDA or HLS.\n  In this paper we have employed TornadoVM, a state-of-the-art heterogeneous\nprogramming framework to transparently accelerate Deep Netts; a Java-based deep\nlearning framework. Our initial results demonstrate up to 8x performance\nspeedup when executing the back propagation process of the network's training\non AMD GPUs against the sequential execution of the original Deep Netts\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:03:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Stratikopoulos", "Athanasios", ""], ["Fumero", "Juan", ""], ["Sevarac", "Zoran", ""], ["Kotselidis", "Christos", ""]]}, {"id": "2001.04243", "submitter": "Yitian Xu", "authors": "Yuzhou Cao, Shuqi Liu and Yitian Xu", "title": "Multi-Complementary and Unlabeled Learning for Arbitrary Losses and\n  Models", "comments": "22 pages, 5 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A weakly-supervised learning framework named as complementary-label learning\nhas been proposed recently, where each sample is equipped with a single\ncomplementary label that denotes one of the classes the sample does not belong\nto. However, the existing complementary-label learning methods cannot learn\nfrom the easily accessible unlabeled samples and samples with multiple\ncomplementary labels, which are more informative. In this paper, to remove\nthese limitations, we propose the novel multi-complementary and unlabeled\nlearning framework that allows unbiased estimation of classification risk from\nsamples with any number of complementary labels and unlabeled samples, for\narbitrary loss functions and models. We first give an unbiased estimator of the\nclassification risk from samples with multiple complementary labels, and then\nfurther improve the estimator by incorporating unlabeled samples into the risk\nformulation. The estimation error bounds show that the proposed methods are in\nthe optimal parametric convergence rate. Finally, the experiments on both\nlinear and deep models show the effectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:52:54 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 15:23:10 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 17:18:42 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Cao", "Yuzhou", ""], ["Liu", "Shuqi", ""], ["Xu", "Yitian", ""]]}, {"id": "2001.04246", "submitter": "Yaliang Li", "authors": "Daoyuan Chen, Yaliang Li, Minghui Qiu, Zhen Wang, Bofang Li, Bolin\n  Ding, Hongbo Deng, Jun Huang, Wei Lin, Jingren Zhou", "title": "AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural\n  Architecture Search", "comments": "accepted by IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models such as BERT have shown their effectiveness\nin various natural language processing tasks. However, the huge parameter size\nmakes them difficult to be deployed in real-time applications that require\nquick inference with limited resources. Existing methods compress BERT into\nsmall models while such compression is task-independent, i.e., the same\ncompressed BERT for all different downstream tasks. Motivated by the necessity\nand benefits of task-oriented BERT compression, we propose a novel compression\nmethod, AdaBERT, that leverages differentiable Neural Architecture Search to\nautomatically compress BERT into task-adaptive small models for specific tasks.\nWe incorporate a task-oriented knowledge distillation loss to provide search\nhints and an efficiency-aware loss as search constraints, which enables a good\ntrade-off between efficiency and effectiveness for task-adaptive BERT\ncompression. We evaluate AdaBERT on several NLP tasks, and the results\ndemonstrate that those task-adaptive compressed models are 12.7x to 29.3x\nfaster than BERT in inference time and 11.5x to 17.0x smaller in terms of\nparameter size, while comparable performance is maintained.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:03:26 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 10:58:24 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Chen", "Daoyuan", ""], ["Li", "Yaliang", ""], ["Qiu", "Minghui", ""], ["Wang", "Zhen", ""], ["Li", "Bofang", ""], ["Ding", "Bolin", ""], ["Deng", "Hongbo", ""], ["Huang", "Jun", ""], ["Lin", "Wei", ""], ["Zhou", "Jingren", ""]]}, {"id": "2001.04251", "submitter": "Rohit Reddy Muthyala", "authors": "Rohit R Muthyala, Davi Geiger, Zvi M. Kedem", "title": "Quantum Interference for Counting Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting the number of clusters, when these clusters overlap significantly is\na challenging problem in machine learning. We argue that a purely mathematical\nquantum theory, formulated using the path integral technique, when applied to\nnon-physics modeling leads to non-physics quantum theories that are statistical\nin nature. We show that a quantum theory can be a more robust statistical\ntheory to separate data to count overlapping clusters. The theory is also\nconfirmed from data simulations.This works identify how quantum theory can be\neffective in counting clusters and hope to inspire the field to further apply\nsuch techniques.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:13:57 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Muthyala", "Rohit R", ""], ["Geiger", "Davi", ""], ["Kedem", "Zvi M.", ""]]}, {"id": "2001.04253", "submitter": "Fajie Yuan", "authors": "Fajie Yuan, Xiangnan He, Alexandros Karatzoglou, Liguang Zhang", "title": "Parameter-Efficient Transfer from Sequential Behaviors for User Modeling\n  and Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive transfer learning has had a big impact on computer vision and NLP\ndomains but has not been used in the area of recommender systems. Even though\nthere has been a large body of research on generating recommendations based on\nmodeling user-item interaction sequences, few of them attempt to represent and\ntransfer these models for serving downstream tasks where only limited data\nexists.\n  In this paper, we delve on the task of effectively learning a single user\nrepresentation that can be applied to a diversity of tasks, from cross-domain\nrecommendations to user profile predictions. Fine-tuning a large pre-trained\nnetwork and adapting it to downstream tasks is an effective way to solve such\ntasks. However, fine-tuning is parameter inefficient considering that an entire\nmodel needs to be re-trained for every new task. To overcome this issue, we\ndevelop a parameter efficient transfer learning architecture, termed as\nPeterRec, which can be configured on-the-fly to various downstream tasks.\nSpecifically, PeterRec allows the pre-trained parameters to remain unaltered\nduring fine-tuning by injecting a series of re-learned neural networks, which\nare small but as expressive as learning the entire network. We perform\nextensive experimental ablation to show the effectiveness of the learned user\nrepresentation in five downstream tasks. Moreover, we show that PeterRec\nperforms efficient transfer learning in multiple domains, where it achieves\ncomparable or sometimes better performance relative to fine-tuning the entire\nmodel parameters. Codes and datasets are available at\nhttps://github.com/fajieyuan/sigir2020_peterrec.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:09:54 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 04:16:15 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 04:07:51 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 12:36:19 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yuan", "Fajie", ""], ["He", "Xiangnan", ""], ["Karatzoglou", "Alexandros", ""], ["Zhang", "Liguang", ""]]}, {"id": "2001.04263", "submitter": "Alec Linot", "authors": "Alec J. Linot and Michael D. Graham", "title": "Deep learning to discover and predict dynamics on an inertial manifold", "comments": "Accepted in Physical Review E", "journal-ref": "Phys. Rev. E 101, 062209 (2020)", "doi": "10.1103/PhysRevE.101.062209", "report-no": null, "categories": "cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A data-driven framework is developed to represent chaotic dynamics on an\ninertial manifold (IM), and applied to solutions of the Kuramoto-Sivashinsky\nequation. A hybrid method combining linear and nonlinear (neural-network)\ndimension reduction transforms between coordinates in the full state space and\non the IM. Additional neural networks predict time-evolution on the IM. The\nformalism accounts for translation invariance and energy conservation, and\nsubstantially outperforms linear dimension reduction, reproducing very well key\ndynamic and statistical features of the attractor.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 15:51:04 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 06:32:04 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 21:14:42 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Linot", "Alec J.", ""], ["Graham", "Michael D.", ""]]}, {"id": "2001.04264", "submitter": "Mohamed Ali Belabbas", "authors": "Mohamed Ali Belabbas", "title": "On implicit regularization: Morse functions and applications to matrix\n  factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit implicit regularization from the ground up using\nnotions from dynamical systems and invariant subspaces of Morse functions. The\nkey contributions are a new criterion for implicit regularization---a leading\ncontender to explain the generalization power of deep models such as neural\nnetworks---and a general blueprint to study it. We apply these techniques to\nsettle a conjecture on implicit regularization in matrix factorization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:17:25 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 22:06:26 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Belabbas", "Mohamed Ali", ""]]}, {"id": "2001.04271", "submitter": "Luigi Tommaso Luppino", "authors": "Luigi Tommaso Luppino, Michael Kampffmeyer, Filippo Maria Bianchi,\n  Gabriele Moser, Sebastiano Bruno Serpico, Robert Jenssen, and Stian Normann\n  Anfinsen", "title": "Deep Image Translation with an Affinity-Based Change Prior for\n  Unsupervised Multimodal Change Detection", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2021.3056196", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image translation with convolutional neural networks has recently been used\nas an approach to multimodal change detection. Existing approaches train the\nnetworks by exploiting supervised information of the change areas, which,\nhowever, is not always available. A main challenge in the unsupervised problem\nsetting is to avoid that change pixels affect the learning of the translation\nfunction. We propose two new network architectures trained with loss functions\nweighted by priors that reduce the impact of change pixels on the learning\nobjective. The change prior is derived in an unsupervised fashion from\nrelational pixel information captured by domain-specific affinity matrices.\nSpecifically, we use the vertex degrees associated with an absolute affinity\ndifference matrix and demonstrate their utility in combination with cycle\nconsistency and adversarial training. The proposed neural networks are compared\nwith state-of-the-art algorithms. Experiments conducted on three real datasets\nshow the effectiveness of our methodology.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:23:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 13:57:53 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Luppino", "Luigi Tommaso", ""], ["Kampffmeyer", "Michael", ""], ["Bianchi", "Filippo Maria", ""], ["Moser", "Gabriele", ""], ["Serpico", "Sebastiano Bruno", ""], ["Jenssen", "Robert", ""], ["Anfinsen", "Stian Normann", ""]]}, {"id": "2001.04276", "submitter": "Amir Mosavi Prof", "authors": "Shahab Shamshirband, Meisam Babanezhad, Amir Mosavi, Narjes Nabipour,\n  Eva Hajnal, Laszlo Nadai, Kwok-Wing Chau", "title": "Prediction of flow characteristics in the bubble column reactor by the\n  artificial pheromone-based communication of biological ants", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to perceive the behavior presented by the multiphase chemical\nreactors, the ant colony optimization algorithm was combined with computational\nfluid dynamics (CFD) data. This intelligent algorithm creates a probabilistic\ntechnique for computing flow and it can predict various levels of\nthree-dimensional bubble column reactor (BCR). This artificial ant algorithm is\nmimicking real ant behavior. This method can anticipate the flow\ncharacteristics in the reactor using almost 30 % of the whole data in the\ndomain. Following discovering the suitable parameters, the method is used for\npredicting the points not being simulated with CFD, which represent mesh\nrefinement of Ant colony method. In addition, it is possible to anticipate the\nbubble-column reactors in the absence of numerical results or training of exact\nvalues of evaluated data. The major benefits include reduced computational\ncosts and time savings. The results show a great agreement between ant colony\nprediction and CFD outputs in different sections of the BCR. The combination of\nant colony system and neural network framework can provide the smart structure\nto estimate biological and nature physics base phenomena. The ant colony\noptimization algorithm (ACO) framework based on ant behavior can solve all\nlocal mathematical answers throughout 3D bubble column reactor. The integration\nof all local answers can provide the overall solution in the reactor for\ndifferent characteristics. This new overview of modelling can illustrate new\nsight into biological behavior in nature.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 19:36:45 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Shamshirband", "Shahab", ""], ["Babanezhad", "Meisam", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Hajnal", "Eva", ""], ["Nadai", "Laszlo", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.04279", "submitter": "Amir Mosavi Prof", "authors": "Narjes Nabipour, Amir Mosavi, Eva Hajnal, Laszlo Nadai, Shahab\n  Shamshirband, Kwok-Wing Chau", "title": "Modeling Climate Change Impact on Wind Power Resources Using Adaptive\n  Neuro-Fuzzy Inference System", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate change impacts and adaptations are the subjects to ongoing issues\nthat attract the attention of many researchers. Insight into the wind power\npotential in an area and its probable variation due to climate change impacts\ncan provide useful information for energy policymakers and strategists for\nsustainable development and management of the energy. In this study, spatial\nvariation of wind power density at the turbine hub-height and its variability\nunder future climatic scenarios are taken under consideration. An ANFIS based\npost-processing technique was employed to match the power outputs of the\nregional climate model with those obtained from the reference data. The\nnear-surface wind data obtained from a regional climate model are employed to\ninvestigate climate change impacts on the wind power resources in the Caspian\nSea. Subsequent to converting near-surface wind speed to turbine hub-height\nspeed and computation of wind power density, the results have been investigated\nto reveal mean annual power, seasonal, and monthly variability for a 20-year\nperiod in the present (1981-2000) and in the future (2081-2100). The findings\nof this study indicated that the middle and northern parts of the Caspian Sea\nare placed with the highest values of wind power. However, the results of the\npost-processing technique using adaptive neuro-fuzzy inference system (ANFIS)\nmodel showed that the real potential of the wind power in the area is lower\nthan those of projected from the regional climate model.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 17:35:56 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Nabipour", "Narjes", ""], ["Mosavi", "Amir", ""], ["Hajnal", "Eva", ""], ["Nadai", "Laszlo", ""], ["Shamshirband", "Shahab", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.04281", "submitter": "Paul J. Pritz", "authors": "Paul J. Pritz and Daniel Perez and Kin K. Leung", "title": "Fast-Fourier-Forecasting Resource Utilisation in Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed computing systems often consist of hundreds of nodes, executing\ntasks with different resource requirements. Efficient resource provisioning and\ntask scheduling in such systems are non-trivial and require close monitoring\nand accurate forecasting of the state of the system, specifically resource\nutilisation at its constituent machines. Two challenges present themselves\ntowards these objectives. First, collecting monitoring data entails substantial\ncommunication overhead. This overhead can be prohibitively high, especially in\nnetworks where bandwidth is limited. Second, forecasting models to predict\nresource utilisation should be accurate and need to exhibit high inference\nspeed. Mission critical scheduling and resource allocation algorithms use these\npredictions and rely on their immediate availability. To address the first\nchallenge, we present a communication-efficient data collection mechanism.\nResource utilisation data is collected at the individual machines in the system\nand transmitted to a central controller in batches. Each batch is processed by\nan adaptive data-reduction algorithm based on Fourier transforms and truncation\nin the frequency domain. We show that the proposed mechanism leads to a\nsignificant reduction in communication overhead while incurring only minimal\nerror and adhering to accuracy guarantees. To address the second challenge, we\npropose a deep learning architecture using complex Gated Recurrent Units to\nforecast resource utilisation. This architecture is directly integrated with\nthe above data collection mechanism to improve inference speed of our\nforecasting model. Using two real-world datasets, we demonstrate the\neffectiveness of our approach, both in terms of forecasting accuracy and\ninference speed. Our approach resolves challenges encountered in resource\nprovisioning frameworks and can be applied to other forecasting problems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:31:33 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 15:58:24 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 14:51:19 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Pritz", "Paul J.", ""], ["Perez", "Daniel", ""], ["Leung", "Kin K.", ""]]}, {"id": "2001.04286", "submitter": "Maani Ghaffari Jadidi", "authors": "William Clark, Maani Ghaffari, and Anthony Bloch", "title": "Nonparametric Continuous Sensor Registration", "comments": "46 pages. arXiv admin note: substantial text overlap with\n  arXiv:1904.02266", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a new mathematical framework that enables nonparametric\njoint semantic and geometric representation of continuous functions using data.\nThe joint embedding is modeled by representing the processes in a reproducing\nkernel Hilbert space. The functions can be defined on arbitrary smooth\nmanifolds where the action of a Lie group aligns them. The continuous functions\nallow the registration to be independent of a specific signal resolution. The\nframework is fully analytical with a closed-form derivation of the Riemannian\ngradient and Hessian. We study a more specialized but widely used case where\nthe Lie group acts on functions isometrically. We solve the problem by\nmaximizing the inner product between two functions defined over data, while the\ncontinuous action of the rigid body motion Lie group is captured through the\nintegration of the flow in the corresponding Lie algebra. Low-dimensional cases\nare derived with numerical examples to show the generality of the proposed\nframework. The high-dimensional derivation for the special Euclidean group\nacting on the Euclidean space showcases the point cloud registration and\nbird's-eye view map registration abilities. An implementation of this framework\nfor RGB-D cameras outperform the state-of-the-art robust visual odometry and\nperforms well in texture and structure-scares environments.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:40:54 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 20:23:50 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 06:05:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Clark", "William", ""], ["Ghaffari", "Maani", ""], ["Bloch", "Anthony", ""]]}, {"id": "2001.04292", "submitter": "WaiChing Sun", "authors": "Nikolaos Vlassis, Ran Ma, WaiChing Sun", "title": "Geometric deep learning for computational mechanics Part I: Anisotropic\n  Hyperelasticity", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113299", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is the first attempt to use geometric deep learning and Sobolev\ntraining to incorporate non-Euclidean microstructural data such that\nanisotropic hyperelastic material machine learning models can be trained in the\nfinite deformation range. While traditional hyperelasticity models often\nincorporate homogenized measures of microstructural attributes, such as\nporosity averaged orientation of constitutes, these measures cannot reflect the\ntopological structures of the attributes. We fill this knowledge gap by\nintroducing the concept of weighted graph as a new mean to store topological\ninformation, such as the connectivity of anisotropic grains in assembles. Then,\nby leveraging a graph convolutional deep neural network architecture in the\nspectral domain, we introduce a mechanism to incorporate these non-Euclidean\nweighted graph data directly as input for training and for predicting the\nelastic responses of materials with complex microstructures. To ensure\nsmoothness and prevent non-convexity of the trained stored energy functional,\nwe introduce a Sobolev training technique for neural networks such that stress\nmeasure is obtained implicitly from taking directional derivatives of the\ntrained energy functional. By optimizing the neural network to approximate both\nthe energy functional output and the stress measure, we introduce a training\nprocedure the improves efficiency and generalize the learned energy functional\nfor different microstructures. The trained hybrid neural network model is then\nused to generate new stored energy functional for unseen microstructures in a\nparametric study to predict the influence of elastic anisotropy on the\nnucleation and propagation of fracture in the brittle regime.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 02:07:39 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Vlassis", "Nikolaos", ""], ["Ma", "Ran", ""], ["Sun", "WaiChing", ""]]}, {"id": "2001.04294", "submitter": "Giuseppe Visconti", "authors": "M. Herty, T. Trimborn, G. Visconti", "title": "Kinetic Theory for Residual Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual neural networks are performing very well for many data science\napplications. We use kinetic theory to improve understanding of existing\nmethods. A simplified residual neural network (SimResNet) model, in which each\nlayer consists of one neuron per input dimension at most, is studied in the\nlimit of infinitely many inputs. This leads to a Vlasov type equation for the\ndistribution of data, and we analyze it with respect to sensitivities and\nsteady states. In the simple case of a linear activation function we can study\nmoment model properties for one-dimensional input data. Further, a modification\nof the microscopic dynamics leads to a Fokker-Planck type formulation of the\nSimResNet, in which the concept of network training is replaced by the task of\nfitting distributions. The performed analysis is validated by numerical\nsimulations. In particular, results on clustering and regression problems are\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 13:41:27 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 16:41:20 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 10:13:05 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Herty", "M.", ""], ["Trimborn", "T.", ""], ["Visconti", "G.", ""]]}, {"id": "2001.04297", "submitter": "John Just", "authors": "John Just", "title": "Granular Learning with Deep Generative Models using Highly Contaminated\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to utilize recent advances in deep generative models for anomaly\ndetection in a granular (continuous) sense on a real-world image dataset with\nquality issues is detailed using recent normalizing flow models, with\nimplications in many other applications/domains/data types. The approach is\ncompletely unsupervised (no annotations available) but qualitatively shown to\nprovide accurate semantic labeling for images via heatmaps of the scaled\nlog-likelihood overlaid on the images. When sorted based on the median values\nper image, clear trends in quality are observed. Furthermore, downstream\nclassification is shown to be possible and effective via a weakly supervised\napproach using the log-likelihood output from a normalizing flow model as a\ntraining signal for a feature-extracting convolutional neural network. The\npre-linear dense layer outputs on the CNN are shown to disentangle high level\nrepresentations and efficiently cluster various quality issues. Thus, an\nentirely non-annotated (fully unsupervised) approach is shown possible for\naccurate estimation and classification of quality issues..\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 23:22:17 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Just", "John", ""]]}, {"id": "2001.04298", "submitter": "Han Bao", "authors": "Han Bao, Nam Dinh, Linyu Lin, Robert Youngblood, Jeffrey Lane, Hongbin\n  Zhang", "title": "Using Deep Learning to Explore Local Physical Similarity for\n  Global-scale Bridging in Thermal-hydraulic Simulation", "comments": "24 pages, 10 tables, 12 figures. This manuscript has been submitted\n  to Annuals of Nuclear Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current system thermal-hydraulic codes have limited credibility in simulating\nreal plant conditions, especially when the geometry and boundary conditions are\nextrapolated beyond the range of test facilities. This paper proposes a\ndata-driven approach, Feature Similarity Measurement FFSM), to establish a\ntechnical basis to overcome these difficulties by exploring local patterns\nusing machine learning. The underlying local patterns in multiscale data are\nrepresented by a set of physical features that embody the information from a\nphysical system of interest, empirical correlations, and the effect of mesh\nsize. After performing a limited number of high-fidelity numerical simulations\nand a sufficient amount of fast-running coarse-mesh simulations, an error\ndatabase is built, and deep learning is applied to construct and explore the\nrelationship between the local physical features and simulation errors. Case\nstudies based on mixed convection have been designed for demonstrating the\ncapability of data-driven models in bridging global scale gaps.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 20:14:46 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bao", "Han", ""], ["Dinh", "Nam", ""], ["Lin", "Linyu", ""], ["Youngblood", "Robert", ""], ["Lane", "Jeffrey", ""], ["Zhang", "Hongbin", ""]]}, {"id": "2001.04321", "submitter": "Man Shun Ang", "authors": "Andersen Man Shun Ang, Jeremy E. Cohen, Nicolas Gillis, Le Thi Khanh\n  Hien", "title": "Accelerating Block Coordinate Descent for Nonnegative Tensor\n  Factorization", "comments": "32 pages, 24 figures", "journal-ref": "Numerical Linear Algebra with Applications, e2373, 2021", "doi": "10.1002/nla.2373", "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with improving the empirical convergence speed of\nblock-coordinate descent algorithms for approximate nonnegative tensor\nfactorization (NTF). We propose an extrapolation strategy in-between block\nupdates, referred to as heuristic extrapolation with restarts (HER). HER\nsignificantly accelerates the empirical convergence speed of most existing\nblock-coordinate algorithms for dense NTF, in particular for challenging\ncomputational scenarios, while requiring a negligible additional computational\nbudget.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:59:03 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 11:54:54 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ang", "Andersen Man Shun", ""], ["Cohen", "Jeremy E.", ""], ["Gillis", "Nicolas", ""], ["Hien", "Le Thi Khanh", ""]]}, {"id": "2001.04341", "submitter": "Yifei Wang", "authors": "Yifei Wang and Wuchen Li", "title": "Information Newton's flow: second-order optimization method in\n  probability space", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for Newton's flows in probability space with\ninformation metrics, named information Newton's flows. Here two information\nmetrics are considered, including both the Fisher-Rao metric and the\nWasserstein-2 metric. A known fact is that overdamped Langevin dynamics\ncorrespond to Wasserstein gradient flows of Kullback-Leibler (KL) divergence.\nExtending this fact to Wasserstein Newton's flows, we derive Newton's Langevin\ndynamics. We provide examples of Newton's Langevin dynamics in both\none-dimensional space and Gaussian families. For the numerical implementation,\nwe design sampling efficient variational methods in affine models and\nreproducing kernel Hilbert space (RKHS) to approximate Wasserstein Newton's\ndirections. We also establish convergence results of the proposed information\nNewton's method with approximated directions. Several numerical examples from\nBayesian sampling problems are shown to demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:33:46 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 07:24:31 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 15:03:54 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 01:28:44 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Wang", "Yifei", ""], ["Li", "Wuchen", ""]]}, {"id": "2001.04344", "submitter": "Olfa Nasraoui", "authors": "Pegah Sagheb Haghighi, Olurotimi Seton, Olfa Nasraoui", "title": "An Explainable Autoencoder For Collaborative Filtering Recommendation", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are a common building block of Deep Learning architectures,\nwhere they are mainly used for representation learning. They have also been\nsuccessfully used in Collaborative Filtering (CF) recommender systems to\npredict missing ratings. Unfortunately, like all black box machine learning\nmodels, they are unable to explain their outputs. Hence, while predictions from\nan Autoencoder-based recommender system might be accurate, it might not be\nclear to the user why a recommendation was generated. In this work, we design\nan explainable recommendation system using an Autoencoder model whose\npredictions can be explained using the neighborhood based explanation style.\nOur preliminary work can be considered to be the first step towards an\nexplainable deep learning architecture based on Autoencoders.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 23:55:30 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Haghighi", "Pegah Sagheb", ""], ["Seton", "Olurotimi", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2001.04345", "submitter": "Mukul Kumar", "authors": "Mukul Kumar, Youna Hu, Will Headden, Rahul Goutam, Heran Lin, Bing Yin", "title": "Shareable Representations for Search Query Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding search queries is critical for shopping search engines to\ndeliver a satisfying customer experience. Popular shopping search engines\nreceive billions of unique queries yearly, each of which can depict any of\nhundreds of user preferences or intents. In order to get the right results to\ncustomers it must be known queries like \"inexpensive prom dresses\" are intended\nto not only surface results of a certain product type but also products with a\nlow price. Referred to as query intents, examples also include preferences for\nauthor, brand, age group, or simply a need for customer service. Recent works\nsuch as BERT have demonstrated the success of a large transformer encoder\narchitecture with language model pre-training on a variety of NLP tasks. We\nadapt such an architecture to learn intents for search queries and describe\nmethods to account for the noisiness and sparseness of search query data. We\nalso describe cost effective ways of hosting transformer encoder models in\ncontext with low latency requirements. With the right domain-specific training\nwe can build a shareable deep learning model whose internal representation can\nbe reused for a variety of query understanding tasks including query intent\nidentification. Model sharing allows for fewer large models needed to be served\nat inference time and provides a platform to quickly build and roll out new\nsearch query classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 22:12:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Kumar", "Mukul", ""], ["Hu", "Youna", ""], ["Headden", "Will", ""], ["Goutam", "Rahul", ""], ["Lin", "Heran", ""], ["Yin", "Bing", ""]]}, {"id": "2001.04349", "submitter": "Angshul Majumdar Dr.", "authors": "Anupriya Gogna and Angshul Majumdar", "title": "Balancing Accuracy and Diversity in Recommendations using Matrix\n  Completion Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of recommender systems aimed at achieving high prediction accuracy is\na widely researched area. However, several studies have suggested the need for\ndiversified recommendations, with acceptable level of accuracy, to avoid\nmonotony and improve customers experience. However, increasing diversity comes\nwith an associated reduction in recommendation accuracy; thereby necessitating\nan optimum tradeoff between the two. In this work, we attempt to achieve\naccuracy vs diversity balance, by exploiting available ratings and item\nmetadata, through a single, joint optimization model built over the matrix\ncompletion framework. Most existing works, unlike our formulation, propose a 2\nstage model, a heuristic item ranking scheme on top of an existing\ncollaborative filtering technique. Experimental evaluation on a movie\nrecommender system indicates that our model achieves higher diversity for a\ngiven drop in accuracy as compared to existing state of the art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 11:07:13 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Gogna", "Anupriya", ""], ["Majumdar", "Angshul", ""]]}, {"id": "2001.04351", "submitter": "Liang  Xu", "authors": "Liang Xu, Yu tong, Qianqian Dong, Yixuan Liao, Cong Yu, Yin Tian,\n  Weitang Liu, Lu Li, Caiquan Liu, Xuanwei Zhang", "title": "CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark\n  for Chinese", "comments": "6 pages, 5 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the NER dataset from CLUE organization\n(CLUENER2020), a well-defined fine-grained dataset for named entity recognition\nin Chinese. CLUENER2020 contains 10 categories. Apart from common labels like\nperson, organization, and location, it contains more diverse categories. It is\nmore challenging than current other Chinese NER datasets and could better\nreflect real-world applications. For comparison, we implement several\nstate-of-the-art baselines as sequence labeling tasks and report human\nperformance, as well as its analysis. To facilitate future work on fine-grained\nNER for Chinese, we release our dataset, baselines, and leader-board.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:39:56 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 19:06:49 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 16:18:16 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 16:32:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xu", "Liang", ""], ["tong", "Yu", ""], ["Dong", "Qianqian", ""], ["Liao", "Yixuan", ""], ["Yu", "Cong", ""], ["Tian", "Yin", ""], ["Liu", "Weitang", ""], ["Li", "Lu", ""], ["Liu", "Caiquan", ""], ["Zhang", "Xuanwei", ""]]}, {"id": "2001.04362", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Source Domain Adaptation for Text Classification via\n  DistanceNet-Bandits", "comments": "AAAI 2020 (10 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation performance of a learning algorithm on a target domain is a\nfunction of its source domain error and a divergence measure between the data\ndistribution of these two domains. We present a study of various distance-based\nmeasures in the context of NLP tasks, that characterize the dissimilarity\nbetween domains based on sample estimates. We first conduct analysis\nexperiments to show which of these distance measures can best differentiate\nsamples from same versus different domains, and are correlated with empirical\nresults. Next, we develop a DistanceNet model which uses these distance\nmeasures, or a mixture of these distance measures, as an additional loss\nfunction to be minimized jointly with the task's loss function, so as to\nachieve better unsupervised domain adaptation. Finally, we extend this model to\na novel DistanceNet-Bandit model, which employs a multi-armed bandit controller\nto dynamically switch between multiple source domains and allow the model to\nlearn an optimal trajectory and mixture of domains for transfer to the\nlow-resource target domain. We conduct experiments on popular sentiment\nanalysis datasets with several diverse domains and show that our DistanceNet\nmodel, as well as its dynamic bandit variant, can outperform competitive\nbaselines in the context of unsupervised domain adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:53:41 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 17:01:49 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 21:21:22 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.04385", "submitter": "Christopher Rackauckas", "authors": "Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner,\n  Kirill Zubov, Rohit Supekar, Dominic Skinner, Ali Ramadhan, Alan Edelman", "title": "Universal Differential Equations for Scientific Machine Learning", "comments": "3 figures, 2 tables, 3 supplemental figures, 27 pages, 18\n  supplemental pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of science, the well-known adage \"a picture is worth a\nthousand words\" might well be \"a model is worth a thousand datasets.\"\nScientific models, such as Newtonian physics or biological gene regulatory\nnetworks, are human-driven simplifications of complex phenomena that serve as\nsurrogates for the countless experiments that validated the models. Recently,\nmachine learning has been able to overcome the inaccuracies of approximate\nmodeling by directly learning the entire set of nonlinear interactions from\ndata. However, without any predetermined structure from the scientific basis\nbehind the problem, machine learning approaches are flexible but\ndata-expensive, requiring large databases of homogeneous labeled training data.\nA central challenge is reconciling data that is at odds with simplified models\nwithout requiring \"big data\".\n  In this work we develop a new methodology, universal differential equations\n(UDEs), which augments scientific models with machine-learnable structures for\nscientifically-based learning. We show how UDEs can be utilized to discover\npreviously unknown governing equations, accurately extrapolate beyond the\noriginal data, and accelerate model simulation, all in a time and\ndata-efficient manner. This advance is coupled with open-source software that\nallows for training UDEs which incorporate physical constraints, delayed\ninteractions, implicitly-defined events, and intrinsic stochasticity in the\nmodel. Our examples show how a diverse set of computationally-difficult\nmodeling issues across scientific disciplines, from automatically discovering\nbiological mechanisms to accelerating the training of physics-informed neural\nnetworks and large-eddy simulations, can all be transformed into UDE training\nproblems that are efficiently solved by a single software methodology.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 16:40:35 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 00:09:47 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 00:19:42 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Rackauckas", "Christopher", ""], ["Ma", "Yingbo", ""], ["Martensen", "Julius", ""], ["Warner", "Collin", ""], ["Zubov", "Kirill", ""], ["Supekar", "Rohit", ""], ["Skinner", "Dominic", ""], ["Ramadhan", "Ali", ""], ["Edelman", "Alan", ""]]}, {"id": "2001.04409", "submitter": "Natalia Ares", "authors": "N.M. van Esbroeck, D.T. Lennon, H. Moon, V. Nguyen, F. Vigneau, L.C.\n  Camenzind, L. Yu, D.M. Zumb\\\"uhl, G.A.D. Briggs, D. Sejdinovic, and N. Ares", "title": "Quantum device fine-tuning using unsupervised embedding learning", "comments": null, "journal-ref": null, "doi": "10.1088/1367-2630/abb64c", "report-no": null, "categories": "cond-mat.mes-hall cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum devices with a large number of gate electrodes allow for precise\ncontrol of device parameters. This capability is hard to fully exploit due to\nthe complex dependence of these parameters on applied gate voltages. We\nexperimentally demonstrate an algorithm capable of fine-tuning several device\nparameters at once. The algorithm acquires a measurement and assigns it a score\nusing a variational auto-encoder. Gate voltage settings are set to optimise\nthis score in real-time in an unsupervised fashion. We report fine-tuning times\nof a double quantum dot device within approximately 40 min.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:18:54 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["van Esbroeck", "N. M.", ""], ["Lennon", "D. T.", ""], ["Moon", "H.", ""], ["Nguyen", "V.", ""], ["Vigneau", "F.", ""], ["Camenzind", "L. C.", ""], ["Yu", "L.", ""], ["Zumb\u00fchl", "D. M.", ""], ["Briggs", "G. A. D.", ""], ["Sejdinovic", "D.", ""], ["Ares", "N.", ""]]}, {"id": "2001.04413", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Backward Feature Correction: How Deep Learning Performs Deep Learning", "comments": "V2 adds more experiments, V3 polishes writing and improves\n  experiments, V4 makes minor fixes to the figures, V5 polishes writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does a 110-layer ResNet learn a high-complexity classifier using\nrelatively few training examples and short training time? We present a theory\ntowards explaining this in terms of Hierarchical Learning. We refer\nhierarchical learning as the learner learns to represent a complicated target\nfunction by decomposing it into a sequence of simpler functions to reduce\nsample and time complexity. We formally analyze how multi-layer neural networks\ncan perform such hierarchical learning efficiently and automatically by\napplying SGD.\n  On the conceptual side, we present, to the best of our knowledge, the FIRST\ntheory result indicating how deep neural networks can still be sample and time\nefficient using SGD on certain hierarchical learning tasks, when NO KNOWN\nexisting algorithm is efficient. We establish a new principle called \"backward\nfeature correction\", where training higher-level layers in the network can\nimprove the features of lower-level ones. We believe this is the key to\nunderstand the deep learning process in multi-layer neural networks.\n  On the technical side, we show for regression and even binary classification,\nfor every input dimension $d>0$, there is a concept class of degree $\\omega(1)$\npolynomials so that, using $\\omega(1)$-layer neural networks as learners, SGD\ncan learn any function from this class in $\\mathsf{poly}(d)$ time and sample\ncomplexity to any $\\frac{1}{\\mathsf{poly}(d)}$ error, through learning to\nrepresent it as a composition of $\\omega(1)$ layers of quadratic functions. In\ncontrast, we do not know any other simple algorithm (including layer-wise\ntraining or applying kernel method sequentially) that can learn this concept\nclass in $\\mathsf{poly}(d)$ time even to any $d^{-0.01}$ error. As a side\nresult, we prove $d^{\\omega(1)}$ lower bounds for several non-hierarchical\nlearners, including any kernel methods, neural tangent or neural compositional\nkernels.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:28:29 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:47:15 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 03:28:52 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 17:48:37 GMT"}, {"version": "v5", "created": "Sat, 13 Mar 2021 12:05:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2001.04417", "submitter": "Florian Seiffarth", "authors": "Florian Seiffarth, Tamas Horvath and Stefan Wrobel", "title": "Maximal Closed Set and Half-Space Separations in Finite Closure Systems", "comments": "An early version of this paper was presented at ECML/PKDD 2019 and\n  has appeared in the Lecture Notes in Computer Science, Machine Learning and\n  Knowledge Discovery in Databases - European Conference, ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several problems of artificial intelligence, such as predictive learning,\nformal concept analysis or inductive logic programming, can be viewed as a\nspecial case of half-space separation in abstract closure systems over finite\nground sets. For the typical scenario that the closure system is given via a\nclosure operator, we show that the half-space separation problem is\nNP-complete. As a first approach to overcome this negative result, we relax the\nproblem to maximal closed set separation, give a greedy algorithm solving this\nproblem with a linear number of closure operator calls, and show that this\nbound is sharp. For a second direction, we consider Kakutani closure systems\nand prove that they are algorithmically characterized by the greedy algorithm.\nAs a first special case of the general problem setting, we consider Kakutani\nclosure systems over graphs, generalize a fundamental characterization result\nbased on the Pasch axiom to graph structured partitioning of finite sets, and\ngive a sufficient condition for this kind of closures systems in terms of graph\nminors. For a second case, we then focus on closure systems over finite\nlattices, give an improved adaptation of the greedy algorithm for this special\ncase, and present two applications concerning formal concept and subsumption\nlattices. We also report some experimental results to demonstrate the practical\nusefulness of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:34:47 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 10:06:19 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Seiffarth", "Florian", ""], ["Horvath", "Tamas", ""], ["Wrobel", "Stefan", ""]]}, {"id": "2001.04437", "submitter": "Vlad Niculae", "authors": "Vlad Niculae, Andr\\'e F. T. Martins", "title": "LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured\n  Prediction", "comments": "34 pages, 5 tables, 4 figures. ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction requires manipulating a large number of combinatorial\nstructures, e.g., dependency trees or alignments, either as latent or output\nvariables. Recently, the SparseMAP method has been proposed as a\ndifferentiable, sparse alternative to maximum a posteriori (MAP) and marginal\ninference. SparseMAP returns a combination of a small number of structures, a\ndesirable property in some downstream applications. However, SparseMAP requires\na tractable MAP inference oracle. This excludes, e.g., loopy graphical models\nor factor graphs with logic constraints, which generally require approximate\ninference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP\nthat addresses this limitation via a local polytope relaxation. LP-SparseMAP\nuses the flexible and powerful domain specific language of factor graphs for\ndefining and backpropagating through arbitrary hidden structure, supporting\ncoarse decompositions, hard logic constraints, and higher-order correlations.\nWe derive the forward and backward algorithms needed for using LP-SparseMAP as\na hidden or output layer. Experiments in three structured prediction tasks show\nbenefits compared to SparseMAP and Structured SVM.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:16:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:05:12 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 15:36:49 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Niculae", "Vlad", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "2001.04438", "submitter": "Marat Dukhan", "authors": "Marat Dukhan and Artsiom Ablavatski", "title": "The Two-Pass Softmax Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The softmax (also called softargmax) function is widely used in machine\nlearning models to normalize real-valued scores into a probability\ndistribution. To avoid floating-point overflow, the softmax function is\nconventionally implemented in three passes: the first pass to compute the\nnormalization constant, and two other passes to compute outputs from normalized\ninputs. We analyze two variants of the Three-Pass algorithm and demonstrate\nthat in a well-optimized implementation on HPC-class processors performance of\nall three passes is limited by memory bandwidth. We then present a novel\nalgorithm for softmax computation in just two passes. The proposed Two-Pass\nalgorithm avoids both numerical overflow and the extra normalization pass by\nemploying an exotic representation for intermediate values, where each value is\nrepresented as a pair of floating-point numbers: one representing the\n\"mantissa\" and another representing the \"exponent\". Performance evaluation\ndemonstrates that on out-of-cache inputs on an Intel Skylake-X processor the\nnew Two-Pass algorithm outperforms the traditional Three-Pass algorithm by up\nto 28% in AVX512 implementation, and by up to 18% in AVX2 implementation. The\nproposed Two-Pass algorithm also outperforms the traditional Three-Pass\nalgorithm on Intel Broadwell and AMD Zen 2 processors. To foster\nreproducibility, we released an open-source implementation of the new Two-Pass\nSoftmax algorithm and other experiments in this paper as a part of XNNPACK\nlibrary at GitHub.com/google/XNNPACK.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:17:57 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Dukhan", "Marat", ""], ["Ablavatski", "Artsiom", ""]]}, {"id": "2001.04451", "submitter": "Nikita Kitaev", "authors": "Nikita Kitaev, {\\L}ukasz Kaiser, Anselm Levskaya", "title": "Reformer: The Efficient Transformer", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer models routinely achieve state-of-the-art results on a\nnumber of tasks but training these models can be prohibitively costly,\nespecially on long sequences. We introduce two techniques to improve the\nefficiency of Transformers. For one, we replace dot-product attention by one\nthat uses locality-sensitive hashing, changing its complexity from O($L^2$) to\nO($L\\log L$), where $L$ is the length of the sequence. Furthermore, we use\nreversible residual layers instead of the standard residuals, which allows\nstoring activations only once in the training process instead of $N$ times,\nwhere $N$ is the number of layers. The resulting model, the Reformer, performs\non par with Transformer models while being much more memory-efficient and much\nfaster on long sequences.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:38:28 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:01:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kitaev", "Nikita", ""], ["Kaiser", "\u0141ukasz", ""], ["Levskaya", "Anselm", ""]]}, {"id": "2001.04463", "submitter": "Kangle Deng", "authors": "Kangle Deng and Aayush Bansal and Deva Ramanan", "title": "Unsupervised Audiovisual Synthesis via Exemplar Autoencoders", "comments": "ICLR 2021; Project page -- https://www.cs.cmu.edu/~exemplar-ae/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an unsupervised approach that converts the input speech of any\nindividual into audiovisual streams of potentially-infinitely many output\nspeakers. Our approach builds on simple autoencoders that project out-of-sample\ndata onto the distribution of the training set. We use Exemplar Autoencoders to\nlearn the voice, stylistic prosody, and visual appearance of a specific target\nexemplar speech. In contrast to existing methods, the proposed approach can be\neasily extended to an arbitrarily large number of speakers and styles using\nonly 3 minutes of target audio-video data, without requiring {\\em any} training\ndata for the input speaker. To do so, we learn audiovisual bottleneck\nrepresentations that capture the structured linguistic content of speech. We\noutperform prior approaches on both audio and video synthesis, and provide\nextensive qualitative analysis on our project page --\nhttps://www.cs.cmu.edu/~exemplar-ae/.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:56:45 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 17:59:14 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 05:24:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Deng", "Kangle", ""], ["Bansal", "Aayush", ""], ["Ramanan", "Deva", ""]]}, {"id": "2001.04465", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Dexter R.R. Scobee, Jaime F. Fisac, S. Shankar Sastry,\n  Anca D. Dragan", "title": "LESS is More: Rethinking Probabilistic Models of Human Behavior", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1145/3319502.3374811", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots need models of human behavior for both inferring human goals and\npreferences, and predicting what people will do. A common model is the\nBoltzmann noisily-rational decision model, which assumes people approximately\noptimize a reward function and choose trajectories in proportion to their\nexponentiated reward. While this model has been successful in a variety of\nrobotics domains, its roots lie in econometrics, and in modeling decisions\namong different discrete options, each with its own utility or reward. In\ncontrast, human trajectories lie in a continuous space, with continuous-valued\nfeatures that influence the reward function. We propose that it is time to\nrethink the Boltzmann model, and design it from the ground up to operate over\nsuch trajectory spaces. We introduce a model that explicitly accounts for\ndistances between trajectories, rather than only their rewards. Rather than\neach trajectory affecting the decision independently, similar trajectories now\naffect the decision together. We start by showing that our model better\nexplains human behavior in a user study. We then analyze the implications this\nhas for robot inference, first in toy environments where we have ground truth\nand find more accurate inference, and finally for a 7DOF robot arm learning\nfrom user demonstrations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:59:01 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Bobu", "Andreea", ""], ["Scobee", "Dexter R. R.", ""], ["Fisac", "Jaime F.", ""], ["Sastry", "S. Shankar", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2001.04484", "submitter": "Luca Papariello", "authors": "Luca Papariello, Alexandros Bampoulidis, Mihai Lupu", "title": "On the Replicability of Combining Word Embeddings and Retrieval Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We replicate recent experiments attempting to demonstrate an attractive\nhypothesis about the use of the Fisher kernel framework and mixture models for\naggregating word embeddings towards document representations and the use of\nthese representations in document classification, clustering, and retrieval.\nSpecifically, the hypothesis was that the use of a mixture model of von\nMises-Fisher (VMF) distributions instead of Gaussian distributions would be\nbeneficial because of the focus on cosine distances of both VMF and the vector\nspace model traditionally used in information retrieval. Previous experiments\nhad validated this hypothesis. Our replication was not able to validate it,\ndespite a large parameter scan space.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:01:07 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Papariello", "Luca", ""], ["Bampoulidis", "Alexandros", ""], ["Lupu", "Mihai", ""]]}, {"id": "2001.04488", "submitter": "Pak Lun Kevin Ding", "authors": "Pak Lun Kevin Ding, Zhiqiang Li, Yuxiang Zhou, Baoxin Li", "title": "Deep Residual Dense U-Net for Resolution Enhancement in Accelerated MRI\n  Acquisition", "comments": "SPIE Medical Imaging 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical Magnetic Resonance Imaging (MRI) scan may take 20 to 60 minutes.\nReducing MRI scan time is beneficial for both patient experience and cost\nconsiderations. Accelerated MRI scan may be achieved by acquiring less amount\nof k-space data (down-sampling in the k-space). However, this leads to lower\nresolution and aliasing artifacts for the reconstructed images. There are many\nexisting approaches for attempting to reconstruct high-quality images from\ndown-sampled k-space data, with varying complexity and performance. In recent\nyears, deep-learning approaches have been proposed for this task, and promising\nresults have been reported. Still, the problem remains challenging especially\nbecause of the high fidelity requirement in most medical applications employing\nreconstructed MRI images. In this work, we propose a deep-learning approach,\naiming at reconstructing high-quality images from accelerated MRI acquisition.\nSpecifically, we use Convolutional Neural Network (CNN) to learn the\ndifferences between the aliased images and the original images, employing a\nU-Net-like architecture. Further, a micro-architecture termed Residual Dense\nBlock (RDB) is introduced for learning a better feature representation than the\nplain U-Net. Considering the peculiarity of the down-sampled k-space data, we\nintroduce a new term to the loss function in learning, which effectively\nemploys the given k-space data during training to provide additional\nregularization on the update of the network weights. To evaluate the proposed\napproach, we compare it with other state-of-the-art methods. In both visual\ninspection and evaluation using standard metrics, the proposed approach is able\nto deliver improved performance, demonstrating its potential for providing an\neffective solution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:01:17 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Ding", "Pak Lun Kevin", ""], ["Li", "Zhiqiang", ""], ["Zhou", "Yuxiang", ""], ["Li", "Baoxin", ""]]}, {"id": "2001.04508", "submitter": "Jones Yirui Liu", "authors": "Jones Yirui Liu and Xinghao Qiao", "title": "Conditional Variational Inference with Adaptive Truncation for Bayesian\n  Nonparametric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scalable inference for Bayesian nonparametric models with big data is\nstill challenging. Current variational inference methods fail to characterise\nthe correlation structure among latent variables due to the mean-field setting\nand cannot infer the true posterior dimension because of the universal\ntruncation. To overcome these limitations, we build a general framework to\ninfer Bayesian nonparametric models by maximising the proposed nonparametric\nevidence lower bound, and then develop a novel approach by combining Monte\nCarlo sampling and stochastic variational inference framework. Our method has\nseveral advantages over the traditional online variational inference method.\nFirst, it achieves a smaller divergence between variational distributions and\nthe true posterior by factorising variational distributions under the\nconditional setting instead of the mean-field setting to capture the\ncorrelation pattern. Second, it reduces the risk of underfitting or overfitting\nby truncating the dimension adaptively rather than using a prespecified\ntruncated dimension for all latent variables. Third, it reduces the\ncomputational complexity by approximating the posterior functionally instead of\nupdating the stick-breaking parameters individually. We apply the proposed\nmethod on hierarchical Dirichlet process and gamma--Dirichlet process models,\ntwo essential Bayesian nonparametric models in topic analysis. The empirical\nstudy on three large datasets including arXiv, New York Times and Wikipedia\nreveals that our proposed method substantially outperforms its competitor in\nterms of lower perplexity and much clearer topic-words clustering.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:27:11 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Liu", "Jones Yirui", ""], ["Qiao", "Xinghao", ""]]}, {"id": "2001.04515", "submitter": "Chengchun Shi", "authors": "C. Shi, S. Zhang, W. Lu and R. Song", "title": "Statistical Inference of the Value Function for Reinforcement Learning\n  in Infinite Horizon Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a general technique that allows an agent to learn\nan optimal policy and interact with an environment in sequential decision\nmaking problems. The goodness of a policy is measured by its value function\nstarting from some initial state. The focus of this paper is to construct\nconfidence intervals (CIs) for a policy's value in infinite horizon settings\nwhere the number of decision points diverges to infinity. We propose to model\nthe action-value state function (Q-function) associated with a policy based on\nseries/sieve method to derive its confidence interval. When the target policy\ndepends on the observed data as well, we propose a SequentiAl Value Evaluation\n(SAVE) method to recursively update the estimated policy and its value\nestimator. As long as either the number of trajectories or the number of\ndecision points diverges to infinity, we show that the proposed CI achieves\nnominal coverage even in cases where the optimal policy is not unique.\nSimulation studies are conducted to back up our theoretical findings. We apply\nthe proposed method to a dataset from mobile health studies and find that\nreinforcement learning algorithms could help improve patient's health status. A\nPython implementation of the proposed procedure is available at\nhttps://github.com/shengzhang37/SAVE.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:42:40 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 20:28:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Shi", "C.", ""], ["Zhang", "S.", ""], ["Lu", "W.", ""], ["Song", "R.", ""]]}, {"id": "2001.04527", "submitter": "Abhay Rawat", "authors": "Abhay Rawat, Kamalakar Karlapalem", "title": "Multi-Robot Formation Control Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a machine learning approach to move a group of\nrobots in a formation. We model the problem as a multi-agent reinforcement\nlearning problem. Our aim is to design a control policy for maintaining a\ndesired formation among a number of agents (robots) while moving towards a\ndesired goal. This is achieved by training our agents to track two agents of\nthe group and maintain the formation with respect to those agents. We consider\nall agents to be homogeneous and model them as unicycle [1]. In contrast to the\nleader-follower approach, where each agent has an independent goal, our\napproach aims to train the agents to be cooperative and work towards the common\ngoal. Our motivation to use this method is to make a fully decentralized\nmulti-agent formation system and scalable for a number of agents.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 20:53:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Rawat", "Abhay", ""], ["Karlapalem", "Kamalakar", ""]]}, {"id": "2001.04528", "submitter": "Jorge Alberto Gutierrez Ortega", "authors": "Jorge Gutierrez, Julien Rabin, Bruno Galerne, Thomas Hurtut", "title": "On Demand Solid Texture Synthesis Using Deep 3D Networks", "comments": null, "journal-ref": null, "doi": "10.1111/cgf.13889", "report-no": null, "categories": "cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a novel approach for on demand volumetric texture\nsynthesis based on a deep learning framework that allows for the generation of\nhigh quality 3D data at interactive rates. Based on a few example images of\ntextures, a generative network is trained to synthesize coherent portions of\nsolid textures of arbitrary sizes that reproduce the visual characteristics of\nthe examples along some directions. To cope with memory limitations and\ncomputation complexity that are inherent to both high resolution and 3D\nprocessing on the GPU, only 2D textures referred to as \"slices\" are generated\nduring the training stage. These synthetic textures are compared to exemplar\nimages via a perceptual loss function based on a pre-trained deep network. The\nproposed network is very light (less than 100k parameters), therefore it only\nrequires sustainable training (i.e. few hours) and is capable of very fast\ngeneration (around a second for $256^3$ voxels) on a single GPU. Integrated\nwith a spatially seeded PRNG the proposed generator network directly returns an\nRGB value given a set of 3D coordinates. The synthesized volumes have good\nvisual results that are at least equivalent to the state-of-the-art patch based\napproaches. They are naturally seamlessly tileable and can be fully generated\nin parallel.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 20:59:14 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Gutierrez", "Jorge", ""], ["Rabin", "Julien", ""], ["Galerne", "Bruno", ""], ["Hurtut", "Thomas", ""]]}, {"id": "2001.04533", "submitter": "Arun Sathanur", "authors": "Kelsey Maass, Arun V Sathanur, Arif Khan, Robert Rallo", "title": "Street-level Travel-time Estimation via Aggregated Uber Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating temporal patterns in travel times along road segments in urban\nsettings is of central importance to traffic engineers and city planners. In\nthis work, we propose a methodology to leverage coarse-grained and aggregated\ntravel time data to estimate the street-level travel times of a given\nmetropolitan area. Our main focus is to estimate travel times along the\narterial road segments where relevant data are often unavailable. The central\nidea of our approach is to leverage easy-to-obtain, aggregated data sets with\nbroad spatial coverage, such as the data published by Uber Movement, as the\nfabric over which other expensive, fine-grained datasets, such as loop counter\nand probe data, can be overlaid. Our proposed methodology uses a graph\nrepresentation of the road network and combines several techniques such as\ngraph-based routing, trip sampling, graph sparsification, and least-squares\noptimization to estimate the street-level travel times. Using sampled trips and\nweighted shortest-path routing, we iteratively solve constrained least-squares\nproblems to obtain the travel time estimates. We demonstrate our method on the\nLos Angeles metropolitan-area street network, where aggregated travel time data\nis available for trips between traffic analysis zones. Additionally, we present\ntechniques to scale our approach via a novel graph pseudo-sparsification\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:14:38 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Maass", "Kelsey", ""], ["Sathanur", "Arun V", ""], ["Khan", "Arif", ""], ["Rallo", "Robert", ""]]}, {"id": "2001.04536", "submitter": "Sifan Wang", "authors": "Sifan Wang, Yujun Teng, Paris Perdikaris", "title": "Understanding and mitigating gradient pathologies in physics-informed\n  neural networks", "comments": "28 Pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread use of neural networks across different scientific domains\noften involves constraining them to satisfy certain symmetries, conservation\nlaws, or other domain knowledge. Such constraints are often imposed as soft\npenalties during model training and effectively act as domain-specific\nregularizers of the empirical risk loss. Physics-informed neural networks is an\nexample of this philosophy in which the outputs of deep neural networks are\nconstrained to approximately satisfy a given set of partial differential\nequations. In this work we review recent advances in scientific machine\nlearning with a specific focus on the effectiveness of physics-informed neural\nnetworks in predicting outcomes of physical systems and discovering hidden\nphysics from noisy data. We will also identify and analyze a fundamental mode\nof failure of such approaches that is related to numerical stiffness leading to\nunbalanced back-propagated gradients during model training. To address this\nlimitation we present a learning rate annealing algorithm that utilizes\ngradient statistics during model training to balance the interplay between\ndifferent terms in composite loss functions. We also propose a novel neural\nnetwork architecture that is more resilient to such gradient pathologies. Taken\ntogether, our developments provide new insights into the training of\nconstrained neural networks and consistently improve the predictive accuracy of\nphysics-informed neural networks by a factor of 50-100x across a range of\nproblems in computational physics. All code and data accompanying this\nmanuscript are publicly available at\n\\url{https://github.com/PredictiveIntelligenceLab/GradientPathologiesPINNs}.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:23:49 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Sifan", ""], ["Teng", "Yujun", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2001.04537", "submitter": "Sunyi Zheng", "authors": "Sunyi Zheng, Ludo J. Cornelissen, Xiaonan Cui, Xueping Jing, Raymond\n  N. J. Veldhuis, Matthijs Oudkerk, and Peter M.A. van Ooijen", "title": "Deep convolutional neural networks for multi-planar lung nodule\n  detection: improvement in small nodule identification", "comments": null, "journal-ref": null, "doi": "10.1002/mp.14648", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: In clinical practice, small lung nodules can be easily overlooked\nby radiologists. The paper aims to provide an efficient and accurate detection\nsystem for small lung nodules while keeping good performance for large nodules.\nMethods: We propose a multi-planar detection system using convolutional neural\nnetworks. The 2-D convolutional neural network model, U-net++, was trained by\naxial, coronal, and sagittal slices for the candidate detection task. All\npossible nodule candidates from the three different planes are combined. For\nfalse positive reduction, we apply 3-D multi-scale dense convolutional neural\nnetworks to efficiently remove false positive candidates. We use the public\nLIDC-IDRI dataset which includes 888 CT scans with 1186 nodules annotated by\nfour radiologists. Results: After ten-fold cross-validation, our proposed\nsystem achieves a sensitivity of 94.2% with 1.0 false positive/scan and a\nsensitivity of 96.0% with 2.0 false positives/scan. Although it is difficult to\ndetect small nodules (i.e. < 6 mm), our designed CAD system reaches a\nsensitivity of 93.4% (95.0%) of these small nodules at an overall false\npositive rate of 1.0 (2.0) false positives/scan. At the nodule candidate\ndetection stage, results show that a multi-planar method is capable to detect\nmore nodules compared to using a single plane. Conclusion: Our approach\nachieves good performance not only for small nodules, but also for large\nlesions on this dataset. This demonstrates the effectiveness and efficiency of\nour developed CAD system for lung nodule detection. Significance: The proposed\nsystem could provide support for radiologists on early detection of lung\ncancer.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 21:37:33 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 21:26:34 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 20:40:29 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Zheng", "Sunyi", ""], ["Cornelissen", "Ludo J.", ""], ["Cui", "Xiaonan", ""], ["Jing", "Xueping", ""], ["Veldhuis", "Raymond N. J.", ""], ["Oudkerk", "Matthijs", ""], ["van Ooijen", "Peter M. A.", ""]]}, {"id": "2001.04552", "submitter": "Luca Puglia", "authors": "Luca Puglia and Cormac Brick", "title": "Deep Learning Stereo Vision at the edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the methodology used to build a new stereo vision\nsolution that is suitable for System on Chip. This new solution was developed\nto bring computer vision capability to embedded devices that live in a power\nconstrained environment. The solution is constructured as a hybrid between\nclassical Stereo Vision techniques and deep learning approaches. The\nstereoscopic module is composed of two separate modules: one that accelerates\nthe neural network we trained and one that accelerates the front-end part. The\nsystem is completely passive and does not require any structured light to\nobtain very compelling accuracy. With respect to the previous Stereo Vision\nsolutions offered by the industries we offer a major improvement is robustness\nto noise. This is mainly possible due to the deep learning part of the chosen\narchitecture. We submitted our result to Middlebury dataset challenge. It\ncurrently ranks as the best System on Chip solution. The system has been\ndeveloped for low latency applications which require better than real time\nperformance on high definition videos.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 22:30:41 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Puglia", "Luca", ""], ["Brick", "Cormac", ""]]}, {"id": "2001.04559", "submitter": "Ali Dabouei", "authors": "Ali Dabouei, Fariborz Taherkhani, Sobhan Soleymani, Jeremy Dawson,\n  Nasser M. Nasrabadi", "title": "Boosting Deep Face Recognition via Disentangling Appearance and Geometry", "comments": "WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework for disentangling the appearance and\ngeometry representations in the face recognition task. To provide supervision\nfor this aim, we generate geometrically identical faces by incorporating\nspatial transformations. We demonstrate that the proposed approach enhances the\nperformance of deep face recognition models by assisting the training process\nin two ways. First, it enforces the early and intermediate convolutional layers\nto learn more representative features that satisfy the properties of\ndisentangled embeddings. Second, it augments the training set by altering faces\ngeometrically. Through extensive experiments, we demonstrate that integrating\nthe proposed approach into state-of-the-art face recognition methods\neffectively improves their performance on challenging datasets, such as LFW,\nYTF, and MegaFace. Both theoretical and practical aspects of the method are\nanalyzed rigorously by concerning ablation studies and knowledge transfer\ntasks. Furthermore, we show that the knowledge leaned by the proposed method\ncan favor other face-related tasks, such as attribute prediction.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:19:58 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Dabouei", "Ali", ""], ["Taherkhani", "Fariborz", ""], ["Soleymani", "Sobhan", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "2001.04560", "submitter": "Anna Guerra", "authors": "Anna Guerra, Davide Dardari, Petar M. Djuric", "title": "Dynamic Radar Network of UAVs: A Joint Navigation and Tracking Approach", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3001393", "report-no": null, "categories": "cs.IT cs.LG cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays there is a growing research interest on the possibility of enriching\nsmall flying robots with autonomous sensing and online navigation capabilities.\nThis will enable a large number of applications spanning from remote\nsurveillance to logistics, smarter cities and emergency aid in hazardous\nenvironments. In this context, an emerging problem is to track unauthorized\nsmall unmanned aerial vehicles (UAVs) hiding behind buildings or concealing in\nlarge UAV networks. In contrast with current solutions mainly based on static\nand on-ground radars, this paper proposes the idea of a dynamic radar network\nof UAVs for real-time and high-accuracy tracking of malicious targets. To this\nend, we describe a solution for real-time navigation of UAVs to track a dynamic\ntarget using heterogeneously sensed information. Such information is shared by\nthe UAVs with their neighbors via multi-hops, allowing tracking the target by a\nlocal Bayesian estimator running at each agent. Since not all the paths are\nequal in terms of information gathering point-of-view, the UAVs plan their own\ntrajectory by minimizing the posterior covariance matrix of the target state\nunder UAV kinematic and anti-collision constraints. Our results show how a\ndynamic network of radars attains better localization results compared to a\nfixed configuration and how the on-board sensor technology impacts the accuracy\nin tracking a target with different radar cross sections, especially in non\nline-of-sight (NLOS) situations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:23:09 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Guerra", "Anna", ""], ["Dardari", "Davide", ""], ["Djuric", "Petar M.", ""]]}, {"id": "2001.04561", "submitter": "Merima Kulin", "authors": "Merima Kulin, Tarik Kazaz, Ingrid Moerman, Eli de Poorter", "title": "A survey on Machine Learning-based Performance Improvement of Wireless\n  Networks: PHY, MAC and Network layer", "comments": "35 pages, survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a systematic and comprehensive survey that reviews the\nlatest research efforts focused on machine learning (ML) based performance\nimprovement of wireless networks, while considering all layers of the protocol\nstack (PHY, MAC and network). First, the related work and paper contributions\nare discussed, followed by providing the necessary background on data-driven\napproaches and machine learning for non-machine learning experts to understand\nall discussed techniques. Then, a comprehensive review is presented on works\nemploying ML-based approaches to optimize the wireless communication parameters\nsettings to achieve improved network quality-of-service (QoS) and\nquality-of-experience (QoE). We first categorize these works into: radio\nanalysis, MAC analysis and network prediction approaches, followed by\nsubcategories within each. Finally, open challenges and broader perspectives\nare discussed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:33:29 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 14:44:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kulin", "Merima", ""], ["Kazaz", "Tarik", ""], ["Moerman", "Ingrid", ""], ["de Poorter", "Eli", ""]]}, {"id": "2001.04567", "submitter": "Ali Siahkoohi", "authors": "Ali Siahkoohi, Gabrio Rizzuti, and Felix J. Herrmann", "title": "A deep-learning based Bayesian approach to seismic imaging and\n  uncertainty quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification is essential when dealing with ill-conditioned\ninverse problems due to the inherent nonuniqueness of the solution. Bayesian\napproaches allow us to determine how likely an estimation of the unknown\nparameters is via formulating the posterior distribution. Unfortunately, it is\noften not possible to formulate a prior distribution that precisely encodes our\nprior knowledge about the unknown. Furthermore, adherence to handcrafted priors\nmay greatly bias the outcome of the Bayesian analysis. To address this issue,\nwe propose to use the functional form of a randomly initialized convolutional\nneural network as an implicit structured prior, which is shown to promote\nnatural images and excludes images with unnatural noise. In order to\nincorporate the model uncertainty into the final estimate, we sample the\nposterior distribution using stochastic gradient Langevin dynamics and perform\nBayesian model averaging on the obtained samples. Our synthetic numerical\nexperiment verifies that deep priors combined with Bayesian model averaging are\nable to partially circumvent imaging artifacts and reduce the risk of\noverfitting in the presence of extreme noise. Finally, we present pointwise\nvariance of the estimates as a measure of uncertainty, which coincides with\nregions that are more difficult to image.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:46:18 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 04:10:53 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Siahkoohi", "Ali", ""], ["Rizzuti", "Gabrio", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2001.04580", "submitter": "Xiyang Luo", "authors": "Xiyang Luo, Ruohan Zhan, Huiwen Chang, Feng Yang, Peyman Milanfar", "title": "Distortion Agnostic Deep Watermarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking is the process of embedding information into an image that can\nsurvive under distortions, while requiring the encoded image to have little or\nno perceptual difference from the original image. Recently, deep learning-based\nmethods achieved impressive results in both visual quality and message payload\nunder a wide variety of image distortions. However, these methods all require\ndifferentiable models for the image distortions at training time, and may\ngeneralize poorly to unknown distortions. This is undesirable since the types\nof distortions applied to watermarked images are usually unknown and\nnon-differentiable. In this paper, we propose a new framework for\ndistortion-agnostic watermarking, where the image distortion is not explicitly\nmodeled during training. Instead, the robustness of our system comes from two\nsources: adversarial training and channel coding. Compared to training on a\nfixed set of distortions and noise levels, our method achieves comparable or\nbetter results on distortions available during training, and better performance\non unknown distortions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 01:04:59 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Luo", "Xiyang", ""], ["Zhan", "Ruohan", ""], ["Chang", "Huiwen", ""], ["Yang", "Feng", ""], ["Milanfar", "Peyman", ""]]}, {"id": "2001.04586", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Zhou Zhao, Yueting Zhuang, Deng Cai", "title": "Bi-Decoder Augmented Network for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has become a popular technology in recent\nyears, and the encoder-decoder framework is the mainstream among all the\nmethods. It's obvious that the quality of the semantic representations from\nencoding is very crucial and can significantly affect the performance of the\nmodel. However, existing unidirectional source-to-target architectures may\nhardly produce a language-independent representation of the text because they\nrely heavily on the specific relations of the given language pairs. To\nalleviate this problem, in this paper, we propose a novel Bi-Decoder Augmented\nNetwork (BiDAN) for the neural machine translation task. Besides the original\ndecoder which generates the target language sequence, we add an auxiliary\ndecoder to generate back the source language sequence at the training time.\nSince each decoder transforms the representations of the input text into its\ncorresponding language, jointly training with two target ends can make the\nshared encoder has the potential to produce a language-independent semantic\nspace. We conduct extensive experiments on several NMT benchmark datasets and\nthe results demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 02:05:14 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""]]}, {"id": "2001.04589", "submitter": "Ciprian Chelba", "authors": "Ciprian Chelba, Mia Chen, Ankur Bapna, and Noam Shazeer", "title": "Faster Transformer Decoding: N-gram Masked Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the fact that most of the information relevant to the prediction\nof target tokens is drawn from the source sentence $S=s_1, \\ldots, s_S$, we\npropose truncating the target-side window used for computing self-attention by\nmaking an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show\nthat the $N$-gram masked self-attention model loses very little in BLEU score\nfor $N$ values in the range $4, \\ldots, 8$, depending on the task.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 02:14:09 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chelba", "Ciprian", ""], ["Chen", "Mia", ""], ["Bapna", "Ankur", ""], ["Shazeer", "Noam", ""]]}, {"id": "2001.04600", "submitter": "Pedro M. Milani", "authors": "Pedro M. Milani, Julia Ling, John K. Eaton", "title": "Turbulent scalar flux in inclined jets in crossflow: counter gradient\n  transport and deep learning modelling", "comments": "30 pages, 20 figures. Final version of the manuscript, accepted for\n  publication in the Journal of Fluid Mechanics", "journal-ref": null, "doi": "10.1017/jfm.2020.820", "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cylindrical and inclined jet in crossflow is studied under two distinct\nvelocity ratios, $r=1$ and $r=2$, using highly resolved large eddy simulations\n(LES). First, an investigation of turbulent scalar mixing sheds light onto the\npreviously observed but unexplained phenomenon of negative turbulent\ndiffusivity. We identify two distinct types of counter gradient transport,\nprevalent in different regions: the first, throughout the windward shear layer,\nis caused by cross-gradient transport; the second, close to the wall right\nafter injection, is caused by non-local effects. Then, we propose a deep\nlearning approach for modelling the turbulent scalar flux by adapting the\ntensor basis neural network previously developed to model Reynolds stresses\n(Ling et al. 2016a). This approach uses a deep neural network with embedded\ncoordinate frame invariance to predict a tensorial turbulent diffusivity that\nis not explicitly available in the high fidelity data used for training. After\nensuring analytically that the matrix diffusivity leads to a stable solution\nfor the advection diffusion equation, we apply this approach in the inclined\njets in crossflow under study. The results show significant improvement\ncompared to a simple model, particularly where cross-gradient effects play an\nimportant role in turbulent mixing. The model proposed herein is not limited to\njets in crossflow; it can be used in any turbulent flow where the Reynolds\naveraged transport of a scalar is considered.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 03:02:14 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 00:37:09 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Milani", "Pedro M.", ""], ["Ling", "Julia", ""], ["Eaton", "John K.", ""]]}, {"id": "2001.04601", "submitter": "Shi Zhao", "authors": "Shi Zhao, Ying Feng", "title": "For2For: Learning to forecast from forecasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a time series forecasting framework which combines\nstandard forecasting methods and a machine learning model. The inputs to the\nmachine learning model are not lagged values or regular time series features,\nbut instead forecasts produced by standard methods. The machine learning model\ncan be either a convolutional neural network model or a recurrent neural\nnetwork model. The intuition behind this approach is that forecasts of a time\nseries are themselves good features characterizing the series, especially when\nthe modelling purpose is forecasting. It can also be viewed as a weighted\nensemble method. Tested on the M4 competition dataset, this approach\noutperforms all submissions for quarterly series, and is more accurate than all\nbut the winning algorithm for monthly series.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 03:06:53 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhao", "Shi", ""], ["Feng", "Ying", ""]]}, {"id": "2001.04625", "submitter": "Lu Wang", "authors": "Lu Wang, Jie Yang", "title": "Asymmetric Correlation Quantization Hashing for Cross-modal Retrieval", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the superiority in similarity computation and database storage for\nlarge-scale multiple modalities data, cross-modal hashing methods have\nattracted extensive attention in similarity retrieval across the heterogeneous\nmodalities. However, there are still some limitations to be further taken into\naccount: (1) most current CMH methods transform real-valued data points into\ndiscrete compact binary codes under the binary constraints, limiting the\ncapability of representation for original data on account of abundant loss of\ninformation and producing suboptimal hash codes; (2) the discrete binary\nconstraint learning model is hard to solve, where the retrieval performance may\ngreatly reduce by relaxing the binary constraints for large quantization error;\n(3) handling the learning problem of CMH in a symmetric framework, leading to\ndifficult and complex optimization objective. To address above challenges, in\nthis paper, a novel Asymmetric Correlation Quantization Hashing (ACQH) method\nis proposed. Specifically, ACQH learns the projection matrixs of heterogeneous\nmodalities data points for transforming query into a low-dimensional\nreal-valued vector in latent semantic space and constructs the stacked\ncompositional quantization embedding in a coarse-to-fine manner for indicating\ndatabase points by a series of learnt real-valued codeword in the codebook with\nthe help of pointwise label information regression simultaneously. Besides, the\nunified hash codes across modalities can be directly obtained by the discrete\niterative optimization framework devised in the paper. Comprehensive\nexperiments on diverse three benchmark datasets have shown the effectiveness\nand rationality of ACQH.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 04:53:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Lu", ""], ["Yang", "Jie", ""]]}, {"id": "2001.04634", "submitter": "Adam Lesnikowski", "authors": "Adam Lesnikowski, Valentin T. Bickel, Daniel Angerhausen", "title": "Unsupervised Distribution Learning for Lunar Surface Anomaly Detection", "comments": "Second Workshop on Machine Learning and the Physical Sciences,\n  NeurIPS 2019. Five pages, three figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.EP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that modern data-driven machine learning techniques can\nbe successfully applied on lunar surface remote sensing data to learn, in an\nunsupervised way, sufficiently good representations of the data distribution to\nenable lunar technosignature and anomaly detection. In particular we train an\nunsupervised distribution learning neural network model to find the Apollo 15\nlanding module in a testing dataset, with no dataset specific model or\nhyperparameter tuning. Sufficiently good unsupervised data density estimation\nhas the promise of enabling myriad useful downstream tasks, including locating\nlunar resources for future space flight and colonization, finding new impact\ncraters or lunar surface reshaping, and algorithmically deciding the importance\nof unlabeled samples to send back from power- and bandwidth-constrained\nmissions. We show in this work that such unsupervised learning can be\nsuccessfully done in the lunar remote sensing and space science contexts.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 05:38:37 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Lesnikowski", "Adam", ""], ["Bickel", "Valentin T.", ""], ["Angerhausen", "Daniel", ""]]}, {"id": "2001.04639", "submitter": "Chiwoo Park", "authors": "Chiwoo Park, David J. Borth, Nicholas S. Wilson, Chad N. Hunter, and\n  Fritz J. Friedersdorf", "title": "Robust Gaussian Process Regression with a Bias Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to a robust Gaussian process (GP)\nregression. Most existing approaches replace an outlier-prone Gaussian\nlikelihood with a non-Gaussian likelihood induced from a heavy tail\ndistribution, such as the Laplace distribution and Student-t distribution.\nHowever, the use of a non-Gaussian likelihood would incur the need for a\ncomputationally expensive Bayesian approximate computation in the posterior\ninferences. The proposed approach models an outlier as a noisy and biased\nobservation of an unknown regression function, and accordingly, the likelihood\ncontains bias terms to explain the degree of deviations from the regression\nfunction. We entail how the biases can be estimated accurately with other\nhyperparameters by a regularized maximum likelihood estimation. Conditioned on\nthe bias estimates, the robust GP regression can be reduced to a standard GP\nregression problem with analytical forms of the predictive mean and variance\nestimates. Therefore, the proposed approach is simple and very computationally\nattractive. It also gives a very robust and accurate GP estimate for many\ntested scenarios. For the numerical evaluation, we perform a comprehensive\nsimulation study to evaluate the proposed approach with the comparison to the\nexisting robust GP approaches under various simulated scenarios of different\noutlier proportions and different noise levels. The approach is applied to data\nfrom two measurement systems, where the predictors are based on robust\nenvironmental parameter measurements and the response variables utilize more\ncomplex chemical sensing methods that contain a certain percentage of outliers.\nThe utility of the measurement systems and value of the environmental data are\nimproved through the computationally efficient GP regression and bias model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 06:21:51 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Park", "Chiwoo", ""], ["Borth", "David J.", ""], ["Wilson", "Nicholas S.", ""], ["Hunter", "Chad N.", ""], ["Friedersdorf", "Fritz J.", ""]]}, {"id": "2001.04643", "submitter": "Jesse Engel", "authors": "Jesse Engel, Lamtharn Hantrakul, Chenjie Gu, Adam Roberts", "title": "DDSP: Differentiable Digital Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most generative models of audio directly generate samples in one of two\ndomains: time or frequency. While sufficient to express any signal, these\nrepresentations are inefficient, as they do not utilize existing knowledge of\nhow sound is generated and perceived. A third approach (vocoders/synthesizers)\nsuccessfully incorporates strong domain knowledge of signal processing and\nperception, but has been less actively researched due to limited expressivity\nand difficulty integrating with modern auto-differentiation-based machine\nlearning methods. In this paper, we introduce the Differentiable Digital Signal\nProcessing (DDSP) library, which enables direct integration of classic signal\nprocessing elements with deep learning methods. Focusing on audio synthesis, we\nachieve high-fidelity generation without the need for large autoregressive\nmodels or adversarial losses, demonstrating that DDSP enables utilizing strong\ninductive biases without losing the expressive power of neural networks.\nFurther, we show that combining interpretable modules permits manipulation of\neach separate model component, with applications such as independent control of\npitch and loudness, realistic extrapolation to pitches not seen during\ntraining, blind dereverberation of room acoustics, transfer of extracted room\nacoustics to new environments, and transformation of timbre between disparate\nsources. In short, DDSP enables an interpretable and modular approach to\ngenerative modeling, without sacrificing the benefits of deep learning. The\nlibrary is publicly available at https://github.com/magenta/ddsp and we welcome\nfurther contributions from the community and domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 06:49:37 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Engel", "Jesse", ""], ["Hantrakul", "Lamtharn", ""], ["Gu", "Chenjie", ""], ["Roberts", "Adam", ""]]}, {"id": "2001.04646", "submitter": "Alessandro Corbetta", "authors": "Joris Willems, Alessandro Corbetta, Vlado Menkovski, Federico Toschi", "title": "Pedestrian orientation dynamics from high-fidelity measurements", "comments": null, "journal-ref": "Scientific Reports 10(1), 2020", "doi": "10.1038/s41598-020-68287-6", "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate in real-life conditions and with very high accuracy the\ndynamics of body rotation, or yawing, of walking pedestrians - an highly\ncomplex task due to the wide variety in shapes, postures and walking gestures.\nWe propose a novel measurement method based on a deep neural architecture that\nwe train on the basis of generic physical properties of the motion of\npedestrians. Specifically, we leverage on the strong statistical correlation\nbetween individual velocity and body orientation: the velocity direction is\ntypically orthogonal with respect to the shoulder line. We make the reasonable\nassumption that this approximation, although instantaneously slightly\nimperfect, is correct on average. This enables us to use velocity data as\ntraining labels for a highly-accurate point-estimator of individual\norientation, that we can train with no dedicated annotation labor. We discuss\nthe measurement accuracy and show the error scaling, both on synthetic and\nreal-life data: we show that our method is capable of estimating orientation\nwith an error as low as 7.5 degrees. This tool opens up new possibilities in\nthe studies of human crowd dynamics where orientation is key. By analyzing the\ndynamics of body rotation in real-life conditions, we show that the\ninstantaneous velocity direction can be described by the combination of\norientation and a random delay, where randomness is provided by an\nOrnstein-Uhlenbeck process centered on an average delay of 100ms. Quantifying\nthese dynamics could have only been possible thanks to a tool as precise as\nthat proposed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 07:08:31 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Willems", "Joris", ""], ["Corbetta", "Alessandro", ""], ["Menkovski", "Vlado", ""], ["Toschi", "Federico", ""]]}, {"id": "2001.04663", "submitter": "Pargorn Puttapirat", "authors": "Jiangbo Shi, Zeyu Gao, Haichuan Zhang, Pargorn Puttapirat, Chunbao\n  Wang, Xiangrong Zhang, Chen Li", "title": "Effects of annotation granularity in deep learning models for\n  histopathological images", "comments": "Accepted by AIPath2019 Workshop in BIBM2019. 7 pages, 4 figures, 4\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pathological is crucial to cancer diagnosis. Usually, Pathologists draw their\nconclusion based on observed cell and tissue structure on histology slides.\nRapid development in machine learning, especially deep learning have\nestablished robust and accurate classifiers. They are being used to analyze\nhistopathological slides and assist pathologists in diagnosis. Most machine\nlearning systems rely heavily on annotated data sets to gain experiences and\nknowledge to correctly and accurately perform various tasks such as\nclassification and segmentation. This work investigates different granularity\nof annotations in histopathological data set including image-wise, bounding\nbox, ellipse-wise, and pixel-wise to verify the influence of annotation in\npathological slide on deep learning models. We design corresponding experiments\nto test classification and segmentation performance of deep learning models\nbased on annotations with different annotation granularity. In classification,\nstate-of-the-art deep learning-based classifiers perform better when trained by\npixel-wise annotation dataset. On average, precision, recall and F1-score\nimproves by 7.87%, 8.83% and 7.85% respectively. Thus, it is suggested that\nfiner granularity annotations are better utilized by deep learning algorithms\nin classification tasks. Similarly, semantic segmentation algorithms can\nachieve 8.33% better segmentation accuracy when trained by pixel-wise\nannotations. Our study shows not only that finer-grained annotation can improve\nthe performance of deep learning models, but also help extracts more accurate\nphenotypic information from histopathological slides. Intelligence systems\ntrained on granular annotations may help pathologists inspecting certain\nregions for better diagnosis. The compartmentalized prediction approach similar\nto this work may contribute to phenotype and genotype association studies.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 08:39:51 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Shi", "Jiangbo", ""], ["Gao", "Zeyu", ""], ["Zhang", "Haichuan", ""], ["Puttapirat", "Pargorn", ""], ["Wang", "Chunbao", ""], ["Zhang", "Xiangrong", ""], ["Li", "Chen", ""]]}, {"id": "2001.04669", "submitter": "Ami Sakakibara", "authors": "Ryohei Oura, Ami Sakakibara, Toshimitsu Ushio", "title": "Reinforcement Learning of Control Policy for Linear Temporal Logic\n  Specifications Using Limit-Deterministic Generalized B\\\"uchi Automata", "comments": "7 pages, 6 figures; an extended version of a manuscript accepted to\n  IEEE L-CSS", "journal-ref": null, "doi": "10.1109/LCSYS.2020.2980552", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes a novel reinforcement learning method for the synthesis\nof a control policy satisfying a control specification described by a linear\ntemporal logic formula. We assume that the controlled system is modeled by a\nMarkov decision process (MDP). We convert the specification to a\nlimit-deterministic generalized B\\\"uchi automaton (LDGBA) with several\naccepting sets that accepts all infinite sequences satisfying the formula. The\nLDGBA is augmented so that it explicitly records the previous visits to\naccepting sets. We take a product of the augmented LDGBA and the MDP, based on\nwhich we define a reward function. The agent gets rewards whenever state\ntransitions are in an accepting set that has not been visited for a certain\nnumber of steps. Consequently, sparsity of rewards is relaxed and optimal\ncirculations among the accepting sets are learned. We show that the proposed\nmethod can learn an optimal policy when the discount factor is sufficiently\nclose to one.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 08:55:56 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 07:25:09 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 07:39:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Oura", "Ryohei", ""], ["Sakakibara", "Ami", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "2001.04676", "submitter": "Takashi Goda", "authors": "Kei Ishikawa, Takashi Goda", "title": "Efficient Debiased Evidence Estimation by Multilevel Monte Carlo\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new stochastic optimization algorithm for\nBayesian inference based on multilevel Monte Carlo (MLMC) methods. In Bayesian\nstatistics, biased estimators of the model evidence have been often used as\nstochastic objectives because the existing debiasing techniques are\ncomputationally costly to apply. To overcome this issue, we apply an MLMC\nsampling technique to construct low-variance unbiased estimators both for the\nmodel evidence and its gradient. In the theoretical analysis, we show that the\ncomputational cost required for our proposed MLMC estimator to estimate the\nmodel evidence or its gradient with a given accuracy is an order of magnitude\nsmaller than those of the previously known estimators. Our numerical\nexperiments confirm considerable computational savings compared to the\nconventional estimators. Combining our MLMC estimator with gradient-based\nstochastic optimization results in a new scalable, efficient, debiased\ninference algorithm for Bayesian statistical models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:14:24 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 23:48:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Ishikawa", "Kei", ""], ["Goda", "Takashi", ""]]}, {"id": "2001.04678", "submitter": "David Balduzzi", "authors": "David Balduzzi, Wojciech M Czarnecki, Thomas W Anthony, Ian M Gemp,\n  Edward Hughes, Joel Z Leibo, Georgios Piliouras, Thore Graepel", "title": "Smooth markets: A basic mechanism for organizing gradient-based learners", "comments": "18 pages, 3 figures", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of modern machine learning, it is becoming increasingly\nimportant to understand and control how learning algorithms interact.\nUnfortunately, negative results from game theory show there is little hope of\nunderstanding or controlling general n-player games. We therefore introduce\nsmooth markets (SM-games), a class of n-player games with pairwise zero sum\ninteractions. SM-games codify a common design pattern in machine learning that\nincludes (some) GANs, adversarial training, and other recent algorithms. We\nshow that SM-games are amenable to analysis and optimization using first-order\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:19:39 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 09:09:22 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Balduzzi", "David", ""], ["Czarnecki", "Wojciech M", ""], ["Anthony", "Thomas W", ""], ["Gemp", "Ian M", ""], ["Hughes", "Edward", ""], ["Leibo", "Joel Z", ""], ["Piliouras", "Georgios", ""], ["Graepel", "Thore", ""]]}, {"id": "2001.04686", "submitter": "Amir Hadifar", "authors": "Amir Hadifar, Johannes Deleu, Chris Develder, and Thomas Demeester", "title": "Block-wise Dynamic Sparseness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have achieved state of the art performance across a wide\nvariety of machine learning tasks, often with large and computation-heavy\nmodels. Inducing sparseness as a way to reduce the memory and computation\nfootprint of these models has seen significant research attention in recent\nyears. In this paper, we present a new method for \\emph{dynamic sparseness},\nwhereby part of the computations are omitted dynamically, based on the input.\nFor efficiency, we combined the idea of dynamic sparseness with block-wise\nmatrix-vector multiplications. In contrast to static sparseness, which\npermanently zeroes out selected positions in weight matrices, our method\npreserves the full network capabilities by potentially accessing any trained\nweights. Yet, matrix vector multiplications are accelerated by omitting a\npre-defined fraction of weight blocks from the matrix, based on the input.\nExperimental results on the task of language modeling, using recurrent and\nquasi-recurrent models, show that the proposed method can outperform a\nmagnitude-based static sparseness baseline. In addition, our method achieves\nsimilar language modeling perplexities as the dense baseline, at half the\ncomputational cost at inference time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:03:21 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hadifar", "Amir", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""], ["Demeester", "Thomas", ""]]}, {"id": "2001.04689", "submitter": "Nikolai Zolotykh", "authors": "Viktor Moskalenko, Nikolai Zolotykh, Grigory Osipov", "title": "Deep Learning for ECG Segmentation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-030-30425-6_29", "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for electrocardiogram (ECG) segmentation using a\nUNet-like full-convolutional neural network. The algorithm receives an\narbitrary sampling rate ECG signal as an input, and gives a list of onsets and\noffsets of P and T waves and QRS complexes as output. Our method of\nsegmentation differs from others in speed, a small number of parameters and a\ngood generalization: it is adaptive to different sampling rates and it is\ngeneralized to various types of ECG monitors. The proposed approach is superior\nto other state-of-the-art segmentation methods in terms of quality. In\nparticular, F1-measures for detection of onsets and offsets of P and T waves\nand for QRS-complexes are at least 97.8%, 99.5%, and 99.9%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:05:09 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moskalenko", "Viktor", ""], ["Zolotykh", "Nikolai", ""], ["Osipov", "Grigory", ""]]}, {"id": "2001.04692", "submitter": "Marco Toldo", "authors": "Marco Toldo and Umberto Michieli and Gianluca Agresti and Pietro\n  Zanuttigh", "title": "Unsupervised Domain Adaptation for Mobile Semantic Segmentation based on\n  Cycle Consistency and Feature Alignment", "comments": "11 pages, 3 figures, 3 tables", "journal-ref": "Image and Vision Computing, Volume 95, March 2020", "doi": "10.1016/j.imavis.2020.103889", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supervised training of deep networks for semantic segmentation requires a\nhuge amount of labeled real world data. To solve this issue, a commonly\nexploited workaround is to use synthetic data for training, but deep networks\nshow a critical performance drop when analyzing data with slightly different\nstatistical properties with respect to the training set. In this work, we\npropose a novel Unsupervised Domain Adaptation (UDA) strategy to address the\ndomain shift issue between real world and synthetic representations. An\nadversarial model, based on the cycle consistency framework, performs the\nmapping between the synthetic and real domain. The data is then fed to a\nMobileNet-v2 architecture that performs the semantic segmentation task. An\nadditional couple of discriminators, working at the feature level of the\nMobileNet-v2, allows to better align the features of the two domain\ndistributions and to further improve the performance. Finally, the consistency\nof the semantic maps is exploited. After an initial supervised training on\nsynthetic data, the whole UDA architecture is trained end-to-end considering\nall its components at once. Experimental results show how the proposed strategy\nis able to obtain impressive performance in adapting a segmentation network\ntrained on synthetic data to real world scenarios. The usage of the lightweight\nMobileNet-v2 architecture allows its deployment on devices with limited\ncomputational resources as the ones employed in autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:12:20 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 10:22:43 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Toldo", "Marco", ""], ["Michieli", "Umberto", ""], ["Agresti", "Gianluca", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "2001.04693", "submitter": "Stephanie Brandl", "authors": "Stephanie Brandl, David Lassner, Maximilian Alber", "title": "Balancing the composition of word embeddings across heterogenous data\n  sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings capture semantic relationships based on contextual\ninformation and are the basis for a wide variety of natural language processing\napplications. Notably these relationships are solely learned from the data and\nsubsequently the data composition impacts the semantic of embeddings which\narguably can lead to biased word vectors. Given qualitatively different data\nsubsets, we aim to align the influence of single subsets on the resulting word\nvectors, while retaining their quality. In this regard we propose a criteria to\nmeasure the shift towards a single data subset and develop approaches to meet\nboth objectives. We find that a weighted average of the two subset embeddings\nbalances the influence of those subsets while word similarity performance\ndecreases. We further propose a promising optimization approach to balance\ninfluences and quality of word embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:12:50 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Brandl", "Stephanie", ""], ["Lassner", "David", ""], ["Alber", "Maximilian", ""]]}, {"id": "2001.04694", "submitter": "Linh Tran", "authors": "Linh Tran, Bastiaan S. Veeling, Kevin Roth, Jakub Swiatkowski, Joshua\n  V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Sebastian Nowozin,\n  Rodolphe Jenatton", "title": "Hydra: Preserving Ensemble Diversity for Model Distillation", "comments": "Accepted to ICML 2020 Workshop on Uncertainty and Robustness in Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of models have been empirically shown to improve predictive\nperformance and to yield robust measures of uncertainty. However, they are\nexpensive in computation and memory. Therefore, recent research has focused on\ndistilling ensembles into a single compact model, reducing the computational\nand memory burden of the ensemble while trying to preserve its predictive\nbehavior. Most existing distillation formulations summarize the ensemble by\ncapturing its average predictions. As a result, the diversity of the ensemble\npredictions, stemming from each member, is lost. Thus, the distilled model\ncannot provide a measure of uncertainty comparable to that of the original\nensemble. To retain more faithfully the diversity of the ensemble, we propose a\ndistillation method based on a single multi-headed neural network, which we\nrefer to as Hydra. The shared body network learns a joint feature\nrepresentation that enables each head to capture the predictive behavior of\neach ensemble member. We demonstrate that with a slight increase in parameter\ncount, Hydra improves distillation performance on classification and regression\nsettings while capturing the uncertainty behavior of the original ensemble over\nboth in-domain and out-of-distribution tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:13:52 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 11:25:46 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Tran", "Linh", ""], ["Veeling", "Bastiaan S.", ""], ["Roth", "Kevin", ""], ["Swiatkowski", "Jakub", ""], ["Dillon", "Joshua V.", ""], ["Snoek", "Jasper", ""], ["Mandt", "Stephan", ""], ["Salimans", "Tim", ""], ["Nowozin", "Sebastian", ""], ["Jenatton", "Rodolphe", ""]]}, {"id": "2001.04705", "submitter": "Jonathan Pan", "authors": "Jonathan Pan", "title": "IoT Network Behavioral Fingerprint Inference with Limited Network Trace\n  for Cyber Investigation: A Meta Learning Approach", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development and adoption of Internet of Things (IoT) devices will grow\nsignificantly in the coming years to enable Industry 4.0. Many forms of IoT\ndevices will be developed and used across industry verticals. However, the\neuphoria of this technology adoption is shadowed by the solemn presence of\ncyber threats that will follow its growth trajectory. Cyber threats would\neither embed their malicious code or attack vulnerabilities in IoT that could\ninduce significant consequences in cyber and physical realms. In order to\nmanage such destructive effects, incident responders and cyber investigators\nrequire the capabilities to find these rogue IoT and contain them quickly. Such\nonline devices may only leave network activity traces. A collection of relevant\ntraces could be used to infer the IoT's network behaviorial fingerprints and in\nturn could facilitate investigative find of these IoT. However, the challenge\nis how to infer these fingerprints when there is limited network activity\ntraces. This research proposes the novel model construct that learns to infer\nthe network behaviorial fingerprint of specific IoT based on limited network\nactivity traces using a One-Card Time Series Meta-Learner called DeepNetPrint.\nOur research also demonstrates the application of DeepNetPrint to identify IoT\ndevices that performs comparatively well against leading supervised learning\nmodels. Our solution would enable cyber investigator to identify specific IoT\nof interest while overcoming the constraints of having only limited network\ntraces of the IoT.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:42:45 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 02:57:24 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pan", "Jonathan", ""]]}, {"id": "2001.04721", "submitter": "Byoung Chul Ko Prof.", "authors": "Sangwon Kim, Mira Jeong, Byoung Chul Ko", "title": "Interpretation and Simplification of Deep Forest", "comments": "Major issues on the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new method for interpreting and simplifying a black box\nmodel of a deep random forest (RF) using a proposed rule elimination. In deep\nRF, a large number of decision trees are connected to multiple layers, thereby\nmaking an analysis difficult. It has a high performance similar to that of a\ndeep neural network (DNN), but achieves a better generalizability. Therefore,\nin this study, we consider quantifying the feature contributions and frequency\nof the fully trained deep RF in the form of a decision rule set. The feature\ncontributions provide a basis for determining how features affect the decision\nprocess in a rule set. Model simplification is achieved by eliminating\nunnecessary rules by measuring the feature contributions. Consequently, the\nsimplified model has fewer parameters and rules than before. Experiment results\nhave shown that a feature contribution analysis allows a black box model to be\ndecomposed for quantitatively interpreting a rule set. The proposed method was\nsuccessfully applied to various deep RF models and benchmark datasets while\nmaintaining a robust performance despite the elimination of a large number of\nrules.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:30:26 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 04:09:22 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 06:25:48 GMT"}, {"version": "v4", "created": "Sat, 12 Dec 2020 04:35:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kim", "Sangwon", ""], ["Jeong", "Mira", ""], ["Ko", "Byoung Chul", ""]]}, {"id": "2001.04733", "submitter": "Ivan Kiskin", "authors": "Ivan Kiskin, Adam D. Cobb, Lawrence Wang, Stephen Roberts", "title": "HumBug Zooniverse: a crowd-sourced acoustic mosquito dataset", "comments": "Awarded Best Paper at the 2019 NeurIPS ML4D workshop. Accepted at\n  ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mosquitoes are the only known vector of malaria, which leads to hundreds of\nthousands of deaths each year. Understanding the number and location of\npotential mosquito vectors is of paramount importance to aid the reduction of\nmalaria transmission cases. In recent years, deep learning has become widely\nused for bioacoustic classification tasks. In order to enable further research\napplications in this field, we release a new dataset of mosquito audio\nrecordings. With over a thousand contributors, we obtained 195,434 labels of\ntwo second duration, of which approximately 10 percent signify mosquito events.\nWe present an example use of the dataset, in which we train a convolutional\nneural network on log-Mel features, showcasing the information content of the\nlabels. We hope this will become a vital resource for those researching all\naspects of malaria, and add to the existing audio datasets for bioacoustic\ndetection and signal processing.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 12:06:17 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:11:11 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kiskin", "Ivan", ""], ["Cobb", "Adam D.", ""], ["Wang", "Lawrence", ""], ["Roberts", "Stephen", ""]]}, {"id": "2001.04754", "submitter": "Yao Zhang", "authors": "Yao Zhang, Alexis Bellot, Mihaela van der Schaar", "title": "Learning Overlapping Representations for the Estimation of\n  Individualized Treatment Effects", "comments": null, "journal-ref": "Proceedings of the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of making an intervention depends on its potential benefit or harm\nin comparison to alternatives. Estimating the likely outcome of alternatives\nfrom observational data is a challenging problem as all outcomes are never\nobserved, and selection bias precludes the direct comparison of differently\nintervened groups. Despite their empirical success, we show that algorithms\nthat learn domain-invariant representations of inputs (on which to make\npredictions) are often inappropriate, and develop generalization bounds that\ndemonstrate the dependence on domain overlap and highlight the need for\ninvertible latent maps. Based on these results, we develop a deep kernel\nregression algorithm and posterior regularization framework that substantially\noutperforms the state-of-the-art on a variety of benchmarks data sets.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 12:56:29 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:18:44 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 12:07:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Yao", ""], ["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.04756", "submitter": "Shiqiang Wang", "authors": "Pengchao Han, Shiqiang Wang, Kin K. Leung", "title": "Adaptive Gradient Sparsification for Efficient Federated Learning: An\n  Online Learning Approach", "comments": "Accepted at IEEE ICDCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging technique for training machine\nlearning models using geographically dispersed data collected by local\nentities. It includes local computation and synchronization steps. To reduce\nthe communication overhead and improve the overall efficiency of FL, gradient\nsparsification (GS) can be applied, where instead of the full gradient, only a\nsmall subset of important elements of the gradient is communicated. Existing\nwork on GS uses a fixed degree of gradient sparsity for i.i.d.-distributed data\nwithin a datacenter. In this paper, we consider adaptive degree of sparsity and\nnon-i.i.d. local datasets. We first present a fairness-aware GS method which\nensures that different clients provide a similar amount of updates. Then, with\nthe goal of minimizing the overall training time, we propose a novel online\nlearning formulation and algorithm for automatically determining the\nnear-optimal communication and computation trade-off that is controlled by the\ndegree of gradient sparsity. The online learning algorithm uses an estimated\nsign of the derivative of the objective function, which gives a regret bound\nthat is asymptotically equal to the case where exact derivative is available.\nExperiments with real datasets confirm the benefits of our proposed approaches,\nshowing up to $40\\%$ improvement in model accuracy for a finite training time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:09:23 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 17:56:09 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 16:34:48 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Han", "Pengchao", ""], ["Wang", "Shiqiang", ""], ["Leung", "Kin K.", ""]]}, {"id": "2001.04761", "submitter": "Jozsef Nemeth", "authors": "Jozsef Nemeth", "title": "Adversarial Disentanglement with Grouped Observations", "comments": "Accepted at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the disentanglement of the representations of the relevant\nattributes of the data (content) from all other factors of variations (style)\nusing Variational Autoencoders. Some recent works addressed this problem by\nutilizing grouped observations, where the content attributes are assumed to be\ncommon within each group, while there is no any supervised information on the\nstyle factors. In many cases, however, these methods fail to prevent the models\nfrom using the style variables to encode content related features as well. This\nwork supplements these algorithms with a method that eliminates the content\ninformation in the style representations. For that purpose the training\nobjective is augmented to minimize an appropriately defined mutual information\nterm in an adversarial way. Experimental results and comparisons on image\ndatasets show that the resulting method can efficiently separate the content\nand style related attributes and generalizes to unseen data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:21:25 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Nemeth", "Jozsef", ""]]}, {"id": "2001.04782", "submitter": "Thomas Haugland Johansen", "authors": "Thomas Haugland Johansen and Steffen Aagaard S{\\o}rensen", "title": "Towards detection and classification of microscopic foraminifera using\n  transfer learning", "comments": "6 pages, 5 figures. To be published in proceedings of Northern Lights\n  Deep Learning Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Foraminifera are single-celled marine organisms, which may have a planktic or\nbenthic lifestyle. During their life cycle they construct shells consisting of\none or more chambers, and these shells remain as fossils in marine sediments.\nClassifying and counting these fossils have become an important tool in e.g.\noceanography and climatology. Currently the process of identifying and counting\nmicrofossils is performed manually using a microscope and is very time\nconsuming. Developing methods to automate this process is therefore considered\nimportant across a range of research fields. The first steps towards developing\na deep learning model that can detect and classify microscopic foraminifera are\nproposed. The proposed model is based on a VGG16 model that has been pretrained\non the ImageNet dataset, and adapted to the foraminifera task using transfer\nlearning. Additionally, a novel image dataset consisting of microscopic\nforaminifera and sediments from the Barents Sea region is introduced.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:57:08 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Johansen", "Thomas Haugland", ""], ["S\u00f8rensen", "Steffen Aagaard", ""]]}, {"id": "2001.04786", "submitter": "Mingyi Hong", "authors": "Tsung-Hui Chang, Mingyi Hong, Hoi-To Wai, Xinwei Zhang, and Songtao Lu", "title": "Distributed Learning in the Non-Convex World: From Batch to Streaming\n  Data, and Beyond", "comments": "Submitted to IEEE Signal Processing Magazine Special Issue on\n  Distributed, Streaming Machine Learning; THC, MH, HTW contributed equally", "journal-ref": null, "doi": "10.1109/MSP.2020.2970170", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning has become a critical enabler of the massively connected\nworld envisioned by many. This article discusses four key elements of scalable\ndistributed processing and real-time intelligence --- problems, data,\ncommunication and computation. Our aim is to provide a fresh and unique\nperspective about how these elements should work together in an effective and\ncoherent manner. In particular, we {provide a selective review} about the\nrecent techniques developed for optimizing non-convex models (i.e., problem\nclasses), processing batch and streaming data (i.e., data types), over the\nnetworks in a distributed manner (i.e., communication and computation\nparadigm). We describe the intuitions and connections behind a core set of\npopular distributed algorithms, emphasizing how to trade off between\ncomputation and communication costs. Practical issues and future research\ndirections will also be discussed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 14:11:32 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Chang", "Tsung-Hui", ""], ["Hong", "Mingyi", ""], ["Wai", "Hoi-To", ""], ["Zhang", "Xinwei", ""], ["Lu", "Songtao", ""]]}, {"id": "2001.04794", "submitter": "Francesco Bardozzo", "authors": "Francesco Bardozzo, Pietro Lio', Roberto Tagliaferri", "title": "A machine learning approach to investigate regulatory control circuits\n  in bacterial metabolic pathways", "comments": "5 pages, 3 figures", "journal-ref": "CIBB 2016 13th International Meeting, CIBB 2016, Stirling, UK,\n  September 1-3, 2016, Revised Selected Papers Springer, 2017, Vol. 10477 pp\n  22-26", "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a machine learning approach for identifying the multi-omics\nmetabolic regulatory control circuits inside the pathways is described.\nTherefore, the identification of bacterial metabolic pathways that are more\nregulated than others in term of their multi-omics follows from the analysis of\nthese circuits . This is a consequence of the alternation of the omic values of\ncodon usage and protein abundance along with the circuits. In this work, the\nE.Coli's Glycolysis and its multi-omic circuit features are shown as an\nexample.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 11:04:26 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Bardozzo", "Francesco", ""], ["Lio'", "Pietro", ""], ["Tagliaferri", "Roberto", ""]]}, {"id": "2001.04798", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Rodrigo S. Sousa, Priscila G.M. dos Santos, Tiago M.L. Veras, Wilson\n  R. de Oliveira and Adenilton J. da Silva", "title": "Parametric Probabilistic Quantum Memory", "comments": null, "journal-ref": "Neurocomputing 416 (2020): 360-369", "doi": "10.1016/j.neucom.2020.01.116", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Quantum Memory (PQM) is a data structure that computes the\ndistance from a binary input to all binary patterns stored in superposition on\nthe memory. This data structure allows the development of heuristics to speed\nup artificial neural networks architecture selection. In this work, we propose\nan improved parametric version of the PQM to perform pattern classification,\nand we also present a PQM quantum circuit suitable for Noisy Intermediate Scale\nQuantum (NISQ) computers. We present a classical evaluation of a parametric PQM\nnetwork classifier on public benchmark datasets. We also perform experiments to\nverify the viability of PQM on a 5-qubit quantum computer.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 11:41:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sousa", "Rodrigo S.", ""], ["Santos", "Priscila G. M. dos", ""], ["Veras", "Tiago M. L.", ""], ["de Oliveira", "Wilson R.", ""], ["da Silva", "Adenilton J.", ""]]}, {"id": "2001.04802", "submitter": "Amir Mosavi Prof", "authors": "Amin Kazemian-Kale-Kale, Azadeh Gholami, Mohammad Rezaie-Balf, Amir\n  Mosavi, Ahmed A Sattar, Bahram Gharabaghi, Hossein Bonakdari", "title": "A Bayesian Monte-Carlo Uncertainty Model for Assessment of Shear Stress\n  Entropy", "comments": "48 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The entropy models have been recently adopted in many studies to evaluate the\ndistribution of the shear stress in circular channels. However, the uncertainty\nin their predictions and their reliability remains an open question. We present\na novel method to evaluate the uncertainty of four popular entropy models,\nincluding Shannon, Shannon-Power Low (PL), Tsallis, and Renyi, in shear stress\nestimation in circular channels. The Bayesian Monte-Carlo (BMC) uncertainty\nmethod is simplified considering a 95% Confidence Bound (CB). We developed a\nnew statistic index called as FREEopt-based OCB (FOCB) using the statistical\nindices Forecasting Range of Error Estimation (FREE) and the percentage of\nobserved data in the CB (Nin), which integrates their combined effect. The\nShannon and Shannon PL entropies had close values of the FOCB equal to 8.781\nand 9.808, respectively, had the highest certainty in the calculation of shear\nstress values in circular channels followed by traditional uniform flow shear\nstress and Tsallis models with close values of 14.491 and 14.895, respectively.\nHowever, Renyi entropy with much higher values of FOCB equal to 57.726 has less\ncertainty in the estimation of shear stress than other models. Using the\npresented results in this study, the amount of confidence in entropy methods in\nthe calculation of shear stress to design and implement different types of open\nchannels and their stability is determined.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 22:46:59 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Kazemian-Kale-Kale", "Amin", ""], ["Gholami", "Azadeh", ""], ["Rezaie-Balf", "Mohammad", ""], ["Mosavi", "Amir", ""], ["Sattar", "Ahmed A", ""], ["Gharabaghi", "Bahram", ""], ["Bonakdari", "Hossein", ""]]}, {"id": "2001.04813", "submitter": "Xiaobo Qu", "authors": "Dicheng Chen, Zi Wang, Di Guo, Vladislav Orekhov, Xiaobo Qu", "title": "Review and Prospect: Deep Learning in Nuclear Magnetic Resonance\n  Spectroscopy", "comments": "8 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the concept of Deep Learning (DL) was formally proposed in 2006, it had\na major impact on academic research and industry. Nowadays, DL provides an\nunprecedented way to analyze and process data with demonstrated great results\nin computer vision, medical imaging, natural language processing, etc. In this\nMinireview, we summarize applications of DL in Nuclear Magnetic Resonance (NMR)\nspectroscopy and outline a perspective for DL as entirely new approaches that\nare likely to transform NMR spectroscopy into a much more efficient and\npowerful technique in chemistry and life science.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 05:13:20 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 07:17:09 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Chen", "Dicheng", ""], ["Wang", "Zi", ""], ["Guo", "Di", ""], ["Orekhov", "Vladislav", ""], ["Qu", "Xiaobo", ""]]}, {"id": "2001.04815", "submitter": "Wei Chen", "authors": "Wei Chen and Mark Fuge", "title": "Adaptive Expansion Bayesian Optimization for Unbounded Global\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is normally performed within fixed variable bounds. In\ncases like hyperparameter tuning for machine learning algorithms, setting the\nvariable bounds is not trivial. It is hard to guarantee that any fixed bounds\nwill include the true global optimum. We propose a Bayesian optimization\napproach that only needs to specify an initial search space that does not\nnecessarily include the global optimum, and expands the search space when\nnecessary. However, over-exploration may occur during the search space\nexpansion. Our method can adaptively balance exploration and exploitation in an\nexpanding space. Results on a range of synthetic test functions and an MLP\nhyperparameter optimization task show that the proposed method out-performs or\nat least as good as the current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 21:48:03 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chen", "Wei", ""], ["Fuge", "Mark", ""]]}, {"id": "2001.04825", "submitter": "Shahpar Yakhchi", "authors": "Shahpar Yakhchi (1), Amin Beheshti (1), Seyed Mohssen Ghafari (1),\n  Mehmet Orgun (1) ((1) Macquarie University- Sydney-Australia)", "title": "Enabling the Analysis of Personality Aspects in Recommender Systems", "comments": "This article contains 3 figures and 14 pages", "journal-ref": "Twenty-Third Pacific Asia Conference on Information Systems, China\n  2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Recommender Systems mainly focus on exploiting users' feedback,\ne.g., ratings, and reviews on common items to detect similar users. Thus, they\nmight fail when there are no common items of interest among users. We call this\nproblem the Data Sparsity With no Feedback on Common Items (DSW-n-FCI).\nPersonality-based recommender systems have shown a great success to identify\nsimilar users based on their personality types. However, there are only a few\npersonality-based recommender systems in the literature which either discover\npersonality explicitly through filling a questionnaire that is a tedious task,\nor neglect the impact of users' personal interests and level of knowledge, as a\nkey factor to increase recommendations' acceptance. Differently, we identifying\nusers' personality type implicitly with no burden on users and incorporate it\nalong with users' personal interests and their level of knowledge. Experimental\nresults on a real-world dataset demonstrate the effectiveness of our model,\nespecially in DSW-n-FCI situations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 23:02:07 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Yakhchi", "Shahpar", "", "Macquarie University- Sydney-Australia"], ["Beheshti", "Amin", "", "Macquarie University- Sydney-Australia"], ["Ghafari", "Seyed Mohssen", "", "Macquarie University- Sydney-Australia"], ["Orgun", "Mehmet", "", "Macquarie University- Sydney-Australia"]]}, {"id": "2001.04828", "submitter": "Kaushik Chakrabarti", "authors": "Kaushik Chakrabarti, Zhimin Chen, Siamak Shakeri, Guihong Cao, Surajit\n  Chaudhuri", "title": "TableQnA: Answering List Intent Queries With Web Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web contains a vast corpus of HTML tables. They can be used to provide\ndirect answers to many web queries. We focus on answering two classes of\nqueries with those tables: those seeking lists of entities (e.g., `cities in\ncalifornia') and those seeking superlative entities (e.g., `largest city in\ncalifornia'). The main challenge is to achieve high precision with significant\ncoverage. Existing approaches train machine learning models to select the\nanswer from the candidates; they rely on textual match features between the\nquery and the content of the table along with features capturing table\nquality/importance. These features alone are inadequate for achieving the above\ngoals. Our main insight is that we can improve precision by (i) first\nextracting intent (structured information) from the query for the above query\nclasses and (ii) then performing structure-aware matching (instead of just\ntextual matching) between the extracted intent and the candidates to select the\nanswer. We model (i) as a sequence tagging task. We leverage state-of-the-art\ndeep neural network models with word embeddings. The model requires large scale\ntraining data which is expensive to obtain via manual labeling; we therefore\ndevelop a novel method to automatically generate the training data. For (ii),\nwe develop novel features to compute structure-aware match and train a machine\nlearning model. Our experiments on real-life web search queries show that (i)\nour intent extractor for list and superlative intent queries has significantly\nhigher precision and coverage compared with baseline approaches and (ii) our\ntable answer selector significantly outperforms the state-of-the-art baseline\napproach. This technology has been used in production by Microsoft's Bing\nsearch engine since 2016.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 01:43:54 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Chakrabarti", "Kaushik", ""], ["Chen", "Zhimin", ""], ["Shakeri", "Siamak", ""], ["Cao", "Guihong", ""], ["Chaudhuri", "Surajit", ""]]}, {"id": "2001.04829", "submitter": "Gavin Graham", "authors": "Gavin H. Graham and Yan Chen", "title": "Bayesian Inversion Of Generative Models For Geologic Storage Of Carbon\n  Dioxide", "comments": "Submitted to the Machine Learning and the Physical Sciences Workshop\n  (NeurIPS 2019), Vancouver, Canada. 5 pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carbon capture and storage (CCS) can aid decarbonization of the atmosphere to\nlimit further global temperature increases. A framework utilizing unsupervised\nlearning is used to generate a range of subsurface geologic volumes to\ninvestigate potential sites for long-term storage of carbon dioxide. Generative\nadversarial networks are used to create geologic volumes, with a further neural\nnetwork used to sample the posterior distribution of a trained Generator\nconditional to sparsely sampled physical measurements. These generative models\nare further conditioned to historic dynamic fluid flow data through Bayesian\ninversion to improve the resolution of the forecast of the storage capacity of\ninjected carbon dioxide.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:09:27 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Graham", "Gavin H.", ""], ["Chen", "Yan", ""]]}, {"id": "2001.04830", "submitter": "Shoujin Wang", "authors": "Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, Mehmet\n  Orgun", "title": "Sequential Recommender Systems: Challenges, Progress and Prospects", "comments": "IJCAI-2019 Survey Track Paper", "journal-ref": null, "doi": "10.24963/ijcai.2019/883", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging topic of sequential recommender systems has attracted increasing\nattention in recent years.Different from the conventional recommender systems\nincluding collaborative filtering and content-based filtering, SRSs try to\nunderstand and model the sequential user behaviors, the interactions between\nusers and items, and the evolution of users preferences and item popularity\nover time. SRSs involve the above aspects for more precise characterization of\nuser contexts, intent and goals, and item consumption trend, leading to more\naccurate, customized and dynamic recommendations.In this paper, we provide a\nsystematic review on SRSs.We first present the characteristics of SRSs, and\nthen summarize and categorize the key challenges in this research area,\nfollowed by the corresponding research progress consisting of the most recent\nand representative developments on this topic.Finally, we discuss the important\nresearch directions in this vibrant area.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 05:12:28 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Wang", "Shoujin", ""], ["Hu", "Liang", ""], ["Wang", "Yan", ""], ["Cao", "Longbing", ""], ["Sheng", "Quan Z.", ""], ["Orgun", "Mehmet", ""]]}, {"id": "2001.04831", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza Pereira Moreira", "title": "CHAMELEON: A Deep Learning Meta-Architecture for News Recommender\n  Systems [Phd. Thesis]", "comments": "Phd. Thesis presented on Dec. 09, 2019 to the Instituto Tecnol\\'ogico\n  de Aeron\\'autica (ITA), in partial fulfillment of the requirements for the\n  degree of Doctor of Science in the Graduate Program of Electronics and\n  Computing Engineering, Field of Informatics", "journal-ref": null, "doi": null, "report-no": "DCTA/ITA/TD-035/2019", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems (RS) have became a popular research topic and, since\n2016, Deep Learning methods and techniques have been increasingly explored in\nthis area. News RS are aimed to personalize users experiences and help them\ndiscover relevant articles from a large and dynamic search space. The main\ncontribution of this research was named CHAMELEON, a Deep Learning\nmeta-architecture designed to tackle the specific challenges of news\nrecommendation. It consists of a modular reference architecture which can be\ninstantiated using different neural building blocks. As information about\nusers' past interactions is scarce in the news domain, the user context can be\nleveraged to deal with the user cold-start problem. Articles' content is also\nimportant to tackle the item cold-start problem. Additionally, the temporal\ndecay of items (articles) relevance is very accelerated in the news domain.\nFurthermore, external breaking events may temporally attract global readership\nattention, a phenomenon generally known as concept drift in machine learning.\nAll those characteristics are explicitly modeled on this research by a\ncontextual hybrid session-based recommendation approach using Recurrent Neural\nNetworks. The task addressed by this research is session-based news\nrecommendation, i.e., next-click prediction using only information available in\nthe current user session. A method is proposed for a realistic temporal offline\nevaluation of such task, replaying the stream of user clicks and fresh articles\nbeing continuously published in a news portal. Experiments performed with two\nlarge datasets have shown the effectiveness of the CHAMELEON for news\nrecommendation on many quality factors such as accuracy, item coverage,\nnovelty, and reduced item cold-start problem, when compared to other\ntraditional and state-of-the-art session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 13:40:56 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moreira", "Gabriel de Souza Pereira", ""]]}, {"id": "2001.04832", "submitter": "Sami Khenissi", "authors": "Sami Khenissi and Olfa Nasraoui", "title": "Modeling and Counteracting Exposure Bias in Recommender Systems", "comments": "9 figures and one table. The paper has 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What we discover and see online, and consequently our opinions and decisions,\nare becoming increasingly affected by automated machine learned predictions.\nSimilarly, the predictive accuracy of learning machines heavily depends on the\nfeedback data that we provide them. This mutual influence can lead to\nclosed-loop interactions that may cause unknown biases which can be exacerbated\nafter several iterations of machine learning predictions and user feedback.\nMachine-caused biases risk leading to undesirable social effects ranging from\npolarization to unfairness and filter bubbles.\n  In this paper, we study the bias inherent in widely used recommendation\nstrategies such as matrix factorization. Then we model the exposure that is\nborne from the interaction between the user and the recommender system and\npropose new debiasing strategies for these systems.\n  Finally, we try to mitigate the recommendation system bias by engineering\nsolutions for several state of the art recommender system models.\n  Our results show that recommender systems are biased and depend on the prior\nexposure of the user. We also show that the studied bias iteratively decreases\ndiversity in the output recommendations. Our debiasing method demonstrates the\nneed for alternative recommendation strategies that take into account the\nexposure process in order to reduce bias.\n  Our research findings show the importance of understanding the nature of and\ndealing with bias in machine learning models such as recommender systems that\ninteract directly with humans, and are thus causing an increasing influence on\nhuman discovery and decision making\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 00:12:34 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Khenissi", "Sami", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "2001.04833", "submitter": "L\\'eonard Torossian", "authors": "L\\'eonard Torossian, Victor Picheny, and Nicolas Durrande", "title": "Bayesian Quantile and Expectile Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is widely used to optimise stochastic black box\nfunctions. While most strategies are focused on optimising conditional\nexpectations, a large variety of applications require risk-averse decisions and\nalternative criteria accounting for the distribution tails need to be\nconsidered. In this paper, we propose new variational models for Bayesian\nquantile and expectile regression that are well-suited for heteroscedastic\nsettings. Our models consist of two latent Gaussian processes accounting\nrespectively for the conditional quantile (or expectile) and variance that are\nchained through asymmetric likelihood functions. Furthermore, we propose two\nBayesian optimisation strategies, either derived from a GP-UCB or Thompson\nsampling, that are tailored to such models and that can accommodate large\nbatches of points. As illustrated in the experimental section, the proposed\napproach clearly outperforms the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:51:21 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Torossian", "L\u00e9onard", ""], ["Picheny", "Victor", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2001.04835", "submitter": "Maarten Bieshaar", "authors": "Kristina Scharei, Florian Heidecker, Maarten Bieshaar", "title": "Knowledge Representations in Technical Systems -- A Taxonomy", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent usage of technical systems in human-centric environments leads to\nthe question, how to teach technical systems, e.g., robots, to understand,\nlearn, and perform tasks desired by the human. Therefore, an accurate\nrepresentation of knowledge is essential for the system to work as expected.\nThis article mainly gives insight into different knowledge representation\ntechniques and their categorization into various problem domains in artificial\nintelligence. Additionally, applications of presented knowledge representations\nare introduced in everyday robotics tasks. By means of the provided taxonomy,\nthe search for a proper knowledge representation technique regarding a specific\nproblem should be facilitated.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:00:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 07:07:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Scharei", "Kristina", ""], ["Heidecker", "Florian", ""], ["Bieshaar", "Maarten", ""]]}, {"id": "2001.04841", "submitter": "Song Cheng", "authors": "Song Cheng, Qi Liu, Enhong Chen", "title": "Domain Adaption for Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of online education system, knowledge tracing\nwhich aims at predicting students' knowledge state is becoming a critical and\nfundamental task in personalized education. Traditionally, existing methods are\ndomain-specified. However, there are a larger number of domains (e.g.,\nsubjects, schools) in the real world and the lacking of data in some domains,\nhow to utilize the knowledge and information in other domains to help train a\nknowledge tracing model for target domains is increasingly important. We refer\nto this problem as domain adaptation for knowledge tracing (DAKT) which\ncontains two aspects: (1) how to achieve great knowledge tracing performance in\neach domain. (2) how to transfer good performed knowledge tracing model between\ndomains. To this end, in this paper, we propose a novel adaptable framework,\nnamely adaptable knowledge tracing (AKT) to address the DAKT problem.\nSpecifically, for the first aspect, we incorporate the educational\ncharacteristics (e.g., slip, guess, question texts) based on the deep knowledge\ntracing (DKT) to obtain a good performed knowledge tracing model. For the\nsecond aspect, we propose and adopt three domain adaptation processes. First,\nwe pre-train an auto-encoder to select useful source instances for target model\ntraining. Second, we minimize the domain-specific knowledge state distribution\ndiscrepancy under maximum mean discrepancy (MMD) measurement to achieve domain\nadaptation. Third, we adopt fine-tuning to deal with the problem that the\noutput dimension of source and target domain are different to make the model\nsuitable for target domains. Extensive experimental results on two private\ndatasets and seven public datasets clearly prove the effectiveness of AKT for\ngreat knowledge tracing performance and its superior transferable ability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:04:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Cheng", "Song", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "2001.04850", "submitter": "Kimessha Paupamah", "authors": "Kimessha Paupamah, Steven James, Richard Klein", "title": "Quantisation and Pruning for Neural Network Compression and\n  Regularisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically too computationally expensive to run in\nreal-time on consumer-grade hardware and low-powered devices. In this paper, we\ninvestigate reducing the computational and memory requirements of neural\nnetworks through network pruning and quantisation. We examine their efficacy on\nlarge networks like AlexNet compared to recent compact architectures:\nShuffleNet and MobileNet. Our results show that pruning and quantisation\ncompresses these networks to less than half their original size and improves\ntheir efficiency, particularly on MobileNet with a 7x speedup. We also\ndemonstrate that pruning, in addition to reducing the number of parameters in a\nnetwork, can aid in the correction of overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 15:22:34 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Paupamah", "Kimessha", ""], ["James", "Steven", ""], ["Klein", "Richard", ""]]}, {"id": "2001.04872", "submitter": "Peter Sorrenson", "authors": "Peter Sorrenson, Carsten Rother, Ullrich K\\\"othe", "title": "Disentanglement by Nonlinear ICA with General Incompressible-flow\n  Networks (GIN)", "comments": "23 pages, 15 figures, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question of representation learning asks under which conditions it\nis possible to reconstruct the true latent variables of an arbitrarily complex\ngenerative process. Recent breakthrough work by Khemakhem et al. (2019) on\nnonlinear ICA has answered this question for a broad class of conditional\ngenerative processes. We extend this important result in a direction relevant\nfor application to real-world data. First, we generalize the theory to the case\nof unknown intrinsic problem dimension and prove that in some special (but not\nvery restrictive) cases, informative latent variables will be automatically\nseparated from noise by an estimating model. Furthermore, the recovered\ninformative latent variables will be in one-to-one correspondence with the true\nlatent variables of the generating process, up to a trivial component-wise\ntransformation. Second, we introduce a modification of the RealNVP invertible\nneural network architecture (Dinh et al. (2016)) which is particularly suitable\nfor this type of problem: the General Incompressible-flow Network (GIN).\nExperiments on artificial data and EMNIST demonstrate that theoretical\npredictions are indeed verified in practice. In particular, we provide a\ndetailed set of exactly 22 informative latent variables extracted from EMNIST.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:25:08 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Sorrenson", "Peter", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2001.04878", "submitter": "Lior Wolf", "authors": "Etai Littwin, Lior Wolf", "title": "On the Convex Behavior of Deep Neural Networks in Relation to the\n  Layers' Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hessian of neural networks can be decomposed into a sum of two matrices:\n(i) the positive semidefinite generalized Gauss-Newton matrix G, and (ii) the\nmatrix H containing negative eigenvalues. We observe that for wider networks,\nminimizing the loss with the gradient descent optimization maneuvers through\nsurfaces of positive curvatures at the start and end of training, and close to\nzero curvatures in between. In other words, it seems that during crucial parts\nof the training process, the Hessian in wide networks is dominated by the\ncomponent G. To explain this phenomenon, we show that when initialized using\ncommon methodologies, the gradients of over-parameterized networks are\napproximately orthogonal to H, such that the curvature of the loss surface is\nstrictly positive in the direction of the gradient.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:30:01 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Littwin", "Etai", ""], ["Wolf", "Lior", ""]]}, {"id": "2001.04879", "submitter": "C. Estelle Smith", "authors": "C. Estelle Smith, Bowen Yu, Anjali Srivastava, Aaron Halfaker, Loren\n  Terveen, Haiyi Zhu", "title": "Keeping Community in the Loop: Understanding Wikipedia Stakeholder\n  Values for Machine Learning-Based Systems", "comments": "10 pages, 1 table, accepted paper to CHI 2020 conference", "journal-ref": null, "doi": "10.1145/3313831.3376783", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  On Wikipedia, sophisticated algorithmic tools are used to assess the quality\nof edits and take corrective actions. However, algorithms can fail to solve the\nproblems they were designed for if they conflict with the values of communities\nwho use them. In this study, we take a Value-Sensitive Algorithm Design\napproach to understanding a community-created and -maintained machine\nlearning-based algorithm called the Objective Revision Evaluation System\n(ORES)---a quality prediction system used in numerous Wikipedia applications\nand contexts. Five major values converged across stakeholder groups that ORES\n(and its dependent applications) should: (1) reduce the effort of community\nmaintenance, (2) maintain human judgement as the final authority, (3) support\ndiffering peoples' differing workflows, (4) encourage positive engagement with\ndiverse editor groups, and (5) establish trustworthiness of people and\nalgorithms within the community. We reveal tensions between these values and\ndiscuss implications for future research to improve algorithms like ORES.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:30:25 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Smith", "C. Estelle", ""], ["Yu", "Bowen", ""], ["Srivastava", "Anjali", ""], ["Halfaker", "Aaron", ""], ["Terveen", "Loren", ""], ["Zhu", "Haiyi", ""]]}, {"id": "2001.04889", "submitter": "Lingbo Liu", "authors": "Lingbo Liu and Jingwen Chen and Hefeng Wu and Jiajie Zhen and Guanbin\n  Li and Liang Lin", "title": "Physical-Virtual Collaboration Modeling for Intra-and Inter-Station\n  Metro Ridership Prediction", "comments": "This paper has been accepted by IEEE Transactions on Intelligent\n  Transportation Systems (TITS). Our code and benchmarks are available at\n  https://github.com/HCPLab-SYSU/PVCGN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the widespread applications in real-world scenarios, metro ridership\nprediction is a crucial but challenging task in intelligent transportation\nsystems. However, conventional methods either ignore the topological\ninformation of metro systems or directly learn on physical topology, and cannot\nfully explore the patterns of ridership evolution. To address this problem, we\nmodel a metro system as graphs with various topologies and propose a unified\nPhysical-Virtual Collaboration Graph Network (PVCGN), which can effectively\nlearn the complex ridership patterns from the tailor-designed graphs.\nSpecifically, a physical graph is directly built based on the realistic\ntopology of the studied metro system, while a similarity graph and a\ncorrelation graph are built with virtual topologies under the guidance of the\ninter-station passenger flow similarity and correlation. These complementary\ngraphs are incorporated into a Graph Convolution Gated Recurrent Unit (GC-GRU)\nfor spatial-temporal representation learning. Further, a Fully-Connected Gated\nRecurrent Unit (FC-GRU) is also applied to capture the global evolution\ntendency. Finally, we develop a Seq2Seq model with GC-GRU and FC-GRU to\nforecast the future metro ridership sequentially. Extensive experiments on two\nlarge-scale benchmarks (e.g., Shanghai Metro and Hangzhou Metro) well\ndemonstrate the superiority of our PVCGN for station-level metro ridership\nprediction. Moreover, we apply the proposed PVCGN to address the online\norigin-destination (OD) ridership prediction and the experiment results show\nthe universality of our method. Our code and benchmarks are available at\nhttps://github.com/HCPLab-SYSU/PVCGN.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:47:54 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 03:17:45 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 04:24:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Liu", "Lingbo", ""], ["Chen", "Jingwen", ""], ["Wu", "Hefeng", ""], ["Zhen", "Jiajie", ""], ["Li", "Guanbin", ""], ["Lin", "Liang", ""]]}, {"id": "2001.04893", "submitter": "Inseok Hwang", "authors": "Inseok Hwang, Jinho Lee, Frank Liu, Minsik Cho", "title": "SimEx: Express Prediction of Inter-dataset Similarity by a Fleet of\n  Autoencoders", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing the similarity between sets of data has a number of positive\nimplications in training an effective model, such as assisting an informed\nselection out of known datasets favorable to model transfer or data\naugmentation problems with an unknown dataset. Common practices to estimate the\nsimilarity between data include comparing in the original sample space,\ncomparing in the embedding space from a model performing a certain task, or\nfine-tuning a pretrained model with different datasets and evaluating the\nperformance changes therefrom. However, these practices would suffer from\nshallow comparisons, task-specific biases, or extensive time and computations\nrequired to perform comparisons. We present SimEx, a new method for early\nprediction of inter-dataset similarity using a set of pretrained autoencoders\neach of which is dedicated to reconstructing a specific part of known data.\nSpecifically, our method takes unknown data samples as input to those\npretrained autoencoders, and evaluate the difference between the reconstructed\noutput samples against their original input samples. Our intuition is that, the\nmore similarity exists between the unknown data samples and the part of known\ndata that an autoencoder was trained with, the better chances there could be\nthat this autoencoder makes use of its trained knowledge, reconstructing output\nsamples closer to the originals. We demonstrate that our method achieves more\nthan 10x speed-up in predicting inter-dataset similarity compared to common\nsimilarity-estimating practices. We also demonstrate that the inter-dataset\nsimilarity estimated by our method is well-correlated with common practices and\noutperforms the baselines approaches of comparing at sample- or\nembedding-spaces, without newly training anything at the comparison time.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:52:50 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Hwang", "Inseok", ""], ["Lee", "Jinho", ""], ["Liu", "Frank", ""], ["Cho", "Minsik", ""]]}, {"id": "2001.04907", "submitter": "Dmitry Krotov", "authors": "Chaitanya K. Ryali, John J. Hopfield, Leopold Grinberg, Dmitry Krotov", "title": "Bio-Inspired Hashing for Unsupervised Similarity Search", "comments": "Accepted for publication in ICML 2020", "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2020, pp.8739-8750", "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fruit fly Drosophila's olfactory circuit has inspired a new locality\nsensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH\nalgorithms that produce low dimensional hash codes, FlyHash produces sparse\nhigh-dimensional hash codes and has also been shown to have superior empirical\nperformance compared to classical LSH algorithms in similarity search. However,\nFlyHash uses random projections and cannot learn from data. Building on\ninspiration from FlyHash and the ubiquity of sparse expansive representations\nin neurobiology, our work proposes a novel hashing algorithm BioHash that\nproduces sparse high dimensional hash codes in a data-driven manner. We show\nthat BioHash outperforms previously published benchmarks for various hashing\nmethods. Since our learning algorithm is based on a local and biologically\nplausible synaptic plasticity rule, our work provides evidence for the proposal\nthat LSH might be a computational reason for the abundance of sparse expansive\nmotifs in a variety of biological systems. We also propose a convolutional\nvariant BioConvHash that further improves performance. From the perspective of\ncomputer science, BioHash and BioConvHash are fast, scalable and yield\ncompressed binary representations that are useful for similarity search.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:04:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:29:56 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ryali", "Chaitanya K.", ""], ["Hopfield", "John J.", ""], ["Grinberg", "Leopold", ""], ["Krotov", "Dmitry", ""]]}, {"id": "2001.04909", "submitter": "Jonathan Brophy", "authors": "Jonathan Brophy and Daniel Lowd", "title": "EGGS: A Flexible Approach to Relational Modeling of Social Network Spam", "comments": "10 pages, 6 figures, 5 tables. STARAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networking websites face a constant barrage of spam, unwanted messages\nthat distract, annoy, and even defraud honest users. These messages tend to be\nvery short, making them difficult to identify in isolation. Furthermore,\nspammers disguise their messages to look legitimate, tricking users into\nclicking on links and tricking spam filters into tolerating their malicious\nbehavior. Thus, some spam filters examine relational structure in the domain,\nsuch as connections among users and messages, to better identify deceptive\ncontent. However, even when it is used, relational structure is often exploited\nin an incomplete or ad hoc manner. In this paper, we present Extended\nGroup-based Graphical models for Spam (EGGS), a general-purpose method for\nclassifying spam in online social networks. Rather than labeling each message\nindependently, we group related messages together when they have the same\nauthor, the same content, or other domain-specific connections. To reason about\nrelated messages, we combine two popular methods: stacked graphical learning\n(SGL) and probabilistic graphical models (PGM). Both methods capture the idea\nthat messages are more likely to be spammy when related messages are also\nspammy, but they do so in different ways; SGL uses sequential classifier\npredictions and PGMs use probabilistic inference. We apply our method to four\ndifferent social network domains. EGGS is more accurate than an independent\nmodel in most experimental settings, especially when the correct label is\nuncertain. For the PGM implementation, we compare Markov logic networks to\nprobabilistic soft logic and find that both work well with neither one\ndominating, and the combination of SGL and PGMs usually performs better than\neither on its own.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:06:13 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 22:10:00 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Brophy", "Jonathan", ""], ["Lowd", "Daniel", ""]]}, {"id": "2001.04918", "submitter": "Burak \\c{C}akmak", "authors": "Burak \\c{C}akmak and Manfred Opper", "title": "Analysis of Bayesian Inference Algorithms by the Dynamical Functional\n  Approach", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ab8ff4", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the dynamics of an algorithm for approximate inference with large\nGaussian latent variable models in a student-teacher scenario. To model\nnontrivial dependencies between the latent variables, we assume random\ncovariance matrices drawn from rotation invariant ensembles. For the case of\nperfect data-model matching, the knowledge of static order parameters derived\nfrom the replica method allows us to obtain efficient algorithmic updates in\nterms of matrix-vector multiplications with a fixed matrix. Using the dynamical\nfunctional approach, we obtain an exact effective stochastic process in the\nthermodynamic limit for a single node. From this, we obtain closed-form\nexpressions for the rate of the convergence. Analytical results are excellent\nagreement with simulations of single instances of large models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:22:02 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["\u00c7akmak", "Burak", ""], ["Opper", "Manfred", ""]]}, {"id": "2001.04932", "submitter": "Michael Fischer", "authors": "Michael H. Fischer, Richard R. Yang, Monica S. Lam", "title": "ImagineNet: Restyling Apps Using Neural Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents ImagineNet, a tool that uses a novel neural style\ntransfer model to enable end-users and app developers to restyle GUIs using an\nimage of their choice. Former neural style transfer techniques are inadequate\nfor this application because they produce GUIs that are illegible and hence\nnonfunctional. We propose a neural solution by adding a new loss term to the\noriginal formulation, which minimizes the squared error in the uncentered\ncross-covariance of features from different levels in a CNN between the style\nand output images. ImagineNet retains the details of GUIs, while transferring\nthe colors and textures of the art. We presented GUIs restyled with ImagineNet\nas well as other style transfer techniques to 50 evaluators and all preferred\nthose of ImagineNet. We show how ImagineNet can be used to restyle (1) the\ngraphical assets of an app, (2) an app with user-supplied content, and (3) an\napp with dynamically generated GUIs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:47:50 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:23:40 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Fischer", "Michael H.", ""], ["Yang", "Richard R.", ""], ["Lam", "Monica S.", ""]]}, {"id": "2001.04935", "submitter": "Roei Schuster", "authors": "Roei Schuster, Tal Schuster, Yoav Meri, Vitaly Shmatikov", "title": "Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning", "comments": "Accepted at IEEE S&P 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings, i.e., low-dimensional vector representations such as GloVe\nand SGNS, encode word \"meaning\" in the sense that distances between words'\nvectors correspond to their semantic proximity. This enables transfer learning\nof semantics for a variety of natural language processing tasks.\n  Word embeddings are typically trained on large public corpora such as\nWikipedia or Twitter. We demonstrate that an attacker who can modify the corpus\non which the embedding is trained can control the \"meaning\" of new and existing\nwords by changing their locations in the embedding space. We develop an\nexplicit expression over corpus features that serves as a proxy for distance\nbetween words and establish a causative relationship between its values and\nembedding distances. We then show how to use this relationship for two\nadversarial objectives: (1) make a word a top-ranked neighbor of another word,\nand (2) move a word from one semantic cluster to another.\n  An attack on the embedding can affect diverse downstream tasks, demonstrating\nfor the first time the power of data poisoning in transfer learning scenarios.\nWe use this attack to manipulate query expansion in information retrieval\nsystems such as resume search, make certain names more or less visible to named\nentity recognition models, and cause new words to be translated to a particular\ntarget word regardless of the language. Finally, we show how the attacker can\ngenerate linguistically likely corpus modifications, thus fooling defenses that\nattempt to filter implausible sentences from the corpus using a language model.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:48:52 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Schuster", "Roei", ""], ["Schuster", "Tal", ""], ["Meri", "Yoav", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2001.04942", "submitter": "David Barber", "authors": "David Barber", "title": "Private Machine Learning via Randomised Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:56:16 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 19:13:28 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Barber", "David", ""]]}, {"id": "2001.04958", "submitter": "Jiahao Ding", "authors": "Jiahao Ding, Xinyue Zhang, Xiaohuan Li, Junyi Wang, Rong Yu, Miao Pan", "title": "Differentially Private and Fair Classification via Calibrated Functional\n  Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is increasingly becoming a powerful tool to make decisions\nin a wide variety of applications, such as medical diagnosis and autonomous\ndriving. Privacy concerns related to the training data and unfair behaviors of\nsome decisions with regard to certain attributes (e.g., sex, race) are becoming\nmore critical. Thus, constructing a fair machine learning model while\nsimultaneously providing privacy protection becomes a challenging problem. In\nthis paper, we focus on the design of classification model with fairness and\ndifferential privacy guarantees by jointly combining functional mechanism and\ndecision boundary fairness. In order to enforce $\\epsilon$-differential privacy\nand fairness, we leverage the functional mechanism to add different amounts of\nLaplace noise regarding different attributes to the polynomial coefficients of\nthe objective function in consideration of fairness constraint. We further\npropose an utility-enhancement scheme, called relaxed functional mechanism by\nadding Gaussian noise instead of Laplace noise, hence achieving\n$(\\epsilon,\\delta)$-differential privacy. Based on the relaxed functional\nmechanism, we can design $(\\epsilon,\\delta)$-differentially private and fair\nclassification model. Moreover, our theoretical analysis and empirical results\ndemonstrate that our two approaches achieve both fairness and differential\nprivacy while preserving good utility and outperform the state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:33:19 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 18:42:17 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Ding", "Jiahao", ""], ["Zhang", "Xinyue", ""], ["Li", "Xiaohuan", ""], ["Wang", "Junyi", ""], ["Yu", "Rong", ""], ["Pan", "Miao", ""]]}, {"id": "2001.04959", "submitter": "Alexander Gorban", "authors": "Alexander N. Gorban, Valery A. Makarov, Ivan Y. Tyukin", "title": "High--Dimensional Brain in a High-Dimensional World: Blessing of\n  Dimensionality", "comments": "18 pages, 5 figures", "journal-ref": "Entropy 2020, 22(1), 82", "doi": "10.3390/e22010082", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-dimensional data and high-dimensional representations of reality are\ninherent features of modern Artificial Intelligence systems and applications of\nmachine learning. The well-known phenomenon of the \"curse of dimensionality\"\nstates: many problems become exponentially difficult in high dimensions.\nRecently, the other side of the coin, the \"blessing of dimensionality\", has\nattracted much attention. It turns out that generic high-dimensional datasets\nexhibit fairly simple geometric properties. Thus, there is a fundamental\ntradeoff between complexity and simplicity in high dimensional spaces. Here we\npresent a brief explanatory review of recent ideas, results and hypotheses\nabout the blessing of dimensionality and related simplifying effects relevant\nto machine learning and neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:40:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Makarov", "Valery A.", ""], ["Tyukin", "Ivan Y.", ""]]}, {"id": "2001.04974", "submitter": "Chuteng Zhou", "authors": "Chuteng Zhou, Prad Kadambi, Matthew Mattina, Paul N. Whatmough", "title": "Noisy Machines: Understanding Noisy Neural Networks and Enhancing\n  Robustness to Analog Hardware Errors Using Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has brought forth a wave of interest in computer\nhardware design to better meet the high demands of neural network inference. In\nparticular, analog computing hardware has been heavily motivated specifically\nfor accelerating neural networks, based on either electronic, optical or\nphotonic devices, which may well achieve lower power consumption than\nconventional digital electronics. However, these proposed analog accelerators\nsuffer from the intrinsic noise generated by their physical components, which\nmakes it challenging to achieve high accuracy on deep neural networks. Hence,\nfor successful deployment on analog accelerators, it is essential to be able to\ntrain deep neural networks to be robust to random continuous noise in the\nnetwork weights, which is a somewhat new challenge in machine learning. In this\npaper, we advance the understanding of noisy neural networks. We outline how a\nnoisy neural network has reduced learning capacity as a result of loss of\nmutual information between its input and output. To combat this, we propose\nusing knowledge distillation combined with noise injection during training to\nachieve more noise robust networks, which is demonstrated experimentally across\ndifferent networks and datasets, including ImageNet. Our method achieves models\nwith as much as two times greater noise tolerance compared with the previous\nbest attempts, which is a significant step towards making analog hardware\npractical for deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:59:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zhou", "Chuteng", ""], ["Kadambi", "Prad", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul N.", ""]]}, {"id": "2001.04980", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Rohan Kohli, Shrimai Prabhumoye", "title": "Modeling Product Search Relevance in e-Commerce", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of e-Commerce, online product search has emerged as a\npopular and effective paradigm for customers to find desired products and\nengage in online shopping. However, there is still a big gap between the\nproducts that customers really desire to purchase and relevance of products\nthat are suggested in response to a query from the customer. In this paper, we\npropose a robust way of predicting relevance scores given a search query and a\nproduct, using techniques involving machine learning, natural language\nprocessing and information retrieval. We compare conventional information\nretrieval models such as BM25 and Indri with deep learning models such as\nword2vec, sentence2vec and paragraph2vec. We share some of our insights and\nfindings from our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:17:55 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Kohli", "Rohan", ""], ["Prabhumoye", "Shrimai", ""]]}, {"id": "2001.05005", "submitter": "Thomas Pock", "authors": "Erich Kobler and Alexander Effland and Karl Kunisch and Thomas Pock", "title": "Total Deep Variation for Linear Inverse Problems", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse inverse problems in imaging can be cast as variational problems\ncomposed of a task-specific data fidelity term and a regularization term. In\nthis paper, we propose a novel learnable general-purpose regularizer exploiting\nrecent architectural design patterns from deep learning. We cast the learning\nproblem as a discrete sampled optimal control problem, for which we derive the\nadjoint state equations and an optimality condition. By exploiting the\nvariational structure of our approach, we perform a sensitivity analysis with\nrespect to the learned parameters obtained from different training datasets.\nMoreover, we carry out a nonlinear eigenfunction analysis, which reveals\ninteresting properties of the learned regularizer. We show state-of-the-art\nperformance for classical image restoration and medical image reconstruction\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:01:50 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 19:39:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kobler", "Erich", ""], ["Effland", "Alexander", ""], ["Kunisch", "Karl", ""], ["Pock", "Thomas", ""]]}, {"id": "2001.05009", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Soltani, Mahdi Jafari Siavoshani, Amir Hossein Jahangir", "title": "A Content-Based Deep Intrusion Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By growing the number of Internet users and the prevalence of web\napplications, we have to deal with very complex software and applications in\nthe network. This results in an increasing number of new vulnerabilities in the\nsystems, which consequently leads to an increase in the cyber and, in\nparticular, zero-day attacks. The cost of generating appropriate signatures for\nthese attacks is a potential motive for using machine learning-based\nmethodologies. Although there exist many studies on the use of learning-based\nmethods for attack detection, they generally use extracted features and\noverlook raw contents. This approach can lessen the performance of detection\nsystems against content-based attacks like SQL injection, Cross-site Scripting\n(XSS), and various viruses.\n  As a new paradigm, in this work, we propose a scheme, called deep intrusion\ndetection (DID) system that uses the pure content of traffic flows in addition\nto traffic metadata in the learning and detection phases. To this end, we\nemploy deep learning techniques recently developed in the machine learning\ncommunity. Due to the inherent nature of deep learning, it can process high\ndimensional data content and, accordingly, discover the sophisticated relations\nbetween the auto extracted features of the traffic. To evaluate the proposed\nDID system, we use the ISCX IDS 2017 dataset. The evaluation metrics, such as\nprecision and recall, reach $0.992$ and $0.998$, respectively, which show the\nhigh performance of the proposed DID method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:08:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Soltani", "Mahdi", ""], ["Siavoshani", "Mahdi Jafari", ""], ["Jahangir", "Amir Hossein", ""]]}, {"id": "2001.05012", "submitter": "Kobi Cohen", "authors": "Dor Livne and Kobi Cohen", "title": "PoPS: Policy Pruning and Shrinking for Deep Reinforcement Learning", "comments": "This paper has been accepted for publication in the IEEE Journal of\n  Selected Topics in Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of deep neural networks (DNNs) for function approximation\nin reinforcement learning has triggered the development of Deep Reinforcement\nLearning (DRL) algorithms in various fields, such as robotics, computer games,\nnatural language processing, computer vision, sensing systems, and wireless\nnetworking. Unfortunately, DNNs suffer from high computational cost and memory\nconsumption, which limits the use of DRL algorithms in systems with limited\nhardware resources. In recent years, pruning algorithms have demonstrated\nconsiderable success in reducing the redundancy of DNNs in classification\ntasks. However, existing algorithms suffer from a significant performance\nreduction in the DRL domain. In this paper, we develop the first effective\nsolution to the performance reduction problem of pruning in the DRL domain, and\nestablish a working algorithm, named Policy Pruning and Shrinking (PoPS), to\ntrain DRL models with strong performance while achieving a compact\nrepresentation of the DNN. The framework is based on a novel iterative policy\npruning and shrinking method that leverages the power of transfer learning when\ntraining the DRL model. We present an extensive experimental study that\ndemonstrates the strong performance of PoPS using the popular Cartpole, Lunar\nLander, Pong, and Pacman environments. Finally, we develop an open source\nsoftware for the benefit of researchers and developers in related fields.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:28:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Livne", "Dor", ""], ["Cohen", "Kobi", ""]]}, {"id": "2001.05014", "submitter": "Dimitrios Boursinos", "authors": "Dimitrios Boursinos, Xenofon Koutsoukos", "title": "Assurance Monitoring of Cyber-Physical Systems with Machine Learning\n  Components", "comments": "Accepted at TMCE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning components such as deep neural networks are used extensively\nin Cyber-Physical Systems (CPS). However, they may introduce new types of\nhazards that can have disastrous consequences and need to be addressed for\nengineering trustworthy systems. Although deep neural networks offer advanced\ncapabilities, they must be complemented by engineering methods and practices\nthat allow effective integration in CPS. In this paper, we investigate how to\nuse the conformal prediction framework for assurance monitoring of CPS with\nmachine learning components. In order to handle high-dimensional inputs in\nreal-time, we compute nonconformity scores using embedding representations of\nthe learned models. By leveraging conformal prediction, the approach provides\nwell-calibrated confidence and can allow monitoring that ensures a bounded\nsmall error rate while limiting the number of inputs for which an accurate\nprediction cannot be made. Empirical evaluation results using the German\nTraffic Sign Recognition Benchmark and a robot navigation dataset demonstrate\nthat the error rates are well-calibrated while the number of alarms is small.\nThe method is computationally efficient, and therefore, the approach is\npromising for assurance monitoring of CPS.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:34:51 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 22:59:01 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Boursinos", "Dimitrios", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2001.05017", "submitter": "Sagie Benaim", "authors": "Ori Press, Tomer Galanti, Sagie Benaim, Lior Wolf", "title": "Emerging Disentanglement in Auto-Encoder Based Unsupervised Image\n  Content Transfer", "comments": null, "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning to map, in an unsupervised way, between\ndomains A and B, such that the samples b in B contain all the information that\nexists in samples a in A and some additional information. For example, ignoring\nocclusions, B can be people with glasses, A people without, and the glasses,\nwould be the added information. When mapping a sample a from the first domain\nto the other domain, the missing information is replicated from an independent\nreference sample b in B. Thus, in the above example, we can create, for every\nperson without glasses a version with the glasses observed in any face image.\n  Our solution employs a single two-pathway encoder and a single decoder for\nboth domains. The common part of the two domains and the separate part are\nencoded as two vectors, and the separate part is fixed at zero for domain A.\nThe loss terms are minimal and involve reconstruction losses for the two\ndomains and a domain confusion term. Our analysis shows that under mild\nassumptions, this architecture, which is much simpler than the literature\nguided-translation methods, is enough to ensure disentanglement between the two\ndomains. We present convincing results in a few visual domains, such as\nno-glasses to glasses, adding facial hair based on a reference image, etc.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:36:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Press", "Ori", ""], ["Galanti", "Tomer", ""], ["Benaim", "Sagie", ""], ["Wolf", "Lior", ""]]}, {"id": "2001.05026", "submitter": "Sagie Benaim", "authors": "Lior Wolf, Sagie Benaim, Tomer Galanti", "title": "Unsupervised Learning of the Set of Local Maxima", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new form of unsupervised learning, whose input is a\nset of unlabeled points that are assumed to be local maxima of an unknown value\nfunction v in an unknown subset of the vector space. Two functions are learned:\n(i) a set indicator c, which is a binary classifier, and (ii) a comparator\nfunction h that given two nearby samples, predicts which sample has the higher\nvalue of the unknown function v. Loss terms are used to ensure that all\ntraining samples x are a local maxima of v, according to h and satisfy c(x)=1.\nTherefore, c and h provide training signals to each other: a point x' in the\nvicinity of x satisfies c(x)=-1 or is deemed by h to be lower in value than x.\nWe present an algorithm, show an example where it is more efficient to use\nlocal maxima as an indicator function than to employ conventional\nclassification, and derive a suitable generalization bound. Our experiments\nshow that the method is able to outperform one-class classification algorithms\nin the task of anomaly detection and also provide an additional signal that is\nextracted in a completely unsupervised way.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:56:36 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wolf", "Lior", ""], ["Benaim", "Sagie", ""], ["Galanti", "Tomer", ""]]}, {"id": "2001.05028", "submitter": "Dongrui Wu", "authors": "Ziang Liu and Dongrui Wu", "title": "Unsupervised Pool-Based Active Learning for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world machine learning applications, unlabeled data can be\neasily obtained, but it is very time-consuming and/or expensive to label them.\nSo, it is desirable to be able to select the optimal samples to label, so that\na good machine learning model can be trained from a minimum amount of labeled\ndata. Active learning (AL) has been widely used for this purpose. However, most\nexisting AL approaches are supervised: they train an initial model from a small\namount of labeled samples, query new samples based on the model, and then\nupdate the model iteratively. Few of them have considered the completely\nunsupervised AL problem, i.e., starting from zero, how to optimally select the\nvery first few samples to label, without knowing any label information at all.\nThis problem is very challenging, as no label information can be utilized. This\npaper studies unsupervised pool-based AL for linear regression problems. We\npropose a novel AL approach that considers simultaneously the informativeness,\nrepresentativeness, and diversity, three essential criteria in AL. Extensive\nexperiments on 14 datasets from various application domains, using three\ndifferent linear regression models (ridge regression, LASSO, and linear support\nvector regression), demonstrated the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:00:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Liu", "Ziang", ""], ["Wu", "Dongrui", ""]]}, {"id": "2001.05031", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Qiang Huang, Thomas Hain", "title": "Robust Speaker Recognition Using Speech Enhancement And Attention Model", "comments": "Acceptted by Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel architecture for speaker recognition is proposed by\ncascading speech enhancement and speaker processing. Its aim is to improve\nspeaker recognition performance when speech signals are corrupted by noise.\nInstead of individually processing speech enhancement and speaker recognition,\nthe two modules are integrated into one framework by a joint optimisation using\ndeep neural networks. Furthermore, to increase robustness against noise, a\nmulti-stage attention mechanism is employed to highlight the speaker related\nfeatures learned from context information in time and frequency domain. To\nevaluate speaker identification and verification performance of the proposed\napproach, we test it on the dataset of VoxCeleb1, one of mostly used benchmark\ndatasets. Moreover, the robustness of our proposed approach is also tested on\nVoxCeleb1 data when being corrupted by three types of interferences, general\nnoise, music, and babble, at different signal-to-noise ratio (SNR) levels. The\nobtained results show that the proposed approach using speech enhancement and\nmulti-stage attention models outperforms two strong baselines not using them in\nmost acoustic conditions in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:03:07 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 09:16:56 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Shi", "Yanpei", ""], ["Huang", "Qiang", ""], ["Hain", "Thomas", ""]]}, {"id": "2001.05050", "submitter": "Michela Paganini", "authors": "Michela Paganini, Jessica Forde", "title": "On Iterative Neural Network Pruning, Reinitialization, and the\n  Similarity of Masks", "comments": "8 pages, 8 figures, plus 5 appendices with additional figures and\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine how recently documented, fundamental phenomena in deep learning\nmodels subject to pruning are affected by changes in the pruning procedure.\nSpecifically, we analyze differences in the connectivity structure and learning\ndynamics of pruned models found through a set of common iterative pruning\ntechniques, to address questions of uniqueness of trainable, high-sparsity\nsub-networks, and their dependence on the chosen pruning method. In\nconvolutional layers, we document the emergence of structure induced by\nmagnitude-based unstructured pruning in conjunction with weight rewinding that\nresembles the effects of structured pruning. We also show empirical evidence\nthat weight stability can be automatically achieved through apposite pruning\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:11:19 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Paganini", "Michela", ""], ["Forde", "Jessica", ""]]}, {"id": "2001.05058", "submitter": "Diedre Carmo", "authors": "Diedre Carmo, Bruna Silva, Clarissa Yasuda, Let\\'icia Rittner and\n  Roberto Lotufo", "title": "Hippocampus Segmentation on Epilepsy and Alzheimer's Disease Studies\n  with Multiple Convolutional Neural Networks", "comments": "Code is available at https://github.com/dscarmo/e2dhipseg Published\n  in Heliyon:\n  https://www.sciencedirect.com/science/article/pii/S2405844021003315", "journal-ref": "Heliyon, Volume 7, Issue 2, 2021", "doi": "10.1016/j.heliyon.2021.e06226", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hippocampus segmentation on magnetic resonance imaging is of key importance\nfor the diagnosis, treatment decision and investigation of neuropsychiatric\ndisorders. Automatic segmentation is an active research field, with many recent\nmodels using deep learning. Most current state-of-the art hippocampus\nsegmentation methods train their methods on healthy or Alzheimer's disease\npatients from public datasets. This raises the question whether these methods\nare capable of recognizing the hippocampus on a different domain, that of\nepilepsy patients with hippocampus resection. In this paper we present a\nstate-of-the-art, open source, ready-to-use, deep learning based hippocampus\nsegmentation method. It uses an extended 2D multi-orientation approach, with\nautomatic pre-processing and orientation alignment. The methodology was\ndeveloped and validated using HarP, a public Alzheimer's disease hippocampus\nsegmentation dataset. We test this methodology alongside other recent deep\nlearning methods, in two domains: The HarP test set and an in-house epilepsy\ndataset, containing hippocampus resections, named HCUnicamp. We show that our\nmethod, while trained only in HarP, surpasses others from the literature in\nboth the HarP test set and HCUnicamp in Dice. Additionally, Results from\ntraining and testing in HCUnicamp volumes are also reported separately,\nalongside comparisons between training and testing in epilepsy and Alzheimer's\ndata and vice versa. Although current state-of-the-art methods, including our\nown, achieve upwards of 0.9 Dice in HarP, all tested methods, including our\nown, produced false positives in HCUnicamp resection regions, showing that\nthere is still room for improvement for hippocampus segmentation methods when\nresection is involved.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:57:46 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 21:23:29 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Carmo", "Diedre", ""], ["Silva", "Bruna", ""], ["Yasuda", "Clarissa", ""], ["Rittner", "Let\u00edcia", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2001.05065", "submitter": "Jacob Schrum", "authors": "Jake Gutierrez and Jacob Schrum", "title": "Generative Adversarial Network Rooms in Generative Graph Grammar\n  Dungeons for The Legend of Zelda", "comments": "Congress on Evolutionary Computation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have demonstrated their ability to\nlearn patterns in data and produce new exemplars similar to, but different\nfrom, their training set in several domains, including video games. However,\nGANs have a fixed output size, so creating levels of arbitrary size for a\ndungeon crawling game is difficult. GANs also have trouble encoding semantic\nrequirements that make levels interesting and playable. This paper combines a\nGAN approach to generating individual rooms with a graph grammar approach to\ncombining rooms into a dungeon. The GAN captures design principles of\nindividual rooms, but the graph grammar organizes rooms into a global layout\nwith a sequence of obstacles determined by a designer. Room data from The\nLegend of Zelda is used to train the GAN. This approach is validated by a user\nstudy, showing that GAN dungeons are as enjoyable to play as a level from the\noriginal game, and levels generated with a graph grammar alone. However, GAN\ndungeons have rooms considered more complex, and plain graph grammar's dungeons\nare considered least complex and challenging. Only the GAN approach creates an\nextensive supply of both layouts and rooms, where rooms span across the\nspectrum of those seen in the training set to new creations merging design\nprinciples from multiple rooms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:22:11 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 19:07:28 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gutierrez", "Jake", ""], ["Schrum", "Jacob", ""]]}, {"id": "2001.05070", "submitter": "Jingling Li", "authors": "Jingling Li, Yanchao Sun, Jiahao Su, Taiji Suzuki, Furong Huang", "title": "Understanding Generalization in Deep Learning via Tensor Methods", "comments": "9 pages (main paper), 42 pages (full version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks generalize well on unseen data though the number of\nparameters often far exceeds the number of training examples. Recently proposed\ncomplexity measures have provided insights to understanding the\ngeneralizability in neural networks from perspectives of PAC-Bayes, robustness,\noverparametrization, compression and so on. In this work, we advance the\nunderstanding of the relations between the network's architecture and its\ngeneralizability from the compression perspective. Using tensor analysis, we\npropose a series of intuitive, data-dependent and easily-measurable properties\nthat tightly characterize the compressibility and generalizability of neural\nnetworks; thus, in practice, our generalization bound outperforms the previous\ncompression-based ones, especially for neural networks using tensors as their\nweight kernels (e.g. CNNs). Moreover, these intuitive measurements provide\nfurther insights into designing neural network architectures with properties\nfavorable for better/guaranteed generalizability. Our experimental results\ndemonstrate that through the proposed measurable properties, our generalization\nerror bound matches the trend of the test error well. Our theoretical analysis\nfurther provides justifications for the empirical success and limitations of\nsome widely-used tensor-based compression approaches. We also discover the\nimprovements to the compressibility and robustness of current neural networks\nwhen incorporating tensor operations via our proposed layer-wise structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:26:57 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 03:38:01 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Li", "Jingling", ""], ["Sun", "Yanchao", ""], ["Su", "Jiahao", ""], ["Suzuki", "Taiji", ""], ["Huang", "Furong", ""]]}, {"id": "2001.05113", "submitter": "Daniel Wilke", "authors": "Dominic Kafka and Daniel N. Wilke", "title": "Resolving learning rates adaptively by locating Stochastic Non-Negative\n  Associated Gradient Projection Points using line searches", "comments": "29 pages, 11 figures, 3 tables, submitted to journal for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rates in stochastic neural network training are currently determined\na priori to training, using expensive manual or automated iterative tuning.\nThis study proposes gradient-only line searches to resolve the learning rate\nfor neural network training algorithms. Stochastic sub-sampling during training\ndecreases computational cost and allows the optimization algorithms to progress\nover local minima. However, it also results in discontinuous cost functions.\nMinimization line searches are not effective in this context, as they use a\nvanishing derivative (first order optimality condition), which often do not\nexist in a discontinuous cost function and therefore converge to\ndiscontinuities as opposed to minima from the data trends. Instead, we base\ncandidate solutions along a search direction purely on gradient information, in\nparticular by a directional derivative sign change from negative to positive (a\nNon-negative Associative Gradient Projection Point (NN- GPP)). Only considering\na sign change from negative to positive always indicates a minimum, thus\nNN-GPPs contain second order information. Conversely, a vanishing gradient is\npurely a first order condition, which may indicate a minimum, maximum or saddle\npoint. This insight allows the learning rate of an algorithm to be reliably\nresolved as the step size along a search direction, increasing convergence\nperformance and eliminating an otherwise expensive hyperparameter.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:08:07 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kafka", "Dominic", ""], ["Wilke", "Daniel N.", ""]]}, {"id": "2001.05119", "submitter": "Zan Gojcic", "authors": "Zan Gojcic, Caifa Zhou, Jan D. Wegner, Leonidas J. Guibas, Tolga\n  Birdal", "title": "Learning multiview 3D point cloud registration", "comments": "CVPR2020 - Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel, end-to-end learnable, multiview 3D point cloud\nregistration algorithm. Registration of multiple scans typically follows a\ntwo-stage pipeline: the initial pairwise alignment and the globally consistent\nrefinement. The former is often ambiguous due to the low overlap of neighboring\npoint clouds, symmetries and repetitive scene parts. Therefore, the latter\nglobal refinement aims at establishing the cyclic consistency across multiple\nscans and helps in resolving the ambiguous cases. In this paper we propose, to\nthe best of our knowledge, the first end-to-end algorithm for joint learning of\nboth parts of this two-stage problem. Experimental evaluation on well accepted\nbenchmark datasets shows that our approach outperforms the state-of-the-art by\na significant margin, while being end-to-end trainable and computationally less\ncostly. Moreover, we present detailed analysis and an ablation study that\nvalidate the novel components of our approach. The source code and pretrained\nmodels are publicly available under\nhttps://github.com/zgojcic/3D_multiview_reg.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:42:14 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:53:36 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Gojcic", "Zan", ""], ["Zhou", "Caifa", ""], ["Wegner", "Jan D.", ""], ["Guibas", "Leonidas J.", ""], ["Birdal", "Tolga", ""]]}, {"id": "2001.05130", "submitter": "Jordan Malof", "authors": "Fanjie Kong, Bohao Huang, Kyle Bradbury, Jordan M. Malof", "title": "The Synthinel-1 dataset: a collection of high resolution synthetic\n  overhead imagery for building segmentation", "comments": "Preprint of paper accepted for publication at Winter Conference on\n  Applications of Computer Vision (WACV) 2020", "journal-ref": "F. Kong, The Synthinel-1 dataset: a collection of high resolution\n  synthetic overhead imagery for building segmentation, 2020, IEEE Winter\n  Conference on Applications of Computer Vision (WACV)", "doi": "10.1109/wacv45572.2020.9093339", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning - namely convolutional neural networks (CNNs) - have\nyielded impressive performance for the task of building segmentation on large\noverhead (e.g., satellite) imagery benchmarks. However, these benchmark\ndatasets only capture a small fraction of the variability present in real-world\noverhead imagery, limiting the ability to properly train, or evaluate, models\nfor real-world application. Unfortunately, developing a dataset that captures\neven a small fraction of real-world variability is typically infeasible due to\nthe cost of imagery, and manual pixel-wise labeling of the imagery. In this\nwork we develop an approach to rapidly and cheaply generate large and diverse\nvirtual environments from which we can capture synthetic overhead imagery for\ntraining segmentation CNNs. Using this approach, generate and publicly-release\na collection of synthetic overhead imagery - termed Synthinel-1 with full\npixel-wise building labels. We use several benchmark dataset to demonstrate\nthat Synthinel-1 is consistently beneficial when used to augment real-world\ntraining imagery, especially when CNNs are tested on novel geographic locations\nor conditions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 04:30:45 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Kong", "Fanjie", ""], ["Huang", "Bohao", ""], ["Bradbury", "Kyle", ""], ["Malof", "Jordan M.", ""]]}, {"id": "2001.05137", "submitter": "Maryam Hashemi Miss", "authors": "Maryam Hashemi, Alireza Mirrashid, Aliasghar Beheshti Shirazi", "title": "Driver Safety Development Real Time Driver Drowsiness Detection System\n  Based on Convolutional Neural Network", "comments": "Hashemi, M., Mirrashid, A. & Beheshti Shirazi, A. Driver Safety\n  Development: Real-Time Driver Drowsiness Detection System Based on\n  Convolutional Neural Network. SN COMPUT. SCI. 1, 289 (2020).\n  https://doi.org/10.1007/s42979-020-00306-9", "journal-ref": null, "doi": "10.1007/s42979-020-00306-9", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the challenge of driver safety on the road and presents\na novel system for driver drowsiness detection. In this system, to detect the\nfalling sleep state of the driver as the sign of drowsiness, Convolutional\nNeural Networks (CNN) are used with regarding the two goals of real-time\napplication, including high accuracy and fastness. Three networks introduced as\na potential network for eye status classifcation in which one of them is a\nFully Designed Neural Network (FD-NN) and others use Transfer Learning in VGG16\nand VGG19 with extra designed layers (TL-VGG). Lack of an available and\naccurate eye dataset strongly feels in the area of eye closure detection.\nTherefore, a new comprehensive dataset proposed. The experimental results show\nthe high accuracy and low computational complexity of the eye closure\nestimation and the ability of the proposed framework on drowsiness detection.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:38:24 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 05:29:38 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 04:30:09 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hashemi", "Maryam", ""], ["Mirrashid", "Alireza", ""], ["Shirazi", "Aliasghar Beheshti", ""]]}, {"id": "2001.05140", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Haopeng Zhang, Congying Xia, Li Sun", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant graph neural networks (GNNs) over-rely on the graph links,\nseveral serious performance problems with which have been witnessed already,\ne.g., suspended animation problem and over-smoothing problem. What's more, the\ninherently inter-connected nature precludes parallelization within the graph,\nwhich becomes critical for large-sized graph, as memory constraints limit\nbatching across the nodes. In this paper, we will introduce a new graph neural\nnetwork, namely GRAPH-BERT (Graph based BERT), solely based on the attention\nmechanism without any graph convolution or aggregation operators. Instead of\nfeeding GRAPH-BERT with the complete large input graph, we propose to train\nGRAPH-BERT with sampled linkless subgraphs within their local contexts.\nGRAPH-BERT can be learned effectively in a standalone mode. Meanwhile, a\npre-trained GRAPH-BERT can also be transferred to other application tasks\ndirectly or with necessary fine-tuning if any supervised label information or\ncertain application oriented objective is available. We have tested the\neffectiveness of GRAPH-BERT on several graph benchmark datasets. Based the\npre-trained GRAPH-BERT with the node attribute reconstruction and structure\nrecovery tasks, we further fine-tune GRAPH-BERT on node classification and\ngraph clustering tasks specifically. The experimental results have demonstrated\nthat GRAPH-BERT can out-perform the existing GNNs in both the learning\neffectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:56:59 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:16:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""], ["Zhang", "Haopeng", ""], ["Xia", "Congying", ""], ["Sun", "Li", ""]]}, {"id": "2001.05142", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe, Tadashi Wadayama", "title": "Theoretical Interpretation of Learned Step Size in Deep-Unfolded\n  Gradient Descent", "comments": "12 pages, 12 figures, typos are fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding is a promising deep-learning technique in which an iterative\nalgorithm is unrolled to a deep network architecture with trainable parameters.\nIn the case of gradient descent algorithms, as a result of the training\nprocess, one often observes the acceleration of the convergence speed with\nlearned non-constant step size parameters whose behavior is not intuitive nor\ninterpretable from conventional theory. In this paper, we provide a theoretical\ninterpretation of the learned step size of deep-unfolded gradient descent\n(DUGD). We first prove that the training process of DUGD reduces not only the\nmean squared error loss but also the spectral radius related to the convergence\nrate. Next, we show that minimizing the upper bound of the spectral radius\nnaturally leads to the Chebyshev step which is a sequence of the step size\nbased on Chebyshev polynomials. The numerical experiments confirm that the\nChebyshev steps qualitatively reproduce the learned step size parameters in\nDUGD, which provides a plausible interpretation of the learned parameters.\nAdditionally, we show that the Chebyshev steps achieve the lower bound of the\nconvergence rate for the first-order method in a specific limit without\nlearning parameters or momentum terms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:58:07 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 11:27:52 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Takabe", "Satoshi", ""], ["Wadayama", "Tadashi", ""]]}, {"id": "2001.05166", "submitter": "Nupur Kumari", "authors": "Nupur Kumari, Siddarth R., Akash Rupela, Piyush Gupta, Balaji\n  Krishnamurthy", "title": "ShapeVis: High-dimensional Data Visualization at Scale", "comments": "Accepted at WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present ShapeVis, a scalable visualization technique for point cloud data\ninspired from topological data analysis. Our method captures the underlying\ngeometric and topological structure of the data in a compressed graphical\nrepresentation. Much success has been reported by the data visualization\ntechnique Mapper, that discreetly approximates the Reeb graph of a filter\nfunction on the data. However, when using standard dimensionality reduction\nalgorithms as the filter function, Mapper suffers from considerable\ncomputational cost. This makes it difficult to scale to high-dimensional data.\nOur proposed technique relies on finding a subset of points called landmarks\nalong the data manifold to construct a weighted witness-graph over it. This\ngraph captures the structural characteristics of the point cloud, and its\nweights are determined using a Finite Markov Chain. We further compress this\ngraph by applying induced maps from standard community detection algorithms.\nUsing techniques borrowed from manifold tearing, we prune and reinstate edges\nin the induced graph based on their modularity to summarize the shape of data.\nWe empirically demonstrate how our technique captures the structural\ncharacteristics of real and synthetic data sets. Further, we compare our\napproach with Mapper using various filter functions like t-SNE, UMAP, LargeVis\nand show that our algorithm scales to millions of data points while preserving\nthe quality of data visualization.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 07:59:13 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 16:12:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Kumari", "Nupur", ""], ["R.", "Siddarth", ""], ["Rupela", "Akash", ""], ["Gupta", "Piyush", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2001.05168", "submitter": "Hadi Mohaghegh Dolatabadi", "authors": "Hadi M. Dolatabadi and Sarah Erfani and Christopher Leckie", "title": "Invertible Generative Modeling using Linear Rational Splines", "comments": "Accepted to the 23rd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2020, Palermo, Sicily, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows attempt to model an arbitrary probability distribution\nthrough a set of invertible mappings. These transformations are required to\nachieve a tractable Jacobian determinant that can be used in high-dimensional\nscenarios. The first normalizing flow designs used coupling layer mappings\nbuilt upon affine transformations. The significant advantage of such models is\ntheir easy-to-compute inverse. Nevertheless, making use of affine\ntransformations may limit the expressiveness of such models. Recently,\ninvertible piecewise polynomial functions as a replacement for affine\ntransformations have attracted attention. However, these methods require\nsolving a polynomial equation to calculate their inverse. In this paper, we\nexplore using linear rational splines as a replacement for affine\ntransformations used in coupling layers. Besides having a straightforward\ninverse, inference and generation have similar cost and architecture in this\nmethod. Moreover, simulation results demonstrate the competitiveness of this\napproach's performance compared to existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:05:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 00:49:42 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 05:22:02 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 00:01:14 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dolatabadi", "Hadi M.", ""], ["Erfani", "Sarah", ""], ["Leckie", "Christopher", ""]]}, {"id": "2001.05171", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Xiong Zhang and Jonathan Engel and Sara Evensen and Yuliang Li and\n  \\c{C}a\\u{g}atay Demiralp and Wang-Chiew Tan", "title": "Teddy: A System for Interactive Review Analysis", "comments": "CHI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reviews are integral to e-commerce services and products. They contain a\nwealth of information about the opinions and experiences of users, which can\nhelp better understand consumer decisions and improve user experience with\nproducts and services. Today, data scientists analyze reviews by developing\nrules and models to extract, aggregate, and understand information embedded in\nthe review text. However, working with thousands of reviews, which are\ntypically noisy incomplete text, can be daunting without proper tools. Here we\nfirst contribute results from an interview study that we conducted with fifteen\ndata scientists who work with review text, providing insights into their\npractices and challenges. Results suggest data scientists need interactive\nsystems for many review analysis tasks. In response we introduce Teddy, an\ninteractive system that enables data scientists to quickly obtain insights from\nreviews and improve their extraction and modeling pipelines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:19:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhang", "Xiong", ""], ["Engel", "Jonathan", ""], ["Evensen", "Sara", ""], ["Li", "Yuliang", ""], ["Demiralp", "\u00c7a\u011fatay", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2001.05172", "submitter": "Cedric Fraces", "authors": "Cedric G. Fraces, Adrien Papaioannou, Hamdi Tchelepi", "title": "Physics Informed Deep Learning for Transport in Porous Media. Buckley\n  Leverett Problem", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new hybrid physics-based machine-learning approach to reservoir\nmodeling. The methodology relies on a series of deep adversarial neural network\narchitecture with physics-based regularization. The network is used to simulate\nthe dynamic behavior of physical quantities (i.e. saturation) subject to a set\nof governing laws (e.g. mass conservation) and corresponding boundary and\ninitial conditions. A residual equation is formed from the governing\npartial-differential equation and used as part of the training. Derivatives of\nthe estimated physical quantities are computed using automatic differentiation\nalgorithms. This allows the model to avoid overfitting, by reducing the\nvariance and permits extrapolation beyond the range of the training data\nincluding uncertainty implicitely derived from the distribution output of the\ngenerative adversarial networks. The approach is used to simulate a 2 phase\nimmiscible transport problem (Buckley Leverett). From a very limited dataset,\nthe model learns the parameters of the governing equation and is able to\nprovide an accurate physical solution, both in terms of shock and rarefaction.\nWe demonstrate how this method can be applied in the context of a forward\nsimulation for continuous problems. The use of these models for the inverse\nproblem is also presented, where the model simultaneously learns the physical\nlaws and determines key uncertainty subsurface parameters. The proposed\nmethodology is a simple and elegant way to instill physical knowledge to\nmachine-learning algorithms. This alleviates the two most significant\nshortcomings of machine-learning algorithms: the requirement for large datasets\nand the reliability of extrapolation. The principles presented in this paper\ncan be generalized in innumerable ways in the future and should lead to a new\nclass of algorithms to solve both forward and inverse physical problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:20:11 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Fraces", "Cedric G.", ""], ["Papaioannou", "Adrien", ""], ["Tchelepi", "Hamdi", ""]]}, {"id": "2001.05198", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang", "title": "Domain-Liftability of Relational Marginal Polytopes", "comments": "A preliminary version of a paper accepted to AISTATS 2020, presented\n  at the StarAI 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study computational aspects of relational marginal polytopes which are\nstatistical relational learning counterparts of marginal polytopes, well-known\nfrom probabilistic graphical models. Here, given some first-order logic\nformula, we can define its relational marginal statistic to be the fraction of\ngroundings that make this formula true in a given possible world. For a list of\nfirst-order logic formulas, the relational marginal polytope is the set of all\npoints that correspond to the expected values of the relational marginal\nstatistics that are realizable. In this paper, we study the following two\nproblems: (i) Do domain-liftability results for the partition functions of\nMarkov logic networks (MLNs) carry over to the problem of relational marginal\npolytope construction? (ii) Is the relational marginal polytope containment\nproblem hard under some plausible complexity-theoretic assumptions? Our\npositive results have consequences for lifted weight learning of MLNs. In\nparticular, we show that weight learning of MLNs is domain-liftable whenever\nthe computation of the partition function of the respective MLNs is\ndomain-liftable (this result has not been rigorously proven before).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 09:45:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""]]}, {"id": "2001.05202", "submitter": "Tianxiang Gao", "authors": "Tianxiang Gao, Songtao Lu, Jia Liu, Chris Chu", "title": "Randomized Bregman Coordinate Descent Methods for Non-Lipschitz\n  Optimization", "comments": "First draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new \\textit{randomized Bregman (block) coordinate descent}\n(RBCD) method for minimizing a composite problem, where the objective function\ncould be either convex or nonconvex, and the smooth part are freed from the\nglobal Lipschitz-continuous (partial) gradient assumption. Under the notion of\nrelative smoothness based on the Bregman distance, we prove that every limit\npoint of the generated sequence is a stationary point. Further, we show that\nthe iteration complexity of the proposed method is $O(n\\varepsilon^{-2})$ to\nachieve $\\epsilon$-stationary point, where $n$ is the number of blocks of\ncoordinates. If the objective is assumed to be convex, the iteration complexity\nis improved to $O(n\\epsilon^{-1} )$. If, in addition, the objective is strongly\nconvex (relative to the reference function), the global linear convergence rate\nis recovered. We also present the accelerated version of the RBCD method, which\nattains an $O(n\\varepsilon^{-1/\\gamma} )$ iteration complexity for the convex\ncase, where the scalar $\\gamma\\in [1,2]$ is determined by the\n\\textit{generalized translation variant} of the Bregman distance. Convergence\nanalysis without assuming the global Lipschitz-continuous (partial) gradient\nsets our results apart from the existing works in the composite problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 09:57:38 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Gao", "Tianxiang", ""], ["Lu", "Songtao", ""], ["Liu", "Jia", ""], ["Chu", "Chris", ""]]}, {"id": "2001.05205", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai and Ohad Shamir", "title": "Learning a Single Neuron with Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of learning a single neuron $x\n\\mapsto\\sigma(w^\\top x)$ using standard gradient methods. As opposed to\nprevious works, which considered specific (and not always realistic) input\ndistributions and activation functions $\\sigma(\\cdot)$, we ask whether a more\ngeneral result is attainable, under milder assumptions. On the one hand, we\nshow that some assumptions on the distribution and the activation function are\nnecessary. On the other hand, we prove positive guarantees under mild\nassumptions, which go beyond those studied in the literature so far. We also\npoint out and study the challenges in further strengthening and generalizing\nour results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:46:34 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "2001.05207", "submitter": "Tomer Galanti", "authors": "Lior Wolf, Tomer Galanti, Tamir Hazan", "title": "A Formal Approach to Explainability", "comments": null, "journal-ref": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and\n  Society, January 2019, Pages 255-261", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We regard explanations as a blending of the input sample and the model's\noutput and offer a few definitions that capture various desired properties of\nthe function that generates these explanations. We study the links between\nthese properties and between explanation-generating functions and intermediate\nrepresentations of learned models and are able to show, for example, that if\nthe activations of a given layer are consistent with an explanation, then so do\nall other subsequent layers. In addition, we study the intersection and union\nof explanations as a way to construct new explanations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:06:47 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wolf", "Lior", ""], ["Galanti", "Tomer", ""], ["Hazan", "Tamir", ""]]}, {"id": "2001.05208", "submitter": "Vaishak Belle", "authors": "Vaishak Belle", "title": "SMT + ILP", "comments": "In AAAI Workshop: Statistical Relational Artificial Intelligence\n  (StarAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive logic programming (ILP) has been a deeply influential paradigm in\nAI, enjoying decades of research on its theory and implementations. As a\nnatural descendent of the fields of logic programming and machine learning, it\nadmits the incorporation of background knowledge, which can be very useful in\ndomains where prior knowledge from experts is available and can lead to a more\ndata-efficient learning regime. Be that as it may, the limitation to Horn\nclauses composed over Boolean variables is a very serious one. Many phenomena\noccurring in the real-world are best characterized using continuous entities,\nand more generally, mixtures of discrete and continuous entities. In this\nposition paper, we motivate a reconsideration of inductive declarative\nprogramming by leveraging satisfiability modulo theory technology.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:09:21 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Belle", "Vaishak", ""]]}, {"id": "2001.05209", "submitter": "Rohan Saphal Mr", "authors": "Rohan Saphal, Balaraman Ravindran, Dheevatsa Mudigere, Sasikanth\n  Avancha, Bharat Kaul", "title": "SEERL: Sample Efficient Ensemble Reinforcement Learning", "comments": "Accepted at Proceedings of the 20th International Conference on\n  Autonomous Agents and MultiAgent Systems", "journal-ref": null, "doi": "10.5555/3463952.3464080", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a very prevalent method employed in machine learning.\nThe relative success of ensemble methods is attributed to their ability to\ntackle a wide range of instances and complex problems that require different\nlow-level approaches. However, ensemble methods are relatively less popular in\nreinforcement learning owing to the high sample complexity and computational\nexpense involved in obtaining a diverse ensemble. We present a novel training\nand model selection framework for model-free reinforcement algorithms that use\nensembles of policies obtained from a single training run. These policies are\ndiverse in nature and are learned through directed perturbation of the model\nparameters at regular intervals. We show that learning and selecting an\nadequately diverse set of policies is required for a good ensemble while\nextreme diversity can prove detrimental to overall performance. Selection of an\nadequately diverse set of policies is done through our novel policy selection\nframework. We evaluate our approach on challenging discrete and continuous\ncontrol tasks and also discuss various ensembling strategies. Our framework is\nsubstantially sample efficient, computationally inexpensive and is seen to\noutperform state-of-the-art (SOTA) scores in Atari 2600 and Mujoco.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:12:00 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 13:35:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Saphal", "Rohan", ""], ["Ravindran", "Balaraman", ""], ["Mudigere", "Dheevatsa", ""], ["Avancha", "Sasikanth", ""], ["Kaul", "Bharat", ""]]}, {"id": "2001.05228", "submitter": "Aditya Kusupati", "authors": "Yashoteja Prabhu, Aditya Kusupati, Nilesh Gupta and Manik Varma", "title": "Extreme Regression for Dynamic Search Advertising", "comments": "15 pages, 4 figures, published at WSDM 2020 as a Long Oral", "journal-ref": null, "doi": "10.1145/3336191.3371768", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new learning paradigm called eXtreme Regression (XR)\nwhose objective is to accurately predict the numerical degrees of relevance of\nan extremely large number of labels to a data point. XR can provide elegant\nsolutions to many large-scale ranking and recommendation applications including\nDynamic Search Advertising (DSA). XR can learn more accurate models than the\nrecently popular extreme classifiers which incorrectly assume strictly\nbinary-valued label relevances. Traditional regression metrics which sum the\nerrors over all the labels are unsuitable for XR problems since they could give\nextremely loose bounds for the label ranking quality. Also, the existing\nregression algorithms won't efficiently scale to millions of labels. This paper\naddresses these limitations through: (1) new evaluation metrics for XR which\nsum only the k largest regression errors; (2) a new algorithm called XReg which\ndecomposes XR task into a hierarchy of much smaller regression problems thus\nleading to highly efficient training and prediction. This paper also introduces\na (3) new labelwise prediction algorithm in XReg useful for DSA and other\nrecommendation tasks. Experiments on benchmark datasets demonstrated that XReg\ncan outperform the state-of-the-art extreme classifiers as well as large-scale\nregressors and rankers by up to 50% reduction in the new XR error metric, and\nup to 2% and 2.4% improvements in terms of the propensity-scored precision\nmetric used in extreme classification and the click-through rate metric used in\nDSA respectively. Deployment of XReg on DSA in Bing resulted in a relative gain\nof 27% in query coverage. XReg's source code can be downloaded from\nhttp://manikvarma.org/code/XReg/download.html.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:56:42 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 02:34:48 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 10:46:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Prabhu", "Yashoteja", ""], ["Kusupati", "Aditya", ""], ["Gupta", "Nilesh", ""], ["Varma", "Manik", ""]]}, {"id": "2001.05253", "submitter": "Mafalda Falc\\~ao Ferreira", "authors": "Mafalda Falcao Ferreira, Rui Camacho, Luis F. Teixeira", "title": "Autoencoders as Weight Initialization of Deep Classification Networks\n  for Cancer versus Cancer Studies", "comments": "5 pages, 2 figures (each one with 6 sub-figures), 2 tables. Special\n  Session of Machine Learning in Healthcare Informatics and Medical Biology of\n  the 16th International Conference on Computational Intelligence methods for\n  Bioinformatics and Biostatistics (CIBB2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer is still one of the most devastating diseases of our time. One way of\nautomatically classifying tumor samples is by analyzing its derived molecular\ninformation (i.e., its genes expression signatures). In this work, we aim to\ndistinguish three different types of cancer: thyroid, skin, and stomach. For\nthat, we compare the performance of a Denoising Autoencoder (DAE) used as\nweight initialization of a deep neural network. Although we address a different\ndomain problem in this work, we have adopted the same methodology of Ferreira\net al.. In our experiments, we assess two different approaches when training\nthe classification model: (a) fixing the weights, after pre-training the DAE,\nand (b) allowing fine-tuning of the entire classification network.\nAdditionally, we apply two different strategies for embedding the DAE into the\nclassification network: (1) by only importing the encoding layers, and (2) by\ninserting the complete autoencoder. Our best result was the combination of\nunsupervised feature learning through a DAE, followed by its full import into\nthe classification network, and subsequent fine-tuning through supervised\ntraining, achieving an F1 score of 98.04% +/- 1.09 when identifying cancerous\nthyroid samples.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 11:49:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Ferreira", "Mafalda Falcao", ""], ["Camacho", "Rui", ""], ["Teixeira", "Luis F.", ""]]}, {"id": "2001.05264", "submitter": "Diego Valsesia", "authors": "Andrea Bordone Molini, Diego Valsesia, Giulia Fracastoro, Enrico Magli", "title": "Towards Deep Unsupervised SAR Despeckling with Blind-Spot Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SAR despeckling is a problem of paramount importance in remote sensing, since\nit represents the first step of many scene analysis algorithms. Recently, deep\nlearning techniques have outperformed classical model-based despeckling\nalgorithms. However, such methods require clean ground truth images for\ntraining, thus resorting to synthetically speckled optical images since clean\nSAR images cannot be acquired. In this paper, inspired by recent works on\nblind-spot denoising networks, we propose a self-supervised Bayesian\ndespeckling method. The proposed method is trained employing only noisy images\nand can therefore learn features of real SAR images rather than synthetic data.\nWe show that the performance of the proposed network is very close to the\nsupervised training approach on synthetic data and competitive on real data.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:21:12 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Molini", "Andrea Bordone", ""], ["Valsesia", "Diego", ""], ["Fracastoro", "Giulia", ""], ["Magli", "Enrico", ""]]}, {"id": "2001.05266", "submitter": "Alexander Schindler", "authors": "Alexander Schindler, Thomas Lidy, Sebastian B\\\"ock", "title": "Deep Learning for MIR Tutorial", "comments": "This is a description of a tutorial held at the 19th International\n  Society for Music Information Retrieval Conference, ISMIR 2018, Paris,\n  France, September 23-27, 2018. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has become state of the art in visual computing and\ncontinuously emerges into the Music Information Retrieval (MIR) and audio\nretrieval domain. In order to bring attention to this topic we propose an\nintroductory tutorial on deep learning for MIR. Besides a general introduction\nto neural networks, the proposed tutorial covers a wide range of MIR relevant\ndeep learning approaches. \\textbf{Convolutional Neural Networks} are currently\na de-facto standard for deep learning based audio retrieval. \\textbf{Recurrent\nNeural Networks} have proven to be effective in onset detection tasks such as\nbeat or audio-event detection. \\textbf{Siamese Networks} have been shown\neffective in learning audio representations and distance functions specific for\nmusic similarity retrieval. We will incorporate both academic and industrial\npoints of view into the tutorial. Accompanying the tutorial, we will create a\nGithub repository for the content presented at the tutorial as well as\nreferences to state of the art work and literature for further reading. This\nrepository will remain public after the conference.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:23:17 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Schindler", "Alexander", ""], ["Lidy", "Thomas", ""], ["B\u00f6ck", "Sebastian", ""]]}, {"id": "2001.05270", "submitter": "Mario Holubar", "authors": "Mario S. Holubar, Marco A. Wiering", "title": "Continuous-action Reinforcement Learning for Playing Racing Games:\n  Comparing SPG to PPO", "comments": "12 pages, 9 figures. Code is available at\n  https://github.com/mario-holubar/RacingRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a novel racing environment for OpenAI Gym is introduced. This\nenvironment operates with continuous action- and state-spaces and requires\nagents to learn to control the acceleration and steering of a car while\nnavigating a randomly generated racetrack. Different versions of two\nactor-critic learning algorithms are tested on this environment: Sampled Policy\nGradient (SPG) and Proximal Policy Optimization (PPO). An extension of SPG is\nintroduced that aims to improve learning performance by weighting action\nsamples during the policy update step. The effect of using experience replay\n(ER) is also investigated. To this end, a modification to PPO is introduced\nthat allows for training using old action samples by optimizing the actor in\nlog space. Finally, a new technique for performing ER is tested that aims to\nimprove learning speed without sacrificing performance by splitting the\ntraining into two parts, whereby networks are first trained using state\ntransitions from the replay buffer, and then using only recent experiences. The\nresults indicate that experience replay is not beneficial to PPO in continuous\naction spaces. The training of SPG seems to be more stable when actions are\nweighted. All versions of SPG outperform PPO when ER is used. The ER trick is\neffective at improving training speed on a computationally less intensive\nversion of SPG.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:30:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Holubar", "Mario S.", ""], ["Wiering", "Marco A.", ""]]}, {"id": "2001.05272", "submitter": "Zhenyu Xuan", "authors": "Zhenyu Xuan, Rui Bao, Shengyi Jiang", "title": "FGN: Fusion Glyph Network for Chinese Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese NER is a challenging task. As pictographs, Chinese characters contain\nlatent glyph information, which is often overlooked. In this paper, we propose\nthe FGN, Fusion Glyph Network for Chinese NER. Except for adding glyph\ninformation, this method may also add extra interactive information with the\nfusion mechanism. The major innovations of FGN include: (1) a novel CNN\nstructure called CGS-CNN is proposed to capture both glyph information and\ninteractive information between glyphs from neighboring characters. (2) we\nprovide a method with sliding window and Slice-Attention to fuse the BERT\nrepresentation and glyph representation for a character, which may capture\npotential interactive knowledge between context and glyph. Experiments are\nconducted on four NER datasets, showing that FGN with LSTM-CRF as tagger\nachieves new state-of-the-arts performance for Chinese NER. Further, more\nexperiments are conducted to investigate the influences of various components\nand settings in FGN.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:39:20 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:58:51 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 05:05:45 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 13:28:21 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 07:54:43 GMT"}, {"version": "v6", "created": "Thu, 8 Oct 2020 11:46:09 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Xuan", "Zhenyu", ""], ["Bao", "Rui", ""], ["Jiang", "Shengyi", ""]]}, {"id": "2001.05277", "submitter": "Wenchao Xia", "authors": "Wenchao Xia, Gan Zheng, Kai-Kit Wong, and Hongbo Zhu", "title": "Model-Driven Beamforming Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/MWC.001.1900239", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beamforming is evidently a core technology in recent generations of mobile\ncommunication networks. Nevertheless, an iterative process is typically\nrequired to optimize the parameters, making it ill-placed for real-time\nimplementation due to high complexity and computational delay. Heuristic\nsolutions such as zero-forcing (ZF) are simpler but at the expense of\nperformance loss. Alternatively, deep learning (DL) is well understood to be a\ngeneralizing technique that can deliver promising results for a wide range of\napplications at much lower complexity if it is sufficiently trained. As a\nconsequence, DL may present itself as an attractive solution to beamforming. To\nexploit DL, this article introduces general data- and model-driven beamforming\nneural networks (BNNs), presents various possible learning strategies, and also\ndiscusses complexity reduction for the DL-based BNNs. We also offer enhancement\nmethods such as training-set augmentation and transfer learning in order to\nimprove the generality of BNNs, accompanied by computer simulation results and\ntestbed results showing the performance of such BNN solutions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:50:09 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Xia", "Wenchao", ""], ["Zheng", "Gan", ""], ["Wong", "Kai-Kit", ""], ["Zhu", "Hongbo", ""]]}, {"id": "2001.05283", "submitter": "Zhen Liu", "authors": "Zhen Liu, Hu li, Chao Wang", "title": "NEW: A Generic Learning Model for Tie Strength Prediction in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tie strength prediction, sometimes named weight prediction, is vital in\nexploring the diversity of connectivity pattern emerged in networks. Due to the\nfundamental significance, it has drawn much attention in the field of network\nanalysis and mining. Some related works appeared in recent years have\nsignificantly advanced our understanding of how to predict the strong and weak\nties in the social networks. However, most of the proposed approaches are\nscenario-aware methods heavily depending on some special contexts and even\nexclusively used in social networks. As a result, they are less applicable to\nvarious kinds of networks.\n  In contrast to the prior studies, here we propose a new computational\nframework called Neighborhood Estimating Weight (NEW) which is purely driven by\nthe basic structure information of the network and has the flexibility for\nadapting to diverse types of networks. In NEW, we design a novel index, i.e.,\nconnection inclination, to generate the representative features of the network,\nwhich is capable of capturing the actual distribution of the tie strength. In\norder to obtain the optimized prediction results, we also propose a\nparameterized regression model which approximately has a linear time complexity\nand thus is readily extended to the implementation in large-scale networks. The\nexperimental results on six real-world networks demonstrate that our proposed\npredictive model outperforms the state of the art methods, which is powerful\nfor predicting the missing tie strengths when only a part of the network's tie\nstrength information is available.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:02:00 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Liu", "Zhen", ""], ["li", "Hu", ""], ["Wang", "Chao", ""]]}, {"id": "2001.05295", "submitter": "Ethan Steinberg", "authors": "Ethan Steinberg, Ken Jung, Jason A. Fries, Conor K. Corbin, Stephen R.\n  Pfohl, Nigam H. Shah", "title": "Language Models Are An Effective Patient Representation Learning\n  Technique For Electronic Health Record Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widespread adoption of electronic health records (EHRs) has fueled the\ndevelopment of using machine learning to build prediction models for various\nclinical outcomes. This process is often constrained by having a relatively\nsmall number of patient records for training the model. We demonstrate that\nusing patient representation schemes inspired from techniques in natural\nlanguage processing can increase the accuracy of clinical prediction models by\ntransferring information learned from the entire patient population to the task\nof training a specific model, where only a subset of the population is\nrelevant. Such patient representation schemes enable a 3.5% mean improvement in\nAUROC on five prediction tasks compared to standard baselines, with the average\nimprovement rising to 19% when only a small number of patient records are\navailable for training the clinical prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:24:59 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 20:58:31 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Steinberg", "Ethan", ""], ["Jung", "Ken", ""], ["Fries", "Jason A.", ""], ["Corbin", "Conor K.", ""], ["Pfohl", "Stephen R.", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2001.05308", "submitter": "Yang Li", "authors": "Yang Li, Julien Amelot, Xin Zhou, Samy Bengio, Si Si", "title": "Auto Completion of User Interface Layout Design Using Transformer-Based\n  Tree Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been of increasing interest in the field to develop automatic\nmachineries to facilitate the design process. In this paper, we focus on\nassisting graphical user interface (UI) layout design, a crucial task in app\ndevelopment. Given a partial layout, which a designer has entered, our model\nlearns to complete the layout by predicting the remaining UI elements with a\ncorrect position and dimension as well as the hierarchical structures. Such\nautomation will significantly ease the effort of UI designers and developers.\nWhile we focus on interface layout prediction, our model can be generally\napplicable for other layout prediction problems that involve tree structures\nand 2-dimensional placements. Particularly, we design two versions of\nTransformer-based tree decoders: Pointer and Recursive Transformer, and\nexperiment with these models on a public dataset. We also propose several\nmetrics for measuring the accuracy of tree prediction and ground these metrics\nin the domain of user experience. These contribute a new task and methods to\ndeep learning research.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:24:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Li", "Yang", ""], ["Amelot", "Julien", ""], ["Zhou", "Xin", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "2001.05312", "submitter": "Bj{\\o}rn Magnus Mathisen", "authors": "Bj{\\o}rn Magnus Mathisen, Agnar Aamodt, Kerstin Bach, Helge Langseth", "title": "Learning similarity measures from data", "comments": "Prog Artif Intell (2019)", "journal-ref": null, "doi": "10.1007/s13748-019-00201-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defining similarity measures is a requirement for some machine learning\nmethods. One such method is case-based reasoning (CBR) where the similarity\nmeasure is used to retrieve the stored case or set of cases most similar to the\nquery case. Describing a similarity measure analytically is challenging, even\nfor domain experts working with CBR experts. However, data sets are typically\ngathered as part of constructing a CBR or machine learning system. These\ndatasets are assumed to contain the features that correctly identify the\nsolution from the problem features, thus they may also contain the knowledge to\nconstruct or learn such a similarity measure. The main motivation for this work\nis to automate the construction of similarity measures using machine learning,\nwhile keeping training time as low as possible. Our objective is to investigate\nhow to apply machine learning to effectively learn a similarity measure. Such a\nlearned similarity measure could be used for CBR systems, but also for\nclustering data in semi-supervised learning, or one-shot learning tasks. Recent\nwork has advanced towards this goal, relies on either very long training times\nor manually modeling parts of the similarity measure. We created a framework to\nhelp us analyze current methods for learning similarity measures. This analysis\nresulted in two novel similarity measure designs. One design using a\npre-trained classifier as basis for a similarity measure. The second design\nuses as little modeling as possible while learning the similarity measure from\ndata and keeping training time low. Both similarity measures were evaluated on\n14 different datasets. The evaluation shows that using a classifier as basis\nfor a similarity measure gives state of the art performance. Finally the\nevaluation shows that our fully data-driven similarity measure design\noutperforms state of the art methods while keeping training time low.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:29:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Mathisen", "Bj\u00f8rn Magnus", ""], ["Aamodt", "Agnar", ""], ["Bach", "Kerstin", ""], ["Langseth", "Helge", ""]]}, {"id": "2001.05313", "submitter": "Xien Liu", "authors": "Xien Liu, Xinxin You, Xiao Zhang, Ji Wu and Ping Lv", "title": "Tensor Graph Convolutional Networks for Text Classification", "comments": "8 pages, 4 figures", "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to sequential learning models, graph-based neural networks exhibit\nsome excellent properties, such as ability capturing global information. In\nthis paper, we investigate graph-based neural networks for text classification\nproblem. A new framework TensorGCN (tensor graph convolutional networks), is\npresented for this task. A text graph tensor is firstly constructed to describe\nsemantic, syntactic, and sequential contextual information. Then, two kinds of\npropagation learning perform on the text graph tensor. The first is intra-graph\npropagation used for aggregating information from neighborhood nodes in a\nsingle graph. The second is inter-graph propagation used for harmonizing\nheterogeneous information between graphs. Extensive experiments are conducted\non benchmark datasets, and the results illustrate the effectiveness of our\nproposed framework. Our proposed TensorGCN presents an effective way to\nharmonize and integrate heterogeneous information from different kinds of\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 14:28:33 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Liu", "Xien", ""], ["You", "Xinxin", ""], ["Zhang", "Xiao", ""], ["Wu", "Ji", ""], ["Lv", "Ping", ""]]}, {"id": "2001.05314", "submitter": "Siyu Liao", "authors": "Siyu Liao, Jie Chen, Yanzhi Wang, Qinru Qiu, Bo Yuan", "title": "Embedding Compression with Isotropic Iterative Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous representation of words is a standard component in deep\nlearning-based NLP models. However, representing a large vocabulary requires\nsignificant memory, which can cause problems, particularly on\nresource-constrained platforms. Therefore, in this paper we propose an\nisotropic iterative quantization (IIQ) approach for compressing embedding\nvectors into binary ones, leveraging the iterative quantization technique well\nestablished for image retrieval, while satisfying the desired isotropic\nproperty of PMI based models. Experiments with pre-trained embeddings (i.e.,\nGloVe and HDC) demonstrate a more than thirty-fold compression ratio with\ncomparable and sometimes even improved performance over the original\nreal-valued embedding vectors.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 20:53:55 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 01:01:56 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liao", "Siyu", ""], ["Chen", "Jie", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""], ["Yuan", "Bo", ""]]}, {"id": "2001.05315", "submitter": "Md Saiful Islam", "authors": "Hemayet Ahmed Chowdhury, Md. Azizul Haque Imon, Anisur Rahman, Aisha\n  Khatun, Md. Saiful Islam", "title": "A Continuous Space Neural Language Model for Bengali Language", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models are generally employed to estimate the probability\ndistribution of various linguistic units, making them one of the fundamental\nparts of natural language processing. Applications of language models include a\nwide spectrum of tasks such as text summarization, translation and\nclassification. For a low resource language like Bengali, the research in this\narea so far can be considered to be narrow at the very least, with some\ntraditional count based models being proposed. This paper attempts to address\nthe issue and proposes a continuous-space neural language model, or more\nspecifically an ASGD weight dropped LSTM language model, along with techniques\nto efficiently train it for Bengali Language. The performance analysis with\nsome currently existing count based models illustrated in this paper also shows\nthat the proposed architecture outperforms its counterparts by achieving an\ninference perplexity as low as 51.2 on the held out data set for Bengali.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:50:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Chowdhury", "Hemayet Ahmed", ""], ["Imon", "Md. Azizul Haque", ""], ["Rahman", "Anisur", ""], ["Khatun", "Aisha", ""], ["Islam", "Md. Saiful", ""]]}, {"id": "2001.05316", "submitter": "Md Saiful Islam", "authors": "Aisha Khatun, Anisur Rahman, Md. Saiful Islam, Marium-E-Jannat", "title": "Authorship Attribution in Bangla literature using Character-level CNN", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:54:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Khatun", "Aisha", ""], ["Rahman", "Anisur", ""], ["Islam", "Md. Saiful", ""], ["Marium-E-Jannat", "", ""]]}, {"id": "2001.05317", "submitter": "Philip Sellars", "authors": "Philip Sellars, Angelica Aviles-Rivero, Carola Bibiane Sch\\\"onlieb", "title": "Two Cycle Learning: Clustering Based Regularisation for Deep\n  Semi-Supervised Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works addresses the challenge of classification with minimal\nannotations. Obtaining annotated data is time consuming, expensive and can\nrequire expert knowledge. As a result, there is an acceleration towards\nsemi-supervised learning (SSL) approaches which utilise large amounts of\nunlabelled data to improve classification performance. The vast majority of SSL\napproaches have focused on implementing the \\textit{low-density separation\nassumption}, in which the idea is that decision boundaries should lie in low\ndensity regions. However, they have implemented this assumption by treating the\ndataset as a set of individual attributes rather than as a global structure,\nwhich limits the overall performance of the classifier. Therefore, in this\nwork, we go beyond this implementation and propose a novel SSL framework called\ntwo-cycle learning. For the first cycle, we use clustering based regularisation\nthat allows for improved decision boundaries as well as features that\ngeneralises well. The second cycle is set as a graph based SSL that take\nadvantages of the richer discriminative features of the first cycle to\nsignificantly boost the accuracy of generated pseudo-labels. We evaluate our\ntwo-cycle learning method extensively across multiple datasets, outperforming\ncurrent approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:34:02 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sellars", "Philip", ""], ["Aviles-Rivero", "Angelica", ""], ["Sch\u00f6nlieb", "Carola Bibiane", ""]]}, {"id": "2001.05343", "submitter": "Yuhao Wang", "authors": "Yuhao Wang, Vlado Menkovski, Hao Wang, Xin Du, Mykola Pechenizkiy", "title": "Causal Discovery from Incomplete Data: A Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As systems are getting more autonomous with the development of artificial\nintelligence, it is important to discover the causal knowledge from\nobservational sensory inputs. By encoding a series of cause-effect relations\nbetween events, causal networks can facilitate the prediction of effects from a\ngiven action and analyze their underlying data generation mechanism. However,\nmissing data are ubiquitous in practical scenarios. Directly performing\nexisting casual discovery algorithms on partially observed data may lead to the\nincorrect inference. To alleviate this issue, we proposed a deep learning\nframework, dubbed Imputated Causal Learning (ICL), to perform iterative missing\ndata imputation and causal structure discovery. Through extensive simulations\non both synthetic and real data, we show that ICL can outperform\nstate-of-the-art methods under different missing data mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:28:21 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wang", "Yuhao", ""], ["Menkovski", "Vlado", ""], ["Wang", "Hao", ""], ["Du", "Xin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2001.05348", "submitter": "Yusuke Sakemi Ph.D.", "authors": "Yusuke Sakemi, Kai Morino, Takashi Morie, Kazuyuki Aihara", "title": "A Supervised Learning Algorithm for Multilayer Spiking Neural Networks\n  Based on Temporal Coding Toward Energy-Efficient VLSI Processor Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are brain-inspired mathematical models with\nthe ability to process information in the form of spikes. SNNs are expected to\nprovide not only new machine-learning algorithms, but also energy-efficient\ncomputational models when implemented in VLSI circuits. In this paper, we\npropose a novel supervised learning algorithm for SNNs based on temporal\ncoding. A spiking neuron in this algorithm is designed to facilitate analog\nVLSI implementations with analog resistive memory, by which ultra-high energy\nefficiency can be achieved. We also propose several techniques to improve the\nperformance on a recognition task, and show that the classification accuracy of\nthe proposed algorithm is as high as that of the state-of-the-art temporal\ncoding SNN algorithms on the MNIST dataset. Finally, we discuss the robustness\nof the proposed SNNs against variations that arise from the device\nmanufacturing process and are unavoidable in analog VLSI implementation. We\nalso propose a technique to suppress the effects of variations in the\nmanufacturing process on the recognition performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:37:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sakemi", "Yusuke", ""], ["Morino", "Kai", ""], ["Morie", "Takashi", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "2001.05361", "submitter": "Lucas B\\\"ottcher", "authors": "Francesco D'Angelo and Lucas B\\\"ottcher", "title": "Learning the Ising Model with Generative Neural Networks", "comments": "18 pages, 13 figures", "journal-ref": "Phys. Rev. Research 2, 023266 (2020)", "doi": "10.1103/PhysRevResearch.2.023266", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning and neural networks have led to an increased\ninterest in the application of generative models in statistical and condensed\nmatter physics. In particular, restricted Boltzmann machines (RBMs) and\nvariational autoencoders (VAEs) as specific classes of neural networks have\nbeen successfully applied in the context of physical feature extraction and\nrepresentation learning. Despite these successes, however, there is only\nlimited understanding of their representational properties and limitations. To\nbetter understand the representational characteristics of RBMs and VAEs, we\nstudy their ability to capture physical features of the Ising model at\ndifferent temperatures. This approach allows us to quantitatively assess\nlearned representations by comparing sample features with corresponding\ntheoretical predictions. Our results suggest that the considered RBMs and\nconvolutional VAEs are able to capture the temperature dependence of\nmagnetization, energy, and spin-spin correlations. The samples generated by\nRBMs are more evenly distributed across temperature than those generated by\nVAEs. We also find that convolutional layers in VAEs are important to model\nspin correlations whereas RBMs achieve similar or even better performances\nwithout convolutional filters.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:04:21 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 22:37:06 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["D'Angelo", "Francesco", ""], ["B\u00f6ttcher", "Lucas", ""]]}, {"id": "2001.05363", "submitter": "Vincent Adam", "authors": "Vincent Adam and Stefanos Eleftheriadis and Nicolas Durrande and Artem\n  Artemev and James Hensman", "title": "Doubly Sparse Variational Gaussian Processes", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Gaussian process models is typically limited to datasets with a\nfew tens of thousands of observations due to their complexity and memory\nfootprint. The two most commonly used methods to overcome this limitation are\n1) the variational sparse approximation which relies on inducing points and 2)\nthe state-space equivalent formulation of Gaussian processes which can be seen\nas exploiting some sparsity in the precision matrix. We propose to take the\nbest of both worlds: we show that the inducing point framework is still valid\nfor state space models and that it can bring further computational and memory\nsavings. Furthermore, we provide the natural gradient formulation for the\nproposed variational parameterisation. Finally, this work makes it possible to\nuse the state-space formulation inside deep Gaussian process models as\nillustrated in one of the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:07:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Adam", "Vincent", ""], ["Eleftheriadis", "Stefanos", ""], ["Durrande", "Nicolas", ""], ["Artemev", "Artem", ""], ["Hensman", "James", ""]]}, {"id": "2001.05371", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger,\n  Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, Kristian Kersting", "title": "Making deep neural networks right for the right scientific reasons by\n  interacting with their explanations", "comments": "arXiv admin note: text overlap with arXiv:1805.08578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have shown excellent performances in many real-world\napplications. Unfortunately, they may show \"Clever Hans\"-like behavior---making\nuse of confounding factors within datasets---to achieve high performance. In\nthis work, we introduce the novel learning setting of \"explanatory interactive\nlearning\" (XIL) and illustrate its benefits on a plant phenotyping research\ntask. XIL adds the scientist into the training loop such that she interactively\nrevises the original model via providing feedback on its explanations. Our\nexperimental results demonstrate that XIL can help avoiding Clever Hans moments\nin machine learning and encourages (or discourages, if appropriate) trust into\nthe underlying model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:20:55 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:59:54 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 13:38:58 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Schramowski", "Patrick", ""], ["Stammer", "Wolfgang", ""], ["Teso", "Stefano", ""], ["Brugger", "Anna", ""], ["Shao", "Xiaoting", ""], ["Luigs", "Hans-Georg", ""], ["Mahlein", "Anne-Katrin", ""], ["Kersting", "Kristian", ""]]}, {"id": "2001.05375", "submitter": "Florian Buettner", "authors": "Florian Buettner, John Piorkowski, Ian McCulloh, Ulli Waltinger", "title": "AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data\n  Proceedings", "comments": "Proceedings for AAAI 2019 Fall Symposium Series - Human-centered AI:\n  Trustworthiness of AI Models & Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate the widespread acceptance of AI systems guiding decision-making\nin real-world applications, it is key that solutions comprise trustworthy,\nintegrated human-AI systems. Not only in safety-critical applications such as\nautonomous driving or medicine, but also in dynamic open world systems in\nindustry and government it is crucial for predictive models to be\nuncertainty-aware and yield trustworthy predictions. Another key requirement\nfor deployment of AI at enterprise scale is to realize the importance of\nintegrating human-centered design into AI systems such that humans are able to\nuse systems effectively, understand results and output, and explain findings to\noversight committees.\n  While the focus of this symposium was on AI systems to improve data quality\nand technical robustness and safety, we welcomed submissions from broadly\ndefined areas also discussing approaches addressing requirements such as\nexplainable models, human trust and ethical aspects of AI.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:30:29 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Buettner", "Florian", ""], ["Piorkowski", "John", ""], ["McCulloh", "Ian", ""], ["Waltinger", "Ulli", ""]]}, {"id": "2001.05401", "submitter": "Quentin Bertrand", "authors": "Mathurin Massias and Quentin Bertrand and Alexandre Gramfort and\n  Joseph Salmon", "title": "Support recovery and sup-norm convergence rates for sparse pivotal\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional sparse regression, pivotal estimators are estimators for\nwhich the optimal regularization parameter is independent of the noise level.\nThe canonical pivotal estimator is the square-root Lasso, formulated along with\nits derivatives as a \"non-smooth + non-smooth\" optimization problem. Modern\ntechniques to solve these include smoothing the datafitting term, to benefit\nfrom fast efficient proximal algorithms. In this work we show minimax sup-norm\nconvergence rates for non smoothed and smoothed, single task and multitask\nsquare-root Lasso-type estimators. Thanks to our theoretical analysis, we\nprovide some guidelines on how to set the smoothing hyperparameter, and\nillustrate on synthetic data the interest of such guidelines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:11:04 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 15:30:03 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:58:48 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Massias", "Mathurin", ""], ["Bertrand", "Quentin", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "2001.05407", "submitter": "Guillaume Marrelec", "authors": "Guillaume Marrelec and Alain Giron", "title": "Automated extraction of mutual independence patterns using Bayesian\n  comparison of partition models", "comments": "IEEE Transactions on Pattern Analysis and Machine Intelligence (in\n  press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual independence is a key concept in statistics that characterizes the\nstructural relationships between variables. Existing methods to investigate\nmutual independence rely on the definition of two competing models, one being\nnested into the other and used to generate a null distribution for a statistic\nof interest, usually under the asymptotic assumption of large sample size. As\nsuch, these methods have a very restricted scope of application. In the present\nmanuscript, we propose to change the investigation of mutual independence from\na hypothesis-driven task that can only be applied in very specific cases to a\nblind and automated search within patterns of mutual independence. To this end,\nwe treat the issue as one of model comparison that we solve in a Bayesian\nframework. We show the relationship between such an approach and existing\nmethods in the case of multivariate normal distributions as well as\ncross-classified multinomial distributions. We propose a general Markov chain\nMonte Carlo (MCMC) algorithm to numerically approximate the posterior\ndistribution on the space of all patterns of mutual independence. The relevance\nof the method is demonstrated on synthetic data as well as two real datasets,\nshowing the unique insight provided by this approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:21:48 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Marrelec", "Guillaume", ""], ["Giron", "Alain", ""]]}, {"id": "2001.05411", "submitter": "Erwan Lecarpentier", "authors": "Erwan Lecarpentier, David Abel, Kavosh Asadi, Yuu Jinnai, Emmanuel\n  Rachelson, Michael L. Littman", "title": "Lipschitz Lifelong Reinforcement Learning", "comments": "In proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI 2021), 21 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of knowledge transfer when an agent is facing a\nseries of Reinforcement Learning (RL) tasks. We introduce a novel metric\nbetween Markov Decision Processes (MDPs) and establish that close MDPs have\nclose optimal value functions. Formally, the optimal value functions are\nLipschitz continuous with respect to the tasks space. These theoretical results\nlead us to a value-transfer method for Lifelong RL, which we use to build a\nPAC-MDP algorithm with improved convergence rate. Further, we show the method\nto experience no negative transfer with high probability. We illustrate the\nbenefits of the method in Lifelong RL experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:29:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 16:25:07 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 14:35:30 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Lecarpentier", "Erwan", ""], ["Abel", "David", ""], ["Asadi", "Kavosh", ""], ["Jinnai", "Yuu", ""], ["Rachelson", "Emmanuel", ""], ["Littman", "Michael L.", ""]]}, {"id": "2001.05419", "submitter": "Ev Zisselman", "authors": "Ev Zisselman and Aviv Tamar", "title": "Deep Residual Flow for Out of Distribution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective application of neural networks in the real-world relies on\nproficiently detecting out-of-distribution examples. Contemporary methods seek\nto model the distribution of feature activations in the training data for\nadequately distinguishing abnormalities, and the state-of-the-art method uses\nGaussian distribution models. In this work, we present a novel approach that\nimproves upon the state-of-the-art by leveraging an expressive density model\nbased on normalizing flows. We introduce the residual flow, a novel flow\narchitecture that learns the residual distribution from a base Gaussian\ndistribution. Our model is general, and can be applied to any data that is\napproximately Gaussian. For out of distribution detection in image datasets,\nour approach provides a principled improvement over the state-of-the-art.\nSpecifically, we demonstrate the effectiveness of our method in ResNet and\nDenseNet architectures trained on various image datasets. For example, on a\nResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution\nsamples from the ImageNet dataset, holding the true positive rate (TPR) at\n$95\\%$, we improve the true negative rate (TNR) from $56.7\\%$ (current\nstate-of-the-art) to $77.5\\%$ (ours).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:38:47 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 16:20:47 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 17:44:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zisselman", "Ev", ""], ["Tamar", "Aviv", ""]]}, {"id": "2001.05443", "submitter": "G C Nandi", "authors": "Priya Shukla, Hitesh Kumar and G. C. Nandi", "title": "Robotic Grasp Manipulation Using Evolutionary Computing and Deep\n  Reinforcement Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Object manipulation for grasping is a challenging problem for\nrobots. Unlike robots, humans almost immediately know how to manipulate objects\nfor grasping due to learning over the years. A grown woman can grasp objects\nmore skilfully than a child because of learning skills developed over years,\nthe absence of which in the present day robotic grasping compels it to perform\nwell below the human object grasping benchmarks. In this paper we have taken up\nthe challenge of developing learning based pose estimation by decomposing the\nproblem into both position and orientation learning. More specifically, for\ngrasp position estimation, we explore three different methods - a Genetic\nAlgorithm (GA) based optimization method to minimize error between calculated\nimage points and predicted end-effector (EE) position, a regression based\nmethod (RM) where collected data points of robot EE and image points have been\nregressed with a linear model, a PseudoInverse (PI) model which has been\nformulated in the form of a mapping matrix with robot EE position and image\npoints for several observations. Further for grasp orientation learning, we\ndevelop a deep reinforcement learning (DRL) model which we name as Grasp Deep\nQ-Network (GDQN) and benchmarked our results with Modified VGG16 (MVGG16).\nRigorous experimentations show that due to inherent capability of producing\nvery high-quality solutions for optimization problems and search problems, GA\nbased predictor performs much better than the other two models for position\nestimation. For orientation learning results indicate that off policy learning\nthrough GDQN outperforms MVGG16, since GDQN architecture is specially made\nsuitable for the reinforcement learning. Based on our proposed architectures\nand algorithms, the robot is capable of grasping all rigid body objects having\nregular shapes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:23:55 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Shukla", "Priya", ""], ["Kumar", "Hitesh", ""], ["Nandi", "G. C.", ""]]}, {"id": "2001.05452", "submitter": "Abishek Sankararaman", "authors": "Ronshee Chawla, Abishek Sankararaman, Ayalvadi Ganesh, Sanjay\n  Shakkottai", "title": "The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits", "comments": "To Appear in AISTATS 2020. The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup\nconsisting of $N$ agents, solving the same MAB instance to minimize individual\ncumulative regret. In our model, agents collaborate by exchanging messages\nthrough pairwise gossip style communications on an arbitrary connected graph.\nWe develop two novel algorithms, where each agent only plays from a subset of\nall the arms. Agents use the communication medium to recommend only arm-IDs\n(not samples), and thus update the set of arms from which they play. We\nestablish that, if agents communicate $\\Omega(\\log(T))$ times through any\nconnected pairwise gossip mechanism, then every agent's regret is a factor of\norder $N$ smaller compared to the case of no collaborations. Furthermore, we\nshow that the communication constraints only have a second order effect on the\nregret of our algorithm. We then analyze this second order term of the regret\nto derive bounds on the regret-communication tradeoffs. Finally, we empirically\nevaluate our algorithm and conclude that the insights are fundamental and not\nartifacts of our bounds. We also show a lower bound which gives that the regret\nscaling obtained by our algorithm cannot be improved even in the absence of any\ncommunication constraints. Our results thus demonstrate that even a minimal\nlevel of collaboration among agents greatly reduces regret for all agents.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 00:09:46 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 21:11:46 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chawla", "Ronshee", ""], ["Sankararaman", "Abishek", ""], ["Ganesh", "Ayalvadi", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2001.05458", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Mausoom Sarkar, Abhishek Sinha, Siddharth Singh,\n  Nikaash Puri, Jayakumar Subramanian, Balaji Krishnamurthy", "title": "Inducing Cooperative behaviour in Sequential-Social dilemmas through\n  Multi-Agent Reinforcement Learning using Status-Quo Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social dilemma situations, individual rationality leads to sub-optimal\ngroup outcomes. Several human engagements can be modeled as a sequential\n(multi-step) social dilemmas. However, in contrast to humans, Deep\nReinforcement Learning agents trained to optimize individual rewards in\nsequential social dilemmas converge to selfish, mutually harmful behavior. We\nintroduce a status-quo loss (SQLoss) that encourages an agent to stick to the\nstatus quo, rather than repeatedly changing its policy. We show how agents\ntrained with SQLoss evolve cooperative behavior in several social dilemma\nmatrix games. To work with social dilemma games that have visual input, we\npropose GameDistill. GameDistill uses self-supervision and clustering to\nautomatically extract cooperative and selfish policies from a social dilemma\ngame. We combine GameDistill and SQLoss to show how agents evolve socially\ndesirable cooperative behavior in the Coin Game.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:10:46 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:55:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Sarkar", "Mausoom", ""], ["Sinha", "Abhishek", ""], ["Singh", "Siddharth", ""], ["Puri", "Nikaash", ""], ["Subramanian", "Jayakumar", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2001.05459", "submitter": "Qian Wang", "authors": "Qian Wang, Najla Megherbi, Toby P. Breckon", "title": "A Reference Architecture for Plausible Threat Image Projection (TIP)\n  Within 3D X-ray Computed Tomography Volumes", "comments": "Technical Report, Durham University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threat Image Projection (TIP) is a technique used in X-ray security baggage\nscreening systems that superimposes a threat object signature onto a benign\nX-ray baggage image in a plausible and realistic manner. It has been shown to\nbe highly effective in evaluating the ongoing performance of human operators,\nimproving their vigilance and performance on threat detection. However, with\nthe increasing use of 3D Computed Tomography (CT) in aviation security for both\nhold and cabin baggage screening a significant challenge arises in extending\nTIP to 3D CT volumes due to the difficulty in 3D CT volume segmentation and the\nproper insertion location determination. In this paper, we present an approach\nfor 3D TIP in CT volumes targeting realistic and plausible threat object\ninsertion within 3D CT baggage images. The proposed approach consists of dual\nthreat (source) and baggage (target) volume segmentation, particle swarm\noptimisation based insertion determination and metal artefact generation. In\naddition, we propose a TIP quality score metric to evaluate the quality of\ngenerated TIP volumes. Qualitative evaluations on real 3D CT baggage imagery\nshow that our approach is able to generate realistic and plausible TIP which\nare indiscernible from real CT volumes and the TIP quality scores are\nconsistent with human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:25:23 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Wang", "Qian", ""], ["Megherbi", "Najla", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2001.05467", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses", "comments": "AAAI 2020 (8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequence-to-sequence dialogue models tend to generate safe,\nuninformative responses. There have been various useful efforts on trying to\neliminate them. However, these approaches either improve decoding algorithms\nduring inference, rely on hand-crafted features, or employ complex models. In\nour work, we build dialogue models that are dynamically aware of what\nutterances or tokens are dull without any feature-engineering. Specifically, we\nstart with a simple yet effective automatic metric, AvgOut, which calculates\nthe average output probability distribution of all time steps on the decoder\nside during training. This metric directly estimates which tokens are more\nlikely to be generated, thus making it a faithful evaluation of the model\ndiversity (i.e., for diverse models, the token probabilities should be more\nevenly distributed rather than peaked at a few dull tokens). We then leverage\nthis novel metric to propose three models that promote diversity without losing\nrelevance. The first model, MinAvgOut, directly maximizes the diversity score\nthrough the output distributions of each batch; the second model, Label\nFine-Tuning (LFT), prepends to the source sequence a label continuously scaled\nby the diversity score to control the diversity level; the third model, RL,\nadopts Reinforcement Learning and treats the diversity score as a reward\nsignal. Moreover, we experiment with a hybrid model by combining the loss terms\nof MinAvgOut and RL. All four models outperform their base LSTM-RNN model on\nboth diversity and relevance by a large margin, and are comparable to or better\nthan competitive baselines (also verified via human evaluation). Moreover, our\napproaches are orthogonal to the base model, making them applicable as an\nadd-on to other emerging better dialogue models in the future.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:32:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "2001.05472", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov and Leonid E. Fedichkin and Ray-Kuang Lee and\n  Alexander Alodjants", "title": "Machine learning transfer efficiencies for noisy quantum walks", "comments": "6 pages, 4 figures", "journal-ref": "Adv. Quantum Technol. 3, 1900115 (2020)", "doi": "10.1002/qute.201900115", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum effects are known to provide an advantage in particle transfer across\nnetworks. In order to achieve this advantage, requirements on both a graph type\nand a quantum system coherence must be found. Here we show that the process of\nfinding these requirements can be automated by learning from simulated\nexamples. The automation is done by using a convolutional neural network of a\nparticular type that learns to understand with which network and under which\ncoherence requirements quantum advantage is possible. Our machine learning\napproach is applied to study noisy quantum walks on cycle graphs of different\nsizes. We found that it is possible to predict the existence of quantum\nadvantage for the entire decoherence parameter range, even for graphs outside\nof the training set. Our results are of importance for demonstration of\nadvantage in quantum experiments and pave the way towards automating scientific\nresearch and discoveries.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:36:53 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:39:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Fedichkin", "Leonid E.", ""], ["Lee", "Ray-Kuang", ""], ["Alodjants", "Alexander", ""]]}, {"id": "2001.05484", "submitter": "Yuxin Chen", "authors": "Yuxin Chen, Jianqing Fan, Cong Ma, Yuling Yan", "title": "Bridging Convex and Nonconvex Optimization in Robust PCA: Noise,\n  Outliers, and Missing Data", "comments": "accepted to the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT math.OC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper delivers improved theoretical guarantees for the convex\nprogramming approach in low-rank matrix estimation, in the presence of (1)\nrandom noise, (2) gross sparse outliers, and (3) missing data. This problem,\noften dubbed as robust principal component analysis (robust PCA), finds\napplications in various domains. Despite the wide applicability of convex\nrelaxation, the available statistical support (particularly the stability\nanalysis vis-\\`a-vis random noise) remains highly suboptimal, which we\nstrengthen in this paper. When the unknown matrix is well-conditioned,\nincoherent, and of constant rank, we demonstrate that a principled convex\nprogram achieves near-optimal statistical accuracy, in terms of both the\nEuclidean loss and the $\\ell_{\\infty}$ loss. All of this happens even when\nnearly a constant fraction of observations are corrupted by outliers with\narbitrary magnitudes. The key analysis idea lies in bridging the convex program\nin use and an auxiliary nonconvex optimization algorithm, and hence the title\nof this paper.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:54:29 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 20:05:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""], ["Ma", "Cong", ""], ["Yan", "Yuling", ""]]}, {"id": "2001.05486", "submitter": "Claudius Krause", "authors": "Christina Gao, Joshua Isaacson, and Claudius Krause", "title": "i-flow: High-dimensional Integration and Sampling with Normalizing Flows", "comments": "21 pages, 5 figures, 4 tables; v2: improved presentation and\n  discussion, matches published version. Mach. Learn.: Sci. Technol (2020)", "journal-ref": null, "doi": "10.1088/2632-2153/abab62", "report-no": "FERMILAB-PUB-20-010-T", "categories": "physics.comp-ph cs.LG hep-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many fields of science, high-dimensional integration is required.\nNumerical methods have been developed to evaluate these complex integrals. We\nintroduce the code i-flow, a python package that performs high-dimensional\nnumerical integration utilizing normalizing flows. Normalizing flows are\nmachine-learned, bijective mappings between two distributions. i-flow can also\nbe used to sample random points according to complicated distributions in high\ndimensions. We compare i-flow to other algorithms for high-dimensional\nnumerical integration and show that i-flow outperforms them for high\ndimensional correlated integrals. The i-flow code is publicly available on\ngitlab at https://gitlab.com/i-flow/i-flow.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:56:57 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 18:16:12 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gao", "Christina", ""], ["Isaacson", "Joshua", ""], ["Krause", "Claudius", ""]]}, {"id": "2001.05489", "submitter": "Shiv Ram Dubey", "authors": "Kancharagunta Kishan Babu, Shiv Ram Dubey", "title": "CDGAN: Cyclic Discriminative Generative Adversarial Networks for\n  Image-to-Image Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-to-image transformation is a kind of problem, where the input image\nfrom one visual representation is transformed into the output image of another\nvisual representation. Since 2014, Generative Adversarial Networks (GANs) have\nfacilitated a new direction to tackle this problem by introducing the generator\nand the discriminator networks in its architecture. Many recent works, like\nPix2Pix, CycleGAN, DualGAN, PS2MAN and CSGAN handled this problem with the\nrequired generator and discriminator networks and choice of the different\nlosses that are used in the objective functions. In spite of these works, still\nthere is a gap to fill in terms of both the quality of the images generated\nthat should look more realistic and as much as close to the ground truth\nimages. In this work, we introduce a new Image-to-Image Transformation network\nnamed Cyclic Discriminative Generative Adversarial Networks (CDGAN) that fills\nthe above mentioned gaps. The proposed CDGAN generates high quality and more\nrealistic images by incorporating the additional discriminator networks for\ncycled images in addition to the original architecture of the CycleGAN. To\ndemonstrate the performance of the proposed CDGAN, it is tested over three\ndifferent baseline image-to-image transformation datasets. The quantitative\nmetrics such as pixel-wise similarity, structural level similarity and\nperceptual level similarity are used to judge the performance. Moreover, the\nqualitative results are also analyzed and compared with the state-of-the-art\nmethods. The proposed CDGAN method clearly outperformed all the\nstate-of-the-art methods when compared over the three baseline Image-to-Image\ntransformation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:12:32 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Babu", "Kancharagunta Kishan", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "2001.05492", "submitter": "Li Cheng", "authors": "Li Cheng, Yijie Wang, Xinwang Liu, Bin Li", "title": "Outlier Detection Ensemble with Embedded Feature Selection", "comments": "10pages, AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection places an important role in improving the performance of\noutlier detection, especially for noisy data. Existing methods usually perform\nfeature selection and outlier scoring separately, which would select feature\nsubsets that may not optimally serve for outlier detection, leading to\nunsatisfying performance. In this paper, we propose an outlier detection\nensemble framework with embedded feature selection (ODEFS), to address this\nissue. Specifically, for each random sub-sampling based learning component,\nODEFS unifies feature selection and outlier detection into a pairwise ranking\nformulation to learn feature subsets that are tailored for the outlier\ndetection method. Moreover, we adopt the thresholded self-paced learning to\nsimultaneously optimize feature selection and example selection, which is\nhelpful to improve the reliability of the training set. After that, we design\nan alternate algorithm with proved convergence to solve the resultant\noptimization problem. In addition, we analyze the generalization error bound of\nthe proposed framework, which provides theoretical guarantee on the method and\ninsightful practical guidance. Comprehensive experimental results on 12\nreal-world datasets from diverse domains validate the superiority of the\nproposed ODEFS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:14:10 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Cheng", "Li", ""], ["Wang", "Yijie", ""], ["Liu", "Xinwang", ""], ["Li", "Bin", ""]]}, {"id": "2001.05494", "submitter": "Andrea Valenti", "authors": "Andrea Valenti, Antonio Carta, Davide Bacciu", "title": "Learning Style-Aware Symbolic Music Representations by Adversarial\n  Autoencoders", "comments": "Accepted for publication at the 24th European Conference on\n  Artificial Intelligence (ECAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenging open problem of learning an effective latent space\nfor symbolic music data in generative music modeling. We focus on leveraging\nadversarial regularization as a flexible and natural mean to imbue variational\nautoencoders with context information concerning music genre and style. Through\nthe paper, we show how Gaussian mixtures taking into account music metadata\ninformation can be used as an effective prior for the autoencoder latent space,\nintroducing the first Music Adversarial Autoencoder (MusAE). The empirical\nanalysis on a large scale benchmark shows that our model has a higher\nreconstruction accuracy than state-of-the-art models based on standard\nvariational autoencoders. It is also able to create realistic interpolations\nbetween two musical sequences, smoothly changing the dynamics of the different\ntracks. Experiments show that the model can organise its latent space\naccordingly to low-level properties of the musical pieces, as well as to embed\ninto the latent variables the high-level genre information injected from the\nprior distribution to increase its overall performance. This allows us to\nperform changes to the generated pieces in a principled way.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:07:20 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 14:44:50 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Valenti", "Andrea", ""], ["Carta", "Antonio", ""], ["Bacciu", "Davide", ""]]}, {"id": "2001.05495", "submitter": "Pinkesh Badjatiya", "authors": "Pinkesh Badjatiya, Manish Gupta, Vasudeva Varma", "title": "Stereotypical Bias Removal for Hate Speech Detection Task using\n  Knowledge-based Generalizations", "comments": null, "journal-ref": "In The World Wide Web Conference (WWW '19). Association for\n  Computing Machinery, New York, NY, USA, 49-59. 2019", "doi": "10.1145/3308558.3313504", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing cases of hate spread on social media platforms, it\nis critical to design abuse detection mechanisms to proactively avoid and\ncontrol such incidents. While there exist methods for hate speech detection,\nthey stereotype words and hence suffer from inherently biased training. Bias\nremoval has been traditionally studied for structured datasets, but we aim at\nbias mitigation from unstructured text data. In this paper, we make two\nimportant contributions. First, we systematically design methods to quantify\nthe bias for any model and propose algorithms for identifying the set of words\nwhich the model stereotypes. Second, we propose novel methods leveraging\nknowledge-based generalizations for bias-free learning. Knowledge-based\ngeneralization provides an effective way to encode knowledge because the\nabstraction they provide not only generalizes content but also facilitates\nretraction of information from the hate speech detection classifier, thereby\nreducing the imbalance. We experiment with multiple knowledge generalization\npolicies and analyze their effect on general performance and in mitigating\nbias. Our experiments with two real-world datasets, a Wikipedia Talk Pages\ndataset (WikiDetox) of size ~96k and a Twitter dataset of size ~24k, show that\nthe use of knowledge-based generalizations results in better performance by\nforcing the classifier to learn from generalized content. Our methods utilize\nexisting knowledge-bases and can easily be extended to other tasks\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 18:17:36 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Badjatiya", "Pinkesh", ""], ["Gupta", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "2001.05497", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel Kane, Shachar Lovett, Gaurav Mahajan", "title": "Noise-tolerant, Reliable Active Classification with Comparison Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion of massive, widely available unlabeled data in the past\nyears, finding label and time efficient, robust learning algorithms has become\never more important in theory and in practice. We study the paradigm of active\nlearning, in which algorithms with access to large pools of data may adaptively\nchoose what samples to label in the hope of exponentially increasing\nefficiency. By introducing comparisons, an additional type of query comparing\ntwo points, we provide the first time and query efficient algorithms for\nlearning non-homogeneous linear separators robust to bounded (Massart) noise.\nWe further provide algorithms for a generalization of the popular Tsybakov low\nnoise condition, and show how comparisons provide a strong reliability\nguarantee that is often impractical or impossible with only labels - returning\na classifier that makes no errors with high probability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel", ""], ["Lovett", "Shachar", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "2001.05517", "submitter": "David Burns", "authors": "David M. Burns and Cari M. Whyne", "title": "Personalized Activity Recognition with Deep Triplet Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge for a supervised learning approach to inertial human\nactivity recognition is the heterogeneity of data between individual users,\nresulting in very poor performance of impersonal algorithms for some subjects.\nWe present an approach to personalized activity recognition based on deep\nembeddings derived from a fully convolutional neural network. We experiment\nwith both categorical cross entropy loss and triplet loss for training the\nembedding, and describe a novel triplet loss function based on subject\ntriplets. We evaluate these methods on three publicly available inertial human\nactivity recognition data sets (MHEALTH, WISDM, and SPAR) comparing\nclassification accuracy, out-of-distribution activity detection, and embedding\ngeneralization to new activities. The novel subject triplet loss provides the\nbest performance overall, and all personalized deep embeddings out-perform our\nbaseline personalized engineered feature embedding and an impersonal fully\nconvolutional neural network classifier.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:17:02 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Burns", "David M.", ""], ["Whyne", "Cari M.", ""]]}, {"id": "2001.05532", "submitter": "Huy Phan", "authors": "Huy Phan and Ian V. McLoughlin and Lam Pham and Oliver Y. Ch\\'en and\n  Philipp Koch and Maarten De Vos and Alfred Mertins", "title": "Improving GANs for Speech Enhancement", "comments": "This letter has been accepted for publication in IEEE Signal\n  Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2020.3025020", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have recently been shown to be\nefficient for speech enhancement. However, most, if not all, existing speech\nenhancement GANs (SEGAN) make use of a single generator to perform one-stage\nenhancement mapping. In this work, we propose to use multiple generators that\nare chained to perform multi-stage enhancement mapping, which gradually refines\nthe noisy input signals in a stage-wise fashion. Furthermore, we study two\nscenarios: (1) the generators share their parameters and (2) the generators'\nparameters are independent. The former constrains the generators to learn a\ncommon mapping that is iteratively applied at all enhancement stages and\nresults in a small model footprint. On the contrary, the latter allows the\ngenerators to flexibly learn different enhancement mappings at different stages\nof the network at the cost of an increased model size. We demonstrate that the\nproposed multi-stage enhancement approach outperforms the one-stage SEGAN\nbaseline, where the independent generators lead to more favorable results than\nthe tied generators. The source code is available at\nhttp://github.com/pquochuy/idsegan.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:57:03 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 11:39:00 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 23:48:06 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Phan", "Huy", ""], ["McLoughlin", "Ian V.", ""], ["Pham", "Lam", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["De Vos", "Maarten", ""], ["Mertins", "Alfred", ""]]}, {"id": "2001.05537", "submitter": "Shiqian Ma", "authors": "Conghui Tan, Yuqiu Qian, Shiqian Ma, Tong Zhang", "title": "Accelerated Dual-Averaging Primal-Dual Method for Composite Convex\n  Minimization", "comments": null, "journal-ref": "Optimization Methods and Software 2020", "doi": "10.1080/10556788.2020.1713779", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual averaging-type methods are widely used in industrial machine learning\napplications due to their ability to promoting solution structure (e.g.,\nsparsity) efficiently. In this paper, we propose a novel accelerated\ndual-averaging primal-dual algorithm for minimizing a composite convex\nfunction. We also derive a stochastic version of the proposed method which\nsolves empirical risk minimization, and its advantages on handling sparse data\nare demonstrated both theoretically and empirically.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:05:41 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Tan", "Conghui", ""], ["Qian", "Yuqiu", ""], ["Ma", "Shiqian", ""], ["Zhang", "Tong", ""]]}, {"id": "2001.05540", "submitter": "Laura Ruis", "authors": "Laura Ruis, Mitchell Stern, Julia Proskurnia, William Chan", "title": "Insertion-Deletion Transformer", "comments": "Accepted as an Extended Abstract at the Workshop of Neural Generation\n  and Translation (WNGT 2019) at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Insertion-Deletion Transformer, a novel transformer-based\nneural architecture and training method for sequence generation. The model\nconsists of two phases that are executed iteratively, 1) an insertion phase and\n2) a deletion phase. The insertion phase parameterizes a distribution of\ninsertions on the current output hypothesis, while the deletion phase\nparameterizes a distribution of deletions over the current output hypothesis.\nThe training method is a principled and simple algorithm, where the deletion\nmodel obtains its signal directly on-policy from the insertion model output. We\ndemonstrate the effectiveness of our Insertion-Deletion Transformer on\nsynthetic translation tasks, obtaining significant BLEU score improvement over\nan insertion-only model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:26:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ruis", "Laura", ""], ["Stern", "Mitchell", ""], ["Proskurnia", "Julia", ""], ["Chan", "William", ""]]}, {"id": "2001.05545", "submitter": "Vinay Verma Kumar", "authors": "Vinay Kumar Verma, Pravendra Singh, Vinay P. Namboodiri, Piyush Rai", "title": "A \"Network Pruning Network\" Approach to Deep Model Compression", "comments": "Accepted in WACV'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a filter pruning approach for deep model compression, using a\nmultitask network. Our approach is based on learning a a pruner network to\nprune a pre-trained target network. The pruner is essentially a multitask deep\nneural network with binary outputs that help identify the filters from each\nlayer of the original network that do not have any significant contribution to\nthe model and can therefore be pruned. The pruner network has the same\narchitecture as the original network except that it has a\nmultitask/multi-output last layer containing binary-valued outputs (one per\nfilter), which indicate which filters have to be pruned. The pruner's goal is\nto minimize the number of filters from the original network by assigning zero\nweights to the corresponding output feature-maps. In contrast to most of the\nexisting methods, instead of relying on iterative pruning, our approach can\nprune the network (original network) in one go and, moreover, does not require\nspecifying the degree of pruning for each layer (and can learn it instead). The\ncompressed model produced by our approach is generic and does not need any\nspecial hardware/software support. Moreover, augmenting with other methods such\nas knowledge distillation, quantization, and connection pruning can increase\nthe degree of compression for the proposed approach. We show the efficacy of\nour proposed approach for classification and object detection tasks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:38:23 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Verma", "Vinay Kumar", ""], ["Singh", "Pravendra", ""], ["Namboodiri", "Vinay P.", ""], ["Rai", "Piyush", ""]]}, {"id": "2001.05549", "submitter": "Ilker Ali Ozkan", "authors": "Esra Kaya, \\.Ismail Sar{\\i}ta\\c{s}, Ilker Ali Ozkan", "title": "Supervised Segmentation of Retinal Vessel Structures Using ANN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, a supervised retina blood vessel segmentation process was\nperformed on the green channel of the RGB image using artificial neural network\n(ANN). The green channel is preferred because the retinal vessel structures can\nbe distinguished most clearly from the green channel of the RGB image. The\nstudy was performed using 20 images in the DRIVE data set which is one of the\nmost common retina data sets known. The images went through some preprocessing\nstages like contrastlimited adaptive histogram equalization (CLAHE), color\nintensity adjustment, morphological operations and median and Gaussian\nfiltering to obtain a good segmentation. Retinal vessel structures were\nhighlighted with top-hat and bot-hat morphological operations and converted to\nbinary image by using global thresholding. Then, the network was trained by the\nbinary version of the images specified as training images in the dataset and\nthe targets are the images segmented manually by a specialist. The average\nsegmentation accuracy for 20 images was found as 0.9492.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 20:48:03 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Kaya", "Esra", ""], ["Sar\u0131ta\u015f", "\u0130smail", ""], ["Ozkan", "Ilker Ali", ""]]}, {"id": "2001.05559", "submitter": "Yan Ru Pei", "authors": "Haik Manukian, Yan Ru Pei, Sean R.B. Bearden, Massimiliano Di Ventra", "title": "Mode-Assisted Unsupervised Learning of Restricted Boltzmann Machines", "comments": "28 pages, 4 figures. Revision: Updated footnote format", "journal-ref": "Communications Physics volume 3, Article number:105 (2020)", "doi": "10.1038/s42005-020-0373-8", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBMs) are a powerful class of generative\nmodels, but their training requires computing a gradient that, unlike\nsupervised backpropagation on typical loss functions, is notoriously difficult\neven to approximate. Here, we show that properly combining standard gradient\nupdates with an off-gradient direction, constructed from samples of the RBM\nground state (mode), improves their training dramatically over traditional\ngradient methods. This approach, which we call mode training, promotes faster\ntraining and stability, in addition to lower converged relative entropy (KL\ndivergence). Along with the proofs of stability and convergence of this method,\nwe also demonstrate its efficacy on synthetic datasets where we can compute KL\ndivergences exactly, as well as on a larger machine learning standard, MNIST.\nThe mode training we suggest is quite versatile, as it can be applied in\nconjunction with any given gradient method, and is easily extended to more\ngeneral energy-based neural network structures such as deep, convolutional and\nunrestricted Boltzmann machines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:12:44 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 21:50:27 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Manukian", "Haik", ""], ["Pei", "Yan Ru", ""], ["Bearden", "Sean R. B.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "2001.05566", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Yuri Boykov, Fatih Porikli, Antonio Plaza, Nasser\n  Kehtarnavaz, and Demetri Terzopoulos", "title": "Image Segmentation Using Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image segmentation is a key topic in image processing and computer vision\nwith applications such as scene understanding, medical image analysis, robotic\nperception, video surveillance, augmented reality, and image compression, among\nmany others. Various algorithms for image segmentation have been developed in\nthe literature. Recently, due to the success of deep learning models in a wide\nrange of vision applications, there has been a substantial amount of works\naimed at developing image segmentation approaches using deep learning models.\nIn this survey, we provide a comprehensive review of the literature at the time\nof this writing, covering a broad spectrum of pioneering works for semantic and\ninstance-level segmentation, including fully convolutional pixel-labeling\nnetworks, encoder-decoder architectures, multi-scale and pyramid based\napproaches, recurrent networks, visual attention models, and generative models\nin adversarial settings. We investigate the similarity, strengths and\nchallenges of these deep learning models, examine the most widely used\ndatasets, report performances, and discuss promising future research directions\nin this area.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:37:47 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 01:40:34 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 14:56:07 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 15:19:39 GMT"}, {"version": "v5", "created": "Sun, 15 Nov 2020 04:51:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Minaee", "Shervin", ""], ["Boykov", "Yuri", ""], ["Porikli", "Fatih", ""], ["Plaza", "Antonio", ""], ["Kehtarnavaz", "Nasser", ""], ["Terzopoulos", "Demetri", ""]]}, {"id": "2001.05567", "submitter": "Nimar Arora", "authors": "Nimar S. Arora, Nazanin Khosravani Tehrani, Kinjal Divesh Shah,\n  Michael Tingley, Yucen Lily Li, Narjes Torabi, David Noursi, Sepehr Akhavan\n  Masouleh, Eric Lippert, Erik Meijer", "title": "Newtonian Monte Carlo: single-site MCMC meets second-order gradient\n  methods", "comments": "StarAI has a 6 page limit excluding references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-site Markov Chain Monte Carlo (MCMC) is a variant of MCMC in which a\nsingle coordinate in the state space is modified in each step. Structured\nrelational models are a good candidate for this style of inference. In the\nsingle-site context, second order methods become feasible because the typical\ncubic costs associated with these methods is now restricted to the dimension of\neach coordinate. Our work, which we call Newtonian Monte Carlo (NMC), is a\nmethod to improve MCMC convergence by analyzing the first and second order\ngradients of the target density to determine a suitable proposal density at\neach point. Existing first order gradient-based methods suffer from the problem\nof determining an appropriate step size. Too small a step size and it will take\na large number of steps to converge, while a very large step size will cause it\nto overshoot the high density region. NMC is similar to the Newton-Raphson\nupdate in optimization where the second order gradient is used to automatically\nscale the step size in each dimension. However, our objective is to find a\nparameterized proposal density rather than the maxima.\n  As a further improvement on existing first and second order methods, we show\nthat random variables with constrained supports don't need to be transformed\nbefore taking a gradient step. We demonstrate the efficiency of NMC on a number\nof different domains. For statistical models where the prior is conjugate to\nthe likelihood, our method recovers the posterior quite trivially in one step.\nHowever, we also show results on fairly large non-conjugate models, where NMC\nperforms better than adaptive first order methods such as NUTS or other inexact\nscalable inference methods such as Stochastic Variational Inference or\nbootstrapping.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:40:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Arora", "Nimar S.", ""], ["Tehrani", "Nazanin Khosravani", ""], ["Shah", "Kinjal Divesh", ""], ["Tingley", "Michael", ""], ["Li", "Yucen Lily", ""], ["Torabi", "Narjes", ""], ["Noursi", "David", ""], ["Masouleh", "Sepehr Akhavan", ""], ["Lippert", "Eric", ""], ["Meijer", "Erik", ""]]}, {"id": "2001.05571", "submitter": "Jan Brabec", "authors": "Jan Brabec, Tom\\'a\\v{s} Kom\\'arek, Vojt\\v{e}ch Franc, Luk\\'a\\v{s}\n  Machlica", "title": "On Model Evaluation under Non-constant Class Imbalance", "comments": "Accepted for proceedings of ICCS 2020. Supplementary code at:\n  https://github.com/CiscoCTA/nci_eval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world classification problems are significantly class-imbalanced to\ndetriment of the class of interest. The standard set of proper evaluation\nmetrics is well-known but the usual assumption is that the test dataset\nimbalance equals the real-world imbalance. In practice, this assumption is\noften broken for various reasons. The reported results are then often too\noptimistic and may lead to wrong conclusions about industrial impact and\nsuitability of proposed techniques. We introduce methods focusing on evaluation\nunder non-constant class imbalance. We show that not only the absolute values\nof commonly used metrics, but even the order of classifiers in relation to the\nevaluation metric used is affected by the change of the imbalance rate.\nFinally, we demonstrate that using subsampling in order to get a test dataset\nwith class imbalance equal to the one observed in the wild is not necessary,\nand eventually can lead to significant errors in classifier's performance\nestimate.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 21:52:24 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 17:58:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Brabec", "Jan", ""], ["Kom\u00e1rek", "Tom\u00e1\u0161", ""], ["Franc", "Vojt\u011bch", ""], ["Machlica", "Luk\u00e1\u0161", ""]]}, {"id": "2001.05572", "submitter": "Oliver Urbann", "authors": "Oliver Urbann, Simon Camphausen, Arne Moos, Ingmar Schwarz, S\\\"oren\n  Kerner, Maximilian Otten", "title": "A C Code Generator for Fast Inference and Simple Deployment of\n  Convolutional Neural Networks on Resource Constrained Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference of Convolutional Neural Networks in time critical applications\nusually requires a GPU. In robotics or embedded devices these are often not\navailable due to energy, space and cost constraints. Furthermore, installation\nof a deep learning framework or even a native compiler on the target platform\nis not possible. This paper presents a neural network code generator (NNCG)\nthat generates from a trained CNN a plain ANSI C code file that encapsulates\nthe inference in single a function. It can easily be included in existing\nprojects and due to lack of dependencies, cross compilation is usually\npossible. Additionally, the code generation is optimized based on the known\ntrained CNN and target platform following four design principles. The system is\nevaluated utilizing small CNN designed for this application. Compared to\nTensorFlow XLA and Glow speed-ups of up to 11.81 can be shown and even GPUs are\noutperformed regarding latency.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:46:14 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Urbann", "Oliver", ""], ["Camphausen", "Simon", ""], ["Moos", "Arne", ""], ["Schwarz", "Ingmar", ""], ["Kerner", "S\u00f6ren", ""], ["Otten", "Maximilian", ""]]}, {"id": "2001.05573", "submitter": "Michael Hind", "authors": "Michael Hind, Dennis Wei, Yunfeng Zhang", "title": "Consumer-Driven Explanations for Machine Learning Decisions: An\n  Empirical Study of Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many proposed methods for explaining machine learning predictions are in fact\nchallenging to understand for nontechnical consumers. This paper builds upon an\nalternative consumer-driven approach called TED that asks for explanations to\nbe provided in training data, along with target labels. Using semi-synthetic\ndata from credit approval and employee retention applications, experiments are\nconducted to investigate some practical considerations with TED, including its\nperformance with different classification algorithms, varying numbers of\nexplanations, and variability in explanations. A new algorithm is proposed to\nhandle the case where some training examples do not have explanations. Our\nresults show that TED is robust to increasing numbers of explanations, noisy\nexplanations, and large fractions of missing explanations, thus making advances\ntoward its practical deployment.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 18:45:48 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hind", "Michael", ""], ["Wei", "Dennis", ""], ["Zhang", "Yunfeng", ""]]}, {"id": "2001.05574", "submitter": "Dou Yan Liu Goodman", "authors": "Dou Goodman, Hao Xin, Wang Yang, Wu Yuesheng, Xiong Junfeng, and Zhang\n  Huan", "title": "Advbox: a toolbox to generate adversarial examples that fool neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have been extensively deployed for computer\nvision tasks, particularly visual classification problems, where new algorithms\nreported to achieve or even surpass the human performance. Recent studies have\nshown that they are all vulnerable to the attack of adversarial examples. Small\nand often imperceptible perturbations to the input images are sufficient to\nfool the most powerful neural networks. \\emph{Advbox} is a toolbox to generate\nadversarial examples that fool neural networks in PaddlePaddle, PyTorch,\nCaffe2, MxNet, Keras, TensorFlow and it can benchmark the robustness of machine\nlearning models. Compared to previous work, our platform supports black box\nattacks on Machine-Learning-as-a-service, as well as more attack scenarios,\nsuch as Face Recognition Attack, Stealth T-shirt, and DeepFake Face Detect. The\ncode is licensed under the Apache 2.0 and is openly available at\nhttps://github.com/advboxes/AdvBox. Advbox now supports Python 3.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:11:27 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 01:43:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 13:35:30 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 14:57:04 GMT"}, {"version": "v5", "created": "Wed, 26 Aug 2020 23:19:21 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Goodman", "Dou", ""], ["Xin", "Hao", ""], ["Yang", "Wang", ""], ["Yuesheng", "Wu", ""], ["Junfeng", "Xiong", ""], ["Huan", "Zhang", ""]]}, {"id": "2001.05591", "submitter": "Michael Minyi Zhang", "authors": "Avinava Dubey, Michael Minyi Zhang, Eric P. Xing, Sinead A. Williamson", "title": "Distributed, partially collapsed MCMC for Bayesian Nonparametrics", "comments": "To appear in the 23rd International Conference on Artificial\n  Intelligence and Statistics", "journal-ref": "Artificial Intelligence and Statistics, 108:3685-3695, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric (BNP) models provide elegant methods for discovering\nunderlying latent features within a data set, but inference in such models can\nbe slow. We exploit the fact that completely random measures, which commonly\nused models like the Dirichlet process and the beta-Bernoulli process can be\nexpressed as, are decomposable into independent sub-measures. We use this\ndecomposition to partition the latent measure into a finite measure containing\nonly instantiated components, and an infinite measure containing all other\ncomponents. We then select different inference algorithms for the two\ncomponents: uncollapsed samplers mix well on the finite measure, while\ncollapsed samplers mix well on the infinite, sparsely occupied tail. The\nresulting hybrid algorithm can be applied to a wide class of models, and can be\neasily distributed to allow scalable inference without sacrificing asymptotic\nconvergence guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 23:10:13 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:29:19 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:57:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Dubey", "Avinava", ""], ["Zhang", "Michael Minyi", ""], ["Xing", "Eric P.", ""], ["Williamson", "Sinead A.", ""]]}, {"id": "2001.05617", "submitter": "Varun Embar", "authors": "Varun Embar, Sriram Srinivasan, Lise Getoor", "title": "Estimating Aggregate Properties In Relational Networks With Unobserved\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregate network properties such as cluster cohesion and the number of\nbridge nodes can be used to glean insights about a network's community\nstructure, spread of influence and the resilience of the network to faults.\nEfficiently computing network properties when the network is fully observed has\nreceived significant attention (Wasserman and Faust 1994; Cook and Holder\n2006), however the problem of computing aggregate network properties when there\nis missing data attributes has received little attention. Computing these\nproperties for networks with missing attributes involves performing inference\nover the network. Statistical relational learning (SRL) and graph neural\nnetworks (GNNs) are two classes of machine learning approaches well suited for\ninferring missing attributes in a graph. In this paper, we study the\neffectiveness of these approaches in estimating aggregate properties on\nnetworks with missing attributes. We compare two SRL approaches and three GNNs.\nFor these approaches we estimate these properties using point estimates such as\nMAP and mean. For SRL-based approaches that can infer a joint distribution over\nthe missing attributes, we also estimate these properties as an expectation\nover the distribution. To compute the expectation tractably for probabilistic\nsoft logic, one of the SRL approaches that we study, we introduce a novel\nsampling framework. In the experimental evaluation, using three benchmark\ndatasets, we show that SRL-based approaches tend to outperform GNN-based\napproaches both in computing aggregate properties and predictive accuracy.\nSpecifically, we show that estimating the aggregate properties as an\nexpectation over the joint distribution outperforms point estimates.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 02:43:02 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 00:50:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Embar", "Varun", ""], ["Srinivasan", "Sriram", ""], ["Getoor", "Lise", ""]]}, {"id": "2001.05624", "submitter": "Toshitaka Hayashi", "authors": "Toshitaka Hayashi and Hamido Fujita", "title": "Cluster-based Zero-shot learning for multivariate data", "comments": "J Ambient Intell Human Comput (2020)", "journal-ref": null, "doi": "10.1007/s12652-020-02268-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning requires a sufficient training dataset which includes all\nlabel. However, there are cases that some class is not in the training data.\nZero-Shot Learning (ZSL) is the task of predicting class that is not in the\ntraining data(target class). The existing ZSL method is done for image data.\nHowever, the zero-shot problem should happen to every data type. Hence,\nconsidering ZSL for other data types is required. In this paper, we propose the\ncluster-based ZSL method, which is a baseline method for multivariate binary\nclassification problems. The proposed method is based on the assumption that if\ndata is far from training data, the data is considered as target class. In\ntraining, clustering is done for training data. In prediction, the data is\ndetermined belonging to a cluster or not. If data does not belong to a cluster,\nthe data is predicted as target class. The proposed method is evaluated and\ndemonstrated using the KEEL dataset. This paper has been published in the\nJournal of Ambient Intelligence and Humanized Computing. The final version is\navailable at the following URL:\nhttps://link.springer.com/article/10.1007/s12652-020-02268-5\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:01:00 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 02:16:46 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 06:23:44 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 02:41:39 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Hayashi", "Toshitaka", ""], ["Fujita", "Hamido", ""]]}, {"id": "2001.05636", "submitter": "Haitao Xu", "authors": "Haitao Xu and Brendan McCane and Lech Szymanski and Craig Atkinson", "title": "MIME: Mutual Information Minimisation Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that reinforcement learning agents that learn by surprise (surprisal)\nget stuck at abrupt environmental transition boundaries because these\ntransitions are difficult to learn. We propose a counter-intuitive solution\nthat we call Mutual Information Minimising Exploration (MIME) where an agent\nlearns a latent representation of the environment without trying to predict the\nfuture states. We show that our agent performs significantly better over sharp\ntransition boundaries while matching the performance of surprisal driven agents\nelsewhere. In particular, we show state-of-the-art performance on difficult\nlearning games such as Gravitar, Montezuma's Revenge and Doom.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 04:01:10 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Xu", "Haitao", ""], ["McCane", "Brendan", ""], ["Szymanski", "Lech", ""], ["Atkinson", "Craig", ""]]}, {"id": "2001.05643", "submitter": "Saeed Amirgholipour Kasmani", "authors": "Saeed Amirgholipour, Xiangjian He, Wenjing Jia, Dadong Wang, and Lei\n  Liu", "title": "PDANet: Pyramid Density-aware Attention Net for Accurate Crowd Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd counting, i.e., estimating the number of people in a crowded area, has\nattracted much interest in the research community. Although many attempts have\nbeen reported, crowd counting remains an open real-world problem due to the\nvast scale variations in crowd density within the interested area, and severe\nocclusion among the crowd. In this paper, we propose a novel Pyramid\nDensity-Aware Attention-based network, abbreviated as PDANet, that leverages\nthe attention, pyramid scale feature and two branch decoder modules for\ndensity-aware crowd counting. The PDANet utilizes these modules to extract\ndifferent scale features, focus on the relevant information, and suppress the\nmisleading ones. We also address the variation of crowdedness levels among\ndifferent images with an exclusive Density-Aware Decoder (DAD). For this\npurpose, a classifier evaluates the density level of the input features and\nthen passes them to the corresponding high and low crowded DAD modules.\nFinally, we generate an overall density map by considering the summation of low\nand high crowded density maps as spatial attention. Meanwhile, we employ two\nlosses to create a precise density map for the input scene. Extensive\nevaluations conducted on the challenging benchmark datasets well demonstrate\nthe superior performance of the proposed PDANet in terms of the accuracy of\ncounting and generated density maps over the well-known state of the arts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 04:26:05 GMT"}, {"version": "v10", "created": "Wed, 29 Apr 2020 03:04:05 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 05:25:17 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2020 05:29:56 GMT"}, {"version": "v4", "created": "Wed, 29 Jan 2020 05:31:50 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2020 05:56:25 GMT"}, {"version": "v6", "created": "Tue, 25 Feb 2020 05:57:54 GMT"}, {"version": "v7", "created": "Thu, 26 Mar 2020 02:44:49 GMT"}, {"version": "v8", "created": "Sat, 4 Apr 2020 12:20:18 GMT"}, {"version": "v9", "created": "Wed, 15 Apr 2020 02:21:27 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Amirgholipour", "Saeed", ""], ["He", "Xiangjian", ""], ["Jia", "Wenjing", ""], ["Wang", "Dadong", ""], ["Liu", "Lei", ""]]}, {"id": "2001.05647", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Yufeng Gu, Nicha Dvornek, Lawrence Staib, Pamela Ventola,\n  and James S. Duncan", "title": "Multi-site fMRI Analysis Using Privacy-preserving Federated Learning and\n  Domain Adaptation: ABIDE Results", "comments": "12 pagers, 11 figures, published at Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have shown their advantage in many different tasks,\nincluding neuroimage analysis. However, to effectively train a high-quality\ndeep learning model, the aggregation of a significant amount of patient\ninformation is required. The time and cost for acquisition and annotation in\nassembling, for example, large fMRI datasets make it difficult to acquire large\nnumbers at a single site. However, due to the need to protect the privacy of\npatient data, it is hard to assemble a central database from multiple\ninstitutions. Federated learning allows for population-level models to be\ntrained without centralizing entities' data by transmitting the global model to\nlocal entities, training the model locally, and then averaging the gradients or\nweights in the global model. However, some studies suggest that private\ninformation can be recovered from the model gradients or weights. In this work,\nwe address the problem of multi-site fMRI classification with a\nprivacy-preserving strategy. To solve the problem, we propose a federated\nlearning approach, where a decentralized iterative optimization algorithm is\nimplemented and shared local model weights are altered by a randomization\nmechanism. Considering the systemic differences of fMRI distributions from\ndifferent sites, we further propose two domain adaptation methods in this\nfederated learning formulation. We investigate various practical aspects of\nfederated model optimization and compare federated learning with alternative\ntraining strategies. Overall, our results demonstrate that it is promising to\nutilize multi-site data without data sharing to boost neuroimage analysis\nperformance and find reliable disease-related biomarkers. Our proposed pipeline\ncan be generalized to other privacy-sensitive medical data analysis problems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 04:49:33 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 19:55:21 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 16:48:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Gu", "Yufeng", ""], ["Dvornek", "Nicha", ""], ["Staib", "Lawrence", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "2001.05654", "submitter": "Hongwei Xie", "authors": "Hongwei Xie, Jiafang Wang, Baitao Shao, Jian Gu, Mingyang Li", "title": "LE-HGR: A Lightweight and Efficient RGB-based Online Gesture Recognition\n  Network for Embedded AR Devices", "comments": "Published in: 2019 IEEE International Symposium on Mixed and\n  Augmented Reality Adjunct (ISMAR-Adjunct)", "journal-ref": null, "doi": "10.1109/ISMAR-Adjunct.2019.00-30", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online hand gesture recognition (HGR) techniques are essential in augmented\nreality (AR) applications for enabling natural human-to-computer interaction\nand communication. In recent years, the consumer market for low-cost AR devices\nhas been rapidly growing, while the technology maturity in this domain is still\nlimited. Those devices are typical of low prices, limited memory, and\nresource-constrained computational units, which makes online HGR a challenging\nproblem. To tackle this problem, we propose a lightweight and computationally\nefficient HGR framework, namely LE-HGR, to enable real-time gesture recognition\non embedded devices with low computing power. We also show that the proposed\nmethod is of high accuracy and robustness, which is able to reach high-end\nperformance in a variety of complicated interaction environments. To achieve\nour goal, we first propose a cascaded multi-task convolutional neural network\n(CNN) to simultaneously predict probabilities of hand detection and regress\nhand keypoint locations online. We show that, with the proposed cascaded\narchitecture design, false-positive estimates can be largely eliminated.\nAdditionally, an associated mapping approach is introduced to track the hand\ntrace via the predicted locations, which addresses the interference of\nmulti-handedness. Subsequently, we propose a trace sequence neural network\n(TraceSeqNN) to recognize the hand gesture by exploiting the motion features of\nthe tracked trace. Finally, we provide a variety of experimental results to\nshow that the proposed framework is able to achieve state-of-the-art accuracy\nwith significantly reduced computational cost, which are the key properties for\nenabling real-time applications in low-cost commercial devices such as mobile\ndevices and AR/VR headsets.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 05:23:24 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Xie", "Hongwei", ""], ["Wang", "Jiafang", ""], ["Shao", "Baitao", ""], ["Gu", "Jian", ""], ["Li", "Mingyang", ""]]}, {"id": "2001.05665", "submitter": "Pegah Jandaghi", "authors": "Pegah Jandaghi, Jay Pujara", "title": "Human-like Time Series Summaries via Trend Utility Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, humans prefer a text-based representation of quantitative\ndata over numerical, tabular, or graphical representations. The attractiveness\nof textual summaries for complex data has inspired research on data-to-text\nsystems. While there are several data-to-text tools for time series, few of\nthem try to mimic how humans summarize for time series. In this paper, we\npropose a model to create human-like text descriptions for time series. Our\nsystem finds patterns in time series data and ranks these patterns based on\nempirical observations of human behavior using utility estimation. Our proposed\nutility estimation model is a Bayesian network capturing interdependencies\nbetween different patterns. We describe the learning steps for this network and\nintroduce baselines along with their performance for each step. The output of\nour system is a natural language description of time series that attempts to\nmatch a human's summary of the same data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:09:50 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:55:15 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Jandaghi", "Pegah", ""], ["Pujara", "Jay", ""]]}, {"id": "2001.05670", "submitter": "Tatsuki Serizawa", "authors": "T. Serizawa, H. Fujita", "title": "Optimization of Convolutional Neural Network Using the Linearly\n  Decreasing Weight Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) is one of the most frequently used deep\nlearning techniques. Various forms of models have been proposed and improved\nfor learning at CNN. When learning with CNN, it is necessary to determine the\noptimal hyperparameters. However, the number of hyperparameters is so large\nthat it is difficult to do it manually, so much research has been done on\nautomation. A method that uses metaheuristic algorithms is attracting attention\nin research on hyperparameter optimization. Metaheuristic algorithms are\nnaturally inspired and include evolution strategies, genetic algorithms,\nantcolony optimization and particle swarm optimization. In particular, particle\nswarm optimization converges faster than genetic algorithms, and various models\nhave been proposed. In this paper, we propose CNN hyperparameter optimization\nwith linearly decreasing weight particle swarm optimization (LDWPSO). In the\nexperiment, the MNIST data set and CIFAR-10 data set, which are often used as\nbenchmark data sets, are used. By optimizing CNN hyperparameters with LDWPSO,\nlearning the MNIST and CIFAR-10 datasets, we compare the accuracy with a\nstandard CNN based on LeNet-5. As a result, when using the MNIST dataset, the\nbaseline CNN is 94.02% at the 5th epoch, compared to 98.95% for LDWPSO CNN,\nwhich improves accuracy. When using the CIFAR-10 dataset, the Baseline CNN is\n28.07% at the 10th epoch, compared to 69.37% for the LDWPSO CNN, which greatly\nimproves accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:27:50 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:49:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Serizawa", "T.", ""], ["Fujita", "H.", ""]]}, {"id": "2001.05674", "submitter": "L\\'eopold Cambier", "authors": "L\\'eopold Cambier, Anahita Bhiwandiwalla, Ting Gong, Mehran Nekuii,\n  Oguz H Elibol, Hanlin Tang", "title": "Shifted and Squeezed 8-bit Floating Point format for Low-Precision\n  Training of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training with larger number of parameters while keeping fast iterations is an\nincreasingly adopted strategy and trend for developing better performing Deep\nNeural Network (DNN) models. This necessitates increased memory footprint and\ncomputational requirements for training. Here we introduce a novel methodology\nfor training deep neural networks using 8-bit floating point (FP8) numbers.\nReduced bit precision allows for a larger effective memory and increased\ncomputational speed. We name this method Shifted and Squeezed FP8 (S2FP8). We\nshow that, unlike previous 8-bit precision training methods, the proposed\nmethod works out-of-the-box for representative models: ResNet-50, Transformer\nand NCF. The method can maintain model accuracy without requiring fine-tuning\nloss scaling parameters or keeping certain layers in single precision. We\nintroduce two learnable statistics of the DNN tensors - shifted and squeezed\nfactors that are used to optimally adjust the range of the tensors in 8-bits,\nthus minimizing the loss in information due to quantization.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:38:27 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Cambier", "L\u00e9opold", ""], ["Bhiwandiwalla", "Anahita", ""], ["Gong", "Ting", ""], ["Nekuii", "Mehran", ""], ["Elibol", "Oguz H", ""], ["Tang", "Hanlin", ""]]}, {"id": "2001.05676", "submitter": "Ji Hyung Jung", "authors": "Ji Hyung Jung, Hye Won Chung, and Ji Oon Lee", "title": "Weak Detection in the Spiked Wigner Model with General Rank", "comments": "35 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical decision process of detecting the signal from a\n`signal+noise' type matrix model with an additive Wigner noise. We propose a\nhypothesis test based on the linear spectral statistics of the data matrix,\nwhich does not depend on the distribution of the signal or the noise. The test\nis optimal under the Gaussian noise if the signal-to-noise ratio is small, as\nit minimizes the sum of the Type-I and Type-II errors. Under the non-Gaussian\nnoise, the test can be improved with an entrywise transformation to the data\nmatrix. We also introduce an algorithm that estimates the rank of the signal\nwhen it is not known a priori.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:40:24 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:29:54 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 05:33:32 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Jung", "Ji Hyung", ""], ["Chung", "Hye Won", ""], ["Lee", "Ji Oon", ""]]}, {"id": "2001.05681", "submitter": "Aaron Hu", "authors": "Youchuan Hu, Le Yan, Tingting Hang and Jun Feng", "title": "Stream-Flow Forecasting of Small Rivers Based on LSTM", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream-flow forecasting for small rivers has always been of great importance,\nyet comparatively challenging due to the special features of rivers with\nsmaller volume. Artificial Intelligence (AI) methods have been employed in this\narea for long, but improvement of forecast quality is still on the way. In this\npaper, we tried to provide a new method to do the forecast using the Long-Short\nTerm Memory (LSTM) deep learning model, which aims in the field of time-series\ndata. Utilizing LSTM, we collected the stream flow data from one hydrologic\nstation in Tunxi, China, and precipitation data from 11 rainfall stations\naround to forecast the stream flow data from that hydrologic station 6 hours in\nthe future. We evaluated the prediction results using three criteria: root mean\nsquare error (RMSE), mean absolute error (MAE), and coefficient of\ndetermination (R^2). By comparing LSTM's prediction with predictions of Support\nVector Regression (SVR) and Multilayer Perceptions (MLP) models, we showed that\nLSTM has better performance, achieving RMSE of 82.007, MAE of 27.752, and R^2\nof 0.970. We also did extended experiments on LSTM model, discussing influence\nfactors of its performance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 07:14:32 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hu", "Youchuan", ""], ["Yan", "Le", ""], ["Hang", "Tingting", ""], ["Feng", "Jun", ""]]}, {"id": "2001.05699", "submitter": "Li Ye", "authors": "Li Ye, Yishi Lin, Hong Xie, John C.S. Lui", "title": "Combining Offline Causal Inference and Online Bandit Learning for Data\n  Driven Decision", "comments": "27 pages, 35 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question for companies with large amount of logged data is: How\nto use such logged data together with incoming streaming data to make good\ndecisions? Many companies currently make decisions via online A/B tests, but\nwrong decisions during testing hurt users' experiences and cause irreversible\ndamage. A typical alternative is offline causal inference, which analyzes\nlogged data alone to make decisions. However, these decisions are not adaptive\nto the new incoming data, and so a wrong decision will continuously hurt users'\nexperiences. To overcome the aforementioned limitations, we propose a framework\nto unify offline causal inference algorithms (e.g., weighting, matching) and\nonline learning algorithms (e.g., UCB, LinUCB). We propose novel algorithms and\nderive bounds on the decision accuracy via the notion of \"regret\". We derive\nthe first upper regret bound for forest-based online bandit algorithms.\nExperiments on two real datasets show that our algorithms outperform other\nalgorithms that use only logged data or online feedbacks, or algorithms that do\nnot use the data properly.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:58:42 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 13:27:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ye", "Li", ""], ["Lin", "Yishi", ""], ["Xie", "Hong", ""], ["Lui", "John C. S.", ""]]}, {"id": "2001.05703", "submitter": "Linh K\\\"astner", "authors": "Linh K\\\"astner, Daniel Dimitrov, Jens Lambrecht", "title": "A Markerless Deep Learning-based 6 Degrees of Freedom PoseEstimation for\n  with Mobile Robots using RGB Data", "comments": "6 pages,5 figures. arXiv admin note: text overlap with\n  arXiv:1912.12101", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmented Reality has been subject to various integration efforts within\nindustries due to its ability to enhance human machine interaction and\nunderstanding. Neural networks have achieved remarkable results in areas of\ncomputer vision, which bear great potential to assist and facilitate an\nenhanced Augmented Reality experience. However, most neural networks are\ncomputationally intensive and demand huge processing power thus, are not\nsuitable for deployment on Augmented Reality devices. In this work we propose a\nmethod to deploy state of the art neural networks for real time 3D object\nlocalization on augmented reality devices. As a result, we provide a more\nautomated method of calibrating the AR devices with mobile robotic systems. To\naccelerate the calibration process and enhance user experience, we focus on\nfast 2D detection approaches which are extracting the 3D pose of the object\nfast and accurately by using only 2D input. The results are implemented into an\nAugmented Reality application for intuitive robot control and sensor data\nvisualization. For the 6D annotation of 2D images, we developed an annotation\ntool, which is, to our knowledge, the first open source tool to be available.\nWe achieve feasible results which are generally applicable to any AR device\nthus making this work promising for further research in combining high\ndemanding neural networks with Internet of Things devices.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 09:13:31 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["K\u00e4stner", "Linh", ""], ["Dimitrov", "Daniel", ""], ["Lambrecht", "Jens", ""]]}, {"id": "2001.05724", "submitter": "Shunwang Gong", "authors": "Guadalupe Gonzalez, Shunwang Gong, Ivan Laponogov, Kirill Veselkov,\n  Michael Bronstein", "title": "Graph Attentional Autoencoder for Anticancer Hyperfood Prediction", "comments": "33rd Conference on Neural Information Processing Systems Workshops\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts have shown the possibility to discover anticancer\ndrug-like molecules in food from their effect on protein-protein interaction\nnetworks, opening a potential pathway to disease-beating diet design. We\nformulate this task as a graph classification problem on which graph neural\nnetworks (GNNs) have achieved state-of-the-art results. However, GNNs are\ndifficult to train on sparse low-dimensional features according to our\nempirical evidence. Here, we present graph augmented features, integrating\ngraph structural information and raw node attributes with varying ratios, to\nease the training of networks. We further introduce a novel neural network\narchitecture on graphs, the Graph Attentional Autoencoder (GAA) to predict food\ncompounds with anticancer properties based on perturbed protein networks. We\ndemonstrate that the method outperforms the baseline approach and\nstate-of-the-art graph classification models in this task.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:08:51 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Gonzalez", "Guadalupe", ""], ["Gong", "Shunwang", ""], ["Laponogov", "Ivan", ""], ["Veselkov", "Kirill", ""], ["Bronstein", "Michael", ""]]}, {"id": "2001.05726", "submitter": "Raju Ram", "authors": "Raju Ram, Sabine M\\\"uller, Franz-Josef Pfreundt, Nicolas R. Gauger,\n  Janis Keuper", "title": "Scalable Hyperparameter Optimization with Lazy Gaussian Processes", "comments": "14 pages; 6 figures; 4 tables; Accepted in proceedings of MLHPC 2019:\n  Fifth International Workshop on Machine Learning in High Performance\n  Computing Environments, Super Computing Conference 2019, Denver, Colorado", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning methods require careful selection of hyper-parameters\nin order to train a high performing model with good generalization abilities.\nHence, several automatic selection algorithms have been introduced to overcome\ntedious manual (try and error) tuning of these parameters. Due to its very high\nsample efficiency, Bayesian Optimization over a Gaussian Processes modeling of\nthe parameter space has become the method of choice. Unfortunately, this\napproach suffers from a cubic compute complexity due to underlying Cholesky\nfactorization, which makes it very hard to be scaled beyond a small number of\nsampling steps. In this paper, we present a novel, highly accurate\napproximation of the underlying Gaussian Process. Reducing its computational\ncomplexity from cubic to quadratic allows an efficient strong scaling of\nBayesian Optimization while outperforming the previous approach regarding\noptimization accuracy. The first experiments show speedups of a factor of 162\nin single node and further speed up by a factor of 5 in a parallel environment.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:15:55 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ram", "Raju", ""], ["M\u00fcller", "Sabine", ""], ["Pfreundt", "Franz-Josef", ""], ["Gauger", "Nicolas R.", ""], ["Keuper", "Janis", ""]]}, {"id": "2001.05759", "submitter": "Diego Garc\\'ia-Gil", "authors": "Diego Garc\\'ia-Gil, Salvador Garc\\'ia, Ning Xiong, Francisco Herrera", "title": "A Methodology guided by Decision Trees Ensemble and Smart Data for\n  Imbalanced Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differences in data size per class, also known as imbalanced data\ndistribution, have become a common problem affecting data quality. Big Data\nscenarios pose a new challenge to traditional imbalanced classification\nalgorithms, since they are not prepared to work with such amount of data. Split\ndata strategies and lack of data in the minority class due to the use of\nMapReduce paradigm have posed new challenges for tackling the imbalance between\nclasses in Big Data scenarios. Ensembles have shown to be able to successfully\naddress imbalanced data problems. Smart Data refers to data of enough quality\nto achieve high performance models. The combination of ensembles and Smart\nData, achieved through Big Data preprocessing, should be a great synergy. In\nthis paper, we propose a novel methodology based on Decision Trees Ensemble\nwith Smart Data for addressing the imbalanced classification problem in Big\nData domains, namely DeTE_SD methodology. This methodology is based on the\nlearning of different decision trees using distributed quality data for the\nensemble process. This quality data is achieved by fusing Random\nDiscretization, Principal Components Analysis and clustering-based Random\nOversampling for obtaining different Smart Data versions of the original data.\nExperiments carried out in 21 binary adapted datasets have shown that our\nmethodology outperforms Random Forest.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:25:59 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 07:29:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Garc\u00eda-Gil", "Diego", ""], ["Garc\u00eda", "Salvador", ""], ["Xiong", "Ning", ""], ["Herrera", "Francisco", ""]]}, {"id": "2001.05768", "submitter": "Tuyen Truong", "authors": "Tuyen Trung Truong", "title": "Some convergent results for Backtracking Gradient Descent method on\n  Banach spaces", "comments": "More details and improvements added, including: C^1 convex functions\n  satisfy Condition C, normalized duality mapping, prevalence and shyness of\n  sets in Banach spaces, hereditary Lindelof property of weak topology. Several\n  typos fixed. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.AP math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main result concerns the following condition:\n  {\\bf Condition C.} Let $X$ be a Banach space. A $C^1$ function\n$f:X\\rightarrow \\mathbb{R}$ satisfies Condition C if whenever $\\{x_n\\}$ weakly\nconverges to $x$ and $\\lim _{n\\rightarrow\\infty}||\\nabla f(x_n)||=0$, then\n$\\nabla f(x)=0$.\n  We assume that there is given a canonical isomorphism between $X$ and its\ndual $X^*$, for example when $X$ is a Hilbert space.\n  {\\bf Theorem.} Let $X$ be a reflexive, complete Banach space and\n$f:X\\rightarrow \\mathbb{R}$ be a $C^2$ function which satisfies Condition C.\nMoreover, we assume that for every bounded set $S\\subset X$, then $\\sup _{x\\in\nS}||\\nabla ^2f(x)||<\\infty$. We choose a random point $x_0\\in X$ and construct\nby the Local Backtracking GD procedure (which depends on $3$ hyper-parameters\n$\\alpha ,\\beta ,\\delta _0$, see later for details) the sequence\n$x_{n+1}=x_n-\\delta (x_n)\\nabla f(x_n)$. Then we have:\n  1) Every cluster point of $\\{x_n\\}$, in the {\\bf weak} topology, is a\ncritical point of $f$.\n  2) Either $\\lim _{n\\rightarrow\\infty}f(x_n)=-\\infty$ or $\\lim\n_{n\\rightarrow\\infty}||x_{n+1}-x_n||=0$.\n  3) Here we work with the weak topology. Let $\\mathcal{C}$ be the set of\ncritical points of $f$. Assume that $\\mathcal{C}$ has a bounded component $A$.\nLet $\\mathcal{B}$ be the set of cluster points of $\\{x_n\\}$. If\n$\\mathcal{B}\\cap A\\not= \\emptyset$, then $\\mathcal{B}\\subset A$ and\n$\\mathcal{B}$ is connected.\n  4) Assume that $X$ is separable. Then for generic choices of $\\alpha ,\\beta\n,\\delta _0$ and the initial point $x_0$, if the sequence $\\{x_n\\}$ converges -\nin the {\\bf weak} topology, then the limit point cannot be a saddle point.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 12:49:42 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 13:40:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Truong", "Tuyen Trung", ""]]}, {"id": "2001.05775", "submitter": "Yichen Zhang", "authors": "Yichen Zhang and Chen Chen and Guodong Liu and Tianqi Hong and Feng\n  Qiu", "title": "Approximating Trajectory Constraints with Machine Learning -- Microgrid\n  Islanding with Frequency Constraints", "comments": null, "journal-ref": null, "doi": "10.1109/TPWRS.2020.3015913", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a deep learning aided constraint encoding method\nto tackle the frequency-constraint microgrid scheduling problem. The nonlinear\nfunction between system operating condition and frequency nadir is approximated\nby using a neural network, which admits an exact mixed-integer formulation\n(MIP). This formulation is then integrated with the scheduling problem to\nencode the frequency constraint. With the stronger representation power of the\nneural network, the resulting commands can ensure adequate frequency response\nin a realistic setting in addition to islanding success. The proposed method is\nvalidated on a modified 33-node system. Successful islanding with a secure\nresponse is simulated under the scheduled commands using a detailed three-phase\nmodel in Simulink. The advantages of our model are particularly remarkable when\nthe inertia emulation functions from wind turbine generators are considered.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 13:04:35 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:37:49 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 22:48:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhang", "Yichen", ""], ["Chen", "Chen", ""], ["Liu", "Guodong", ""], ["Hong", "Tianqi", ""], ["Qiu", "Feng", ""]]}, {"id": "2001.05819", "submitter": "Yuling Jiao", "authors": "Jian Huang, Yuling Jiao, Lican Kang, Jin Liu, Yanyan Liu, Xiliang Lu", "title": "A Support Detection and Root Finding Approach for Learning\n  High-dimensional Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is important for modeling high-dimensional data, where the\nnumber of variables can be much larger than the sample size. In this paper, we\ndevelop a support detection and root finding procedure to learn the high\ndimensional sparse generalized linear models and denote this method by GSDAR.\nBased on the KKT condition for $\\ell_0$-penalized maximum likelihood\nestimations, GSDAR generates a sequence of estimators iteratively.\n  Under some restricted invertibility conditions on the maximum likelihood\nfunction and sparsity assumption on the target coefficients, the errors of the\nproposed estimate decays exponentially to the optimal order. Moreover, the\noracle estimator can be recovered if the target signal is stronger than the\ndetectable level.\n  We conduct simulations and real data analysis to illustrate the advantages of\nour proposed method over several existing methods, including Lasso and MCP.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 14:35:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Kang", "Lican", ""], ["Liu", "Jin", ""], ["Liu", "Yanyan", ""], ["Lu", "Xiliang", ""]]}, {"id": "2001.05834", "submitter": "Georg Hille", "authors": "Georg Hille and Johannes Steffen and Max D\\\"unnwald and Mathias Becker\n  and Sylvia Saalfeld and Klaus T\\\"onnies", "title": "Spinal Metastases Segmentation in MR Imaging using Deep Convolutional\n  Neural Networks", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study's objective was to segment spinal metastases in diagnostic MR\nimages using a deep learning-based approach. Segmentation of such lesions can\npresent a pivotal step towards enhanced therapy planning and validation, as\nwell as intervention support during minimally invasive and image-guided\nsurgeries like radiofrequency ablations. For this purpose, we used a U-Net like\narchitecture trained with 40 clinical cases including both, lytic and sclerotic\nlesion types and various MR sequences. Our proposed method was evaluated with\nregards to various factors influencing the segmentation quality, e.g. the used\nMR sequences and the input dimension. We quantitatively assessed our\nexperiments using Dice coefficients, sensitivity and specificity rates.\nCompared to expertly annotated lesion segmentations, the experiments yielded\npromising results with average Dice scores up to 77.6% and mean sensitivity\nrates up to 78.9%. To our best knowledge, our proposed study is one of the\nfirst to tackle this particular issue, which limits direct comparability with\nrelated works. In respect to similar deep learning-based lesion segmentations,\ne.g. in liver MR images or spinal CT images, our experiments showed similar or\nin some respects superior segmentation quality. Overall, our automatic approach\ncan provide almost expert-like segmentation accuracy in this challenging and\nambitious task.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:59:31 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:21:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hille", "Georg", ""], ["Steffen", "Johannes", ""], ["D\u00fcnnwald", "Max", ""], ["Becker", "Mathias", ""], ["Saalfeld", "Sylvia", ""], ["T\u00f6nnies", "Klaus", ""]]}, {"id": "2001.05835", "submitter": "Gilberto Luis De Conto Junior", "authors": "Gilberto Luis De Conto Junior", "title": "Diabetic Retinopathy detection by retinal image recognizing", "comments": "10 source codes, 12 figures, 48 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people are affected by diabetes around the world. This disease may have\ntype 1 and 2. Diabetes brings with it several complications including diabetic\nretinopathy, which is a disease that if not treated correctly can lead to\nirreversible damage in the patient's vision. The earlier it is detected, the\nbetter the chances that the patient will not lose vision. Methods of automating\nmanual procedures are currently in evidence and the diagnostic process for\nretinopathy is manual with the physician analyzing the patient's retina on the\nmonitor. The practice of image recognition can aid this detection by\nrecognizing Diabetic Retinopathy patterns and comparing it with the patient's\nretina in diagnosis. This method can also assist in the act of telemedicine, in\nwhich people without access to the exam can benefit from the diagnosis provided\nby the application. The application development took place through\nconvolutional neural networks, which do digital image processing analyzing each\nimage pixel. The use of VGG-16 as a pre-trained model to the application basis\nwas very useful and the final model accuracy was 82%.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:36:59 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Junior", "Gilberto Luis De Conto", ""]]}, {"id": "2001.05837", "submitter": "German I. Parisi", "authors": "German I. Parisi", "title": "Human Action Recognition and Assessment via Deep Neural Network\n  Self-Organization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust recognition and assessment of human actions are crucial in\nhuman-robot interaction (HRI) domains. While state-of-the-art models of action\nperception show remarkable results in large-scale action datasets, they mostly\nlack the flexibility, robustness, and scalability needed to operate in natural\nHRI scenarios which require the continuous acquisition of sensory information\nas well as the classification or assessment of human body patterns in real\ntime. In this chapter, I introduce a set of hierarchical models for the\nlearning and recognition of actions from depth maps and RGB images through the\nuse of neural network self-organization. A particularity of these models is the\nuse of growing self-organizing networks that quickly adapt to non-stationary\ndistributions and implement dedicated mechanisms for continual learning from\ntemporally correlated input.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 15:58:06 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 16:56:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Parisi", "German I.", ""]]}, {"id": "2001.05838", "submitter": "Anandhanarayanan K", "authors": "Anandhanarayanan Kamalakannan, Shiva Shankar Ganesan and Govindaraj\n  Rajamanickam", "title": "Self-Learning AI Framework for Skin Lesion Image Segmentation and\n  Classification", "comments": "10 pages, 3 figures, 2 tables", "journal-ref": null, "doi": "10.5121/ijcsit.2019.11604", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image segmentation and classification are the two main fundamental steps in\npattern recognition. To perform medical image segmentation or classification\nwith deep learning models, it requires training on large image dataset with\nannotation. The dermoscopy images (ISIC archive) considered for this work does\nnot have ground truth information for lesion segmentation. Performing manual\nlabelling on this dataset is time-consuming. To overcome this issue,\nself-learning annotation scheme was proposed in the two-stage deep learning\nalgorithm. The two-stage deep learning algorithm consists of U-Net segmentation\nmodel with the annotation scheme and CNN classifier model. The annotation\nscheme uses a K-means clustering algorithm along with merging conditions to\nachieve initial labelling information for training the U-Net model. The\nclassifier models namely ResNet-50 and LeNet-5 were trained and tested on the\nimage dataset without segmentation for comparison and with the U-Net\nsegmentation for implementing the proposed self-learning Artificial\nIntelligence (AI) framework. The classification results of the proposed AI\nframework achieved training accuracy of 93.8% and testing accuracy of 82.42%\nwhen compared with the two classifier models directly trained on the input\nimages.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 09:31:11 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Kamalakannan", "Anandhanarayanan", ""], ["Ganesan", "Shiva Shankar", ""], ["Rajamanickam", "Govindaraj", ""]]}, {"id": "2001.05839", "submitter": "David Noever", "authors": "David Noever, Wes Regian, Matt Ciolino, Josh Kalin, Dom Hambrick, Kaye\n  Blankenship", "title": "Discoverability in Satellite Imagery: A Good Sentence is Worth a\n  Thousand Pictures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small satellite constellations provide daily global coverage of the earth's\nlandmass, but image enrichment relies on automating key tasks like change\ndetection or feature searches. For example, to extract text annotations from\nraw pixels requires two dependent machine learning models, one to analyze the\noverhead image and the other to generate a descriptive caption. We evaluate\nseven models on the previously largest benchmark for satellite image captions.\nWe extend the labeled image samples five-fold, then augment, correct and prune\nthe vocabulary to approach a rough min-max (minimum word, maximum description).\nThis outcome compares favorably to previous work with large pre-trained image\nmodels but offers a hundred-fold reduction in model size without sacrificing\noverall accuracy (when measured with log entropy loss). These smaller models\nprovide new deployment opportunities, particularly when pushed to edge\nprocessors, on-board satellites, or distributed ground stations. To quantify a\ncaption's descriptiveness, we introduce a novel multi-class confusion or error\nmatrix to score both human-labeled test data and never-labeled images that\ninclude bounding box detection but lack full sentence captions. This work\nsuggests future captioning strategies, particularly ones that can enrich the\nclass coverage beyond land use applications and that lessen color-centered and\nadjacency adjectives (\"green\", \"near\", \"between\", etc.). Many modern language\ntransformers present novel and exploitable models with world knowledge gleaned\nfrom training from their vast online corpus. One interesting, but easy example\nmight learn the word association between wind and waves, thus enriching a beach\nscene with more than just color descriptions that otherwise might be accessed\nfrom raw pixels without text annotation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:41:18 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Noever", "David", ""], ["Regian", "Wes", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""], ["Hambrick", "Dom", ""], ["Blankenship", "Kaye", ""]]}, {"id": "2001.05844", "submitter": "Satoshi Ono", "authors": "Takahiro Suzuki, Shingo Takeshita, Satoshi Ono", "title": "Adversarial Example Generation using Evolutionary Multi-objective\n  Optimization", "comments": null, "journal-ref": "2019 IEEE Congress on Evolutionary Computation (CEC), Wellington,\n  New Zealand, 2019, pp. 2136-2144", "doi": "10.1109/CEC.2019.8790123", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Evolutionary Multi-objective Optimization (EMO)-based\nAdversarial Example (AE) design method that performs under black-box setting.\nPrevious gradient-based methods produce AEs by changing all pixels of a target\nimage, while previous EC-based method changes small number of pixels to produce\nAEs. Thanks to EMO's property of population based-search, the proposed method\nproduces various types of AEs involving ones locating between AEs generated by\nthe previous two approaches, which helps to know the characteristics of a\ntarget model or to know unknown attack patterns. Experimental results showed\nthe potential of the proposed method, e.g., it can generate robust AEs and,\nwith the aid of DCT-based perturbation pattern generation, AEs for high\nresolution images.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:34:09 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Suzuki", "Takahiro", ""], ["Takeshita", "Shingo", ""], ["Ono", "Satoshi", ""]]}, {"id": "2001.05847", "submitter": "Pablo Lanillos", "authors": "Cansu Sancaktar, Marcel van Gerven, Pablo Lanillos", "title": "End-to-End Pixel-Based Deep Active Inference for Body Perception and\n  Action", "comments": null, "journal-ref": null, "doi": "10.1109/ICDL-EpiRob48136.2020.9278105", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pixel-based deep active inference algorithm (PixelAI) inspired\nby human body perception and action. Our algorithm combines the free-energy\nprinciple from neuroscience, rooted in variational inference, with deep\nconvolutional decoders to scale the algorithm to directly deal with raw visual\ninput and provide online adaptive inference. Our approach is validated by\nstudying body perception and action in a simulated and a real Nao robot.\nResults show that our approach allows the robot to perform 1) dynamical body\nestimation of its arm using only monocular camera images and 2) autonomous\nreaching to \"imagined\" arm poses in the visual space. This suggests that robot\nand human body perception and action can be efficiently solved by viewing both\nas an active inference problem guided by ongoing sensory input.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 12:19:09 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:15:16 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 21:30:12 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Sancaktar", "Cansu", ""], ["van Gerven", "Marcel", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2001.05851", "submitter": "Alberto Rossi", "authors": "Alberto Rossi, Markus Hagenbuchner, Franco Scarselli, Ah Chung Tsoi", "title": "Embedding of FRPN in CNN architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the fully recursive perceptron network (FRPN) model for\nvectorial inputs to include deep convolutional neural networks (CNNs) which can\naccept multi-dimensional inputs. A FRPN consists of a recursive layer, which,\ngiven a fixed input, iteratively computes an equilibrium state. The unfolding\nrealized with this kind of iterative mechanism allows to simulate a deep neural\nnetwork with any number of layers. The extension of the FRPN to CNN results in\nan architecture, which we call convolutional-FRPN (C-FRPN), where the\nconvolutional layers are recursive. The method is evaluated on several image\nclassification benchmarks. It is shown that the C-FRPN consistently outperforms\nstandard CNNs having the same number of parameters. The gap in performance is\nparticularly large for small networks, showing that the C-FRPN is a very\npowerful architecture, since it allows to obtain equivalent performance with\nfewer parameters when compared with deep CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 12:41:15 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Rossi", "Alberto", ""], ["Hagenbuchner", "Markus", ""], ["Scarselli", "Franco", ""], ["Tsoi", "Ah Chung", ""]]}, {"id": "2001.05852", "submitter": "Mingxin Zhao", "authors": "Mingxin Zhao, Li Cheng, Xu Yang, Peng Feng, Liyuan Liu, and Nanjian Wu", "title": "TBC-Net: A real-time detector for infrared small target detection using\n  semantic constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrared small target detection is a key technique in infrared search and\ntracking (IRST) systems. Although deep learning has been widely used in the\nvision tasks of visible light images recently, it is rarely used in infrared\nsmall target detection due to the difficulty in learning small target features.\nIn this paper, we propose a novel lightweight convolutional neural network\nTBC-Net for infrared small target detection. The TBCNet consists of a target\nextraction module (TEM) and a semantic constraint module (SCM), which are used\nto extract small targets from infrared images and to classify the extracted\ntarget images during the training, respectively. Meanwhile, we propose a joint\nloss function and a training method. The SCM imposes a semantic constraint on\nTEM by combining the high-level classification task and solve the problem of\nthe difficulty to learn features caused by class imbalance problem. During the\ntraining, the targets are extracted from the input image and then be classified\nby SCM. During the inference, only the TEM is used to detect the small targets.\nWe also propose a data synthesis method to generate training data. The\nexperimental results show that compared with the traditional methods, TBC-Net\ncan better reduce the false alarm caused by complicated background, the\nproposed network structure and joint loss have a significant improvement on\nsmall target feature learning. Besides, TBC-Net can achieve real-time detection\non the NVIDIA Jetson AGX Xavier development board, which is suitable for\napplications such as field research with drones equipped with infrared sensors.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 05:25:39 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Zhao", "Mingxin", ""], ["Cheng", "Li", ""], ["Yang", "Xu", ""], ["Feng", "Peng", ""], ["Liu", "Liyuan", ""], ["Wu", "Nanjian", ""]]}, {"id": "2001.05855", "submitter": "Jacob Decoto", "authors": "Jacob J Decoto, David RC Dayton", "title": "Deep Learning Enabled Uncorrelated Space Observation Association", "comments": "Approved for public release by Department of Defense Prepublication\n  Office, Ref: 20-S-0428", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncorrelated optical space observation association represents a classic\nneedle in a haystack problem. The objective being to find small groups of\nobservations that are likely of the same resident space objects (RSOs) from\namongst the much larger population of all uncorrelated observations. These\nobservations being potentially widely disparate both temporally and with\nrespect to the observing sensor position. By training on a large representative\ndata set this paper shows that a deep learning enabled learned model with no\nencoded knowledge of physics or orbital mechanics can learn a model for\nidentifying observations of common objects. When presented with balanced input\nsets of 50% matching observation pairs the learned model was able to correctly\nidentify if the observation pairs were of the same RSO 83.1% of the time. The\nresulting learned model is then used in conjunction with a search algorithm on\nan unbalanced demonstration set of 1,000 disparate simulated uncorrelated\nobservations and is shown to be able to successfully identify true three\nobservation sets representing 111 out of 142 objects in the population. With\nmost objects being identified in multiple three observation triplets. This is\naccomplished while only exploring 0.06% of the search space of 1.66e8 possible\nunique triplet combinations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:33:11 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Decoto", "Jacob J", ""], ["Dayton", "David RC", ""]]}, {"id": "2001.05857", "submitter": "Aysu Can", "authors": "Ethem F. Can, Aysu Ezen-Can", "title": "The Effect of Data Ordering in Image Classification", "comments": null, "journal-ref": "Under consideration at Pattern Recognition Letters 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success stories from deep learning models increase every day spanning\ndifferent tasks from image classification to natural language understanding.\nWith the increasing popularity of these models, scientists spend more and more\ntime finding the optimal parameters and best model architectures for their\ntasks. In this paper, we focus on the ingredient that feeds these machines: the\ndata. We hypothesize that the data ordering affects how well a model performs.\nTo that end, we conduct experiments on an image classification task using\nImageNet dataset and show that some data orderings are better than others in\nterms of obtaining higher classification accuracies. Experimental results show\nthat independent of model architecture, learning rate and batch size, ordering\nof the data significantly affects the outcome. We show these findings using\ndifferent metrics: NDCG, accuracy @ 1 and accuracy @ 5. Our goal here is to\nshow that not only parameters and model architectures but also the data\nordering has a say in obtaining better results.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 20:34:00 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Can", "Ethem F.", ""], ["Ezen-Can", "Aysu", ""]]}, {"id": "2001.05862", "submitter": "Siming Bayer", "authors": "Siming Bayer, Ute Spiske, Jie Luo, Tobias Geimer, William M. Wells\n  III, Martin Ostermeier, Rebecca Fahrig, Arya Nabavi, Christoph Bert, Ilker\n  Eyupoglo, and Andreas Maier", "title": "An Investigation of Feature-based Nonrigid Image Registration using\n  Gaussian Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a wide range of clinical applications, such as adaptive treatment\nplanning or intraoperative image update, feature-based deformable registration\n(FDR) approaches are widely employed because of their simplicity and low\ncomputational complexity. FDR algorithms estimate a dense displacement field by\ninterpolating a sparse field, which is given by the established correspondence\nbetween selected features. In this paper, we consider the deformation field as\na Gaussian Process (GP), whereas the selected features are regarded as prior\ninformation on the valid deformations. Using GP, we are able to estimate the\nboth dense displacement field and a corresponding uncertainty map at once.\nFurthermore, we evaluated the performance of different hyperparameter settings\nfor squared exponential kernels with synthetic, phantom and clinical data\nrespectively. The quantitative comparison shows, GP-based interpolation has\nperformance on par with state-of-the-art B-spline interpolation. The greatest\nclinical benefit of GP-based interpolation is that it gives a reliable estimate\nof the mathematical uncertainty of the calculated dense displacement map.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 20:51:41 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Bayer", "Siming", ""], ["Spiske", "Ute", ""], ["Luo", "Jie", ""], ["Geimer", "Tobias", ""], ["Wells", "William M.", "III"], ["Ostermeier", "Martin", ""], ["Fahrig", "Rebecca", ""], ["Nabavi", "Arya", ""], ["Bert", "Christoph", ""], ["Eyupoglo", "Ilker", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.05864", "submitter": "Yiyan Chen", "authors": "Yiyan Chen, Li Tao, Xueting Wang and Toshihiko Yamasaki", "title": "Weakly Supervised Video Summarization by Hierarchical Reinforcement\n  Learning", "comments": "mmasia 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional video summarization approaches based on reinforcement learning\nhave the problem that the reward can only be received after the whole summary\nis generated. Such kind of reward is sparse and it makes reinforcement learning\nhard to converge. Another problem is that labelling each frame is tedious and\ncostly, which usually prohibits the construction of large-scale datasets. To\nsolve these problems, we propose a weakly supervised hierarchical reinforcement\nlearning framework, which decomposes the whole task into several subtasks to\nenhance the summarization quality. This framework consists of a manager network\nand a worker network. For each subtask, the manager is trained to set a subgoal\nonly by a task-level binary label, which requires much fewer labels than\nconventional approaches. With the guide of the subgoal, the worker predicts the\nimportance scores for video frames in the subtask by policy gradient according\nto both global reward and innovative defined sub-rewards to overcome the sparse\nproblem. Experiments on two benchmark datasets show that our proposal has\nachieved the best performance, even better than supervised approaches.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 07:47:02 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 15:31:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Yiyan", ""], ["Tao", "Li", ""], ["Wang", "Xueting", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "2001.05865", "submitter": "Raghav Goyal", "authors": "Shubham Agarwal, Raghav Goyal", "title": "Ensemble based discriminative models for Visual Dialog Challenge 2018", "comments": "Rankings: https://visualdialog.org/challenge/2018#winners", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript describes our approach for the Visual Dialog Challenge 2018.\nWe use an ensemble of three discriminative models with different encoders and\ndecoders for our final submission. Our best performing model on 'test-std'\nsplit achieves the NDCG score of 55.46 and the MRR value of 63.77, securing\nthird position in the challenge.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:20:54 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Agarwal", "Shubham", ""], ["Goyal", "Raghav", ""]]}, {"id": "2001.05868", "submitter": "Hao Cheng", "authors": "Fanxu Meng, Hao Cheng, Ke Li, Zhixin Xu, Rongrong Ji, Xing Sun,\n  Gaungming Lu", "title": "Filter Grafting for Deep Neural Networks", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new learning paradigm called filter grafting, which\naims to improve the representation capability of Deep Neural Networks (DNNs).\nThe motivation is that DNNs have unimportant (invalid) filters (e.g., l1 norm\nclose to 0). These filters limit the potential of DNNs since they are\nidentified as having little effect on the network. While filter pruning removes\nthese invalid filters for efficiency consideration, filter grafting\nre-activates them from an accuracy boosting perspective. The activation is\nprocessed by grafting external information (weights) into invalid filters. To\nbetter perform the grafting process, we develop an entropy-based criterion to\nmeasure the information of filters and an adaptive weighting strategy for\nbalancing the grafted information among networks. After the grafting operation,\nthe network has very few invalid filters compared with its untouched state,\nenpowering the model with more representation capacity. We also perform\nextensive experiments on the classification and recognition tasks to show the\nsuperiority of our method. For example, the grafted MobileNetV2 outperforms the\nnon-grafted MobileNetV2 by about 7 percent on CIFAR-100 dataset. Code is\navailable at https://github.com/fxmeng/filter-grafting.git.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:18:57 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 11:19:24 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:42:25 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Meng", "Fanxu", ""], ["Cheng", "Hao", ""], ["Li", "Ke", ""], ["Xu", "Zhixin", ""], ["Ji", "Rongrong", ""], ["Sun", "Xing", ""], ["Lu", "Gaungming", ""]]}, {"id": "2001.05870", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar and Massoud Pedram", "title": "Runtime Deep Model Multiplexing for Reduced Latency and Energy\n  Consumption Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning algorithm to design a light-weight neural multiplexer\nthat given the input and computational resource requirements, calls the model\nthat will consume the minimum compute resources for a successful inference.\nMobile devices can use the proposed algorithm to offload the hard inputs to the\ncloud while inferring the easy ones locally. Besides, in the large scale\ncloud-based intelligent applications, instead of replicating the most-accurate\nmodel, a range of small and large models can be multiplexed from depending on\nthe input's complexity which will save the cloud's computational resources. The\ninput complexity or hardness is determined by the number of models that can\npredict the correct label. For example, if no model can predict the label\ncorrectly, then the input is considered as the hardest. The proposed algorithm\nallows the mobile device to detect the inputs that can be processed locally and\nthe ones that require a larger model and should be sent a cloud server.\nTherefore, the mobile user benefits from not only the local processing but also\nfrom an accurate model hosted on a cloud server. Our experimental results show\nthat the proposed algorithm improves mobile's model accuracy by 8.52% which is\nbecause of those inputs that are properly selected and offloaded to the cloud\nserver. In addition, it saves the cloud providers' compute resources by a\nfactor of 2.85x as small models are chosen for easier inputs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 23:49:51 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:07:31 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Pedram", "Massoud", ""]]}, {"id": "2001.05871", "submitter": "Vivian Lai", "authors": "Vivian Lai, Han Liu, Chenhao Tan", "title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials\n  for Humans", "comments": "26 pages, 48 figures, CHI 2020", "journal-ref": null, "doi": "10.1145/10.1145/3313831.3376873", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support human decision making with machine learning models, we often need\nto elucidate patterns embedded in the models that are unsalient, unknown, or\ncounterintuitive to humans. While existing approaches focus on explaining\nmachine predictions with real-time assistance, we explore model-driven\ntutorials to help humans understand these patterns in a training phase. We\nconsider both tutorials with guidelines from scientific papers, analogous to\ncurrent practices of science communication, and automatically selected examples\nfrom training data with explanations. We use deceptive review detection as a\ntestbed and conduct large-scale, randomized human-subject experiments to\nexamine the effectiveness of such tutorials. We find that tutorials indeed\nimprove human performance, with and without real-time assistance. In\nparticular, although deep learning provides superior predictive performance\nthan simple models, tutorials and explanations from simple models are more\nuseful to humans. Our work suggests future directions for human-centered\ntutorials and explanations towards a synergy between humans and AI.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Lai", "Vivian", ""], ["Liu", "Han", ""], ["Tan", "Chenhao", ""]]}, {"id": "2001.05873", "submitter": "Harshitha Machiraju", "authors": "Harshitha Machiraju, Vineeth N Balasubramanian", "title": "A Little Fog for a Large Turn", "comments": "Accepted to WACV 2020", "journal-ref": null, "doi": "10.1109/WACV45572.2020.9093549", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small, carefully crafted perturbations called adversarial perturbations can\neasily fool neural networks. However, these perturbations are largely additive\nand not naturally found. We turn our attention to the field of Autonomous\nnavigation wherein adverse weather conditions such as fog have a drastic effect\non the predictions of these systems. These weather conditions are capable of\nacting like natural adversaries that can help in testing models. To this end,\nwe introduce a general notion of adversarial perturbations, which can be\ncreated using generative models and provide a methodology inspired by\nCycle-Consistent Generative Adversarial Networks to generate adversarial\nweather conditions for a given image. Our formulation and results show that\nthese images provide a suitable testbed for steering models used in Autonomous\nnavigation models. Our work also presents a more natural and general definition\nof Adversarial perturbations based on Perceptual Similarity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:09:48 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Machiraju", "Harshitha", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2001.05876", "submitter": "Li Wang", "authors": "Li Wang, Zechen Bai, Yonghua Zhang, Hongtao Lu", "title": "Show, Recall, and Tell: Image Captioning with Recall Mechanism", "comments": "Published in AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i07.6898", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating natural and accurate descriptions in image cap-tioning has always\nbeen a challenge. In this paper, we pro-pose a novel recall mechanism to\nimitate the way human con-duct captioning. There are three parts in our recall\nmecha-nism : recall unit, semantic guide (SG) and recalled-wordslot (RWS).\nRecall unit is a text-retrieval module designedto retrieve recalled words for\nimages. SG and RWS are de-signed for the best use of recalled words. SG branch\ncangenerate a recalled context, which can guide the process ofgenerating\ncaption. RWS branch is responsible for copyingrecalled words to the caption.\nInspired by pointing mecha-nism in text summarization, we adopt a soft switch\nto balancethe generated-word probabilities between SG and RWS. Inthe CIDEr\noptimization step, we also introduce an individualrecalled-word reward (WR) to\nboost training. Our proposedmethods (SG+RWS+WR) achieve BLEU-4 / CIDEr /\nSPICEscores of 36.6 / 116.9 / 21.3 with cross-entropy loss and 38.7 /129.1 /\n22.4 with CIDEr optimization on MSCOCO Karpathytest split, which surpass the\nresults of other state-of-the-artmethods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:32:51 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:09:06 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 05:00:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Wang", "Li", ""], ["Bai", "Zechen", ""], ["Zhang", "Yonghua", ""], ["Lu", "Hongtao", ""]]}, {"id": "2001.05878", "submitter": "Sourav Mishra", "authors": "Sourav Mishra, Subhajit Chaudhury, Hideaki Imaizumi, Toshihiko\n  Yamasaki", "title": "Assessing Robustness of Deep learning Methods in Dermatological Workflow", "comments": "Accepted in ACM CHIL 2020 Workshop (Oral and poster, without\n  publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to evaluate the suitability of current deep learning methods\nfor clinical workflow especially by focusing on dermatology. Although deep\nlearning methods have been attempted to get dermatologist level accuracy in\nseveral individual conditions, it has not been rigorously tested for common\nclinical complaints. Most projects involve data acquired in well-controlled\nlaboratory conditions. This may not reflect regular clinical evaluation where\ncorresponding image quality is not always ideal. We test the robustness of deep\nlearning methods by simulating non-ideal characteristics on user submitted\nimages of ten classes of diseases. Assessing via imitated conditions, we have\nfound the overall accuracy to drop and individual predictions change\nsignificantly in many cases despite of robust training.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:15:38 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 13:51:35 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Mishra", "Sourav", ""], ["Chaudhury", "Subhajit", ""], ["Imaizumi", "Hideaki", ""], ["Yamasaki", "Toshihiko", ""]]}, {"id": "2001.05887", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Xudong Li, Shun Lu, Bo Zhang, and Jixiang Li", "title": "MixPath: A Unified Approach for One-shot Neural Architecture Search", "comments": "Bridge the gap between one shot NAS and multi branch using shadow BN\n  with good ranking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blending multiple convolutional kernels is proved advantageous in neural\narchitectural design. However, current neural architecture search approaches\nare mainly limited to stacked single-path search space. How can the one-shot\ndoctrine search for multi-path models remains unresolved. Specifically, we are\nmotivated to train a multi-path supernet to accurately evaluate the candidate\narchitectures. In this paper, we discover that in the studied search space,\nfeature vectors summed from multiple paths are nearly multiples of those from a\nsingle path, which perturbs supernet training and its ranking ability. In this\nregard, we propose a novel mechanism called Shadow Batch Normalization(SBN) to\nregularize the disparate feature statistics. Extensive experiments prove that\nSBN is capable of stabilizing the training and improving the ranking\nperformance (e.g. Kendall Tau 0.597 tested on NAS-Bench-101). We call our\nunified multi-path one-shot approach as MixPath, which generates a series of\nmodels that achieve state-of-the-art results on ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:24:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 11:05:45 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 10:47:27 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Li", "Xudong", ""], ["Lu", "Shun", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""]]}, {"id": "2001.05895", "submitter": "Daniel H Thompson", "authors": "Divya Gautam, Maria Lomeli, Kostis Gourgoulias, Daniel H. Thompson,\n  Saurabh Johri", "title": "Masking schemes for universal marginalisers", "comments": "To be published in Proceedings of the 2nd Symposium on Advances in\n  Approximate Bayesian Inference, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the effect of structure-agnostic and structure-dependent masking\nschemes when training a universal marginaliser (arXiv:1711.00695) in order to\nlearn conditional distributions of the form $P(x_i |\\mathbf x_{\\mathbf b})$,\nwhere $x_i$ is a given random variable and $\\mathbf x_{\\mathbf b}$ is some\narbitrary subset of all random variables of the generative model of interest.\nIn other words, we mimic the self-supervised training of a denoising\nautoencoder, where a dataset of unlabelled data is used as partially observed\ninput and the neural approximator is optimised to minimise reconstruction loss.\nWe focus on studying the underlying process of the partially observed\ndata---how good is the neural approximator at learning all conditional\ndistributions when the observation process at prediction time differs from the\nmasking process during training? We compare networks trained with different\nmasking schemes in terms of their predictive performance and generalisation\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:35:06 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Gautam", "Divya", ""], ["Lomeli", "Maria", ""], ["Gourgoulias", "Kostis", ""], ["Thompson", "Daniel H.", ""], ["Johri", "Saurabh", ""]]}, {"id": "2001.05918", "submitter": "Giorgi Nadiradze", "authors": "Giorgi Nadiradze, Ilia Markov, Bapi Chatterjee, Vyacheslav Kungurtsev,\n  Dan Alistarh", "title": "Elastic Consistency: A General Consistency Model for Distributed\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has made tremendous progress in recent years, with models\nmatching or even surpassing humans on a series of specialized tasks. One key\nelement behind the progress of machine learning in recent years has been the\nability to train machine learning models in large-scale distributed\nshared-memory and message-passing environments. Many of these models are\ntrained employing variants of stochastic gradient descent (SGD) based\noptimization.\n  In this paper, we introduce a general consistency condition covering\ncommunication-reduced and asynchronous distributed SGD implementations. Our\nframework, called elastic consistency enables us to derive convergence bounds\nfor a variety of distributed SGD methods used in practice to train large-scale\nmachine learning models. The proposed framework de-clutters the\nimplementation-specific convergence analysis and provides an abstraction to\nderive convergence bounds. We utilize the framework to analyze a sparsification\nscheme for distributed SGD methods in an asynchronous setting for convex and\nnon-convex objectives. We implement the distributed SGD variant to train deep\nCNN models in an asynchronous shared-memory setting. Empirical results show\nthat error-feedback may not necessarily help in improving the convergence of\nsparsified asynchronous distributed SGD, which corroborates an insight\nsuggested by our convergence analysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:10:58 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 11:02:38 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Nadiradze", "Giorgi", ""], ["Markov", "Ilia", ""], ["Chatterjee", "Bapi", ""], ["Kungurtsev", "Vyacheslav", ""], ["Alistarh", "Dan", ""]]}, {"id": "2001.05922", "submitter": "Matthias Lenga", "authors": "Matthias Lenga, Heinrich Schulz, Axel Saalbach", "title": "Continual Learning for Domain Adaptation in Chest X-ray Classification", "comments": null, "journal-ref": "Proceedings of the Third Conference on Medical Imaging with Deep\n  Learning, PMLR 121:413-423, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, Deep Learning has been successfully applied to a broad\nrange of medical applications. Especially in the context of chest X-ray\nclassification, results have been reported which are on par, or even superior\nto experienced radiologists. Despite this success in controlled experimental\nenvironments, it has been noted that the ability of Deep Learning models to\ngeneralize to data from a new domain (with potentially different tasks) is\noften limited. In order to address this challenge, we investigate techniques\nfrom the field of Continual Learning (CL) including Joint Training (JT),\nElastic Weight Consolidation (EWC) and Learning Without Forgetting (LWF). Using\nthe ChestX-ray14 and the MIMIC-CXR datasets, we demonstrate empirically that\nthese methods provide promising options to improve the performance of Deep\nLearning models on a target domain and to mitigate effectively catastrophic\nforgetting for the source domain. To this end, the best overall performance was\nobtained using JT, while for LWF competitive results could be achieved - even\nwithout accessing data from the source domain.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:20:43 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Lenga", "Matthias", ""], ["Schulz", "Heinrich", ""], ["Saalbach", "Axel", ""]]}, {"id": "2001.05936", "submitter": "Joseph Bethge", "authors": "Joseph Bethge, Christian Bartz, Haojin Yang, Ying Chen, and Christoph\n  Meinel", "title": "MeliusNet: Can Binary Neural Networks Achieve MobileNet-level Accuracy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) are neural networks which use binary weights\nand activations instead of the typical 32-bit floating point values. They have\nreduced model sizes and allow for efficient inference on mobile or embedded\ndevices with limited power and computational resources. However, the\nbinarization of weights and activations leads to feature maps of lower quality\nand lower capacity and thus a drop in accuracy compared to traditional\nnetworks. Previous work has increased the number of channels or used multiple\nbinary bases to alleviate these problems. In this paper, we instead present an\narchitectural approach: MeliusNet. It consists of alternating a DenseBlock,\nwhich increases the feature capacity, and our proposed ImprovementBlock, which\nincreases the feature quality. Experiments on the ImageNet dataset demonstrate\nthe superior performance of our MeliusNet over a variety of popular binary\narchitectures with regards to both computation savings and accuracy.\nFurthermore, with our method we trained BNN models, which for the first time\ncan match the accuracy of the popular compact network MobileNet-v1 in terms of\nmodel size, number of operations and accuracy. Our code is published online at\nhttps://github.com/hpi-xnor/BMXNet-v2\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:56:10 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 11:52:06 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bethge", "Joseph", ""], ["Bartz", "Christian", ""], ["Yang", "Haojin", ""], ["Chen", "Ying", ""], ["Meinel", "Christoph", ""]]}, {"id": "2001.05948", "submitter": "S\\'andor Baran", "authors": "\\'Agnes Baran, Sebastian Lerch, Mehrez El Ayari and S\\'andor Baran", "title": "Machine learning for total cloud cover prediction", "comments": "24 pages, 7 figures", "journal-ref": "Neural Computing and Applications 33 (2021), 2605-2620", "doi": "10.1007/s00521-020-05139-4", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and reliable forecasting of total cloud cover (TCC) is vital for\nmany areas such as astronomy, energy demand and production, or agriculture.\nMost meteorological centres issue ensemble forecasts of TCC, however, these\nforecasts are often uncalibrated and exhibit worse forecast skill than ensemble\nforecasts of other weather variables. Hence, some form of post-processing is\nstrongly required to improve predictive performance. As TCC observations are\nusually reported on a discrete scale taking just nine different values called\noktas, statistical calibration of TCC ensemble forecasts can be considered a\nclassification problem with outputs given by the probabilities of the oktas.\nThis is a classical area where machine learning methods are applied. We\ninvestigate the performance of post-processing using multilayer perceptron\n(MLP) neural networks, gradient boosting machines (GBM) and random forest (RF)\nmethods. Based on the European Centre for Medium-Range Weather Forecasts global\nTCC ensemble forecasts for 2002-2014 we compare these approaches with the\nproportional odds logistic regression (POLR) and multiclass logistic regression\n(MLR) models, as well as the raw TCC ensemble forecasts. We further assess\nwhether improvements in forecast skill can be obtained by incorporating\nensemble forecasts of precipitation as additional predictor. Compared to the\nraw ensemble, all calibration methods result in a significant improvement in\nforecast skill. RF models provide the smallest increase in predictive\nperformance, while MLP, POLR and GBM approaches perform best. The use of\nprecipitation forecast data leads to further improvements in forecast skill and\nexcept for very short lead times the extended MLP model shows the best overall\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:13:37 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Baran", "\u00c1gnes", ""], ["Lerch", "Sebastian", ""], ["Ayari", "Mehrez El", ""], ["Baran", "S\u00e1ndor", ""]]}, {"id": "2001.05972", "submitter": "Aditi Krishnapriyan", "authors": "Aditi S. Krishnapriyan, Maciej Haranczyk, Dmitriy Morozov", "title": "Topological Descriptors Help Predict Guest Adsorption in Nanoporous\n  Materials", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG math.AT physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has emerged as an attractive alternative to experiments and\nsimulations for predicting material properties. Usually, such an approach\nrelies on specific domain knowledge for feature design: each learning target\nrequires careful selection of features that an expert recognizes as important\nfor the specific task. The major drawback of this approach is that computation\nof only a few structural features has been implemented so far, and it is\ndifficult to tell a priori which features are important for a particular\napplication. The latter problem has been empirically observed for predictors of\nguest uptake in nanoporous materials: local and global porosity features become\ndominant descriptors at low and high pressures, respectively. We investigate a\nfeature representation of materials using tools from topological data analysis.\nSpecifically, we use persistent homology to describe the geometry of nanoporous\nmaterials at various scales. We combine our topological descriptor with\ntraditional structural features and investigate the relative importance of each\nto the prediction tasks. We demonstrate an application of this feature\nrepresentation by predicting methane adsorption in zeolites, for pressures in\nthe range of 1-200 bar. Our results not only show a considerable improvement\ncompared to the baseline, but they also highlight that topological features\ncapture information complementary to the structural features: this is\nespecially important for the adsorption at low pressure, a task particularly\ndifficult for the traditional features. Furthermore, by investigation of the\nimportance of individual topological features in the adsorption model, we are\nable to pinpoint the location of the pores that correlate best to adsorption at\ndifferent pressure, contributing to our atom-level understanding of\nstructure-property relationships.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:08:25 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 23:06:29 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 23:19:22 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Krishnapriyan", "Aditi S.", ""], ["Haranczyk", "Maciej", ""], ["Morozov", "Dmitriy", ""]]}, {"id": "2001.05977", "submitter": "Dominik Wojtczak", "authors": "E. M. Hahn, M. Perez, S. Schewe, F. Somenzi, A. Trivedi, D. Wojtczak", "title": "Reward Shaping for Reinforcement Learning with Omega-Regular Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, successful approaches have been made to exploit good-for-MDPs\nautomata (B\\\"uchi automata with a restricted form of nondeterminism) for model\nfree reinforcement learning, a class of automata that subsumes good for games\nautomata and the most widespread class of limit deterministic automata. The\nfoundation of using these B\\\"uchi automata is that the B\\\"uchi condition can,\nfor good-for-MDP automata, be translated to reachability.\n  The drawback of this translation is that the rewards are, on average, reaped\nvery late, which requires long episodes during the learning process. We devise\na new reward shaping approach that overcomes this issue. We show that the\nresulting model is equivalent to a discounted payoff objective with a biased\ndiscount that simplifies and improves on prior work in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:22:50 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hahn", "E. M.", ""], ["Perez", "M.", ""], ["Schewe", "S.", ""], ["Somenzi", "F.", ""], ["Trivedi", "A.", ""], ["Wojtczak", "D.", ""]]}, {"id": "2001.05989", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Cross-conformal e-prediction", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "26", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note discusses a simple modification of cross-conformal prediction\ninspired by recent work on e-values. The precursor of conformal prediction\ndeveloped in the 1990s by Gammerman, Vapnik, and Vovk was also based on\ne-values and is called conformal e-prediction in this note. Replacing e-values\nby p-values led to conformal prediction, which has important advantages over\nconformal e-prediction without obvious disadvantages. The situation with\ncross-conformal prediction is, however, different: whereas for cross-conformal\nprediction validity is only an empirical fact (and can be broken with excessive\nrandomization), this note draws the reader's attention to the obvious fact that\ncross-conformal e-prediction enjoys a guaranteed property of validity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:41:17 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "2001.05990", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Jiachun Liao, Flavio P. Calmon, Oliver Kosut, Lalitha\n  Sankar", "title": "A Better Bound Gives a Hundred Rounds: Enhanced Privacy Guarantees via\n  $f$-Divergences", "comments": "Submitted for Publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the optimal differential privacy (DP) parameters of a mechanism\nthat satisfies a given level of R\\'enyi differential privacy (RDP). Our result\nis based on the joint range of two $f$-divergences that underlie the\napproximate and the R\\'enyi variations of differential privacy. We apply our\nresult to the moments accountant framework for characterizing privacy\nguarantees of stochastic gradient descent. When compared to the\nstate-of-the-art, our bounds may lead to about 100 more stochastic gradient\ndescent iterations for training deep learning models for the same privacy\nbudget.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:45:05 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Liao", "Jiachun", ""], ["Calmon", "Flavio P.", ""], ["Kosut", "Oliver", ""], ["Sankar", "Lalitha", ""]]}, {"id": "2001.05992", "submitter": "Wei Hu", "authors": "Wei Hu, Lechao Xiao, Jeffrey Pennington", "title": "Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear\n  Networks", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of initial parameter values for gradient-based optimization of\ndeep neural networks is one of the most impactful hyperparameter choices in\ndeep learning systems, affecting both convergence times and model performance.\nYet despite significant empirical and theoretical analysis, relatively little\nhas been proved about the concrete effects of different initialization schemes.\nIn this work, we analyze the effect of initialization in deep linear networks,\nand provide for the first time a rigorous proof that drawing the initial\nweights from the orthogonal group speeds up convergence relative to the\nstandard Gaussian initialization with iid weights. We show that for deep\nnetworks, the width needed for efficient convergence to a global minimum with\northogonal initializations is independent of the depth, whereas the width\nneeded for efficient convergence with Gaussian initializations scales linearly\nin the depth. Our results demonstrate how the benefits of a good initialization\ncan persist throughout learning, suggesting an explanation for the recent\nempirical successes found by initializing very deep non-linear networks\naccording to the principle of dynamical isometry.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:48:34 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hu", "Wei", ""], ["Xiao", "Lechao", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2001.05993", "submitter": "Ryan Rossi", "authors": "Ryan Rossi, Somdeb Sarkhel, Nesreen Ahmed", "title": "Inferring Individual Level Causal Models from Graph-based Relational\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formalize the problem of causal inference over graph-based\nrelational time-series data where each node in the graph has one or more\ntime-series associated to it. We propose causal inference models for this\nproblem that leverage both the graph topology and time-series to accurately\nestimate local causal effects of nodes. Furthermore, the relational time-series\ncausal inference models are able to estimate local effects for individual nodes\nby exploiting local node-centric temporal dependencies and\ntopological/structural dependencies. We show that simpler causal models that do\nnot consider the graph topology are recovered as special cases of the proposed\nrelational time-series causal inference model. We describe the conditions under\nwhich the resulting estimate can be used to estimate a causal effect, and\ndescribe how the Durbin-Wu-Hausman test of specification can be used to test\nfor the consistency of the proposed estimator from data. Empirically, we\ndemonstrate the effectiveness of the causal inference models on both synthetic\ndata with known ground-truth and a large-scale observational relational\ntime-series data set collected from Wikipedia.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:48:40 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 17:07:33 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 22:14:30 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Rossi", "Ryan", ""], ["Sarkhel", "Somdeb", ""], ["Ahmed", "Nesreen", ""]]}, {"id": "2001.05996", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Jens Dalter, Mareike Dornh\\\"ofer, Johannes Zenkert,\n  Madjid Fathi", "title": "Knowledge Discovery from Social Media using Big Data provided Sentiment\n  Analysis (SoMABiT)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays competitive business world, being aware of customer needs and\nmarket-oriented production is a key success factor for industries. To this aim,\nthe use of efficient analytic algorithms ensures a better understanding of\ncustomer feedback and improves the next generation of products. Accordingly,\nthe dramatic increase in using social media in daily life provides beneficial\nsources for market analytics. But how traditional analytic algorithms and\nmethods can scale up for such disparate and multi-structured data sources is\nthe main challenge in this regard. This paper presents and discusses the\ntechnological and scientific focus of the SoMABiT as a social media analysis\nplatform using big data technology. Sentiment analysis has been employed in\norder to discover knowledge from social media. The use of MapReduce and\ndeveloping a distributed algorithm towards an integrated platform that can\nscale for any data volume and provide a social media-driven knowledge is the\nmain novelty of the proposed concept in comparison to the state-of-the-art\ntechnologies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:53:59 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Dalter", "Jens", ""], ["Dornh\u00f6fer", "Mareike", ""], ["Zenkert", "Johannes", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.06001", "submitter": "Paola Cascante-Bonilla", "authors": "Paola Cascante-Bonilla, Fuwen Tan, Yanjun Qi, Vicente Ordonez", "title": "Curriculum Labeling: Revisiting Pseudo-Labeling for Semi-Supervised\n  Learning", "comments": "In the 35th AAAI Conference on Artificial Intelligence. AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we revisit the idea of pseudo-labeling in the context of\nsemi-supervised learning where a learning algorithm has access to a small set\nof labeled samples and a large set of unlabeled samples. Pseudo-labeling works\nby applying pseudo-labels to samples in the unlabeled set by using a model\ntrained on the combination of the labeled samples and any previously\npseudo-labeled samples, and iteratively repeating this process in a\nself-training cycle. Current methods seem to have abandoned this approach in\nfavor of consistency regularization methods that train models under a\ncombination of different styles of self-supervised losses on the unlabeled\nsamples and standard supervised losses on the labeled samples. We empirically\ndemonstrate that pseudo-labeling can in fact be competitive with the\nstate-of-the-art, while being more resilient to out-of-distribution samples in\nthe unlabeled set. We identify two key factors that allow pseudo-labeling to\nachieve such remarkable results (1) applying curriculum learning principles and\n(2) avoiding concept drift by restarting model parameters before each\nself-training cycle. We obtain 94.91% accuracy on CIFAR-10 using only 4,000\nlabeled samples, and 68.87% top-1 accuracy on Imagenet-ILSVRC using only 10% of\nthe labeled samples. The code is available at\nhttps://github.com/uvavision/Curriculum-Labeling\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:24:27 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 16:14:35 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cascante-Bonilla", "Paola", ""], ["Tan", "Fuwen", ""], ["Qi", "Yanjun", ""], ["Ordonez", "Vicente", ""]]}, {"id": "2001.06007", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, Cl\\'ement Delgrange, David Mugisha, Jean-Michel Dussoux,\n  Pierre-Yves Oudeyer, and Peter Ford Dominey", "title": "User-in-the-loop Adaptive Intent Detection for Instructable Digital\n  Assistant", "comments": "To be published as a conference paper in the proceedings of IUI'20", "journal-ref": "25th International Conference on Intelligent User Interfaces (IUI\n  '20), March 17--20, 2020, Cagliari, Italy", "doi": "10.1145/3377325.3377490", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are becoming increasingly comfortable using Digital Assistants (DAs)\nto interact with services or connected objects. However, for non-programming\nusers, the available possibilities for customizing their DA are limited and do\nnot include the possibility of teaching the assistant new tasks. To make the\nmost of the potential of DAs, users should be able to customize assistants by\ninstructing them through Natural Language (NL). To provide such\nfunctionalities, NL interpretation in traditional assistants should be\nimproved: (1) The intent identification system should be able to recognize new\nforms of known intents, and to acquire new intents as they are expressed by the\nuser. (2) In order to be adaptive to novel intents, the Natural Language\nUnderstanding module should be sample efficient, and should not rely on a\npretrained model. Rather, the system should continuously collect the training\ndata as it learns new intents from the user. In this work, we propose AidMe\n(Adaptive Intent Detection in Multi-Domain Environments), a user-in-the-loop\nadaptive intent detection framework that allows the assistant to adapt to its\nuser by learning his intents as their interaction progresses. AidMe builds its\nrepertoire of intents and collects data to train a model of semantic similarity\nevaluation that can discriminate between the learned intents and autonomously\ndiscover new forms of known intents. AidMe addresses two major issues - intent\nlearning and user adaptation - for instructable digital assistants. We\ndemonstrate the capabilities of AidMe as a standalone system by comparing it\nwith a one-shot learning system and a pretrained NLU module through simulations\nof interactions with a user. We also show how AidMe can smoothly integrate to\nan existing instructable digital assistant.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:06:43 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Lair", "Nicolas", ""], ["Delgrange", "Cl\u00e9ment", ""], ["Mugisha", "David", ""], ["Dussoux", "Jean-Michel", ""], ["Oudeyer", "Pierre-Yves", ""], ["Dominey", "Peter Ford", ""]]}, {"id": "2001.06033", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand", "title": "Extracting more from boosted decision trees: A high energy physics case\n  study", "comments": "Second Workshop on Machine Learning and the Physical Sciences\n  (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle identification is one of the core tasks in the data analysis\npipeline at the Large Hadron Collider (LHC). Statistically, this entails the\nidentification of rare signal events buried in immense backgrounds that mimic\nthe properties of the former. In machine learning parlance, particle\nidentification represents a classification problem characterized by overlapping\nand imbalanced classes. Boosted decision trees (BDTs) have had tremendous\nsuccess in the particle identification domain but more recently have been\novershadowed by deep learning (DNNs) approaches. This work proposes an\nalgorithm to extract more out of standard boosted decision trees by targeting\ntheir main weakness, susceptibility to overfitting. This novel construction\nharnesses the meta-learning techniques of boosting and bagging simultaneously\nand performs remarkably well on the ATLAS Higgs (H) to tau-tau data set (ATLAS\net al., 2014) which was the subject of the 2014 Higgs ML Challenge\n(Adam-Bourdarios et al., 2015). While the decay of Higgs to a pair of tau\nleptons was established in 2018 (CMS collaboration et al., 2017) at the\n4.9$\\sigma$ significance based on the 2016 data taking period, the 2014 public\ndata set continues to serve as a benchmark data set to test the performance of\nsupervised classification schemes. We show that the score achieved by the\nproposed algorithm is very close to the published winning score which leverages\nan ensemble of deep neural networks (DNNs). Although this paper focuses on a\nsingle application, it is expected that this simple and robust technique will\nfind wider applications in high energy physics.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 19:13:28 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Lalchand", "Vidhi", ""]]}, {"id": "2001.06047", "submitter": "Assaf Marron", "authors": "Assaf Marron, Lior Limonad, Sarah Pollack, and David Harel", "title": "Expecting the Unexpected: Developing Autonomous-System Design Principles\n  for Reacting to Unpredicted Events and Conditions", "comments": "6 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When developing autonomous systems, engineers and other stakeholders make\ngreat effort to prepare the system for all foreseeable events and conditions.\nHowever, these systems are still bound to encounter events and conditions that\nwere not considered at design time. For reasons like safety, cost, or ethics,\nit is often highly desired that these new situations be handled correctly upon\nfirst encounter. In this paper we first justify our position that there will\nalways exist unpredicted events and conditions, driven among others by: new\ninventions in the real world; the diversity of world-wide system deployments\nand uses; and, the non-negligible probability that multiple seemingly unlikely\nevents, which may be neglected at design time, will not only occur, but occur\ntogether. We then argue that despite this unpredictability property, handling\nthese events and conditions is indeed possible. Hence, we offer and exemplify\ndesign principles that when applied in advance, can enable systems to deal, in\nthe future, with unpredicted circumstances. We conclude with a discussion of\nhow this work and a broader theoretical study of the unexpected can contribute\ntoward a foundation of engineering principles for developing trustworthy\nnext-generation autonomous systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 19:39:01 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 12:30:23 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 13:39:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Marron", "Assaf", ""], ["Limonad", "Lior", ""], ["Pollack", "Sarah", ""], ["Harel", "David", ""]]}, {"id": "2001.06057", "submitter": "Evgenia Rusak", "authors": "Evgenia Rusak, Lukas Schott, Roland S. Zimmermann, Julian Bitterwolf,\n  Oliver Bringmann, Matthias Bethge, Wieland Brendel", "title": "A simple way to make neural networks robust against diverse image\n  corruptions", "comments": "Oral presentation at the European Conference for Computer Vision\n  (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human visual system is remarkably robust against a wide range of\nnaturally occurring variations and corruptions like rain or snow. In contrast,\nthe performance of modern image recognition models strongly degrades when\nevaluated on previously unseen corruptions. Here, we demonstrate that a simple\nbut properly tuned training with additive Gaussian and Speckle noise\ngeneralizes surprisingly well to unseen corruptions, easily reaching the\nprevious state of the art on the corruption benchmark ImageNet-C (with\nResNet50) and on MNIST-C. We build on top of these strong baseline results and\nshow that an adversarial training of the recognition model against uncorrelated\nworst-case noise distributions leads to an additional increase in performance.\nThis regularization can be combined with previously proposed defense methods\nfor further improvement.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:10:25 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 16:19:26 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 16:33:23 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 15:41:26 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2020 12:25:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Rusak", "Evgenia", ""], ["Schott", "Lukas", ""], ["Zimmermann", "Roland S.", ""], ["Bitterwolf", "Julian", ""], ["Bringmann", "Oliver", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "2001.06058", "submitter": "Chen Cai", "authors": "Chen Cai, Yusu Wang", "title": "Understanding the Power of Persistence Pairing via Permutation Test", "comments": "20 pages, 6 graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently many efforts have been made to incorporate persistence diagrams, one\nof the major tools in topological data analysis (TDA), into machine learning\npipelines. To better understand the power and limitation of persistence\ndiagrams, we carry out a range of experiments on both graph data and shape\ndata, aiming to decouple and inspect the effects of different factors involved.\nTo this end, we also propose the so-called \\emph{permutation test} for\npersistence diagrams to delineate critical values and pairings of critical\nvalues. For graph classification tasks, we note that while persistence pairing\nyields consistent improvement over various benchmark datasets, it appears that\nfor various filtration functions tested, most discriminative power comes from\ncritical values. For shape segmentation and classification, however, we note\nthat persistence pairing shows significant power on most of the benchmark\ndatasets, and improves over both summaries based on merely critical values, and\nthose based on permutation tests. Our results help provide insights on when\npersistence diagram based summaries could be more suitable.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:13:20 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Cai", "Chen", ""], ["Wang", "Yusu", ""]]}, {"id": "2001.06081", "submitter": "Soheil Mehrabkhani", "authors": "Soheil Mehrabkhani", "title": "Fourier Transform Approach to Machine Learning III: Fourier\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Fourier-based learning algorithm for highly nonlinear multiclass\nclassification. The algorithm is based on a smoothing technique to calculate\nthe probability distribution of all classes. To obtain the probability\ndistribution, the density distribution of each class is smoothed by a low-pass\nfilter separately. The advantage of the Fourier representation is capturing the\nnonlinearities of the data distribution without defining any kernel function.\nFurthermore, contrary to the support vector machines, it makes a probabilistic\nexplanation for the classification possible. Moreover, it can treat overlapped\nclasses as well. Comparing to the logistic regression, it does not require\nfeature engineering. In general, its computational performance is also very\nwell for large data sets and in contrast to other algorithms, the typical\noverfitting problem does not happen at all. The capability of the algorithm is\ndemonstrated for multiclass classification with overlapped classes and very\nhigh nonlinearity of the class distributions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 10:29:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 14:52:34 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Mehrabkhani", "Soheil", ""]]}, {"id": "2001.06086", "submitter": "Johan Pauwels", "authors": "Johan Pauwels, Gy\\\"orgy Fazekas, Mark B. Sandler", "title": "A Critical Look at the Applicability of Markov Logic Networks for Music\n  Signal Analysis", "comments": "Accepted for presentation at the Ninth International Workshop on\n  Statistical Relational AI (StarAI 2020) at the 34th AAAI Conference on\n  Artificial Intelligence (AAAI) in New York, on February 7th 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Markov logic networks (MLNs) have been proposed as a\npotentially useful paradigm for music signal analysis. Because all hidden\nMarkov models can be reformulated as MLNs, the latter can provide an\nall-encompassing framework that reuses and extends previous work in the field.\nHowever, just because it is theoretically possible to reformulate previous work\nas MLNs, does not mean that it is advantageous. In this paper, we analyse some\nproposed examples of MLNs for musical analysis and consider their practical\ndisadvantages when compared to formulating the same musical dependence\nrelationships as (dynamic) Bayesian networks. We argue that a number of\npractical hurdles such as the lack of support for sequences and for arbitrary\ncontinuous probability distributions make MLNs less than ideal for the proposed\nmusical applications, both in terms of easy of formulation and computational\nrequirements due to their required inference algorithms. These conclusions are\nnot specific to music, but apply to other fields as well, especially when\nsequential data with continuous observations is involved. Finally, we show that\nthe ideas underlying the proposed examples can be expressed perfectly well in\nthe more commonly used framework of (dynamic) Bayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:46:13 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Pauwels", "Johan", ""], ["Fazekas", "Gy\u00f6rgy", ""], ["Sandler", "Mark B.", ""]]}, {"id": "2001.06089", "submitter": "Daniel Steinberg", "authors": "Daniel Steinberg, Alistair Reid and Simon O'Callaghan", "title": "Fairness Measures for Regression via Probabilistic Classification", "comments": "Accepted to the 2nd Ethics of Data Science Conference 2020 (March,\n  Sydney, Australia)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness involves expressing notions such as equity, or\nreasonable treatment, as quantifiable measures that a machine learning\nalgorithm can optimise. Most work in the literature to date has focused on\nclassification problems where the prediction is categorical, such as accepting\nor rejecting a loan application. This is in part because classification\nfairness measures are easily computed by comparing the rates of outcomes,\nleading to behaviours such as ensuring that the same fraction of eligible men\nare selected as eligible women. But such measures are computationally difficult\nto generalise to the continuous regression setting for problems such as\npricing, or allocating payments. The difficulty arises from estimating\nconditional densities (such as the probability density that a system will\nover-charge by a certain amount). For the regression setting we introduce\ntractable approximations of the independence, separation and sufficiency\ncriteria by observing that they factorise as ratios of different conditional\nprobabilities of the protected attributes. We introduce and train machine\nlearning classifiers, distinct from the predictor, as a mechanism to estimate\nthese probabilities from the data. This naturally leads to model agnostic,\ntractable approximations of the criteria, which we explore experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:53:26 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 03:46:01 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Steinberg", "Daniel", ""], ["Reid", "Alistair", ""], ["O'Callaghan", "Simon", ""]]}, {"id": "2001.06099", "submitter": "Farnaz Behnia", "authors": "Farnaz Behnia, Ali Mirzaeian, Mohammad Sabokrou, Sai Manoj, Tinoosh\n  Mohsenin, Khaled N. Khasawneh, Liang Zhao, Houman Homayoun, Avesta Sasan", "title": "Code-Bridged Classifier (CBC): A Low or Negative Overhead Defense for\n  Making a CNN Classifier Robust Against Adversarial Attacks", "comments": "6 pages, Accepted and to appear in ISQED 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Code-Bridged Classifier (CBC), a framework for\nmaking a Convolutional Neural Network (CNNs) robust against adversarial attacks\nwithout increasing or even by decreasing the overall models' computational\ncomplexity. More specifically, we propose a stacked encoder-convolutional\nmodel, in which the input image is first encoded by the encoder module of a\ndenoising auto-encoder, and then the resulting latent representation (without\nbeing decoded) is fed to a reduced complexity CNN for image classification. We\nillustrate that this network not only is more robust to adversarial examples\nbut also has a significantly lower computational complexity when compared to\nthe prior art defenses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:16:58 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Behnia", "Farnaz", ""], ["Mirzaeian", "Ali", ""], ["Sabokrou", "Mohammad", ""], ["Manoj", "Sai", ""], ["Mohsenin", "Tinoosh", ""], ["Khasawneh", "Khaled N.", ""], ["Zhao", "Liang", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "2001.06103", "submitter": "Vansh Narula", "authors": "Vansh Narula, Zhangyang (Atlas) Wang and Theodora Chaspari", "title": "An adversarial learning framework for preserving users' anonymity in\n  face-based emotion recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image and video-capturing technologies have permeated our every-day life.\nSuch technologies can continuously monitor individuals' expressions in\nreal-life settings, affording us new insights into their emotional states and\ntransitions, thus paving the way to novel well-being and healthcare\napplications. Yet, due to the strong privacy concerns, the use of such\ntechnologies is met with strong skepticism, since current face-based emotion\nrecognition systems relying on deep learning techniques tend to preserve\nsubstantial information related to the identity of the user, apart from the\nemotion-specific information. This paper proposes an adversarial learning\nframework which relies on a convolutional neural network (CNN) architecture\ntrained through an iterative procedure for minimizing identity-specific\ninformation and maximizing emotion-dependent information. The proposed approach\nis evaluated through emotion classification and face identification metrics,\nand is compared against two CNNs, one trained solely for emotion recognition\nand the other trained solely for face identification. Experiments are performed\nusing the Yale Face Dataset and Japanese Female Facial Expression Database.\nResults indicate that the proposed approach can learn a convolutional\ntransformation for preserving emotion recognition accuracy and degrading face\nidentity recognition, providing a foundation toward privacy-aware emotion\nrecognition technologies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:45:52 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Narula", "Vansh", "", "Atlas"], ["Zhangyang", "", "", "Atlas"], ["Wang", "", ""], ["Chaspari", "Theodora", ""]]}, {"id": "2001.06105", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou, Joseph Mellor, Nikunj C. Oza, Gavin Brown", "title": "Better Boosting with Bandits for Online Learning", "comments": "44 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probability estimates generated by boosting ensembles are poorly calibrated\nbecause of the margin maximization nature of the algorithm. The outputs of the\nensemble need to be properly calibrated before they can be used as probability\nestimates. In this work, we demonstrate that online boosting is also prone to\nproducing distorted probability estimates. In batch learning, calibration is\nachieved by reserving part of the training data for training the calibrator\nfunction. In the online setting, a decision needs to be made on each round:\nshall the new example(s) be used to update the parameters of the ensemble or\nthose of the calibrator. We proceed to resolve this decision with the aid of\nbandit optimization algorithms. We demonstrate superior performance to\nuncalibrated and naively-calibrated on-line boosting ensembles in terms of\nprobability estimation. Our proposed mechanism can be easily adapted to other\ntasks(e.g. cost-sensitive classification) and is robust to the choice of\nhyperparameters of both the calibrator and the ensemble.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 22:48:22 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Mellor", "Joseph", ""], ["Oza", "Nikunj C.", ""], ["Brown", "Gavin", ""]]}, {"id": "2001.06116", "submitter": "Gaurav Manek", "authors": "Gaurav Manek, J. Zico Kolter", "title": "Learning Stable Deep Dynamics Models", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are commonly used to model dynamical systems, predicting how\nthe state of a system will evolve over time (either autonomously or in response\nto control inputs). Despite the predictive power of these systems, it has been\ndifficult to make formal claims about the basic properties of the learned\nsystems. In this paper, we propose an approach for learning dynamical systems\nthat are guaranteed to be stable over the entire state space. The approach\nworks by jointly learning a dynamics model and Lyapunov function that\nguarantees non-expansiveness of the dynamics under the learned Lyapunov\nfunction. We show that such learning systems are able to model simple dynamical\nsystems and can be combined with additional deep generative models to learn\ncomplex dynamics, such as video textures, in a fully end-to-end fashion.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 00:04:45 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Manek", "Gaurav", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2001.06130", "submitter": "Xuebin Zheng", "authors": "Bingxin Zhou, Xuebin Zheng, Junbin Gao", "title": "On the Trend-corrected Variant of Adaptive Stochastic Optimization\n  Methods", "comments": "8 pages, 4 figures, 2 tables, IJCNN2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207166", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam-type optimizers, as a class of adaptive moment estimation methods with\nthe exponential moving average scheme, have been successfully used in many\napplications of deep learning. Such methods are appealing due to the capability\non large-scale sparse datasets with high computational efficiency. In this\npaper, we present a new framework for Adam-type methods with the trend\ninformation when updating the parameters with the adaptive step size and\ngradients. The additional terms in the algorithm promise an efficient movement\non the complex cost surface, and thus the loss would converge more rapidly. We\nshow empirically the importance of adding the trend component, where our\nframework outperforms the conventional Adam and AMSGrad methods constantly on\nthe classical models with several real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 01:23:23 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 01:39:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhou", "Bingxin", ""], ["Zheng", "Xuebin", ""], ["Gao", "Junbin", ""]]}, {"id": "2001.06137", "submitter": "Zhen Cui", "authors": "Chunyan Xu, Zhen Cui, Xiaobin Hong, Tong Zhang, Jian Yang, and Wei Liu", "title": "Graph Inference Learning for Semi-supervised Classification", "comments": "11 pages", "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address semi-supervised classification of graph data, where\nthe categories of those unlabeled nodes are inferred from labeled nodes as well\nas graph structures. Recent works often solve this problem via advanced graph\nconvolution in a conventionally supervised manner, but the performance could\ndegrade significantly when labeled data is scarce. To this end, we propose a\nGraph Inference Learning (GIL) framework to boost the performance of\nsemi-supervised node classification by learning the inference of node labels on\ngraph topology. To bridge the connection between two nodes, we formally define\na structure relation by encapsulating node attributes, between-node paths, and\nlocal topological structures together, which can make the inference\nconveniently deduced from one node to another node. For learning the inference\nprocess, we further introduce meta-optimization on structure relations from\ntraining nodes to validation nodes, such that the learnt graph inference\ncapability can be better self-adapted to testing nodes. Comprehensive\nevaluations on four benchmark datasets (including Cora, Citeseer, Pubmed, and\nNELL) demonstrate the superiority of our proposed GIL when compared against\nstate-of-the-art methods on the semi-supervised node classification task.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 02:52:30 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Xu", "Chunyan", ""], ["Cui", "Zhen", ""], ["Hong", "Xiaobin", ""], ["Zhang", "Tong", ""], ["Yang", "Jian", ""], ["Liu", "Wei", ""]]}, {"id": "2001.06145", "submitter": "Adam Stinchcombe", "authors": "Jihun Han, Mihai Nica, Adam R Stinchcombe", "title": "A Derivative-Free Method for Solving Elliptic Partial Differential\n  Equations with Deep Neural Networks", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109672", "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep neural network based method for solving a class of\nelliptic partial differential equations. We approximate the solution of the PDE\nwith a deep neural network which is trained under the guidance of a\nprobabilistic representation of the PDE in the spirit of the Feynman-Kac\nformula. The solution is given by an expectation of a martingale process driven\nby a Brownian motion. As Brownian walkers explore the domain, the deep neural\nnetwork is iteratively trained using a form of reinforcement learning. Our\nmethod is a 'Derivative-Free Loss Method' since it does not require the\nexplicit calculation of the derivatives of the neural network with respect to\nthe input neurons in order to compute the training loss. The advantages of our\nmethod are showcased in a series of test problems: a corner singularity\nproblem, an interface problem, and an application to a chemotaxis population\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 03:29:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Han", "Jihun", ""], ["Nica", "Mihai", ""], ["Stinchcombe", "Adam R", ""]]}, {"id": "2001.06178", "submitter": "Marelie Davel", "authors": "Marelie H. Davel, Marthinus W. Theunissen, Arnold M. Pretorius,\n  Etienne Barnard", "title": "DNNs as Layers of Cooperating Classifiers", "comments": "Accepted at AAAI-2020. The preprint contains additional figures and\n  an appendix not included in the conference version. Main text remains\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robust theoretical framework that can describe and predict the\ngeneralization ability of deep neural networks (DNNs) in general circumstances\nremains elusive. Classical attempts have produced complexity metrics that rely\nheavily on global measures of compactness and capacity with little\ninvestigation into the effects of sub-component collaboration. We demonstrate\nintriguing regularities in the activation patterns of the hidden nodes within\nfully-connected feedforward networks. By tracing the origin of these patterns,\nwe show how such networks can be viewed as the combination of two information\nprocessing systems: one continuous and one discrete. We describe how these two\nsystems arise naturally from the gradient-based optimization process, and\ndemonstrate the classification ability of the two systems, individually and in\ncollaboration. This perspective on DNN classification offers a novel way to\nthink about generalization, in which different subsets of the training data are\nused to train distinct classifiers; those classifiers are then combined to\nperform the classification task, and their consistency is crucial for accurate\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 07:45:26 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Davel", "Marelie H.", ""], ["Theunissen", "Marthinus W.", ""], ["Pretorius", "Arnold M.", ""], ["Barnard", "Etienne", ""]]}, {"id": "2001.06194", "submitter": "Zhen Yu", "authors": "Ping Zhou, Zhen Yu, Jingyi Ma, Maozai Tian, and Ye Fan", "title": "Communication-Efficient Distributed Estimator for Generalized Linear\n  Models with a Diverging Number of Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed statistical inference has recently attracted immense attention.\nThe asymptotic efficiency of the maximum likelihood estimator (MLE), the\none-step MLE, and the aggregated estimating equation estimator are established\nfor generalized linear models under the \"large $n$, diverging $p_n$\" framework,\nwhere the dimension of the covariates $p_n$ grows to infinity at a polynomial\nrate $o(n^\\alpha)$ for some $0<\\alpha<1$. Then a novel method is proposed to\nobtain an asymptotically efficient estimator for large-scale distributed data\nby two rounds of communication. In this novel method, the assumption on the\nnumber of servers is more relaxed and thus practical for real-world\napplications. Simulations and a case study demonstrate the satisfactory\nfinite-sample performance of the proposed estimators.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 08:51:11 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 17:25:05 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zhou", "Ping", ""], ["Yu", "Zhen", ""], ["Ma", "Jingyi", ""], ["Tian", "Maozai", ""], ["Fan", "Ye", ""]]}, {"id": "2001.06202", "submitter": "Anbu Huang", "authors": "Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen,\n  Lican Feng, Tianjian Chen, Han Yu, Qiang Yang", "title": "FedVision: An Online Visual Object Detection Platform Powered by\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object detection is a computer vision-based artificial intelligence\n(AI) technique which has many practical applications (e.g., fire hazard\nmonitoring). However, due to privacy concerns and the high cost of transmitting\nvideo data, it is highly challenging to build object detection models on\ncentrally stored large training datasets following the current approach.\nFederated learning (FL) is a promising approach to resolve this challenge.\nNevertheless, there currently lacks an easy to use tool to enable computer\nvision application developers who are not experts in federated learning to\nconveniently leverage this technology and apply it in their systems. In this\npaper, we report FedVision - a machine learning engineering platform to support\nthe development of federated learning powered computer vision applications. The\nplatform has been deployed through a collaboration between WeBank and Extreme\nVision to help customers develop computer vision-based safety monitoring\nsolutions in smart city applications. Over four months of usage, it has\nachieved significant efficiency improvement and cost reduction while removing\nthe need to transmit sensitive data for three major corporate customers. To the\nbest of our knowledge, this is the first real application of FL in computer\nvision-based tasks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:02:36 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Liu", "Yang", ""], ["Huang", "Anbu", ""], ["Luo", "Yun", ""], ["Huang", "He", ""], ["Liu", "Youzhi", ""], ["Chen", "Yuanyuan", ""], ["Feng", "Lican", ""], ["Chen", "Tianjian", ""], ["Yu", "Han", ""], ["Yang", "Qiang", ""]]}, {"id": "2001.06216", "submitter": "Qiang Huang", "authors": "Qiang Huang, Makoto Yamada, Yuan Tian, Dinesh Singh, Dawei Yin, Yi\n  Chang", "title": "GraphLIME: Local Interpretable Model Explanations for Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structured data has wide applicability in various domains such as\nphysics, chemistry, biology, computer vision, and social networks, to name a\nfew. Recently, graph neural networks (GNN) were shown to be successful in\neffectively representing graph structured data because of their good\nperformance and generalization ability. GNN is a deep learning based method\nthat learns a node representation by combining specific nodes and the\nstructural/topological information of a graph. However, like other deep models,\nexplaining the effectiveness of GNN models is a challenging task because of the\ncomplex nonlinear transformations made over the iterations. In this paper, we\npropose GraphLIME, a local interpretable model explanation for graphs using the\nHilbert-Schmidt Independence Criterion (HSIC) Lasso, which is a nonlinear\nfeature selection method. GraphLIME is a generic GNN-model explanation\nframework that learns a nonlinear interpretable model locally in the subgraph\nof the node being explained. More specifically, to explain a node, we generate\na nonlinear interpretable model from its $N$-hop neighborhood and then compute\nthe K most representative features as the explanations of its prediction using\nHSIC Lasso. Through experiments on two real-world datasets, the explanations of\nGraphLIME are found to be of extraordinary degree and more descriptive in\ncomparison to the existing explanation methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:50:28 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 04:29:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Huang", "Qiang", ""], ["Yamada", "Makoto", ""], ["Tian", "Yuan", ""], ["Singh", "Dinesh", ""], ["Yin", "Dawei", ""], ["Chang", "Yi", ""]]}, {"id": "2001.06232", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Grzegorz Swirszcz and Joao Carreira and Viorica\n  Patraucean", "title": "Sideways: Depth-Parallel Training of Video Models", "comments": "Accepted at CVPR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sideways, an approximate backpropagation scheme for training video\nmodels. In standard backpropagation, the gradients and activations at every\ncomputation step through the model are temporally synchronized. The forward\nactivations need to be stored until the backward pass is executed, preventing\ninter-layer (depth) parallelization. However, can we leverage smooth, redundant\ninput streams such as videos to develop a more efficient training scheme? Here,\nwe explore an alternative to backpropagation; we overwrite network activations\nwhenever new ones, i.e., from new frames, become available. Such a more gradual\naccumulation of information from both passes breaks the precise correspondence\nbetween gradients and activations, leading to theoretically more noisy weight\nupdates. Counter-intuitively, we show that Sideways training of deep\nconvolutional video networks not only still converges, but can also potentially\nexhibit better generalization compared to standard synchronized\nbackpropagation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:49:55 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 18:16:44 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 22:48:10 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Swirszcz", "Grzegorz", ""], ["Carreira", "Joao", ""], ["Patraucean", "Viorica", ""]]}, {"id": "2001.06238", "submitter": "Linda Senigagliesi", "authors": "Linda Senigagliesi, Marco Baldi, and Ennio Gambi", "title": "Comparison of Statistical and Machine Learning Techniques for Physical\n  Layer Authentication", "comments": null, "journal-ref": null, "doi": "10.1109/TIFS.2020.3033454", "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider authentication at the physical layer, in which the\nauthenticator aims at distinguishing a legitimate supplicant from an attacker\non the basis of the characteristics of a set of parallel wireless channels,\nwhich are affected by time-varying fading. Moreover, the attacker's channel has\na spatial correlation with the supplicant's one. In this setting, we assess and\ncompare the performance achieved by different approaches under different\nchannel conditions. We first consider the use of two different statistical\ndecision methods, and we prove that using a large number of references (in the\nform of channel estimates) affected by different levels of time-varying fading\nis not beneficial from a security point of view. We then consider\nclassification methods based on machine learning. In order to face the worst\ncase scenario of an authenticator provided with no forged messages during\ntraining, we consider one-class classifiers. When instead the training set\nincludes some forged messages, we resort to more conventional binary\nclassifiers, considering the cases in which such messages are either labelled\nor not. For the latter case, we exploit clustering algorithms to label the\ntraining set. The performance of both nearest neighbor (NN) and support vector\nmachine (SVM) classification techniques is evaluated. Through numerical\nexamples, we show that under the same probability of false alarm, one-class\nclassification (OCC) algorithms achieve the lowest probability of missed\ndetection when a small spatial correlation exists between the main channel and\nthe adversary one, while statistical methods are advantageous when the spatial\ncorrelation between the two channels is large.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:02:23 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 10:11:23 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Senigagliesi", "Linda", ""], ["Baldi", "Marco", ""], ["Gambi", "Ennio", ""]]}, {"id": "2001.06246", "submitter": "Wilhelm Kirchg\\\"assner", "authors": "Wilhelm Kirchg\\\"assner, Oliver Wallscheid, Joachim B\\\"ocker", "title": "Data-Driven Permanent Magnet Temperature Estimation in Synchronous\n  Motors with Supervised Machine Learning", "comments": "preprint for TII: SS on Applications of Artificial Intelligence in\n  Industrial Power Electronics and Systems", "journal-ref": null, "doi": "10.1109/TEC.2021.3052546", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the magnet temperature in permanent magnet synchronous motors\n(PMSMs) for automotive applications is a challenging task for several decades\nnow, as signal injection or sensor-based methods still prove unfeasible in a\ncommercial context. Overheating results in severe motor deterioration and is\nthus of high concern for the machine's control strategy and its design. Lack of\nprecise temperature estimations leads to lesser device utilization and higher\nmaterial cost. In this work, several machine learning (ML) models are\nempirically evaluated on their estimation accuracy for the task of predicting\nlatent high-dynamic magnet temperature profiles. The range of selected\nalgorithms covers as diverse approaches as possible with ordinary and weighted\nleast squares, support vector regression, $k$-nearest neighbors, randomized\ntrees and neural networks. Having test bench data available, it is shown that\nML approaches relying merely on collected data meet the estimation performance\nof classical thermal models built on thermodynamic theory, yet not all kinds of\nmodels render efficient use of large datasets or sufficient modeling\ncapacities. Especially linear regression and simple feed-forward neural\nnetworks with optimized hyperparameters mark strong predictive quality at low\nto moderate model sizes.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:41:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Kirchg\u00e4ssner", "Wilhelm", ""], ["Wallscheid", "Oliver", ""], ["B\u00f6cker", "Joachim", ""]]}, {"id": "2001.06263", "submitter": "Shayan Aziznejad", "authors": "Shayan Aziznejad, Harshit Gupta, Joaquim Campos, Michael Unser", "title": "Deep Neural Networks with Trainable Activations and Controlled Lipschitz\n  Constant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a variational framework to learn the activation functions of\ndeep neural networks. Our aim is to increase the capacity of the network while\ncontrolling an upper-bound of the actual Lipschitz constant of the input-output\nrelation. To that end, we first establish a global bound for the Lipschitz\nconstant of neural networks. Based on the obtained bound, we then formulate a\nvariational problem for learning activation functions. Our variational problem\nis infinite-dimensional and is not computationally tractable. However, we prove\nthat there always exists a solution that has continuous and piecewise-linear\n(linear-spline) activations. This reduces the original problem to a\nfinite-dimensional minimization where an l1 penalty on the parameters of the\nactivations favors the learning of sparse nonlinearities. We numerically\ncompare our scheme with standard ReLU network and its variations, PReLU and\nLeakyReLU and we empirically demonstrate the practical aspects of our\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:32:55 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:27:44 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Aziznejad", "Shayan", ""], ["Gupta", "Harshit", ""], ["Campos", "Joaquim", ""], ["Unser", "Michael", ""]]}, {"id": "2001.06265", "submitter": "Ayush Chopra", "authors": "Surgan Jandial, Ayush Chopra, Kumar Ayush, Mayur Hemani, Abhijeet\n  Kumar, and Balaji Krishnamurthy", "title": "SieveNet: A Unified Framework for Robust Image-Based Virtual Try-On", "comments": "Accepted at IEEE WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-based virtual try-on for fashion has gained considerable attention\nrecently. The task requires trying on a clothing item on a target model image.\nAn efficient framework for this is composed of two stages: (1) warping\n(transforming) the try-on cloth to align with the pose and shape of the target\nmodel, and (2) a texture transfer module to seamlessly integrate the warped\ntry-on cloth onto the target model image. Existing methods suffer from\nartifacts and distortions in their try-on output. In this work, we present\nSieveNet, a framework for robust image-based virtual try-on. Firstly, we\nintroduce a multi-stage coarse-to-fine warping network to better model\nfine-grained intricacies (while transforming the try-on cloth) and train it\nwith a novel perceptual geometric matching loss. Next, we introduce a try-on\ncloth conditioned segmentation mask prior to improve the texture transfer\nnetwork. Finally, we also introduce a dueling triplet loss strategy for\ntraining the texture translation network which further improves the quality of\nthe generated try-on results. We present extensive qualitative and quantitative\nevaluations of each component of the proposed pipeline and show significant\nperformance improvements against the current state-of-the-art method.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:33:54 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Jandial", "Surgan", ""], ["Chopra", "Ayush", ""], ["Ayush", "Kumar", ""], ["Hemani", "Mayur", ""], ["Kumar", "Abhijeet", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2001.06270", "submitter": "Marc Bocquet", "authors": "Marc Bocquet, Julien Brajard, Alberto Carrassi, Laurent Bertino", "title": "Bayesian inference of chaotic dynamics by merging data assimilation,\n  machine learning and expectation-maximization", "comments": null, "journal-ref": "Foundations of Data Science, 2, 55-80, 2020", "doi": "10.3934/fods.2020004", "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction from observations of high-dimensional chaotic dynamics\nsuch as geophysical flows is hampered by (i) the partial and noisy observations\nthat can realistically be obtained, (ii) the need to learn from long time\nseries of data, and (iii) the unstable nature of the dynamics. To achieve such\ninference from the observations over long time series, it has been suggested to\ncombine data assimilation and machine learning in several ways. We show how to\nunify these approaches from a Bayesian perspective using\nexpectation-maximization and coordinate descents. In doing so, the model, the\nstate trajectory and model error statistics are estimated all together.\nImplementations and approximations of these methods are discussed. Finally, we\nnumerically and successfully test the approach on two relevant low-order\nchaotic models with distinct identifiability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 12:46:26 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 19:52:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bocquet", "Marc", ""], ["Brajard", "Julien", ""], ["Carrassi", "Alberto", ""], ["Bertino", "Laurent", ""]]}, {"id": "2001.06282", "submitter": "Omid Kavehei", "authors": "Tennison Liu, Nhan Duy Truong, Armin Nikpour, Luping Zhou, Omid\n  Kavehei", "title": "Epileptic Seizure Classification with Symmetric and Hybrid Bilinear\n  Models", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy affects nearly 1% of the global population, of which two thirds can\nbe treated by anti-epileptic drugs and a much lower percentage by surgery.\nDiagnostic procedures for epilepsy and monitoring are highly specialized and\nlabour-intensive. The accuracy of the diagnosis is also complicated by\noverlapping medical symptoms, varying levels of experience and inter-observer\nvariability among clinical professions. This paper proposes a novel hybrid\nbilinear deep learning network with an application in the clinical procedures\nof epilepsy classification diagnosis, where the use of surface\nelectroencephalogram (sEEG) and audiovisual monitoring is standard practice.\nHybrid bilinear models based on two types of feature extractors, namely\nConvolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), are\ntrained using Short-Time Fourier Transform (STFT) of one-second sEEG. In the\nproposed hybrid models, CNNs extract spatio-temporal patterns, while RNNs focus\non the characteristics of temporal dynamics in relatively longer intervals\ngiven the same input data. Second-order features, based on interactions between\nthese spatio-temporal features are further explored by bilinear pooling and\nused for epilepsy classification. Our proposed methods obtain an F1-score of\n97.4% on the Temple University Hospital Seizure Corpus and 97.2% on the\nEPILEPSIAE dataset, comparing favourably to existing benchmarks for sEEG-based\nseizure type classification. The open-source implementation of this study is\navailable at https://github.com/NeuroSyd/Epileptic-Seizure-Classification\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:22:10 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Liu", "Tennison", ""], ["Truong", "Nhan Duy", ""], ["Nikpour", "Armin", ""], ["Zhou", "Luping", ""], ["Kavehei", "Omid", ""]]}, {"id": "2001.06286", "submitter": "Pieter Delobelle", "authors": "Pieter Delobelle, Thomas Winters, Bettina Berendt", "title": "RobBERT: a Dutch RoBERTa-based Language Model", "comments": "11 pages, 4 tables, 3 figures. Accepted in EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have been dominating the field of natural\nlanguage processing in recent years, and have led to significant performance\ngains for various complex natural language tasks. One of the most prominent\npre-trained language models is BERT, which was released as an English as well\nas a multilingual version. Although multilingual BERT performs well on many\ntasks, recent studies show that BERT models trained on a single language\nsignificantly outperform the multilingual version. Training a Dutch BERT model\nthus has a lot of potential for a wide range of Dutch NLP tasks. While previous\napproaches have used earlier implementations of BERT to train a Dutch version\nof BERT, we used RoBERTa, a robustly optimized BERT approach, to train a Dutch\nlanguage model called RobBERT. We measured its performance on various tasks as\nwell as the importance of the fine-tuning dataset size. We also evaluated the\nimportance of language-specific tokenizers and the model's fairness. We found\nthat RobBERT improves state-of-the-art results for various tasks, and\nespecially significantly outperforms other models when dealing with smaller\ndatasets. These results indicate that it is a powerful pre-trained model for a\nlarge variety of Dutch language tasks. The pre-trained and fine-tuned models\nare publicly available to support further downstream Dutch NLP applications.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 13:25:44 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 13:42:16 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Delobelle", "Pieter", ""], ["Winters", "Thomas", ""], ["Berendt", "Bettina", ""]]}, {"id": "2001.06291", "submitter": "Davis Rempe", "authors": "Davis Rempe, Srinath Sridhar, He Wang, Leonidas J. Guibas", "title": "Predicting the Physical Dynamics of Unseen 3D Objects", "comments": "In Proceedings of Winter Conference on Applications of Computer\n  Vision (WACV) 2020. arXiv admin note: text overlap with arXiv:1901.00466", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines that can predict the effect of physical interactions on the dynamics\nof previously unseen object instances are important for creating better robots\nand interactive virtual worlds. In this work, we focus on predicting the\ndynamics of 3D objects on a plane that have just been subjected to an impulsive\nforce. In particular, we predict the changes in state - 3D position, rotation,\nvelocities, and stability. Different from previous work, our approach can\ngeneralize dynamics predictions to object shapes and initial conditions that\nwere unseen during training. Our method takes the 3D object's shape as a point\ncloud and its initial linear and angular velocities as input. We extract shape\nfeatures and use a recurrent neural network to predict the full change in state\nat each time step. Our model can support training with data from both a physics\nengine or the real world. Experiments show that we can accurately predict the\nchanges in state for unseen object geometries and initial conditions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:27:59 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Rempe", "Davis", ""], ["Sridhar", "Srinath", ""], ["Wang", "He", ""], ["Guibas", "Leonidas J.", ""]]}, {"id": "2001.06296", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele, Isabelle Dehaene, Gy\\\"orgy Kov\\'acs, Lucas Sterckx,\n  Olivier Janssens, Femke Ongenae, Femke De Backere, Filip De Turck, Kristien\n  Roelens, Johan Decruyenaere, Sofie Van Hoecke, Thomas Demeester", "title": "Overly Optimistic Prediction Results on Imbalanced Data: a Case Study of\n  Flaws and Benefits when Applying Over-sampling", "comments": null, "journal-ref": "Artificial Intelligence in Medicine. 111 (2021). 101987", "doi": "10.1016/j.artmed.2020.101987", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information extracted from electrohysterography recordings could potentially\nprove to be an interesting additional source of information to estimate the\nrisk on preterm birth. Recently, a large number of studies have reported\nnear-perfect results to distinguish between recordings of patients that will\ndeliver term or preterm using a public resource, called the Term/Preterm\nElectrohysterogram database. However, we argue that these results are overly\noptimistic due to a methodological flaw being made. In this work, we focus on\none specific type of methodological flaw: applying over-sampling before\npartitioning the data into mutually exclusive training and testing sets. We\nshow how this causes the results to be biased using two artificial datasets and\nreproduce results of studies in which this flaw was identified. Moreover, we\nevaluate the actual impact of over-sampling on predictive performance, when\napplied prior to data partitioning, using the same methodologies of related\nstudies, to provide a realistic view of these methodologies' generalization\ncapabilities. We make our research reproducible by providing all the code under\nan open license.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 12:53:23 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 16:41:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Dehaene", "Isabelle", ""], ["Kov\u00e1cs", "Gy\u00f6rgy", ""], ["Sterckx", "Lucas", ""], ["Janssens", "Olivier", ""], ["Ongenae", "Femke", ""], ["De Backere", "Femke", ""], ["De Turck", "Filip", ""], ["Roelens", "Kristien", ""], ["Decruyenaere", "Johan", ""], ["Van Hoecke", "Sofie", ""], ["Demeester", "Thomas", ""]]}, {"id": "2001.06309", "submitter": "Antoine Delplace", "authors": "Antoine Delplace, Sheryl Hermoso and Kristofer Anandita", "title": "Cyber Attack Detection thanks to Machine Learning Algorithms", "comments": "46 pages, 38 figures, project report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity attacks are growing both in frequency and sophistication over\nthe years. This increasing sophistication and complexity call for more\nadvancement and continuous innovation in defensive strategies. Traditional\nmethods of intrusion detection and deep packet inspection, while still largely\nused and recommended, are no longer sufficient to meet the demands of growing\nsecurity threats. As computing power increases and cost drops, Machine Learning\nis seen as an alternative method or an additional mechanism to defend against\nmalwares, botnets, and other attacks. This paper explores Machine Learning as a\nviable solution by examining its capabilities to classify malicious traffic in\na network.\n  First, a strong data analysis is performed resulting in 22 extracted features\nfrom the initial Netflow datasets. All these features are then compared with\none another through a feature selection process. Then, our approach analyzes\nfive different machine learning algorithms against NetFlow dataset containing\ncommon botnets. The Random Forest Classifier succeeds in detecting more than\n95% of the botnets in 8 out of 13 scenarios and more than 55% in the most\ndifficult datasets. Finally, insight is given to improve and generalize the\nresults, especially through a bootstrapping technique.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 13:52:12 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Delplace", "Antoine", ""], ["Hermoso", "Sheryl", ""], ["Anandita", "Kristofer", ""]]}, {"id": "2001.06323", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Juan C. Rodriguez Gamboa, Eva Susana Albarracin E., Adenilton J. da\n  Silva, Luciana Leite, Tiago A. E. Ferreira", "title": "Wine quality rapid detection using a compact electronic nose system:\n  application focused on spoilage thresholds by acetic acid", "comments": null, "journal-ref": "LWT, Volume 108, 2019, Pages 377-384", "doi": "10.1016/j.lwt.2019.03.074", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is crucial for the wine industry to have methods like electronic nose\nsystems (E-Noses) for real-time monitoring thresholds of acetic acid in wines,\npreventing its spoilage or determining its quality. In this paper, we prove\nthat the portable and compact self-developed E-Nose, based on thin film\nsemiconductor (SnO2) sensors and trained with an approach that uses deep\nMultilayer Perceptron (MLP) neural network, can perform early detection of wine\nspoilage thresholds in routine tasks of wine quality control. To obtain rapid\nand online detection, we propose a method of rising-window focused on raw data\nprocessing to find an early portion of the sensor signals with the best\nrecognition performance. Our approach was compared with the conventional\napproach employed in E-Noses for gas recognition that involves feature\nextraction and selection techniques for preprocessing data, succeeded by a\nSupport Vector Machine (SVM) classifier. The results evidence that is possible\nto classify three wine spoilage levels in 2.7 seconds after the gas injection\npoint, implying in a methodology 63 times faster than the results obtained with\nthe conventional approach in our experimental setup.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:49:06 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Gamboa", "Juan C. Rodriguez", ""], ["E.", "Eva Susana Albarracin", ""], ["da Silva", "Adenilton J.", ""], ["Leite", "Luciana", ""], ["Ferreira", "Tiago A. E.", ""]]}, {"id": "2001.06325", "submitter": "Sizhe Chen", "authors": "Sizhe Chen, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang", "title": "Universal Adversarial Attack on Attention and the Resulting Dataset\n  DAmageNet", "comments": "accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks on deep neural networks (DNNs) have been found for\nseveral years. However, the existing adversarial attacks have high success\nrates only when the information of the victim DNN is well-known or could be\nestimated by the structure similarity or massive queries. In this paper, we\npropose to Attack on Attention (AoA), a semantic property commonly shared by\nDNNs. AoA enjoys a significant increase in transferability when the traditional\ncross entropy loss is replaced with the attention loss. Since AoA alters the\nloss function only, it could be easily combined with other\ntransferability-enhancement techniques and then achieve SOTA performance. We\napply AoA to generate 50000 adversarial samples from ImageNet validation set to\ndefeat many neural networks, and thus name the dataset as DAmageNet. 13\nwell-trained DNNs are tested on DAmageNet, and all of them have an error rate\nover 85%. Even with defenses or adversarial training, most models still\nmaintain an error rate over 70% on DAmageNet. DAmageNet is the first universal\nadversarial dataset. It could be downloaded freely and serve as a benchmark for\nrobustness testing and adversarial training.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 07:58:21 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 04:45:15 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 09:10:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Chen", "Sizhe", ""], ["He", "Zhengbao", ""], ["Sun", "Chengjin", ""], ["Yang", "Jie", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2001.06338", "submitter": "Henrique Da Costa Siqueira", "authors": "Henrique Siqueira, Sven Magg and Stefan Wermter", "title": "Efficient Facial Feature Learning with Wide Ensemble-based Convolutional\n  Neural Networks", "comments": "Accepted at the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-20), 1-1, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods, traditionally built with independently trained\nde-correlated models, have proven to be efficient methods for reducing the\nremaining residual generalization error, which results in robust and accurate\nmethods for real-world applications. In the context of deep learning, however,\ntraining an ensemble of deep networks is costly and generates high redundancy\nwhich is inefficient. In this paper, we present experiments on Ensembles with\nShared Representations (ESRs) based on convolutional networks to demonstrate,\nquantitatively and qualitatively, their data processing efficiency and\nscalability to large-scale datasets of facial expressions. We show that\nredundancy and computational load can be dramatically reduced by varying the\nbranching level of the ESR without loss of diversity and generalization power,\nwhich are both important for ensemble performance. Experiments on large-scale\ndatasets suggest that ESRs reduce the remaining residual generalization error\non the AffectNet and FER+ datasets, reach human-level performance, and\noutperform state-of-the-art methods on facial expression recognition in the\nwild using emotion and affect concepts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 14:32:27 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Siqueira", "Henrique", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "2001.06342", "submitter": "Diego Valsesia", "authors": "Andrea Bordone Molini, Diego Valsesia, Giulia Fracastoro, Enrico Magli", "title": "DeepSUM++: Non-local Deep Neural Network for Super-Resolution of\n  Unregistered Multitemporal Images", "comments": "arXiv admin note: text overlap with arXiv:1907.06490", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods for super-resolution of a remote sensing scene from\nmultiple unregistered low-resolution images have recently gained attention\nthanks to a challenge proposed by the European Space Agency. This paper\npresents an evolution of the winner of the challenge, showing how incorporating\nnon-local information in a convolutional neural network allows to exploit\nself-similar patterns that provide enhanced regularization of the\nsuper-resolution problem. Experiments on the dataset of the challenge show\nimproved performance over the state-of-the-art, which does not exploit\nnon-local information.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 11:17:19 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Molini", "Andrea Bordone", ""], ["Valsesia", "Diego", ""], ["Fracastoro", "Giulia", ""], ["Magli", "Enrico", ""]]}, {"id": "2001.06362", "submitter": "Tian Bian", "authors": "Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong,\n  Junzhou Huang", "title": "Rumor Detection on Social Media with Bi-Directional Graph Convolutional\n  Networks", "comments": "8 pages, 4 figures, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has been developing rapidly in public due to its nature of\nspreading new information, which leads to rumors being circulated. Meanwhile,\ndetecting rumors from such massive information in social media is becoming an\narduous challenge. Therefore, some deep learning methods are applied to\ndiscover rumors through the way they spread, such as Recursive Neural Network\n(RvNN) and so on. However, these deep learning methods only take into account\nthe patterns of deep propagation but ignore the structures of wide dispersion\nin rumor detection. Actually, propagation and dispersion are two crucial\ncharacteristics of rumors. In this paper, we propose a novel bi-directional\ngraph model, named Bi-Directional Graph Convolutional Networks (Bi-GCN), to\nexplore both characteristics by operating on both top-down and bottom-up\npropagation of rumors. It leverages a GCN with a top-down directed graph of\nrumor spreading to learn the patterns of rumor propagation, and a GCN with an\nopposite directed graph of rumor diffusion to capture the structures of rumor\ndispersion. Moreover, the information from the source post is involved in each\nlayer of GCN to enhance the influences from the roots of rumors. Encouraging\nempirical results on several benchmarks confirm the superiority of the proposed\nmethod over the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:12:08 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Bian", "Tian", ""], ["Xiao", "Xi", ""], ["Xu", "Tingyang", ""], ["Zhao", "Peilin", ""], ["Huang", "Wenbing", ""], ["Rong", "Yu", ""], ["Huang", "Junzhou", ""]]}, {"id": "2001.06370", "submitter": "Nicholas Gerard Timmons", "authors": "Nicholas Gerard Timmons, Andrew Rice", "title": "Approximating Activation Functions", "comments": "10 Pages, 5 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ReLU is widely seen as the default choice for activation functions in neural\nnetworks. However, there are cases where more complicated functions are\nrequired. In particular, recurrent neural networks (such as LSTMs) make\nextensive use of both hyperbolic tangent and sigmoid functions. These functions\nare expensive to compute. We used function approximation techniques to develop\nreplacements for these functions and evaluated them empirically on three\npopular network configurations. We find safe approximations that yield a 10% to\n37% improvement in training times on the CPU. These approximations were\nsuitable for all cases we considered and we believe are appropriate\nreplacements for all networks using these activation functions. We also develop\nranged approximations which only apply in some cases due to restrictions on\ntheir input domain. Our ranged approximations yield a performance improvement\nof 20% to 53% in network training time. Our functions also match or\nconsiderably out perform the ad-hoc approximations used in Theano and the\nimplementation of Word2Vec.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:25:44 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Timmons", "Nicholas Gerard", ""], ["Rice", "Andrew", ""]]}, {"id": "2001.06386", "submitter": "Mikhail Hushchyn", "authors": "Mikhail Hushchyn and Andrey Ustyuzhanin", "title": "Generalization of Change-Point Detection in Time Series Data Based on\n  Direct Density Ratio Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of the change-point detection is to discover changes of time series\ndistribution. One of the state of the art approaches of the change-point\ndetection are based on direct density ratio estimation. In this work we show\nhow existing algorithms can be generalized using various binary classification\nand regression models. In particular, we show that the Gradient Boosting over\nDecision Trees and Neural Networks can be used for this purpose. The algorithms\nare tested on several synthetic and real-world datasets. The results show that\nthe proposed methods outperform classical RuLSIF algorithm. Discussion of cases\nwhere the proposed algorithms have advantages over existing methods are also\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:45:38 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Hushchyn", "Mikhail", ""], ["Ustyuzhanin", "Andrey", ""]]}, {"id": "2001.06397", "submitter": "Yanpei Shi", "authors": "Yanpei Shi, Thomas Hain", "title": "Supervised Speaker Embedding De-Mixing in Two-Speaker Environment", "comments": "Published at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating different speaker properties from a multi-speaker environment is\nchallenging. Instead of separating a two-speaker signal in signal space like\nspeech source separation, a speaker embedding de-mixing approach is proposed.\nThe proposed approach separates different speaker properties from a two-speaker\nsignal in embedding space. The proposed approach contains two steps. In step\none, the clean speaker embeddings are learned and collected by a residual TDNN\nbased network. In step two, the two-speaker signal and the embedding of one of\nthe speakers are both input to a speaker embedding de-mixing network. The\nde-mixing network is trained to generate the embedding of the other speaker by\nreconstruction loss. Speaker identification accuracy and the cosine similarity\nscore between the clean embeddings and the de-mixed embeddings are used to\nevaluate the quality of the obtained embeddings. Experiments are done in two\nkind of data: artificial augmented two-speaker data (TIMIT) and real world\nrecording of two-speaker data (MC-WSJ). Six different speaker embedding\nde-mixing architectures are investigated. Comparing with the performance on the\nclean speaker embeddings, the obtained results show that one of the proposed\narchitectures obtained close performance, reaching 96.9% identification\naccuracy and 0.89 cosine similarity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:13:43 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:46:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shi", "Yanpei", ""], ["Hain", "Thomas", ""]]}, {"id": "2001.06399", "submitter": "Amedeo Esposito", "authors": "Amedeo Roberto Esposito, Michael Gastpar, Ibrahim Issa", "title": "Robust Generalization via $\\alpha$-Mutual Information", "comments": "Accepted to IZS2020. arXiv admin note: substantial text overlap with\n  arXiv:1912.01439", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to provide bounds connecting two probability measures\nof the same event using R\\'enyi $\\alpha$-Divergences and Sibson's\n$\\alpha$-Mutual Information, a generalization of respectively the\nKullback-Leibler Divergence and Shannon's Mutual Information. A particular case\nof interest can be found when the two probability measures considered are a\njoint distribution and the corresponding product of marginals (representing the\nstatistically independent scenario). In this case, a bound using Sibson's\n$\\alpha-$Mutual Information is retrieved, extending a result involving Maximal\nLeakage to general alphabets. These results have broad applications, from\nbounding the generalization error of learning algorithms to the more general\nframework of adaptive data analysis, provided that the divergences and/or\ninformation measures used are amenable to such an analysis ({\\it i.e.,} are\nrobust to post-processing and compose adaptively). The generalization error\nbounds are derived with respect to high-probability events but a corresponding\nbound on expected generalization error is also retrieved.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:28:30 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Esposito", "Amedeo Roberto", ""], ["Gastpar", "Michael", ""], ["Issa", "Ibrahim", ""]]}, {"id": "2001.06416", "submitter": "Aleksandr Koryagin", "authors": "Alexander Koryagin, Roman Khudorozhkov, Sergey Tsimfer, Darima\n  Mylzenova", "title": "SeismiQB -- a novel framework for deep learning with seismic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Neural Networks were successfully adopted in numerous\ndomains to solve various image-related tasks, ranging from simple\nclassification to fine borders annotation. Naturally, many researches proposed\nto use it to solve geological problems. Unfortunately, many of the seismic\nprocessing tools were developed years before the era of machine learning,\nincluding the most popular SEG-Y data format for storing seismic cubes. Its\nslow loading speed heavily hampers experimentation speed, which is essential\nfor getting acceptable results. Worse yet, there is no widely-used format for\nstoring surfaces inside the volume (for example, seismic horizons). To address\nthese problems, we've developed an open-sourced Python framework with emphasis\non working with neural networks, that provides convenient tools for (i) fast\nloading seismic cubes in multiple data formats and converting between them,\n(ii) generating crops of desired shape and augmenting them with various\ntransformations, and (iii) pairing cube data with labeled horizons or other\ntypes of geobodies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:45:56 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Koryagin", "Alexander", ""], ["Khudorozhkov", "Roman", ""], ["Tsimfer", "Sergey", ""], ["Mylzenova", "Darima", ""]]}, {"id": "2001.06448", "submitter": "Lynton Ardizzone", "authors": "Lynton Ardizzone, Radek Mackowiak, Carsten Rother, Ullrich K\\\"othe", "title": "Training Normalizing Flows with the Information Bottleneck for\n  Competitive Generative Classification", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 Proceedings\n  (NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck (IB) objective uses information theory to\nformulate a task-performance versus robustness trade-off. It has been\nsuccessfully applied in the standard discriminative classification setting. We\npose the question whether the IB can also be used to train generative\nlikelihood models such as normalizing flows. Since normalizing flows use\ninvertible network architectures (INNs), they are information-preserving by\nconstruction. This seems contradictory to the idea of a bottleneck. In this\nwork, firstly, we develop the theory and methodology of IB-INNs, a class of\nconditional normalizing flows where INNs are trained using the IB objective:\nIntroducing a small amount of {\\em controlled} information loss allows for an\nasymptotically exact formulation of the IB, while keeping the INN's generative\ncapabilities intact. Secondly, we investigate the properties of these models\nexperimentally, specifically used as generative classifiers. This model class\noffers advantages such as improved uncertainty quantification and\nout-of-distribution detection, but traditional generative classifier solutions\nsuffer considerably in classification accuracy. We find the trade-off parameter\nin the IB controls a mix of generative capabilities and accuracy close to\nstandard classifiers. Empirically, our uncertainty estimates in this mixed\nregime compare favourably to conventional generative and discriminative\nclassifiers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 17:48:40 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 12:41:05 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 15:24:12 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 14:37:54 GMT"}, {"version": "v5", "created": "Tue, 12 Jan 2021 15:01:24 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Ardizzone", "Lynton", ""], ["Mackowiak", "Radek", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2001.06471", "submitter": "Hussein Hazimeh", "authors": "Antoine Dedieu, Hussein Hazimeh, Rahul Mazumder", "title": "Learning Sparse Classifiers: Continuous and Mixed Integer Optimization\n  Perspectives", "comments": "To appear in JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a discrete optimization formulation for learning sparse\nclassifiers, where the outcome depends upon a linear combination of a small\nsubset of features. Recent work has shown that mixed integer programming (MIP)\ncan be used to solve (to optimality) $\\ell_0$-regularized regression problems\nat scales much larger than what was conventionally considered possible. Despite\ntheir usefulness, MIP-based global optimization approaches are significantly\nslower compared to the relatively mature algorithms for $\\ell_1$-regularization\nand heuristics for nonconvex regularized problems. We aim to bridge this gap in\ncomputation times by developing new MIP-based algorithms for\n$\\ell_0$-regularized classification. We propose two classes of scalable\nalgorithms: an exact algorithm that can handle $p\\approx 50,000$ features in a\nfew minutes, and approximate algorithms that can address instances with\n$p\\approx 10^6$ in times comparable to the fast $\\ell_1$-based algorithms. Our\nexact algorithm is based on the novel idea of \\textsl{integrality generation},\nwhich solves the original problem (with $p$ binary variables) via a sequence of\nmixed integer programs that involve a small number of binary variables. Our\napproximate algorithms are based on coordinate descent and local combinatorial\nsearch. In addition, we present new estimation error bounds for a class of\n$\\ell_0$-regularized estimators. Experiments on real and synthetic data\ndemonstrate that our approach leads to models with considerably improved\nstatistical performance (especially, variable selection) when compared to\ncompeting methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:47:02 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:38:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dedieu", "Antoine", ""], ["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2001.06472", "submitter": "Masudul Haque", "authors": "Goran Nakerst, John Brennan, Masudul Haque", "title": "Gradient descent with momentum --- to accelerate or to super-accelerate?", "comments": "19 pages + references, 8 figures. A variant of Nesterov acceleration\n  is proposed and studied", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider gradient descent with `momentum', a widely used method for loss\nfunction minimization in machine learning. This method is often used with\n`Nesterov acceleration', meaning that the gradient is evaluated not at the\ncurrent position in parameter space, but at the estimated position after one\nstep. In this work, we show that the algorithm can be improved by extending\nthis `acceleration' --- by using the gradient at an estimated position several\nsteps ahead rather than just one step ahead. How far one looks ahead in this\n`super-acceleration' algorithm is determined by a new hyperparameter.\nConsidering a one-parameter quadratic loss function, the optimal value of the\nsuper-acceleration can be exactly calculated and analytically estimated. We\nshow explicitly that super-accelerating the momentum algorithm is beneficial,\nnot only for this idealized problem, but also for several synthetic loss\nlandscapes and for the MNIST classification task with neural networks.\nSuper-acceleration is also easy to incorporate into adaptive algorithms like\nRMSProp or Adam, and is shown to improve these algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 18:50:07 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Nakerst", "Goran", ""], ["Brennan", "John", ""], ["Haque", "Masudul", ""]]}, {"id": "2001.06485", "submitter": "Boris Ndjia Njike", "authors": "Boris Ndjia Njike, Xavier Siebert", "title": "K-NN active learning under local smoothness assumption", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.03055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of work on convergence rates either in passive or\nactive learning. Here we first outline some of the main results that have been\nobtained, more specifically in a nonparametric setting under assumptions about\nthe smoothness of the regression function (or the boundary between classes) and\nthe margin noise. We discuss the relative merits of these underlying\nassumptions by putting active learning in perspective with recent work on\npassive learning. We design an active learning algorithm with a rate of\nconvergence better than in passive learning, using a particular smoothness\nassumption customized for k-nearest neighbors. Unlike previous active learning\nalgorithms, we use a smoothness assumption that provides a dependence on the\nmarginal distribution of the instance space. Additionally, our algorithm avoids\nthe strong density assumption that supposes the existence of the density\nfunction of the marginal distribution of the instance space and is therefore\nmore generally applicable.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:44:36 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 08:05:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Njike", "Boris Ndjia", ""], ["Siebert", "Xavier", ""]]}, {"id": "2001.06487", "submitter": "Kai Yan", "authors": "Yunlong Lu and Kai Yan", "title": "Algorithms in Multi-Agent Systems: A Holistic Perspective from\n  Reinforcement Learning and Game Theory", "comments": "14 pages, review. Reorganizing the expressions in part of\n  introduction and background", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears, which has led a dramatic increase in the number of methods and\napplications. Recent works are exploring learning beyond single-agent scenarios\nand considering multi-agent scenarios. However, they are faced with lots of\nchallenges and are seeking for help from traditional game-theoretic algorithms,\nwhich, in turn, show bright application promise combined with modern algorithms\nand boosting computing power. In this survey, we first introduce basic concepts\nand algorithms in single agent RL and multi-agent systems; then, we summarize\nthe related algorithms from three aspects. Solution concepts from game theory\ngive inspiration to algorithms which try to evaluate the agents or find better\nsolutions in multi-agent systems. Fictitious self-play becomes popular and has\na great impact on the algorithm of multi-agent reinforcement learning.\nCounterfactual regret minimization is an important tool to solve games with\nincomplete information, and has shown great strength when combined with deep\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:08:04 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 13:28:37 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 02:16:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lu", "Yunlong", ""], ["Yan", "Kai", ""]]}, {"id": "2001.06509", "submitter": "Dakuo Wang", "authors": "Jaimie Drozdal, Justin Weisz, Dakuo Wang, Gaurav Dass, Bingsheng Yao,\n  Changruo Zhao, Michael Muller, Lin Ju, Hui Su", "title": "Trust in AutoML: Exploring Information Needs for Establishing Trust in\n  Automated Machine Learning Systems", "comments": "IUI 2020", "journal-ref": null, "doi": "10.1145/3377325.3377501", "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore trust in a relatively new area of data science: Automated Machine\nLearning (AutoML). In AutoML, AI methods are used to generate and optimize\nmachine learning models by automatically engineering features, selecting\nmodels, and optimizing hyperparameters. In this paper, we seek to understand\nwhat kinds of information influence data scientists' trust in the models\nproduced by AutoML? We operationalize trust as a willingness to deploy a model\nproduced using automated methods. We report results from three studies --\nqualitative interviews, a controlled experiment, and a card-sorting task -- to\nunderstand the information needs of data scientists for establishing trust in\nAutoML systems. We find that including transparency features in an AutoML tool\nincreased user trust and understandability in the tool; and out of all proposed\nfeatures, model performance metrics and visualizations are the most important\ninformation to data scientists when establishing their trust with an AutoML\ntool.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 19:50:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Drozdal", "Jaimie", ""], ["Weisz", "Justin", ""], ["Wang", "Dakuo", ""], ["Dass", "Gaurav", ""], ["Yao", "Bingsheng", ""], ["Zhao", "Changruo", ""], ["Muller", "Michael", ""], ["Ju", "Lin", ""], ["Su", "Hui", ""]]}, {"id": "2001.06541", "submitter": "Imtiaz Ahmed", "authors": "Imtiaz Ahmed, Xia Ben Hu, Mithun P. Acharya and Yu Ding", "title": "Neighborhood Structure Assisted Non-negative Matrix Factorization and\n  its Application in Unsupervised Point-wise Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is considered as an important step for ensuring\ncompetitive performance in unsupervised learning such as anomaly detection.\nNon-negative matrix factorization (NMF) is a popular and widely used method to\naccomplish this goal. But NMF do not have the provision to include the\nneighborhood structure information and, as a result, may fail to provide\nsatisfactory performance in presence of nonlinear manifold structure. To\naddress that shortcoming, we propose to consider and incorporate the\nneighborhood structural similarity information within the NMF framework by\nmodeling the data through a minimum spanning tree. We label the resulting\nmethod as the neighborhood structure assisted NMF. We further devise both\noffline and online algorithmic versions of the proposed method. Empirical\ncomparisons using twenty benchmark datasets as well as an industrial dataset\nextracted from a hydropower plant demonstrate the superiority of the\nneighborhood structure assisted NMF and support our claim of merit. Looking\ncloser into the formulation and properties of the neighborhood structure\nassisted NMF with other recent, enhanced versions of NMF reveals that inclusion\nof the neighborhood structure information using MST plays a key role in\nattaining the enhanced performance in anomaly detection.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 21:43:20 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 20:40:48 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 03:04:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Ahmed", "Imtiaz", ""], ["Hu", "Xia Ben", ""], ["Acharya", "Mithun P.", ""], ["Ding", "Yu", ""]]}, {"id": "2001.06543", "submitter": "Katsiaryna Mirylenka", "authors": "Evgeny Krivosheev, Mattia Atzeni, Katsiaryna Mirylenka, Paolo Scotton,\n  Fabio Casati", "title": "Siamese Graph Neural Networks for Data Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration has been studied extensively for decades and approached from\ndifferent angles. However, this domain still remains largely rule-driven and\nlacks universal automation. Recent development in machine learning and in\nparticular deep learning has opened the way to more general and more efficient\nsolutions to data integration problems. In this work, we propose a general\napproach to modeling and integrating entities from structured data, such as\nrelational databases, as well as unstructured sources, such as free text from\nnews articles. Our approach is designed to explicitly model and leverage\nrelations between entities, thereby using all available information and\npreserving as much context as possible. This is achieved by combining siamese\nand graph neural networks to propagate information between connected entities\nand support high scalability. We evaluate our method on the task of integrating\ndata about business entities, and we demonstrate that it outperforms standard\nrule-based systems, as well as other deep learning approaches that do not use\ngraph-based representations.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 21:51:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Krivosheev", "Evgeny", ""], ["Atzeni", "Mattia", ""], ["Mirylenka", "Katsiaryna", ""], ["Scotton", "Paolo", ""], ["Casati", "Fabio", ""]]}, {"id": "2001.06545", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka and Benjamin Kaufman", "title": "Machine learning and AI-based approaches for bioactive ligand discovery\n  and GPCR-ligand recognition", "comments": "2nd submission fixed the mis-formatted quotation characters (i.e.,\n  \\^a)", "journal-ref": "Elsevier Methods, Volume 180, 1 August 2020, Pages 89-110", "doi": "10.1016/j.ymeth.2020.06.016", "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, machine learning and artificial intelligence applications\nhave received a significant boost in performance and attention in both academic\nresearch and industry. The success behind most of the recent state-of-the-art\nmethods can be attributed to the latest developments in deep learning. When\napplied to various scientific domains that are concerned with the processing of\nnon-tabular data, for example, image or text, deep learning has been shown to\noutperform not only conventional machine learning but also highly specialized\ntools developed by domain experts. This review aims to summarize AI-based\nresearch for GPCR bioactive ligand discovery with a particular focus on the\nmost recent achievements and research trends. To make this article accessible\nto a broad audience of computational scientists, we provide instructive\nexplanations of the underlying methodology, including overviews of the most\ncommonly used deep learning architectures and feature representations of\nmolecular data. We highlight the latest AI-based research that has led to the\nsuccessful discovery of GPCR bioactive ligands. However, an equal focus of this\nreview is on the discussion of machine learning-based technology that has been\napplied to ligand discovery in general and has the potential to pave the way\nfor successful GPCR bioactive ligand discovery in the future. This review\nconcludes with a brief outlook highlighting the recent research trends in deep\nlearning, such as active learning and semi-supervised learning, which have\ngreat potential for advancing bioactive ligand discovery.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:01:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 23:57:00 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 04:08:39 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Raschka", "Sebastian", ""], ["Kaufman", "Benjamin", ""]]}, {"id": "2001.06546", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Mario Diaz, and Flavio P. Calmon", "title": "Privacy Amplification of Iterative Algorithms via Contraction\n  Coefficients", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the framework of privacy amplification by iteration, recently\nproposed by Feldman et al., from an information-theoretic lens. We demonstrate\nthat differential privacy guarantees of iterative mappings can be determined by\na direct application of contraction coefficients derived from strong data\nprocessing inequalities for $f$-divergences. In particular, by generalizing the\nDobrushin's contraction coefficient for total variation distance to an\n$f$-divergence known as $E_{\\gamma}$-divergence, we derive tighter bounds on\nthe differential privacy parameters of the projected noisy stochastic gradient\ndescent algorithm with hidden intermediate updates.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:06:48 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2001.06570", "submitter": "Matej Ulicny", "authors": "Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot", "title": "Harmonic Convolutional Networks based on Discrete Cosine Transform", "comments": "arXiv admin note: substantial text overlap with arXiv:1812.03205", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) learn filters in order to capture local\ncorrelation patterns in feature space. We propose to learn these filters as\ncombinations of preset spectral filters defined by the Discrete Cosine\nTransform (DCT). Our proposed DCT-based harmonic blocks replace conventional\nconvolutional layers to produce partially or fully harmonic versions of new or\nexisting CNN architectures. Using DCT energy compaction properties, we\ndemonstrate how the harmonic networks can be efficiently compressed by\ntruncating high-frequency information in harmonic blocks thanks to the\nredundancies in the spectral domain. We report extensive experimental\nvalidation demonstrating benefits of the introduction of harmonic blocks into\nstate-of-the-art CNN models in image classification, object detection and\nsemantic segmentation applications.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 01:13:20 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 16:31:40 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Ulicny", "Matej", ""], ["Krylov", "Vladimir A.", ""], ["Dahyot", "Rozenn", ""]]}, {"id": "2001.06576", "submitter": "Mengyuan Chen", "authors": "Mengyuan Chen, Jiang Zhang, Zhang Zhang, Lun Du, Qiao Hu, Shuo Wang,\n  Jiaqi Zhu", "title": "Inference for Network Structure and Dynamics from Time Series Data via\n  Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network structures in various backgrounds play important roles in social,\ntechnological, and biological systems. However, the observable network\nstructures in real cases are often incomplete or unavailable due to measurement\nerrors or private protection issues. Therefore, inferring the complete network\nstructure is useful for understanding complex systems. The existing studies\nhave not fully solved the problem of inferring network structure with partial\nor no information about connections or nodes. In this paper, we tackle the\nproblem by utilizing time series data generated by network dynamics. We regard\nthe network inference problem based on dynamical time series data as a problem\nof minimizing errors for predicting future states and proposed a novel\ndata-driven deep learning model called Gumbel Graph Network (GGN) to solve the\ntwo kinds of network inference problems: Network Reconstruction and Network\nCompletion. For the network reconstruction problem, the GGN framework includes\ntwo modules: the dynamics learner and the network generator. For the network\ncompletion problem, GGN adds a new module called the States Learner to infer\nmissing parts of the network. We carried out experiments on discrete and\ncontinuous time series data. The experiments show that our method can\nreconstruct up to 100% network structure on the network reconstruction task.\nWhile the model can also infer the unknown parts of the structure with up to\n90% accuracy when some nodes are missing. And the accuracy decays with the\nincrease of the fractions of missing nodes. Our framework may have wide\napplication areas where the network structure is hard to obtained and the time\nseries data is rich.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 02:05:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chen", "Mengyuan", ""], ["Zhang", "Jiang", ""], ["Zhang", "Zhang", ""], ["Du", "Lun", ""], ["Hu", "Qiao", ""], ["Wang", "Shuo", ""], ["Zhu", "Jiaqi", ""]]}, {"id": "2001.06587", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Saayan Mitra, Somdeb Sarkhel, Jason Xie, Gang Wu,\n  Viswanathan Swaminathan", "title": "Scalable Bid Landscape Forecasting in Real-time Bidding", "comments": "Appeared in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In programmatic advertising, ad slots are usually sold using second-price\n(SP) auctions in real-time. The highest bidding advertiser wins but pays only\nthe second-highest bid (known as the winning price). In SP, for a single item,\nthe dominant strategy of each bidder is to bid the true value from the bidder's\nperspective. However, in a practical setting, with budget constraints, bidding\nthe true value is a sub-optimal strategy. Hence, to devise an optimal bidding\nstrategy, it is of utmost importance to learn the winning price distribution\naccurately. Moreover, a demand-side platform (DSP), which bids on behalf of\nadvertisers, observes the winning price if it wins the auction. For losing\nauctions, DSPs can only treat its bidding price as the lower bound for the\nunknown winning price. In literature, typically censored regression is used to\nmodel such partially observed data. A common assumption in censored regression\nis that the winning price is drawn from a fixed variance (homoscedastic)\nuni-modal distribution (most often Gaussian). However, in reality, these\nassumptions are often violated. We relax these assumptions and propose a\nheteroscedastic fully parametric censored regression approach, as well as a\nmixture density censored network. Our approach not only generalizes censored\nregression but also provides flexibility to model arbitrarily distributed\nreal-world data. Experimental evaluation on the publicly available dataset for\nwinning price estimation demonstrates the effectiveness of our method.\nFurthermore, we evaluate our algorithm on one of the largest demand-side\nplatforms and significant improvement has been achieved in comparison with the\nbaseline solutions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:20:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ghosh", "Aritra", ""], ["Mitra", "Saayan", ""], ["Sarkhel", "Somdeb", ""], ["Xie", "Jason", ""], ["Wu", "Gang", ""], ["Swaminathan", "Viswanathan", ""]]}, {"id": "2001.06588", "submitter": "Pooyan Jamshidi", "authors": "Md Shahriar Iqbal, Jianhai Su, Lars Kotthoff, Pooyan Jamshidi", "title": "FlexiBO: Cost-Aware Multi-Objective Optimization of Deep Neural Networks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges in designing machine learning systems is to\ndetermine the right balance amongst several objectives, which also oftentimes\nare incommensurable and conflicting. For example, when designing deep neural\nnetworks (DNNs), one often has to trade-off between multiple objectives, such\nas accuracy, energy consumption, and inference time. Typically, there is no\nsingle configuration that performs equally well for all objectives.\nConsequently, one is interested in identifying Pareto-optimal designs. Although\ndifferent multi-objective optimization algorithms have been developed to\nidentify Pareto-optimal configurations, state-of-the-art multi-objective\noptimization methods do not consider the different evaluation costs attending\nthe objectives under consideration. This is particularly important for\noptimizing DNNs: the cost arising on account of assessing the accuracy of DNNs\nis orders of magnitude higher than that of measuring the energy consumption of\npre-trained DNNs. We propose FlexiBO, a flexible Bayesian optimization method,\nto address this issue. We formulate a new acquisition function based on the\nimprovement of the Pareto hyper-volume weighted by the measurement cost of each\nobjective. Our acquisition function selects the next sample and objective that\nprovides maximum information gain per unit of cost. We evaluated FlexiBO on 7\nstate-of-the-art DNNs for object detection, natural language processing, and\nspeech recognition. Our results indicate that, when compared to other\nstate-of-the-art methods across the 7 architectures we tested, the Pareto front\nobtained using FlexiBO has, on average, a 28.44% higher contribution to the\ntrue Pareto front and achieves 25.64% better diversity.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:26:03 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Iqbal", "Md Shahriar", ""], ["Su", "Jianhai", ""], ["Kotthoff", "Lars", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2001.06591", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Iman Soltani Bozchalooi and Eric Darve", "title": "Regularized Cycle Consistent Generative Adversarial Network for Anomaly\n  Detection", "comments": "the 24th European Conference on Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate algorithms for anomaly detection. Previous\nanomaly detection methods focus on modeling the distribution of non-anomalous\ndata provided during training. However, this does not necessarily ensure the\ncorrect detection of anomalous data. We propose a new Regularized Cycle\nConsistent Generative Adversarial Network (RCGAN) in which deep neural networks\nare adversarially trained to better recognize anomalous samples. This approach\nis based on leveraging a penalty distribution with a new definition of the loss\nfunction and novel use of discriminator networks. It is based on a solid\nmathematical foundation, and proofs show that our approach has stronger\nguarantees for detecting anomalous examples compared to the current\nstate-of-the-art. Experimental results on both real-world and synthetic data\nshow that our model leads to significant and consistent improvements on\nprevious anomaly detection benchmarks. Notably, RCGAN improves on the\nstate-of-the-art on the KDDCUP, Arrhythmia, Thyroid, Musk and CIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:35:05 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 20:35:24 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Yang", "Ziyi", ""], ["Bozchalooi", "Iman Soltani", ""], ["Darve", "Eric", ""]]}, {"id": "2001.06597", "submitter": "Xiaofeng Yang", "authors": "Tonghe Wang, Yang Lei, Yabo Fu, Walter J. Curran, Tian Liu, Xiaofeng\n  Yang", "title": "Machine Learning in Quantitative PET Imaging", "comments": "25 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviewed the machine learning-based studies for quantitative\npositron emission tomography (PET). Specifically, we summarized the recent\ndevelopments of machine learning-based methods in PET attenuation correction\nand low-count PET reconstruction by listing and comparing the proposed methods,\nstudy designs and reported performances of the current published studies with\nbrief discussion on representative studies. The contributions and challenges\namong the reviewed studies were summarized and highlighted in the discussion\npart followed by.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 04:35:59 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Tonghe", ""], ["Lei", "Yang", ""], ["Fu", "Yabo", ""], ["Curran", "Walter J.", ""], ["Liu", "Tian", ""], ["Yang", "Xiaofeng", ""]]}, {"id": "2001.06626", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao,\n  Dawei Yin", "title": "Adaptive Parameterization for Neural Dialogue Generation", "comments": "Published as a long paper in EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1188", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversation systems generate responses based on the\nsequence-to-sequence (SEQ2SEQ) paradigm. Typically, the model is equipped with\na single set of learned parameters to generate responses for given input\ncontexts. When confronting diverse conversations, its adaptability is rather\nlimited and the model is hence prone to generate generic responses. In this\nwork, we propose an {\\bf Ada}ptive {\\bf N}eural {\\bf D}ialogue generation\nmodel, \\textsc{AdaND}, which manages various conversations with\nconversation-specific parameterization. For each conversation, the model\ngenerates parameters of the encoder-decoder by referring to the input context.\nIn particular, we propose two adaptive parameterization mechanisms: a\ncontext-aware and a topic-aware parameterization mechanism. The context-aware\nparameterization directly generates the parameters by capturing local semantics\nof the given context. The topic-aware parameterization enables parameter\nsharing among conversations with similar topics by first inferring the latent\ntopics of the given context and then generating the parameters with respect to\nthe distributional topics. Extensive experiments conducted on a large-scale\nreal-world conversational dataset show that our model achieves superior\nperformance in terms of both quantitative metrics and human evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 08:18:19 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Zhang", "Cheng", ""], ["Song", "Yonghao", ""], ["Zhao", "Xiaofang", ""], ["Yin", "Dawei", ""]]}, {"id": "2001.06627", "submitter": "Samaneh Hoseini Semnani", "authors": "Samaneh Hosseini Semnani, Hugh Liu, Michael Everett, Anton de Ruiter,\n  Jonathan P. How", "title": "Multi-agent Motion Planning for Dense and Dynamic Environments via Deep\n  Reinforcement Learning", "comments": "IEEE Robotics and Automation Letters (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a hybrid algorithm of deep reinforcement learning (RL)\nand Force-based motion planning (FMP) to solve distributed motion planning\nproblem in dense and dynamic environments. Individually, RL and FMP algorithms\neach have their own limitations. FMP is not able to produce time-optimal paths\nand existing RL solutions are not able to produce collision-free paths in dense\nenvironments. Therefore, we first tried improving the performance of recent RL\napproaches by introducing a new reward function that not only eliminates the\nrequirement of a pre supervised learning (SL) step but also decreases the\nchance of collision in crowded environments. That improved things, but there\nwere still a lot of failure cases. So, we developed a hybrid approach to\nleverage the simpler FMP approach in stuck, simple and high-risk cases, and\ncontinue using RL for normal cases in which FMP can't produce optimal path.\nAlso, we extend GA3C-CADRL algorithm to 3D environment. Simulation results show\nthat the proposed algorithm outperforms both deep RL and FMP algorithms and\nproduces up to 50% more successful scenarios than deep RL and up to 75% less\nextra time to reach goal than FMP.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 08:24:40 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Semnani", "Samaneh Hosseini", ""], ["Liu", "Hugh", ""], ["Everett", "Michael", ""], ["de Ruiter", "Anton", ""], ["How", "Jonathan P.", ""]]}, {"id": "2001.06631", "submitter": "Kangfei Zhao", "authors": "Kangfei Zhao, Yu Rong, Jeffrey Xu Yu, Junzhou Huang, Hao Zhang", "title": "Graph Ordering: Towards the Optimal by Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has achieved a remarkable success in many\ngraph-based applications, such as node classification, link prediction, and\ncommunity detection. These models are usually designed to preserve the vertex\ninformation at different granularity and reduce the problems in discrete space\nto some machine learning tasks in continuous space. However, regardless of the\nfruitful progress, for some kind of graph applications, such as graph\ncompression and edge partition, it is very hard to reduce them to some graph\nrepresentation learning tasks. Moreover, these problems are closely related to\nreformulating a global layout for a specific graph, which is an important\nNP-hard combinatorial optimization problem: graph ordering. In this paper, we\npropose to attack the graph ordering problem behind such applications by a\nnovel learning approach. Distinguished from greedy algorithms based on\npredefined heuristics, we propose a neural network model: Deep Order Network\n(DON) to capture the hidden locality structure from partial vertex order sets.\nSupervised by sampled partial order, DON has the ability to infer unseen\ncombinations. Furthermore, to alleviate the combinatorial explosion in the\ntraining space of DON and make the efficient partial vertex order sampling , we\nemploy a reinforcement learning model: the Policy Network, to adjust the\npartial order sampling probabilities during the training phase of DON\nautomatically. To this end, the Policy Network can improve the training\nefficiency and guide DON to evolve towards a more effective model\nautomatically. Comprehensive experiments on both synthetic and real data\nvalidate that DON-RL outperforms the current state-of-the-art heuristic\nalgorithm consistently. Two case studies on graph compression and edge\npartitioning demonstrate the potential power of DON-RL in real applications.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 09:14:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhao", "Kangfei", ""], ["Rong", "Yu", ""], ["Yu", "Jeffrey Xu", ""], ["Huang", "Junzhou", ""], ["Zhang", "Hao", ""]]}, {"id": "2001.06640", "submitter": "Shuo Wang", "authors": "Shuo Wang, Tianle Chen, Shangyu Chen, Carsten Rudolph, Surya Nepal,\n  Marthie Grobler", "title": "OIAD: One-for-all Image Anomaly Detection with Disentanglement Learning", "comments": "arXiv admin note: text overlap with arXiv:1802.05983,\n  arXiv:1909.02755, arXiv:1804.03599 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to recognize samples with anomalous and unusual\npatterns with respect to a set of normal data. This is significant for numerous\ndomain applications, such as industrial inspection, medical imaging, and\nsecurity enforcement. There are two key research challenges associated with\nexisting anomaly detection approaches: (1) many approaches perform well on\nlow-dimensional problems however the performance on high-dimensional instances,\nsuch as images, is limited; (2) many approaches often rely on traditional\nsupervised approaches and manual engineering of features, while the topic has\nnot been fully explored yet using modern deep learning approaches, even when\nthe well-label samples are limited. In this paper, we propose a One-for-all\nImage Anomaly Detection system (OIAD) based on disentangled learning using only\nclean samples. Our key insight is that the impact of small perturbation on the\nlatent representation can be bounded for normal samples while anomaly images\nare usually outside such bounded intervals, referred to as structure\nconsistency. We implement this idea and evaluate its performance for anomaly\ndetection. Our experiments with three datasets show that OIAD can detect over\n$90\\%$ of anomalies while maintaining a low false alarm rate. It can also\ndetect suspicious samples from samples labeled as clean, coincided with what\nhumans would deem unusual.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 09:57:37 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 09:00:14 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Tianle", ""], ["Chen", "Shangyu", ""], ["Rudolph", "Carsten", ""], ["Nepal", "Surya", ""], ["Grobler", "Marthie", ""]]}, {"id": "2001.06657", "submitter": "Vinay Verma Kumar", "authors": "Anubha Pandey, Ashish Mishra, Vinay Kumar Verma, Anurag Mittal and\n  Hema A. Murthy", "title": "Stacked Adversarial Network for Zero-Shot Sketch based Image Retrieval", "comments": "Accepted in WACV'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional approaches to Sketch-Based Image Retrieval (SBIR) assume that\nthe data of all the classes are available during training. The assumption may\nnot always be practical since the data of a few classes may be unavailable, or\nthe classes may not appear at the time of training. Zero-Shot Sketch-Based\nImage Retrieval (ZS-SBIR) relaxes this constraint and allows the algorithm to\nhandle previously unseen classes during the test. This paper proposes a\ngenerative approach based on the Stacked Adversarial Network (SAN) and the\nadvantage of Siamese Network (SN) for ZS-SBIR. While SAN generates a\nhigh-quality sample, SN learns a better distance metric compared to that of the\nnearest neighbor search. The capability of the generative model to synthesize\nimage features based on the sketch reduces the SBIR problem to that of an\nimage-to-image retrieval problem. We evaluate the efficacy of our proposed\napproach on TU-Berlin, and Sketchy database in both standard ZSL and\ngeneralized ZSL setting. The proposed method yields a significant improvement\nin standard ZSL as well as in a more challenging generalized ZSL setting (GZSL)\nfor SBIR.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 12:18:28 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Pandey", "Anubha", ""], ["Mishra", "Ashish", ""], ["Verma", "Vinay Kumar", ""], ["Mittal", "Anurag", ""], ["Murthy", "Hema A.", ""]]}, {"id": "2001.06665", "submitter": "Ning Yang", "authors": "Yuhui Zhao, Ning Yang, Tao Lin, Philip S. Yu", "title": "Deep Collaborative Embedding for information cascade prediction", "comments": null, "journal-ref": "Knowledge-Based Systems, 2020, 105502", "doi": "10.1016/j.knosys.2020.105502", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, information cascade prediction has attracted increasing interest\nfrom researchers, but it is far from being well solved partly due to the three\ndefects of the existing works. First, the existing works often assume an\nunderlying information diffusion model, which is impractical in real world due\nto the complexity of information diffusion. Second, the existing works often\nignore the prediction of the infection order, which also plays an important\nrole in social network analysis. At last, the existing works often depend on\nthe requirement of underlying diffusion networks which are likely unobservable\nin practice. In this paper, we aim at the prediction of both node infection and\ninfection order without requirement of the knowledge about the underlying\ndiffusion mechanism and the diffusion network, where the challenges are\ntwo-fold. The first is what cascading characteristics of nodes should be\ncaptured and how to capture them, and the second is that how to model the\nnon-linear features of nodes in information cascades. To address these\nchallenges, we propose a novel model called Deep Collaborative Embedding (DCE)\nfor information cascade prediction, which can capture not only the node\nstructural property but also two kinds of node cascading characteristics. We\npropose an auto-encoder based collaborative embedding framework to learn the\nnode embeddings with cascade collaboration and node collaboration, in which way\nthe non-linearity of information cascades can be effectively captured. The\nresults of extensive experiments conducted on real-world datasets verify the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:32:18 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhao", "Yuhui", ""], ["Yang", "Ning", ""], ["Lin", "Tao", ""], ["Yu", "Philip S.", ""]]}, {"id": "2001.06668", "submitter": "Douglas Blank", "authors": "Douglas S. Blank", "title": "Learning to See Analogies: A Connectionist Exploration", "comments": "191 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This dissertation explores the integration of learning and analogy-making\nthrough the development of a computer program, called Analogator, that learns\nto make analogies by example. By \"seeing\" many different analogy problems,\nalong with possible solutions, Analogator gradually develops an ability to make\nnew analogies. That is, it learns to make analogies by analogy. This approach\nstands in contrast to most existing research on analogy-making, in which\ntypically the a priori existence of analogical mechanisms within a model is\nassumed. The present research extends standard connectionist methodologies by\ndeveloping a specialized associative training procedure for a recurrent network\narchitecture. The network is trained to divide input scenes (or situations)\ninto appropriate figure and ground components. Seeing one scene in terms of a\nparticular figure and ground provides the context for seeing another in an\nanalogous fashion. After training, the model is able to make new analogies\nbetween novel situations. Analogator has much in common with lower-level\nperceptual models of categorization and recognition; it thus serves as a\nunifying framework encompassing both high-level analogical learning and\nlow-level perception. This approach is compared and contrasted with other\ncomputational models of analogy-making. The model's training and generalization\nperformance is examined, and limitations are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:06:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Blank", "Douglas S.", ""]]}, {"id": "2001.06679", "submitter": "Zixiang Ding", "authors": "Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao, Zhiquan Sun and\n  C.L. Philip Chen", "title": "BNAS:An Efficient Neural Architecture Search Approach Using Broad\n  Scalable Architecture", "comments": "15 pages, 12 figures, 5 tables", "journal-ref": null, "doi": "10.1109/TNNLS.2021.3067028", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Broad Neural Architecture Search (BNAS) where we\nelaborately design broad scalable architecture dubbed Broad Convolutional\nNeural Network (BCNN) to solve the above issue. On one hand, the proposed broad\nscalable architecture has fast training speed due to its shallow topology.\nMoreover, we also adopt reinforcement learning and parameter sharing used in\nENAS as the optimization strategy of BNAS. Hence, the proposed approach can\nachieve higher search efficiency. On the other hand, the broad scalable\narchitecture extracts multi-scale features and enhancement representations, and\nfeeds them into global average pooling layer to yield more reasonable and\ncomprehensive representations. Therefore, the performance of broad scalable\narchitecture can be promised. In particular, we also develop two variants for\nBNAS who modify the topology of BCNN. In order to verify the effectiveness of\nBNAS, several experiments are performed and experimental results show that 1)\nBNAS delivers 0.19 days which is 2.37x less expensive than ENAS who ranks the\nbest in reinforcement learning-based NAS approaches, 2) compared with\nsmall-size (0.5 millions parameters) and medium-size (1.1 millions parameters)\nmodels, the architecture learned by BNAS obtains state-of-the-art performance\n(3.58% and 3.24% test error) on CIFAR-10, 3) the learned architecture achieves\n25.3% top-1 error on ImageNet just using 3.9 millions parameters.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:07:55 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 11:04:01 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 15:06:12 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 07:09:50 GMT"}, {"version": "v5", "created": "Wed, 20 Jan 2021 07:09:11 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ding", "Zixiang", ""], ["Chen", "Yaran", ""], ["Li", "Nannan", ""], ["Zhao", "Dongbin", ""], ["Sun", "Zhiquan", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "2001.06684", "submitter": "Dakuo Wang", "authors": "Amy X. Zhang, Michael Muller, Dakuo Wang", "title": "How do Data Science Workers Collaborate? Roles, Workflows, and Tools", "comments": "CSCW'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the prominence of data science within organizations has given rise to\nteams of data science workers collaborating on extracting insights from data,\nas opposed to individual data scientists working alone. However, we still lack\na deep understanding of how data science workers collaborate in practice. In\nthis work, we conducted an online survey with 183 participants who work in\nvarious aspects of data science. We focused on their reported interactions with\neach other (e.g., managers with engineers) and with different tools (e.g.,\nJupyter Notebook). We found that data science teams are extremely collaborative\nand work with a variety of stakeholders and tools during the six common steps\nof a data science workflow (e.g., clean data and train model). We also found\nthat the collaborative practices workers employ, such as documentation, vary\naccording to the kinds of tools they use. Based on these findings, we discuss\ndesign implications for supporting data science team collaborations and future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:11:56 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 08:38:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 16:38:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhang", "Amy X.", ""], ["Muller", "Michael", ""], ["Wang", "Dakuo", ""]]}, {"id": "2001.06691", "submitter": "Christian K\\\"astner", "authors": "Christian K\\\"astner, Eunsuk Kang", "title": "Teaching Software Engineering for AI-Enabled Systems", "comments": "to be published in ICSE-SEET 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software engineers have significant expertise to offer when building\nintelligent systems, drawing on decades of experience and methods for building\nsystems that are scalable, responsive and robust, even when built on unreliable\ncomponents. Systems with artificial-intelligence or machine-learning (ML)\ncomponents raise new challenges and require careful engineering. We designed a\nnew course to teach software-engineering skills to students with a background\nin ML. We specifically go beyond traditional ML courses that teach modeling\ntechniques under artificial conditions and focus, in lecture and assignments,\non realism with large and changing datasets, robust and evolvable\ninfrastructure, and purposeful requirements engineering that considers ethics\nand fairness as well. We describe the course and our infrastructure and share\nexperience and all material from teaching the course for the first time.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:24:17 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["K\u00e4stner", "Christian", ""], ["Kang", "Eunsuk", ""]]}, {"id": "2001.06693", "submitter": "Vijay Arya", "authors": "Karan Dabas, Nishtha Madan, Vijay Arya, Sameep Mehta, Gautam Singh,\n  Tanmoy Chakraborty", "title": "Fair Transfer of Multiple Style Attributes in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To preserve anonymity and obfuscate their identity on online platforms users\nmay morph their text and portray themselves as a different gender or\ndemographic. Similarly, a chatbot may need to customize its communication style\nto improve engagement with its audience. This manner of changing the style of\nwritten text has gained significant attention in recent years. Yet these past\nresearch works largely cater to the transfer of single style attributes. The\ndisadvantage of focusing on a single style alone is that this often results in\ntarget text where other existing style attributes behave unpredictably or are\nunfairly dominated by the new style. To counteract this behavior, it would be\nnice to have a style transfer mechanism that can transfer or control multiple\nstyles simultaneously and fairly. Through such an approach, one could obtain\nobfuscated or written text incorporated with a desired degree of multiple soft\nstyles such as female-quality, politeness, or formalness.\n  In this work, we demonstrate that the transfer of multiple styles cannot be\nachieved by sequentially performing multiple single-style transfers. This is\nbecause each single style-transfer step often reverses or dominates over the\nstyle incorporated by a previous transfer step. We then propose a neural\nnetwork architecture for fairly transferring multiple style attributes in a\ngiven text. We test our architecture on the Yelp data set to demonstrate our\nsuperior performance as compared to existing one-style transfer steps performed\nin a sequence.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 15:38:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Dabas", "Karan", ""], ["Madan", "Nishtha", ""], ["Arya", "Vijay", ""], ["Mehta", "Sameep", ""], ["Singh", "Gautam", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2001.06699", "submitter": "Frank E. Curtis", "authors": "Frank E. Curtis and Katya Scheinberg", "title": "Adaptive Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization lies at the heart of machine learning and signal processing.\nContemporary approaches based on the stochastic gradient method are\nnon-adaptive in the sense that their implementation employs prescribed\nparameter values that need to be tuned for each application. This article\nsummarizes recent research and motivates future work on adaptive stochastic\noptimization methods, which have the potential to offer significant\ncomputational savings when training large-scale systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 16:30:19 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Curtis", "Frank E.", ""], ["Scheinberg", "Katya", ""]]}, {"id": "2001.06720", "submitter": "Marek Smieja", "authors": "Marek \\'Smieja, {\\L}ukasz Struski, M\\'ario A. T. Figueiredo", "title": "A Classification-Based Approach to Semi-Supervised Clustering with\n  Pairwise Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a neural network framework for semi-supervised\nclustering (SSC) with pairwise (must-link or cannot-link) constraints. In\ncontrast to existing approaches, we decompose SSC into two simpler\nclassification tasks/stages: the first stage uses a pair of Siamese neural\nnetworks to label the unlabeled pairs of points as must-link or cannot-link;\nthe second stage uses the fully pairwise-labeled dataset produced by the first\nstage in a supervised neural-network-based clustering method. The proposed\napproach, S3C2 (Semi-Supervised Siamese Classifiers for Clustering), is\nmotivated by the observation that binary classification (such as assigning\npairwise relations) is usually easier than multi-class clustering with partial\nsupervision. On the other hand, being classification-based, our method solves\nonly well-defined classification problems, rather than less well specified\nclustering tasks. Extensive experiments on various datasets demonstrate the\nhigh performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 20:13:07 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["\u015amieja", "Marek", ""], ["Struski", "\u0141ukasz", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2001.06725", "submitter": "Juan Vargas", "authors": "Juan Vargas, Lazar Andjelic, Amir Barati Farimani", "title": "Effects of sparse rewards of different magnitudes in the speed of\n  learning of model-based actor critic methods", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actor critic methods with sparse rewards in model-based deep reinforcement\nlearning typically require a deterministic binary reward function that reflects\nonly two possible outcomes: if, for each step, the goal has been achieved or\nnot. Our hypothesis is that we can influence an agent to learn faster by\napplying an external environmental pressure during training, which adversely\nimpacts its ability to get higher rewards. As such, we deviate from the\nclassical paradigm of sparse rewards and add a uniformly sampled reward value\nto the baseline reward to show that (1) sample efficiency of the training\nprocess can be correlated to the adversity experienced during training, (2) it\nis possible to achieve higher performance in less time and with less resources,\n(3) we can reduce the performance variability experienced seed over seed, (4)\nthere is a maximum point after which more pressure will not generate better\nresults, and (5) that random positive incentives have an adverse effect when\nusing a negative reward strategy, making an agent under those conditions learn\npoorly and more slowly. These results have been shown to be valid for Deep\nDeterministic Policy Gradients using Hindsight Experience Replay in a well\nknown Mujoco environment, but we argue that they could be generalized to other\nmethods and environments as well.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 20:52:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Vargas", "Juan", ""], ["Andjelic", "Lazar", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2001.06728", "submitter": "Kevin Maik Jablonka", "authors": "Kevin Maik Jablonka, Daniele Ongari, Seyed Mohamad Moosavi, Berend\n  Smit", "title": "Big-Data Science in Porous Materials: Materials Genomics and Machine\n  Learning", "comments": "Editorial changes (typos fixed, minor adjustments to figures)", "journal-ref": null, "doi": "10.1021/acs.chemrev.0c00004", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By combining metal nodes with organic linkers we can potentially synthesize\nmillions of possible metal organic frameworks (MOFs). At present, we have\nlibraries of over ten thousand synthesized materials and millions of in-silico\npredicted materials. The fact that we have so many materials opens many\nexciting avenues to tailor make a material that is optimal for a given\napplication. However, from an experimental and computational point of view we\nsimply have too many materials to screen using brute-force techniques. In this\nreview, we show that having so many materials allows us to use big-data methods\nas a powerful technique to study these materials and to discover complex\ncorrelations. The first part of the review gives an introduction to the\nprinciples of big-data science. We emphasize the importance of data collection,\nmethods to augment small data sets, how to select appropriate training sets. An\nimportant part of this review are the different approaches that are used to\nrepresent these materials in feature space. The review also includes a general\noverview of the different ML techniques, but as most applications in porous\nmaterials use supervised ML our review is focused on the different approaches\nfor supervised ML. In particular, we review the different method to optimize\nthe ML process and how to quantify the performance of the different methods. In\nthe second part, we review how the different approaches of ML have been applied\nto porous materials. In particular, we discuss applications in the field of gas\nstorage and separation, the stability of these materials, their electronic\nproperties, and their synthesis. The range of topics illustrates the large\nvariety of topics that can be studied with big-data science. Given the\nincreasing interest of the scientific community in ML, we expect this list to\nrapidly expand in the coming years.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 21:01:07 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 00:15:05 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 20:05:47 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Jablonka", "Kevin Maik", ""], ["Ongari", "Daniele", ""], ["Moosavi", "Seyed Mohamad", ""], ["Smit", "Berend", ""]]}, {"id": "2001.06744", "submitter": "Borja S\\'anchez-L\\'opez", "authors": "Borja S\\'anchez-L\\'opez and Jesus Cerquides", "title": "Dual Stochastic Natural Gradient Descent and convergence of interior\n  half-space gradient approximations", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multinomial logistic regression (MLR) model is widely used in statistics\nand machine learning. Stochastic gradient descent (SGD) is the most common\napproach for determining the parameters of a MLR model in big data scenarios.\nHowever, SGD has slow sub-linear rates of convergence. A way to improve these\nrates of convergence is to use manifold optimization. Along this line,\nstochastic natural gradient descent (SNGD), proposed by Amari, was proven to be\nFisher efficient when it converged. However, SNGD is not guaranteed to converge\nand it is computationally too expensive for MLR models with a large number of\nparameters.\n  Here, we propose a stochastic optimization method for MLR based on manifold\noptimization concepts which (i) has per-iteration computational complexity is\nlinear in the number of parameters and (ii) can be proven to converge.\n  To achieve (i) we establish that the family of joint distributions for MLR is\na dually flat manifold and we use that to speed up calculations.\nS\\'anchez-L\\'opez and Cerquides have recently introduced convergent stochastic\nnatural gradient descent (CSNGD), a variant of SNGD whose convergence is\nguaranteed. To obtain (ii) our algorithm uses the fundamental idea from CSNGD,\nthus relying on an independent sequence to build a bounded approximation of the\nnatural gradient. We call the resulting algorithm dual stochastic natural\ngradient descent (DNSGD). By generalizing a result from Sunehag et al., we\nprove that DSNGD converges. Furthermore, we prove that the computational\ncomplexity of DSNGD iterations are linear on the number of variables of the\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 00:53:49 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 16:45:51 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["S\u00e1nchez-L\u00f3pez", "Borja", ""], ["Cerquides", "Jesus", ""]]}, {"id": "2001.06776", "submitter": "Soumyabrata Pal", "authors": "Akshay Krishnamurthy, Arya Mazumdar, Andrew McGregor, Soumyabrata Pal", "title": "Algebraic and Analytic Approaches for Parameter Learning in Mixture\n  Models", "comments": "22 pages, Accepted at Algorithmic Learning Theory (ALT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two different approaches for parameter learning in several mixture\nmodels in one dimension. Our first approach uses complex-analytic methods and\napplies to Gaussian mixtures with shared variance, binomial mixtures with\nshared success probability, and Poisson mixtures, among others. An example\nresult is that $\\exp(O(N^{1/3}))$ samples suffice to exactly learn a mixture of\n$k<N$ Poisson distributions, each with integral rate parameters bounded by $N$.\nOur second approach uses algebraic and combinatorial tools and applies to\nbinomial mixtures with shared trial parameter $N$ and differing success\nparameters, as well as to mixtures of geometric distributions. Again, as an\nexample, for binomial mixtures with $k$ components and success parameters\ndiscretized to resolution $\\epsilon$, $O(k^2(N/\\epsilon)^{8/\\sqrt{\\epsilon}})$\nsamples suffice to exactly recover the parameters. For some of these\ndistributions, our results represent the first guarantees for parameter\nestimation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 05:10:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Mazumdar", "Arya", ""], ["McGregor", "Andrew", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2001.06782", "submitter": "Tianhe Yu", "authors": "Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol\n  Hausman, Chelsea Finn", "title": "Gradient Surgery for Multi-Task Learning", "comments": "NeurIPS 2020. Code is available at\n  https://github.com/tianheyu927/PCGrad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning and deep reinforcement learning (RL) systems have\ndemonstrated impressive results in domains such as image classification, game\nplaying, and robotic control, data efficiency remains a major challenge.\nMulti-task learning has emerged as a promising approach for sharing structure\nacross multiple tasks to enable more efficient learning. However, the\nmulti-task setting presents a number of optimization challenges, making it\ndifficult to realize large efficiency gains compared to learning tasks\nindependently. The reasons why multi-task learning is so challenging compared\nto single-task learning are not fully understood. In this work, we identify a\nset of three conditions of the multi-task optimization landscape that cause\ndetrimental gradient interference, and develop a simple yet general approach\nfor avoiding such interference between task gradients. We propose a form of\ngradient surgery that projects a task's gradient onto the normal plane of the\ngradient of any other task that has a conflicting gradient. On a series of\nchallenging multi-task supervised and multi-task RL problems, this approach\nleads to substantial gains in efficiency and performance. Further, it is\nmodel-agnostic and can be combined with previously-proposed multi-task\narchitectures for enhanced performance.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 06:33:47 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 23:41:08 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 06:07:19 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 00:35:46 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yu", "Tianhe", ""], ["Kumar", "Saurabh", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""]]}, {"id": "2001.06793", "submitter": "Matthew Cockcroft", "authors": "Matthew Cockcroft, Shahil Mawjee, Steven James, Pravesh Ranchod", "title": "Learning Options from Demonstration using Skill Segmentation", "comments": "To be published in SAUPEC/RobMech/PRASA 2020. Consists of 6 pages, 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning options from segmented demonstration\ntrajectories. The trajectories are first segmented into skills using\nnonparametric Bayesian clustering and a reward function for each segment is\nthen learned using inverse reinforcement learning. From this, a set of inferred\ntrajectories for the demonstration are generated. Option initiation sets and\ntermination conditions are learned from these trajectories using the one-class\nsupport vector machine clustering algorithm. We demonstrate our method in the\nfour rooms domain, where an agent is able to autonomously discover usable\noptions from human demonstration. Our results show that these inferred options\ncan then be used to improve learning and planning.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 09:29:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Cockcroft", "Matthew", ""], ["Mawjee", "Shahil", ""], ["James", "Steven", ""], ["Ranchod", "Pravesh", ""]]}, {"id": "2001.06808", "submitter": "Daichi Nishio", "authors": "Daichi Nishio, Daiki Kuyoshi, Toi Tsuneda and Satoshi Yamane", "title": "Discriminator Soft Actor Critic without Extrinsic Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is difficult to be able to imitate well in unknown states from a small\namount of expert data and sampling data. Supervised learning methods such as\nBehavioral Cloning do not require sampling data, but usually suffer from\ndistribution shift. The methods based on reinforcement learning, such as\ninverse reinforcement learning and generative adversarial imitation learning\n(GAIL), can learn from only a few expert data. However, they often need to\ninteract with the environment. Soft Q imitation learning addressed the\nproblems, and it was shown that it could learn efficiently by combining\nBehavioral Cloning and soft Q-learning with constant rewards. In order to make\nthis algorithm more robust to distribution shift, we propose Discriminator Soft\nActor Critic (DSAC). It uses a reward function based on adversarial inverse\nreinforcement learning instead of constant rewards. We evaluated it on PyBullet\nenvironments with only four expert trajectories.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 10:45:35 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 15:39:22 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 12:39:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Nishio", "Daichi", ""], ["Kuyoshi", "Daiki", ""], ["Tsuneda", "Toi", ""], ["Yamane", "Satoshi", ""]]}, {"id": "2001.06814", "submitter": "Thanh Nguyen Tang", "authors": "Thanh Tang Nguyen, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh", "title": "Distributionally Robust Bayesian Quadrature Optimization", "comments": "AISTATS2020", "journal-ref": "AISTATS2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian quadrature optimization (BQO) maximizes the expectation of an\nexpensive black-box integrand taken over a known probability distribution. In\nthis work, we study BQO under distributional uncertainty in which the\nunderlying probability distribution is unknown except for a limited set of its\ni.i.d. samples. A standard BQO approach maximizes the Monte Carlo estimate of\nthe true expected objective given the fixed sample set. Though Monte Carlo\nestimate is unbiased, it has high variance given a small set of samples; thus\ncan result in a spurious objective function. We adopt the distributionally\nrobust optimization perspective to this problem by maximizing the expected\nobjective under the most adversarial distribution. In particular, we propose a\nnovel posterior sampling based algorithm, namely distributionally robust BQO\n(DRBQO) for this purpose. We demonstrate the empirical effectiveness of our\nproposed framework in synthetic and real-world problems, and characterize its\ntheoretical convergence via Bayesian regret.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 12:00:33 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Nguyen", "Thanh Tang", ""], ["Gupta", "Sunil", ""], ["Ha", "Huong", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2001.06838", "submitter": "Ruosi Wan", "authors": "Junjie Yan, Ruosi Wan, Xiangyu Zhang, Wei Zhang, Yichen Wei, Jian Sun", "title": "Towards Stabilizing Batch Statistics in Backward Propagation of Batch\n  Normalization", "comments": "ICLR2020; https://github.com/megvii-model/MABN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is one of the most widely used techniques in Deep\nLearning field. But its performance can awfully degrade with insufficient batch\nsize. This weakness limits the usage of BN on many computer vision tasks like\ndetection or segmentation, where batch size is usually small due to the\nconstraint of memory consumption. Therefore many modified normalization\ntechniques have been proposed, which either fail to restore the performance of\nBN completely, or have to introduce additional nonlinear operations in\ninference procedure and increase huge consumption. In this paper, we reveal\nthat there are two extra batch statistics involved in backward propagation of\nBN, on which has never been well discussed before. The extra batch statistics\nassociated with gradients also can severely affect the training of deep neural\nnetwork. Based on our analysis, we propose a novel normalization method, named\nMoving Average Batch Normalization (MABN). MABN can completely restore the\nperformance of vanilla BN in small batch cases, without introducing any\nadditional nonlinear operations in inference procedure. We prove the benefits\nof MABN by both theoretical analysis and experiments. Our experiments\ndemonstrate the effectiveness of MABN in multiple computer vision tasks\nincluding ImageNet and COCO. The code has been released in\nhttps://github.com/megvii-model/MABN.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 14:41:22 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 10:06:09 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yan", "Junjie", ""], ["Wan", "Ruosi", ""], ["Zhang", "Xiangyu", ""], ["Zhang", "Wei", ""], ["Wei", "Yichen", ""], ["Sun", "Jian", ""]]}, {"id": "2001.06846", "submitter": "Yi Wang Dr.", "authors": "Yi Wang, Yang Yang, Weiguo Zhu, Yi Wu, Xu Yan, Yongfeng Liu, Yu Wang,\n  Liang Xie, Ziyao Gao, Wenjing Zhu, Xiang Chen, Wei Yan, Mingjie Tang, Yuan\n  Tang", "title": "SQLFlow: A Bridge between SQL and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industrial AI systems are mostly end-to-end machine learning (ML) workflows.\nA typical recommendation or business intelligence system includes many online\nmicro-services and offline jobs. We describe SQLFlow for developing such\nworkflows efficiently in SQL. SQL enables developers to write short programs\nfocusing on the purpose (what) and ignoring the procedure (how). Previous\ndatabase systems extended their SQL dialect to support ML. SQLFlow\n(https://sqlflow.org/sqlflow ) takes another strategy to work as a bridge over\nvarious database systems, including MySQL, Apache Hive, and Alibaba MaxCompute,\nand ML engines like TensorFlow, XGBoost, and scikit-learn. We extended SQL\nsyntax carefully to make the extension working with various SQL dialects. We\nimplement the extension by inventing a collaborative parsing algorithm. SQLFlow\nis efficient and expressive to a wide variety of ML techniques -- supervised\nand unsupervised learning; deep networks and tree models; visual model\nexplanation in addition to training and prediction; data processing and feature\nextraction in addition to ML. SQLFlow compiles a SQL program into a\nKubernetes-native workflow for fault-tolerable execution and on-cloud\ndeployment. Current industrial users include Ant Financial, DiDi, and Alibaba\nGroup.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 15:19:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Yi", ""], ["Yang", "Yang", ""], ["Zhu", "Weiguo", ""], ["Wu", "Yi", ""], ["Yan", "Xu", ""], ["Liu", "Yongfeng", ""], ["Wang", "Yu", ""], ["Xie", "Liang", ""], ["Gao", "Ziyao", ""], ["Zhu", "Wenjing", ""], ["Chen", "Xiang", ""], ["Yan", "Wei", ""], ["Tang", "Mingjie", ""], ["Tang", "Yuan", ""]]}, {"id": "2001.06858", "submitter": "Yuan Wang", "authors": "Ray-Bing Chen, Yuan Wang, C. F. Jeff Wu", "title": "Finding Optimal Points for Expensive Functions Using Adaptive RBF-Based\n  Surrogate Model Via Uncertainty Quantification", "comments": "35 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global optimization of expensive functions has important applications in\nphysical and computer experiments. It is a challenging problem to develop\nefficient optimization scheme, because each function evaluation can be costly\nand the derivative information of the function is often not available. We\npropose a novel global optimization framework using adaptive Radial Basis\nFunctions (RBF) based surrogate model via uncertainty quantification. The\nframework consists of two iteration steps. It first employs an RBF-based\nBayesian surrogate model to approximate the true function, where the parameters\nof the RBFs can be adaptively estimated and updated each time a new point is\nexplored. Then it utilizes a model-guided selection criterion to identify a new\npoint from a candidate set for function evaluation. The selection criterion\nadopted here is a sample version of the expected improvement (EI) criterion. We\nconduct simulation studies with standard test functions, which show that the\nproposed method has some advantages, especially when the true surface is not\nvery smooth. In addition, we also propose modified approaches to improve the\nsearch performance for identifying global optimal points and to deal with the\nhigher dimension scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 16:15:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chen", "Ray-Bing", ""], ["Wang", "Yuan", ""], ["Wu", "C. F. Jeff", ""]]}, {"id": "2001.06880", "submitter": "Vidhi Lalchand Miss", "authors": "Vidhi Lalchand", "title": "A meta-algorithm for classification using random recursive tree\n  ensembles: A high energy physics application", "comments": "MPhil Thesis (Scientific Computing, Physics, Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to propose a meta-algorithm for automatic\nclassification in the presence of discrete binary classes. Classifier learning\nin the presence of overlapping class distributions is a challenging problem in\nmachine learning. Overlapping classes are described by the presence of\nambiguous areas in the feature space with a high density of points belonging to\nboth classes. This often occurs in real-world datasets, one such example is\nnumeric data denoting properties of particle decays derived from high-energy\naccelerators like the Large Hadron Collider (LHC). A significant body of\nresearch targeting the class overlap problem use ensemble classifiers to boost\nthe performance of algorithms by using them iteratively in multiple stages or\nusing multiple copies of the same model on different subsets of the input\ntraining data. The former is called boosting and the latter is called bagging.\nThe algorithm proposed in this thesis targets a challenging classification\nproblem in high energy physics - that of improving the statistical significance\nof the Higgs discovery. The underlying dataset used to train the algorithm is\nexperimental data built from the official ATLAS full-detector simulation with\nHiggs events (signal) mixed with different background events (background) that\nclosely mimic the statistical properties of the signal generating class\noverlap. The algorithm proposed is a variant of the classical boosted decision\ntree which is known to be one of the most successful analysis techniques in\nexperimental physics. The algorithm utilizes a unified framework that combines\ntwo meta-learning techniques - bagging and boosting. The results show that this\ncombination only works in the presence of a randomization trick in the base\nlearners.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 18:22:18 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lalchand", "Vidhi", ""]]}, {"id": "2001.06888", "submitter": "Meysam Asgari-Chenaghlu", "authors": "Meysam Asgari-Chenaghlu, M.Reza Feizi-Derakhshi, Leili Farzinvash, M.\n  A. Balafar, Cina Motamed", "title": "A multimodal deep learning approach for named entity recognition from\n  social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) from social media posts is a challenging task.\nUser generated content that forms the nature of social media, is noisy and\ncontains grammatical and linguistic errors. This noisy content makes it much\nharder for tasks such as named entity recognition. We propose two novel deep\nlearning approaches utilizing multimodal deep learning and Transformers. Both\nof our approaches use image features from short social media posts to provide\nbetter results on the NER task. On the first approach, we extract image\nfeatures using InceptionV3 and use fusion to combine textual and image\nfeatures. This presents more reliable name entity recognition when the images\nrelated to the entities are provided by the user. On the second approach, we\nuse image features combined with text and feed it into a BERT like Transformer.\nThe experimental results, namely, the precision, recall and F1 score metrics\nshow the superiority of our work compared to other state-of-the-art NER\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:37:45 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:00:12 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 12:29:04 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "M. Reza", ""], ["Farzinvash", "Leili", ""], ["Balafar", "M. A.", ""], ["Motamed", "Cina", ""]]}, {"id": "2001.06892", "submitter": "Guang Cheng", "authors": "Tianyang Hu, Zuofeng Shang, Guang Cheng", "title": "Sharp Rate of Convergence for Deep Neural Network Classifiers under the\n  Teacher-Student Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifiers built with neural networks handle large-scale high dimensional\ndata, such as facial images from computer vision, extremely well while\ntraditional statistical methods often fail miserably. In this paper, we attempt\nto understand this empirical success in high dimensional classification by\nderiving the convergence rates of excess risk. In particular, a teacher-student\nframework is proposed that assumes the Bayes classifier to be expressed as ReLU\nneural networks. In this setup, we obtain a sharp rate of convergence, i.e.,\n$\\tilde{O}_d(n^{-2/3})$, for classifiers trained using either 0-1 loss or hinge\nloss. This rate can be further improved to $\\tilde{O}_d(n^{-1})$ when the data\ndistribution is separable. Here, $n$ denotes the sample size. An interesting\nobservation is that the data dimension only contributes to the $\\log(n)$ term\nin the above rates. This may provide one theoretical explanation for the\nempirical successes of deep neural networks in high dimensional classification,\nparticularly for structured data.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 19:58:43 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 04:58:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hu", "Tianyang", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "2001.06916", "submitter": "Anthony Dunn", "authors": "Stefano Coniglio, Anthony J. Dunn and Alain B. Zemkoho", "title": "Infrequent adverse event prediction in low carbon energy production\n  using machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of predicting the occurrence of infrequent adverse\nevents in the context of predictive maintenance. We cast the corresponding\nmachine learning task as an imbalanced classification problem and propose a\nframework for solving it that is capable of leveraging different classifiers in\norder to predict the occurrence of an adverse event before it takes place. In\nparticular, we focus on two applications arising in low-carbon energy\nproduction: foam formation in anaerobic digestion and condenser tube leakage in\nthe steam turbines of a nuclear power station. The results of an extensive set\nof omputational experiments show the effectiveness of the techniques that we\npropose.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 23:02:07 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 09:59:56 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Coniglio", "Stefano", ""], ["Dunn", "Anthony J.", ""], ["Zemkoho", "Alain B.", ""]]}, {"id": "2001.06927", "submitter": "Ramprasaath R. Selvaraju", "authors": "Ramprasaath R. Selvaraju, Purva Tendulkar, Devi Parikh, Eric Horvitz,\n  Marco Ribeiro, Besmira Nushi, Ece Kamar", "title": "SQuINTing at VQA Models: Introspecting VQA Models with Sub-Questions", "comments": "Accepted to CVPR'20 as an Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing VQA datasets contain questions with varying levels of complexity.\nWhile the majority of questions in these datasets require perception for\nrecognizing existence, properties, and spatial relationships of entities, a\nsignificant portion of questions pose challenges that correspond to reasoning\ntasks - tasks that can only be answered through a synthesis of perception and\nknowledge about the world, logic and / or reasoning. Analyzing performance\nacross this distinction allows us to notice when existing VQA models have\nconsistency issues; they answer the reasoning questions correctly but fail on\nassociated low-level perception questions. For example, in Figure 1, models\nanswer the complex reasoning question \"Is the banana ripe enough to eat?\"\ncorrectly, but fail on the associated perception question \"Are the bananas\nmostly green or yellow?\" indicating that the model likely answered the\nreasoning question correctly but for the wrong reason. We quantify the extent\nto which this phenomenon occurs by creating a new Reasoning split of the VQA\ndataset and collecting VQA-introspect, a new dataset1 which consists of 238K\nnew perception questions which serve as sub questions corresponding to the set\nof perceptual tasks needed to effectively answer the complex reasoning\nquestions in the Reasoning split. Our evaluation shows that state-of-the-art\nVQA models have comparable performance in answering perception and reasoning\nquestions, but suffer from consistency problems. To address this shortcoming,\nwe propose an approach called Sub-Question Importance-aware Network Tuning\n(SQuINT), which encourages the model to attend to the same parts of the image\nwhen answering the reasoning question and the perception sub question. We show\nthat SQuINT improves model consistency by ~5%, also marginally improving\nperformance on the Reasoning questions in VQA, while also displaying better\nattention maps.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:02:36 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:54:16 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Selvaraju", "Ramprasaath R.", ""], ["Tendulkar", "Purva", ""], ["Parikh", "Devi", ""], ["Horvitz", "Eric", ""], ["Ribeiro", "Marco", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""]]}, {"id": "2001.06930", "submitter": "Nan Wu", "authors": "Nan Wu, Adrien Vincent, Dmitri Strukov, Yuan Xie", "title": "Memristor Hardware-Friendly Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant progress has been made in solving sophisticated\nproblems among various domains by using reinforcement learning (RL), which\nallows machines or agents to learn from interactions with environments rather\nthan explicit supervision. As the end of Moore's law seems to be imminent,\nemerging technologies that enable high performance neuromorphic hardware\nsystems are attracting increasing attention. Namely, neuromorphic architectures\nthat leverage memristors, the programmable and nonvolatile two-terminal\ndevices, as synaptic weights in hardware neural networks, are candidates of\nchoice to realize such highly energy-efficient and complex nervous systems.\nHowever, one of the challenges for memristive hardware with integrated learning\ncapabilities is prohibitively large number of write cycles that might be\nrequired during learning process, and this situation is even exacerbated under\nRL situations. In this work we propose a memristive neuromorphic hardware\nimplementation for the actor-critic algorithm in RL. By introducing a two-fold\ntraining procedure (i.e., ex-situ pre-training and in-situ re-training) and\nseveral training techniques, the number of weight updates can be significantly\nreduced and thus it will be suitable for efficient in-situ learning\nimplementations. As a case study, we consider the task of balancing an inverted\npendulum, a classical problem in both RL and control theory. We believe that\nthis study shows the promise of using memristor-based hardware neural networks\nfor handling complex tasks through in-situ reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:08:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Nan", ""], ["Vincent", "Adrien", ""], ["Strukov", "Dmitri", ""], ["Xie", "Yuan", ""]]}, {"id": "2001.06931", "submitter": "Shunichi Amari", "authors": "Shun-ichi Amari", "title": "Any Target Function Exists in a Neighborhood of Any Sufficiently Wide\n  Random Network: A Geometrical Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that any target function is realized in a sufficiently small\nneighborhood of any randomly connected deep network, provided the width (the\nnumber of neurons in a layer) is sufficiently large. There are sophisticated\ntheories and discussions concerning this striking fact, but rigorous theories\nare very complicated. We give an elementary geometrical proof by using a simple\nmodel for the purpose of elucidating its structure. We show that\nhigh-dimensional geometry plays a magical role: When we project a\nhigh-dimensional sphere of radius 1 to a low-dimensional subspace, the uniform\ndistribution over the sphere reduces to a Gaussian distribution of negligibly\nsmall covariances.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:09:53 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 01:00:37 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Amari", "Shun-ichi", ""]]}, {"id": "2001.06937", "submitter": "Jie Gui", "authors": "Jie Gui, Zhenan Sun, Yonggang Wen, Dacheng Tao, Jieping Ye", "title": "A Review on Generative Adversarial Networks: Algorithms, Theory, and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a hot research topic recently.\nGANs have been widely studied since 2014, and a large number of algorithms have\nbeen proposed. However, there is few comprehensive study explaining the\nconnections among different GANs variants, and how they have evolved. In this\npaper, we attempt to provide a review on various GANs methods from the\nperspectives of algorithms, theory, and applications. Firstly, the motivations,\nmathematical representations, and structure of most GANs algorithms are\nintroduced in details. Furthermore, GANs have been combined with other machine\nlearning algorithms for specific applications, such as semi-supervised\nlearning, transfer learning, and reinforcement learning. This paper compares\nthe commonalities and differences of these GANs methods. Secondly, theoretical\nissues related to GANs are investigated. Thirdly, typical applications of GANs\nin image processing and computer vision, natural language processing, music,\nspeech and audio, medical field, and data science are illustrated. Finally, the\nfuture open research problems for GANs are pointed out.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:52:05 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gui", "Jie", ""], ["Sun", "Zhenan", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""], ["Ye", "Jieping", ""]]}, {"id": "2001.06938", "submitter": "Roman Vershynin", "authors": "Roman Vershynin", "title": "Memory capacity of neural networks with threshold and ReLU activations", "comments": "26 pages. Minor inaccuracies corrected, discussion of prior work\n  expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overwhelming theoretical and empirical evidence shows that mildly\noverparametrized neural networks -- those with more connections than the size\nof the training data -- are often able to memorize the training data with\n$100\\%$ accuracy. This was rigorously proved for networks with sigmoid\nactivation functions and, very recently, for ReLU activations. Addressing a\n1988 open question of Baum, we prove that this phenomenon holds for general\nmultilayered perceptrons, i.e. neural networks with threshold activation\nfunctions, or with any mix of threshold and ReLU activations. Our construction\nis probabilistic and exploits sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:54:21 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 18:38:18 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Vershynin", "Roman", ""]]}, {"id": "2001.06940", "submitter": "Tom Blau", "authors": "Philippe Morere, Gilad Francis, Tom Blau, Fabio Ramos", "title": "Reinforcement Learning with Probabilistically Complete Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing exploration and exploitation remains a key challenge in\nreinforcement learning (RL). State-of-the-art RL algorithms suffer from high\nsample complexity, particularly in the sparse reward case, where they can do no\nbetter than to explore in all directions until the first positive rewards are\nfound. To mitigate this, we propose Rapidly Randomly-exploring Reinforcement\nLearning (R3L). We formulate exploration as a search problem and leverage\nwidely-used planning algorithms such as Rapidly-exploring Random Tree (RRT) to\nfind initial solutions. These solutions are used as demonstrations to\ninitialize a policy, then refined by a generic RL algorithm, leading to faster\nand more stable convergence. We provide theoretical guarantees of R3L\nexploration finding successful solutions, as well as bounds for its sampling\ncomplexity. We experimentally demonstrate the method outperforms classic and\nintrinsic exploration techniques, requiring only a fraction of exploration\nsamples and achieving better asymptotic performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:11:24 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Morere", "Philippe", ""], ["Francis", "Gilad", ""], ["Blau", "Tom", ""], ["Ramos", "Fabio", ""]]}, {"id": "2001.06944", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Changyou Chen, Zhe Gan, Zheng Wen, Wenlin Wang, Lawrence\n  Carin", "title": "Nested-Wasserstein Self-Imitation Learning for Sequence Generation", "comments": "Accepted by AISTATS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been widely studied for improving\nsequence-generation models. However, the conventional rewards used for RL\ntraining typically cannot capture sufficient semantic information and therefore\nrender model bias. Further, the sparse and delayed rewards make RL exploration\ninefficient. To alleviate these issues, we propose the concept of\nnested-Wasserstein distance for distributional semantic matching. To further\nexploit it, a novel nested-Wasserstein self-imitation learning framework is\ndeveloped, encouraging the model to exploit historical high-rewarded sequences\nfor enhanced exploration and better semantic matching. Our solution can be\nunderstood as approximately executing proximal policy optimization with\nWasserstein trust-regions. Experiments on a variety of unconditional and\nconditional sequence-generation tasks demonstrate the proposed approach\nconsistently leads to improved performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 02:19:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Chen", "Changyou", ""], ["Gan", "Zhe", ""], ["Wen", "Zheng", ""], ["Wang", "Wenlin", ""], ["Carin", "Lawrence", ""]]}, {"id": "2001.06954", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Navaneeth Kamballur Kottayil, Xinyao\n  Sun, Parwant Ghuman, Irene Cheng", "title": "CNN-based InSAR Denoising and Coherence Metric", "comments": "2018 IEEE SENSORS", "journal-ref": null, "doi": "10.1109/ICSENS.2018.8589920", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interferometric Synthetic Aperture Radar (InSAR) imagery for estimating\nground movement, based on microwaves reflected off ground targets is gaining\nincreasing importance in remote sensing. However, noise corrupts microwave\nreflections received at satellite and contaminates the signal's wrapped phase.\nWe introduce Convolutional Neural Networks (CNNs) to this problem domain and\nshow the effectiveness of autoencoder CNN architectures to learn InSAR image\ndenoising filters in the absence of clean ground truth images, and for artefact\nreduction in estimated coherence through intelligent preprocessing of training\ndata. We compare our results with four established methods to illustrate\nsuperiority of proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:20:29 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Kottayil", "Navaneeth Kamballur", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06956", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Xinyao Sun, Parwant Ghuman, and\n  Irene Cheng", "title": "CNN-based InSAR Coherence Classification", "comments": "2018 IEEE SENSORS", "journal-ref": null, "doi": "10.1109/ICSENS.2018.8589742", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interferometric Synthetic Aperture Radar (InSAR) imagery based on microwaves\nreflected off ground targets is becoming increasingly important in remote\nsensing for ground movement estimation. However, the reflections are\ncontaminated by noise, which distorts the signal's wrapped phase. Demarcation\nof image regions based on degree of contamination (\"coherence\") is an important\ncomponent of the InSAR processing pipeline. We introduce Convolutional Neural\nNetworks (CNNs) to this problem domain and show their effectiveness in\nimproving coherence-based demarcation and reducing misclassifications in\ncompletely incoherent regions through intelligent preprocessing of training\ndata. Quantitative and qualitative comparisons prove superiority of proposed\nmethod over three established methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:25:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06961", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Navaneeth Kamballur Kottayil, Xinyao Sun, and\n  Irene Cheng", "title": "CNN-Based Real-Time Parameter Tuning for Optimizing Denoising Filter\n  Performance", "comments": "2019 International Conference on Image Analysis and Recognition", "journal-ref": null, "doi": "10.1007/978-3-030-27202-9_10", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel direction to improve the denoising quality of\nfiltering-based denoising algorithms in real time by predicting the best filter\nparameter value using a Convolutional Neural Network (CNN). We take the use\ncase of BM3D, the state-of-the-art filtering-based denoising algorithm, to\ndemonstrate and validate our approach. We propose and train a simple, shallow\nCNN to predict in real time, the optimum filter parameter value, given the\ninput noisy image. Each training example consists of a noisy input image\n(training data) and the filter parameter value that produces the best output\n(training label). Both qualitative and quantitative results using the widely\nused PSNR and SSIM metrics on the popular BSD68 dataset show that the\nCNN-guided BM3D outperforms the original, unguided BM3D across different noise\nlevels. Thus, our proposed method is a CNN-based improvement on the original\nBM3D which uses a fixed, default parameter value for all images.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 03:46:06 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Kottayil", "Navaneeth Kamballur", ""], ["Sun", "Xinyao", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.06970", "submitter": "Qing Qu", "authors": "Qing Qu, Zhihui Zhu, Xiao Li, Manolis C. Tsakiris, John Wright, and\n  Ren\\'e Vidal", "title": "Finding the Sparsest Vectors in a Subspace: Theory, Algorithms, and\n  Applications", "comments": "QQ and ZZ contributed equally to the work. Invited review paper for\n  IEEE Signal Processing Magazine Special Issue on non-convex optimization for\n  signal processing and machine learning. This article contains 26 pages with\n  11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.IV math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding the sparsest vector (direction) in a low dimensional\nsubspace can be considered as a homogeneous variant of the sparse recovery\nproblem, which finds applications in robust subspace recovery, dictionary\nlearning, sparse blind deconvolution, and many other problems in signal\nprocessing and machine learning. However, in contrast to the classical sparse\nrecovery problem, the most natural formulation for finding the sparsest vector\nin a subspace is usually nonconvex. In this paper, we overview recent advances\non global nonconvex optimization theory for solving this problem, ranging from\ngeometric analysis of its optimization landscapes, to efficient optimization\nalgorithms for solving the associated nonconvex optimization problem, to\napplications in machine intelligence, representation learning, and imaging\nsciences. Finally, we conclude this review by pointing out several interesting\nopen problems for future research.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:48:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Qu", "Qing", ""], ["Zhu", "Zhihui", ""], ["Li", "Xiao", ""], ["Tsakiris", "Manolis C.", ""], ["Wright", "John", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "2001.06988", "submitter": "Yasuho Yamashita", "authors": "Yasuho Yamashita, Takuma Shibahara and Junichi Kuwata", "title": "A point-wise linear model reveals reasons for 30-day readmission of\n  heart failure patients", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart failures in the United States cost an estimated 30.7 billion dollars\nannually and predictive analysis can decrease costs due to readmission of heart\nfailure patients. Deep learning can predict readmissions but does not give\nreasons for its predictions. Ours is the first study on a deep-learning\napproach to explaining decisions behind readmission predictions. Additionally,\nit provides an automatic patient stratification to explain cohorts of\nreadmitted patients. The new deep-learning model called a point-wise linear\nmodel is a meta-learning machine of linear models. It generates a logistic\nregression model to predict early readmission for each patient. The custom-made\nprediction models allow us to analyze feature importance. We evaluated the\napproach using a dataset that had 30-days readmission patients with heart\nfailures. This study has been submitted in PLOS ONE. In advance, we would like\nto share the theoretical aspect of the point-wise linear model as a part of our\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:56:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yamashita", "Yasuho", ""], ["Shibahara", "Takuma", ""], ["Kuwata", "Junichi", ""]]}, {"id": "2001.07002", "submitter": "Faizal Hafiz", "authors": "Renoh Johnson Chalakkal, Faizal Hafiz, Waleed Abdulla, and Akshya\n  Swain", "title": "An Efficient Framework for Automated Screening of Clinically Significant\n  Macular Edema", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes a new approach to automated screening of\nClinically Significant Macular Edema (CSME) and addresses two major challenges\nassociated with such screenings, i.e., exudate segmentation and imbalanced\ndatasets. The proposed approach replaces the conventional exudate segmentation\nbased feature extraction by combining a pre-trained deep neural network with\nmeta-heuristic feature selection. A feature space over-sampling technique is\nbeing used to overcome the effects of skewed datasets and the screening is\naccomplished by a k-NN based classifier. The role of each data-processing step\n(e.g., class balancing, feature selection) and the effects of limiting the\nregion-of-interest to fovea on the classification performance are critically\nanalyzed. Finally, the selection and implication of operating point on Receiver\nOperating Characteristic curve are discussed. The results of this study\nconvincingly demonstrate that by following these fundamental practices of\nmachine learning, a basic k-NN based classifier could effectively accomplish\nthe CSME screening.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 07:34:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chalakkal", "Renoh Johnson", ""], ["Hafiz", "Faizal", ""], ["Abdulla", "Waleed", ""], ["Swain", "Akshya", ""]]}, {"id": "2001.07026", "submitter": "Daniel J. Trosten", "authors": "Daniel J. Trosten, Michael C. Kampffmeyer, Robert Jenssen", "title": "Deep Image Clustering with Tensor Kernels and Unsupervised Companion\n  Objectives", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a new model for deep image clustering, using\nconvolutional neural networks and tensor kernels. The proposed Deep Tensor\nKernel Clustering (DTKC) consists of a convolutional neural network (CNN),\nwhich is trained to reflect a common cluster structure at the output of its\nintermediate layers. Encouraging a consistent cluster structure throughout the\nnetwork has the potential to guide it towards meaningful clusters, even though\nthese clusters might appear to be nonlinear in the input space. The cluster\nstructure is enforced through the idea of unsupervised companion objectives,\nwhere separate loss functions are attached to layers in the network. These\nunsupervised companion objectives are constructed based on a proposed\ngeneralization of the Cauchy-Schwarz (CS) divergence, from vectors to tensors\nof arbitrary rank. Generalizing the CS divergence to tensor-valued data is a\ncrucial step, due to the tensorial nature of the intermediate representations\nin the CNN. Several experiments are conducted to thoroughly assess the\nperformance of the proposed DTKC model. The results indicate that the model\noutperforms, or performs comparable to, a wide range of baseline algorithms. We\nalso empirically demonstrate that our model does not suffer from objective\nfunction mismatch, which can be a problematic artifact in autoencoder-based\nclustering models.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 09:07:59 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 15:12:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Trosten", "Daniel J.", ""], ["Kampffmeyer", "Michael C.", ""], ["Jenssen", "Robert", ""]]}, {"id": "2001.07034", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan V, Prachi Singh, Sriram Ganapathy", "title": "Pairwise Discriminative Neural PLDA for Speaker Verification", "comments": "This paper was submitted to IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP) 2020. Link to GitHub\n  Repository: https://github.com/iiscleap/NeuralPlda", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art approach to speaker verification involves the extraction of\ndiscriminative embeddings like x-vectors followed by a generative model\nback-end using a probabilistic linear discriminant analysis (PLDA). In this\npaper, we propose a Pairwise neural discriminative model for the task of\nspeaker verification which operates on a pair of speaker embeddings such as\nx-vectors/i-vectors and outputs a score that can be considered as a scaled\nlog-likelihood ratio. We construct a differentiable cost function which\napproximates speaker verification loss, namely the minimum detection cost. The\npre-processing steps of linear discriminant analysis (LDA), unit length\nnormalization and within class covariance normalization are all modeled as\nlayers of a neural model and the speaker verification cost functions can be\nback-propagated through these layers during training. We also explore\nregularization techniques to prevent overfitting, which is a major concern in\nusing discriminative back-end models for verification tasks. The experiments\nare performed on the NIST SRE 2018 development and evaluation datasets. We\nobserve average relative improvements of 8% in CMN2 condition and 30% in VAST\ncondition over the PLDA baseline system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 09:52:52 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 09:32:10 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", "V"], ["Singh", "Prachi", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2001.07072", "submitter": "Zhengqi Gao", "authors": "Zhengqi Gao, Jun Tao, Yangfeng Su, Dian Zhou, and Xuan Zeng", "title": "Projection based Active Gaussian Process Regression for Pareto Front\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pareto Front (PF) modeling is essential in decision making problems across\nall domains such as economics, medicine or engineering. In Operation Research\nliterature, this task has been addressed based on multi-objective optimization\nalgorithms. However, without learning models for PF, these methods cannot\nexamine whether a new provided point locates on PF or not. In this paper, we\nreconsider the task from Data Mining perspective. A novel projection based\nactive Gaussian process regression (P- aGPR) method is proposed for efficient\nPF modeling. First, P- aGPR chooses a series of projection spaces with\ndimensionalities ranking from low to high. Next, in each projection space, a\nGaussian process regression (GPR) model is trained to represent the constraint\nthat PF should satisfy in that space. Moreover, in order to improve modeling\nefficacy and stability, an active learning framework has been developed by\nexploiting the uncertainty information obtained in the GPR models. Different\nfrom all existing methods, our proposed P-aGPR method can not only provide a\ngenerative PF model, but also fast examine whether a provided point locates on\nPF or not. The numerical results demonstrate that compared to state-of-the-art\npassive learning methods the proposed P-aGPR method can achieve higher modeling\naccuracy and stability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 11:52:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Gao", "Zhengqi", ""], ["Tao", "Jun", ""], ["Su", "Yangfeng", ""], ["Zhou", "Dian", ""], ["Zeng", "Xuan", ""]]}, {"id": "2001.07093", "submitter": "Zhen-Liang Ni", "authors": "Zhen-Liang Ni, Gui-Bin Bian, Guan-An Wang, Xiao-Hu Zhou, Zeng-Guang\n  Hou, Xiao-Liang Xie, Zhen Li and Yu-Han Wang", "title": "BARNet: Bilinear Attention Network with Adaptive Receptive Fields for\n  Surgical Instrument Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surgical instrument segmentation is extremely important for computer-assisted\nsurgery. Different from common object segmentation, it is more challenging due\nto the large illumination and scale variation caused by the special surgical\nscenes. In this paper, we propose a novel bilinear attention network with\nadaptive receptive field to solve these two challenges. For the illumination\nvariation, the bilinear attention module can capture second-order statistics to\nencode global contexts and semantic dependencies between local pixels. With\nthem, semantic features in challenging areas can be inferred from their\nneighbors and the distinction of various semantics can be boosted. For the\nscale variation, our adaptive receptive field module aggregates multi-scale\nfeatures and automatically fuses them with different weights. Specifically, it\nencodes the semantic relationship between channels to emphasize feature maps\nwith appropriate scales, changing the receptive field of subsequent\nconvolutions. The proposed network achieves the best performance 97.47% mean\nIOU on Cata7 and comes first place on EndoVis 2017 by 10.10% IOU overtaking\nsecond-ranking method.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:05:08 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 08:16:52 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 09:45:53 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 03:12:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Ni", "Zhen-Liang", ""], ["Bian", "Gui-Bin", ""], ["Wang", "Guan-An", ""], ["Zhou", "Xiao-Hu", ""], ["Hou", "Zeng-Guang", ""], ["Xie", "Xiao-Liang", ""], ["Li", "Zhen", ""], ["Wang", "Yu-Han", ""]]}, {"id": "2001.07104", "submitter": "Holger Fr\\\"oning", "authors": "Lorenz Braun, Sotirios Nikas, Chen Song, Vincent Heuveline, Holger\n  Fr\\\"oning", "title": "A Simple Model for Portable and Fast Prediction of Execution Time and\n  Power Consumption of GPU Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing compute kernel execution behavior on GPUs for efficient task\nscheduling is a non-trivial task. We address this with a simple model enabling\nportable and fast predictions among different GPUs using only\nhardware-independent features. This model is built based on random forests\nusing 189 individual compute kernels from benchmarks such as Parboil, Rodinia,\nPolybench-GPU and SHOC. Evaluation of the model performance using\ncross-validation yields a median Mean Average Percentage Error (MAPE) of\n8.86-52.00% and 1.84-2.94%, for time respectively power prediction across five\ndifferent GPUs, while latency for a single prediction varies between 15 and 108\nmilliseconds.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:40:54 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 12:15:51 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 12:47:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Braun", "Lorenz", ""], ["Nikas", "Sotirios", ""], ["Song", "Chen", ""], ["Heuveline", "Vincent", ""], ["Fr\u00f6ning", "Holger", ""]]}, {"id": "2001.07118", "submitter": "Ryan Carey", "authors": "Ryan Carey, Eric Langlois, Tom Everitt and Shane Legg", "title": "The Incentives that Shape Behaviour", "comments": "In SafeAI workshop at AAAI. Superseded by arXiv:2102.01685", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which variables does an agent have an incentive to control with its decision,\nand which variables does it have an incentive to respond to? We formalise these\nincentives, and demonstrate unique graphical criteria for detecting them in any\nsingle decision causal influence diagram. To this end, we introduce structural\ncausal influence models, a hybrid of the influence diagram and structural\ncausal model frameworks. Finally, we illustrate how these incentives predict\nagent incentives in both fairness and AI safety applications.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 14:32:07 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 20:02:54 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Carey", "Ryan", ""], ["Langlois", "Eric", ""], ["Everitt", "Tom", ""], ["Legg", "Shane", ""]]}, {"id": "2001.07119", "submitter": "Mengzhuo Guo", "authors": "Mengzhuo Guo, Qingpeng Zhang, Xiuwu Liao, Daniel Dajun Zeng", "title": "An interpretable neural network model through piecewise linear\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing interpretable methods explain a black-box model in a post-hoc\nmanner, which uses simpler models or data analysis techniques to interpret the\npredictions after the model is learned. However, they (a) may derive\ncontradictory explanations on the same predictions given different methods and\ndata samples, and (b) focus on using simpler models to provide higher\ndescriptive accuracy at the sacrifice of prediction accuracy. To address these\nissues, we propose a hybrid interpretable model that combines a piecewise\nlinear component and a nonlinear component. The first component describes the\nexplicit feature contributions by piecewise linear approximation to increase\nthe expressiveness of the model. The other component uses a multi-layer\nperceptron to capture feature interactions and implicit nonlinearity, and\nincrease the prediction performance. Different from the post-hoc approaches,\nthe interpretability is obtained once the model is learned in the form of\nfeature shapes. We also provide a variant to explore higher-order interactions\namong features to demonstrate that the proposed model is flexible for\nadaptation. Experiments demonstrate that the proposed model can achieve good\ninterpretability by describing feature shapes while maintaining\nstate-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 14:32:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Guo", "Mengzhuo", ""], ["Zhang", "Qingpeng", ""], ["Liao", "Xiuwu", ""], ["Zeng", "Daniel Dajun", ""]]}, {"id": "2001.07135", "submitter": "Zhi-Hua Zhou", "authors": "Xi-Zhu Wu, Wenkai Xu, Song Liu, and Zhi-Hua Zhou", "title": "Model Reuse with Reduced Kernel Mean Embedding Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a publicly available pool of machine learning models constructed for\nvarious tasks, when a user plans to build a model for her own machine learning\napplication, is it possible to build upon models in the pool such that the\nprevious efforts on these existing models can be reused rather than starting\nfrom scratch? Here, a grand challenge is how to find models that are helpful\nfor the current application, without accessing the raw training data for the\nmodels in the pool. In this paper, we present a two-phase framework. In the\nupload phase, when a model is uploading into the pool, we construct a reduced\nkernel mean embedding (RKME) as a specification for the model. Then in the\ndeployment phase, the relatedness of the current task and pre-trained models\nwill be measured based on the value of the RKME specification. Theoretical\nresults and extensive experiments validate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:15:07 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wu", "Xi-Zhu", ""], ["Xu", "Wenkai", ""], ["Liu", "Song", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2001.07150", "submitter": "Wei Wang", "authors": "Wei Wang, Xiang-Gen Xia, Chuanjiang He, Zemin Ren, Jian Lu, Tianfu\n  Wang and Baiying Lei", "title": "A deep network for sinogram and CT image reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A CT image can be well reconstructed when the sampling rate of the sinogram\nsatisfies the Nyquist criteria and the sampled signal is noise-free. However,\nin practice, the sinogram is usually contaminated by noise, which degrades the\nquality of a reconstructed CT image. In this paper, we design a deep network\nfor sinogram and CT image reconstruction. The network consists of two cascaded\nblocks that are linked by a filter backprojection (FBP) layer, where the former\nblock is responsible for denoising and completing the sinograms while the\nlatter is used to removing the noise and artifacts of the CT images.\nExperimental results show that the reconstructed CT images by our methods have\nthe highest PSNR and SSIM in average compared to state of the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 15:50:16 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Wei", ""], ["Xia", "Xiang-Gen", ""], ["He", "Chuanjiang", ""], ["Ren", "Zemin", ""], ["Lu", "Jian", ""], ["Wang", "Tianfu", ""], ["Lei", "Baiying", ""]]}, {"id": "2001.07155", "submitter": "Vladimir Berikov", "authors": "Vladimir Berikov", "title": "Heterogeneous Transfer Learning in Ensemble Clustering", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an ensemble clustering method using transfer learning\napproach. We consider a clustering problem, in which in addition to data under\nconsideration, \"similar\" labeled data are available. The datasets can be\ndescribed with different features. The method is based on constructing\nmeta-features which describe structural characteristics of data, and their\ntransfer from source to target domain. An experimental study of the method\nusing Monte Carlo modeling has confirmed its efficiency. In comparison with\nother similar methods, the proposed one is able to work under arbitrary feature\ndescriptions of source and target domains; it has smaller complexity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 16:03:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Berikov", "Vladimir", ""]]}, {"id": "2001.07194", "submitter": "Yichao Zhou", "authors": "Yichao Zhou, Shaunak Mishra, Manisha Verma, Narayan Bhamidipati, and\n  Wei Wang", "title": "Recommending Themes for Ad Creative Design via Visual-Linguistic\n  Representations", "comments": "7 pages, 8 figures, 2 tables, accepted by The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380001", "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a perennial need in the online advertising industry to refresh ad\ncreatives, i.e., images and text used for enticing online users towards a\nbrand. Such refreshes are required to reduce the likelihood of ad fatigue among\nonline users, and to incorporate insights from other successful campaigns in\nrelated product categories. Given a brand, to come up with themes for a new ad\nis a painstaking and time consuming process for creative strategists.\nStrategists typically draw inspiration from the images and text used for past\nad campaigns, as well as world knowledge on the brands. To automatically infer\nad themes via such multimodal sources of information in past ad campaigns, we\npropose a theme (keyphrase) recommender system for ad creative strategists. The\ntheme recommender is based on aggregating results from a visual question\nanswering (VQA) task, which ingests the following: (i) ad images, (ii) text\nassociated with the ads as well as Wikipedia pages on the brands in the ads,\nand (iii) questions around the ad. We leverage transformer based cross-modality\nencoders to train visual-linguistic representations for our VQA task. We study\ntwo formulations for the VQA task along the lines of classification and\nranking; via experiments on a public dataset, we show that cross-modal\nrepresentations lead to significantly better classification accuracy and\nranking precision-recall metrics. Cross-modal representations show better\nperformance compared to separate image and text representations. In addition,\nthe use of multimodal information shows a significant lift over using only\ntextual or visual information.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 18:04:10 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 23:05:46 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhou", "Yichao", ""], ["Mishra", "Shaunak", ""], ["Verma", "Manisha", ""], ["Bhamidipati", "Narayan", ""], ["Wang", "Wei", ""]]}, {"id": "2001.07233", "submitter": "Yuxiao Chen", "authors": "Yuxiao Chen, Sumanth Dathathri, Tung Phan-Minh, and Richard M. Murray", "title": "Counter-example Guided Learning of Bounds on Environment Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in building autonomous systems that interact with\ncomplex environments. The difficulty associated with obtaining an accurate\nmodel for such environments poses a challenge to the task of assessing and\nguaranteeing the system's performance. We present a data-driven solution that\nallows for a system to be evaluated for specification conformance without an\naccurate model of the environment. Our approach involves learning a\nconservative reactive bound of the environment's behavior using data and\nspecification of the system's desired behavior. First, the approach begins by\nlearning a conservative reactive bound on the environment's actions that\ncaptures its possible behaviors with high probability. This bound is then used\nto assist verification, and if the verification fails under this bound, the\nalgorithm returns counter-examples to show how failure occurs and then uses\nthese to refine the bound. We demonstrate the applicability of the approach\nthrough two case-studies: i) verifying controllers for a toy multi-robot\nsystem, and ii) verifying an instance of human-robot interaction during a\nlane-change maneuver given real-world human driving data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 19:58:24 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 03:02:11 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 06:19:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Chen", "Yuxiao", ""], ["Dathathri", "Sumanth", ""], ["Phan-Minh", "Tung", ""], ["Murray", "Richard M.", ""]]}, {"id": "2001.07248", "submitter": "Liudmila Ostroumova Prokhorenkova", "authors": "Aleksei Ustimenko and Liudmila Prokhorenkova", "title": "SGLB: Stochastic Gradient Langevin Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Stochastic Gradient Langevin Boosting (SGLB) - a\npowerful and efficient machine learning framework that may deal with a wide\nrange of loss functions and has provable generalization guarantees. The method\nis based on a special form of the Langevin diffusion equation specifically\ndesigned for gradient boosting. This allows us to theoretically guarantee the\nglobal convergence even for multimodal loss functions, while standard gradient\nboosting algorithms can guarantee only local optimum. We also empirically show\nthat SGLB outperforms classic gradient boosting when applied to classification\ntasks with 0-1 loss function, which is known to be multimodal.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 20:44:52 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 14:45:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 15:56:26 GMT"}, {"version": "v4", "created": "Sun, 4 Jul 2021 19:03:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ustimenko", "Aleksei", ""], ["Prokhorenkova", "Liudmila", ""]]}, {"id": "2001.07252", "submitter": "Tsun-Yi Yang", "authors": "Tsun-Yi Yang and Duy-Kien Nguyen and Huub Heijnen and Vassileios\n  Balntas", "title": "UR2KiD: Unifying Retrieval, Keypoint Detection, and Keypoint Description\n  without Local Correspondence Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore how three related tasks, namely keypoint detection,\ndescription, and image retrieval can be jointly tackled using a single unified\nframework, which is trained without the need of training data with point to\npoint correspondences. By leveraging diverse information from sequential layers\nof a standard ResNet-based architecture, we are able to extract keypoints and\ndescriptors that encode local information using generic techniques such as\nlocal activation norms, channel grouping and dropping, and self-distillation.\nSubsequently, global information for image retrieval is encoded in an\nend-to-end pipeline, based on pooling of the aforementioned local responses. In\ncontrast to previous methods in local matching, our method does not depend on\npointwise/pixelwise correspondences, and requires no such supervision at all\ni.e. no depth-maps from an SfM model nor manually created synthetic affine\ntransformations. We illustrate that this simple and direct paradigm, is able to\nachieve very competitive results against the state-of-the-art methods in\nvarious challenging benchmark conditions such as viewpoint changes, scale\nchanges, and day-night shifting localization.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 21:01:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yang", "Tsun-Yi", ""], ["Nguyen", "Duy-Kien", ""], ["Heijnen", "Huub", ""], ["Balntas", "Vassileios", ""]]}, {"id": "2001.07267", "submitter": "Aydogan Ozcan", "authors": "Yijie Zhang, Kevin de Haan, Yair Rivenson, Jingxi Li, Apostolos Delis,\n  Aydogan Ozcan", "title": "Digital synthesis of histological stains using micro-structured and\n  multiplexed virtual staining of label-free tissue", "comments": "19 pages, 5 figures, 2 tables", "journal-ref": "Light: Science & Applications (2020)", "doi": "10.1038/s41377-020-0315-y", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histological staining is a vital step used to diagnose various diseases and\nhas been used for more than a century to provide contrast to tissue sections,\nrendering the tissue constituents visible for microscopic analysis by medical\nexperts. However, this process is time-consuming, labor-intensive, expensive\nand destructive to the specimen. Recently, the ability to virtually-stain\nunlabeled tissue sections, entirely avoiding the histochemical staining step,\nhas been demonstrated using tissue-stain specific deep neural networks. Here,\nwe present a new deep learning-based framework which generates\nvirtually-stained images using label-free tissue, where different stains are\nmerged following a micro-structure map defined by the user. This approach uses\na single deep neural network that receives two different sources of information\nat its input: (1) autofluorescence images of the label-free tissue sample, and\n(2) a digital staining matrix which represents the desired microscopic map of\ndifferent stains to be virtually generated at the same tissue section. This\ndigital staining matrix is also used to virtually blend existing stains,\ndigitally synthesizing new histological stains. We trained and blindly tested\nthis virtual-staining network using unlabeled kidney tissue sections to\ngenerate micro-structured combinations of Hematoxylin and Eosin (H&E), Jones\nsilver stain, and Masson's Trichrome stain. Using a single network, this\napproach multiplexes virtual staining of label-free tissue with multiple types\nof stains and paves the way for synthesizing new digital histological stains\nthat can be created on the same tissue cross-section, which is currently not\nfeasible with standard histochemical staining methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 22:14:06 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zhang", "Yijie", ""], ["de Haan", "Kevin", ""], ["Rivenson", "Yair", ""], ["Li", "Jingxi", ""], ["Delis", "Apostolos", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2001.07278", "submitter": "Arturo Berrones", "authors": "Arturo Berrones-Santos", "title": "Mixed integer programming formulation of unsupervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel formulation and training procedure for full Boltzmann machines in\nterms of a mixed binary quadratic feasibility problem is given. As a proof of\nconcept, the theory is analytically and numerically tested on XOR patterns.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 23:09:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Berrones-Santos", "Arturo", ""]]}, {"id": "2001.07301", "submitter": "Jascha Sohl-Dickstein", "authors": "Jascha Sohl-Dickstein, Roman Novak, Samuel S. Schoenholz, Jaehoon Lee", "title": "On the infinite width limit of neural networks with a standard\n  parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are currently two parameterizations used to derive fixed kernels\ncorresponding to infinite width neural networks, the NTK (Neural Tangent\nKernel) parameterization and the naive standard parameterization. However, the\nextrapolation of both of these parameterizations to infinite width is\nproblematic. The standard parameterization leads to a divergent neural tangent\nkernel while the NTK parameterization fails to capture crucial aspects of\nfinite width networks such as: the dependence of training dynamics on relative\nlayer widths, the relative training dynamics of weights and biases, and overall\nlearning rate scale. Here we propose an improved extrapolation of the standard\nparameterization that preserves all of these properties as width is taken to\ninfinity and yields a well-defined neural tangent kernel. We show\nexperimentally that the resulting kernels typically achieve similar accuracy to\nthose resulting from an NTK parameterization, but with better correspondence to\nthe parameterization of typical finite width networks. Additionally, with\ncareful tuning of width parameters, the improved standard parameterization\nkernels can outperform those stemming from an NTK parameterization. We release\ncode implementing this improved standard parameterization as part of the Neural\nTangents library at https://github.com/google/neural-tangents.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 01:02:21 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 00:53:47 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 21:06:06 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sohl-Dickstein", "Jascha", ""], ["Novak", "Roman", ""], ["Schoenholz", "Samuel S.", ""], ["Lee", "Jaehoon", ""]]}, {"id": "2001.07305", "submitter": "Haibin Chang", "authors": "Hao Xu, Haibin Chang, Dongxiao Zhang", "title": "DLGA-PDE: Discovery of PDEs with incomplete candidate library via\n  combination of deep learning and genetic algorithm", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109584", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently been developed to discover underlying\npartial differential equations (PDEs) of physical problems. However, for these\nmethods, a complete candidate library of potential terms in a PDE are usually\nrequired. To overcome this limitation, we propose a novel framework combining\ndeep learning and genetic algorithm, called DLGA-PDE, for discovering PDEs. In\nthe proposed framework, a deep neural network that is trained with available\ndata of a physical problem is utilized to generate meta-data and calculate\nderivatives, and the genetic algorithm is then employed to discover the\nunderlying PDE. Owing to the merits of the genetic algorithm, such as mutation\nand crossover, DLGA-PDE can work with an incomplete candidate library. The\nproposed DLGA-PDE is tested for discovery of the Korteweg-de Vries (KdV)\nequation, the Burgers equation, the wave equation, and the Chaffee-Infante\nequation, respectively, for proof-of-concept. Satisfactory results are obtained\nwithout the need for a complete candidate library, even in the presence of\nnoisy and limited data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 01:28:58 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Xu", "Hao", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2001.07321", "submitter": "Gantugs Atarsaikhan", "authors": "Gantugs Atarsaikhan, Brian Kenji Iwana and Seiichi Uchida", "title": "Neural Style Difference Transfer and Its Application to Font Generation", "comments": "Submitted to DAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing fonts requires a great deal of time and effort. It requires\nprofessional skills, such as sketching, vectorizing, and image editing.\nAdditionally, each letter has to be designed individually. In this paper, we\nwill introduce a method to create fonts automatically. In our proposed method,\nthe difference of font styles between two different fonts is found and\ntransferred to another font using neural style transfer. Neural style transfer\nis a method of stylizing the contents of an image with the styles of another\nimage. We proposed a novel neural style difference and content difference loss\nfor the neural style transfer. With these losses, new fonts can be generated by\nadding or removing font styles from a font. We provided experimental results\nwith various combinations of input fonts and discussed limitations and future\ndevelopment for the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:32:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Atarsaikhan", "Gantugs", ""], ["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "2001.07322", "submitter": "Bahareh Behboodi", "authors": "Bahareh Behboodi, Mina Amiri, Rupert Brooks, Hassan Rivaz", "title": "Breast lesion segmentation in ultrasound images with limited annotated\n  data", "comments": "Accepted to ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound (US) is one of the most commonly used imaging modalities in both\ndiagnosis and surgical interventions due to its low-cost, safety, and\nnon-invasive characteristic. US image segmentation is currently a unique\nchallenge because of the presence of speckle noise. As manual segmentation\nrequires considerable efforts and time, the development of automatic\nsegmentation algorithms has attracted researchers attention. Although recent\nmethodologies based on convolutional neural networks have shown promising\nperformances, their success relies on the availability of a large number of\ntraining data, which is prohibitively difficult for many applications.\nTherefore, in this study we propose the use of simulated US images and natural\nimages as auxiliary datasets in order to pre-train our segmentation network,\nand then to fine-tune with limited in vivo data. We show that with as little as\n19 in vivo images, fine-tuning the pre-trained network improves the dice score\nby 21% compared to training from scratch. We also demonstrate that if the same\nnumber of natural and simulation US images is available, pre-training on\nsimulation data is preferable.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:34:42 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Behboodi", "Bahareh", ""], ["Amiri", "Mina", ""], ["Brooks", "Rupert", ""], ["Rivaz", "Hassan", ""]]}, {"id": "2001.07342", "submitter": "Natarajan Subramanyam", "authors": "Rajath S, Sumukh Aithal K, Natarajan Subramanyam", "title": "Transfer Learning using Neural Ordinary Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A concept of using Neural Ordinary Differential Equations(NODE) for Transfer\nLearning has been introduced. In this paper we use the EfficientNets to explore\ntransfer learning on CIFAR-10 dataset. We use NODE for fine-tuning our model.\nUsing NODE for fine tuning provides more stability during training and\nvalidation.These continuous depth blocks can also have a trade off between\nnumerical precision and speed .Using Neural ODEs for transfer learning has\nresulted in much stable convergence of the loss function.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 04:59:08 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["S", "Rajath", ""], ["K", "Sumukh Aithal", ""], ["Subramanyam", "Natarajan", ""]]}, {"id": "2001.07343", "submitter": "Colin Summers", "authors": "Colin Summers, Kendall Lowrey, Aravind Rajeswaran, Siddhartha\n  Srinivasa, Emanuel Todorov", "title": "Lyceum: An efficient and scalable ecosystem for robot learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Lyceum, a high-performance computational ecosystem for robot\nlearning. Lyceum is built on top of the Julia programming language and the\nMuJoCo physics simulator, combining the ease-of-use of a high-level programming\nlanguage with the performance of native C. In addition, Lyceum has a\nstraightforward API to support parallel computation across multiple cores and\nmachines. Overall, depending on the complexity of the environment, Lyceum is\n5-30x faster compared to other popular abstractions like OpenAI's Gym and\nDeepMind's dm-control. This substantially reduces training time for various\nreinforcement learning algorithms; and is also fast enough to support real-time\nmodel predictive control through MuJoCo. The code, tutorials, and demonstration\nvideos can be found at: www.lyceum.ml.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 05:03:04 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Summers", "Colin", ""], ["Lowrey", "Kendall", ""], ["Rajeswaran", "Aravind", ""], ["Srinivasa", "Siddhartha", ""], ["Todorov", "Emanuel", ""]]}, {"id": "2001.07384", "submitter": "Jinlong Liu", "authors": "Jinlong Liu, Guoqing Jiang, Yunzhi Bai, Ting Chen, Huayan Wang", "title": "Understanding Why Neural Networks Generalize Well Through GSNR of\n  Parameters", "comments": "14 pages, 8 figures, ICLR2020 accepted as spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As deep neural networks (DNNs) achieve tremendous success across many\napplication domains, researchers tried to explore in many aspects on why they\ngeneralize well. In this paper, we provide a novel perspective on these issues\nusing the gradient signal to noise ratio (GSNR) of parameters during training\nprocess of DNNs. The GSNR of a parameter is defined as the ratio between its\ngradient's squared mean and variance, over the data distribution. Based on\nseveral approximations, we establish a quantitative relationship between model\nparameters' GSNR and the generalization gap. This relationship indicates that\nlarger GSNR during training process leads to better generalization performance.\nMoreover, we show that, different from that of shallow models (e.g. logistic\nregression, support vector machines), the gradient descent optimization\ndynamics of DNNs naturally produces large GSNR during training, which is\nprobably the key to DNNs' remarkable generalization ability.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 08:33:29 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 10:47:39 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liu", "Jinlong", ""], ["Jiang", "Guoqing", ""], ["Bai", "Yunzhi", ""], ["Chen", "Ting", ""], ["Wang", "Huayan", ""]]}, {"id": "2001.07394", "submitter": "Lukas Fr\\\"ohlich", "authors": "Lukas P. Fr\\\"ohlich, Edgar D. Klenske, Christian G. Daniel, Melanie N.\n  Zeilinger", "title": "Bayesian Optimization for Policy Search in High-Dimensional Systems via\n  Automatic Domain Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is an effective method for optimizing\nexpensive-to-evaluate black-box functions with a wide range of applications for\nexample in robotics, system design and parameter optimization. However, scaling\nBO to problems with large input dimensions (>10) remains an open challenge. In\nthis paper, we propose to leverage results from optimal control to scale BO to\nhigher dimensional control tasks and to reduce the need for manually selecting\nthe optimization domain. The contributions of this paper are twofold: 1) We\nshow how we can make use of a learned dynamics model in combination with a\nmodel-based controller to simplify the BO problem by focusing onto the most\nrelevant regions of the optimization domain. 2) Based on (1) we present a\nmethod to find an embedding in parameter space that reduces the effective\ndimensionality of the optimization problem. To evaluate the effectiveness of\nthe proposed approach, we present an experimental evaluation on real hardware,\nas well as simulated tasks including a 48-dimensional policy for a quadcopter.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:04:15 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Fr\u00f6hlich", "Lukas P.", ""], ["Klenske", "Edgar D.", ""], ["Daniel", "Christian G.", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "2001.07402", "submitter": "Daniele Gammelli", "authors": "Daniele Gammelli, Inon Peled, Filipe Rodrigues, Dario Pacino, Haci A.\n  Kurtaran, Francisco C. Pereira", "title": "Estimating Latent Demand of Shared Mobility through Censored Gaussian\n  Processes", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transport demand is highly dependent on supply, especially for shared\ntransport services where availability is often limited. As observed demand\ncannot be higher than available supply, historical transport data typically\nrepresents a biased, or censored, version of the true underlying demand\npattern. Without explicitly accounting for this inherent distinction,\npredictive models of demand would necessarily represent a biased version of\ntrue demand, thus less effectively predicting the needs of service users. To\ncounter this problem, we propose a general method for censorship-aware demand\nmodeling, for which we devise a censored likelihood function. We apply this\nmethod to the task of shared mobility demand prediction by incorporating the\ncensored likelihood within a Gaussian Process model, which can flexibly\napproximate arbitrary functional forms. Experiments on artificial and\nreal-world datasets show how taking into account the limiting effect of supply\non demand is essential in the process of obtaining an unbiased predictive model\nof user demand behavior.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:26:16 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 12:09:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gammelli", "Daniele", ""], ["Peled", "Inon", ""], ["Rodrigues", "Filipe", ""], ["Pacino", "Dario", ""], ["Kurtaran", "Haci A.", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2001.07415", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on", "title": "Explicit agreement extremes for a $2\\times2$ table with given marginals", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of maximizing (or minimizing) the agreement between clusterings,\nsubject to given marginals, can be formally posed under a common framework for\nseveral agreement measures. Until now, it was possible to find its solution\nonly through numerical algorithms. Here, an explicit solution is shown for the\ncase where the two clusterings have two clusters each.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:47:57 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""]]}, {"id": "2001.07416", "submitter": "Kaixuan Chen", "authors": "Kaixuan Chen, Dalin Zhang, Lina Yao, Bin Guo, Zhiwen Yu, Yunhao Liu", "title": "Deep Learning for Sensor-based Human Activity Recognition: Overview,\n  Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast proliferation of sensor devices and Internet of Things enables the\napplications of sensor-based activity recognition. However, there exist\nsubstantial challenges that could influence the performance of the recognition\nsystem in practical scenarios. Recently, as deep learning has demonstrated its\neffectiveness in many areas, plenty of deep methods have been investigated to\naddress the challenges in activity recognition. In this study, we present a\nsurvey of the state-of-the-art deep learning methods for sensor-based human\nactivity recognition. We first introduce the multi-modality of the sensory data\nand provide information for public datasets that can be used for evaluation in\ndifferent challenge tasks. We then propose a new taxonomy to structure the deep\nmethods by challenges. Challenges and challenge-related deep methods are\nsummarized and analyzed to form an overview of the current research progress.\nAt the end of this work, we discuss the open issues and provide some insights\nfor future directions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:55:59 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 14:27:27 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Chen", "Kaixuan", ""], ["Zhang", "Dalin", ""], ["Yao", "Lina", ""], ["Guo", "Bin", ""], ["Yu", "Zhiwen", ""], ["Liu", "Yunhao", ""]]}, {"id": "2001.07417", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia, Foster Provost, Xintian Han", "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine counterfactual explanations for explaining the decisions made by\nmodel-based AI systems. The counterfactual approach we consider defines an\nexplanation as a set of the system's data inputs that causally drives the\ndecision (i.e., changing the inputs in the set changes the decision) and is\nirreducible (i.e., changing any subset of the inputs does not change the\ndecision). We (1) demonstrate how this framework may be used to provide\nexplanations for decisions made by general, data-driven AI systems that may\nincorporate features with arbitrary data types and multiple predictive models,\nand (2) propose a heuristic procedure to find the most useful explanations\ndepending on the context. We then contrast counterfactual explanations with\nmethods that explain model predictions by weighting features according to their\nimportance (e.g., SHAP, LIME) and present two fundamental reasons why we should\ncarefully consider whether importance-weight explanations are well-suited to\nexplain system decisions. Specifically, we show that (i) features that have a\nlarge importance weight for a model prediction may not affect the corresponding\ndecision, and (ii) importance weights are insufficient to communicate whether\nand how features influence decisions. We demonstrate this with several concise\nexamples and three detailed case studies that compare the counterfactual\napproach with SHAP to illustrate various conditions under which counterfactual\nexplanations explain data-driven decisions better than importance weights.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 09:58:58 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 13:28:14 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 03:30:11 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 21:52:22 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""], ["Han", "Xintian", ""]]}, {"id": "2001.07426", "submitter": "Fredrik D. Johansson", "authors": "Fredrik D. Johansson, Uri Shalit, Nathan Kallus, David Sontag", "title": "Generalization Bounds and Representation Learning for Estimation of\n  Potential Outcomes and Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners in diverse fields such as healthcare, economics and education\nare eager to apply machine learning to improve decision making. The cost and\nimpracticality of performing experiments and a recent monumental increase in\nelectronic record keeping has brought attention to the problem of evaluating\ndecisions based on non-experimental observational data. This is the setting of\nthis work. In particular, we study estimation of individual-level causal\neffects, such as a single patient's response to alternative medication, from\nrecorded contexts, decisions and outcomes. We give generalization bounds on the\nerror in estimated effects based on distance measures between groups receiving\ndifferent treatments, allowing for sample re-weighting. We provide conditions\nunder which our bound is tight and show how it relates to results for\nunsupervised domain adaptation. Led by our theoretical results, we devise\nrepresentation learning algorithms that minimize our bound, by regularizing the\nrepresentation's induced treatment group distance, and encourage sharing of\ninformation between treatment groups. We extend these algorithms to\nsimultaneously learn a weighted representation to further reduce treatment\ngroup distances. Finally, an experimental evaluation on real and synthetic data\nshows the value of our proposed representation architecture and regularization\nscheme.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 10:16:33 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 09:21:02 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Johansson", "Fredrik D.", ""], ["Shalit", "Uri", ""], ["Kallus", "Nathan", ""], ["Sontag", "David", ""]]}, {"id": "2001.07437", "submitter": "Hyunjung Shim Dr.", "authors": "Junsuk Choe, Seong Joon Oh, Seungho Lee, Sanghyuk Chun, Zeynep Akata,\n  Hyunjung Shim", "title": "Evaluating Weakly Supervised Object Localization Methods Right", "comments": "CVPR 2020 camera-ready. First two authors contributed equally. Code:\n  https://github.com/clovaai/wsolevaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised object localization (WSOL) has gained popularity over the\nlast years for its promise to train localization models with only image-level\nlabels. Since the seminal WSOL work of class activation mapping (CAM), the\nfield has focused on how to expand the attention regions to cover objects more\nbroadly and localize them better. However, these strategies rely on full\nlocalization supervision to validate hyperparameters and for model selection,\nwhich is in principle prohibited under the WSOL setup. In this paper, we argue\nthat WSOL task is ill-posed with only image-level labels, and propose a new\nevaluation protocol where full supervision is limited to only a small held-out\nset not overlapping with the test set. We observe that, under our protocol, the\nfive most recent WSOL methods have not made a major improvement over the CAM\nbaseline. Moreover, we report that existing WSOL methods have not reached the\nfew-shot learning baseline, where the full-supervision at validation time is\nused for model training instead. Based on our findings, we discuss some future\ndirections for WSOL.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 10:50:06 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 05:35:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Choe", "Junsuk", ""], ["Oh", "Seong Joon", ""], ["Lee", "Seungho", ""], ["Chun", "Sanghyuk", ""], ["Akata", "Zeynep", ""], ["Shim", "Hyunjung", ""]]}, {"id": "2001.07442", "submitter": "Xiaofu Wu Dr", "authors": "Ben Xie, Xiaofu Wu, Suofei Zhang, Shiliang Zhao, Ming Li", "title": "Learning Diverse Features with Part-Level Resolution for Person\n  Re-Identification", "comments": "8 pages, 5 figures, submitted to IEEE TCSVT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning diverse features is key to the success of person re-identification.\nVarious part-based methods have been extensively proposed for learning local\nrepresentations, which, however, are still inferior to the best-performing\nmethods for person re-identification. This paper proposes to construct a strong\nlightweight network architecture, termed PLR-OSNet, based on the idea of\nPart-Level feature Resolution over the Omni-Scale Network (OSNet) for achieving\nfeature diversity. The proposed PLR-OSNet has two branches, one branch for\nglobal feature representation and the other branch for local feature\nrepresentation. The local branch employs a uniform partition strategy for\npart-level feature resolution but produces only a single identity-prediction\nloss, which is in sharp contrast to the existing part-based methods. Empirical\nevidence demonstrates that the proposed PLR-OSNet achieves state-of-the-art\nperformance on popular person Re-ID datasets, including Market1501,\nDukeMTMC-reID and CUHK03, despite its small model size.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:01:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Xie", "Ben", ""], ["Wu", "Xiaofu", ""], ["Zhang", "Suofei", ""], ["Zhao", "Shiliang", ""], ["Li", "Ming", ""]]}, {"id": "2001.07455", "submitter": "Martin Lindvall", "authors": "Martin Lindvall and Jesper Molin", "title": "Designing for the Long Tail of Machine Learning", "comments": "Accepted for presentation in poster format for the ACM CHI'19\n  Workshop <Emerging Perspectives in Human-Centered Machine Learning>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technical advances has made machine learning (ML) a promising\ncomponent to include in end user facing systems. However, user experience (UX)\npractitioners face challenges in relating ML to existing user-centered design\nprocesses and how to navigate the possibilities and constraints of this design\nspace. Drawing on our own experience, we characterize designing within this\nspace as navigating trade-offs between data gathering, model development and\ndesigning valuable interactions for a given model performance. We suggest that\nthe theoretical description of how machine learning performance scales with\ntraining data can guide designers in these trade-offs as well as having\nimplications for prototyping. We exemplify the learning curve's usage by\narguing that a useful pattern is to design an initial system in a bootstrap\nphase that aims to exploit the training effect of data collected at increasing\norders of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:53:28 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Lindvall", "Martin", ""], ["Molin", "Jesper", ""]]}, {"id": "2001.07457", "submitter": "Philipp Holl", "authors": "Philipp Holl, Vladlen Koltun, Nils Thuerey", "title": "Learning to Control PDEs with Differentiable Physics", "comments": "Published as a conference paper at ICLR 2020. Main text: 10 pages, 6\n  figures, 3 tables. Total: 28 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting outcomes and planning interactions with the physical world are\nlong-standing goals for machine learning. A variety of such tasks involves\ncontinuous physical systems, which can be described by partial differential\nequations (PDEs) with many degrees of freedom. Existing methods that aim to\ncontrol the dynamics of such systems are typically limited to relatively short\ntime frames or a small number of interaction parameters. We present a novel\nhierarchical predictor-corrector scheme which enables neural networks to learn\nto understand and control complex nonlinear physical systems over long time\nframes. We propose to split the problem into two distinct tasks: planning and\ncontrol. To this end, we introduce a predictor network that plans optimal\ntrajectories and a control network that infers the corresponding control\nparameters. Both stages are trained end-to-end using a differentiable PDE\nsolver. We demonstrate that our method successfully develops an understanding\nof complex physical systems and learns to control them for tasks involving PDEs\nsuch as the incompressible Navier-Stokes equations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:58:41 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Holl", "Philipp", ""], ["Koltun", "Vladlen", ""], ["Thuerey", "Nils", ""]]}, {"id": "2001.07463", "submitter": "Benedek Rozemberczki", "authors": "Benedek Rozemberczki and Rik Sarkar", "title": "Fast Sequence-Based Embedding with Diffusion Graphs", "comments": "Source code available at:\n  https://github.com/benedekrozemberczki/diff2vec", "journal-ref": "CompleNet 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SI stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A graph embedding is a representation of graph vertices in a low-dimensional\nspace, which approximately preserves properties such as distances between\nnodes. Vertex sequence-based embedding procedures use features extracted from\nlinear sequences of nodes to create embeddings using a neural network. In this\npaper, we propose diffusion graphs as a method to rapidly generate vertex\nsequences for network embedding. Its computational efficiency is superior to\nprevious methods due to simpler sequence generation, and it produces more\naccurate results. In experiments, we found that the performance relative to\nother methods improves with increasing edge density in the graph. In a\ncommunity detection task, clustering nodes in the embedding space produces\nbetter results compared to other sequence-based embedding methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:04:21 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rozemberczki", "Benedek", ""], ["Sarkar", "Rik", ""]]}, {"id": "2001.07464", "submitter": "Andreas Buchberger", "authors": "Andreas Buchberger, Christian H\\\"ager, Henry D. Pfister, Laurent\n  Schmalen, Alexandre Graell i Amat", "title": "Pruning Neural Belief Propagation Decoders", "comments": "This work was presented at the IEEE International Symposium on\n  Information Theory (ISIT) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider near maximum-likelihood (ML) decoding of short linear block codes\nbased on neural belief propagation (BP) decoding recently introduced by\nNachmani et al.. While this method significantly outperforms conventional BP\ndecoding, the underlying parity-check matrix may still limit the overall\nperformance. In this paper, we introduce a method to tailor an overcomplete\nparity-check matrix to (neural) BP decoding using machine learning. We consider\nthe weights in the Tanner graph as an indication of the importance of the\nconnected check nodes (CNs) to decoding and use them to prune unimportant CNs.\nAs the pruning is not tied over iterations, the final decoder uses a different\nparity-check matrix in each iteration. For Reed-Muller and short low-density\nparity-check codes, we achieve performance within 0.27 dB and 1.5 dB of the ML\nperformance while reducing the complexity of the decoder.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:05:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:40:04 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Buchberger", "Andreas", ""], ["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""], ["Schmalen", "Laurent", ""], ["Amat", "Alexandre Graell i", ""]]}, {"id": "2001.07493", "submitter": "Artem Ryzhikov", "authors": "Artem Ryzhikov, Denis Derkach, Mikhail Hushchyn", "title": "Variational Dropout Sparsification for Particle Identification speed-up", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012099", "report-no": null, "categories": "physics.data-an cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate particle identification (PID) is one of the most important aspects\nof the LHCb experiment. Modern machine learning techniques such as neural\nnetworks (NNs) are efficiently applied to this problem and are integrated into\nthe LHCb software. In this research, we discuss novel applications of neural\nnetwork speed-up techniques to achieve faster PID in LHC upgrade conditions. We\nshow that the best results are obtained using variational dropout\nsparsification, which provides a prediction (feedforward pass) speed increase\nof up to a factor of sixteen even when compared to a model with shallow\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:02:49 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Ryzhikov", "Artem", ""], ["Derkach", "Denis", ""], ["Hushchyn", "Mikhail", ""]]}, {"id": "2001.07495", "submitter": "Daniel Nissani", "authors": "Daniel N. Nissani (Nissensohn)", "title": "Unsupervisedly Learned Representations: Should the Quest be Over?", "comments": "To be published at The 6th International Conference on Machine\n  Learning, Optimization and Data Science - LOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a Classification accuracy gap of about 20% between our best\nmethods of generating Unsupervisedly Learned Representations and the accuracy\nrates achieved by (naturally Unsupervisedly Learning) humans. We are at our\nfourth decade at least in search of this class of paradigms. It thus may well\nbe that we are looking in the wrong direction. We present in this paper a\npossible solution to this puzzle. We demonstrate that Reinforcement Learning\nschemes can learn representations, which may be used for Pattern Recognition\ntasks such as Classification, achieving practically the same accuracy as that\nof humans. Our main modest contribution lies in the observations that: a. when\napplied to a real world environment (e.g. nature itself) Reinforcement Learning\ndoes not require labels, and thus may be considered a natural candidate for the\nlong sought, accuracy competitive Unsupervised Learning method, and b. in\ncontrast, when Reinforcement Learning is applied in a simulated or symbolic\nprocessing environment (e.g. a computer program) it does inherently require\nlabels and should thus be generally classified, with some exceptions, as\nSupervised Learning. The corollary of these observations is that further search\nfor Unsupervised Learning competitive paradigms which may be trained in\nsimulated environments like many of those found in research and applications\nmay be futile.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:05:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 07:52:59 GMT"}, {"version": "v3", "created": "Sun, 26 Jul 2020 08:14:00 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nissani", "Daniel N.", "", "Nissensohn"]]}, {"id": "2001.07501", "submitter": "Wen Wang", "authors": "Wen Wang, Xiaojiang Peng, Yu Qiao, Jian Cheng", "title": "A Comprehensive Study on Temporal Modeling for Online Action Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online action detection (OAD) is a practical yet challenging task, which has\nattracted increasing attention in recent years. A typical OAD system mainly\nconsists of three modules: a frame-level feature extractor which is usually\nbased on pre-trained deep Convolutional Neural Networks (CNNs), a temporal\nmodeling module, and an action classifier. Among them, the temporal modeling\nmodule is crucial which aggregates discriminative information from historical\nand current features. Though many temporal modeling methods have been developed\nfor OAD and other topics, their effects are lack of investigation on OAD\nfairly. This paper aims to provide a comprehensive study on temporal modeling\nfor OAD including four meta types of temporal modeling methods, \\ie temporal\npooling, temporal convolution, recurrent neural networks, and temporal\nattention, and uncover some good practices to produce a state-of-the-art OAD\nsystem. Many of them are explored in OAD for the first time, and extensively\nevaluated with various hyper parameters. Furthermore, based on our\ncomprehensive study, we present several hybrid temporal modeling methods, which\noutperform the recent state-of-the-art methods with sizable margins on\nTHUMOS-14 and TVSeries.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:12:58 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Wang", "Wen", ""], ["Peng", "Xiaojiang", ""], ["Qiao", "Yu", ""], ["Cheng", "Jian", ""]]}, {"id": "2001.07522", "submitter": "Jan Bosch", "authors": "Jan Bosch, Ivica Crnkovic, Helena Holmstr\\\"om Olsson", "title": "Engineering AI Systems: A Research Agenda", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) and machine learning (ML) are increasingly\nbroadly adopted in industry, However, based on well over a dozen case studies,\nwe have learned that deploying industry-strength, production quality ML models\nin systems proves to be challenging. Companies experience challenges related to\ndata quality, design methods and processes, performance of models as well as\ndeployment and compliance. We learned that a new, structured engineering\napproach is required to construct and evolve systems that contain ML/DL\ncomponents. In this paper, we provide a conceptualization of the typical\nevolution patterns that companies experience when employing ML as well as an\noverview of the key problems experienced by the companies that we have studied.\nThe main contribution of the paper is a research agenda for AI engineering that\nprovides an overview of the key engineering challenges surrounding ML solutions\nand an overview of open items that need to be addressed by the research\ncommunity at large.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:29:48 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 12:59:36 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Bosch", "Jan", ""], ["Crnkovic", "Ivica", ""], ["Olsson", "Helena Holmstr\u00f6m", ""]]}, {"id": "2001.07523", "submitter": "Nick Dexter", "authors": "Ben Adcock and Nick Dexter", "title": "The gap between theory and practice in function approximation with deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) is transforming industry as decision-making processes are\nbeing automated by deep neural networks (DNNs) trained on real-world data.\nDriven partly by rapidly-expanding literature on DNN approximation theory\nshowing they can approximate a rich variety of functions, such tools are\nincreasingly being considered for problems in scientific computing. Yet, unlike\ntraditional algorithms in this field, little is known about DNNs from the\nprinciples of numerical analysis, e.g., stability, accuracy, computational\nefficiency and sample complexity. In this paper we introduce a computational\nframework for examining DNNs in practice, and use it to study empirical\nperformance with regard to these issues. We study performance of DNNs of\ndifferent widths & depths on test functions in various dimensions, including\nsmooth and piecewise smooth functions. We also compare DL against best-in-class\nmethods for smooth function approx. based on compressed sensing (CS). Our main\nconclusion from these experiments is that there is a crucial gap between the\napproximation theory of DNNs and their practical performance, with trained DNNs\nperforming relatively poorly on functions for which there are strong\napproximation results (e.g. smooth functions), yet performing well in\ncomparison to best-in-class methods for other functions. To analyze this gap\nfurther, we provide some theoretical insights. We establish a practical\nexistence theorem, asserting existence of a DNN architecture and training\nprocedure that offers the same performance as CS. This establishes a key\ntheoretical benchmark, showing the gap can be closed, albeit via a strategy\nguaranteed to perform as well as, but no better than, current best-in-class\nschemes. Nevertheless, it demonstrates the promise of practical DNN approx., by\nhighlighting potential for better schemes through careful design of DNN\narchitectures and training strategies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:08:56 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 00:23:46 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 23:42:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Adcock", "Ben", ""], ["Dexter", "Nick", ""]]}, {"id": "2001.07524", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Aleksandra Piktus, Gerard Goossen, Fabrizio Silvestri", "title": "Node Masking: Making Graph Neural Networks Generalize and Scale Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have received a lot of interest in the recent\ntimes. From the early spectral architectures that could only operate on\nundirected graphs per a transductive learning paradigm to the current state of\nthe art spatial ones that can apply inductively to arbitrary graphs, GNNs have\nseen significant contributions from the research community. In this paper, we\nutilize some theoretical tools to better visualize the operations performed by\nstate of the art spatial GNNs. We analyze the inner workings of these\narchitectures and introduce a simple concept, Node Masking, that allows them to\ngeneralize and scale better. To empirically validate the concept, we perform\nseveral experiments on some widely-used datasets for node classification in\nboth the transductive and inductive settings, hence laying down strong\nbenchmarks for future research.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 06:26:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 10:14:08 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 12:40:50 GMT"}, {"version": "v4", "created": "Sun, 16 May 2021 19:40:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mishra", "Pushkar", ""], ["Piktus", "Aleksandra", ""], ["Goossen", "Gerard", ""], ["Silvestri", "Fabrizio", ""]]}, {"id": "2001.07527", "submitter": "Eugenio Bargiacchi", "authors": "Eugenio Bargiacchi, Timothy Verstraeten, Diederik M. Roijers, Ann\n  Now\\'e", "title": "Model-based Multi-Agent Reinforcement Learning with Cooperative\n  Prioritized Sweeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model-based reinforcement learning algorithm, Cooperative\nPrioritized Sweeping, for efficient learning in multi-agent Markov decision\nprocesses. The algorithm allows for sample-efficient learning on large problems\nby exploiting a factorization to approximate the value function. Our approach\nonly requires knowledge about the structure of the problem in the form of a\ndynamic decision network. Using this information, our method learns a model of\nthe environment and performs temporal difference updates which affect multiple\njoint states and actions at once. Batch updates are additionally performed\nwhich efficiently back-propagate knowledge throughout the factored Q-function.\nOur method outperforms the state-of-the-art algorithm sparse cooperative\nQ-learning algorithm, both on the well-known SysAdmin benchmark and randomized\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:13:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bargiacchi", "Eugenio", ""], ["Verstraeten", "Timothy", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.07553", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Jo\\~ao E. Batista, Sara Silva", "title": "Ensemble Genetic Programming", "comments": "eurogp 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a powerful paradigm that has been usedin the top\nstate-of-the-art machine learning methods like Random Forestsand XGBoost.\nInspired by the success of such methods, we have devel-oped a new Genetic\nProgramming method called Ensemble GP. The evo-lutionary cycle of Ensemble GP\nfollows the same steps as other GeneticProgramming systems, but with\ndifferences in the population structure,fitness evaluation and genetic\noperators. We have tested this method oneight binary classification problems,\nachieving results significantly betterthan standard GP, with much smaller\nmodels. Although other methodslike M3GP and XGBoost were the best overall,\nEnsemble GP was able toachieve exceptionally good generalization results on a\nparticularly hardproblem where none of the other methods was able to succeed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:10:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Batista", "Jo\u00e3o E.", ""], ["Silva", "Sara", ""]]}, {"id": "2001.07558", "submitter": "Tiphaine Viard", "authors": "Tiphaine Viard, Thomas McLachlan, Hamidreza Ghader, Satoshi Sekine", "title": "Classifying Wikipedia in a fine-grained hierarchy: what graphs can\n  contribute", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is a huge opportunity for machine learning, being the largest\nsemi-structured base of knowledge available. Because of this, many works\nexamine its contents, and focus on structuring it in order to make it usable in\nlearning tasks, for example by classifying it into an ontology. Beyond its\ntextual contents, Wikipedia also displays a typical graph structure, where\npages are linked together through citations. In this paper, we address the task\nof integrating graph (i.e. structure) information to classify Wikipedia into a\nfine-grained named entity ontology (NE), the Extended Named Entity hierarchy.\nTo address this task, we first start by assessing the relevance of the graph\nstructure for NE classification. We then explore two directions, one related to\nfeature vectors using graph descriptors commonly used in large-scale network\nanalysis, and one extending flat classification to a weighted model taking into\naccount semantic similarity. We conduct at-scale practical experiments, on a\nmanually labeled subset of 22,000 pages extracted from the Japanese Wikipedia.\nOur results show that integrating graph information succeeds at reducing\nsparsity of the input feature space, and yields classification results that are\ncomparable or better than previous works.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:19:49 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 08:24:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Viard", "Tiphaine", ""], ["McLachlan", "Thomas", ""], ["Ghader", "Hamidreza", ""], ["Sekine", "Satoshi", ""]]}, {"id": "2001.07569", "submitter": "Luca Benedetto", "authors": "Luca Benedetto, Andrea Cappelli, Roberto Turrin, Paolo Cremonesi", "title": "R2DE: a NLP approach to estimating IRT parameters of newly generated\n  questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of exams consists in performing an assessment of students'\nexpertise on a specific subject. Such expertise, also referred to as skill or\nknowledge level, can then be leveraged in different ways (e.g., to assign a\ngrade to the students, to understand whether a student might need some support,\netc.). Similarly, the questions appearing in the exams have to be assessed in\nsome way before being used to evaluate students. Standard approaches to\nquestions' assessment are either subjective (e.g., assessment by human experts)\nor introduce a long delay in the process of question generation (e.g.,\npretesting with real students). In this work we introduce R2DE (which is a\nRegressor for Difficulty and Discrimination Estimation), a model capable of\nassessing newly generated multiple-choice questions by looking at the text of\nthe question and the text of the possible choices. In particular, it can\nestimate the difficulty and the discrimination of each question, as they are\ndefined in Item Response Theory. We also present the results of extensive\nexperiments we carried out on a real world large scale dataset coming from an\ne-learning platform, showing that our model can be used to perform an initial\nassessment of newly created questions and ease some of the problems that arise\nin question generation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:31:01 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Benedetto", "Luca", ""], ["Cappelli", "Andrea", ""], ["Turrin", "Roberto", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2001.07575", "submitter": "Iman Marivani", "authors": "Iman Marivani, Evaggelia Tsiligianni, Bruno Cornelis and Nikos\n  Deligiannis", "title": "Multimodal Deep Unfolding for Guided Image Super-Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction of a high resolution image given a low resolution\nobservation is an ill-posed inverse problem in imaging. Deep learning methods\nrely on training data to learn an end-to-end mapping from a low-resolution\ninput to a high-resolution output. Unlike existing deep multimodal models that\ndo not incorporate domain knowledge about the problem, we propose a multimodal\ndeep learning design that incorporates sparse priors and allows the effective\nintegration of information from another image modality into the network\narchitecture. Our solution relies on a novel deep unfolding operator,\nperforming steps similar to an iterative algorithm for convolutional sparse\ncoding with side information; therefore, the proposed neural network is\ninterpretable by design. The deep unfolding architecture is used as a core\ncomponent of a multimodal framework for guided image super-resolution. An\nalternative multimodal design is investigated by employing residual learning to\nimprove the training efficiency. The presented multimodal approach is applied\nto super-resolution of near-infrared and multi-spectral images as well as depth\nupsampling using RGB images as side information. Experimental results show that\nour model outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:41:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Marivani", "Iman", ""], ["Tsiligianni", "Evaggelia", ""], ["Cornelis", "Bruno", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2001.07582", "submitter": "Yadong Zhang", "authors": "Yadong Zhang and Xin Chen", "title": "Motif Difference Field: A Simple and Effective Image Representation of\n  Time Series for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series motifs play an important role in the time series analysis. The\nmotif-based time series clustering is used for the discovery of higher-order\npatterns or structures in time series data. Inspired by the convolutional\nneural network (CNN) classifier based on the image representations of time\nseries, motif difference field (MDF) is proposed. Compared to other image\nrepresentations of time series, MDF is simple and easy to construct. With the\nFully Convolution Network (FCN) as the classifier, MDF demonstrates the\nsuperior performance on the UCR time series dataset in benchmark with other\ntime series classification methods. It is interesting to find that the triadic\ntime series motifs give the best result in the test. Due to the motif\nclustering reflected in MDF, the significant motifs are detected with the help\nof the Gradient-weighted Class Activation Mapping (Grad-CAM). The areas in MDF\nwith high weight in Grad-CAM have a high contribution from the significant\nmotifs with the desired ordinal patterns associated with the signature patterns\nin time series. However, the signature patterns cannot be identified with the\nneural network classifiers directly based on the time series.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:48:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhang", "Yadong", ""], ["Chen", "Xin", ""]]}, {"id": "2001.07607", "submitter": "Timothy LaRock", "authors": "Timothy LaRock, Timothy Sakharov, Sahely Bhadra, Tina Eliassi-Rad", "title": "Understanding the Limitations of Network Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies of networked phenomena, such as interactions in online social media,\noften rely on incomplete data, either because these phenomena are partially\nobserved, or because the data is too large or expensive to acquire all at once.\nAnalysis of incomplete data leads to skewed or misleading results. In this\npaper, we investigate limitations of learning to complete partially observed\nnetworks via node querying. Concretely, we study the following problem: given\n(i) a partially observed network, (ii) the ability to query nodes for their\nconnections (e.g., by accessing an API), and (iii) a budget on the number of\nsuch queries, sequentially learn which nodes to query in order to maximally\nincrease observability. We call this querying process Network Online Learning\nand present a family of algorithms called NOL*. These algorithms learn to\nchoose which partially observed node to query next based on a parameterized\nmodel that is trained online through a process of exploration and exploitation.\nExtensive experiments on both synthetic and real world networks show that (i)\nit is possible to sequentially learn to choose which nodes are best to query in\na network and (ii) some macroscopic properties of networks, such as the degree\ndistribution and modular structure, impact the potential for learning and the\noptimal amount of random exploration.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:59:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["LaRock", "Timothy", ""], ["Sakharov", "Timothy", ""], ["Bhadra", "Sahely", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "2001.07608", "submitter": "Mark Chilenski", "authors": "Mark Chilenski, George Cybenko, Isaac Dekine, Piyush Kumar, Gil Raz", "title": "Analytic Properties of Trackable Weak Models", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several new results on the feasibility of inferring the hidden\nstates in strongly-connected trackable weak models. Here, a weak model is a\ndirected graph in which each node is assigned a set of colors which may be\nemitted when that node is visited. A hypothesis is a node sequence which is\nconsistent with a given color sequence. A weak model is said to be trackable if\nthe worst case number of such hypotheses grows as a polynomial in the sequence\nlength. We show that the number of hypotheses in strongly-connected trackable\nmodels is bounded by a constant and give an expression for this constant. We\nalso consider the problem of reconstructing which branch was taken at a node\nwith same-colored out-neighbors, and show that it is always eventually possible\nto identify which branch was taken if the model is strongly connected and\ntrackable. We illustrate these properties by assigning transition probabilities\nand employing standard tools for analyzing Markov chains. In addition, we\npresent new results for the entropy rates of weak models according to whether\nthey are trackable or not. These theorems indicate that the combination of\ntrackability and strong connectivity dramatically simplifies the task of\nreconstructing which nodes were visited. This work has implications for any\nproblem which can be described in terms of an agent traversing a colored graph,\nsuch as the reconstruction of hidden states in a hidden Markov model (HMM).\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 15:54:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chilenski", "Mark", ""], ["Cybenko", "George", ""], ["Dekine", "Isaac", ""], ["Kumar", "Piyush", ""], ["Raz", "Gil", ""]]}, {"id": "2001.07613", "submitter": "Kyoung-Woon On", "authors": "Kyoung-Woon On, Eun-Sol Kim, Yu-Jung Heo and Byoung-Tak Zhang", "title": "Cut-Based Graph Learning Networks to Discover Compositional Structure of\n  Sequential Video Data", "comments": "8 pages, 3 figures, Association for the Advancement of Artificial\n  Intelligence (AAAI2020). arXiv admin note: substantial text overlap with\n  arXiv:1907.01709", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional sequential learning methods such as Recurrent Neural Networks\n(RNNs) focus on interactions between consecutive inputs, i.e. first-order\nMarkovian dependency. However, most of sequential data, as seen with videos,\nhave complex dependency structures that imply variable-length semantic flows\nand their compositions, and those are hard to be captured by conventional\nmethods. Here, we propose Cut-Based Graph Learning Networks (CB-GLNs) for\nlearning video data by discovering these complex structures of the video. The\nCB-GLNs represent video data as a graph, with nodes and edges corresponding to\nframes of the video and their dependencies respectively. The CB-GLNs find\ncompositional dependencies of the data in multilevel graph forms via a\nparameterized kernel with graph-cut and a message passing framework. We\nevaluate the proposed method on the two different tasks for video\nunderstanding: Video theme classification (Youtube-8M dataset) and Video\nQuestion and Answering (TVQA dataset). The experimental results show that our\nmodel efficiently learns the semantic compositional structure of video data.\nFurthermore, our model achieves the highest performance in comparison to other\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 10:09:24 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["On", "Kyoung-Woon", ""], ["Kim", "Eun-Sol", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2001.07614", "submitter": "Guillaume Salha", "authors": "Guillaume Salha, Romain Hennequin, Michalis Vazirgiannis", "title": "Simple and Effective Graph Autoencoders with One-Hop Linear Models", "comments": "Accepted at ECML-PKDD 2020. A preliminary version of this work has\n  previously been presented at the NeurIPS 2019 workshop on Graph\n  Representation Learning: arXiv:1910.00942", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, graph autoencoders (AE) and variational autoencoders\n(VAE) emerged as powerful node embedding methods, with promising performances\non challenging tasks such as link prediction and node clustering. Graph AE, VAE\nand most of their extensions rely on multi-layer graph convolutional networks\n(GCN) encoders to learn vector space representations of nodes. In this paper,\nwe show that GCN encoders are actually unnecessarily complex for many\napplications. We propose to replace them by significantly simpler and more\ninterpretable linear models w.r.t. the direct neighborhood (one-hop) adjacency\nmatrix of the graph, involving fewer operations, fewer parameters and no\nactivation function. For the two aforementioned tasks, we show that this\nsimpler approach consistently reaches competitive performances w.r.t. GCN-based\ngraph AE and VAE for numerous real-world graphs, including all benchmark\ndatasets commonly used to evaluate graph AE and VAE. Based on these results, we\nalso question the relevance of repeatedly using these datasets to compare\ncomplex graph AE and VAE.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:33:12 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 15:09:36 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 09:54:33 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2001.07617", "submitter": "Haolin Zou", "authors": "Victor de la Pena, Haolin Zou", "title": "TopRank+: A Refinement of TopRank Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning to rank is a core problem in machine learning. In Lattimore\net al. (2018), a novel online learning algorithm was proposed based on\ntopological sorting. In the paper they provided a set of self-normalized\ninequalities (a) in the algorithm as a criterion in iterations and (b) to\nprovide an upper bound for cumulative regret, which is a measure of algorithm\nperformance. In this work, we utilized method of mixtures and asymptotic\nexpansions of certain implicit function to provide a tighter, iterated-log-like\nboundary for the inequalities, and as a consequence improve both the algorithm\nitself as well as its performance estimation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:44:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["de la Pena", "Victor", ""], ["Zou", "Haolin", ""]]}, {"id": "2001.07620", "submitter": "Fernando Gama", "authors": "Elvin Isufi, Fernando Gama, Alejandro Ribeiro", "title": "EdgeNets:Edge Varying Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the outstanding performance of neural networks in the structured\nEuclidean domain, recent years have seen a surge of interest in developing\nneural networks for graphs and data supported on graphs. The graph is leveraged\nat each layer of the neural network as a parameterization to capture detail at\nthe node level with a reduced number of parameters and computational\ncomplexity. Following this rationale, this paper puts forth a general framework\nthat unifies state-of-the-art graph neural networks (GNNs) through the concept\nof EdgeNet. An EdgeNet is a GNN architecture that allows different nodes to use\ndifferent parameters to weigh the information of different neighbors. By\nextrapolating this strategy to more iterations between neighboring nodes, the\nEdgeNet learns edge- and neighbor-dependent weights to capture local detail.\nThis is a general linear and local operation that a node can perform and\nencompasses under one formulation all existing graph convolutional neural\nnetworks (GCNNs) as well as graph attention networks (GATs). In writing\ndifferent GNN architectures with a common language, EdgeNets highlight specific\narchitecture advantages and limitations, while providing guidelines to improve\ntheir capacity without compromising their local implementation. An interesting\nconclusion is the unification of GCNNs and GATs -- approaches that have been so\nfar perceived as separate. In particular, we show that GATs are GCNNs on a\ngraph that is learned from the features. This particularization opens the doors\nto develop alternative attention mechanisms for improving discriminatory power.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:51:17 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 13:28:10 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 14:02:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Isufi", "Elvin", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2001.07627", "submitter": "Maciej A. Czyzewski", "authors": "Maciej A. Czyzewski", "title": "batchboost: regularization for stabilizing training with resistance to\n  underfitting & overfitting", "comments": "6 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting & underfitting and stable training are an important challenges in\nmachine learning. Current approaches for these issues are mixup, SamplePairing\nand BC learning. In our work, we state the hypothesis that mixing many images\ntogether can be more effective than just two. Batchboost pipeline has three\nstages: (a) pairing: method of selecting two samples. (b) mixing: how to create\na new one from two samples. (c) feeding: combining mixed samples with new ones\nfrom dataset into batch (with ratio $\\gamma$). Note that sample that appears in\nour batch propagates with subsequent iterations with less and less importance\nuntil the end of training. Pairing stage calculates the error per sample, sorts\nthe samples and pairs with strategy: hardest with easiest one, than mixing\nstage merges two samples using mixup, $x_1 + (1-\\lambda)x_2$. Finally, feeding\nstage combines new samples with mixed by ratio 1:1. Batchboost has 0.5-3%\nbetter accuracy than the current state-of-the-art mixup regularization on\nCIFAR-10 & Fashion-MNIST. Our method is slightly better than SamplePairing\ntechnique on small datasets (up to 5%). Batchboost provides stable training on\nnot tuned parameters (like weight decay), thus its a good method to test\nperformance of different architectures. Source code is at:\nhttps://github.com/maciejczyzewski/batchboost\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:07:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Czyzewski", "Maciej A.", ""]]}, {"id": "2001.07631", "submitter": "Sizhe Chen", "authors": "Zhixing Ye, Sizhe Chen, Peidong Zhang, Chengjin Sun, Xiaolin Huang", "title": "HRFA: High-Resolution Feature-based Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks have long been developed for revealing the vulnerability\nof Deep Neural Networks (DNNs) by adding imperceptible perturbations to the\ninput. Most methods generate perturbations like normal noise, which is not\ninterpretable and without semantic meaning. In this paper, we propose\nHigh-Resolution Feature-based Attack (HRFA), yielding authentic adversarial\nexamples with up to $1024 \\times 1024$ resolution. HRFA exerts attack by\nmodifying the latent feature representation of the image, i.e., the gradients\nback propagate not only through the victim DNN, but also through the generative\nmodel that maps the feature space to the image space. In this way, HRFA\ngenerates adversarial examples that are in high-resolution, realistic,\nnoise-free, and hence is able to evade several denoising-based defenses. In the\nexperiment, the effectiveness of HRFA is validated by attacking the object\nclassification and face verification tasks with BigGAN and StyleGAN,\nrespectively. The advantages of HRFA are verified from the high quality, high\nauthenticity, and high attack success rate faced with defenses.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:21:20 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 13:08:04 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ye", "Zhixing", ""], ["Chen", "Sizhe", ""], ["Zhang", "Peidong", ""], ["Sun", "Chengjin", ""], ["Huang", "Xiaolin", ""]]}, {"id": "2001.07636", "submitter": "Lei Shi", "authors": "Lei Shi", "title": "Mobility Inference on Long-Tailed Sparse Trajectory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the urban trajectory in cities has become an important topic in\ndata mining. How can we model the human mobility consisting of stay and travel\nfrom the raw trajectory data? How can we infer such a mobility model from the\nsingle trajectory information? How can we further generalize the mobility\ninference to accommodate the real-world trajectory data that is sparsely\nsampled over time?\n  In this paper, based on formal and rigid definitions of the stay/travel\nmobility, we propose a single trajectory inference algorithm that utilizes a\ngeneric long-tailed sparsity pattern in the large-scale trajectory data. The\nalgorithm guarantees a 100\\% precision in the stay/travel inference with a\nprovable lower-bound in the recall. Furthermore, we introduce an\nencoder-decoder learning architecture that admits multiple trajectories as\ninputs. The architecture is optimized for the mobility inference problem\nthrough customized embedding and learning mechanism. Evaluations with three\ntrajectory data sets of 40 million urban users validate the performance\nguarantees of the proposed inference algorithm and demonstrate the superiority\nof our deep learning model, in comparison to well-known sequence learning\nmethods. On extremely sparse trajectories, the deep learning model achieves a\n2$\\times$ overall accuracy improvement from the single trajectory inference\nalgorithm, through proven scalability and generalizability to large-scale\nversatile training data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:32:38 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Shi", "Lei", ""]]}, {"id": "2001.07641", "submitter": "Johannes Schneider", "authors": "Johannes Schneider, Joshua Handali, Michalis Vlachos and Christian\n  Meske", "title": "Deceptive AI Explanations: Creation and Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) comes with great opportunities but also great\nrisks. Automatically generated explanations for decisions are deemed helpful to\nbetter understand AI, increasing transparency and fostering trust. However,\ngiven e.g. economic incentives to create dishonest AI, can we trust its\nexplanations? To address this issue, our paper investigates to what extent\nmodels of AI, i.e. deep learning, and existing instruments to increase\ntransparency regarding AI decisions can be used to create and detect deceptive\nexplanations. For empirical evaluation, we focus on text classification and\nalter explanations originating from GradCAM, a well-established technique for\ncreating explanations in neural networks. We then evaluate the effect of\ndeceptive explanations on users in an experiment with 200 participants. Our\nfindings confirm that deceptive explanations can indeed fool humans while\nmachine learning methods can detect seemingly minor attempts of deception with\naccuracy that exceeds 80\\% given sufficient domain knowledge in the form of\ntraining data. Without domain knowledge, one can still infer inconsistencies in\nthe explanations in an unsupervised manner given basic knowledge on the\nallegedly deceptive model.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:41:22 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 21:02:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Schneider", "Johannes", ""], ["Handali", "Joshua", ""], ["Vlachos", "Michalis", ""], ["Meske", "Christian", ""]]}, {"id": "2001.07685", "submitter": "Kihyuk Sohn", "authors": "Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas\n  Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel", "title": "FixMatch: Simplifying Semi-Supervised Learning with Consistency and\n  Confidence", "comments": "Published at NeurIPS 2020 as a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) provides an effective means of leveraging\nunlabeled data to improve a model's performance. In this paper, we demonstrate\nthe power of a simple combination of two common SSL methods: consistency\nregularization and pseudo-labeling. Our algorithm, FixMatch, first generates\npseudo-labels using the model's predictions on weakly-augmented unlabeled\nimages. For a given image, the pseudo-label is only retained if the model\nproduces a high-confidence prediction. The model is then trained to predict the\npseudo-label when fed a strongly-augmented version of the same image. Despite\nits simplicity, we show that FixMatch achieves state-of-the-art performance\nacross a variety of standard semi-supervised learning benchmarks, including\n94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -- just\n4 labels per class. Since FixMatch bears many similarities to existing SSL\nmethods that achieve worse performance, we carry out an extensive ablation\nstudy to tease apart the experimental factors that are most important to\nFixMatch's success. We make our code available at\nhttps://github.com/google-research/fixmatch.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:32:27 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 17:22:06 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Sohn", "Kihyuk", ""], ["Berthelot", "David", ""], ["Li", "Chun-Liang", ""], ["Zhang", "Zizhao", ""], ["Carlini", "Nicholas", ""], ["Cubuk", "Ekin D.", ""], ["Kurakin", "Alex", ""], ["Zhang", "Han", ""], ["Raffel", "Colin", ""]]}, {"id": "2001.07697", "submitter": "Darina Dvinskikh", "authors": "Darina Dvinskikh", "title": "Stochastic Approximation versus Sample Average Approximation for\n  population Wasserstein barycenters", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning and optimization community there are two main approaches\nfor convex risk minimization problem, namely, the Stochastic Approximation (SA)\nand the Sample Average Approximation (SAA). In terms of oracle complexity\n(required number of stochastic gradient evaluations), both approaches are\nconsidered equivalent on average (up to a logarithmic factor). The total\ncomplexity depends on the specific problem, however, starting from work\n\\cite{nemirovski2009robust} it was generally accepted that the SA is better\nthan the SAA. Nevertheless, in case of large-scale problems SA may run out of\nmemory as storing all data on one machine and organizing online access to it\ncan be impossible without communications with other machines. SAA in\ncontradistinction to SA allows parallel/distributed calculations. In this\npaper, we shed new light on the comparison of SA and SAA for particular problem\nof calculating the population (regularized) Wasserstein barycenter of discrete\nmeasures. The conclusion is valid even for non-parallel (non-decentralized)\nsetup.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:54:39 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 14:56:01 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:29:32 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 10:02:53 GMT"}, {"version": "v5", "created": "Wed, 16 Sep 2020 13:33:01 GMT"}, {"version": "v6", "created": "Wed, 21 Oct 2020 13:02:59 GMT"}, {"version": "v7", "created": "Thu, 26 Nov 2020 16:09:07 GMT"}, {"version": "v8", "created": "Tue, 1 Dec 2020 14:34:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dvinskikh", "Darina", ""]]}, {"id": "2001.07698", "submitter": "Bernardo Huberman", "authors": "Qi Zhou, Jingjie Zhu, Junwen Zhang, Zhensheng Jia, Bernardo Huberman\n  and Gee-Kung Chang", "title": "Intelligent Bandwidth Allocation for Latency Management in NG-EPON using\n  Reinforcement Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel intelligent bandwidth allocation scheme in NG-EPON using\nreinforcement learning is proposed and demonstrated for latency management. We\nverify the capability of the proposed scheme under both fixed and dynamic\ntraffic loads scenarios to achieve <1ms average latency. The RL agent\ndemonstrates an efficient intelligent mechanism to manage the latency, which\nprovides a promising IBA solution for the next-generation access network.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 18:58:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhou", "Qi", ""], ["Zhu", "Jingjie", ""], ["Zhang", "Junwen", ""], ["Jia", "Zhensheng", ""], ["Huberman", "Bernardo", ""], ["Chang", "Gee-Kung", ""]]}, {"id": "2001.07708", "submitter": "Christoph Klemenjak", "authors": "Christoph Klemenjak, Stephen Makonin and Wilfried Elmenreich", "title": "Towards Comparability in Non-Intrusive Load Monitoring: On Data and\n  Performance Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Intrusive Load Monitoring (NILM) comprises of a set of techniques that\nprovide insights into the energy consumption of households and industrial\nfacilities. Latest contributions show significant improvements in terms of\naccuracy and generalisation abilities. Despite all progress made concerning\ndisaggregation techniques, performance evaluation and comparability remains an\nopen research question. The lack of standardisation and consensus on evaluation\nprocedures makes reproducibility and comparability extremely difficult. In this\npaper, we draw attention to comparability in NILM with a focus on highlighting\nthe considerable differences amongst common energy datasets used to test the\nperformance of algorithms. We divide discussion on comparability into data\naspects, performance metrics, and give a close view on evaluation processes.\nDetailed information on pre-processing as well as data cleaning methods, the\nimportance of unified performance reporting, and the need for complexity\nmeasures in load disaggregation are found to be the most urgent issues in\nNILM-related research. In addition, our evaluation suggests that datasets\nshould be chosen carefully. We conclude by formulating suggestions for future\nwork to enhance comparability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:13:51 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Klemenjak", "Christoph", ""], ["Makonin", "Stephen", ""], ["Elmenreich", "Wilfried", ""]]}, {"id": "2001.07710", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Wei Niu, Tianyun Zhang, Sijia Liu, Sheng Lin, Hongjia Li,\n  Xiang Chen, Jian Tang, Kaisheng Ma, Bin Ren, Yanzhi Wang", "title": "An Image Enhancing Pattern-based Sparsity for Real-time Inference on\n  Mobile Devices", "comments": "Paper accepted in the 16th European Conference on Computer Vision\n  (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning has been widely acknowledged as a straightforward and\neffective method to eliminate redundancy in Deep Neural Networks (DNN), thereby\nachieving acceleration on various platforms. However, most of the pruning\ntechniques are essentially trade-offs between model accuracy and regularity\nwhich lead to impaired inference accuracy and limited on-device acceleration\nperformance. To solve the problem, we introduce a new sparsity dimension,\nnamely pattern-based sparsity that comprises pattern and connectivity sparsity,\nand becoming both highly accurate and hardware friendly. With carefully\ndesigned patterns, the proposed pruning unprecedentedly and consistently\nachieves accuracy enhancement and better feature extraction ability on\ndifferent DNN structures and datasets, and our pattern-aware pruning framework\nalso achieves pattern library extraction, pattern selection, pattern and\nconnectivity pruning and weight training simultaneously. Our approach on the\nnew pattern-based sparsity naturally fits into compiler optimization for highly\nefficient DNN execution on mobile platforms. To the best of our knowledge, it\nis the first time that mobile devices achieve real-time inference for the\nlarge-scale DNN models thanks to the unique spatial property of pattern-based\nsparsity and the help of the code generation capability of compilers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 16:17:36 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 02:55:08 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 01:22:19 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Ma", "Xiaolong", ""], ["Niu", "Wei", ""], ["Zhang", "Tianyun", ""], ["Liu", "Sijia", ""], ["Lin", "Sheng", ""], ["Li", "Hongjia", ""], ["Chen", "Xiang", ""], ["Tang", "Jian", ""], ["Ma", "Kaisheng", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.07712", "submitter": "Tian Xu", "authors": "X. Chen (1), S. Chen (1), T. Xu (1), B. Yin (1), X. Mei (2), J. Peng\n  (2), H. Li (2) ((1) School of Computer Science, Wuhan University, Wuhan,\n  China, (2) School of Geosciences and Info-Physics, Central South University,\n  Changsha, China)", "title": "SMAPGAN: Generative Adversarial Network Based Semi-Supervised Styled Map\n  Tiles Generating Method", "comments": "in IEEE Transactions on Geoscience and Remote Sensing", "journal-ref": null, "doi": "10.1109/TGRS.2020.3021819", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional online map tiles, widely used on the Internet such as Google Map\nand Baidu Map, are rendered from vector data. Timely updating online map tiles\nfrom vector data, of which the generating is time-consuming, is a difficult\nmission. It is a shortcut to generate map tiles in time from remote sensing\nimages, which can be acquired timely without vector data. However, this mission\nused to be challenging or even impossible. Inspired by image-to-image\ntranslation (img2img) techniques based on generative adversarial networks\n(GAN), we proposed a semi-supervised Generation of styled map Tiles based on\nGenerative Adversarial Network (SMAPGAN) model to generate styled map tiles\ndirectly from remote sensing images. In this model, we designed a\nsemi-supervised learning strategy to pre-train SMAPGAN on rich unpaired samples\nand fine-tune it on limited paired samples in reality. We also designed image\ngradient L1 loss and image gradient structure loss to generate a styled map\ntile with global topological relationships and detailed edge curves of objects,\nwhich are important in cartography. Moreover, we proposed edge structural\nsimilarity index (ESSI) as a metric to evaluate the quality of topological\nconsistency between generated map tiles and ground truths. Experimental results\npresent that SMAPGAN outperforms state-of-the-art (SOTA) works according to\nmean squared error, structural similarity index, and ESSI. Also, SMAPGAN won\nmore approval than SOTA in the human perceptual test on the visual realism of\ncartography. Our work shows that SMAPGAN is potentially a new paradigm to\nproduce styled map tiles. Our implementation of the SMAPGAN is available at\nhttps://github.com/imcsq/SMAPGAN.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 04:13:21 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 11:47:26 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Chen", "X.", ""], ["Chen", "S.", ""], ["Xu", "T.", ""], ["Yin", "B.", ""], ["Mei", "X.", ""], ["Peng", "J.", ""], ["Li", "H.", ""]]}, {"id": "2001.07739", "submitter": "Joy Egede", "authors": "Joy O. Egede, Siyang Song, Temitayo A. Olugbade, Chongyang Wang,\n  Amanda Williams, Hongying Meng, Min Aung, Nicholas D. Lane, Michel Valstar\n  and Nadia Bianchi-Berthouze", "title": "EMOPAIN Challenge 2020: Multimodal Pain Evaluation from Facial and\n  Bodily Expressions", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EmoPain 2020 Challenge is the first international competition aimed at\ncreating a uniform platform for the comparison of machine learning and\nmultimedia processing methods of automatic chronic pain assessment from human\nexpressive behaviour, and also the identification of pain-related behaviours.\nThe objective of the challenge is to promote research in the development of\nassistive technologies that help improve the quality of life for people with\nchronic pain via real-time monitoring and feedback to help manage their\ncondition and remain physically active. The challenge also aims to encourage\nthe use of the relatively underutilised, albeit vital bodily expression signals\nfor automatic pain and pain-related emotion recognition. This paper presents a\ndescription of the challenge, competition guidelines, bench-marking dataset,\nand the baseline systems' architecture and performance on the three sub-tasks:\npain estimation from facial expressions, pain recognition from multimodal\nmovement, and protective movement behaviour detection.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:09:08 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 12:11:08 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 16:14:31 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Egede", "Joy O.", ""], ["Song", "Siyang", ""], ["Olugbade", "Temitayo A.", ""], ["Wang", "Chongyang", ""], ["Williams", "Amanda", ""], ["Meng", "Hongying", ""], ["Aung", "Min", ""], ["Lane", "Nicholas D.", ""], ["Valstar", "Michel", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "2001.07744", "submitter": "Lihi Dery", "authors": "Lihi Dery and Erez Shmueli", "title": "Improving Label Ranking Ensembles using Boosting Techniques", "comments": null, "journal-ref": "IEEE Access 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label ranking is a prediction task which deals with learning a mapping\nbetween an instance and a ranking (i.e., order) of labels from a finite set,\nrepresenting their relevance to the instance. Boosting is a well-known and\nreliable ensemble technique that was shown to often outperform other learning\nalgorithms. While boosting algorithms were developed for a multitude of machine\nlearning tasks, label ranking tasks were overlooked. In this paper, we propose\na boosting algorithm which was specifically designed for label ranking tasks.\nExtensive evaluation of the proposed algorithm on 24 semi-synthetic and\nreal-world label ranking datasets shows that it significantly outperforms\nexisting state-of-the-art label ranking algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:16:11 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Dery", "Lihi", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.07752", "submitter": "Luyao Yuan", "authors": "Luyao Yuan, Zipeng Fu, Jingyue Shen, Lu Xu, Junhong Shen, Song-Chun\n  Zhu", "title": "Emergence of Pragmatics from Referential Game between Theory of Mind\n  Agents", "comments": null, "journal-ref": "Emergent Communication Workshop, 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pragmatics studies how context can contribute to language meanings [1]. In\nhuman communication, language is never interpreted out of context, and\nsentences can usually convey more information than their literal meanings [2].\nHowever, this mechanism is missing in most multi-agent systems [3, 4, 5, 6],\nrestricting the communication efficiency and the capability of human-agent\ninteraction. In this paper, we propose an algorithm, using which agents can\nspontaneously learn the ability to \"read between lines\" without any explicit\nhand-designed rules. We integrate the theory of mind (ToM) [7, 8] in a\ncooperative multi-agent pedagogical situation and propose an adaptive\nreinforcement learning (RL) algorithm to develop a communication protocol. ToM\nis a profound cognitive science concept, claiming that people regularly reason\nabout other's mental states, including beliefs, goals, and intentions, to\nobtain performance advantage in competition, cooperation or coalition. With\nthis ability, agents consider language as not only messages but also rational\nacts reflecting others' hidden states. Our experiments demonstrate the\nadvantage of pragmatic protocols over non-pragmatic protocols. We also show the\nteaching complexity following the pragmatic protocol empirically approximates\nto recursive teaching dimension (RTD).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:37:33 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Yuan", "Luyao", ""], ["Fu", "Zipeng", ""], ["Shen", "Jingyue", ""], ["Xu", "Lu", ""], ["Shen", "Junhong", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2001.07761", "submitter": "Koki Madono", "authors": "Koki Madono, Masayuki Tanaka, Masaki Onishi, Tetsuji Ogawa", "title": "Block-wise Scrambled Image Recognition Using Adaptation Network", "comments": "6 pages Artificial Intelligence of Things(AAAI-2020 WS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a perceptually hidden object-recognition method is\ninvestigated to generate secure images recognizable by humans but not machines.\nHence, both the perceptual information hiding and the corresponding object\nrecognition methods should be developed. Block-wise image scrambling is\nintroduced to hide perceptual information from a third party. In addition, an\nadaptation network is proposed to recognize those scrambled images.\nExperimental comparisons conducted using CIFAR datasets demonstrated that the\nproposed adaptation network performed well in incorporating simple perceptual\ninformation hiding into DNN-based image classification.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 20:22:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Madono", "Koki", ""], ["Tanaka", "Masayuki", ""], ["Onishi", "Masaki", ""], ["Ogawa", "Tetsuji", ""]]}, {"id": "2001.07766", "submitter": "Seyed Mehdi Ayyoubzadeh", "authors": "Seyed Mehdi Ayyoubzadeh, Xiaolin Wu", "title": "Adaptive Loss Function for Super Resolution Neural Networks Using Convex\n  Optimization Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single Image Super-Resolution (SISR) task refers to learn a mapping from\nlow-resolution images to the corresponding high-resolution ones. This task is\nknown to be extremely difficult since it is an ill-posed problem. Recently,\nConvolutional Neural Networks (CNNs) have achieved state of the art performance\non SISR. However, the images produced by CNNs do not contain fine details of\nthe images. Generative Adversarial Networks (GANs) aim to solve this issue and\nrecover sharp details. Nevertheless, GANs are notoriously difficult to train.\nBesides that, they generate artifacts in the high-resolution images. In this\npaper, we have proposed a method in which CNNs try to align images in different\nspaces rather than only the pixel space. Such a space is designed using convex\noptimization techniques. CNNs are encouraged to learn high-frequency components\nof the images as well as low-frequency components. We have shown that the\nproposed method can recover fine details of the images and it is stable in the\ntraining process.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 20:31:10 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ayyoubzadeh", "Seyed Mehdi", ""], ["Wu", "Xiaolin", ""]]}, {"id": "2001.07769", "submitter": "Haekyu Park", "authors": "Nilaksh Das, Haekyu Park, Zijie J. Wang, Fred Hohman, Robert Firstman,\n  Emily Rogers, Duen Horng Chau", "title": "Massif: Interactive Interpretation of Adversarial Attacks on Deep\n  Learning", "comments": "Appear in ACM Conference on Human Factors in Computing Systems (CHI)\n  Late-Breaking Works 2020, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are increasingly powering high-stakes\napplications such as autonomous cars and healthcare; however, DNNs are often\ntreated as \"black boxes\" in such applications. Recent research has also\nrevealed that DNNs are highly vulnerable to adversarial attacks, raising\nserious concerns over deploying DNNs in the real world. To overcome these\ndeficiencies, we are developing Massif, an interactive tool for deciphering\nadversarial attacks. Massif identifies and interactively visualizes neurons and\ntheir connections inside a DNN that are strongly activated or suppressed by an\nadversarial attack. Massif provides both a high-level, interpretable overview\nof the effect of an attack on a DNN, and a low-level, detailed description of\nthe affected neurons. These tightly coupled views in Massif help people better\nunderstand which input features are most vulnerable or important for correct\npredictions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 20:41:27 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 17:26:08 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 22:19:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Das", "Nilaksh", ""], ["Park", "Haekyu", ""], ["Wang", "Zijie J.", ""], ["Hohman", "Fred", ""], ["Firstman", "Robert", ""], ["Rogers", "Emily", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.07787", "submitter": "Dimitrios Michael Manias", "authors": "Dimitrios Michael Manias, Manar Jammal, Hassan Hawilo, Abdallah Shami,\n  Parisa Heidari, Adel Larabi, Richard Brunner", "title": "Machine Learning for Performance-Aware Virtual Network Function\n  Placement", "comments": "6 pages, 6 figures, 1 table, 9 equations, 18 references, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing demand for data connectivity, network service providers are\nfaced with the task of reducing their capital and operational expenses while\nsimultaneously improving network performance and addressing the increased\nconnectivity demand. Although Network Function Virtualization (NFV) has been\nidentified as a solution, several challenges must be addressed to ensure its\nfeasibility. In this paper, we address the Virtual Network Function (VNF)\nplacement problem by developing a machine learning decision tree model that\nlearns from the effective placement of the various VNF instances forming a\nService Function Chain (SFC). The model takes several performance-related\nfeatures from the network as an input and selects the placement of the various\nVNF instances on network servers with the objective of minimizing the delay\nbetween dependent VNF instances. The benefits of using machine learning are\nrealized by moving away from a complex mathematical modelling of the system and\ntowards a data-based understanding of the system. Using the Evolved Packet Core\n(EPC) as a use case, we evaluate our model on different data center networks\nand compare it to the BACON algorithm in terms of the delay between\ninterconnected components and the total delay across the SFC. Furthermore, a\ntime complexity analysis is performed to show the effectiveness of the model in\nNFV applications.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:08:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Manias", "Dimitrios Michael", ""], ["Jammal", "Manar", ""], ["Hawilo", "Hassan", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""]]}, {"id": "2001.07792", "submitter": "Yanmao Man", "authors": "Yanmao Man, Ming Li, Ryan Gerdes", "title": "GhostImage: Remote Perception Attacks against Camera-based Image\n  Classification Systems", "comments": "Accepted by USENIX RAID 2020. Source code is available at\n  https://github.com/Harry1993/GhostImage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vision-based object classification systems imaging sensors perceive the\nenvironment and machine learning is then used to detect and classify objects\nfor decision-making purposes; e.g., to maneuver an automated vehicle around an\nobstacle or to raise an alarm to indicate the presence of an intruder in\nsurveillance settings. In this work we demonstrate how the perception domain\ncan be remotely and unobtrusively exploited to enable an attacker to create\nspurious objects or alter an existing object. An automated system relying on a\ndetection/classification framework subject to our attack could be made to\nundertake actions with catastrophic results due to attacker-induced\nmisperception.\n  We focus on camera-based systems and show that it is possible to remotely\nproject adversarial patterns into camera systems by exploiting two common\neffects in optical imaging systems, viz., lens flare/ghost effects and\nauto-exposure control. To improve the robustness of the attack to channel\neffects, we generate optimal patterns by integrating adversarial machine\nlearning techniques with a trained end-to-end channel model. We experimentally\ndemonstrate our attacks using a low-cost projector, on three different image\ndatasets, in indoor and outdoor environments, and with three different cameras.\nExperimental results show that, depending on the projector-camera distance,\nattack success rates can reach as high as 100% and under targeted conditions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 21:58:45 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:56:05 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 20:13:52 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Man", "Yanmao", ""], ["Li", "Ming", ""], ["Gerdes", "Ryan", ""]]}, {"id": "2001.07793", "submitter": "Ashraful Islam", "authors": "Ashraful Islam, Richard J. Radke", "title": "Weakly Supervised Temporal Action Localization Using Deep Metric\n  Learning", "comments": "accepted to WACV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal action localization is an important step towards video\nunderstanding. Most current action localization methods depend on untrimmed\nvideos with full temporal annotations of action instances. However, it is\nexpensive and time-consuming to annotate both action labels and temporal\nboundaries of videos. To this end, we propose a weakly supervised temporal\naction localization method that only requires video-level action instances as\nsupervision during training. We propose a classification module to generate\naction labels for each segment in the video, and a deep metric learning module\nto learn the similarity between different action instances. We jointly optimize\na balanced binary cross-entropy loss and a metric loss using a standard\nbackpropagation algorithm. Extensive experiments demonstrate the effectiveness\nof both of these components in temporal localization. We evaluate our algorithm\non two challenging untrimmed video datasets: THUMOS14 and ActivityNet1.2. Our\napproach improves the current state-of-the-art result for THUMOS14 by 6.5% mAP\nat IoU threshold 0.5, and achieves competitive performance for ActivityNet1.2.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:01:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Islam", "Ashraful", ""], ["Radke", "Richard J.", ""]]}, {"id": "2001.07798", "submitter": "Rohit Jena", "authors": "Rohit Jena, Changliu Liu, Katia Sycara", "title": "Augmenting GAIL with BC for sample efficient imitation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is the problem of recovering an expert policy without\naccess to a reward signal. Behavior cloning and GAIL are two widely used\nmethods for performing imitation learning. Behavior cloning converges in a few\niterations but doesn't achieve peak performance due to its inherent iid\nassumption about the state-action distribution. GAIL addresses the issue by\naccounting for the temporal dependencies when performing a state distribution\nmatching between the agent and the expert. Although GAIL is sample efficient in\nthe number of expert trajectories required, it is still not very sample\nefficient in terms of the environment interactions needed for convergence of\nthe policy. Given the complementary benefits of both methods, we present a\nsimple and elegant method to combine both methods to enable stable and sample\nefficient learning. Our algorithm is very simple to implement and integrates\nwith different policy gradient algorithms. We demonstrate the effectiveness of\nthe algorithm in low dimensional control tasks, gridworlds and in high\ndimensional image-based tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:28:50 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 19:45:53 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 02:18:24 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 20:04:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Jena", "Rohit", ""], ["Liu", "Changliu", ""], ["Sycara", "Katia", ""]]}, {"id": "2001.07805", "submitter": "Banghua Zhu", "authors": "Banghua Zhu, Jiantao Jiao, Jacob Steinhardt", "title": "When does the Tukey median work?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG eess.SP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of the Tukey median estimator under total\nvariation (TV) distance corruptions. Previous results show that under Huber's\nadditive corruption model, the breakdown point is 1/3 for high-dimensional\nhalfspace-symmetric distributions. We show that under TV corruptions, the\nbreakdown point reduces to 1/4 for the same set of distributions. We also show\nthat a certain projection algorithm can attain the optimal breakdown point of\n1/2. Both the Tukey median estimator and the projection algorithm achieve\nsample complexity linear in dimension.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:04:39 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 19:46:43 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhu", "Banghua", ""], ["Jiao", "Jiantao", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2001.07809", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Ram Mohana Reddy Guddeti", "title": "Depth-Based Selective Blurring in Stereo Images Using Accelerated\n  Framework", "comments": "arXiv admin note: text overlap with arXiv:2001.06967", "journal-ref": "3D Research (Springer) 5, Article number: 14 (2014)", "doi": "10.1007/s13319-014-0014-7", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid method for stereo disparity estimation by combining block\nand region-based stereo matching approaches. It generates dense depth maps from\ndisparity measurements of only 18 % image pixels (left or right). The\nmethodology involves segmenting pixel lightness values using fast K-Means\nimplementation, refining segment boundaries using morphological filtering and\nconnected components analysis; then determining boundaries' disparities using\nsum of absolute differences (SAD) cost function. Complete disparity maps are\nreconstructed from boundaries' disparities. We consider an application of our\nmethod for depth-based selective blurring of non-interest regions of stereo\nimages, using Gaussian blur to de-focus users' non-interest regions.\nExperiments on Middlebury dataset demonstrate that our method outperforms\ntraditional disparity estimation approaches using SAD and normalized cross\ncorrelation by up to 33.6 % and some recent methods by up to 6.1 %. Further,\nour method is highly parallelizable using CPU and GPU framework based on Java\nThread Pool and APARAPI with speed-up of 5.8 for 250 stereo video frames (4,096\nx 2,304).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:26:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Guddeti", "Ram Mohana Reddy", ""]]}, {"id": "2001.07819", "submitter": "Krishnakumar Balasubramanian", "authors": "Zhongruo Wang, Krishnakumar Balasubramanian, Shiqian Ma, Meisam\n  Razaviyayn", "title": "Zeroth-Order Algorithms for Nonconvex Minimax Problems with Improved\n  Complexities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study zeroth-order algorithms for minimax optimization\nproblems that are nonconvex in one variable and strongly-concave in the other\nvariable. Such minimax optimization problems have attracted significant\nattention lately due to their applications in modern machine learning tasks. We\nfirst design and analyze the Zeroth-Order Gradient Descent Ascent\n(\\texttt{ZO-GDA}) algorithm, and provide improved results compared to existing\nworks, in terms of oracle complexity. Next, we propose the Zeroth-Order\nGradient Descent Multi-Step Ascent (\\texttt{ZO-GDMSA}) algorithm that\nsignificantly improves the oracle complexity of \\texttt{ZO-GDA}. We also\nprovide stochastic version of \\texttt{ZO-GDA} and \\texttt{ZO-GDMSA} to handle\nstochastic nonconvex minimax problems, and provide oracle complexity results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:05:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wang", "Zhongruo", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ma", "Shiqian", ""], ["Razaviyayn", "Meisam", ""]]}, {"id": "2001.07820", "submitter": "Ying Xu", "authors": "Ying Xu, Xu Zhong, Antonio Jose Jimeno Yepes, Jey Han Lau", "title": "Elephant in the Room: An Evaluation Framework for Assessing Adversarial\n  Examples in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial example is an input transformed by small perturbations that\nmachine learning models consistently misclassify. While there are a number of\nmethods proposed to generate adversarial examples for text data, it is not\ntrivial to assess the quality of these adversarial examples, as minor\nperturbations (such as changing a word in a sentence) can lead to a significant\nshift in their meaning, readability and classification label. In this paper, we\npropose an evaluation framework consisting of a set of automatic evaluation\nmetrics and human evaluation guidelines, to rigorously assess the quality of\nadversarial examples based on the aforementioned properties. We experiment with\nsix benchmark attacking methods and found that some methods generate\nadversarial examples with poor readability and content preservation. We also\nlearned that multiple factors could influence the attacking performance, such\nas the length of the text inputs and architecture of the classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:05:45 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 06:09:37 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 04:16:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Xu", "Ying", ""], ["Zhong", "Xu", ""], ["Yepes", "Antonio Jose Jimeno", ""], ["Lau", "Jey Han", ""]]}, {"id": "2001.07827", "submitter": "Derek DeSantis", "authors": "Derek DeSantis, Phillip J. Wolfram, Katrina Bennett, Boian Alexandrov", "title": "Coarse-Grain Cluster Analysis of Tensors with Application to Climate\n  Biome Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": "LA-UR-20-20548", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tensor provides a concise way to codify the interdependence of complex\ndata. Treating a tensor as a d-way array, each entry records the interaction\nbetween the different indices. Clustering provides a way to parse the\ncomplexity of the data into more readily understandable information. Clustering\nmethods are heavily dependent on the algorithm of choice, as well as the chosen\nhyperparameters of the algorithm. However, their sensitivity to data scales is\nlargely unknown.\n  In this work, we apply the discrete wavelet transform to analyze the effects\nof coarse-graining on clustering tensor data. We are particularly interested in\nunderstanding how scale effects clustering of the Earth's climate system. The\ndiscrete wavelet transform allows classification of the Earth's climate across\na multitude of spatial-temporal scales. The discrete wavelet transform is used\nto produce an ensemble of classification estimates, as opposed to a single\nclassification. Information theoretic approaches are used to identify important\nscale lenghts in clustering The L15 Climate Datset. We also discover a\nsub-collection of the ensemble that spans the majority of the variance\nobserved, allowing for efficient consensus clustering techniques that can be\nused to identify climate biomes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:28:58 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:49:14 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["DeSantis", "Derek", ""], ["Wolfram", "Phillip J.", ""], ["Bennett", "Katrina", ""], ["Alexandrov", "Boian", ""]]}, {"id": "2001.07831", "submitter": "Achin Jain", "authors": "Achin Jain, Francesco Smarra, Enrico Reticcioli, Alessandro\n  D'Innocenzo, and Manfred Morari", "title": "NeurOpt: Neural network based optimization for building energy\n  management and climate control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model predictive control (MPC) can provide significant energy cost savings in\nbuilding operations in the form of energy-efficient control with better\noccupant comfort, lower peak demand charges, and risk-free participation in\ndemand response. However, the engineering effort required to obtain\nphysics-based models of buildings is considered to be the biggest bottleneck in\nmaking MPC scalable to real buildings. In this paper, we propose a data-driven\ncontrol algorithm based on neural networks to reduce this cost of model\nidentification. Our approach does not require building domain expertise or\nretrofitting of existing heating and cooling systems. We validate our learning\nand control algorithms on a two-story building with ten independently\ncontrolled zones, located in Italy. We learn dynamical models of energy\nconsumption and zone temperatures with high accuracy and demonstrate energy\nsavings and better occupant comfort compared to the default system controller.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:51:03 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 04:32:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jain", "Achin", ""], ["Smarra", "Francesco", ""], ["Reticcioli", "Enrico", ""], ["D'Innocenzo", "Alessandro", ""], ["Morari", "Manfred", ""]]}, {"id": "2001.07832", "submitter": "Angfan Zhu", "authors": "Angfan Zhu, Jiaqi Yang, Weiyue Zhao, Zhiguo Cao", "title": "LRF-Net: Learning Local Reference Frames for 3D Local Shape Description\n  and Matching", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local reference frame (LRF) acts as a critical role in 3D local shape\ndescription and matching. However, most of existing LRFs are hand-crafted and\nsuffer from limited repeatability and robustness. This paper presents the first\nattempt to learn an LRF via a Siamese network that needs weak supervision only.\nIn particular, we argue that each neighboring point in the local surface gives\na unique contribution to LRF construction and measure such contributions via\nlearned weights. Extensive analysis and comparative experiments on three public\ndatasets addressing different application scenarios have demonstrated that\nLRF-Net is more repeatable and robust than several state-of-the-art LRF methods\n(LRF-Net is only trained on one dataset). In addition, LRF-Net can\nsignificantly boost the local shape description and 6-DoF pose estimation\nperformance when matching 3D point clouds.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 00:52:48 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 00:13:41 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhu", "Angfan", ""], ["Yang", "Jiaqi", ""], ["Zhao", "Weiyue", ""], ["Cao", "Zhiguo", ""]]}, {"id": "2001.07845", "submitter": "Mingzhe Chen", "authors": "Mingzhe Chen, H. Vincent Poor, Walid Saad, and Shuguang Cui", "title": "Convergence Time Optimization for Federated Learning over Wireless\n  Networks", "comments": "This paper has been accepted in the IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the convergence time of federated learning (FL), when deployed\nover a realistic wireless network, is studied. In particular, a wireless\nnetwork is considered in which wireless users transmit their local FL models\n(trained using their locally collected data) to a base station (BS). The BS,\nacting as a central controller, generates a global FL model using the received\nlocal FL models and broadcasts it back to all users. Due to the limited number\nof resource blocks (RBs) in a wireless network, only a subset of users can be\nselected to transmit their local FL model parameters to the BS at each learning\nstep. Moreover, since each user has unique training data samples, the BS\nprefers to include all local user FL models to generate a converged global FL\nmodel. Hence, the FL performance and convergence time will be significantly\naffected by the user selection scheme. Therefore, it is necessary to design an\nappropriate user selection scheme that enables users of higher importance to be\nselected more frequently. This joint learning, wireless resource allocation,\nand user selection problem is formulated as an optimization problem whose goal\nis to minimize the FL convergence time while optimizing the FL performance. To\nsolve this problem, a probabilistic user selection scheme is proposed such that\nthe BS is connected to the users whose local FL models have significant effects\non its global FL model with high probabilities. Given the user selection\npolicy, the uplink RB allocation can be determined. To further reduce the FL\nconvergence time, artificial neural networks (ANNs) are used to estimate the\nlocal FL models of the users that are not allocated any RBs for local FL model\ntransmission at each given learning step, which enables the BS to enhance its\nglobal FL model and improve the FL convergence speed and performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 01:55:12 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 13:28:33 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Chen", "Mingzhe", ""], ["Poor", "H. Vincent", ""], ["Saad", "Walid", ""], ["Cui", "Shuguang", ""]]}, {"id": "2001.07847", "submitter": "Hisaichi Shibata", "authors": "H. Shibata (1), S. Hanaoka (2), Y. Nomura (1), T. Nakao (1), I. Sato\n  (2 and 4 and 5), D. Sato (3), N. Hayashi (1) and O. Abe (2 and 3) ((1)\n  Department of Computational Diagnostic Radiology and Preventive Medicine, The\n  University of Tokyo Hospital, (2) Department of Radiology, The University of\n  Tokyo Hospital, (3) Division of Radiology and Biomedical Engineering,\n  Graduate School of Medicine, The University of Tokyo, (4) Department of\n  Computer Science, Graduate School of Information Science and Technology, The\n  University of Tokyo, (5) Center for Advanced Intelligence Project, RIKEN)", "title": "A versatile anomaly detection method for medical images with a\n  flow-based generative model in semi-supervision setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oversight in medical images is a crucial problem, and timely reporting of\nmedical images is desired. Therefore, an all-purpose anomaly detection method\nthat can detect virtually all types of lesions/diseases in a given image is\nstrongly desired. However, few commercially available and versatile anomaly\ndetection methods for medical images have been provided so far. Recently,\nanomaly detection methods built upon deep learning methods have been rapidly\ngrowing in popularity, and these methods seem to provide reasonable solutions\nto the problem. However, the workload to label the images necessary for\ntraining in deep learning remains heavy. In this study, we present an anomaly\ndetection method based on two trained flow-based generative models. With this\nmethod, the posterior probability can be computed as a normality metric for any\ngiven image. The training of the generative models requires two sets of images:\na set containing only normal images and another set containing both normal and\nabnormal images without any labels. In the latter set, each sample does not\nhave to be labeled as normal or abnormal; therefore, any mixture of images\n(e.g., all cases in a hospital) can be used as the dataset without cumbersome\nmanual labeling. The method was validated with two types of medical images:\nchest X-ray radiographs (CXRs) and brain computed tomographies (BCTs). The\nareas under the receiver operating characteristic curves for logarithm\nposterior probabilities of CXRs (0.868 for pneumonia-like opacities) and BCTs\n(0.904 for infarction) were comparable to those in previous studies with other\nanomaly detection methods. This result showed the versatility of our method.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:01:57 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 13:00:36 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 07:09:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Shibata", "H.", "", "2 and 4 and 5"], ["Hanaoka", "S.", "", "2 and 4 and 5"], ["Nomura", "Y.", "", "2 and 4 and 5"], ["Nakao", "T.", "", "2 and 4 and 5"], ["Sato", "I.", "", "2 and 4 and 5"], ["Sato", "D.", "", "2 and 3"], ["Hayashi", "N.", "", "2 and 3"], ["Abe", "O.", "", "2 and 3"]]}, {"id": "2001.07849", "submitter": "Wen-Chin Huang", "authors": "Wen-Chin Huang, Hao Luo, Hsin-Te Hwang, Chen-Chou Lo, Yu-Huai Peng, Yu\n  Tsao, Hsin-Min Wang", "title": "Unsupervised Representation Disentanglement using Cross Domain Features\n  and Adversarial Learning in Variational Autoencoder based Voice Conversion", "comments": "Accepted to IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": "10.1109/TETCI.2020.2977678", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective approach for voice conversion (VC) is to disentangle linguistic\ncontent from other components in the speech signal. The effectiveness of\nvariational autoencoder (VAE) based VC (VAE-VC), for instance, strongly relies\non this principle. In our prior work, we proposed a cross-domain VAE-VC\n(CDVAE-VC) framework, which utilized acoustic features of different properties,\nto improve the performance of VAE-VC. We believed that the success came from\nmore disentangled latent representations. In this paper, we extend the CDVAE-VC\nframework by incorporating the concept of adversarial learning, in order to\nfurther increase the degree of disentanglement, thereby improving the quality\nand similarity of converted speech. More specifically, we first investigate the\neffectiveness of incorporating the generative adversarial networks (GANs) with\nCDVAE-VC. Then, we consider the concept of domain adversarial training and add\nan explicit constraint to the latent representation, realized by a speaker\nclassifier, to explicitly eliminate the speaker information that resides in the\nlatent code. Experimental results confirm that the degree of disentanglement of\nthe learned latent representation can be enhanced by both GANs and the speaker\nclassifier. Meanwhile, subjective evaluation results in terms of quality and\nsimilarity scores demonstrate the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:06:06 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 04:24:04 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 10:16:28 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Huang", "Wen-Chin", ""], ["Luo", "Hao", ""], ["Hwang", "Hsin-Te", ""], ["Lo", "Chen-Chou", ""], ["Peng", "Yu-Huai", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "2001.07853", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal and Theja Tulabandhula", "title": "Incentivising Exploration and Recommendations for Contextual Bandits\n  with Payments", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a contextual bandit based model to capture the learning and social\nwelfare goals of a web platform in the presence of myopic users. By using\npayments to incentivize these agents to explore different\nitems/recommendations, we show how the platform can learn the inherent\nattributes of items and achieve a sublinear regret while maximizing cumulative\nsocial welfare. We also calculate theoretical bounds on the cumulative costs of\nincentivization to the platform. Unlike previous works in this domain, we\nconsider contexts to be completely adversarial, and the behavior of the\nadversary is unknown to the platform. Our approach can improve various\nengagement metrics of users on e-commerce stores, recommendation engines and\nmatching platforms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:26:22 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Agrawal", "Priyank", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2001.07859", "submitter": "Christopher Urban", "authors": "Christopher J. Urban and Daniel J. Bauer", "title": "A Deep Learning Algorithm for High-Dimensional Exploratory Item Factor\n  Analysis", "comments": "30 pages; 12 figures; accepted for publication in Psychometrika", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal maximum likelihood (MML) estimation is the preferred approach to\nfitting item response theory models in psychometrics due to the MML estimator's\nconsistency, normality, and efficiency as the sample size tends to infinity.\nHowever, state-of-the-art MML estimation procedures such as the\nMetropolis-Hastings Robbins-Monro (MH-RM) algorithm as well as approximate MML\nestimation procedures such as variational inference (VI) are computationally\ntime-consuming when the sample size and the number of latent factors are very\nlarge. In this work, we investigate a deep learning-based VI algorithm for\nexploratory item factor analysis (IFA) that is computationally fast even in\nlarge data sets with many latent factors. The proposed approach applies a deep\nartificial neural network model called an importance-weighted autoencoder\n(IWAE) for exploratory IFA. The IWAE approximates the MML estimator using an\nimportance sampling technique wherein increasing the number of\nimportance-weighted (IW) samples drawn during fitting improves the\napproximation, typically at the cost of decreased computational efficiency. We\nprovide a real data application that recovers results aligning with\npsychological theory across random starts. Via simulation studies, we show that\nthe IWAE yields more accurate estimates as either the sample size or the number\nof IW samples increases (although factor correlation and intercepts estimates\nexhibit some bias) and obtains similar results to MH-RM in less time. Our\nsimulations also suggest that the proposed approach performs similarly to and\nis potentially faster than constrained joint maximum likelihood estimation, a\nfast procedure that is consistent when the sample size and the number of items\nsimultaneously tend to infinity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:02:34 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 00:21:19 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 18:24:46 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 17:29:22 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Urban", "Christopher J.", ""], ["Bauer", "Daniel J.", ""]]}, {"id": "2001.07861", "submitter": "Xin Bing", "authors": "Xin Bing and Florentina Bunea and Marten Wegkamp", "title": "Optimal estimation of sparse topic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have become popular tools for dimension reduction and\nexploratory analysis of text data which consists in observed frequencies of a\nvocabulary of $p$ words in $n$ documents, stored in a $p\\times n$ matrix. The\nmain premise is that the mean of this data matrix can be factorized into a\nproduct of two non-negative matrices: a $p\\times K$ word-topic matrix $A$ and a\n$K\\times n$ topic-document matrix $W$. This paper studies the estimation of $A$\nthat is possibly element-wise sparse, and the number of topics $K$ is unknown.\nIn this under-explored context, we derive a new minimax lower bound for the\nestimation of such $A$ and propose a new computationally efficient algorithm\nfor its recovery. We derive a finite sample upper bound for our estimator, and\nshow that it matches the minimax lower bound in many scenarios. Our estimate\nadapts to the unknown sparsity of $A$ and our analysis is valid for any finite\n$n$, $p$, $K$ and document lengths. Empirical results on both synthetic data\nand semi-synthetic data show that our proposed estimator is a strong competitor\nof the existing state-of-the-art algorithms for both non-sparse $A$ and sparse\n$A$, and has superior performance is many scenarios of interest.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:19:50 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Bing", "Xin", ""], ["Bunea", "Florentina", ""], ["Wegkamp", "Marten", ""]]}, {"id": "2001.07866", "submitter": "Xingyu Wang", "authors": "Xingyu Wang, Lida Zhang, Diego Klabjan", "title": "Keyword-based Topic Modeling and Keyword Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain type of documents such as tweets are collected by specifying a set of\nkeywords. As topics of interest change with time it is beneficial to adjust\nkeywords dynamically. The challenge is that these need to be specified ahead of\nknowing the forthcoming documents and the underlying topics. The future topics\nshould mimic past topics of interest yet there should be some novelty in them.\nWe develop a keyword-based topic model that dynamically selects a subset of\nkeywords to be used to collect future documents. The generative process first\nselects keywords and then the underlying documents based on the specified\nkeywords. The model is trained by using a variational lower bound and\nstochastic gradient optimization. The inference consists of finding a subset of\nkeywords where given a subset the model predicts the underlying topic-word\nmatrix for the unknown forthcoming documents. We compare the keyword topic\nmodel against a benchmark model using viral predictions of tweets combined with\na topic model. The keyword-based topic model outperforms this sophisticated\nbaseline model by 67%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:41:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Wang", "Xingyu", ""], ["Zhang", "Lida", ""], ["Klabjan", "Diego", ""]]}, {"id": "2001.07885", "submitter": "Jinyang Liu", "authors": "Jinyang Liu, Yujia Zhai, Zizhong Chen", "title": "Normalization of Input-output Shared Embeddings in Text Generation\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network based models have been state-of-the-art models for various\nNatural Language Processing tasks, however, the input and output dimension\nproblem in the networks has still not been fully resolved, especially in text\ngeneration tasks (e.g. Machine Translation, Text Summarization), in which input\nand output both have huge sizes of vocabularies. Therefore, input-output\nembedding weight sharing has been introduced and adopted widely, which remains\nto be improved. Based on linear algebra and statistical theories, this paper\nlocates the shortcoming of existed input-output embedding weight sharing\nmethod, then raises methods for improving input-output weight shared embedding,\namong which methods of normalization of embedding weight matrices show best\nperformance. These methods are nearly computational cost-free, can get combined\nwith other embedding techniques, and show good effectiveness when applied on\nstate-of-the-art Neural Network models. For Transformer-big models, the\nnormalization techniques can get at best 0.6 BLEU improvement compared to the\noriginal version of model on WMT'16 En-De dataset, and similar BLEU\nimprovements on IWSLT 14' datasets. For DynamicConv models, 0.5 BLEU\nimprovement can be attained on WMT'16 En-De dataset, and 0.41 BLEU improvement\non IWSLT 14' De-En translation task is achieved.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 05:34:45 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 04:42:13 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Liu", "Jinyang", ""], ["Zhai", "Yujia", ""], ["Chen", "Zizhong", ""]]}, {"id": "2001.07910", "submitter": "Victor Berger", "authors": "Victor Berger (TAU), Mich\\`ele Sebag (LRI)", "title": "From abstract items to latent spaces to observed data and back:\n  Compositional Variational Auto-Encoder", "comments": null, "journal-ref": "ECMLPKDD 2019 : European Conference on Machine learning and\n  knowledge discovery in databases, Sep 2019, W{\\\"u}rzburg, Germany", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Models are now acknowledged an essential tool in\nMachine Learning. This paper focuses on their control. While many approaches\naim at disentangling the data through the coordinate-wise control of their\nlatent representations, another direction is explored in this paper. The\nproposed CompVAE handles data with a natural multi-ensemblist structure (i.e.\nthat can naturally be decomposed into elements). Derived from Bayesian\nvariational principles, CompVAE learns a latent representation leveraging both\nobservational and symbolic information. A first contribution of the approach is\nthat this latent representation supports a compositional generative model,\namenable to multi-ensemblist operations (addition or subtraction of elements in\nthe composition). This compositional ability is enabled by the invariance and\ngenerality of the whole framework w.r.t. respectively, the order and number of\nthe elements. The second contribution of the paper is a proof of concept on\nsynthetic 1D and 2D problems, demonstrating the efficiency of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:30:39 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Berger", "Victor", "", "TAU"], ["Sebag", "Mich\u00e8le", "", "LRI"]]}, {"id": "2001.07915", "submitter": "Hamza Khan", "authors": "Hamza Khan, Anis Elgabli, Sumudu Samarakoon, Mehdi Bennis, and Choong\n  Seon Hong", "title": "Reinforcement Learning Based Vehicle-cell Association Algorithm for\n  Highly Mobile Millimeter Wave Communication", "comments": "13 pages, 14 figures", "journal-ref": "IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING, VOL.\n  5, NO. 4, DECEMBER 2019", "doi": "10.1109/TCCN.2019.2941191", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle-to-everything (V2X) communication is a growing area of communication\nwith a variety of use cases. This paper investigates the problem of\nvehicle-cell association in millimeter wave (mmWave) communication networks.\nThe aim is to maximize the time average rate per vehicular user (VUE) while\nensuring a target minimum rate for all VUEs with low signaling overhead. We\nfirst formulate the user (vehicle) association problem as a discrete non-convex\noptimization problem. Then, by leveraging tools from machine learning,\nspecifically distributed deep reinforcement learning (DDRL) and the\nasynchronous actor critic algorithm (A3C), we propose a low complexity\nalgorithm that approximates the solution of the proposed optimization problem.\nThe proposed DDRL-based algorithm endows every road side unit (RSU) with a\nlocal RL agent that selects a local action based on the observed input state.\nActions of different RSUs are forwarded to a central entity, that computes a\nglobal reward which is then fed back to RSUs. It is shown that each\nindependently trained RL performs the vehicle-RSU association action with low\ncontrol overhead and less computational complexity compared to running an\nonline complex algorithm to solve the non-convex optimization problem. Finally,\nsimulation results show that the proposed solution achieves up to 15\\% gains in\nterms of sum rate and 20\\% reduction in VUE outages compared to several\nbaseline designs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:51:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Khan", "Hamza", ""], ["Elgabli", "Anis", ""], ["Samarakoon", "Sumudu", ""], ["Bennis", "Mehdi", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2001.07922", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on\n  Graph Semi-Supervised Classification", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph neural networks may suffer from the \"suspended animation\nproblem\" when the model architecture goes deep. Meanwhile, for some graph\nlearning scenarios, e.g., nodes with text/image attributes or graphs with\nlong-distance node correlations, deep graph neural networks will be necessary\nfor effective graph representation learning. In this paper, we propose a new\ngraph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph\nrepresentation learning and node classification. DIFNET utilizes both neural\ngates and graph residual learning for node hidden state modeling, and includes\nan attention mechanism for node neighborhood information diffusion. Extensive\nexperiments will be done in this paper to compare DIFNET against several\nstate-of-the-art graph neural network models. The experimental results can\nillustrate both the learning performance advantages and effectiveness of\nDIFNET, especially in addressing the \"suspended animation problem\".\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:19:12 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2001.07933", "submitter": "Han Zhichao", "authors": "Jia Li, Honglei Zhang, Zhichao Han, Yu Rong, Hong Cheng, Junzhou Huang", "title": "Adversarial Attack on Community Detection by Hiding Individuals", "comments": "In Proceedings of The Web Conference 2020, April 20-24, 2020, Taipei,\n  Taiwan. 11 pages", "journal-ref": null, "doi": "10.1145/3366423.3380171", "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been demonstrated that adversarial graphs, i.e., graphs with\nimperceptible perturbations added, can cause deep graph models to fail on\nnode/graph classification tasks. In this paper, we extend adversarial graphs to\nthe problem of community detection which is much more difficult. We focus on\nblack-box attack and aim to hide targeted individuals from the detection of\ndeep graph community detection models, which has many applications in\nreal-world scenarios, for example, protecting personal privacy in social\nnetworks and understanding camouflage patterns in transaction networks. We\npropose an iterative learning framework that takes turns to update two modules:\none working as the constrained graph generator and the other as the surrogate\ncommunity detection model. We also find that the adversarial graphs generated\nby our method can be transferred to other learning based community detection\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:50:04 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Li", "Jia", ""], ["Zhang", "Honglei", ""], ["Han", "Zhichao", ""], ["Rong", "Yu", ""], ["Cheng", "Hong", ""], ["Huang", "Junzhou", ""]]}, {"id": "2001.07935", "submitter": "Grigori Fursin", "authors": "Grigori Fursin, Herve Guillou and Nicolas Essayan", "title": "CodeReef: an open platform for portable MLOps, reusable automation\n  actions and reproducible benchmarking", "comments": "Presented at the 1st Workshop on MLOps Systems co-located with the\n  3rd Conference on Machine Learning and Systems (MLSys'20) in Austin, TX, USA:\n  https://mlops-systems.github.io . A live interactive demo:\n  https://CodeReef.ai/demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present CodeReef - an open platform to share all the components necessary\nto enable cross-platform MLOps (MLSysOps), i.e. automating the deployment of ML\nmodels across diverse systems in the most efficient way. We also introduce the\nCodeReef solution - a way to package and share models as non-virtualized,\nportable, customizable and reproducible archive files. Such ML packages include\nJSON meta description of models with all dependencies, Python APIs, CLI actions\nand portable workflows necessary to automatically build, benchmark, test and\ncustomize models across diverse platforms, AI frameworks, libraries, compilers\nand datasets. We demonstrate several CodeReef solutions to automatically build,\nrun and measure object detection based on SSD-Mobilenets, TensorFlow and COCO\ndataset from the latest MLPerf inference benchmark across a wide range of\nplatforms from Raspberry Pi, Android phones and IoT devices to data centers.\nOur long-term goal is to help researchers share their new techniques as\nproduction-ready packages along with research papers to participate in\ncollaborative and reproducible benchmarking, compare the different\nML/software/hardware stacks and select the most efficient ones on a Pareto\nfrontier using online CodeReef dashboards.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:52:51 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 11:09:34 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fursin", "Grigori", ""], ["Guillou", "Herve", ""], ["Essayan", "Nicolas", ""]]}, {"id": "2001.07937", "submitter": "Mustafa Ozger", "authors": "Amin Azari, Fayezeh Ghavimi, Mustafa Ozger, Riku Jantti, and Cicek\n  Cavdar", "title": "Machine Learning assisted Handover and Resource Management for Cellular\n  Connected Drones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling cellular connectivity for drones introduces a wide set of challenges\nand opportunities. Communication of cellular-connected drones is influenced by\n3-dimensional mobility and line-of-sight channel characteristics which results\nin higher number of handovers with increasing altitude. Our cell planning\nsimulations in coexistence of aerial and terrestrial users indicate that the\nsevere interference from drones to base stations is a major challenge for\nuplink communications of terrestrial users. Here, we first present the major\nchallenges in co-existence of terrestrial and drone communications by\nconsidering real geographical network data for Stockholm. Then, we derive\nanalytical models for the key performance indicators (KPIs), including\ncommunications delay and interference over cellular networks, and formulate the\nhandover and radio resource management (H-RRM) optimization problem.\nAfterwards, we transform this problem into a machine learning problem, and\npropose a deep reinforcement learning solution to solve H-RRM problem. Finally,\nusing simulation results, we present how the speed and altitude of drones, and\nthe tolerable level of interference, shape the optimal H-RRM policy in the\nnetwork. Especially, the heat-maps of handover decisions in different drone's\naltitudes/speeds have been presented, which promote a revision of the legacy\nhandover schemes and redefining the boundaries of cells in the sky.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 10:04:26 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Azari", "Amin", ""], ["Ghavimi", "Fayezeh", ""], ["Ozger", "Mustafa", ""], ["Jantti", "Riku", ""], ["Cavdar", "Cicek", ""]]}, {"id": "2001.07973", "submitter": "Gerardo Aragon-Camarasa", "authors": "Ameya Pore and Gerardo Aragon-Camarasa", "title": "On Simple Reactive Neural Networks for Behaviour-Based Reinforcement\n  Learning", "comments": "6 pages, 5 figures. Accepted for publication to the International\n  Conference on Robotics and Automation (ICRA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a behaviour-based reinforcement learning approach, inspired by\nBrook's subsumption architecture, in which simple fully connected networks are\ntrained as reactive behaviours. Our working assumption is that a pick and place\nrobotic task can be simplified by leveraging domain knowledge of a robotics\ndeveloper to decompose and train such reactive behaviours; namely, approach,\ngrasp, and retract. Then the robot autonomously learns how to combine them via\nan Actor-Critic architecture. The Actor-Critic policy is to determine the\nactivation and inhibition mechanisms of the reactive behaviours in a particular\ntemporal sequence. We validate our approach in a simulated robot environment\nwhere the task is picking a block and taking it to a target position while\norienting the gripper from a top grasp. The latter represents an extra\ndegree-of-freedom of which current end-to-end reinforcement learning fail to\ngeneralise. Our findings suggest that robotic learning can be more effective if\neach behaviour is learnt in isolation and then combined them to accomplish the\ntask. That is, our approach learns the pick and place task in 8,000 episodes,\nwhich represents a drastic reduction in the number of training episodes\nrequired by an end-to-end approach and the existing state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:49:52 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 13:33:20 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Pore", "Ameya", ""], ["Aragon-Camarasa", "Gerardo", ""]]}, {"id": "2001.07974", "submitter": "Bin Han", "authors": "Bin Han and Hans D. Schotten", "title": "Machine Learning for Network Slicing Resource Management: A\n  Comprehensive Survey", "comments": "To appear in ZTE Communications, 2020", "journal-ref": "ZTE Communications, 68(4), 2019", "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging technology of multi-tenancy network slicing is considered as an\nessential feature of 5G cellular networks. It provides network slices as a new\ntype of public cloud services, and therewith increases the service flexibility\nand enhances the network resource efficiency. Meanwhile, it raises new\nchallenges of network resource management. A number of various methods have\nbeen proposed over the recent past years, in which machine learning and\nartificial intelligence techniques are widely deployed. In this article, we\nprovide a survey to existing approaches of network slicing resource management,\nwith a highlight on the roles played by machine learning in them.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:55:29 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Han", "Bin", ""], ["Schotten", "Hans D.", ""]]}, {"id": "2001.07993", "submitter": "Rajiv Ranjan Kumar", "authors": "Rajiv Ranjan Kumar, Pradeep Varakantham", "title": "On Solving Cooperative MARL Problems with a Few Good Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative Multi-agent Reinforcement Learning (MARL) is crucial for\ncooperative decentralized decision learning in many domains such as search and\nrescue, drone surveillance, package delivery and fire fighting problems. In\nthese domains, a key challenge is learning with a few good experiences, i.e.,\npositive reinforcements are obtained only in a few situations (e.g., on\nextinguishing a fire or tracking a crime or delivering a package) and in most\nother situations there is zero or negative reinforcement. Learning decisions\nwith a few good experiences is extremely challenging in cooperative MARL\nproblems due to three reasons. First, compared to the single agent case,\nexploration is harder as multiple agents have to be coordinated to receive a\ngood experience. Second, environment is not stationary as all the agents are\nlearning at the same time (and hence change policies). Third, scale of problem\nincreases significantly with every additional agent.\n  Relevant existing work is extensive and has focussed on dealing with a few\ngood experiences in single-agent RL problems or on scalable approaches for\nhandling non-stationarity in MARL problems. Unfortunately, neither of these\napproaches (or their extensions) are able to address the problem of sparse good\nexperiences effectively. Therefore, we provide a novel fictitious self\nimitation approach that is able to simultaneously handle non-stationarity and\nsparse good experiences in a scalable manner. Finally, we provide a thorough\ncomparison (experimental or descriptive) against relevant cooperative MARL\nalgorithms to demonstrate the utility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 12:53:53 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kumar", "Rajiv Ranjan", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "2001.08001", "submitter": "Oliver Willers", "authors": "Oliver Willers, Sebastian Sudholt, Shervin Raafatnia, Stephanie\n  Abrecht", "title": "Safety Concerns and Mitigation Approaches Regarding the Use of Deep\n  Learning in Safety-Critical Perception Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are widely regarded as indispensable when it comes to\ndesigning perception pipelines for autonomous agents such as robots, drones or\nautomated vehicles. The main reasons, however, for deep learning not being used\nfor autonomous agents at large scale already are safety concerns. Deep learning\napproaches typically exhibit a black-box behavior which makes it hard for them\nto be evaluated with respect to safety-critical aspects. While there have been\nsome work on safety in deep learning, most papers typically focus on high-level\nsafety concerns. In this work, we seek to dive into the safety concerns of deep\nlearning methods and present a concise enumeration on a deeply technical level.\nAdditionally, we present extensive discussions on possible mitigation methods\nand give an outlook regarding what mitigation methods are still missing in\norder to facilitate an argumentation for the safety of a deep learning method.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 13:22:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Willers", "Oliver", ""], ["Sudholt", "Sebastian", ""], ["Raafatnia", "Shervin", ""], ["Abrecht", "Stephanie", ""]]}, {"id": "2001.08025", "submitter": "Guillermo Navas Palencia", "authors": "Guillermo Navas-Palencia", "title": "Optimal binning: mathematical programming formulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal binning is the optimal discretization of a variable into bins\ngiven a discrete or continuous numeric target. We present a rigorous and\nextensible mathematical programming formulation to solving the optimal binning\nproblem for a binary, continuous and multi-class target type, incorporating\nconstraints not previously addressed. For all three target types, we introduce\na convex mixed-integer programming formulation. Several algorithmic\nenhancements such as automatic determination of the most suitable monotonic\ntrend via a Machine-Learning-based classifier and implementation aspects are\nthoughtfully discussed. The new mathematical programming formulations are\ncarefully implemented in the open-source python library OptBinning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:11:13 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Navas-Palencia", "Guillermo", ""]]}, {"id": "2001.08047", "submitter": "Nicholas Santavas Mr", "authors": "Nicholas Santavas, Ioannis Kansizoglou, Loukas Bampis, Evangelos\n  Karakasis and Antonios Gasteratos", "title": "Attention! A Lightweight 2D Hand Pose Estimation Approach", "comments": "updated version with ablation studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision based human pose estimation is an non-invasive technology for\nHuman-Computer Interaction (HCI). Direct use of the hand as an input device\nprovides an attractive interaction method, with no need for specialized sensing\nequipment, such as exoskeletons, gloves etc, but a camera. Traditionally, HCI\nis employed in various applications spreading in areas including manufacturing,\nsurgery, entertainment industry and architecture, to mention a few. Deployment\nof vision based human pose estimation algorithms can give a breath of\ninnovation to these applications. In this letter, we present a novel\nConvolutional Neural Network architecture, reinforced with a Self-Attention\nmodule that it can be deployed on an embedded system, due to its lightweight\nnature, with just 1.9 Million parameters. The source code and qualitative\nresults are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:05:00 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 01:24:50 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Santavas", "Nicholas", ""], ["Kansizoglou", "Ioannis", ""], ["Bampis", "Loukas", ""], ["Karakasis", "Evangelos", ""], ["Gasteratos", "Antonios", ""]]}, {"id": "2001.08049", "submitter": "Nicolas Brosse", "authors": "Nicolas Brosse, Carlos Riquelme, Alice Martin, Sylvain Gelly, \\'Eric\n  Moulines", "title": "On Last-Layer Algorithms for Classification: Decoupling Representation\n  from Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification for deep learning is a challenging open problem.\nBayesian statistics offer a mathematically grounded framework to reason about\nuncertainties; however, approximate posteriors for modern neural networks still\nrequire prohibitive computational costs. We propose a family of algorithms\nwhich split the classification task into two stages: representation learning\nand uncertainty estimation. We compare four specific instances, where\nuncertainty estimation is performed via either an ensemble of Stochastic\nGradient Descent or Stochastic Gradient Langevin Dynamics snapshots, an\nensemble of bootstrapped logistic regressions, or via a number of Monte Carlo\nDropout passes. We evaluate their performance in terms of \\emph{selective}\nclassification (risk-coverage), and their ability to detect out-of-distribution\nsamples. Our experiments suggest there is limited value in adding multiple\nuncertainty layers to deep classifiers, and we observe that these simple\nmethods strongly outperform a vanilla point-estimate SGD in some complex\nbenchmarks like ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:08:30 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Brosse", "Nicolas", ""], ["Riquelme", "Carlos", ""], ["Martin", "Alice", ""], ["Gelly", "Sylvain", ""], ["Moulines", "\u00c9ric", ""]]}, {"id": "2001.08053", "submitter": "Vincent Guigue", "authors": "Bruno Taill\\'e, Vincent Guigue, Patrick Gallinari", "title": "Contextualized Embeddings in Named-Entity Recognition: An Empirical\n  Study on Generalization", "comments": null, "journal-ref": "ECIR 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized embeddings use unsupervised language model pretraining to\ncompute word representations depending on their context. This is intuitively\nuseful for generalization, especially in Named-Entity Recognition where it is\ncrucial to detect mentions never seen during training. However, standard\nEnglish benchmarks overestimate the importance of lexical over contextual\nfeatures because of an unrealistic lexical overlap between train and test\nmentions. In this paper, we perform an empirical analysis of the generalization\ncapabilities of state-of-the-art contextualized embeddings by separating\nmentions by novelty and with out-of-domain evaluation. We show that they are\nparticularly beneficial for unseen mentions detection, especially\nout-of-domain. For models trained on CoNLL03, language model contextualization\nleads to a +1.2% maximal relative micro-F1 score increase in-domain against\n+13% out-of-domain on the WNUT dataset\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:15:34 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Taill\u00e9", "Bruno", ""], ["Guigue", "Vincent", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2001.08055", "submitter": "Muhammad Firmansyah Kasim", "authors": "M. F. Kasim, D. Watson-Parris, L. Deaconu, S. Oliver, P. Hatfield, D.\n  H. Froula, G. Gregori, M. Jarvis, S. Khatiwala, J. Korenaga, J.\n  Topp-Mugglestone, E. Viezzer, S. M. Vinko", "title": "Building high accuracy emulators for scientific simulations with deep\n  neural architecture search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph physics.comp-ph physics.plasm-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computer simulations are invaluable tools for scientific discovery. However,\naccurate simulations are often slow to execute, which limits their\napplicability to extensive parameter exploration, large-scale data analysis,\nand uncertainty quantification. A promising route to accelerate simulations by\nbuilding fast emulators with machine learning requires large training datasets,\nwhich can be prohibitively expensive to obtain with slow simulations. Here we\npresent a method based on neural architecture search to build accurate\nemulators even with a limited number of training data. The method successfully\naccelerates simulations by up to 2 billion times in 10 scientific cases\nincluding astrophysics, climate science, biogeochemistry, high energy density\nphysics, fusion energy, and seismology, using the same super-architecture,\nalgorithm, and hyperparameters. Our approach also inherently provides emulator\nuncertainty estimation, adding further confidence in their use. We anticipate\nthis work will accelerate research involving expensive simulations, allow more\nextensive parameters exploration, and enable new, previously unfeasible\ncomputational discovery.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:14:12 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 14:42:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Kasim", "M. F.", ""], ["Watson-Parris", "D.", ""], ["Deaconu", "L.", ""], ["Oliver", "S.", ""], ["Hatfield", "P.", ""], ["Froula", "D. H.", ""], ["Gregori", "G.", ""], ["Jarvis", "M.", ""], ["Khatiwala", "S.", ""], ["Korenaga", "J.", ""], ["Topp-Mugglestone", "J.", ""], ["Viezzer", "E.", ""], ["Vinko", "S. M.", ""]]}, {"id": "2001.08073", "submitter": "Nathana\\\"el Carraz Rakotonirina", "authors": "Nathana\\\"el Carraz Rakotonirina, Andry Rasoanaivo", "title": "ESRGAN+ : Further Improving Enhanced Super-Resolution Generative\n  Adversarial Network", "comments": "ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054071", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhanced Super-Resolution Generative Adversarial Network (ESRGAN) is a\nperceptual-driven approach for single image super resolution that is able to\nproduce photorealistic images. Despite the visual quality of these generated\nimages, there is still room for improvement. In this fashion, the model is\nextended to further improve the perceptual quality of the images. We have\ndesigned a novel block to replace the one used by the original ESRGAN.\nMoreover, we introduce noise inputs to the generator network in order to\nexploit stochastic variation. The resulting images present more realistic\ntextures. The code is available at https://github.com/ncarraz/ESRGANplus .\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:44:15 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 10:15:37 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Rakotonirina", "Nathana\u00ebl Carraz", ""], ["Rasoanaivo", "Andry", ""]]}, {"id": "2001.08075", "submitter": "Yang Chen", "authors": "Yang Chen", "title": "Active Learning over DNN: Automated Engineering Design Optimization for\n  Fluid Dynamics Based on Self-Simulated Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing fluid-dynamic performance is an important engineering task.\nTraditionally, experts design shapes based on empirical estimations and verify\nthem through expensive experiments. This costly process, both in terms of time\nand space, may only explore a limited number of shapes and lead to sub-optimal\ndesigns. In this research, a test-proven deep learning architecture is applied\nto predict the performance under various restrictions and search for better\nshapes by optimizing the learned prediction function. The major challenge is\nthe vast amount of data points Deep Neural Network (DNN) demands, which is\nimprovident to simulate. To remedy this drawback, a Frequentist active learning\nis used to explore regions of the output space that DNN predicts promising.\nThis operation reduces the number of data samples demanded from ~8000 to 625.\nThe final stage, a user interface, made the model capable of optimizing with\ngiven user input of minimum area and viscosity. Flood fill is used to define a\nboundary area function so that the optimal shape does not bypass the minimum\narea. Stochastic Gradient Langevin Dynamics (SGLD) is employed to make sure the\nultimate shape is optimized while circumventing the required area. Jointly,\nshapes with extremely low drags are found explored by a practical user\ninterface with no human domain knowledge and modest computation overhead.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 07:35:00 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 03:16:45 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Chen", "Yang", ""]]}, {"id": "2001.08088", "submitter": "Shakiba Yaghoubi", "authors": "Shakiba Yaghoubi, Georgios Fainekos, Sriram Sankaranarayanan", "title": "Training Neural Network Controllers Using Control Barrier Functions in\n  the Presence of Disturbances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control Barrier Functions (CBF) have been recently utilized in the design of\nprovably safe feedback control laws for nonlinear systems. These feedback\ncontrol methods typically compute the next control input by solving an online\nQuadratic Program (QP). Solving QP in real-time can be a computationally\nexpensive process for resource constraint systems. In this work, we propose to\nuse imitation learning to learn Neural Network-based feedback controllers which\nwill satisfy the CBF constraints. In the process, we also develop a new class\nof High Order CBF for systems under external disturbances. We demonstrate the\nframework on a unicycle model subject to external disturbances, e.g., wind or\ncurrents.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 18:43:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Yaghoubi", "Shakiba", ""], ["Fainekos", "Georgios", ""], ["Sankaranarayanan", "Sriram", ""]]}, {"id": "2001.08090", "submitter": "Romain Bey", "authors": "R. Bey, R. Goussault, M. Benchoufi, R. Porcher", "title": "Stratified cross-validation for unbiased and privacy-preserving\n  federated learning", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": "10.1093/jamia/ocaa096", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale collections of electronic records constitute both an opportunity\nfor the development of more accurate prediction models and a threat for\nprivacy. To limit privacy exposure new privacy-enhancing techniques are\nemerging such as federated learning which enables large-scale data analysis\nwhile avoiding the centralization of records in a unique database that would\nrepresent a critical point of failure. Although promising regarding privacy\nprotection, federated learning prevents using some data-cleaning algorithms\nthus inducing new biases. In this work we focus on the recurrent problem of\nduplicated records that, if not handled properly, may cause over-optimistic\nestimations of a model's performances. We introduce and discuss stratified\ncross-validation, a validation methodology that leverages stratification\ntechniques to prevent data leakage in federated learning settings without\nrelying on demanding deduplication algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:49:34 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 08:43:26 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bey", "R.", ""], ["Goussault", "R.", ""], ["Benchoufi", "M.", ""], ["Porcher", "R.", ""]]}, {"id": "2001.08092", "submitter": "Devesh Jha", "authors": "Patrik Kolaric, Devesh K. Jha, Arvind U. Raghunathan, Frank L. Lewis,\n  Mouhacine Benosman, Diego Romeres and Daniel Nikovski", "title": "Local Policy Optimization for Trajectory-Centric Reinforcement Learning", "comments": null, "journal-ref": "ICRA 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to present a method for simultaneous trajectory and\nlocal stabilizing policy optimization to generate local policies for\ntrajectory-centric model-based reinforcement learning (MBRL). This is motivated\nby the fact that global policy optimization for non-linear systems could be a\nvery challenging problem both algorithmically and numerically. However, a lot\nof robotic manipulation tasks are trajectory-centric, and thus do not require a\nglobal model or policy. Due to inaccuracies in the learned model estimates, an\nopen-loop trajectory optimization process mostly results in very poor\nperformance when used on the real system. Motivated by these problems, we try\nto formulate the problem of trajectory optimization and local policy synthesis\nas a single optimization problem. It is then solved simultaneously as an\ninstance of nonlinear programming. We provide some results for analysis as well\nas achieved performance of the proposed technique under some simplifying\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:56:00 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kolaric", "Patrik", ""], ["Jha", "Devesh K.", ""], ["Raghunathan", "Arvind U.", ""], ["Lewis", "Frank L.", ""], ["Benosman", "Mouhacine", ""], ["Romeres", "Diego", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2001.08099", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Olaf Owe", "title": "PDS: Deduce Elder Privacy from Smart Homes", "comments": "31 pages, 23 figures, and 2 tables, journal paper. arXiv admin note:\n  text overlap with arXiv:1808.07379", "journal-ref": "Internet of Things, 7, 1000072, 2019", "doi": "10.1016/j.iot.2019.100072", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of IoT technologies in the past few years, a wide range\nof smart devices are deployed in a variety of environments aiming to improve\nthe quality of human life in a cost efficient way. Due to the increasingly\nserious aging problem around the world, smart homes for elder healthcare have\nbecome an important IoT-based application, which not only enables elders'\nhealth to be properly monitored and taken care of, but also allows them to live\nmore comfortably and independently in their houses. However, elders' privacy\nmight be disclosed from smart homes due to non-fully protected network\ncommunication. To show that elders' privacy could be substantially exposed, in\nthis paper we develop a Privacy Deduction Scheme (PDS for short) by\neavesdropping sensor traffic from a smart home to identify elders' movement\nactivities and speculating sensor locations in the smart home based on a series\nof deductions from the viewpoint of an attacker. The experimental results based\non sensor datasets from real smart homes demonstrate the effectiveness of PDS\nin deducing and disclosing elders' privacy, which might be maliciously\nexploited by attackers to endanger elders and their properties.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 13:55:40 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Owe", "Olaf", ""]]}, {"id": "2001.08103", "submitter": "Adnan Qayyum", "authors": "Adnan Qayyum, Junaid Qadir, Muhammad Bilal, and Ala Al-Fuqaha", "title": "Secure and Robust Machine Learning for Healthcare: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed widespread adoption of machine learning (ML)/deep\nlearning (DL) techniques due to their superior performance for a variety of\nhealthcare applications ranging from the prediction of cardiac arrest from\none-dimensional heart signals to computer-aided diagnosis (CADx) using\nmulti-dimensional medical images. Notwithstanding the impressive performance of\nML/DL, there are still lingering doubts regarding the robustness of ML/DL in\nhealthcare settings (which is traditionally considered quite challenging due to\nthe myriad security and privacy issues involved), especially in light of recent\nresults that have shown that ML/DL are vulnerable to adversarial attacks. In\nthis paper, we present an overview of various application areas in healthcare\nthat leverage such techniques from security and privacy point of view and\npresent associated challenges. In addition, we present potential methods to\nensure secure and privacy-preserving ML for healthcare applications. Finally,\nwe provide insight into the current research challenges and promising\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 08:12:36 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Qayyum", "Adnan", ""], ["Qadir", "Junaid", ""], ["Bilal", "Muhammad", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2001.08109", "submitter": "Xiaoming Li", "authors": "Xiaoming Li, Chun Wang, Xiao Huang", "title": "DDKSP: A Data-Driven Stochastic Programming Framework for Car-Sharing\n  Relocation Problem", "comments": "arXiv admin note: text overlap with arXiv:1909.09293", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car-sharing issue is a popular research field in sharing economy. In this\npaper, we investigate the car-sharing relocation problem (CSRP) under uncertain\ndemands. Normally, the real customer demands follow complicating probability\ndistribution which cannot be described by parametric approaches. In order to\novercome the problem, an innovative framework called Data-Driven Kernel\nStochastic Programming (DDKSP) that integrates a non-parametric approach -\nkernel density estimation (KDE) and a two-stage stochastic programming (SP)\nmodel is proposed. Specifically, the probability distributions are derived from\nhistorical data by KDE, which are used as the input uncertain parameters for\nSP. Additionally, the CSRP is formulated as a two-stage SP model. Meanwhile, a\nMonte Carlo method called sample average approximation (SAA) and Benders\ndecomposition algorithm are introduced to solve the large-scale optimization\nmodel. Finally, the numerical experimental validations which are based on New\nYork taxi trip data sets show that the proposed framework outperforms the pure\nparametric approaches including Gaussian, Laplace and Poisson distributions\nwith 3.72% , 4.58% and 11% respectively in terms of overall profits.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 19:04:29 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Li", "Xiaoming", ""], ["Wang", "Chun", ""], ["Huang", "Xiao", ""]]}, {"id": "2001.08116", "submitter": "David Warde-Farley", "authors": "Tom Van de Wiele, David Warde-Farley, Andriy Mnih and Volodymyr Mnih", "title": "Q-Learning in enormous action spaces via amortized approximate\n  maximization", "comments": "A previous version of this work appeared at the Deep Reinforcement\n  Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying Q-learning to high-dimensional or continuous action spaces can be\ndifficult due to the required maximization over the set of possible actions.\nMotivated by techniques from amortized inference, we replace the expensive\nmaximization over all actions with a maximization over a small subset of\npossible actions sampled from a learned proposal distribution. The resulting\napproach, which we dub Amortized Q-learning (AQL), is able to handle discrete,\ncontinuous, or hybrid action spaces while maintaining the benefits of\nQ-learning. Our experiments on continuous control tasks with up to 21\ndimensional actions show that AQL outperforms D3PG (Barth-Maron et al, 2018)\nand QT-Opt (Kalashnikov et al, 2018). Experiments on structured discrete action\nspaces demonstrate that AQL can efficiently learn good policies in spaces with\nthousands of discrete actions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:14:38 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Van de Wiele", "Tom", ""], ["Warde-Farley", "David", ""], ["Mnih", "Andriy", ""], ["Mnih", "Volodymyr", ""]]}, {"id": "2001.08126", "submitter": "Sheng Zhong", "authors": "Sheng Zhong and Shifu Zhou (Agora.io)", "title": "Optimizing Generative Adversarial Networks for Image Super Resolution\n  via Latent Space Regularization", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural images can be regarded as residing in a manifold that is embedded in\na higher dimensional Euclidean space. Generative Adversarial Networks (GANs)\ntry to learn the distribution of the real images in the manifold to generate\nsamples that look real. But the results of existing methods still exhibit many\nunpleasant artifacts and distortions even for the cases where the desired\nground truth target images are available for supervised learning such as in\nsingle image super resolution (SISR). We probe for ways to alleviate these\nproblems for supervised GANs in this paper. We explicitly apply the Lipschitz\nContinuity Condition (LCC) to regularize the GAN. An encoding network that maps\nthe image space to a new optimal latent space is derived from the LCC, and it\nis used to augment the GAN as a coupling component. The LCC is also converted\nto new regularization terms in the generator loss function to enforce local\ninvariance. The GAN is optimized together with the encoding network in an\nattempt to make the generator converge to a more ideal and disentangled mapping\nthat can generate samples more faithful to the target images. When the proposed\nmodels are applied to the single image super resolution problem, the results\noutperform the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:27:20 GMT"}, {"version": "v2", "created": "Sat, 9 Jan 2021 04:40:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhong", "Sheng", "", "Agora.io"], ["Zhou", "Shifu", "", "Agora.io"]]}, {"id": "2001.08140", "submitter": "Di Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits", "title": "A Simple Baseline to Semi-Supervised Domain Adaptation for Machine\n  Translation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural machine translation (NMT) systems are data-hungry and\nperform poorly on new domains with no supervised data. As data collection is\nexpensive and infeasible in many cases, domain adaptation methods are needed.\nIn this work, we propose a simple but effect approach to the semi-supervised\ndomain adaptation scenario of NMT, where the aim is to improve the performance\nof a translation model on the target domain consisting of only non-parallel\ndata with the help of supervised source domain data. This approach iteratively\ntrains a Transformer-based NMT model via three training objectives: language\nmodeling, back-translation, and supervised translation. We evaluate this method\non two adaptation settings: adaptation between specific domains and adaptation\nfrom a general domain to specific domains, and on two language pairs: German to\nEnglish and Romanian to English. With substantial performance improvement\nachieved---up to +19.31 BLEU over the strongest baseline, and +47.69 BLEU\nimprovement over the unadapted model---we present this method as a simple but\ntough-to-beat baseline in the field of semi-supervised domain adaptation for\nNMT.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:42:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 02:45:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2001.08142", "submitter": "Csan\\'ad S\\'andor", "authors": "Csan\\'ad S\\'andor, Szabolcs P\\'avel, Lehel Csat\\'o", "title": "Pruning CNN's with linear filter ensembles", "comments": "accepted to ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the promising results of convolutional neural networks (CNNs), their\napplication on devices with limited resources is still a big challenge; this is\nmainly due to the huge memory and computation requirements of the CNN. To\ncounter the limitation imposed by the network size, we use pruning to reduce\nthe network size and -- implicitly -- the number of floating point operations\n(FLOPs). Contrary to the filter norm method -- used in ``conventional`` network\npruning -- based on the assumption that a smaller norm implies ``less\nimportance'' to its associated component, we develop a novel filter importance\nnorm that is based on the change in the empirical loss caused by the presence\nor removal of a component from the network architecture.\n  Since there are too many individual possibilities for filter configuration,\nwe repeatedly sample from these architectural components and measure the system\nperformance in the respective state of components being active or disabled. The\nresult is a collection of filter ensembles -- filter masks -- and associated\nperformance values. We rank the filters based on a linear and additive model\nand remove the least important ones such that the drop in network accuracy is\nminimal. We evaluate our method on a fully connected network, as well as on the\nResNet architecture trained on the CIFAR-10 dataset. Using our pruning method,\nwe managed to remove $60\\%$ of the parameters and $64\\%$ of the FLOPs from the\nResNet with an accuracy drop of less than $0.6\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:52:06 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 09:25:32 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["S\u00e1ndor", "Csan\u00e1d", ""], ["P\u00e1vel", "Szabolcs", ""], ["Csat\u00f3", "Lehel", ""]]}, {"id": "2001.08155", "submitter": "Awais Ahmed Mr", "authors": "Awais Ahmed, Sufian Hameed, Muhammad Rafi, Qublai Khan Ali Mirza", "title": "An Intelligent and Time-Efficient DDoS Identification Framework for\n  Real-Time Enterprise Networks SAD-F: Spark Based Anomaly Detection Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a crucial step for preventing malicious activities in\nthe network and keeping resources available all the time for legitimate users.\nIt is noticed from various studies that classical anomaly detectors work well\nwith small and sampled data, but the chances of failures increase with\nreal-time (non-sampled data) traffic data. In this paper, we will be exploring\nsecurity analytic techniques for DDoS anomaly detection using different machine\nlearning techniques. In this paper, we are proposing a novel approach which\ndeals with real traffic as input to the system. Further, we study and compare\nthe performance factor of our proposed framework on three different testbeds\nincluding normal commodity hardware, low-end system, and high-end system.\nHardware details of testbeds are discussed in the respective section. Further\nin this paper, we investigate the performance of the classifiers in (near)\nreal-time detection of anomalies attacks. This study also focused on the\nfeature selection process that is as important for the anomaly detection\nprocess as it is for general modeling problems. Several techniques have been\nstudied for feature selection and it is observed that proper feature selection\ncan increase performance in terms of model's execution time - which totally\ndepends upon the traffic file or traffic capturing process.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:05:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 12:19:56 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ahmed", "Awais", ""], ["Hameed", "Sufian", ""], ["Rafi", "Muhammad", ""], ["Mirza", "Qublai Khan Ali", ""]]}, {"id": "2001.08169", "submitter": "Nawanol Theera-Ampornpunt", "authors": "Nawanol Theera-Ampornpunt, Shikhar Suryavansh, Sameer Manchanda,\n  Rajesh Panta, Kaustubh Joshi, Mostafa Ammar, Mung Chiang, Saurabh Bagchi", "title": "AppStreamer: Reducing Storage Requirements of Mobile Games through\n  Predictive Streaming", "comments": "12 pages; EWSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage has become a constrained resource on smartphones. Gaming is a popular\nactivity on mobile devices and the explosive growth in the number of games\ncoupled with their growing size contributes to the storage crunch. Even where\nstorage is plentiful, it takes a long time to download and install a heavy app\nbefore it can be launched. This paper presents AppStreamer, a novel technique\nfor reducing the storage requirements or startup delay of mobile games, and\nheavy mobile apps in general. AppStreamer is based on the intuition that most\napps do not need the entirety of its files (images, audio and video clips,\netc.) at any one time. AppStreamer can, therefore, keep only a small part of\nthe files on the device, akin to a \"cache\", and download the remainder from a\ncloud storage server or a nearby edge server when it predicts that the app will\nneed them in the near future. AppStreamer continuously predicts file blocks for\nthe near future as the user uses the app, and fetches them from the storage\nserver before the user sees a stall due to missing resources. We implement\nAppStreamer at the Android file system layer. This ensures that the apps\nrequire no source code or modification, and the approach generalizes across\napps. We evaluate AppStreamer using two popular games: Dead Effect 2, a 3D\nfirst-person shooter, and Fire Emblem Heroes, a 2D turn-based strategy\nrole-playing game. Through a user study, 75% and 87% of the users respectively\nfind that AppStreamer provides the same quality of user experience as the\nbaseline where all files are stored on the device. AppStreamer cuts down the\nstorage requirement by 87% for Dead Effect 2 and 86% for Fire Emblem Heroes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:42:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Theera-Ampornpunt", "Nawanol", ""], ["Suryavansh", "Shikhar", ""], ["Manchanda", "Sameer", ""], ["Panta", "Rajesh", ""], ["Joshi", "Kaustubh", ""], ["Ammar", "Mostafa", ""], ["Chiang", "Mung", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2001.08177", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Patrick Mannion, Yijie Zhang, Diederik M.\n  Roijers, and Ann Now\\'e", "title": "A utility-based analysis of equilibria in multi-objective normal form\n  games", "comments": "Under review since 16 January 2020", "journal-ref": null, "doi": "10.1017/S0269888920000351", "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-objective multi-agent systems (MOMAS), agents explicitly consider\nthe possible tradeoffs between conflicting objective functions. We argue that\ncompromises between competing objectives in MOMAS should be analysed on the\nbasis of the utility that these compromises have for the users of a system,\nwhere an agent's utility function maps their payoff vectors to scalar utility\nvalues. This utility-based approach naturally leads to two different\noptimisation criteria for agents in a MOMAS: expected scalarised returns (ESR)\nand scalarised expected returns (SER). In this article, we explore the\ndifferences between these two criteria using the framework of multi-objective\nnormal form games (MONFGs). We demonstrate that the choice of optimisation\ncriterion (ESR or SER) can radically alter the set of equilibria in a MONFG\nwhen non-linear utility functions are used.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:27:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Mannion", "Patrick", ""], ["Zhang", "Yijie", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2001.08179", "submitter": "Xingyao Zhang", "authors": "Xingyao Zhang, Cao Xiao, Lucas M. Glass, Jimeng Sun", "title": "DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment\n  Prediction", "comments": "accepted by The World Wide Web Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials are essential for drug development but often suffer from\nexpensive, inaccurate and insufficient patient recruitment. The core problem of\npatient-trial matching is to find qualified patients for a trial, where patient\ninformation is stored in electronic health records (EHR) while trial\neligibility criteria (EC) are described in text documents available on the web.\nHow to represent longitudinal patient EHR? How to extract complex logical rules\nfrom EC? Most existing works rely on manual rule-based extraction, which is\ntime consuming and inflexible for complex inference. To address these\nchallenges, we proposed DeepEnroll, a cross-modal inference learning model to\njointly encode enrollment criteria (text) and patients records (tabular data)\ninto a shared latent space for matching inference. DeepEnroll applies a\npre-trained Bidirectional Encoder Representations from Transformers(BERT) model\nto encode clinical trial information into sentence embedding. And uses a\nhierarchical embedding model to represent patient longitudinal EHR. In\naddition, DeepEnroll is augmented by a numerical information embedding and\nentailment module to reason over numerical information in both EC and EHR.\nThese encoders are trained jointly to optimize patient-trial matching score. We\nevaluated DeepEnroll on the trial-patient matching task with demonstrated on\nreal world datasets. DeepEnroll outperformed the best baseline by up to 12.4%\nin average F1.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:51:25 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 02:39:47 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Xingyao", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.08184", "submitter": "Harsh Vardhan Jain", "authors": "Nikhil Goyal, Harsh Vardhan Jain, Sayan Ranu", "title": "GraphGen: A Scalable Approach to Domain-agnostic Labeled Graph\n  Generation", "comments": "Fixed typo in Table 1; The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph generative models have been extensively studied in the data mining\nliterature. While traditional techniques are based on generating structures\nthat adhere to a pre-decided distribution, recent techniques have shifted\ntowards learning this distribution directly from the data. While learning-based\napproaches have imparted significant improvement in quality, some limitations\nremain to be addressed. First, learning graph distributions introduces\nadditional computational overhead, which limits their scalability to large\ngraph databases. Second, many techniques only learn the structure and do not\naddress the need to also learn node and edge labels, which encode important\nsemantic information and influence the structure itself. Third, existing\ntechniques often incorporate domain-specific rules and lack generalizability.\nFourth, the experimentation of existing techniques is not comprehensive enough\ndue to either using weak evaluation metrics or focusing primarily on synthetic\nor small datasets. In this work, we develop a domain-agnostic technique called\nGraphGen to overcome all of these limitations. GraphGen converts graphs to\nsequences using minimum DFS codes. Minimum DFS codes are canonical labels and\ncapture the graph structure precisely along with the label information. The\ncomplex joint distributions between structure and semantic labels are learned\nthrough a novel LSTM architecture. Extensive experiments on million-sized, real\ngraph datasets show GraphGen to be 4 times faster on average than\nstate-of-the-art techniques while being significantly better in quality across\na comprehensive set of 11 different metrics. Our code is released at\nhttps://github.com/idea-iitd/graphgen.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:07:43 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 13:18:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Goyal", "Nikhil", ""], ["Jain", "Harsh Vardhan", ""], ["Ranu", "Sayan", ""]]}, {"id": "2001.08188", "submitter": "Richard Droste", "authors": "Richard Droste, Pierre Chatelain, Lior Drukker, Harshita Sharma, Aris\n  T. Papageorghiou, J. Alison Noble", "title": "Discovering Salient Anatomical Landmarks by Predicting Human Gaze", "comments": "Accepted at IEEE International Symposium on Biomedical Imaging 2020\n  (ISBI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anatomical landmarks are a crucial prerequisite for many medical imaging\ntasks. Usually, the set of landmarks for a given task is predefined by experts.\nThe landmark locations for a given image are then annotated manually or via\nmachine learning methods trained on manual annotations. In this paper, in\ncontrast, we present a method to automatically discover and localize anatomical\nlandmarks in medical images. Specifically, we consider landmarks that attract\nthe visual attention of humans, which we term visually salient landmarks. We\nillustrate the method for fetal neurosonographic images. First, full-length\nclinical fetal ultrasound scans are recorded with live sonographer\ngaze-tracking. Next, a convolutional neural network (CNN) is trained to predict\nthe gaze point distribution (saliency map) of the sonographers on scan video\nframes. The CNN is then used to predict saliency maps of unseen fetal\nneurosonographic images, and the landmarks are extracted as the local maxima of\nthese saliency maps. Finally, the landmarks are matched across images by\nclustering the landmark CNN features. We show that the discovered landmarks can\nbe used within affine image registration, with average landmark alignment\nerrors between 4.1% and 10.9% of the fetal head long axis length.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:17:14 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Droste", "Richard", ""], ["Chatelain", "Pierre", ""], ["Drukker", "Lior", ""], ["Sharma", "Harshita", ""], ["Papageorghiou", "Aris T.", ""], ["Noble", "J. Alison", ""]]}, {"id": "2001.08189", "submitter": "Rafael Fricks", "authors": "Rafael B. Fricks, Justin Solomon, Ehsan Samei", "title": "Automatic phantom test pattern classification through transfer learning\n  with deep neural networks", "comments": null, "journal-ref": null, "doi": "10.1117/12.2549366", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imaging phantoms are test patterns used to measure image quality in computer\ntomography (CT) systems. A new phantom platform (Mercury Phantom, Gammex)\nprovides test patterns for estimating the task transfer function (TTF) or noise\npower spectrum (NPF) and simulates different patient sizes. Determining which\nimage slices are suitable for analysis currently requires manual annotation of\nthese patterns by an expert, as subtle defects may make an image unsuitable for\nmeasurement. We propose a method of automatically classifying these test\npatterns in a series of phantom images using deep learning techniques. By\nadapting a convolutional neural network based on the VGG19 architecture with\nweights trained on ImageNet, we use transfer learning to produce a classifier\nfor this domain. The classifier is trained and evaluated with over 3,500\nphantom images acquired at a university medical center. Input channels for\ncolor images are successfully adapted to convey contextual information for\nphantom images. A series of ablation studies are employed to verify design\naspects of the classifier and evaluate its performance under varying training\nconditions. Our solution makes extensive use of image augmentation to produce a\nclassifier that accurately classifies typical phantom images with 98% accuracy,\nwhile maintaining as much as 86% accuracy when the phantom is improperly\nimaged.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:17:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fricks", "Rafael B.", ""], ["Solomon", "Justin", ""], ["Samei", "Ehsan", ""]]}, {"id": "2001.08247", "submitter": "Ziyang Tang", "authors": "Ziyang Tang, Xiang Liu, Guangyu Shen, and Baijian Yang", "title": "PENet: Object Detection using Points Estimation in Aerial Images", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerial imagery has been increasingly adopted in mission-critical tasks, such\nas traffic surveillance, smart cities, and disaster assistance. However,\nidentifying objects from aerial images faces the following challenges: 1)\nobjects of interests are often too small and too dense relative to the images;\n2) objects of interests are often in different relative sizes; and 3) the\nnumber of objects in each category is imbalanced. A novel network structure,\nPoints Estimated Network (PENet), is proposed in this work to answer these\nchallenges. PENet uses a Mask Resampling Module (MRM) to augment the imbalanced\ndatasets, a coarse anchor-free detector (CPEN) to effectively predict the\ncenter points of the small object clusters, and a fine anchor-free detector\nFPEN to locate the precise positions of the small objects. An adaptive merge\nalgorithm Non-maximum Merge (NMM) is implemented in CPEN to address the issue\nof detecting dense small objects, and a hierarchical loss is defined in FPEN to\nfurther improve the classification accuracy. Our extensive experiments on\naerial datasets visDrone and UAVDT showed that PENet achieved higher precision\nresults than existing state-of-the-art approaches. Our best model achieved 8.7%\nimprovement on visDrone and 20.3% on UAVDT.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 19:43:17 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tang", "Ziyang", ""], ["Liu", "Xiang", ""], ["Shen", "Guangyu", ""], ["Yang", "Baijian", ""]]}, {"id": "2001.08248", "submitter": "Md Amirul Islam", "authors": "Md Amirul Islam, Sen Jia, Neil D. B. Bruce", "title": "How Much Position Information Do Convolutional Neural Networks Encode?", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to fully connected networks, Convolutional Neural Networks (CNNs)\nachieve efficiency by learning weights associated with local filters with a\nfinite spatial extent. An implication of this is that a filter may know what it\nis looking at, but not where it is positioned in the image. Information\nconcerning absolute position is inherently useful, and it is reasonable to\nassume that deep CNNs may implicitly learn to encode this information if there\nis a means to do so. In this paper, we test this hypothesis revealing the\nsurprising degree of absolute position information that is encoded in commonly\nused neural networks. A comprehensive set of experiments show the validity of\nthis hypothesis and shed light on how and where this information is represented\nwhile offering clues to where positional information is derived from in deep\nCNNs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 19:44:43 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Islam", "Md Amirul", ""], ["Jia", "Sen", ""], ["Bruce", "Neil D. B.", ""]]}, {"id": "2001.08255", "submitter": "Stefan L\\\"ockel", "authors": "Stefan L\\\"ockel, Jan Peters, Peter van Vliet", "title": "A Probabilistic Framework for Imitating Human Race Driver Behavior", "comments": "updated references [17] and [33]; added journal info", "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 2, pp.\n  2086-2093, April 2020", "doi": "10.1109/LRA.2020.2970620", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and modeling human driver behavior is crucial for advanced\nvehicle development. However, unique driving styles, inconsistent behavior, and\ncomplex decision processes render it a challenging task, and existing\napproaches often lack variability or robustness. To approach this problem, we\npropose Probabilistic Modeling of Driver behavior (ProMoD), a modular framework\nwhich splits the task of driver behavior modeling into multiple modules. A\nglobal target trajectory distribution is learned with Probabilistic Movement\nPrimitives, clothoids are utilized for local path generation, and the\ncorresponding choice of actions is performed by a neural network. Experiments\nin a simulated car racing setting show considerable advantages in imitation\naccuracy and robustness compared to other imitation learning algorithms. The\nmodular architecture of the proposed framework facilitates straightforward\nextensibility in driving line adaptation and sequencing of multiple movement\nprimitives for future research.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:06:38 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 09:43:38 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["L\u00f6ckel", "Stefan", ""], ["Peters", "Jan", ""], ["van Vliet", "Peter", ""]]}, {"id": "2001.08269", "submitter": "Karol Antczak", "authors": "Karol Antczak", "title": "Representation Learning for Medical Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a representation learning framework for medical diagnosis domain.\nIt is based on heterogeneous network-based model of diagnostic data as well as\nmodified metapath2vec algorithm for learning latent node representation. We\ncompare the proposed algorithm with other representation learning methods in\ntwo practical case studies: symptom/disease classification and disease\nprediction. We observe a significant performance boost in these task resulting\nfrom learning representations of domain data in a form of heterogeneous\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:34:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "2001.08277", "submitter": "Haozhao Wang", "authors": "Haozhao Wang, Zhihao Qu, Song Guo, Xin Gao, Ruixuan Li, and Baoliu Ye", "title": "Intermittent Pulling with Local Compensation for Communication-Efficient\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a powerful machine learning paradigm to cooperatively\ntrain a global model with highly distributed data. A major bottleneck on the\nperformance of distributed Stochastic Gradient Descent (SGD) algorithm for\nlarge-scale Federated Learning is the communication overhead on pushing local\ngradients and pulling global model. In this paper, to reduce the communication\ncomplexity of Federated Learning, a novel approach named Pulling Reduction with\nLocal Compensation (PRLC) is proposed. Specifically, each training node\nintermittently pulls the global model from the server in SGD iterations,\nresulting in that it is sometimes unsynchronized with the server. In such a\ncase, it will use its local update to compensate the gap between the local\nmodel and the global model. Our rigorous theoretical analysis of PRLC achieves\ntwo important findings. First, we prove that the convergence rate of PRLC\npreserves the same order as the classical synchronous SGD for both\nstrongly-convex and non-convex cases with good scalability due to the linear\nspeedup with respect to the number of training nodes. Second, we show that PRLC\nadmits lower pulling frequency than the existing pulling reduction method\nwithout local compensation. We also conduct extensive experiments on various\nmachine learning models to validate our theoretical results. Experimental\nresults show that our approach achieves a significant pulling reduction over\nthe state-of-the-art methods, e.g., PRLC requiring only half of the pulling\noperations of LAG.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:53:14 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wang", "Haozhao", ""], ["Qu", "Zhihao", ""], ["Guo", "Song", ""], ["Gao", "Xin", ""], ["Li", "Ruixuan", ""], ["Ye", "Baoliu", ""]]}, {"id": "2001.08279", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Miguel Ballesteros, Chris Dyer, Robert\n  Frederking", "title": "Transition-Based Dependency Parsing using Perceptron Learner", "comments": "This was part of an assignment at my graduate course at LTI. This\n  does not offer any major novelties", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing using dependency structures has become a standard technique\nin natural language processing with many different parsing models, in\nparticular data-driven models that can be trained on syntactically annotated\ncorpora. In this paper, we tackle transition-based dependency parsing using a\nPerceptron Learner. Our proposed model, which adds more relevant features to\nthe Perceptron Learner, outperforms a baseline arc-standard parser. We beat the\nUAS of the MALT and LSTM parsers. We also give possible ways to address parsing\nof non-projective trees.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:58:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 22:09:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Ballesteros", "Miguel", ""], ["Dyer", "Chris", ""], ["Frederking", "Robert", ""]]}, {"id": "2001.08286", "submitter": "Justin  Reyes", "authors": "Justin Reyes, Miles Stoudenmire", "title": "A Multi-Scale Tensor Network Architecture for Classification and\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for supervised learning using tensor networks,\nemploying a step of preprocessing the data by coarse-graining through a\nsequence of wavelet transformations. We represent these transformations as a\nset of tensor network layers identical to those in a multi-scale entanglement\nrenormalization ansatz (MERA) tensor network, and perform supervised learning\nand regression tasks through a model based on a matrix product state (MPS)\ntensor network acting on the coarse-grained data. Because the entire model\nconsists of tensor contractions (apart from the initial non-linear feature\nmap), we can adaptively fine-grain the optimized MPS model backwards through\nthe layers with essentially no loss in performance. The MPS itself is trained\nusing an adaptive algorithm based on the density matrix renormalization group\n(DMRG) algorithm. We test our methods by performing a classification task on\naudio data and a regression task on temperature time-series data, studying the\ndependence of training accuracy on the number of coarse-graining layers and\nshowing how fine-graining through the network may be used to initialize models\nwith access to finer-scale features.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 21:26:28 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Reyes", "Justin", ""], ["Stoudenmire", "Miles", ""]]}, {"id": "2001.08290", "submitter": "Haoran Miao", "authors": "Haoran Miao, Gaofeng Cheng, Changfeng Gao, Pengyuan Zhang and Yonghong\n  Yan", "title": "Transformer-based Online CTC/attention End-to-End Speech Recognition\n  Architecture", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Transformer has gained success in automatic speech recognition\n(ASR) field. However, it is challenging to deploy a Transformer-based\nend-to-end (E2E) model for online speech recognition. In this paper, we propose\nthe Transformer-based online CTC/attention E2E ASR architecture, which contains\nthe chunk self-attention encoder (chunk-SAE) and the monotonic truncated\nattention (MTA) based self-attention decoder (SAD). Firstly, the chunk-SAE\nsplits the speech into isolated chunks. To reduce the computational cost and\nimprove the performance, we propose the state reuse chunk-SAE. Sencondly, the\nMTA based SAD truncates the speech features monotonically and performs\nattention on the truncated features. To support the online recognition, we\nintegrate the state reuse chunk-SAE and the MTA based SAD into online\nCTC/attention architecture. We evaluate the proposed online models on the HKUST\nMandarin ASR benchmark and achieve a 23.66% character error rate (CER) with a\n320 ms latency. Our online model yields as little as 0.19% absolute CER\ndegradation compared with the offline baseline, and achieves significant\nimprovement over our prior work on Long Short-Term Memory (LSTM) based online\nE2E models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:36:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:05:47 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Miao", "Haoran", ""], ["Cheng", "Gaofeng", ""], ["Gao", "Changfeng", ""], ["Zhang", "Pengyuan", ""], ["Yan", "Yonghong", ""]]}, {"id": "2001.08299", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Tom Silver, Joshua Tenenbaum, Leslie Pack Kaelbling,\n  Tomas Lozano-Perez", "title": "GLIB: Efficient Exploration for Relational Model-Based Reinforcement\n  Learning via Goal-Literal Babbling", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of efficient exploration for transition model learning\nin the relational model-based reinforcement learning setting without extrinsic\ngoals or rewards. Inspired by human curiosity, we propose goal-literal babbling\n(GLIB), a simple and general method for exploration in such problems. GLIB\nsamples relational conjunctive goals that can be understood as specific,\ntargeted effects that the agent would like to achieve in the world, and plans\nto achieve these goals using the transition model being learned. We provide\ntheoretical guarantees showing that exploration with GLIB will converge almost\nsurely to the ground truth model. Experimentally, we find GLIB to strongly\noutperform existing methods in both prediction and planning on a range of\ntasks, encompassing standard PDDL and PPDDL planning benchmarks and a robotic\nmanipulation task implemented in the PyBullet physics simulator. Video:\nhttps://youtu.be/F6lmrPT6TOY Code: https://git.io/JIsTB\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 22:24:06 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:54:54 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 19:53:36 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chitnis", "Rohan", ""], ["Silver", "Tom", ""], ["Tenenbaum", "Joshua", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "2001.08300", "submitter": "Shiqiang Wang", "authors": "Tiffany Tuor, Shiqiang Wang, Bong Jun Ko, Changchang Liu, Kin K. Leung", "title": "Overcoming Noisy and Irrelevant Data in Federated Learning", "comments": "Accepted version in the 25th International Conference on Pattern\n  Recognition (ICPR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many image and vision applications require a large amount of data for model\ntraining. Collecting all such data at a central location can be challenging due\nto data privacy and communication bandwidth restrictions. Federated learning is\nan effective way of training a machine learning model in a distributed manner\nfrom local data collected by client devices, which does not require exchanging\nthe raw data among clients. A challenge is that among the large variety of data\ncollected at each client, it is likely that only a subset is relevant for a\nlearning task while the rest of data has a negative impact on model training.\nTherefore, before starting the learning process, it is important to select the\nsubset of data that is relevant to the given federated learning task. In this\npaper, we propose a method for distributedly selecting relevant data, where we\nuse a benchmark model trained on a small benchmark dataset that is\ntask-specific, to evaluate the relevance of individual data samples at each\nclient and select the data with sufficiently high relevance. Then, each client\nonly uses the selected subset of its data in the federated learning process.\nThe effectiveness of our proposed approach is evaluated on multiple real-world\nimage datasets in a simulated system with a large number of clients, showing up\nto $25\\%$ improvement in model accuracy compared to training with all data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 22:28:47 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:12:29 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tuor", "Tiffany", ""], ["Wang", "Shiqiang", ""], ["Ko", "Bong Jun", ""], ["Liu", "Changchang", ""], ["Leung", "Kin K.", ""]]}, {"id": "2001.08317", "submitter": "Neo Wu", "authors": "Neo Wu, Bradley Green, Xue Ben, Shawn O'Banion", "title": "Deep Transformer Models for Time Series Forecasting: The Influenza\n  Prevalence Case", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new approach to time series forecasting. Time\nseries data are prevalent in many scientific and engineering disciplines. Time\nseries forecasting is a crucial task in modeling time series data, and is an\nimportant area of machine learning. In this work we developed a novel method\nthat employs Transformer-based machine learning models to forecast time series\ndata. This approach works by leveraging self-attention mechanisms to learn\ncomplex patterns and dynamics from time series data. Moreover, it is a generic\nframework and can be applied to univariate and multivariate time series data,\nas well as time series embeddings. Using influenza-like illness (ILI)\nforecasting as a case study, we show that the forecasting results produced by\nour approach are favorably comparable to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 00:22:22 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wu", "Neo", ""], ["Green", "Bradley", ""], ["Ben", "Xue", ""], ["O'Banion", "Shawn", ""]]}, {"id": "2001.08322", "submitter": "Makoto Yamada", "authors": "Dinesh Singh and H\\'ector Climente-Gonz\\'alez and Mathis Petrovich and\n  Eiryo Kawakami and Makoto Yamada", "title": "FsNet: Feature Selection Network on High-dimensional Biological Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological data including gene expression data are generally high-dimensional\nand require efficient, generalizable, and scalable machine-learning methods to\ndiscover their complex nonlinear patterns. The recent advances in machine\nlearning can be attributed to deep neural networks (DNNs), which excel in\nvarious tasks in terms of computer vision and natural language processing.\nHowever, standard DNNs are not appropriate for high-dimensional datasets\ngenerated in biology because they have many parameters, which in turn require\nmany samples. In this paper, we propose a DNN-based, nonlinear feature\nselection method, called the feature selection network (FsNet), for\nhigh-dimensional and small number of sample data. Specifically, FsNet comprises\na selection layer that selects features and a reconstruction layer that\nstabilizes the training. Because a large number of parameters in the selection\nand reconstruction layers can easily result in overfitting under a limited\nnumber of samples, we use two tiny networks to predict the large, virtual\nweight matrices of the selection and reconstruction layers. Experimental\nresults on several real-world, high-dimensional biological datasets demonstrate\nthe efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 00:49:57 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 06:46:11 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 00:48:37 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Singh", "Dinesh", ""], ["Climente-Gonz\u00e1lez", "H\u00e9ctor", ""], ["Petrovich", "Mathis", ""], ["Kawakami", "Eiryo", ""], ["Yamada", "Makoto", ""]]}, {"id": "2001.08328", "submitter": "Yuwei Tu", "authors": "Yuwei Tu, Weiyu Chen, Christopher G. Brinton", "title": "A Deep Learning Approach to Behavior-Based Learner Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of e-learning has created demand for improving\nonline education through techniques such as predictive analytics and content\nrecommendations. In this paper, we study learner outcome predictions, i.e.,\npredictions of how they will perform at the end of a course. We propose a novel\nTwo Branch Decision Network for performance prediction that incorporates two\nimportant factors: how learners progress through the course and how the content\nprogresses through the course. We combine clickstream features which log every\naction the learner takes while learning, and textual features which are\ngenerated through pre-trained GloVe word embeddings. To assess the performance\nof our proposed network, we collect data from a short online course designed\nfor corporate training and evaluate both neural network and non-neural network\nbased algorithms on it. Our proposed algorithm achieves 95.7% accuracy and\n0.958 AUC score, which outperforms all other models. The results also indicate\nthe combination of behavior features and text features are more predictive than\nbehavior features only and neural network models are powerful in capturing the\njoint relationship between user behavior and course content.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:26:52 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tu", "Yuwei", ""], ["Chen", "Weiyu", ""], ["Brinton", "Christopher G.", ""]]}, {"id": "2001.08333", "submitter": "Clarence Chen", "authors": "Clarence Chen, Zachary Pardos", "title": "Applying Recent Innovations from NLP to MOOC Student Course Trajectory\n  Modeling", "comments": "4 pages, 0 figures, accepted to EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several strategies that can improve neural network-based\npredictive methods for MOOC student course trajectory modeling, applying\nmultiple ideas previously applied to tackle NLP (Natural Language Processing)\ntasks. In particular, this paper investigates LSTM networks enhanced with two\nforms of regularization, along with the more recently introduced Transformer\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:36:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 19:11:26 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Clarence", ""], ["Pardos", "Zachary", ""]]}, {"id": "2001.08345", "submitter": "Daniel Jarrett", "authors": "Daniel Jarrett, Mihaela van der Schaar", "title": "Target-Embedding Autoencoders for Supervised Representation Learning", "comments": null, "journal-ref": "In Proc. 8th International Conference on Learning Representations\n  (ICLR 2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder-based learning has emerged as a staple for disciplining\nrepresentations in unsupervised and semi-supervised settings. This paper\nanalyzes a framework for improving generalization in a purely supervised\nsetting, where the target space is high-dimensional. We motivate and formalize\nthe general framework of target-embedding autoencoders (TEA) for supervised\nprediction, learning intermediate latent representations jointly optimized to\nbe both predictable from features as well as predictive of targets---encoding\nthe prior that variations in targets are driven by a compact set of underlying\nfactors. As our theoretical contribution, we provide a guarantee of\ngeneralization for linear TEAs by demonstrating uniform stability, interpreting\nthe benefit of the auxiliary reconstruction task as a form of regularization.\nAs our empirical contribution, we extend validation of this approach beyond\nexisting static classification applications to multivariate sequence\nforecasting, verifying their advantage on both linear and nonlinear recurrent\narchitectures---thereby underscoring the further generality of this framework\nbeyond feedforward instantiations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:37:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2001.08353", "submitter": "Haiyue Song", "authors": "Haiyue Song, Raj Dabre, Zhuoyuan Mao, Fei Cheng, Sadao Kurohashi,\n  Eiichiro Sumita", "title": "Pre-training via Leveraging Assisting Languages and Data Selection for\n  Neural Machine Translation", "comments": "Work in progress. Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (S2S) pre-training using large monolingual data is known\nto improve performance for various S2S NLP tasks in low-resource settings.\nHowever, large monolingual corpora might not always be available for the\nlanguages of interest (LOI). To this end, we propose to exploit monolingual\ncorpora of other languages to complement the scarcity of monolingual corpora\nfor the LOI. A case study of low-resource Japanese-English neural machine\ntranslation (NMT) reveals that leveraging large Chinese and French monolingual\ncorpora can help overcome the shortage of Japanese and English monolingual\ncorpora, respectively, for S2S pre-training. We further show how to utilize\nscript mapping (Chinese to Japanese) to increase the similarity between the two\nmonolingual corpora leading to further improvements in translation quality.\nAdditionally, we propose simple data-selection techniques to be used prior to\npre-training that significantly impact the quality of S2S pre-training. An\nempirical comparison of our proposed methods reveals that leveraging assisting\nlanguage monolingual corpora, data selection and script mapping are extremely\nimportant for NMT pre-training in low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:47:39 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Song", "Haiyue", ""], ["Dabre", "Raj", ""], ["Mao", "Zhuoyuan", ""], ["Cheng", "Fei", ""], ["Kurohashi", "Sadao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "2001.08357", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Zhengang Li, Yifan Gong, Tianyun Zhang, Wei Niu, Zheng\n  Zhan, Pu Zhao, Jian Tang, Xue Lin, Bin Ren, Yanzhi Wang", "title": "BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted\n  Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating DNN execution on various resource-limited computing platforms\nhas been a long-standing problem. Prior works utilize l1-based group lasso or\ndynamic regularization such as ADMM to perform structured pruning on DNN models\nto leverage the parallel computing architectures. However, both of the pruning\ndimensions and pruning methods lack universality, which leads to degraded\nperformance and limited applicability. To solve the problem, we propose a new\nblock-based pruning framework that comprises a general and flexible structured\npruning dimension as well as a powerful and efficient reweighted regularization\nmethod. Our framework is universal, which can be applied to both CNNs and RNNs,\nimplying complete support for the two major kinds of computation-intensive\nlayers (i.e., CONV and FC layers). To complete all aspects of the\npruning-for-acceleration task, we also integrate compiler-based code\noptimization into our framework that can perform DNN inference in a real-time\nmanner. To the best of our knowledge, it is the first time that the weight\npruning framework achieves universal coverage for both CNNs and RNNs with\nreal-time mobile acceleration and no accuracy compromise.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:30:56 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:00:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiaolong", ""], ["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Zhang", "Tianyun", ""], ["Niu", "Wei", ""], ["Zhan", "Zheng", ""], ["Zhao", "Pu", ""], ["Tang", "Jian", ""], ["Lin", "Xue", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08361", "submitter": "Samuel McCandlish", "authors": "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin\n  Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei", "title": "Scaling Laws for Neural Language Models", "comments": "19 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study empirical scaling laws for language model performance on the\ncross-entropy loss. The loss scales as a power-law with model size, dataset\nsize, and the amount of compute used for training, with some trends spanning\nmore than seven orders of magnitude. Other architectural details such as\nnetwork width or depth have minimal effects within a wide range. Simple\nequations govern the dependence of overfitting on model/dataset size and the\ndependence of training speed on model size. These relationships allow us to\ndetermine the optimal allocation of a fixed compute budget. Larger models are\nsignificantly more sample-efficient, such that optimally compute-efficient\ntraining involves training very large models on a relatively modest amount of\ndata and stopping significantly before convergence.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:59:20 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kaplan", "Jared", ""], ["McCandlish", "Sam", ""], ["Henighan", "Tom", ""], ["Brown", "Tom B.", ""], ["Chess", "Benjamin", ""], ["Child", "Rewon", ""], ["Gray", "Scott", ""], ["Radford", "Alec", ""], ["Wu", "Jeffrey", ""], ["Amodei", "Dario", ""]]}, {"id": "2001.08366", "submitter": "Canyu Le", "authors": "Canyu Le, Zhonggui Chen, Xihan Wei, Biao Wang, Lei Zhang", "title": "Continual Local Replacement for Few-shot Learning", "comments": "Update experiment results and reorganize paper writting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot learning is to learn a model that can recognize novel\nclasses based on one or few training data. It is challenging mainly due to two\naspects: (1) it lacks good feature representation of novel classes; (2) a few\nof labeled data could not accurately represent the true data distribution and\nthus it's hard to learn a good decision function for classification. In this\nwork, we use a sophisticated network architecture to learn better feature\nrepresentation and focus on the second issue. A novel continual local\nreplacement strategy is proposed to address the data deficiency problem. It\ntakes advantage of the content in unlabeled images to continually enhance\nlabeled ones. Specifically, a pseudo labeling method is adopted to constantly\nselect semantically similar images on the fly. Original labeled images will be\nlocally replaced by the selected images for the next epoch training. In this\nway, the model can directly learn new semantic information from unlabeled\nimages and the capacity of supervised signals in the embedding space can be\nsignificantly enlarged. This allows the model to improve generalization and\nlearn a better decision boundary for classification. Our method is conceptually\nsimple and easy to implement. Extensive experiments demonstrate that it can\nachieve state-of-the-art results on various few-shot image recognition\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 04:26:21 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:21:57 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Le", "Canyu", ""], ["Chen", "Zhonggui", ""], ["Wei", "Xihan", ""], ["Wang", "Biao", ""], ["Zhang", "Lei", ""]]}, {"id": "2001.08370", "submitter": "Mohamed El Amine Seddik", "authors": "Mohamed El Amine Seddik, Cosme Louart, Mohamed Tamaazousti, Romain\n  Couillet", "title": "Random Matrix Theory Proves that Deep Learning Representations of\n  GAN-data Behave as Gaussian Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that deep learning (DL) representations of data produced by\ngenerative adversarial nets (GANs) are random vectors which fall within the\nclass of so-called \\textit{concentrated} random vectors. Further exploiting the\nfact that Gram matrices, of the type $G = X^T X$ with $X=[x_1,\\ldots,x_n]\\in\n\\mathbb{R}^{p\\times n}$ and $x_i$ independent concentrated random vectors from\na mixture model, behave asymptotically (as $n,p\\to \\infty$) as if the $x_i$\nwere drawn from a Gaussian mixture, suggests that DL representations of\nGAN-data can be fully described by their first two statistical moments for a\nwide range of standard classifiers. Our theoretical findings are validated by\ngenerating images with the BigGAN model and across different popular deep\nrepresentation networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:17:09 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Seddik", "Mohamed El Amine", ""], ["Louart", "Cosme", ""], ["Tamaazousti", "Mohamed", ""], ["Couillet", "Romain", ""]]}, {"id": "2001.08371", "submitter": "Chiyu Zhang", "authors": "Yihui Qiu, Chiyu Zhang", "title": "Wrapper Feature Selection Algorithm for the Optimization of an Indicator\n  System of Patent Value Assessment", "comments": "Qiu, Y., & Zhang, C.. (2018, September). Wrapper feature selection\n  algorithm for the optimization of an indicator system of patent value\n  assessment. IPPTA: Quarterly Journal ofIndian Pulp and Paper Technical\n  Association, 30(3), 300-308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Effective patent value assessment provides decision support for patent\ntransection and promotes the practical application of patent technology. The\nlimitations of previous research on patent value assessment were analyzed in\nthis work, and a wrapper-mode feature selection algorithm that is based on\nclassifier prediction accuracy was developed. Verification experiments on\nmultiple UCI standard datasets indicated that the algorithm effectively reduced\nthe size of the feature set and significantly enhanced the prediction accuracy\nof the classifier. When the algorithm was utilized to establish an indicator\nsystem of patent value assessment, the size of the system was reduced, and the\ngeneralization performance of the classifier was enhanced. Sequential forward\nselection was applied to further reduce the size of the indicator set and\ngenerate an optimal indicator system of patent value assessment.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:04:42 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Qiu", "Yihui", ""], ["Zhang", "Chiyu", ""]]}, {"id": "2001.08374", "submitter": "Zhengkun Li", "authors": "Zhengkun Li, Minh-Ngoc Tran, Chao Wang, Richard Gerlach and Junbin Gao", "title": "A Bayesian Long Short-Term Memory Model for Value at Risk and Expected\n  Shortfall Joint Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value-at-Risk (VaR) and Expected Shortfall (ES) are widely used in the\nfinancial sector to measure the market risk and manage the extreme market\nmovement. The recent link between the quantile score function and the\nAsymmetric Laplace density has led to a flexible likelihood-based framework for\njoint modelling of VaR and ES. It is of high interest in financial applications\nto be able to capture the underlying joint dynamics of these two quantities. We\naddress this problem by developing a hybrid model that is based on the\nAsymmetric Laplace quasi-likelihood and employs the Long Short-Term Memory\n(LSTM) time series modelling technique from Machine Learning to capture\nefficiently the underlying dynamics of VaR and ES. We refer to this model as\nLSTM-AL. We adopt the adaptive Markov chain Monte Carlo (MCMC) algorithm for\nBayesian inference in the LSTM-AL model. Empirical results show that the\nproposed LSTM-AL model can improve the VaR and ES forecasting accuracy over a\nrange of well-established competing models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:13:36 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 01:19:08 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Li", "Zhengkun", ""], ["Tran", "Minh-Ngoc", ""], ["Wang", "Chao", ""], ["Gerlach", "Richard", ""], ["Gao", "Junbin", ""]]}, {"id": "2001.08379", "submitter": "Chuan Wang", "authors": "Chuan Wang, Xumeng Wang, Kwan-Liu Ma", "title": "Visual Summary of Value-level Feature Attribution in Prediction Classes\n  with Recurrent Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Recurrent Neural Networks (RNN) is increasingly used in decision-making\nwith temporal sequences. However, understanding how RNN models produce final\npredictions remains a major challenge. Existing work on interpreting RNN models\nfor sequence predictions often focuses on explaining predictions for individual\ndata instances (e.g., patients or students). Because state-of-the-art\npredictive models are formed with millions of parameters optimized over\nmillions of instances, explaining predictions for single data instances can\neasily miss a bigger picture. Besides, many outperforming RNN models use\nmulti-hot encoding to represent the presence/absence of features, where the\ninterpretability of feature value attribution is missing. We present ViSFA, an\ninteractive system that visually summarizes feature attribution over time for\ndifferent feature values. ViSFA scales to large data such as the MIMIC dataset\ncontaining the electronic health records of 1.2 million high-dimensional\ntemporal events. We demonstrate that ViSFA can help us reason RNN prediction\nand uncover insights from data by distilling complex attribution into compact\nand easy-to-interpret visualizations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:38:30 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 19:22:38 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Wang", "Chuan", ""], ["Wang", "Xumeng", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2001.08381", "submitter": "Jason Su", "authors": "Sadanand Singh, Thomas Paul Matthews, Meet Shah, Brent Mombourquette,\n  Trevor Tsue, Aaron Long, Ranya Almohsen, Stefano Pedemonte, and Jason Su", "title": "Adaptation of a deep learning malignancy model from full-field digital\n  mammography to digital breast tomosynthesis", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mammography-based screening has helped reduce the breast cancer mortality\nrate, but has also been associated with potential harms due to low specificity,\nleading to unnecessary exams or procedures, and low sensitivity. Digital breast\ntomosynthesis (DBT) improves on conventional mammography by increasing both\nsensitivity and specificity and is becoming common in clinical settings.\nHowever, deep learning (DL) models have been developed mainly on conventional\n2D full-field digital mammography (FFDM) or scanned film images. Due to a lack\nof large annotated DBT datasets, it is difficult to train a model on DBT from\nscratch. In this work, we present methods to generalize a model trained on FFDM\nimages to DBT images. In particular, we use average histogram matching (HM) and\nDL fine-tuning methods to generalize a FFDM model to the 2D maximum intensity\nprojection (MIP) of DBT images. In the proposed approach, the differences\nbetween the FFDM and DBT domains are reduced via HM and then the base model,\nwhich was trained on abundant FFDM images, is fine-tuned. When evaluating on\nimage patches extracted around identified findings, we are able to achieve\nsimilar areas under the receiver operating characteristic curve (ROC AUC) of\n$\\sim 0.9$ for FFDM and $\\sim 0.85$ for MIP images, as compared to a ROC AUC of\n$\\sim 0.75$ when tested directly on MIP images.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:44:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Singh", "Sadanand", ""], ["Matthews", "Thomas Paul", ""], ["Shah", "Meet", ""], ["Mombourquette", "Brent", ""], ["Tsue", "Trevor", ""], ["Long", "Aaron", ""], ["Almohsen", "Ranya", ""], ["Pedemonte", "Stefano", ""], ["Su", "Jason", ""]]}, {"id": "2001.08382", "submitter": "Jason Su", "authors": "Stefano Pedemonte, Brent Mombourquette, Alexis Goh, Trevor Tsue, Aaron\n  Long, Sadanand Singh, Thomas Paul Matthews, Meet Shah, and Jason Su", "title": "A Hypersensitive Breast Cancer Detector", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of breast cancer through screening mammography yields a\n20-35% increase in survival rate; however, there are not enough radiologists to\nserve the growing population of women seeking screening mammography. Although\ncommercial computer aided detection (CADe) software has been available to\nradiologists for decades, it has failed to improve the interpretation of\nfull-field digital mammography (FFDM) images due to its low sensitivity over\nthe spectrum of findings. In this work, we leverage a large set of FFDM images\nwith loose bounding boxes of mammographically significant findings to train a\ndeep learning detector with extreme sensitivity. Building upon work from the\nHourglass architecture, we train a model that produces segmentation-like images\nwith high spatial resolution, with the aim of producing 2D Gaussian blobs\ncentered on ground-truth boxes. We replace the pixel-wise $L_2$ norm with a\nweak-supervision loss designed to achieve high sensitivity, asymmetrically\npenalizing false positives and false negatives while softening the noise of the\nloose bounding boxes by permitting a tolerance in misaligned predictions. The\nresulting system achieves a sensitivity for malignant findings of 0.99 with\nonly 4.8 false positive markers per image. When utilized in a CADe system, this\nmodel could enable a novel workflow where radiologists can focus their\nattention with trust on only the locations proposed by the model, expediting\nthe interpretation process and bringing attention to potential findings that\ncould otherwise have been missed. Due to its nearly perfect sensitivity, the\nproposed detector can also be used as a high-performance proposal generator in\ntwo-stage detection systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:44:39 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Pedemonte", "Stefano", ""], ["Mombourquette", "Brent", ""], ["Goh", "Alexis", ""], ["Tsue", "Trevor", ""], ["Long", "Aaron", ""], ["Singh", "Sadanand", ""], ["Matthews", "Thomas Paul", ""], ["Shah", "Meet", ""], ["Su", "Jason", ""]]}, {"id": "2001.08383", "submitter": "Thomas Matthews", "authors": "Thomas P. Matthews (1), Sadanand Singh (1), Brent Mombourquette (1),\n  Jason Su (1), Meet P. Shah (1), Stefano Pedemonte (1), Aaron Long (1), David\n  Maffit (2), Jenny Gurney (2), Rodrigo Morales Hoil (1), Nikita Ghare (1),\n  Douglas Smith (1), Stephen M. Moore (2), Susan C. Marks (3), Richard L. Wahl\n  (2), ((1) Whiterabbit AI, Inc., Santa Clara, CA, (2) Mallinckrodt Institute\n  of Radiology, Washington University School of Medicine, St. Louis, MO, (3)\n  Peninsula Diagnostic Imaging, San Mateo, CA)", "title": "A Multi-site Study of a Breast Density Deep Learning Model for\n  Full-field Digital Mammography Images and Synthetic Mammography Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To develop a Breast Imaging Reporting and Data System (BI-RADS)\nbreast density deep learning (DL) model in a multi-site setting for synthetic\ntwo-dimensional mammography (SM) images derived from digital breast\ntomosynthesis exams using full-field digital mammography (FFDM) images and\nlimited SM data.\n  Materials and Methods: A DL model was trained to predict BI-RADS breast\ndensity using FFDM images acquired from 2008 to 2017 (Site 1: 57492 patients,\n187627 exams, 750752 images) for this retrospective study. The FFDM model was\nevaluated using SM datasets from two institutions (Site 1: 3842 patients, 3866\nexams, 14472 images, acquired from 2016 to 2017; Site 2: 7557 patients, 16283\nexams, 63973 images, 2015 to 2019). Each of the three datasets were then split\ninto training, validation, and test datasets. Adaptation methods were\ninvestigated to improve performance on the SM datasets and the effect of\ndataset size on each adaptation method is considered. Statistical significance\nwas assessed using confidence intervals (CI), estimated by bootstrapping.\n  Results: Without adaptation, the model demonstrated substantial agreement\nwith the original reporting radiologists for all three datasets (Site 1 FFDM:\nlinearly-weighted $\\kappa_w$ = 0.75 [95% CI: 0.74, 0.76]; Site 1 SM: $\\kappa_w$\n= 0.71 [95% CI: 0.64, 0.78]; Site 2 SM: $\\kappa_w$ = 0.72 [95% CI: 0.70,\n0.75]). With adaptation, performance improved for Site 2 (Site 1: $\\kappa_w$ =\n0.72 [95% CI: 0.66, 0.79], 0.71 vs 0.72, P = .80; Site 2: $\\kappa_w$ = 0.79\n[95% CI: 0.76, 0.81], 0.72 vs 0.79, P $<$ .001) using only 500 SM images from\nthat site.\n  Conclusion: A BI-RADS breast density DL model demonstrated strong performance\non FFDM and SM images from two institutions without training on SM images and\nimproved using few SM images.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 05:51:27 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:07:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Matthews", "Thomas P.", ""], ["Singh", "Sadanand", ""], ["Mombourquette", "Brent", ""], ["Su", "Jason", ""], ["Shah", "Meet P.", ""], ["Pedemonte", "Stefano", ""], ["Long", "Aaron", ""], ["Maffit", "David", ""], ["Gurney", "Jenny", ""], ["Hoil", "Rodrigo Morales", ""], ["Ghare", "Nikita", ""], ["Smith", "Douglas", ""], ["Moore", "Stephen M.", ""], ["Marks", "Susan C.", ""], ["Wahl", "Richard L.", ""]]}, {"id": "2001.08389", "submitter": "Yaguan Qian", "authors": "Ya-guan Qian, Xi-Ming Zhang, Wassim Swaileh, Li Wei, Bin Wang,\n  Jian-Hai Chen, Wu-Jie Zhou, and Jing-Sheng Lei", "title": "TEAM: An Taylor Expansion-Based Method for Generating Adversarial\n  Examples", "comments": "25 pages,5 figures,3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Deep Neural Networks(DNNs) have achieved successful applications in\nmany fields, they are vulnerable to adversarial examples.Adversarial training\nis one of the most effective methods to improve the robustness of DNNs, and it\nis generally considered as solving a saddle point problem that minimizes risk\nand maximizes perturbation.Therefore, powerful adversarial examples can\neffectively replicate the situation of perturbation maximization to solve the\nsaddle point problem.The method proposed in this paper approximates the output\nof DNNs in the input neighborhood by using the Taylor expansion, and then\noptimizes it by using the Lagrange multiplier method to generate adversarial\nexamples. If it is used for adversarial training, the DNNs can be effectively\nregularized and the defects of the model can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 07:03:32 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 15:08:20 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Qian", "Ya-guan", ""], ["Zhang", "Xi-Ming", ""], ["Swaileh", "Wassim", ""], ["Wei", "Li", ""], ["Wang", "Bin", ""], ["Chen", "Jian-Hai", ""], ["Zhou", "Wu-Jie", ""], ["Lei", "Jing-Sheng", ""]]}, {"id": "2001.08395", "submitter": "Qun Liu", "authors": "Qun Liu, Supratik Mukhopadhyay, Maria Ximena Bastidas Rodriguez, Xing\n  Fu, Sushant Sahu, David Burk, Manas Gartia", "title": "A One-Shot Learning Framework for Assessment of Fibrillar Collagen from\n  Second Harmonic Generation Images of an Infarcted Myocardium", "comments": "Paper was accepted at the IEEE International Symposium on Biomedical\n  Imaging (ISBI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Myocardial infarction (MI) is a scientific term that refers to heart attack.\nIn this study, we infer highly relevant second harmonic generation (SHG) cues\nfrom collagen fibers exhibiting highly non-centrosymmetric assembly together\nwith two-photon excited cellular autofluorescence in infarcted mouse heart to\nquantitatively probe fibrosis, especially targeted at an early stage after MI.\nWe present a robust one-shot machine learning algorithm that enables\ndetermination of 2D assembly of collagen with high spatial resolution along\nwith its structural arrangement in heart tissues post-MI with spectral\nspecificity and sensitivity. Detection, evaluation, and precise quantification\nof fibrosis extent at early stage would guide one to develop treatment\ntherapies that may prevent further progression and determine heart transplant\nneeds for patient survival.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 07:35:56 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:49:13 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Liu", "Qun", ""], ["Mukhopadhyay", "Supratik", ""], ["Rodriguez", "Maria Ximena Bastidas", ""], ["Fu", "Xing", ""], ["Sahu", "Sushant", ""], ["Burk", "David", ""], ["Gartia", "Manas", ""]]}, {"id": "2001.08406", "submitter": "Tuukka Salmi", "authors": "Tuukka Salmi, Jussi Kiljander and Daniel Pakkala", "title": "Stacked Boosters Network Architecture for Short Term Load Forecasting in\n  Buildings", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning architecture for short term load\nforecasting of building energy loads. The architecture is based on a simple\nbase learner and multiple boosting systems that are modelled as a single deep\nneural network. The architecture transforms the original multivariate time\nseries into multiple cascading univariate time series. Together with sparse\ninteractions, parameter sharing and equivariant representations, this approach\nmakes it possible to combat against overfitting while still achieving good\npresentation power with a deep network architecture. The architecture is\nevaluated in several short-term load forecasting tasks with energy data from an\noffice building in Finland. The proposed architecture outperforms\nstate-of-the-art load forecasting model in all the tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 08:35:36 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 05:20:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Salmi", "Tuukka", ""], ["Kiljander", "Jussi", ""], ["Pakkala", "Daniel", ""]]}, {"id": "2001.08427", "submitter": "Maxim Panov", "authors": "Valentina Shumovskaia, Kirill Fedyanin, Ivan Sukharev, Dmitry\n  Berestnev and Maxim Panov", "title": "Linking Bank Clients using Graph Neural Networks Powered by Rich\n  Transactional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial institutions obtain enormous amounts of data about user\ntransactions and money transfers, which can be considered as a large graph\ndynamically changing in time. In this work, we focus on the task of predicting\nnew interactions in the network of bank clients and treat it as a link\nprediction problem. We propose a new graph neural network model, which uses not\nonly the topological structure of the network but rich time-series data\navailable for the graph nodes and edges. We evaluate the developed method using\nthe data provided by a large European bank for several years. The proposed\nmodel outperforms the existing approaches, including other neural network\nmodels, with a significant gap in ROC AUC score on link prediction problem and\nalso allows to improve the quality of credit scoring.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:02:02 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Shumovskaia", "Valentina", ""], ["Fedyanin", "Kirill", ""], ["Sukharev", "Ivan", ""], ["Berestnev", "Dmitry", ""], ["Panov", "Maxim", ""]]}, {"id": "2001.08434", "submitter": "Sourav Garg", "authors": "Sourav Garg and Michael Milford", "title": "Fast, Compact and Highly Scalable Visual Place Recognition through\n  Sequence-based Matching of Overloaded Representations", "comments": "8 pages, 4 figures, Accepted for oral presentation at the 2020 IEEE\n  International Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual place recognition algorithms trade off three key characteristics:\ntheir storage footprint, their computational requirements, and their resultant\nperformance, often expressed in terms of recall rate. Significant prior work\nhas investigated highly compact place representations, sub-linear computational\nscaling and sub-linear storage scaling techniques, but have always involved a\nsignificant compromise in one or more of these regards, and have only been\ndemonstrated on relatively small datasets. In this paper we present a novel\nplace recognition system which enables for the first time the combination of\nultra-compact place representations, near sub-linear storage scaling and\nextremely lightweight compute requirements. Our approach exploits the\ninherently sequential nature of much spatial data in the robotics domain and\ninverts the typical target criteria, through intentionally coarse scalar\nquantization-based hashing that leads to more collisions but is resolved by\nsequence-based matching. For the first time, we show how effective place\nrecognition rates can be achieved on a new very large 10 million place dataset,\nrequiring only 8 bytes of storage per place and 37K unitary operations to\nachieve over 50% recall for matching a sequence of 100 frames, where a\nconventional state-of-the-art approach both consumes 1300 times more compute\nand fails catastrophically. We present analysis investigating the effectiveness\nof our hashing overload approach under varying sizes of quantized vector\nlength, comparison of near miss matches with the actual match selections and\ncharacterise the effect of variance re-scaling of data on quantization.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:31:28 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 12:51:41 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Garg", "Sourav", ""], ["Milford", "Michael", ""]]}, {"id": "2001.08437", "submitter": "Fengwei Zhou", "authors": "Zewei Chen, Fengwei Zhou, George Trimponias, Zhenguo Li", "title": "Multi-objective Neural Architecture Search via Non-stationary Policy\n  Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective Neural Architecture Search (NAS) aims to discover novel\narchitectures in the presence of multiple conflicting objectives. Despite\nrecent progress, the problem of approximating the full Pareto front accurately\nand efficiently remains challenging. In this work, we explore the novel\nreinforcement learning (RL) based paradigm of non-stationary policy gradient\n(NPG). NPG utilizes a non-stationary reward function, and encourages a\ncontinuous adaptation of the policy to capture the entire Pareto front\nefficiently. We introduce two novel reward functions with elements from the\ndominant paradigms of scalarization and evolution. To handle non-stationarity,\nwe propose a new exploration scheme using cosine temperature decay with warm\nrestarts. For fast and accurate architecture evaluation, we introduce a novel\npre-trained shared model that we continuously fine-tune throughout training.\nOur extensive experimental study with various datasets shows that our framework\ncan approximate the full Pareto front well at fast speeds. Moreover, our\ndiscovered cells can achieve supreme predictive performance compared to other\nmulti-objective NAS methods, and other single-objective NAS methods at similar\nnetwork sizes. Our work demonstrates the potential of NPG as a simple,\nefficient, and effective paradigm for multi-objective NAS.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:37:11 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 03:42:43 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chen", "Zewei", ""], ["Zhou", "Fengwei", ""], ["Trimponias", "George", ""], ["Li", "Zhenguo", ""]]}, {"id": "2001.08444", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo and Roberto Santana", "title": "On the human evaluation of audio adversarial examples", "comments": "Preprint. 17 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.HC cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human-machine interaction is increasingly dependent on speech communication.\nMachine Learning models are usually applied to interpret human speech commands.\nHowever, these models can be fooled by adversarial examples, which are inputs\nintentionally perturbed to produce a wrong prediction without being noticed.\nWhile much research has been focused on developing new techniques to generate\nadversarial perturbations, less attention has been given to aspects that\ndetermine whether and how the perturbations are noticed by humans. This\nquestion is relevant since high fooling rates of proposed adversarial\nperturbation strategies are only valuable if the perturbations are not\ndetectable. In this paper we investigate to which extent the distortion metrics\nproposed in the literature for audio adversarial examples, and which are\ncommonly applied to evaluate the effectiveness of methods for generating these\nattacks, are a reliable measure of the human perception of the perturbations.\nUsing an analytical framework, and an experiment in which 18 subjects evaluate\naudio adversarial examples, we demonstrate that the metrics employed by\nconvention are not a reliable measure of the perceptual similarity of\nadversarial examples in the audio domain.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:56:50 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 14:27:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""]]}, {"id": "2001.08450", "submitter": "Yu-Tung Liu", "authors": "Yu-Tung Liu, Tzi-Dar Chiueh", "title": "Low-Complexity LSTM Training and Inference with FloatSD8 Weight\n  Representation", "comments": "Submitted to International Joint Conference on Neural Networks\n  (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FloatSD technology has been shown to have excellent performance on\nlow-complexity convolutional neural networks (CNNs) training and inference. In\nthis paper, we applied FloatSD to recurrent neural networks (RNNs),\nspecifically long short-term memory (LSTM). In addition to FloatSD weight\nrepresentation, we quantized the gradients and activations in model training to\n8 bits. Moreover, the arithmetic precision for accumulations and the master\ncopy of weights were reduced from 32 bits to 16 bits. We demonstrated that the\nproposed training scheme can successfully train several LSTM models from\nscratch, while fully preserving model accuracy. Finally, to verify the proposed\nmethod's advantage in implementation, we designed an LSTM neuron circuit and\nshowed that it achieved significantly reduced die area and power consumption.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:17:48 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Liu", "Yu-Tung", ""], ["Chiueh", "Tzi-Dar", ""]]}, {"id": "2001.08456", "submitter": "Aviad Aberdam", "authors": "Aviad Aberdam, Alona Golts, Michael Elad", "title": "Ada-LISTA: Learned Solvers Adaptive to Varying Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks that are based on unfolding of an iterative solver, such as\nLISTA (learned iterative soft threshold algorithm), are widely used due to\ntheir accelerated performance. Nevertheless, as opposed to non-learned solvers,\nthese networks are trained on a certain dictionary, and therefore they are\ninapplicable for varying model scenarios. This work introduces an adaptive\nlearned solver, termed Ada-LISTA, which receives pairs of signals and their\ncorresponding dictionaries as inputs, and learns a universal architecture to\nserve them all. We prove that this scheme is guaranteed to solve sparse coding\nin linear rate for varying models, including dictionary perturbations and\npermutations. We also provide an extensive numerical study demonstrating its\npractical adaptation capabilities. Finally, we deploy Ada-LISTA to natural\nimage inpainting, where the patch-masks vary spatially, thus requiring such an\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:34:03 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 14:28:35 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Aberdam", "Aviad", ""], ["Golts", "Alona", ""], ["Elad", "Michael", ""]]}, {"id": "2001.08477", "submitter": "G C Nandi", "authors": "Mridul Mahajan, Tryambak Bhattacharjee, Arya Krishnan, Priya Shukla\n  and G C Nandi", "title": "Semi-supervised Grasp Detection by Representation Learning in a Vector\n  Quantized Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a robot to perform complex manipulation tasks, it is necessary for it to\nhave a good grasping ability. However, vision based robotic grasp detection is\nhindered by the unavailability of sufficient labelled data. Furthermore, the\napplication of semi-supervised learning techniques to grasp detection is\nunder-explored. In this paper, a semi-supervised learning based grasp detection\napproach has been presented, which models a discrete latent space using a\nVector Quantized Variational AutoEncoder (VQ-VAE). To the best of our\nknowledge, this is the first time a Variational AutoEncoder (VAE) has been\napplied in the domain of robotic grasp detection. The VAE helps the model in\ngeneralizing beyond the Cornell Grasping Dataset (CGD) despite having a limited\namount of labelled data by also utilizing the unlabelled data. This claim has\nbeen validated by testing the model on images, which are not available in the\nCGD. Along with this, we augment the Generative Grasping Convolutional Neural\nNetwork (GGCNN) architecture with the decoder structure used in the VQ-VAE\nmodel with the intuition that it should help to regress in the vector-quantized\nlatent space. Subsequently, the model performs significantly better than the\nexisting approaches which do not make use of unlabelled images to improve the\ngrasp.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 12:47:13 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 06:41:33 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 05:50:35 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mahajan", "Mridul", ""], ["Bhattacharjee", "Tryambak", ""], ["Krishnan", "Arya", ""], ["Shukla", "Priya", ""], ["Nandi", "G C", ""]]}, {"id": "2001.08499", "submitter": "Davide Migliore", "authors": "Pierre de Tournemire, Davide Nitti, Etienne Perot, Davide Migliore,\n  Amos Sironi", "title": "A Large Scale Event-based Detection Dataset for Automotive", "comments": "8 pages, 29 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first very large detection dataset for event cameras. The\ndataset is composed of more than 39 hours of automotive recordings acquired\nwith a 304x240 ATIS sensor. It contains open roads and very diverse driving\nscenarios, ranging from urban, highway, suburbs and countryside scenes, as well\nas different weather and illumination conditions. Manual bounding box\nannotations of cars and pedestrians contained in the recordings are also\nprovided at a frequency between 1 and 4Hz, yielding more than 255,000 labels in\ntotal. We believe that the availability of a labeled dataset of this size will\ncontribute to major advances in event-based vision tasks such as object\ndetection and classification. We also expect benefits in other tasks such as\noptical flow, structure from motion and tracking, where for example, the large\namount of data can be leveraged by self-supervised learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 13:40:51 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:45:21 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 13:35:45 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["de Tournemire", "Pierre", ""], ["Nitti", "Davide", ""], ["Perot", "Etienne", ""], ["Migliore", "Davide", ""], ["Sironi", "Amos", ""]]}, {"id": "2001.08503", "submitter": "Narjes Nikzad-Khasmakhi", "authors": "N. Nikzad-Khasmakhi, M. A. Balafar, M.Reza Feizi-Derakhshi, Cina\n  Motamed", "title": "ExEm: Expert Embedding using dominating set theory with deep learning\n  approaches", "comments": "Submitted to Expert Systems with Applications for review", "journal-ref": null, "doi": "10.1016/j.eswa.2021.114913", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collaborative network is a social network that is comprised of experts who\ncooperate with each other to fulfill a special goal. Analyzing this network\nyields meaningful information about the expertise of these experts and their\nsubject areas. To perform the analysis, graph embedding techniques have emerged\nas an effective and promising tool. Graph embedding attempts to represent graph\nnodes as low-dimensional vectors. In this paper, we propose a graph embedding\nmethod, called ExEm, that uses dominating-set theory and deep learning\napproaches to capture node representations. ExEm finds dominating nodes of the\ncollaborative network and constructs intelligent random walks that comprise of\nat least two dominating nodes. One dominating node should appear at the\nbeginning of each path sampled to characterize the local neighborhoods.\nMoreover, the second dominating node reflects the global structure information.\nTo learn the node embeddings, ExEm exploits three embedding methods including\nWord2vec, fastText and the concatenation of these two. The final result is the\nlow-dimensional vectors of experts, called expert embeddings. The extracted\nexpert embeddings can be applied to many applications. In order to extend these\nembeddings into the expert recommendation system, we introduce a novel strategy\nthat uses expert vectors to calculate experts' scores and recommend experts. At\nthe end, we conduct extensive experiments to validate the effectiveness of ExEm\nthrough assessing its performance over the multi-label classification, link\nprediction, and recommendation tasks on common datasets and our collected data\nformed by crawling the vast author Scopus profiles. The experiments show that\nExEm outperforms the baselines especially in dense networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 10:47:40 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 15:16:42 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Nikzad-Khasmakhi", "N.", ""], ["Balafar", "M. A.", ""], ["Feizi-Derakhshi", "M. Reza", ""], ["Motamed", "Cina", ""]]}, {"id": "2001.08523", "submitter": "Peilun Wu", "authors": "Peilun Wu, Hui Guo and Nour Moustafa", "title": "Pelican: A Deep Residual Network for Network Intrusion Detection", "comments": "Final version papaer will be published as the supplementary volumn at\n  the 2020 50th Annual IEEE/IFIP International Conference on Dependable\n  Networks and Systems (DSN'20), and presented at the Workshop on Data-Centric\n  Dependability and Security (DCDS'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge for building a secure network communication environment is how\nto effectively detect and prevent malicious network behaviours. The abnormal\nnetwork activities threaten users' privacy and potentially damage the function\nand infrastructure of the whole network. To address this problem, the network\nintrusion detection system (NIDS) has been used. By continuously monitoring\nnetwork activities, the system can timely identify attacks and prompt\ncounter-attack actions. NIDS has been evolving over years. The\ncurrent-generation NIDS incorporates machine learning (ML) as the core\ntechnology in order to improve the detection performance on novel attacks.\nHowever, the high detection rate achieved by a traditional ML-based detection\nmethod is often accompanied by large false-alarms, which greatly affects its\noverall performance. In this paper, we propose a deep neural network, Pelican,\nthat is built upon specially-designed residual blocks. We evaluated Pelican on\ntwo network traffic datasets, NSL-KDD and UNSW-NB15. Our experiments show that\nPelican can achieve a high attack detection performance while keeping a much\nlow false alarm rate when compared with a set of up-to-date machine learning\nbased designs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 05:07:48 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:54:57 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 10:20:29 GMT"}, {"version": "v4", "created": "Thu, 19 Mar 2020 18:26:50 GMT"}, {"version": "v5", "created": "Tue, 14 Apr 2020 16:03:44 GMT"}, {"version": "v6", "created": "Wed, 15 Apr 2020 15:40:57 GMT"}, {"version": "v7", "created": "Fri, 8 May 2020 12:27:42 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wu", "Peilun", ""], ["Guo", "Hui", ""], ["Moustafa", "Nour", ""]]}, {"id": "2001.08533", "submitter": "Fariba Zohrizadeh", "authors": "Mohsen Kheirandishfard, Fariba Zohrizadeh, Farhad Kamangar", "title": "Multi-Level Representation Learning for Deep Subspace Clustering", "comments": "IEEE Winter Conference on Applications of Computer Vision (WACV),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel deep subspace clustering approach which uses\nconvolutional autoencoders to transform input images into new representations\nlying on a union of linear subspaces. The first contribution of our work is to\ninsert multiple fully-connected linear layers between the encoder layers and\ntheir corresponding decoder layers to promote learning more favorable\nrepresentations for subspace clustering. These connection layers facilitate the\nfeature learning procedure by combining low-level and high-level information\nfor generating multiple sets of self-expressive and informative representations\nat different levels of the encoder. Moreover, we introduce a novel loss\nminimization problem which leverages an initial clustering of the samples to\neffectively fuse the multi-level representations and recover the underlying\nsubspaces more accurately. The loss function is then minimized through an\niterative scheme which alternatively updates the network parameters and\nproduces new clusterings of the samples. Experiments on four real-world\ndatasets demonstrate that our approach exhibits superior performance compared\nto the state-of-the-art methods on most of the subspace clustering problems.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 23:29:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kheirandishfard", "Mohsen", ""], ["Zohrizadeh", "Fariba", ""], ["Kamangar", "Farhad", ""]]}, {"id": "2001.08537", "submitter": "Weijun Xie", "authors": "Yongchun Li, Weijun Xie", "title": "Best Principal Submatrix Selection for the Maximum Entropy Sampling\n  Problem: Scalable Algorithms and Performance Guarantees", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a classic maximum entropy sampling problem (MESP), which\naims to select the most informative principal submatrix of a prespecified size\nfrom a covariance matrix. MESP has been widely applied to many areas, including\nhealthcare, power system, manufacturing and data science. By investigating its\nLagrangian dual and primal characterization, we derive a novel convex integer\nprogram for MESP and show that its continuous relaxation yields a near-optimal\nsolution. The results motivate us to study an efficient sampling algorithm and\ndevelop its approximation bound for MESP, which improves the best-known bound\nin literature. We then provide an efficient deterministic implementation of the\nsampling algorithm with the same approximation bound. By developing new\nmathematical tools for the singular matrices and analyzing the Lagrangian dual\nof the proposed convex integer program, we investigate the widely-used local\nsearch algorithm and prove its first-known approximation bound for MESP. The\nproof techniques further inspire us with an efficient implementation of the\nlocal search algorithm. Our numerical experiments demonstrate that these\napproximation algorithms can efficiently solve medium-sized and large-scale\ninstances to near-optimality. Our proposed algorithms are coded and released as\nopen-source software. Finally, we extend the analyses to the A-Optimal MESP\n(A-MESP), where the objective is to minimize the trace of the inverse of the\nselected principal submatrix.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:14:18 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Li", "Yongchun", ""], ["Xie", "Weijun", ""]]}, {"id": "2001.08539", "submitter": "David Millard", "authors": "David Millard, Eric Heiden, Shubham Agrawal, Gaurav S. Sukhatme", "title": "Automatic Differentiation and Continuous Sensitivity Analysis of Rigid\n  Body Dynamics", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.10706", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key ingredient to achieving intelligent behavior is physical understanding\nthat equips robots with the ability to reason about the effects of their\nactions in a dynamic environment. Several methods have been proposed to learn\ndynamics models from data that inform model-based control algorithms. While\nsuch learning-based approaches can model locally observed behaviors, they fail\nto generalize to more complex dynamics and under long time horizons.\n  In this work, we introduce a differentiable physics simulator for rigid body\ndynamics. Leveraging various techniques for differential equation integration\nand gradient calculation, we compare different methods for parameter estimation\nthat allow us to infer the simulation parameters that are relevant to\nestimation and control of physical systems. In the context of trajectory\noptimization, we introduce a closed-loop model-predictive control algorithm\nthat infers the simulation parameters through experience while achieving\ncost-minimizing performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:54:00 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Millard", "David", ""], ["Heiden", "Eric", ""], ["Agrawal", "Shubham", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2001.08540", "submitter": "Kun He Prof.", "authors": "Kun He, Min Zhang, Jianrong Zhou, Yan Jin, and Chu-min Li", "title": "Stochastic Item Descent Method for Large Scale Equal Circle Packing\n  Problem", "comments": "7 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CG cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is a powerful method for large-scale\noptimization problems in the area of machine learning, especially for a\nfinite-sum formulation with numerous variables. In recent years, mini-batch SGD\ngains great success and has become a standard technique for training deep\nneural networks fed with big amount of data. Inspired by its success in deep\nlearning, we apply the idea of SGD with batch selection of samples to a classic\noptimization problem in decision version. Given $n$ unit circles, the equal\ncircle packing problem (ECPP) asks whether there exist a feasible packing that\ncould put all the circles inside a circular container without overlapping.\nSpecifically, we propose a stochastic item descent method (SIDM) for ECPP in\nlarge scale, which randomly divides the unit circles into batches and runs\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm on the corresponding batch\nfunction iteratively to speedup the calculation. We also increase the batch\nsize during the batch iterations to gain higher quality solution. Comparing to\nthe current best packing algorithms, SIDM greatly speeds up the calculation of\noptimization process and guarantees the solution quality for large scale\ninstances with up to 1500 circle items, while the baseline algorithms usually\nhandle about 300 circle items. The results indicate the highly efficiency of\nSIDM for this classic optimization problem in large scale, and show potential\nfor other large scale classic optimization problems in which gradient descent\nis used for optimization.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:40:31 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["He", "Kun", ""], ["Zhang", "Min", ""], ["Zhou", "Jianrong", ""], ["Jin", "Yan", ""], ["Li", "Chu-min", ""]]}, {"id": "2001.08546", "submitter": "Preslav Nakov", "authors": "Alberto Barron-Cedeno, Tamer Elsayed, Preslav Nakov, Giovanni Da San\n  Martino, Maram Hasanain, Reem Suwaileh, and Fatima Haouari", "title": "CheckThat! at CLEF 2020: Enabling the Automatic Identification and\n  Verification of Claims in Social Media", "comments": "Computational journalism, Check-worthiness, Fact-checking, Veracity,\n  CLEF-2020 CheckThat! Lab", "journal-ref": "CLEF-2018 ECIR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the third edition of the CheckThat! Lab, which is part of the\n2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four\ncomplementary tasks and a related task from previous lab editions, offered in\nEnglish, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter\nstream are worth fact-checking. Task 2 asks to determine whether a claim posted\nin a tweet can be verified using a set of previously fact-checked claims. Task\n3 asks to retrieve text snippets from a given set of Web pages that would be\nuseful for verifying a target tweet's claim. Task 4 asks to predict the\nveracity of a target tweet's claim using a set of Web pages and potentially\nuseful snippets in them. Finally, the lab offers a fifth task that asks to\npredict the check-worthiness of the claims made in English political debates\nand speeches. CheckThat! features a full evaluation framework. The evaluation\nis carried out using mean average precision or precision at rank k for ranking\ntasks, and F1 for classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:47:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Barron-Cedeno", "Alberto", ""], ["Elsayed", "Tamer", ""], ["Nakov", "Preslav", ""], ["Martino", "Giovanni Da San", ""], ["Hasanain", "Maram", ""], ["Suwaileh", "Reem", ""], ["Haouari", "Fatima", ""]]}, {"id": "2001.08552", "submitter": "Arkadiy Dushatskiy", "authors": "Arkadiy Dushatskiy, Adri\\\"enne M. Mendrik, Peter A. N. Bosman, Tanja\n  Alderliesten", "title": "Observer variation-aware medical image segmentation by combining deep\n  learning and surrogate-assisted genetic algorithms", "comments": "11 pages, 5 figures, SPIE Medical Imaging Conference - 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been great progress in automatic segmentation of medical\nimages with deep learning algorithms. In most works observer variation is\nacknowledged to be a problem as it makes training data heterogeneous but so far\nno attempts have been made to explicitly capture this variation. Here, we\npropose an approach capable of mimicking different styles of segmentation,\nwhich potentially can improve quality and clinical acceptance of automatic\nsegmentation methods. In this work, instead of training one neural network on\nall available data, we train several neural networks on subgroups of data\nbelonging to different segmentation variations separately. Because a priori it\nmay be unclear what styles of segmentation exist in the data and because\ndifferent styles do not necessarily map one-on-one to different observers, the\nsubgroups should be automatically determined. We achieve this by searching for\nthe best data partition with a genetic algorithm. Therefore, each network can\nlearn a specific style of segmentation from grouped training data. We provide\nproof of principle results for open-sourced prostate segmentation MRI data with\nsimulated observer variations. Our approach provides an improvement of up to\n23% (depending on simulated variations) in terms of Dice and surface Dice\ncoefficients compared to one network trained on all data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:51:40 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Dushatskiy", "Arkadiy", ""], ["Mendrik", "Adri\u00ebnne M.", ""], ["Bosman", "Peter A. N.", ""], ["Alderliesten", "Tanja", ""]]}, {"id": "2001.08559", "submitter": "Zehao Wang", "authors": "Zehao Wang, Kaili Wang, Tinne Tuytelaars, Jose Oramas", "title": "Information Compensation for Deep Conditional Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, unsupervised/weakly-supervised conditional generative\nadversarial networks (GANs) have achieved many successes on the task of\nmodeling and generating data. However, one of their weaknesses lies in their\npoor ability to separate, or disentangle, the different factors that\ncharacterize the representation encoded in their latent space. To address this\nissue, we propose a novel structure for unsupervised conditional GANs powered\nby a novel Information Compensation Connection (IC-Connection). The proposed\nIC-Connection enables GANs to compensate for information loss incurred during\ndeconvolution operations. In addition, to quantify the degree of\ndisentanglement on both discrete and continuous latent variables, we design a\nnovel evaluation procedure. Our empirical results suggest that our method\nachieves better disentanglement compared to the state-of-the-art GANs in a\nconditional generation setting.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:39:53 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 12:00:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Wang", "Zehao", ""], ["Wang", "Kaili", ""], ["Tuytelaars", "Tinne", ""], ["Oramas", "Jose", ""]]}, {"id": "2001.08570", "submitter": "Nathaniel Braman", "authors": "Nathaniel Braman, Mohammed El Adoui, Manasa Vulchi, Paulette Turk,\n  Maryam Etesami, Pingfu Fu, Kaustav Bera, Stylianos Drisis, Vinay Varadan,\n  Donna Plecha, Mohammed Benjelloun, Jame Abraham, Anant Madabhushi", "title": "Deep learning-based prediction of response to HER2-targeted neoadjuvant\n  chemotherapy from pre-treatment dynamic breast MRI: A multi-institutional\n  validation study", "comments": "Braman and El Adoui contributed equally to this work. 33 pages, 3\n  figures in main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting response to neoadjuvant therapy is a vexing challenge in breast\ncancer. In this study, we evaluate the ability of deep learning to predict\nresponse to HER2-targeted neo-adjuvant chemotherapy (NAC) from pre-treatment\ndynamic contrast-enhanced (DCE) MRI acquired prior to treatment. In a\nretrospective study encompassing DCE-MRI data from a total of 157 HER2+ breast\ncancer patients from 5 institutions, we developed and validated a deep learning\napproach for predicting pathological complete response (pCR) to HER2-targeted\nNAC prior to treatment. 100 patients who received HER2-targeted neoadjuvant\nchemotherapy at a single institution were used to train (n=85) and tune (n=15)\na convolutional neural network (CNN) to predict pCR. A multi-input CNN\nleveraging both pre-contrast and late post-contrast DCE-MRI acquisitions was\nidentified to achieve optimal response prediction within the validation set\n(AUC=0.93). This model was then tested on two independent testing cohorts with\npre-treatment DCE-MRI data. It achieved strong performance in a 28 patient\ntesting set from a second institution (AUC=0.85, 95% CI 0.67-1.0, p=.0008) and\na 29 patient multicenter trial including data from 3 additional institutions\n(AUC=0.77, 95% CI 0.58-0.97, p=0.006). Deep learning-based response prediction\nmodel was found to exceed a multivariable model incorporating predictive\nclinical variables (AUC < .65 in testing cohorts) and a model of\nsemi-quantitative DCE-MRI pharmacokinetic measurements (AUC < .60 in testing\ncohorts). The results presented in this work across multiple sites suggest that\nwith further validation deep learning could provide an effective and reliable\ntool to guide targeted therapy in breast cancer, thus reducing overtreatment\namong HER2+ patients.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:54:24 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Braman", "Nathaniel", ""], ["Adoui", "Mohammed El", ""], ["Vulchi", "Manasa", ""], ["Turk", "Paulette", ""], ["Etesami", "Maryam", ""], ["Fu", "Pingfu", ""], ["Bera", "Kaustav", ""], ["Drisis", "Stylianos", ""], ["Varadan", "Vinay", ""], ["Plecha", "Donna", ""], ["Benjelloun", "Mohammed", ""], ["Abraham", "Jame", ""], ["Madabhushi", "Anant", ""]]}, {"id": "2001.08572", "submitter": "Zengjie Song", "authors": "Zengjie Song, Oluwasanmi Koyejo, Jiangshe Zhang", "title": "Toward a Controllable Disentanglement Network", "comments": "Improved version of arXiv:1912.11675", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses two crucial problems of learning disentangled image\nrepresentations, namely controlling the degree of disentanglement during image\nediting, and balancing the disentanglement strength and the reconstruction\nquality. To encourage disentanglement, we devise a distance covariance based\ndecorrelation regularization. Further, for the reconstruction step, our model\nleverages a soft target representation combined with the latent image code. By\nexploring the real-valued space of the soft target representation, we are able\nto synthesize novel images with the designated properties. To improve the\nperceptual quality of images generated by autoencoder (AE)-based models, we\nextend the encoder-decoder architecture with the generative adversarial network\n(GAN) by collapsing the AE decoder and the GAN generator into one. We also\ndesign a classification based protocol to quantitatively evaluate the\ndisentanglement strength of our model. Experimental results showcase the\nbenefits of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:54:07 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 06:13:18 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 04:02:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Song", "Zengjie", ""], ["Koyejo", "Oluwasanmi", ""], ["Zhang", "Jiangshe", ""]]}, {"id": "2001.08578", "submitter": "Mohammed Abuhamad", "authors": "Mohammed Abuhamad, Ahmed Abusnaina, DaeHun Nyang, and David Mohaisen", "title": "Sensor-based Continuous Authentication of Smartphones' Users Using\n  Behavioral Biometrics: A Contemporary Survey", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices and technologies have become increasingly popular, offering\ncomparable storage and computational capabilities to desktop computers allowing\nusers to store and interact with sensitive and private information. The\nsecurity and protection of such personal information are becoming more and more\nimportant since mobile devices are vulnerable to unauthorized access or theft.\nUser authentication is a task of paramount importance that grants access to\nlegitimate users at the point-of-entry and continuously through the usage\nsession. This task is made possible with today's smartphones' embedded sensors\nthat enable continuous and implicit user authentication by capturing behavioral\nbiometrics and traits. In this paper, we survey more than 140 recent behavioral\nbiometric-based approaches for continuous user authentication, including\nmotion-based methods (28 studies), gait-based methods (19 studies), keystroke\ndynamics-based methods (20 studies), touch gesture-based methods (29 studies),\nvoice-based methods (16 studies), and multimodal-based methods (34 studies).\nThe survey provides an overview of the current state-of-the-art approaches for\ncontinuous user authentication using behavioral biometrics captured by\nsmartphones' embedded sensors, including insights and open challenges for\nadoption, usability, and performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:07:28 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 17:31:29 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Abuhamad", "Mohammed", ""], ["Abusnaina", "Ahmed", ""], ["Nyang", "DaeHun", ""], ["Mohaisen", "David", ""]]}, {"id": "2001.08579", "submitter": "Marco Antonio Pinto Orellana", "authors": "Marco A. Pinto-Orellana, Diego C. Nascimento, Peyman Mirtaheri, Rune\n  Jonassen, Anis Yazidi and Hugo L. Hammer", "title": "A hemodynamic decomposition model for detecting cognitive load using\n  functional near-infrared spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current paper, we introduce a parametric data-driven model for\nfunctional near-infrared spectroscopy that decomposes a signal into a series of\nindependent, rescaled, time-shifted, hemodynamic basis functions. Each\ndecomposed waveform retains relevant biological information about the expected\nhemodynamic behavior. The model is also presented along with an efficient\niterative estimation method to improve the computational speed. Our hemodynamic\ndecomposition model (HDM) extends the canonical model for instances when a) the\nexternal stimuli are unknown, or b) when the assumption of a direct\nrelationship between the experimental stimuli and the hemodynamic responses\ncannot hold. We also argue that the proposed approach can be potentially\nadopted as a feature transformation method for machine learning purposes. By\nvirtue of applying our devised HDM to a cognitive load classification task on\nfNIRS signals, we have achieved an accuracy of 86.20%+-2.56% using six channels\nin the frontal cortex, and 86.34%+-2.81% utilizing only the AFpz channel also\nlocated in the frontal area. In comparison, state-of-the-art time-spectral\ntransformations only yield 64.61%+-3.03% and 37.8%+-2.96% under identical\nexperimental settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:56:23 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Pinto-Orellana", "Marco A.", ""], ["Nascimento", "Diego C.", ""], ["Mirtaheri", "Peyman", ""], ["Jonassen", "Rune", ""], ["Yazidi", "Anis", ""], ["Hammer", "Hugo L.", ""]]}, {"id": "2001.08581", "submitter": "Liming Jiang", "authors": "Tianzhu Ren, Yuanchang Xie, Liming Jiang", "title": "Cooperative Highway Work Zone Merge Control based on Reinforcement\n  Learning in A Connected and Automated Environment", "comments": "17pages, 6 figures, TRB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the aging infrastructure and the anticipated growing number of highway\nwork zones in the United States, it is important to investigate work zone merge\ncontrol, which is critical for improving work zone safety and capacity. This\npaper proposes and evaluates a novel highway work zone merge control strategy\nbased on cooperative driving behavior enabled by artificial intelligence. The\nproposed method assumes that all vehicles are fully automated, connected and\ncooperative. It inserts two metering zones in the open lane to make space for\nmerging vehicles in the closed lane. In addition, each vehicle in the closed\nlane learns how to optimally adjust its longitudinal position to find a safe\ngap in the open lane using an off-policy soft actor critic (SAC) reinforcement\nlearning (RL) algorithm, considering the traffic conditions in its surrounding.\nThe learning results are captured in convolutional neural networks and used to\ncontrol individual vehicles in the testing phase. By adding the metering zones\nand taking the locations, speeds, and accelerations of surrounding vehicles\ninto account, cooperation among vehicles is implicitly considered. This\nRL-based model is trained and evaluated using a microscopic traffic simulator.\nThe results show that this cooperative RL-based merge control significantly\noutperforms popular strategies such as late merge and early merge in terms of\nboth mobility and safety measures.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 21:39:44 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ren", "Tianzhu", ""], ["Xie", "Yuanchang", ""], ["Jiang", "Liming", ""]]}, {"id": "2001.08582", "submitter": "Sevgi Zubeyde Gurbuz", "authors": "Baris Erol, Sevgi Zubeyde Gurbuz, Moeness G. Amin", "title": "Motion Classification using Kinematically Sifted ACGAN-Synthesized Radar\n  Micro-Doppler Signatures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have recently received vast attention in\napplications requiring classification of radar returns, including radar-based\nhuman activity recognition for security, smart homes, assisted living, and\nbiomedicine. However,acquiring a sufficiently large training dataset remains a\ndaunting task due to the high human costs and resources required for radar data\ncollection. In this paper, an extended approach to adversarial learning is\nproposed for generation of synthetic radar micro-Doppler signatures that are\nwell-adapted to different environments. The synthetic data is evaluated using\nvisual interpretation, analysis of kinematic consistency, data diversity,\ndimensions of the latent space, and saliency maps. A principle-component\nanalysis (PCA) based kinematic-sifting algorithm is introduced to ensure that\nsynthetic signatures are consistent with physically possible human motions. The\nsynthetic dataset is used to train a 19-layer deep convolutional neural network\n(DCNN) to classify micro-Doppler signatures acquired from an environment\ndifferent from that of the dataset supplied to the adversarial network. An\noverall accuracy 93% is achieved on a dataset that contains multiple aspect\nangles (0 deg., 30 deg., and 45 deg. as well as 60 deg.), with 9% improvement\nas a result of kinematic sifting.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 16:50:10 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Erol", "Baris", ""], ["Gurbuz", "Sevgi Zubeyde", ""], ["Amin", "Moeness G.", ""]]}, {"id": "2001.08583", "submitter": "Amir Mosavi Prof", "authors": "Nader Karballaeezadeh, Farah Zaremotekhases, Shahaboddin Shamshirband,\n  Amir Mosavi, Narjes Nabipour, Peter Csiba, Annamaria R. Varkonyi-Koczy", "title": "Intelligent Road Inspection with Advanced Machine Learning; Hybrid\n  Prediction Models for Smart Mobility and Transportation Maintenance Systems", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction models in mobility and transportation maintenance systems have\nbeen dramatically improved through using machine learning methods. This paper\nproposes novel machine learning models for intelligent road inspection. The\ntraditional road inspection systems based on the pavement condition index (PCI)\nare often associated with the critical safety, energy and cost issues.\nAlternatively, the proposed models utilize surface deflection data from falling\nweight deflectometer (FWD) tests to predict the PCI. Machine learning methods\nare the single multi-layer perceptron (MLP) and radial basis function (RBF)\nneural networks as well as their hybrids, i.e., Levenberg-Marquardt (MLP-LM),\nscaled conjugate gradient (MLP-SCG), imperialist competitive (RBF-ICA), and\ngenetic algorithms (RBF-GA). Furthermore, the committee machine intelligent\nsystems (CMIS) method was adopted to combine the results and improve the\naccuracy of the modeling. The results of the analysis have been verified\nthrough using four criteria of average percent relative error (APRE), average\nabsolute percent relative error (AAPRE), root mean square error (RMSE), and\nstandard error (SD). The CMIS model outperforms other models with the promising\nresults of APRE=2.3303, AAPRE=11.6768, RMSE=12.0056, and SD=0.0210.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 19:12:51 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Karballaeezadeh", "Nader", ""], ["Zaremotekhases", "Farah", ""], ["Shamshirband", "Shahaboddin", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Csiba", "Peter", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "2001.08600", "submitter": "Anbu Huang", "authors": "Anbu Huang, Yuanyuan Chen, Yang Liu, Tianjian Chen, and Qiang Yang", "title": "RPN: A Residual Pooling Network for Efficient Federated Learning", "comments": "Accepted by the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed machine learning framework which enables\ndifferent parties to collaboratively train a model while protecting data\nprivacy and security. Due to model complexity, network unreliability and\nconnection in-stability, communication cost has became a major bottleneck for\napplying federated learning to real-world applications. Current existing\nstrategies are either need to manual setting for hyperparameters, or break up\nthe original process into multiple steps, which make it hard to realize\nend-to-end implementation. In this paper, we propose a novel compression\nstrategy called Residual Pooling Network (RPN). Our experiments show that RPN\nnot only reduce data transmission effectively, but also achieve almost the same\nperformance as compared to standard federated learning. Our new approach\nperforms as an end-to-end procedure, which should be readily applied to all\nCNN-based model training scenarios for improvement of communication efficiency,\nand hence make it easy to deploy in real-world application without much human\nintervention.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:30:56 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 00:15:52 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Huang", "Anbu", ""], ["Chen", "Yuanyuan", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""], ["Yang", "Qiang", ""]]}, {"id": "2001.08603", "submitter": "Nitesh Kumar", "authors": "Kumar Nitesh, Kuzelka Ondrej and De Raedt Luc", "title": "Learning Distributional Programs for Relational Autocompletion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relational autocompletion is the problem of automatically filling out some\nmissing values in multi-relational data. We tackle this problem within the\nprobabilistic logic programming framework of Distributional Clauses (DC), which\nsupports both discrete and continuous probability distributions. Within this\nframework, we introduce DiceML { an approach to learn both the structure and\nthe parameters of DC programs from relational data (with possibly missing\ndata). To realize this, DiceML integrates statistical modeling and\ndistributional clauses with rule learning. The distinguishing features of\nDiceML are that it 1) tackles autocompletion in relational data, 2) learns\ndistributional clauses extended with statistical models, 3) deals with both\ndiscrete and continuous distributions, 4) can exploit background knowledge, and\n5) uses an expectation-maximization based algorithm to cope with missing data.\nThe empirical results show the promise of the approach, even when there is\nmissing data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:34:42 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 11:51:31 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 17:22:42 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 14:08:55 GMT"}, {"version": "v5", "created": "Mon, 5 Jul 2021 14:35:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nitesh", "Kumar", ""], ["Ondrej", "Kuzelka", ""], ["Luc", "De Raedt", ""]]}, {"id": "2001.08604", "submitter": "Kang Min Yoo", "authors": "Kang Min Yoo, Hanbit Lee, Franck Dernoncourt, Trung Bui, Walter Chang,\n  Sang-goo Lee", "title": "Variational Hierarchical Dialog Autoencoder for Dialog State Tracking\n  Data Augmentation", "comments": "11 pages (main) + 9 pages (appendix), 1 figure, 6 tables, accepted to\n  EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that generative data augmentation, where synthetic\nsamples generated from deep generative models complement the training dataset,\nbenefit NLP tasks. In this work, we extend this approach to the task of dialog\nstate tracking for goal-oriented dialogs. Due to the inherent hierarchical\nstructure of goal-oriented dialogs over utterances and related annotations, the\ndeep generative model must be capable of capturing the coherence among\ndifferent hierarchies and types of dialog features. We propose the Variational\nHierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of\ngoal-oriented dialogs, including linguistic features and underlying structured\nannotations, namely speaker information, dialog acts, and goals. The proposed\narchitecture is designed to model each aspect of goal-oriented dialogs using\ninter-connected latent variables and learns to generate coherent goal-oriented\ndialogs from the latent spaces. To overcome training issues that arise from\ntraining complex variational models, we propose appropriate training\nstrategies. Experiments on various dialog datasets show that our model improves\nthe downstream dialog trackers' robustness via generative data augmentation. We\nalso discover additional benefits of our unified approach to modeling\ngoal-oriented dialogs: dialog response generation and user simulation, where\nour model outperforms previous strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:34:56 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 12:15:35 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 01:39:34 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Yoo", "Kang Min", ""], ["Lee", "Hanbit", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""], ["Chang", "Walter", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2001.08606", "submitter": "Han Wu", "authors": "Han Wu, Kun Zhang, Guangyi Lv, Qi Liu, Runlong Yu, Weihao Zhao, Enhong\n  Chen and Jianhui Ma", "title": "Deep Technology Tracing for High-tech Companies", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": "10.1109/ICDM.2019.00180", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological change and innovation are vitally important, especially for\nhigh-tech companies. However, factors influencing their future research and\ndevelopment (R&D) trends are both complicated and various, leading it a quite\ndifficult task to make technology tracing for high-tech companies. To this end,\nin this paper, we develop a novel data-driven solution, i.e., Deep Technology\nForecasting (DTF) framework, to automatically find the most possible technology\ndirections customized to each high-tech company. Specially, DTF consists of\nthree components: Potential Competitor Recognition (PCR), Collaborative\nTechnology Recognition (CTR), and Deep Technology Tracing (DTT) neural network.\nFor one thing, PCR and CTR aim to capture competitive relations among\nenterprises and collaborative relations among technologies, respectively. For\nanother, DTT is designed for modeling dynamic interactions between companies\nand technologies with the above relations involved. Finally, we evaluate our\nDTF framework on real-world patent data, and the experimental results clearly\nprove that DTF can precisely help to prospect future technology emphasis of\ncompanies by exploiting hybrid factors.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:44:12 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wu", "Han", ""], ["Zhang", "Kun", ""], ["Lv", "Guangyi", ""], ["Liu", "Qi", ""], ["Yu", "Runlong", ""], ["Zhao", "Weihao", ""], ["Chen", "Enhong", ""], ["Ma", "Jianhui", ""]]}, {"id": "2001.08615", "submitter": "Alberto Tejero", "authors": "Alberto Tejero, Victor Rodriguez-Doncel and Ivan Pau", "title": "Knowledge Graphs for Innovation Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovation ecosystems can be naturally described as a collection of networked\nentities, such as experts, institutions, projects, technologies and products.\nRepresenting in a machine-readable form these entities and their relations is\nnot entirely attainable, due to the existence of abstract concepts such as\nknowledge and due to the confidential, non-public nature of this information,\nbut even its partial depiction is of strong interest. The representation of\ninnovation ecosystems incarnated as knowledge graphs would enable the\ngeneration of reports with new insights, the execution of advanced data\nanalysis tasks. An ontology to capture the essential entities and relations is\npresented, as well as the description of data sources, which can be used to\npopulate innovation knowledge graphs. Finally, the application case of the\nUniversidad Politecnica de Madrid is presented, as well as an insight of future\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 08:02:32 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tejero", "Alberto", ""], ["Rodriguez-Doncel", "Victor", ""], ["Pau", "Ivan", ""]]}, {"id": "2001.08618", "submitter": "Bence Keresztury", "authors": "Bence Keresztury and Elia Bruni", "title": "Compositional properties of emergent languages in deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in multi-agent deep learning systems point towards the\nemergence of compositional languages. These claims are often made without exact\nanalysis or testing of the language. In this work, we analyze the emergent\nlanguage resulting from two different cooperative multi-agent game with more\nexact measures for compositionality. Our findings suggest that solutions found\nby deep learning models are often lacking the ability to reason on an abstract\nlevel therefore failing to generalize the learned knowledge to out of the\ntraining distribution examples. Strategies for testing compositional capacities\nand emergence of human-level concepts are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:55:36 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Keresztury", "Bence", ""], ["Bruni", "Elia", ""]]}, {"id": "2001.08625", "submitter": "Ivo Matteo Baltruschat", "authors": "Ivo M. Baltruschat, Leonhard Steinmeister, Hannes Nickisch, Axel\n  Saalbach, Michael Grass, Gerhard Adam, Tobias Knopp, Harald Ittrich", "title": "Smart Chest X-ray Worklist Prioritization using Artificial Intelligence:\n  A Clinical Workflow Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim is to evaluate whether smart worklist prioritization by artificial\nintelligence (AI) can optimize the radiology workflow and reduce report\nturnaround times (RTAT) for critical findings in chest radiographs (CXRs).\nFurthermore, we investigate a method to counteract the effect of false negative\npredictions by AI -- resulting in an extremely and dangerously long RTAT, as\nCXRs are sorted to the end of the worklist.\n  We developed a simulation framework that models the current workflow at a\nuniversity hospital by incorporating hospital specific CXR generation rates,\nreporting rates and pathology distribution. Using this, we simulated the\nstandard worklist processing \"first-in, first-out\" (FIFO) and compared it with\na worklist prioritization based on urgency. Examination prioritization was\nperformed by the AI, classifying eight different pathological findings ranked\nin descending order of urgency: pneumothorax, pleural effusion, infiltrate,\ncongestion, atelectasis, cardiomegaly, mass and foreign object. Furthermore, we\nintroduced an upper limit for the maximum waiting time, after which the highest\nurgency is assigned to the examination.\n  The average RTAT for all critical findings was significantly reduced in all\nPrioritization-simulations compared to the FIFO-simulation (e.g. pneumothorax:\n35.6 min vs. 80.1 min; p $<0.0001$), while the maximum RTAT for most findings\nincreased at the same time (e.g. pneumothorax: 1293 min vs 890 min; p\n$<0.0001$). Our \"upper limit\" substantially reduced the maximum RTAT all\nclasses (e.g. pneumothorax: 979 min vs. 1293 min / 1178 min; p $<0.0001$).\n  Our simulations demonstrate that smart worklist prioritization by AI can\nreduce the average RTAT for critical findings in CXRs while maintaining a small\nmaximum RTAT as FIFO.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:02:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 13:02:51 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Baltruschat", "Ivo M.", ""], ["Steinmeister", "Leonhard", ""], ["Nickisch", "Hannes", ""], ["Saalbach", "Axel", ""], ["Grass", "Michael", ""], ["Adam", "Gerhard", ""], ["Knopp", "Tobias", ""], ["Ittrich", "Harald", ""]]}, {"id": "2001.08635", "submitter": "Chao Wang", "authors": "Chao Wang", "title": "A Study of the Tasks and Models in Machine Reading Comprehension", "comments": "PhD Qualifying Examination Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide a survey on the existing tasks and models in Machine Reading\nComprehension (MRC), this report reviews: 1) the dataset collection and\nperformance evaluation of some representative simple-reasoning and\ncomplex-reasoning MRC tasks; 2) the architecture designs, attention mechanisms,\nand performance-boosting approaches for developing neural-network-based MRC\nmodels; 3) some recently proposed transfer learning approaches to incorporating\ntext-style knowledge contained in external corpora into the neural networks of\nMRC models; 4) some recently proposed knowledge base encoding approaches to\nincorporating graph-style knowledge contained in external knowledge bases into\nthe neural networks of MRC models. Besides, according to what has been achieved\nand what are still deficient, this report also proposes some open problems for\nthe future research.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:11:44 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wang", "Chao", ""]]}, {"id": "2001.08650", "submitter": "Gobinda Saha", "authors": "Gobinda Saha, Isha Garg, Aayush Ankit and Kaushik Roy", "title": "SPACE: Structured Compression and Sharing of Representational Space for\n  Continual Learning", "comments": "The first two authors contributed equally to this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn adaptively and efficiently throughout their lives. However,\nincrementally learning tasks causes artificial neural networks to overwrite\nrelevant information learned about older tasks, resulting in 'Catastrophic\nForgetting'. Efforts to overcome this phenomenon often utilize resources\npoorly, for instance, by growing the network architecture or needing to save\nparametric importance scores, or violate data privacy between tasks. To tackle\nthis, we propose SPACE, an algorithm that enables a network to learn\ncontinually and efficiently by partitioning the learnt space into a Core space,\nthat serves as the condensed knowledge base over previously learned tasks, and\na Residual space, which is akin to a scratch space for learning the current\ntask. After learning each task, the Residual is analyzed for redundancy, both\nwithin itself and with the learnt Core space. A minimal number of extra\ndimensions required to explain the current task are added to the Core space and\nthe remaining Residual is freed up for learning the next task. We evaluate our\nalgorithm on P-MNIST, CIFAR and a sequence of 8 different datasets, and achieve\ncomparable accuracy to the state-of-the-art methods while overcoming\ncatastrophic forgetting. Additionally, our algorithm is well suited for\npractical use. The partitioning algorithm analyzes all layers in one shot,\nensuring scalability to deeper networks. Moreover, the analysis of dimensions\ntranslates to filter-level sparsity, and the structured nature of the resulting\narchitecture gives us up to 5x improvement in energy efficiency during task\ninference over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:40:56 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 21:02:50 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 15:22:00 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 06:23:33 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Saha", "Gobinda", ""], ["Garg", "Isha", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "2001.08655", "submitter": "Zixin Zhong", "authors": "Zixin Zhong, Wang Chi Cheung, and Vincent Y. F. Tan", "title": "Best Arm Identification for Cascading Bandits in the Fixed Confidence\n  Setting", "comments": "39 pages, 25 figures. Proceedings of the 37th International\n  Conference on Machine Learning (ICML), Vienna, Austria, PMLR 108, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and analyze CascadeBAI, an algorithm for finding the best set of\n$K$ items, also called an arm, within the framework of cascading bandits. An\nupper bound on the time complexity of CascadeBAI is derived by overcoming a\ncrucial analytical challenge, namely, that of probabilistically estimating the\namount of available feedback at each step. To do so, we define a new class of\nrandom variables (r.v.'s) which we term as left-sided sub-Gaussian r.v.'s;\nthese are r.v.'s whose cumulant generating functions (CGFs) can be bounded by a\nquadratic only for non-positive arguments of the CGFs. This enables the\napplication of a sufficiently tight Bernstein-type concentration inequality. We\nshow, through the derivation of a lower bound on the time complexity, that the\nperformance of CascadeBAI is optimal in some practical regimes. Finally,\nextensive numerical simulations corroborate the efficacy of CascadeBAI as well\nas the tightness of our upper bound on its time complexity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:47:52 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 04:03:09 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 16:26:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhong", "Zixin", ""], ["Cheung", "Wang Chi", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2001.08656", "submitter": "David Melhart", "authors": "David Melhart, Georgios N. Yannakakis, Antonios Liapis", "title": "I Feel I Feel You: A Theory of Mind Experiment in Games", "comments": "Accepted manuscript for the KI-Kunstliche Intelligenz special issue\n  on Artificial Intelligence in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study into the player's emotional theory of mind of gameplaying\nagents, we investigate how an agent's behaviour and the player's own\nperformance and emotions shape the recognition of a frustrated behaviour. We\nfocus on the perception of frustration as it is a prevalent affective\nexperience in human-computer interaction. We present a testbed game tailored\ntowards this end, in which a player competes against an agent with a\nfrustration model based on theory. We collect gameplay data, an annotated\nground truth about the player's appraisal of the agent's frustration, and apply\nface recognition to estimate the player's emotional state. We examine the\ncollected data through correlation analysis and predictive machine learning\nmodels, and find that the player's observable emotions are not correlated\nhighly with the perceived frustration of the agent. This suggests that our\nsubject's theory of mind is a cognitive process based on the gameplay context.\nOur predictive models---using ranking support vector machines---corroborate\nthese results, yielding moderately accurate predictors of players' theory of\nmind.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 16:49:39 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Melhart", "David", ""], ["Yannakakis", "Georgios N.", ""], ["Liapis", "Antonios", ""]]}, {"id": "2001.08662", "submitter": "Chandan Karadagur Ananda Reddy", "authors": "Chandan K. A. Reddy, Ebrahim Beyrami, Harishchandra Dubey, Vishak\n  Gopal, Roger Cheng, Ross Cutler, Sergiy Matusevych, Robert Aichner, Ashkan\n  Aazami, Sebastian Braun, Puneet Rana, Sriram Srinivasan, Johannes Gehrke", "title": "The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets,\n  Subjective Speech Quality and Testing Framework", "comments": "Details about Deep Noise Suppression Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The INTERSPEECH 2020 Deep Noise Suppression Challenge is intended to promote\ncollaborative research in real-time single-channel Speech Enhancement aimed to\nmaximize the subjective (perceptual) quality of the enhanced speech. A typical\napproach to evaluate the noise suppression methods is to use objective metrics\non the test set obtained by splitting the original dataset. Many publications\nreport reasonable performance on the synthetic test set drawn from the same\ndistribution as that of the training set. However, often the model performance\ndegrades significantly on real recordings. Also, most of the conventional\nobjective metrics do not correlate well with subjective tests and lab\nsubjective tests are not scalable for a large test set. In this challenge, we\nopen-source a large clean speech and noise corpus for training the noise\nsuppression models and a representative test set to real-world scenarios\nconsisting of both synthetic and real recordings. We also open source an online\nsubjective test framework based on ITU-T P.808 for researchers to quickly test\ntheir developments. The winners of this challenge will be selected based on\nsubjective evaluation on a representative test set using P.808 framework.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:00:21 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 16:16:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Reddy", "Chandan K. A.", ""], ["Beyrami", "Ebrahim", ""], ["Dubey", "Harishchandra", ""], ["Gopal", "Vishak", ""], ["Cheng", "Roger", ""], ["Cutler", "Ross", ""], ["Matusevych", "Sergiy", ""], ["Aichner", "Robert", ""], ["Aazami", "Ashkan", ""], ["Braun", "Sebastian", ""], ["Rana", "Puneet", ""], ["Srinivasan", "Sriram", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2001.08665", "submitter": "Qing Wan", "authors": "Qing Wan, Yoonsuck Choe", "title": "Action Recognition and State Change Prediction in a Recipe Understanding\n  Task Using a Lightweight Neural Network Model", "comments": "AAAI-2020 Student Abstract and Poster Program (Accept)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a natural language sentence describing a specific step in a food\nrecipe. In such instructions, recognizing actions (such as press, bake, etc.)\nand the resulting changes in the state of the ingredients (shape molded,\ncustard cooked, temperature hot, etc.) is a challenging task. One way to cope\nwith this challenge is to explicitly model a simulator module that applies\nactions to entities and predicts the resulting outcome (Bosselut et al. 2018).\nHowever, such a model can be unnecessarily complex. In this paper, we propose a\nsimplified neural network model that separates action recognition and state\nchange prediction, while coupling the two through a novel loss function. This\nallows learning to indirectly influence each other. Our model, although\nsimpler, achieves higher state change prediction performance (67% average\naccuracy for ours vs. 55% in (Bosselut et al. 2018)) and takes fewer samples to\ntrain (10K ours vs. 65K+ by (Bosselut et al. 2018)).\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:04:00 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Wan", "Qing", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "2001.08677", "submitter": "Diego Pinheiro", "authors": "Paulo Rocha, Diego Pinheiro, Martin Cadeiras, Carmelo Bastos-Filho", "title": "Towards Automatic Clustering Analysis using Traces of Information Gain:\n  The InfoGuide Method", "comments": "The 33rd International FLAIRS Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering analysis has become a ubiquitous information retrieval tool in a\nwide range of domains, but a more automatic framework is still lacking. Though\ninternal metrics are the key players towards a successful retrieval of\nclusters, their effectiveness on real-world datasets remains not fully\nunderstood, mainly because of their unrealistic assumptions underlying\ndatasets. We hypothesized that capturing {\\it traces of information gain}\nbetween increasingly complex clustering retrievals---{\\it InfoGuide}---enables\nan automatic clustering analysis with improved clustering retrievals. We\nvalidated the {\\it InfoGuide} hypothesis by capturing the traces of information\ngain using the Kolmogorov-Smirnov statistic and comparing the clusters\nretrieved by {\\it InfoGuide} against those retrieved by other commonly used\ninternal metrics in artificially-generated, benchmarks, and real-world\ndatasets. Our results suggested that {\\it InfoGuide} can enable a more\nautomatic clustering analysis and may be more suitable for retrieving clusters\nin real-world datasets displaying nontrivial statistical properties.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:19:29 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Rocha", "Paulo", ""], ["Pinheiro", "Diego", ""], ["Cadeiras", "Martin", ""], ["Bastos-Filho", "Carmelo", ""]]}, {"id": "2001.08682", "submitter": "Philipp Becker", "authors": "Philipp Becker, Oleg Arenz, Gerhard Neumann", "title": "Expected Information Maximization: Using the I-Projection for Mixture\n  Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling highly multi-modal data is a challenging problem in machine\nlearning. Most algorithms are based on maximizing the likelihood, which\ncorresponds to the M(oment)-projection of the data distribution to the model\ndistribution. The M-projection forces the model to average over modes it cannot\nrepresent. In contrast, the I(information)-projection ignores such modes in the\ndata and concentrates on the modes the model can represent. Such behavior is\nappealing whenever we deal with highly multi-modal data where modelling single\nmodes correctly is more important than covering all the modes. Despite this\nadvantage, the I-projection is rarely used in practice due to the lack of\nalgorithms that can efficiently optimize it based on data. In this work, we\npresent a new algorithm called Expected Information Maximization (EIM) for\ncomputing the I-projection solely based on samples for general latent variable\nmodels, where we focus on Gaussian mixtures models and Gaussian mixtures of\nexperts. Our approach applies a variational upper bound to the I-projection\nobjective which decomposes the original objective into single objectives for\neach mixture component as well as for the coefficients, allowing an efficient\noptimization. Similar to GANs, our approach employs discriminators but uses a\nmore stable optimization procedure, using a tight upper bound. We show that our\nalgorithm is much more effective in computing the I-projection than recent GAN\napproaches and we illustrate the effectiveness of our approach for modelling\nmulti-modal behavior on two pedestrian and traffic prediction datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:24:50 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Becker", "Philipp", ""], ["Arenz", "Oleg", ""], ["Neumann", "Gerhard", ""]]}, {"id": "2001.08699", "submitter": "Aaron Defazio", "authors": "Aaron Defazio and Tullie Murrell and Michael P. Recht", "title": "MRI Banding Removal via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  MRI images reconstructed from sub-sampled Cartesian data using deep learning\ntechniques often show a characteristic banding (sometimes described as\nstreaking), which is particularly strong in low signal-to-noise regions of the\nreconstructed image. In this work, we propose the use of an adversarial loss\nthat penalizes banding structures without requiring any human annotation. Our\ntechnique greatly reduces the appearance of banding, without requiring any\nadditional computation or post-processing at reconstruction time. We report the\nresults of a blind comparison against a strong baseline by a group of expert\nevaluators (board-certified radiologists), where our approach is ranked\nsuperior at banding removal with no statistically significant loss of detail.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:46:14 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:15:01 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 15:54:45 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Defazio", "Aaron", ""], ["Murrell", "Tullie", ""], ["Recht", "Michael P.", ""]]}, {"id": "2001.08700", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem and Calton Pu", "title": "EventMapper: Detecting Real-World Physical Events Using Corroborative\n  and Probabilistic Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of social media makes it a rich source for physical event\ndetection, such as disasters, and as a potential resource for crisis management\nresource allocation. There have been some recent works on leveraging social\nmedia sources for retrospective, after-the-fact event detection of large events\nsuch as earthquakes or hurricanes. Similarly, there is a long history of using\ntraditional physical sensors such as climate satellites to perform regional\nevent detection. However, combining social media with corroborative physical\nsensors for real-time, accurate, and global physical detection has remained\nunexplored.\n  This paper presents EventMapper, a framework to support event recognition of\nsmall yet equally costly events (landslides, flooding, wildfires). EventMapper\nintegrates high-latency, high-accuracy corroborative sources such as physical\nsensors with low-latency, noisy probabilistic sources such as social media\nstreams to deliver real-time, global event recognition. Furthermore,\nEventMapper is resilient to the concept drift phenomenon, where machine\nlearning models require continuous fine-tuning to maintain high performance.\n  By exploiting the common features of probabilistic and corroborative sources,\nEventMapper automates machine learning model updates, maintenance, and\nfine-tuning. We describe three applications built on EventMapper for landslide,\nwildfire, and flooding detection.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:47:31 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""]]}, {"id": "2001.08703", "submitter": "Guangliang Li", "authors": "Guangliang Li, Hamdi Dibeklio\\u{g}lu, Shimon Whiteson and Hayley Hung", "title": "Facial Feedback for Reinforcement Learning: A Case Study and Offline\n  Analysis Using the TAMER Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive reinforcement learning provides a way for agents to learn to\nsolve tasks from evaluative feedback provided by a human user. Previous\nresearch showed that humans give copious feedback early in training but very\nsparsely thereafter. In this article, we investigate the potential of agent\nlearning from trainers' facial expressions via interpreting them as evaluative\nfeedback. To do so, we implemented TAMER which is a popular interactive\nreinforcement learning method in a reinforcement-learning benchmark problem ---\nInfinite Mario, and conducted the first large-scale study of TAMER involving\n561 participants. With designed CNN-RNN model, our analysis shows that telling\ntrainers to use facial expressions and competition can improve the accuracies\nfor estimating positive and negative feedback using facial expressions. In\naddition, our results with a simulation experiment show that learning solely\nfrom predicted feedback based on facial expressions is possible and using\nstrong/effective prediction models or a regression method, facial responses\nwould significantly improve the performance of agents. Furthermore, our\nexperiment supports previous studies demonstrating the importance of\nbi-directional feedback and competitive elements in the training interface.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:50:57 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Li", "Guangliang", ""], ["Dibeklio\u011flu", "Hamdi", ""], ["Whiteson", "Shimon", ""], ["Hung", "Hayley", ""]]}, {"id": "2001.08726", "submitter": "Jianyu Chen", "authors": "Jianyu Chen, Shengbo Eben Li, Masayoshi Tomizuka", "title": "Interpretable End-to-end Urban Autonomous Driving with Latent Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike popular modularized framework, end-to-end autonomous driving seeks to\nsolve the perception, decision and control problems in an integrated way, which\ncan be more adapting to new scenarios and easier to generalize at scale.\nHowever, existing end-to-end approaches are often lack of interpretability, and\ncan only deal with simple driving tasks like lane keeping. In this paper, we\npropose an interpretable deep reinforcement learning method for end-to-end\nautonomous driving, which is able to handle complex urban scenarios. A\nsequential latent environment model is introduced and learned jointly with the\nreinforcement learning process. With this latent model, a semantic birdeye mask\ncan be generated, which is enforced to connect with a certain intermediate\nproperty in today's modularized framework for the purpose of explaining the\nbehaviors of learned policy. The latent space also significantly reduces the\nsample complexity of reinforcement learning. Comparison tests with a simulated\nautonomous car in CARLA show that the performance of our method in urban\nscenarios with crowded surrounding vehicles dominates many baselines including\nDQN, DDPG, TD3 and SAC. Moreover, through masked outputs, the learned policy is\nable to provide a better explanation of how the car reasons about the driving\nenvironment. The codes and videos of this work are available at our github repo\nand project website.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:36:35 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 05:57:16 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 06:23:50 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Chen", "Jianyu", ""], ["Li", "Shengbo Eben", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2001.08730", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Shivansh Pate, and Vinay P. Namboodiri", "title": "Robust Explanations for Visual Question Answering", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a method to obtain robust explanations for visual\nquestion answering(VQA) that correlate well with the answers. Our model\nexplains the answers obtained through a VQA model by providing visual and\ntextual explanations. The main challenges that we address are i) Answers and\ntextual explanations obtained by current methods are not well correlated and\nii) Current methods for visual explanation do not focus on the right location\nfor explaining the answer. We address both these challenges by using a\ncollaborative correlated module which ensures that even if we do not train for\nnoise based attacks, the enhanced correlation ensures that the right\nexplanation and answer can be generated. We further show that this also aids in\nimproving the generated visual and textual explanations. The use of the\ncorrelated module can be thought of as a robust method to verify if the answer\nand explanations are coherent. We evaluate this model using VQA-X dataset. We\nobserve that the proposed method yields better textual and visual justification\nthat supports the decision. We showcase the robustness of the model against a\nnoise-based perturbation attack using corresponding visual and textual\nexplanations. A detailed empirical analysis is shown. Here we provide source\ncode link for our model \\url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:43:34 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Patro", "Badri N.", ""], ["Pate", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08735", "submitter": "Hung-Yu Tseng", "authors": "Hung-Yu Tseng, Hsin-Ying Lee, Jia-Bin Huang, Ming-Hsuan Yang", "title": "Cross-Domain Few-Shot Classification via Learned Feature-Wise\n  Transformation", "comments": "ICLR 2020 (Spotlight). Project page:\n  http://vllab.ucmerced.edu/ym41608/projects/CrossDomainFewShot Code:\n  https://github.com/hytseng0509/CrossDomainFewShot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification aims to recognize novel categories with only few\nlabeled images in each class. Existing metric-based few-shot classification\nalgorithms predict categories by comparing the feature embeddings of query\nimages with those from a few labeled images (support examples) using a learned\nmetric function. While promising performance has been demonstrated, these\nmethods often fail to generalize to unseen domains due to large discrepancy of\nthe feature distribution across domains. In this work, we address the problem\nof few-shot classification under domain shifts for metric-based methods. Our\ncore idea is to use feature-wise transformation layers for augmenting the image\nfeatures using affine transforms to simulate various feature distributions\nunder different domains in the training stage. To capture variations of the\nfeature distributions under different domains, we further apply a\nlearning-to-learn approach to search for the hyper-parameters of the\nfeature-wise transformation layers. We conduct extensive experiments and\nablation studies under the domain generalization setting using five few-shot\nclassification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae.\nExperimental results demonstrate that the proposed feature-wise transformation\nlayer is applicable to various metric-based models, and provides consistent\nimprovements on the few-shot classification performance under domain shift.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:55:43 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:18:22 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 08:58:10 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Tseng", "Hung-Yu", ""], ["Lee", "Hsin-Ying", ""], ["Huang", "Jia-Bin", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2001.08737", "submitter": "Wei-Ting Chang", "authors": "Wei-Ting Chang, Ravi Tandon", "title": "Communication Efficient Federated Learning over Multiple Access Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of federated learning (FL), where\ndistributed users aim to jointly train a machine learning model with the help\nof a parameter server (PS). In each iteration of FL, users compute local\ngradients, followed by transmission of the quantized gradients for subsequent\naggregation and model updates at PS. One of the challenges of FL is that of\ncommunication overhead due to FL's iterative nature and large model sizes. One\nrecent direction to alleviate communication bottleneck in FL is to let users\ncommunicate simultaneously over a multiple access channel (MAC), possibly\nmaking better use of the communication resources.\n  In this paper, we consider the problem of FL learning over a MAC. In\nparticular, we focus on the design of digital gradient transmission schemes\nover a MAC, where gradients at each user are first quantized, and then\ntransmitted over a MAC to be decoded individually at the PS. When designing\ndigital FL schemes over MACs, there are new opportunities to assign different\namount of resources (such as rate or bandwidth) to different users based on a)\nthe informativeness of the gradients at each user, and b) the underlying\nchannel conditions. We propose a stochastic gradient quantization scheme, where\nthe quantization parameters are optimized based on the capacity region of the\nMAC. We show that such channel aware quantization for FL outperforms uniform\nquantization, particularly when users experience different channel conditions,\nand when have gradients with varying levels of informativeness.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:59:07 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Chang", "Wei-Ting", ""], ["Tandon", "Ravi", ""]]}, {"id": "2001.08741", "submitter": "Leihao Wei", "authors": "Leihao Wei and Yannan Lin and William Hsu", "title": "Using a Generative Adversarial Network for CT Normalization and its\n  Impact on Radiomic Features", "comments": "ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-Aided-Diagnosis (CADx) systems assist radiologists with identifying\nand classifying potentially malignant pulmonary nodules on chest CT scans using\nmorphology and texture-based (radiomic) features. However, radiomic features\nare sensitive to differences in acquisitions due to variations in dose levels\nand slice thickness. This study investigates the feasibility of generating a\nnormalized scan from heterogeneous CT scans as input. We obtained projection\ndata from 40 low-dose chest CT scans, simulating acquisitions at 10%, 25% and\n50% dose and reconstructing the scans at 1.0mm and 2.0mm slice thickness. A 3D\ngenerative adversarial network (GAN) was used to simultaneously normalize\nreduced dose, thick slice (2.0mm) images to normal dose (100%), thinner slice\n(1.0mm) images. We evaluated the normalized image quality using peak\nsignal-to-noise ratio (PSNR), structural similarity index (SSIM) and Learned\nPerceptual Image Patch Similarity (LPIPS). Our GAN improved perceptual\nsimilarity by 35%, compared to a baseline CNN method. Our analysis also shows\nthat the GAN-based approach led to a significantly smaller error (p-value <\n0.05) in nine studied radiomic features. These results indicated that GANs\ncould be used to normalize heterogeneous CT images and reduce the variability\nin radiomic feature values.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 23:41:29 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Wei", "Leihao", ""], ["Lin", "Yannan", ""], ["Hsu", "William", ""]]}, {"id": "2001.08743", "submitter": "Byung Hoon Ahn", "authors": "Byung Hoon Ahn, Prannoy Pilligundla, Amir Yazdanbakhsh, Hadi\n  Esmaeilzadeh", "title": "Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network\n  Compilation", "comments": "Published as a conference paper at ICLR 2020. arXiv admin note: text\n  overlap with arXiv:1905.12799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving faster execution with shorter compilation time can foster further\ndiversity and innovation in neural networks. However, the current paradigm of\nexecuting neural networks either relies on hand-optimized libraries,\ntraditional compilation heuristics, or very recently genetic algorithms and\nother stochastic methods. These methods suffer from frequent costly hardware\nmeasurements rendering them not only too time consuming but also suboptimal. As\nsuch, we devise a solution that can learn to quickly adapt to a previously\nunseen design space for code optimization, both accelerating the search and\nimproving the output performance. This solution dubbed Chameleon leverages\nreinforcement learning whose solution takes fewer steps to converge, and\ndevelops an adaptive sampling algorithm that not only focuses on the costly\nsamples (real hardware measurements) on representative points but also uses a\ndomain-knowledge inspired logic to improve the samples itself. Experimentation\nwith real hardware shows that Chameleon provides 4.45x speed up in optimization\ntime over AutoTVM, while also improving inference time of the modern deep\nnetworks by 5.6%.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 20:42:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ahn", "Byung Hoon", ""], ["Pilligundla", "Prannoy", ""], ["Yazdanbakhsh", "Amir", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2001.08746", "submitter": "Mohammad Golbabaee", "authors": "Mohammad Golbabaee, Guido Buonincontri, Carolin Pirkl, Marion Menzel,\n  Bjoern Menze, Mike Davies, Pedro Gomez", "title": "Compressive MRI quantification using convex spatiotemporal priors and\n  deep auto-encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dictionary-matching-free pipeline for multi-parametric\nquantitative MRI image computing. Our approach has two stages based on\ncompressed sensing reconstruction and deep learned quantitative inference. The\nreconstruction phase is convex and incorporates efficient spatiotemporal\nregularisations within an accelerated iterative shrinkage algorithm. This\nminimises the under-sampling (aliasing) artefacts from aggressively short scan\ntimes. The learned quantitative inference phase is purely trained on physical\nsimulations (Bloch equations) that are flexible for producing rich training\nsamples. We propose a deep and compact auto-encoder network with residual\nblocks in order to embed Bloch manifold projections through multiscale\npiecewise affine approximations, and to replace the nonscalable\ndictionary-matching baseline. Tested on a number of datasets we demonstrate\neffectiveness of the proposed scheme for recovering accurate and consistent\nquantitative information from novel and aggressively subsampled 2D/3D\nquantitative MRI acquisition protocols.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:15:42 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 20:09:21 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Golbabaee", "Mohammad", ""], ["Buonincontri", "Guido", ""], ["Pirkl", "Carolin", ""], ["Menzel", "Marion", ""], ["Menze", "Bjoern", ""], ["Davies", "Mike", ""], ["Gomez", "Pedro", ""]]}, {"id": "2001.08747", "submitter": "Max Daniels", "authors": "Max Daniels, Paul Hand, Reinhard Heckel", "title": "Reducing the Representation Error of GAN Image Priors Using the Deep\n  Decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models, such as GANs, learn an explicit low-dimensional\nrepresentation of a particular class of images, and so they may be used as\nnatural image priors for solving inverse problems such as image restoration and\ncompressive sensing. GAN priors have demonstrated impressive performance on\nthese tasks, but they can exhibit substantial representation error for both\nin-distribution and out-of-distribution images, because of the mismatch between\nthe learned, approximate image distribution and the data generating\ndistribution. In this paper, we demonstrate a method for reducing the\nrepresentation error of GAN priors by modeling images as the linear combination\nof a GAN prior with a Deep Decoder. The deep decoder is an underparameterized\nand most importantly unlearned natural signal model similar to the Deep Image\nPrior. No knowledge of the specific inverse problem is needed in the training\nof the GAN underlying our method. For compressive sensing and image\nsuperresolution, our hybrid model exhibits consistently higher PSNRs than both\nthe GAN priors and Deep Decoder separately, both on in-distribution and\nout-of-distribution images. This model provides a method for extensibly and\ncheaply leveraging both the benefits of learned and unlearned image recovery\npriors in inverse problems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 18:37:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Daniels", "Max", ""], ["Hand", "Paul", ""], ["Heckel", "Reinhard", ""]]}, {"id": "2001.08767", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis and Anay Mehrotra and Nisheeth K. Vishnoi", "title": "Interventions for Ranking in the Presence of Implicit Bias", "comments": "This paper will appear at the ACM FAT* 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit bias is the unconscious attribution of particular qualities (or lack\nthereof) to a member from a particular social group (e.g., defined by gender or\nrace). Studies on implicit bias have shown that these unconscious stereotypes\ncan have adverse outcomes in various social contexts, such as job screening,\nteaching, or policing. Recently, (Kleinberg and Raghavan, 2018) considered a\nmathematical model for implicit bias and showed the effectiveness of the Rooney\nRule as a constraint to improve the utility of the outcome for certain cases of\nthe subset selection problem. Here we study the problem of designing\ninterventions for the generalization of subset selection -- ranking -- that\nrequires to output an ordered set and is a central primitive in various social\nand computational contexts. We present a family of simple and interpretable\nconstraints and show that they can optimally mitigate implicit bias for a\ngeneralization of the model studied in (Kleinberg and Raghavan, 2018).\nSubsequently, we prove that under natural distributional assumptions on the\nutilities of items, simple, Rooney Rule-like, constraints can also surprisingly\nrecover almost all the utility lost due to implicit biases. Finally, we augment\nour theoretical results with empirical findings on real-world distributions\nfrom the IIT-JEE (2009) dataset and the Semantic Scholar Research corpus.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:11:31 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2001.08768", "submitter": "Sorour Mohajerani", "authors": "Sorour Mohajerani and Parvaneh Saeedi", "title": "Cloud and Cloud Shadow Segmentation for Remote Sensing Imagery via\n  Filtered Jaccard Loss Function and Parametric Augmentation", "comments": "12 pages. This version is a bit different from the one published in\n  IEEE JSTARS", "journal-ref": "IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing (JSTARS), 2021", "doi": "10.1109/JSTARS.2021.3070786", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud and cloud shadow segmentation are fundamental processes in optical\nremote sensing image analysis. Current methods for cloud/shadow identification\nin geospatial imagery are not as accurate as they should, especially in the\npresence of snow and haze. This paper presents a deep learning-based framework\nfor the detection of cloud/shadow in Landsat 8 images. Our method benefits from\na convolutional neural network, Cloud-Net+ (a modification of our previously\nproposed Cloud-Net \\cite{myigarss}) that is trained with a novel loss function\n(Filtered Jaccard Loss). The proposed loss function is more sensitive to the\nabsence of foreground objects in an image and penalizes/rewards the predicted\nmask more accurately than other common loss functions. In addition, a sunlight\ndirection-aware data augmentation technique is developed for the task of cloud\nshadow detection to extend the generalization ability of the proposed model by\nexpanding existing training sets. The combination of Cloud-Net+, Filtered\nJaccard Loss function, and the proposed augmentation algorithm delivers\nsuperior results on four public cloud/shadow detection datasets. Our\nexperiments on Pascal VOC dataset exemplifies the applicability and quality of\nour proposed network and loss function in other computer vision applications.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:13:00 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 22:01:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Mohajerani", "Sorour", ""], ["Saeedi", "Parvaneh", ""]]}, {"id": "2001.08779", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Vinod K. Kurmi, Sandeep Kumar, and Vinay P. Namboodiri", "title": "Deep Bayesian Network for Visual Question Generation", "comments": "WACV-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating natural questions from an image is a semantic task that requires\nusing vision and language modalities to learn multimodal representations.\nImages can have multiple visual and language cues such as places, captions, and\ntags. In this paper, we propose a principled deep Bayesian learning framework\nthat combines these cues to produce natural questions. We observe that with the\naddition of more cues and by minimizing uncertainty in the among cues, the\nBayesian network becomes more confident. We propose a Minimizing Uncertainty of\nMixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues\nexperts for generating probabilistic questions. This is a Bayesian framework\nand the results show a remarkable similarity to natural questions as validated\nby a human study. We observe that with the addition of more cues and by\nminimizing uncertainty among the cues, the Bayesian framework becomes more\nconfident. Ablation studies of our model indicate that a subset of cues is\ninferior at this task and hence the principled fusion of cues is preferred.\nFurther, we observe that the proposed approach substantially improves over\nstate-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,\nand CIDEr). Here we provide project link for Deep Bayesian VQG\n\\url{https://delta-lab-iitk.github.io/BVQG/}\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:37:20 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Patro", "Badri N.", ""], ["Kurmi", "Vinod K.", ""], ["Kumar", "Sandeep", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2001.08785", "submitter": "Marjan Ghazvininejad", "authors": "Marjan Ghazvininejad, Omer Levy, Luke Zettlemoyer", "title": "Semi-Autoregressive Training Improves Mask-Predict Decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed mask-predict decoding algorithm has narrowed the\nperformance gap between semi-autoregressive machine translation models and the\ntraditional left-to-right approach. We introduce a new training method for\nconditional masked language models, SMART, which mimics the semi-autoregressive\nbehavior of mask-predict, producing training examples that contain model\npredictions as part of their inputs. Models trained with SMART produce\nhigher-quality translations when using mask-predict decoding, effectively\nclosing the remaining performance gap with fully autoregressive models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:56:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Levy", "Omer", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2001.08791", "submitter": "Brian Quanz", "authors": "Brian Quanz, Wei Sun, Ajay Deshpande, Dhruv Shah, Jae-eun Park", "title": "Machine learning based co-creative design framework", "comments": "Thirty-third Conference on Neural Information Processing Systems\n  (NeurIPS) 2019 Workshop on Machine Learning for Creativity and Design,\n  December 14th, 2019, Vancouver, Canada\n  (https://neurips2019creativity.github.io/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible, co-creative framework bringing together multiple\nmachine learning techniques to assist human users to efficiently produce\neffective creative designs. We demonstrate its potential with a perfume bottle\ndesign case study, including human evaluation and quantitative and qualitative\nanalyses.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 20:18:44 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Quanz", "Brian", ""], ["Sun", "Wei", ""], ["Deshpande", "Ajay", ""], ["Shah", "Dhruv", ""], ["Park", "Jae-eun", ""]]}, {"id": "2001.08806", "submitter": "Masoomeh Jasemi", "authors": "Masoomeh Jasemi, Shaahin Hessabi, Nader Bagherzadeh", "title": "Reliable and Energy Efficient MLC STT-RAM Buffer for CNN Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lightweight scheme where the formation of a data block is\nchanged in such a way that it can tolerate soft errors significantly better\nthan the baseline. The key insight behind our work is that CNN weights are\nnormalized between -1 and 1 after each convolutional layer, and this leaves one\nbit unused in half-precision floating-point representation. By taking advantage\nof the unused bit, we create a backup for the most significant bit to protect\nit against the soft errors. Also, considering the fact that in MLC STT-RAMs the\ncost of memory operations (read and write), and reliability of a cell are\ncontent-dependent (some patterns take larger current and longer time, while\nthey are more susceptible to soft error), we rearrange the data block to\nminimize the number of costly bit patterns. Combining these two techniques\nprovides the same level of accuracy compared to an error-free baseline while\nimproving the read and write energy by 9% and 6%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:14:42 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Jasemi", "Masoomeh", ""], ["Hessabi", "Shaahin", ""], ["Bagherzadeh", "Nader", ""]]}, {"id": "2001.08809", "submitter": "Kursat Rasim Mestav", "authors": "Kursat Rasim Mestav, Lang Tong", "title": "Universal Data Anomaly Detection via Inverse Generative Adversary\n  Network", "comments": "5 pages, letter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting data anomaly is considered. Under the null\nhypothesis that models anomaly-free data, measurements are assumed to be from\nan unknown distribution with some authenticated historical samples. Under the\ncomposite alternative hypothesis, measurements are from an unknown distribution\npositive distance away from the distribution under the null hypothesis. No\ntraining data are available for the distribution of anomaly data. A\nsemi-supervised deep learning technique based on an inverse generative\nadversary network is proposed.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:11:36 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Mestav", "Kursat Rasim", ""], ["Tong", "Lang", ""]]}, {"id": "2001.08817", "submitter": "Evan Schwab", "authors": "Evan Schwab, Andr\\'e Goo{\\ss}en, Hrishikesh Deshpande, Axel Saalbach", "title": "Localization of Critical Findings in Chest X-Ray without Local\n  Annotations Using Multi-Instance Learning", "comments": "Accepted to International Symposium of Biomedical Imaging (ISBI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of critical findings in chest X-rays (CXR), such as\npneumothorax, is important for assisting radiologists in their clinical\nworkflow like triaging time-sensitive cases and screening for incidental\nfindings. While deep learning (DL) models has become a promising predictive\ntechnology with near-human accuracy, they commonly suffer from a lack of\nexplainability, which is an important aspect for clinical deployment of DL\nmodels in the highly regulated healthcare industry. For example, localizing\ncritical findings in an image is useful for explaining the predictions of DL\nclassification algorithms. While there have been a host of joint classification\nand localization methods for computer vision, the state-of-the-art DL models\nrequire locally annotated training data in the form of pixel level labels or\nbounding box coordinates. In the medical domain, this requires an expensive\namount of manual annotation by medical experts for each critical finding. This\nrequirement becomes a major barrier for training models that can rapidly scale\nto various findings. In this work, we address these shortcomings with an\ninterpretable DL algorithm based on multi-instance learning that jointly\nclassifies and localizes critical findings in CXR without the need for local\nannotations. We show competitive classification results on three different\ncritical findings (pneumothorax, pneumonia, and pulmonary edema) from three\ndifferent CXR datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:29:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Schwab", "Evan", ""], ["Goo\u00dfen", "Andr\u00e9", ""], ["Deshpande", "Hrishikesh", ""], ["Saalbach", "Axel", ""]]}, {"id": "2001.08823", "submitter": "Alex Kearney", "authors": "Alex Kearney, Anna Koop, Patrick M. Pilarski", "title": "What's a Good Prediction? Challenges in evaluating an agent's knowledge", "comments": "In preparation for submission to Adaptive Behaviour", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing general knowledge by learning task-independent models of the\nworld can help agents solve challenging problems. However, both constructing\nand evaluating such models remains an open challenge. The most common\napproaches to evaluating models is to assess their accuracy with respect to\nobservable values. However, the prevailing reliance on estimator accuracy as a\nproxy for the usefulness of the knowledge has the potential to lead us astray.\nWe demonstrate the conflict between accuracy and usefulness through a series of\nillustrative examples including both a thought experiment and empirical example\nin MineCraft, using the General Value Function framework (GVF). Having\nidentified challenges in assessing an agent's knowledge, we propose an\nalternate evaluation approach that arises continually in the online continual\nlearning setting we recommend evaluation by examining internal learning\nprocesses, specifically the relevance of a GVF's features to the prediction\ntask at hand. This paper contributes a first look into evaluation of\npredictions through their use, an integral component of predictive knowledge\nwhich is as of yet unexplored.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:44:43 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 23:44:37 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Kearney", "Alex", ""], ["Koop", "Anna", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "2001.08826", "submitter": "Haihao Lu", "authors": "Haihao Lu", "title": "An $O(s^r)$-Resolution ODE Framework for Understanding Discrete-Time\n  Algorithms and Applications to the Linear Convergence of Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a long history of using ordinary differential equations (ODEs)\nto understand the dynamics of discrete-time algorithms (DTAs). Surprisingly,\nthere are still two fundamental and unanswered questions: (i) it is unclear how\nto obtain a \\emph{suitable} ODE from a given DTA, and (ii) it is unclear the\nconnection between the convergence of a DTA and its corresponding ODEs. In this\npaper, we propose a new machinery -- an $O(s^r)$-resolution ODE framework --\nfor analyzing the behavior of a generic DTA, which (partially) answers the\nabove two questions. The framework contains three steps: 1. To obtain a\nsuitable ODE from a given DTA, we define a hierarchy of $O(s^r)$-resolution\nODEs of a DTA parameterized by the degree $r$, where $s$ is the step-size of\nthe DTA. We present a principal approach to construct the unique\n$O(s^r)$-resolution ODEs from a DTA; 2. To analyze the resulting ODE, we\npropose the $O(s^r)$-linear-convergence condition of a DTA with respect to an\nenergy function, under which the $O(s^r)$-resolution ODE converges linearly to\nan optimal solution; 3. To bridge the convergence properties of a DTA and its\ncorresponding ODEs, we define the properness of an energy function and show\nthat the linear convergence of the $O(s^r)$-resolution ODE with respect to a\nproper energy function can automatically guarantee the linear convergence of\nthe DTA. To better illustrate this machinery, we utilize it to study three\nclassic algorithms -- gradient descent ascent (GDA), proximal point method\n(PPM) and extra-gradient method (EGM) -- for solving the unconstrained minimax\nproblem $\\min_{x\\in\\RR^n} \\max_{y\\in \\RR^m} L(x,y)$.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:53:17 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 16:01:33 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 01:47:01 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 19:51:10 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 21:21:31 GMT"}, {"version": "v6", "created": "Sun, 3 Jan 2021 03:12:38 GMT"}, {"version": "v7", "created": "Fri, 9 Jul 2021 16:19:13 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lu", "Haihao", ""]]}, {"id": "2001.08830", "submitter": "Sr{\\dj}an Kiti\\'c", "authors": "Sr{\\dj}an Kiti\\'c, Gilles Puy, Patrick P\\'erez, Philippe Gilberton", "title": "Scattering Features for Multimodal Gait Recognition", "comments": "Published at IEEE GlobalSIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying people on the basis of their walk\n(gait) pattern. Classical approaches to tackle this problem are based on, e.g.,\nvideo recordings or piezoelectric sensors embedded in the floor. In this work,\nwe rely on acoustic and vibration measurements, obtained from a microphone and\na geophone sensor, respectively. The contribution of this work is twofold.\nFirst, we propose a feature extraction method based on an (untrained) shallow\nscattering network, specially tailored for the gait signals. Second, we\ndemonstrate that fusing the two modalities improves identification in the\npractically relevant open set scenario.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:11:38 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Kiti\u0107", "Sr\u0111an", ""], ["Puy", "Gilles", ""], ["P\u00e9rez", "Patrick", ""], ["Gilberton", "Philippe", ""]]}, {"id": "2001.08837", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Matthew Hausknecht", "title": "Graph Constrained Reinforcement Learning for Natural Language Action\n  Spaces", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive Fiction games are text-based simulations in which an agent\ninteracts with the world purely through natural language. They are ideal\nenvironments for studying how to extend reinforcement learning agents to meet\nthe challenges of natural language understanding, partial observability, and\naction generation in combinatorially-large text-based action spaces. We present\nKG-A2C, an agent that builds a dynamic knowledge graph while exploring and\ngenerates actions using a template-based action space. We contend that the dual\nuses of the knowledge graph to reason about game state and to constrain natural\nlanguage generation are the keys to scalable exploration of combinatorially\nlarge natural language actions. Results across a wide variety of IF games show\nthat KG-A2C outperforms current IF agents despite the exponential increase in\naction space size.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "2001.08839", "submitter": "Xiaolong Ma", "authors": "Zhengang Li, Yifan Gong, Xiaolong Ma, Sijia Liu, Mengshu Sun, Zheng\n  Zhan, Zhenglun Kong, Geng Yuan, Yanzhi Wang", "title": "SS-Auto: A Single-Shot, Automatic Structured Weight Pruning Framework of\n  DNNs with Ultra-High Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs for hardware efficiency and inference accelerations. Previous works in\nthis area leave great space for improvement since sparse structures with\ncombinations of different structured pruning schemes are not exploited fully\nand efficiently. To mitigate the limitations, we propose SS-Auto, a\nsingle-shot, automatic structured pruning framework that can achieve row\npruning and column pruning simultaneously. We adopt soft constraint-based\nformulation to alleviate the strong non-convexity of l0-norm constraints used\nin state-of-the-art ADMM-based methods for faster convergence and fewer\nhyperparameters. Instead of solving the problem directly, a Primal-Proximal\nsolution is proposed to avoid the pitfall of penalizing all weights equally,\nthereby enhancing the accuracy. Extensive experiments on CIFAR-10 and CIFAR-100\ndatasets demonstrate that the proposed framework can achieve ultra-high pruning\nrates while maintaining accuracy. Furthermore, significant inference speedup\nhas been observed from the proposed framework through actual measurements on\nthe smartphone.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:45:02 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Ma", "Xiaolong", ""], ["Liu", "Sijia", ""], ["Sun", "Mengshu", ""], ["Zhan", "Zheng", ""], ["Kong", "Zhenglun", ""], ["Yuan", "Geng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08841", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Sima Azizi, Mohammadamir Kavousi, and Donald Wunsch", "title": "Autonomous Control of a Line Follower Robot Using a Q-Learning\n  Controller", "comments": "Accepted paper in IEEE CCWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a MIMO simulated annealing SA based Q learning method is\nproposed to control a line follower robot. The conventional controller for\nthese types of robots is the proportional P controller. Considering the unknown\nmechanical characteristics of the robot and uncertainties such as friction and\nslippery surfaces, system modeling and controller designing can be extremely\nchallenging. The mathematical modeling for the robot is presented in this\npaper, and a simulator is designed based on this model. The basic Q learning\nmethods are based pure exploitation and the epsilon-greedy methods, which help\nexploration, can harm the controller performance after learning completion by\nexploring nonoptimal actions. The simulated annealing based Q learning method\ntackles this drawback by decreasing the exploration rate when the learning\nincreases. The simulation and experimental results are provided to evaluate the\neffectiveness of the proposed controller.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:50:14 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Azizi", "Sima", ""], ["Kavousi", "Mohammadamir", ""], ["Wunsch", "Donald", ""]]}, {"id": "2001.08842", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "Improving generalisation of AutoML systems with dynamic fitness\n  evaluations", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3377930.3389805", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem machine learning developers are faced with is overfitting,\nthat is, fitting a pipeline too closely to the training data that the\nperformance degrades for unseen data. Automated machine learning aims to free\n(or at least ease) the developer from the burden of pipeline creation, but this\noverfitting problem can persist. In fact, this can become more of a problem as\nwe look to iteratively optimise the performance of an internal cross-validation\n(most often \\textit{k}-fold). While this internal cross-validation hopes to\nreduce this overfitting, we show we can still risk overfitting to the\nparticular folds used. In this work, we aim to remedy this problem by\nintroducing dynamic fitness evaluations which approximate repeated\n\\textit{k}-fold cross-validation, at little extra cost over single\n\\textit{k}-fold, and far lower cost than typical repeated \\textit{k}-fold. The\nresults show that when time equated, the proposed fitness function results in\nsignificant improvement over the current state-of-the-art baseline method which\nuses an internal single \\textit{k}-fold. Furthermore, the proposed extension is\nvery simple to implement on top of existing evolutionary computation methods,\nand can provide essentially a free boost in generalisation/testing performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:54:54 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.08844", "submitter": "Ali Mohammad Alqudah", "authors": "Ali Mohammad Alqudah, Hiam Alquraan, Isam Abu Qasmieh, Amin Alqudah,\n  Wafaa Al-Sharu", "title": "Brain Tumor Classification Using Deep Learning Technique -- A Comparison\n  between Cropped, Uncropped, and Segmented Lesion Images with Different Sizes", "comments": null, "journal-ref": "IJATCSE, 8(6), pp.3684-3691 (2019)", "doi": "10.30534/ijatcse/2019/155862019", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning is the newest and the current trend of the machine learning\nfield that paid a lot of the researchers' attention in the recent few years. As\na proven powerful machine learning tool, deep learning was widely used in\nseveral applications for solving various complex problems that require\nextremely high accuracy and sensitivity, particularly in the medical field. In\ngeneral, brain tumor is one of the most common and aggressive malignant tumor\ndiseases which is leading to a very short expected life if it is diagnosed at\nhigher grade. Based on that, brain tumor grading is a very critical step after\ndetecting the tumor in order to achieve an effective treating plan. In this\npaper, we used Convolutional Neural Network (CNN) which is one of the most\nwidely used deep learning architectures for classifying a dataset of 3064 T1\nweighted contrast-enhanced brain MR images for grading (classifying) the brain\ntumors into three classes (Glioma, Meningioma, and Pituitary Tumor). The\nproposed CNN classifier is a powerful tool and its overall performance with\naccuracy of 98.93% and sensitivity of 98.18% for the cropped lesions, while the\nresults for the uncropped lesions are 99% accuracy and 98.52% sensitivity and\nthe results for segmented lesion images are 97.62% for accuracy and 97.40%\nsensitivity.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 23:05:19 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Alqudah", "Ali Mohammad", ""], ["Alquraan", "Hiam", ""], ["Qasmieh", "Isam Abu", ""], ["Alqudah", "Amin", ""], ["Al-Sharu", "Wafaa", ""]]}, {"id": "2001.08853", "submitter": "Kijung Shin", "authors": "Jihoon Ko, Kyuhan Lee, Kijung Shin, Noseong Park", "title": "MONSTOR: An Inductive Approach for Estimating and Maximizing Influence\n  over Unseen Networks", "comments": "To appear at the 2020 IEEE/ACM International Conference on Advances\n  in Social Networks Analysis and Mining (ASONAM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization (IM) is one of the most important problems in social\nnetwork analysis. Its objective is to find a given number of seed nodes that\nmaximize the spread of information through a social network. Since it is an\nNP-hard problem, many approximate/heuristic methods have been developed, and a\nnumber of them repeat Monte Carlo (MC) simulations over and over to reliably\nestimate the influence (i.e., the number of infected nodes) of a seed set. In\nthis work, we present an inductive machine learning method, called Monte Carlo\nSimulator (MONSTOR), for estimating the influence of given seed nodes in social\nnetworks unseen during training. To the best of our knowledge, MONSTOR is the\nfirst inductive method for this purpose. MONSTOR can greatly accelerate\nexisting IM algorithms by replacing repeated MC simulations. In our\nexperiments, MONSTOR provided highly accurate estimates, achieving 0.998 or\nhigher Pearson and Spearman correlation coefficients in unseen real-world\nsocial networks. Moreover, IM algorithms equipped with MONSTOR are more\naccurate than state-of-the-art competitors in 63% of IM use cases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 00:20:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 00:56:42 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 05:38:55 GMT"}, {"version": "v4", "created": "Wed, 19 Aug 2020 17:12:03 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 10:18:52 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ko", "Jihoon", ""], ["Lee", "Kyuhan", ""], ["Shin", "Kijung", ""], ["Park", "Noseong", ""]]}, {"id": "2001.08856", "submitter": "Yahia Assiri", "authors": "Yahia Assiri", "title": "Stochastic Optimization of Plain Convolutional Neural Networks with\n  Simple methods", "comments": "arXiv admin note: substantial text overlap with arXiv:1708.04552 by\n  other authors", "journal-ref": "15th International Conference on Machine Learning and Data Mining,\n  MLDM 2019, vol.II, New York, NY, USA, July 20-25, 2019, ibai-publishing, ISSN\n  1864-9734 ISBN 978-3-942952-63-7, pages(833-844)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been achieving the best possible\naccuracies in many visual pattern classification problems. However, due to the\nmodel capacity required to capture such representations, they are often\noversensitive to overfitting and therefore require proper regularization to\ngeneralize well. In this paper, we present a combination of regularization\ntechniques which work together to get better performance, we built plain CNNs,\nand then we used data augmentation, dropout and customized early stopping\nfunction, we tested and evaluated these techniques by applying models on five\nfamous datasets, MNIST, CIFAR10, CIFAR100, SVHN, STL10, and we achieved three\nstate-of-the-art-of (MNIST, SVHN, STL10) and very high-Accuracy on the other\ntwo datasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 01:20:59 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Assiri", "Yahia", ""]]}, {"id": "2001.08861", "submitter": "Giovanni Sutanto", "authors": "Giovanni Sutanto, Austin S. Wang, Yixin Lin, Mustafa Mukadam, Gaurav\n  S. Sukhatme, Akshara Rai, Franziska Meier", "title": "Encoding Physical Constraints in Differentiable Newton-Euler Algorithm", "comments": "Accepted for publication at the 2nd Annual Conference on Learning for\n  Dynamics and Control (L4DC), year 2020. Paper length is 10 pages (i.e. 8\n  pages of technical content and 2 pages of the Bibliography/References). The\n  code is available at\n  https://github.com/facebookresearch/differentiable-robot-model", "journal-ref": "Proceedings of the 2nd Conference on Learning for Dynamics and\n  Control, PMLR 120:804-813, 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recursive Newton-Euler Algorithm (RNEA) is a popular technique for\ncomputing the dynamics of robots. RNEA can be framed as a differentiable\ncomputational graph, enabling the dynamics parameters of the robot to be\nlearned from data via modern auto-differentiation toolboxes. However, the\ndynamics parameters learned in this manner can be physically implausible. In\nthis work, we incorporate physical constraints in the learning by adding\nstructure to the learned parameters. This results in a framework that can learn\nphysically plausible dynamics via gradient descent, improving the training\nspeed as well as generalization of the learned dynamics models. We evaluate our\nmethod on real-time inverse dynamics control tasks on a 7 degree of freedom\nrobot arm, both in simulation and on the real robot. Our experiments study a\nspectrum of structure added to the parameters of the differentiable RNEA\nalgorithm, and compare their performance and generalization.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 02:08:09 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 04:52:22 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 08:50:19 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 09:23:43 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Sutanto", "Giovanni", ""], ["Wang", "Austin S.", ""], ["Lin", "Yixin", ""], ["Mukadam", "Mustafa", ""], ["Sukhatme", "Gaurav S.", ""], ["Rai", "Akshara", ""], ["Meier", "Franziska", ""]]}, {"id": "2001.08869", "submitter": "Yifei Chen", "authors": "Yifei Chen, Haoyu Ma, Deying Kong, Xiangyi Yan, Jianbao Wu, Wei Fan,\n  Xiaohui Xie", "title": "Nonparametric Structure Regularization Machine for 2D Hand Pose\n  Estimation", "comments": "The paper has be accepted and will be presented at 2020 IEEE Winter\n  Conference on Applications of Computer Vision (WACV). The code is freely\n  available at https://github.com/HowieMa/NSRMhand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand pose estimation is more challenging than body pose estimation due to\nsevere articulation, self-occlusion and high dexterity of the hand. Current\napproaches often rely on a popular body pose algorithm, such as the\nConvolutional Pose Machine (CPM), to learn 2D keypoint features. These\nalgorithms cannot adequately address the unique challenges of hand pose\nestimation, because they are trained solely based on keypoint positions without\nseeking to explicitly model structural relationship between them. We propose a\nnovel Nonparametric Structure Regularization Machine (NSRM) for 2D hand pose\nestimation, adopting a cascade multi-task architecture to learn hand structure\nand keypoint representations jointly. The structure learning is guided by\nsynthetic hand mask representations, which are directly computed from keypoint\npositions, and is further strengthened by a novel probabilistic representation\nof hand limbs and an anatomically inspired composition strategy of mask\nsynthesis. We conduct extensive studies on two public datasets - OneHand 10k\nand CMU Panoptic Hand. Experimental results demonstrate that explicitly\nenforcing structure learning consistently improves pose estimation accuracy of\nCPM baseline models, by 1.17% on the first dataset and 4.01% on the second one.\nThe implementation and experiment code is freely available online. Our proposal\nof incorporating structural learning to hand pose estimation requires no\nadditional training information, and can be a generic add-on module to other\npose estimation models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 03:27:32 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Chen", "Yifei", ""], ["Ma", "Haoyu", ""], ["Kong", "Deying", ""], ["Yan", "Xiangyi", ""], ["Wu", "Jianbao", ""], ["Fan", "Wei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "2001.08873", "submitter": "Penny Chong", "authors": "Penny Chong, Lukas Ruff, Marius Kloft, Alexander Binder", "title": "Simple and Effective Prevention of Mode Collapse in Deep One-Class\n  Classification", "comments": "Accepted in 2020 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207209", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection algorithms find extensive use in various fields. This area\nof research has recently made great advances thanks to deep learning. A recent\nmethod, the deep Support Vector Data Description (deep SVDD), which is inspired\nby the classic kernel-based Support Vector Data Description (SVDD), is capable\nof simultaneously learning a feature representation of the data and a\ndata-enclosing hypersphere. The method has shown promising results in both\nunsupervised and semi-supervised settings. However, deep SVDD suffers from\nhypersphere collapse -- also known as mode collapse, if the architecture of the\nmodel does not comply with certain architectural constraints, e.g. the removal\nof bias terms. These constraints limit the adaptability of the model and in\nsome cases, may affect the model performance due to learning sub-optimal\nfeatures. In this work, we consider two regularizers to prevent hypersphere\ncollapse in deep SVDD. The first regularizer is based on injecting random noise\nvia the standard cross-entropy loss. The second regularizer penalizes the\nminibatch variance when it becomes too small. Moreover, we introduce an\nadaptive weighting scheme to control the amount of penalization between the\nSVDD loss and the respective regularizer. Our proposed regularized variants of\ndeep SVDD show encouraging results and outperform a prominent state-of-the-art\nmethod on a setup where the anomalies have no apparent geometrical structure.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 03:44:47 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 01:51:12 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 09:25:17 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 06:45:48 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Chong", "Penny", ""], ["Ruff", "Lukas", ""], ["Kloft", "Marius", ""], ["Binder", "Alexander", ""]]}, {"id": "2001.08877", "submitter": "Hongji Wei", "authors": "T. Tony Cai, Hongji Wei", "title": "Distributed Gaussian Mean Estimation under Communication Constraints:\n  Optimal Rates and Communication-Efficient Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed estimation of a Gaussian mean under communication\nconstraints in a decision theoretical framework. Minimax rates of convergence,\nwhich characterize the tradeoff between the communication costs and statistical\naccuracy, are established in both the univariate and multivariate settings.\nCommunication-efficient and statistically optimal procedures are developed. In\nthe univariate case, the optimal rate depends only on the total communication\nbudget, so long as each local machine has at least one bit. However, in the\nmultivariate case, the minimax rate depends on the specific allocations of the\ncommunication budgets among the local machines.\n  Although optimal estimation of a Gaussian mean is relatively simple in the\nconventional setting, it is quite involved under the communication constraints,\nboth in terms of the optimal procedure design and lower bound argument. The\ntechniques developed in this paper can be of independent interest. An essential\nstep is the decomposition of the minimax estimation problem into two stages,\nlocalization and refinement. This critical decomposition provides a framework\nfor both the lower bound analysis and optimal procedure design.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:19:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cai", "T. Tony", ""], ["Wei", "Hongji", ""]]}, {"id": "2001.08883", "submitter": "Tugba Erpek", "authors": "Yalin E. Sagduyu, Yi Shi, Tugba Erpek, William Headley, Bryse Flowers,\n  George Stantchev, Zhuo Lu", "title": "When Wireless Security Meets Machine Learning: Motivation, Challenges,\n  and Research Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless systems are vulnerable to various attacks such as jamming and\neavesdropping due to the shared and broadcast nature of wireless medium. To\nsupport both attack and defense strategies, machine learning (ML) provides\nautomated means to learn from and adapt to wireless communication\ncharacteristics that are hard to capture by hand-crafted features and models.\nThis article discusses motivation, background, and scope of research efforts\nthat bridge ML and wireless security. Motivated by research directions surveyed\nin the context of ML for wireless security, ML-based attack and defense\nsolutions and emerging adversarial ML techniques in the wireless domain are\nidentified along with a roadmap to foster research efforts in bridging ML and\nwireless security.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:07:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sagduyu", "Yalin E.", ""], ["Shi", "Yi", ""], ["Erpek", "Tugba", ""], ["Headley", "William", ""], ["Flowers", "Bryse", ""], ["Stantchev", "George", ""], ["Lu", "Zhuo", ""]]}, {"id": "2001.08885", "submitter": "Khe Chai Sim", "authors": "Mary Gooneratne, Khe Chai Sim, Petr Zadrazil, Andreas Kabel,\n  Fran\\c{c}oise Beaufays, Giovanni Motta", "title": "Low-rank Gradient Approximation For Memory-Efficient On-device Training\n  of Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models on mobile devices has the potential of\nimproving both privacy and accuracy of the models. However, one of the major\nobstacles to achieving this goal is the memory limitation of mobile devices.\nReducing training memory enables models with high-dimensional weight matrices,\nlike automatic speech recognition (ASR) models, to be trained on-device. In\nthis paper, we propose approximating the gradient matrices of deep neural\nnetworks using a low-rank parameterization as an avenue to save training\nmemory. The low-rank gradient approximation enables more advanced,\nmemory-intensive optimization techniques to be run on device. Our experimental\nresults show that we can reduce the training memory by about 33.0% for Adam\noptimization. It uses comparable memory to momentum optimization and achieves a\n4.5% relative lower word error rate on an ASR personalization task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:12:18 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Gooneratne", "Mary", ""], ["Sim", "Khe Chai", ""], ["Zadrazil", "Petr", ""], ["Kabel", "Andreas", ""], ["Beaufays", "Fran\u00e7oise", ""], ["Motta", "Giovanni", ""]]}, {"id": "2001.08886", "submitter": "Luna Zhang", "authors": "Luna M. Zhang", "title": "PairNets: Novel Fast Shallow Artificial Neural Networks on Partitioned\n  Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, an artificial neural network (ANN) is trained slowly by a\ngradient descent algorithm such as the backpropagation algorithm since a large\nnumber of hyperparameters of the ANN need to be fine-tuned with many training\nepochs. To highly speed up training, we created a novel shallow 4-layer ANN\ncalled \"Pairwise Neural Network\" (\"PairNet\") with high-speed hyperparameter\noptimization. In addition, a value of each input is partitioned into multiple\nintervals, and then an n-dimensional space is partitioned into M n-dimensional\nsubspaces. M local PairNets are built in M partitioned local n-dimensional\nsubspaces. A local PairNet is trained very quickly with only one epoch since\nits hyperparameters are directly optimized one-time via simply solving a system\nof linear equations by using the multivariate least squares fitting method.\nSimulation results for three regression problems indicated that the PairNet\nachieved much higher speeds and lower average testing mean squared errors\n(MSEs) for the three cases, and lower average training MSEs for two cases than\nthe traditional ANNs. A significant future work is to develop better and faster\noptimization algorithms based on intelligent methods and parallel computing\nmethods to optimize both partitioned subspaces and hyperparameters to build the\nfast and effective PairNets for applications in big data mining and real-time\nmachine learning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 05:23:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Zhang", "Luna M.", ""]]}, {"id": "2001.08895", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Calton Pu, Joao Eduardo Ferreira", "title": "Small, Accurate, and Fast Vehicle Re-ID on the Edge: the SAFR Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Small, Accurate, and Fast Re-ID (SAFR) design for flexible\nvehicle re-id under a variety of compute environments such as cloud, mobile,\nedge, or embedded devices by only changing the re-id model backbone. Through\nbest-fit design choices, feature extraction, training tricks, global attention,\nand local attention, we create a reid model design that optimizes\nmulti-dimensionally along model size, speed, & accuracy for deployment under\nvarious memory and compute constraints. We present several variations of our\nflexible SAFR model: SAFR-Large for cloud-type environments with large compute\nresources, SAFR-Small for mobile devices with some compute constraints, and\nSAFR-Micro for edge devices with severe memory & compute constraints.\n  SAFR-Large delivers state-of-the-art results with mAP 81.34 on the VeRi-776\nvehicle re-id dataset (15% better than related work). SAFR-Small trades a 5.2%\ndrop in performance (mAP 77.14 on VeRi-776) for over 60% model compression and\n150% speedup. SAFR-Micro, at only 6MB and 130MFLOPS, trades 6.8% drop in\naccuracy (mAP 75.80 on VeRi-776) for 95% compression and 33x speedup compared\nto SAFR-Large.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 06:07:17 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Suprem", "Abhijit", ""], ["Pu", "Calton", ""], ["Ferreira", "Joao Eduardo", ""]]}, {"id": "2001.08896", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Paul N. Whatmough, Zhi-Gang Liu, Matthew Mattina,\n  Jesse Beu", "title": "Compressing Language Models using Doped Kronecker Products", "comments": "Link to Workshop\n  (https://research.fb.com/programs/on-device-intelligence-workshop/)", "journal-ref": "Presented at On-device Intelligence Workshop at Third Conference\n  on Machine Learning and Systems (MLSys) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Kronecker Products (KP) have been used to compress IoT RNN Applications by\n15-38x compression factors, achieving better results than traditional\ncompression methods. However when KP is applied to large Natural Language\nProcessing tasks, it leads to significant accuracy loss (approx 26%). This\npaper proposes a way to recover accuracy otherwise lost when applying KP to\nlarge NLP tasks, by allowing additional degrees of freedom in the KP matrix.\nMore formally, we propose doping, a process of adding an extremely sparse\noverlay matrix on top of the pre-defined KP structure. We call this compression\nmethod doped kronecker product compression. To train these models, we present a\nnew solution to the phenomenon of co-matrix adaption (CMA), which uses a new\nregularization scheme called co matrix dropout regularization (CMR). We present\nexperimental results that demonstrate compression of a large language model\nwith LSTM layers of size 25 MB by 25x with 1.4% loss in perplexity score. At\n25x compression, an equivalent pruned network leads to 7.9% loss in perplexity\nscore, while HMD and LMF lead to 15% and 27% loss in perplexity score\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 06:07:21 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 05:36:36 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 15:58:58 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 07:07:22 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 05:27:00 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Thakker", "Urmish", ""], ["Whatmough", "Paul N.", ""], ["Liu", "Zhi-Gang", ""], ["Mattina", "Matthew", ""], ["Beu", "Jesse", ""]]}, {"id": "2001.08904", "submitter": "Muhammad Khan", "authors": "Muhammad Raza Khan, Morteza Ziyadi and Mohamed AbdelHady", "title": "MT-BioNER: Multi-task Learning for Biomedical Named Entity Recognition\n  using Deep Bidirectional Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents such as Cortana, Alexa and Siri are continuously\nworking on increasing their capabilities by adding new domains. The support of\na new domain includes the design and development of a number of NLU components\nfor domain classification, intents classification and slots tagging (including\nnamed entity recognition). Each component only performs well when trained on a\nlarge amount of labeled data. Second, these components are deployed on\nlimited-memory devices which requires some model compression. Third, for some\ndomains such as the health domain, it is hard to find a single training data\nset that covers all the required slot types. To overcome these mentioned\nproblems, we present a multi-task transformer-based neural architecture for\nslot tagging. We consider the training of a slot tagger using multiple data\nsets covering different slot types as a multi-task learning problem. The\nexperimental results on the biomedical domain have shown that the proposed\napproach outperforms the previous state-of-the-art systems for slot tagging on\nthe different benchmark biomedical datasets in terms of (time and memory)\nefficiency and effectiveness. The output slot tagger can be used by the\nconversational agent to better identify entities in the input utterances.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 07:16:32 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Khan", "Muhammad Raza", ""], ["Ziyadi", "Morteza", ""], ["AbdelHady", "Mohamed", ""]]}, {"id": "2001.08922", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "RePAD: Real-time Proactive Anomaly Detection for Time Series", "comments": "12 pages, 8 figures, the 34th International Conference on Advanced\n  Information Networking and Applications (AINA 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-44041-1_110", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decade, many anomaly detection approaches have been\nintroduced in different fields such as network monitoring, fraud detection, and\nintrusion detection. However, they require understanding of data pattern and\noften need a long off-line period to build a model or network for the target\ndata. Providing real-time and proactive anomaly detection for streaming time\nseries without human intervention and domain knowledge is highly valuable since\nit greatly reduces human effort and enables appropriate countermeasures to be\nundertaken before a disastrous damage, failure, or other harmful event occurs.\nHowever, this issue has not been well studied yet. To address it, this paper\nproposes RePAD, which is a Real-time Proactive Anomaly Detection algorithm for\nstreaming time series based on Long Short-Term Memory (LSTM). RePAD utilizes\nshort-term historic data points to predict and determine whether or not the\nupcoming data point is a sign that an anomaly is likely to happen in the near\nfuture. By dynamically adjusting the detection threshold over time, RePAD is\nable to tolerate minor pattern change in time series and detect anomalies\neither proactively or on time. Experiments based on two time series datasets\ncollected from the Numenta Anomaly Benchmark demonstrate that RePAD is able to\nproactively detect anomalies and provide early warnings in real time without\nhuman intervention and domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:13:33 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 10:05:32 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 13:48:49 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2001.08943", "submitter": "Max Berrendorf", "authors": "Max Berrendorf and Evgeniy Faerman and Volker Tresp", "title": "Active Learning for Entity Alignment", "comments": "to be published in ECIR'21; fix typo and add acknowledgement", "journal-ref": null, "doi": "10.1007/978-3-030-72113-8_4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel framework for the labeling of entity\nalignments in knowledge graph datasets. Different strategies to select\ninformative instances for the human labeler build the core of our framework. We\nillustrate how the labeling of entity alignments is different from assigning\nclass labels to single instances and how these differences affect the labeling\nefficiency. Based on these considerations we propose and evaluate different\nactive and passive learning strategies. One of our main findings is that\npassive learning approaches, which can be efficiently precomputed and deployed\nmore easily, achieve performance comparable to the active learning strategies.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 10:33:08 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:16:03 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 15:10:00 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.08950", "submitter": "Saurabh Goyal", "authors": "Saurabh Goyal, Anamitra R. Choudhury, Saurabh M. Raje, Venkatesan T.\n  Chakaravarthy, Yogish Sabharwal, Ashish Verma", "title": "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector\n  Elimination", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel method, called PoWER-BERT, for improving the inference\ntime of the popular BERT model, while maintaining the accuracy. It works by: a)\nexploiting redundancy pertaining to word-vectors (intermediate encoder outputs)\nand eliminating the redundant vectors. b) determining which word-vectors to\neliminate by developing a strategy for measuring their significance, based on\nthe self-attention mechanism. c) learning how many word-vectors to eliminate by\naugmenting the BERT model and the loss function. Experiments on the standard\nGLUE benchmark shows that PoWER-BERT achieves up to 4.5x reduction in inference\ntime over BERT with <1% loss in accuracy. We show that PoWER-BERT offers\nsignificantly better trade-off between accuracy and inference time compared to\nprior methods. We demonstrate that our method attains up to 6.8x reduction in\ninference time with <1% loss in accuracy when applied over ALBERT, a highly\ncompressed version of BERT. The code for PoWER-BERT is publicly available at\nhttps://github.com/IBM/PoWER-BERT.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 11:36:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:53:56 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 12:22:08 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 18:35:54 GMT"}, {"version": "v5", "created": "Tue, 8 Sep 2020 14:11:33 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Goyal", "Saurabh", ""], ["Choudhury", "Anamitra R.", ""], ["Raje", "Saurabh M.", ""], ["Chakaravarthy", "Venkatesan T.", ""], ["Sabharwal", "Yogish", ""], ["Verma", "Ashish", ""]]}, {"id": "2001.08957", "submitter": "Rujikorn Charakorn", "authors": "Rujikorn Charakorn, Yuttapong Thawornwattana, Sirawaj Itthipuripat,\n  Nick Pawlowski, Poramate Manoonpong, Nat Dilokthanakul", "title": "An Explicit Local and Global Representation Disentanglement Framework\n  with Applications in Deep Clustering and Unsupervised Object Detection", "comments": "13 pages and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual data can be understood at different levels of granularity, where\nglobal features correspond to semantic-level information and local features\ncorrespond to texture patterns. In this work, we propose a framework, called\nSPLIT, which allows us to disentangle local and global information into two\nseparate sets of latent variables within the variational autoencoder (VAE)\nframework. Our framework adds generative assumption to the VAE by requiring a\nsubset of the latent variables to generate an auxiliary set of observable data.\nThis additional generative assumption primes the latent variables to local\ninformation and encourages the other latent variables to represent global\ninformation. We examine three different flavours of VAEs with different\ngenerative assumptions. We show that the framework can effectively disentangle\nlocal and global information within these models leads to improved\nrepresentation, with better clustering and unsupervised object detection\nbenchmarks. Finally, we establish connections between SPLIT and recent research\nin cognitive neuroscience regarding the disentanglement in human visual\nperception. The code for our experiments is at\nhttps://github.com/51616/split-vae .\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 12:09:20 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 10:11:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Charakorn", "Rujikorn", ""], ["Thawornwattana", "Yuttapong", ""], ["Itthipuripat", "Sirawaj", ""], ["Pawlowski", "Nick", ""], ["Manoonpong", "Poramate", ""], ["Dilokthanakul", "Nat", ""]]}, {"id": "2001.08961", "submitter": "Hossein A. Rahmani", "authors": "Hossein A. Rahmani, Mohammad Aliannejadi, Mitra Baratchi, Fabio\n  Crestani", "title": "Joint Geographical and Temporal Modeling based on Matrix Factorization\n  for Point-of-Interest Recommendation", "comments": "To be appear in ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the popularity of Location-based Social Networks, Point-of-Interest\n(POI) recommendation has become an important task, which learns the users'\npreferences and mobility patterns to recommend POIs. Previous studies show that\nincorporating contextual information such as geographical and temporal\ninfluences is necessary to improve POI recommendation by addressing the data\nsparsity problem. However, existing methods model the geographical influence\nbased on the physical distance between POIs and users, while ignoring the\ntemporal characteristics of such geographical influences. In this paper, we\nperform a study on the user mobility patterns where we find out that users'\ncheck-ins happen around several centers depending on their current temporal\nstate. Next, we propose a spatio-temporal activity-centers algorithm to model\nusers' behavior more accurately. Finally, we demonstrate the effectiveness of\nour proposed contextual model by incorporating it into the matrix factorization\nmodel under two different settings: i) static and ii) temporal. To show the\neffectiveness of our proposed method, which we refer to as STACP, we conduct\nexperiments on two well-known real-world datasets acquired from Gowalla and\nFoursquare LBSNs. Experimental results show that the STACP model achieves a\nstatistically significant performance improvement, compared to the\nstate-of-the-art techniques. Also, we demonstrate the effectiveness of\ncapturing geographical and temporal information for modeling users' activity\ncenters and the importance of modeling them jointly.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 12:25:37 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Rahmani", "Hossein A.", ""], ["Aliannejadi", "Mohammad", ""], ["Baratchi", "Mitra", ""], ["Crestani", "Fabio", ""]]}, {"id": "2001.08972", "submitter": "Tony Ng", "authors": "Tony Ng, Vassileios Balntas, Yurun Tian, Krystian Mikolajczyk", "title": "SOLAR: Second-Order Loss and Attention for Image Retrieval", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in deep-learning have shown that second-order information is\nbeneficial in many computer-vision tasks. Second-order information can be\nenforced both in the spatial context and the abstract feature dimensions. In\nthis work, we explore two second-order components. One is focused on\nsecond-order spatial information to increase the performance of image\ndescriptors, both local and global. It is used to re-weight feature maps, and\nthus emphasise salient image locations that are subsequently used for\ndescription. The second component is concerned with a second-order similarity\n(SOS) loss, that we extend to global descriptors for image retrieval, and is\nused to enhance the triplet loss with hard-negative mining. We validate our\napproach on two different tasks and datasets for image retrieval and image\nmatching. The results show that our two second-order components complement each\nother, bringing significant performance improvements in both tasks and lead to\nstate-of-the-art results across the public benchmarks. Code available at:\nhttp://github.com/tonyngjichun/SOLAR\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 12:54:23 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:47:42 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 12:09:07 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 13:43:47 GMT"}, {"version": "v5", "created": "Tue, 4 Aug 2020 17:36:45 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ng", "Tony", ""], ["Balntas", "Vassileios", ""], ["Tian", "Yurun", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "2001.08973", "submitter": "Jeff Calder", "authors": "Amber Yuan, Jeff Calder, Braxton Osting", "title": "A continuum limit for the PageRank algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised and unsupervised machine learning methods often rely on\ngraphs to model data, prompting research on how theoretical properties of\noperators on graphs are leveraged in learning problems. While most of the\nexisting literature focuses on undirected graphs, directed graphs are very\nimportant in practice, giving models for physical, biological, or\ntransportation networks, among many other applications. In this paper, we\npropose a new framework for rigorously studying continuum limits of learning\nalgorithms on directed graphs. We use the new framework to study the PageRank\nalgorithm, and show how it can be interpreted as a numerical scheme on a\ndirected graph involving a type of normalized graph Laplacian. We show that the\ncorresponding continuum limit problem, which is taken as the number of webpages\ngrows to infinity, is a second-order, possibly degenerate, elliptic equation\nthat contains reaction, diffusion, and advection terms. We prove that the\nnumerical scheme is consistent and stable and compute explicit rates of\nconvergence of the discrete solution to the solution of the continuum limit\nPDE. We give applications to proving stability and asymptotic regularity of the\nPageRank vector. Finally, we illustrate our results with numerical experiments\nand explore an application to data depth.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 12:56:09 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 17:29:54 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 15:05:01 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Yuan", "Amber", ""], ["Calder", "Jeff", ""], ["Osting", "Braxton", ""]]}, {"id": "2001.08975", "submitter": "Carlos Sevilla Salcedo", "authors": "Carlos Sevilla-Salcedo, Vanessa G\\'omez-Verdejo and Pablo M. Olmos", "title": "Sparse Semi-supervised Heterogeneous Interbattery Bayesian Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian approach to feature extraction, known as factor analysis (FA),\nhas been widely studied in machine learning to obtain a latent representation\nof the data. An adequate selection of the probabilities and priors of these\nbayesian models allows the model to better adapt to the data nature (i.e.\nheterogeneity, sparsity), obtaining a more representative latent space.\n  The objective of this article is to propose a general FA framework capable of\nmodelling any problem. To do so, we start from the Bayesian Inter-Battery\nFactor Analysis (BIBFA) model, enhancing it with new functionalities to be able\nto work with heterogeneous data, include feature selection, and handle missing\nvalues as well as semi-supervised problems.\n  The performance of the proposed model, Sparse Semi-supervised Heterogeneous\nInterbattery Bayesian Analysis (SSHIBA) has been tested on 4 different\nscenarios to evaluate each one of its novelties, showing not only a great\nversatility and an interpretability gain, but also outperforming most of the\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:00:56 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sevilla-Salcedo", "Carlos", ""], ["G\u00f3mez-Verdejo", "Vanessa", ""], ["Olmos", "Pablo M.", ""]]}, {"id": "2001.08979", "submitter": "Amit Tewari", "authors": "Amit Tewari", "title": "Forecasting NIFTY 50 benchmark Index using Seasonal ARIMA time series\n  models", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10332.95364", "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyses how Time Series Analysis techniques can be applied to\ncapture movement of an exchange traded index in a stock market. Specifically,\nSeasonal Auto Regressive Integrated Moving Average (SARIMA) class of models is\napplied to capture the movement of Nifty 50 index which is one of the most\nactively exchange traded contracts globally [1]. A total of 729 model parameter\ncombinations were evaluated and the most appropriate selected for making the\nfinal forecast based on AIC criteria [8]. NIFTY 50 can be used for a variety of\npurposes such as benchmarking fund portfolios, launching of index funds,\nexchange traded funds (ETFs) and structured products. The index tracks the\nbehaviour of a portfolio of blue chip companies, the largest and most liquid\nIndian securities and can be regarded as a true reflection of the Indian stock\nmarket [2].\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 12:58:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Tewari", "Amit", ""]]}, {"id": "2001.08985", "submitter": "Saptarshi Ghosh", "authors": "M.A. Ganaie, Saptarshi Ghosh, Naveen Mendola, M Tanveer and Sarika\n  Jalan", "title": "Identification of Chimera using Machine Learning", "comments": "20 Pages, 4 Figures; Comments welcome", "journal-ref": "Chaos 30, 063128 (2020)", "doi": "10.1063/1.5143285", "report-no": null, "categories": "nlin.AO cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chimera state refers to coexistence of coherent and non-coherent phases in\nidentically coupled dynamical units found in various complex dynamical systems.\nIdentification of Chimera, on one hand is essential due to its applicability in\nvarious areas including neuroscience, and on other hand is challenging due to\nits widely varied appearance in different systems and the peculiar nature of\nits profile. Therefore, a simple yet universal method for its identification\nremains an open problem. Here, we present a very distinctive approach using\nmachine learning techniques to characterize different dynamical phases and\nidentify the chimera state from given spatial profiles generated using various\ndifferent models. The experimental results show that the performance of the\nclassification algorithms varies for different dynamical models. The machine\nlearning algorithms, namely random forest, oblique random forest based on\ntikhonov, parallel-axis split and null space regularization achieved more than\n$96\\% $ accuracy for the Kuramoto model. For the logistic-maps, random forest\nand tikhonov regularization based oblique random forest showed more than $90\\%$\naccuracy, and for the H\\'enon-Map model, random forest, null-space and\naxis-parallel split regularization based oblique random forest achieved more\nthan $80\\%$ accuracy. The oblique random forest with null space regularization\nachieved consistent performance (more than $83\\%$ accuracy) across different\ndynamical models while the auto-encoder based random vector functional link\nneural network showed relatively lower performance. This work provides a\ndirection for employing machine learning techniques to identify dynamical\npatterns arising in coupled non-linear units on large-scale, and for\ncharacterizing complex spatio-temporal patterns in real-world systems for\nvarious applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:59:27 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 14:16:51 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ganaie", "M. A.", ""], ["Ghosh", "Saptarshi", ""], ["Mendola", "Naveen", ""], ["Tanveer", "M", ""], ["Jalan", "Sarika", ""]]}, {"id": "2001.08997", "submitter": "Yana Lyakhova", "authors": "Ya. S. Lyakhova, E. A. Polyakov, A. N. Rubtsov", "title": "Effectively Trainable Semi-Quantum Restricted Boltzmann Machine", "comments": "8 pages, 6 figures; misprints have been corrected; numerical\n  experiments have been extended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel quantum model for the restricted Boltzmann machine (RBM),\nin which the visible units remain classical whereas the hidden units are\nquantized as noninteracting fermions. The free motion of the fermions is\nparametrically coupled to the classical signal of the visible units. This model\npossesses a quantum behaviour such as coherences between the hidden units.\nNumerical experiments show that this fact makes it more powerful than the\nclassical RBM with the same number of hidden units. At the same time, a\nsignificant advantage of the proposed model over the other approaches to the\nQuantum Boltzmann Machine (QBM) is that it is exactly solvable and efficiently\ntrainable on a classical computer: there is a closed expression for the\nlog-likelihood gradient with respect to its parameters. This fact makes it\ninteresting not only as a model of a hypothetical quantum simulator, but also\nas a quantum-inspired classical machine-learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:38:48 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 08:48:37 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 17:02:33 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 21:05:44 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Lyakhova", "Ya. S.", ""], ["Polyakov", "E. A.", ""], ["Rubtsov", "A. N.", ""]]}, {"id": "2001.09001", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Arslan Ali, Burhan A. Mudassar, Yun Long, and Saibal\n  Mukhopadhyay", "title": "MagNet: Discovering Multi-agent Interaction Dynamics using Neural\n  Network", "comments": "Accepted manuscript by ICRA 2020", "journal-ref": "ICRA 2020, pp. 8158-8164", "doi": "10.1109/ICRA40945.2020.9196846", "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the MagNet, a neural network-based multi-agent interaction model\nto discover the governing dynamics and predict evolution of a complex\nmulti-agent system from observations. We formulate a multi-agent system as a\ncoupled non-linear network with a generic ordinary differential equation (ODE)\nbased state evolution, and develop a neural network-based realization of its\ntime-discretized model. MagNet is trained to discover the core dynamics of a\nmulti-agent system from observations, and tuned on-line to learn agent-specific\nparameters of the dynamics to ensure accurate prediction even when physical or\nrelational attributes of agents, or number of agents change. We evaluate MagNet\non a point-mass system in two-dimensional space, Kuramoto phase synchronization\ndynamics and predator-swarm interaction dynamics demonstrating orders of\nmagnitude improvement in prediction accuracy over traditional deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:41:01 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:17:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Saha", "Priyabrata", ""], ["Ali", "Arslan", ""], ["Mudassar", "Burhan A.", ""], ["Long", "Yun", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2001.09005", "submitter": "Federico Errica", "authors": "Federico Errica, Davide Bacciu, Alessio Micheli", "title": "Theoretically Expressive and Edge-aware Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Graph Neural Network that combines recent advancements in\nthe field. We give theoretical contributions by proving that the model is\nstrictly more general than the Graph Isomorphism Network and the Gated Graph\nNeural Network, as it can approximate the same functions and deal with\narbitrary edge values. Then, we show how a single node information can flow\nthrough the graph unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:43:39 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Errica", "Federico", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2001.09027", "submitter": "Yu-Feng Li", "authors": "Lan-Zhe Guo, Feng Kuang, Zhang-Xun Liu, Yu-Feng Li, Nan Ma, Xiao-Hu\n  Qie", "title": "Weakly Supervised Learning Meets Ride-Sharing User Experience\n  Enhancement", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning aims at coping with scarce labeled data. Previous\nweakly supervised studies typically assume that there is only one kind of weak\nsupervision in data. In many applications, however, raw data usually contains\nmore than one kind of weak supervision at the same time. For example, in user\nexperience enhancement from Didi, one of the largest online ride-sharing\nplatforms, the ride comment data contains severe label noise (due to the\nsubjective factors of passengers) and severe label distribution bias (due to\nthe sampling bias). We call such a problem as \"compound weakly supervised\nlearning\". In this paper, we propose the CWSL method to address this problem\nbased on Didi ride-sharing comment data. Specifically, an instance reweighting\nstrategy is employed to cope with severe label noise in comment data, where the\nweights for harmful noisy instances are small. Robust criteria like AUC rather\nthan accuracy and the validation performance are optimized for the correction\nof biased data label. Alternating optimization and stochastic gradient methods\naccelerate the optimization on large-scale data. Experiments on Didi\nride-sharing comment data clearly validate the effectiveness. We hope this work\nmay shed some light on applying weakly supervised learning to complex real\nsituations.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 05:36:27 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Guo", "Lan-Zhe", ""], ["Kuang", "Feng", ""], ["Liu", "Zhang-Xun", ""], ["Li", "Yu-Feng", ""], ["Ma", "Nan", ""], ["Qie", "Xiao-Hu", ""]]}, {"id": "2001.09040", "submitter": "Se Un Park", "authors": "Se Un Park", "title": "Estimation for Compositional Data using Measurements from Nonlinear\n  Systems using Artificial Neural Networks", "comments": "43 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our objective is to estimate the unknown compositional input from its output\nresponse through an unknown system after estimating the inverse of the original\nsystem with a training set. The proposed methods using artificial neural\nnetworks (ANNs) can compete with the optimal bounds for linear systems, where\nconvex optimization theory applies, and demonstrate promising results for\nnonlinear system inversions. We performed extensive experiments by designing\nnumerous different types of nonlinear systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Park", "Se Un", ""]]}, {"id": "2001.09046", "submitter": "Bart Smets", "authors": "Bart Smets, Jim Portegies, Erik Bekkers, Remco Duits", "title": "PDE-based Group Equivariant Convolutional Neural Networks", "comments": "27 pages, 18 figures. v2 changes: - mentioned KerCNNs - added section\n  Generalization of G-CNNs - clarification that the experiments utilized\n  automatic differentiation and SGD. v3 changes: - streamlined theoretical\n  framework - formulation and proof Thm.1 & 2 - expanded experiments. v4\n  changes: typos in Prop.5 and (20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a PDE-based framework that generalizes Group equivariant\nConvolutional Neural Networks (G-CNNs). In this framework, a network layer is\nseen as a set of PDE-solvers where geometrically meaningful PDE-coefficients\nbecome the layer's trainable weights. Formulating our PDEs on homogeneous\nspaces allows these networks to be designed with built-in symmetries such as\nrotation in addition to the standard translation equivariance of CNNs.\n  Having all the desired symmetries included in the design obviates the need to\ninclude them by means of costly techniques such as data augmentation. We will\ndiscuss our PDE-based G-CNNs (PDE-G-CNNs) in a general homogeneous space\nsetting while also going into the specifics of our primary case of interest:\nroto-translation equivariance.\n  We solve the PDE of interest by a combination of linear group convolutions\nand non-linear morphological group convolutions with analytic kernel\napproximations that we underpin with formal theorems. Our kernel approximations\nallow for fast GPU-implementation of the PDE-solvers, we release our\nimplementation with this article. Just like for linear convolution a\nmorphological convolution is specified by a kernel that we train in our\nPDE-G-CNNs. In PDE-G-CNNs we do not use non-linearities such as max/min-pooling\nand ReLUs as they are already subsumed by morphological convolutions.\n  We present a set of experiments to demonstrate the strength of the proposed\nPDE-G-CNNs in increasing the performance of deep learning based imaging\napplications with far fewer parameters than traditional CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:00:46 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 14:16:16 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 07:56:22 GMT"}, {"version": "v4", "created": "Sat, 24 Jul 2021 11:14:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Smets", "Bart", ""], ["Portegies", "Jim", ""], ["Bekkers", "Erik", ""], ["Duits", "Remco", ""]]}, {"id": "2001.09055", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu, Sotirios V. Archontoulis", "title": "Forecasting Corn Yield with Machine Learning Ensembles", "comments": null, "journal-ref": "Frontiers in Plant Science 11 (2020) 1120", "doi": "10.3389/fpls.2020.01120", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerge of new technologies to synthesize and analyze big data with\nhigh-performance computing, has increased our capacity to more accurately\npredict crop yields. Recent research has shown that Machine learning (ML) can\nprovide reasonable predictions, faster, and with higher flexibility compared to\nsimulation crop modeling. The earlier the prediction during the growing season\nthe better, but this has not been thoroughly investigated as previous studies\nconsidered all data available to predict yields. This paper provides a machine\nlearning based framework to forecast corn yields in three US Corn Belt states\n(Illinois, Indiana, and Iowa) considering complete and partial in-season\nweather knowledge. Several ensemble models are designed using blocked\nsequential procedure to generate out-of-bag predictions. The forecasts are made\nin county-level scale and aggregated for agricultural district, and state level\nscales. Results show that ensemble models based on weighted average of the base\nlearners outperform individual models. Specifically, the proposed ensemble\nmodel could achieve best prediction accuracy (RRMSE of 7.8%) and least mean\nbias error (-6.06 bu/acre) compared to other developed models. Comparing our\nproposed model forecasts with the literature demonstrates the superiority of\nforecasts made by our proposed ensemble model. Results from the scenario of\nhaving partial in-season weather knowledge reveal that decent yield forecasts\ncan be made as early as June 1st. To find the marginal effect of each input\nfeature on the forecasts made by the proposed ensemble model, a methodology is\nsuggested that is the basis for finding feature importance for the ensemble\nmodel. The findings suggest that weather features corresponding to weather in\nweeks 18-24 (May 1st to June 1st) are the most important input features.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 03:55:20 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 18:20:59 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "2001.09061", "submitter": "Jonas Teuwen", "authors": "Nikita Moriakov, Jonas Adler, Jonas Teuwen", "title": "Kernel of CycleGAN as a Principle homogeneous space", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unpaired image-to-image translation has attracted significant interest due to\nthe invention of CycleGAN, a method which utilizes a combination of adversarial\nand cycle consistency losses to avoid the need for paired data. It is known\nthat the CycleGAN problem might admit multiple solutions, and our goal in this\npaper is to analyze the space of exact solutions and to give perturbation\nbounds for approximate solutions. We show theoretically that the exact solution\nspace is invariant with respect to automorphisms of the underlying probability\nspaces, and, furthermore, that the group of automorphisms acts freely and\ntransitively on the space of exact solutions. We examine the case of zero\n`pure' CycleGAN loss first in its generality, and, subsequently, expand our\nanalysis to approximate solutions for `extended' CycleGAN loss where identity\nloss term is included. In order to demonstrate that these results are\napplicable, we show that under mild conditions nontrivial smooth automorphisms\nexist. Furthermore, we provide empirical evidence that neural networks can\nlearn these automorphisms with unexpected and unwanted results. We conclude\nthat finding optimal solutions to the CycleGAN loss does not necessarily lead\nto the envisioned result in image-to-image translation tasks and that\nunderlying hidden symmetries can render the result utterly useless.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:47:12 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Moriakov", "Nikita", ""], ["Adler", "Jonas", ""], ["Teuwen", "Jonas", ""]]}, {"id": "2001.09063", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden", "title": "Towards Graph Representation Learning in Emergent Communication", "comments": "The first two authors contributed equally. Accepted at the\n  Reinforcement Learning in Games workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent findings in neuroscience suggest that the human brain represents\ninformation in a geometric structure (for instance, through conceptual spaces).\nIn order to communicate, we flatten the complex representation of entities and\ntheir attributes into a single word or a sentence. In this paper we use graph\nconvolutional networks to support the evolution of language and cooperation in\nmulti-agent systems. Motivated by an image-based referential game, we propose a\ngraph referential game with varying degrees of complexity, and we provide\nstrong baseline models that exhibit desirable properties in terms of language\nemergence and cooperation. We show that the emerged communication protocol is\nrobust, that the agents uncover the true factors of variation in the game, and\nthat they learn to generalize beyond the samples encountered during training.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 15:55:59 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 14:18:31 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""]]}, {"id": "2001.09067", "submitter": "Matthias Hullin", "authors": "Javier Grau Chopite, Matthias B. Hullin, Michael Wand and Julian\n  Iseringhausen", "title": "Deep Non-Line-of-Sight Reconstruction", "comments": "Minor editorial update (typos, figure captions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent years have seen a surge of interest in methods for imaging beyond\nthe direct line of sight. The most prominent techniques rely on time-resolved\noptical impulse responses, obtained by illuminating a diffuse wall with an\nultrashort light pulse and observing multi-bounce indirect reflections with an\nultrafast time-resolved imager. Reconstruction of geometry from such data,\nhowever, is a complex non-linear inverse problem that comes with substantial\ncomputational demands. In this paper, we employ convolutional feed-forward\nnetworks for solving the reconstruction problem efficiently while maintaining\ngood reconstruction quality. Specifically, we devise a tailored autoencoder\narchitecture, trained end-to-end, that maps transient images directly to a\ndepth map representation. Training is done using an efficient transient\nrenderer for diffuse three-bounce indirect light transport that enables the\nquick generation of large amounts of training data for the network. We examine\nthe performance of our method on a variety of synthetic and experimental\ndatasets and its dependency on the choice of training data and augmentation\nstrategies, as well as architectural features. We demonstrate that our\nfeed-forward network, even though it is trained solely on synthetic data,\ngeneralizes to measured data from SPAD sensors and is able to obtain results\nthat are competitive with model-based reconstruction methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 16:05:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 12:42:53 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chopite", "Javier Grau", ""], ["Hullin", "Matthias B.", ""], ["Wand", "Michael", ""], ["Iseringhausen", "Julian", ""]]}, {"id": "2001.09122", "submitter": "Lydia Zakynthinou", "authors": "Thomas Steinke and Lydia Zakynthinou", "title": "Reasoning About Generalization via Conditional Mutual Information", "comments": "58 pages. Changes from previous version: Added discussion on related\n  work and updated references. Simplified part of the proof of Theorem 4.10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an information-theoretic framework for studying the generalization\nproperties of machine learning algorithms. Our framework ties together existing\napproaches, including uniform convergence bounds and recent methods for\nadaptive data analysis. Specifically, we use Conditional Mutual Information\n(CMI) to quantify how well the input (i.e., the training data) can be\nrecognized given the output (i.e., the trained model) of the learning\nalgorithm. We show that bounds on CMI can be obtained from VC dimension,\ncompression schemes, differential privacy, and other methods. We then show that\nbounded CMI implies various forms of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:13:04 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 05:48:00 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 00:42:03 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Steinke", "Thomas", ""], ["Zakynthinou", "Lydia", ""]]}, {"id": "2001.09127", "submitter": "Oliver Kirsebom", "authors": "Oliver S. Kirsebom, Fabio Frazao, Yvan Simard, Nathalie Roy, Stan\n  Matwin, Samuel Giard", "title": "Performance of a Deep Neural Network at Detecting North Atlantic Right\n  Whale Upcalls", "comments": "11 pages, 9 figures, 2 tables, submitted to JASA on Dec 22, 2019, as\n  part of a special issue on The Effects of Noise on Aquatic Life; resubmitted\n  on Feb 29, 2020, upon minor revisions and improved SNR estimates", "journal-ref": null, "doi": "10.1121/10.0001132", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Passive acoustics provides a powerful tool for monitoring the endangered\nNorth Atlantic right whale ($Eubalaena$ $glacialis$), but robust detection\nalgorithms are needed to handle diverse and variable acoustic conditions and\ndifferences in recording techniques and equipment. Here, we investigate the\npotential of deep neural networks for addressing this need. ResNet, an\narchitecture commonly used for image recognition, is trained to recognize the\ntime-frequency representation of the characteristic North Atlantic right whale\nupcall. The network is trained on several thousand examples recorded at various\nlocations in the Gulf of St.\\ Lawrence in 2018 and 2019, using different\nequipment and deployment techniques. Used as a detection algorithm on fifty\n30-minute recordings from the years 2015-2017 containing over one thousand\nupcalls, the network achieves recalls up to 80%, while maintaining a precision\nof 90%. Importantly, the performance of the network improves as more variance\nis introduced into the training dataset, whereas the opposite trend is observed\nusing a conventional linear discriminant analysis approach. Our work\ndemonstrates that deep neural networks can be trained to identify North\nAtlantic right whale upcalls under diverse and variable conditions with a\nperformance that compares favorably to that of existing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:22:27 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 20:39:30 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kirsebom", "Oliver S.", ""], ["Frazao", "Fabio", ""], ["Simard", "Yvan", ""], ["Roy", "Nathalie", ""], ["Matwin", "Stan", ""], ["Giard", "Samuel", ""]]}, {"id": "2001.09128", "submitter": "Yang Chen", "authors": "Yang Chen, Weiran Wang, Chao Wang", "title": "Semi-supervised ASR by End-to-end Self-training", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning based end-to-end automatic speech recognition (ASR)\nsystems have greatly simplified modeling pipelines, they suffer from the data\nsparsity issue. In this work, we propose a self-training method with an\nend-to-end system for semi-supervised ASR. Starting from a Connectionist\nTemporal Classification (CTC) system trained on the supervised data, we\niteratively generate pseudo-labels on a mini-batch of unsupervised utterances\nwith the current model, and use the pseudo-labels to augment the supervised\ndata for immediate model update. Our method retains the simplicity of\nend-to-end ASR systems, and can be seen as performing alternating optimization\nover a well-defined learning objective. We also perform empirical\ninvestigations of our method, regarding the effect of data augmentation,\ndecoding beamsize for pseudo-label generation, and freshness of pseudo-labels.\nOn a commonly used semi-supervised ASR setting with the WSJ corpus, our method\ngives 14.4% relative WER improvement over a carefully-trained base system with\ndata augmentation, reducing the performance gap between the base system and the\noracle system by 50%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:22:57 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 14:48:51 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Chen", "Yang", ""], ["Wang", "Weiran", ""], ["Wang", "Chao", ""]]}, {"id": "2001.09136", "submitter": "Adam Byerly", "authors": "Adam Byerly, Tatiana Kalganova, Ian Dear", "title": "No Routing Needed Between Capsules", "comments": "13 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most capsule network designs rely on traditional matrix multiplication\nbetween capsule layers and computationally expensive routing mechanisms to deal\nwith the capsule dimensional entanglement that the matrix multiplication\nintroduces. By using Homogeneous Vector Capsules (HVCs), which use element-wise\nmultiplication rather than matrix multiplication, the dimensions of the\ncapsules remain unentangled. In this work, we study HVCs as applied to the\nhighly structured MNIST dataset in order to produce a direct comparison to the\ncapsule research direction of Geoffrey Hinton, et al. In our study, we show\nthat a simple convolutional neural network using HVCs performs as well as the\nprior best performing capsule network on MNIST using 5.5x fewer parameters, 4x\nfewer training epochs, no reconstruction sub-network, and requiring no routing\nmechanism. The addition of multiple classification branches to the network\nestablishes a new state of the art for the MNIST dataset with an accuracy of\n99.87% for an ensemble of these models, as well as establishing a new state of\nthe art for a single model (99.83% accurate).\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 18:37:41 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 17:04:40 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 15:47:01 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 15:55:18 GMT"}, {"version": "v5", "created": "Wed, 27 Jan 2021 01:44:46 GMT"}, {"version": "v6", "created": "Thu, 17 Jun 2021 20:14:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Byerly", "Adam", ""], ["Kalganova", "Tatiana", ""], ["Dear", "Ian", ""]]}, {"id": "2001.09181", "submitter": "Ziran Wang", "authors": "Zhensong Wei, Yu Jiang, Xishun Liao, Xuewei Qi, Ziran Wang, Guoyuan\n  Wu, Peng Hao, Matthew Barth", "title": "End-to-End Vision-Based Adaptive Cruise Control (ACC) Using Deep\n  Reinforcement Learning", "comments": "This manuscript was presented at 99th Transportation Research Board\n  Annual Meeting in Washington D.C., Jan 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presented a deep reinforcement learning method named Double Deep\nQ-networks to design an end-to-end vision-based adaptive cruise control (ACC)\nsystem. A simulation environment of a highway scene was set up in Unity, which\nis a game engine that provided both physical models of vehicles and feature\ndata for training and testing. Well-designed reward functions associated with\nthe following distance and throttle/brake force were implemented in the\nreinforcement learning model for both internal combustion engine (ICE) vehicles\nand electric vehicles (EV) to perform adaptive cruise control. The gap\nstatistics and total energy consumption are evaluated for different vehicle\ntypes to explore the relationship between reward functions and powertrain\ncharacteristics. Compared with the traditional radar-based ACC systems or\nhuman-in-the-loop simulation, the proposed vision-based ACC system can generate\neither a better gap regulated trajectory or a smoother speed trajectory\ndepending on the preset reward function. The proposed system can be well\nadaptive to different speed trajectories of the preceding vehicle and operated\nin real-time.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 20:02:50 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Wei", "Zhensong", ""], ["Jiang", "Yu", ""], ["Liao", "Xishun", ""], ["Qi", "Xuewei", ""], ["Wang", "Ziran", ""], ["Wu", "Guoyuan", ""], ["Hao", "Peng", ""], ["Barth", "Matthew", ""]]}, {"id": "2001.09187", "submitter": "Jonas Latz", "authors": "Daniel Kressner, Jonas Latz, Stefano Massei, Elisabeth Ullmann", "title": "Certified and fast computations with shallow covariance kernels", "comments": null, "journal-ref": "Foundations of Data Science 2(4): 487-512, 2020", "doi": "10.3934/fods.2020022", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many techniques for data science and uncertainty quantification demand\nefficient tools to handle Gaussian random fields, which are defined in terms of\ntheir mean functions and covariance operators. Recently, parameterized Gaussian\nrandom fields have gained increased attention, due to their higher degree of\nflexibility. However, especially if the random field is parameterized through\nits covariance operator, classical random field discretization techniques fail\nor become inefficient. In this work we introduce and analyze a new and\ncertified algorithm for the low-rank approximation of a parameterized family of\ncovariance operators which represents an extension of the adaptive cross\napproximation method for symmetric positive definite matrices. The algorithm\nrelies on an affine linear expansion of the covariance operator with respect to\nthe parameters, which needs to be computed in a preprocessing step using, e.g.,\nthe empirical interpolation method. We discuss and test our new approach for\nisotropic covariance kernels, such as Mat\\'ern kernels. The numerical results\ndemonstrate the advantages of our approach in terms of computational time and\nconfirm that the proposed algorithm provides the basis of a fast sampling\nprocedure for parameter dependent Gaussian random fields.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 20:28:05 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 10:01:10 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 11:16:20 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 18:48:41 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kressner", "Daniel", ""], ["Latz", "Jonas", ""], ["Massei", "Stefano", ""], ["Ullmann", "Elisabeth", ""]]}, {"id": "2001.09201", "submitter": "Austin Wright", "authors": "Austin P. Wright, Herbert Wiklicky", "title": "Comparison of Syntactic and Semantic Representations of Programs in\n  Neural Embeddings", "comments": "54 Pages, Imperial College London Masters Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches to program synthesis and understanding have proliferated\nwidely in the last few years; at the same time graph based neural networks have\nbecome a promising new tool. This work aims to be the first empirical study\ncomparing the effectiveness of natural language models and static analysis\ngraph based models in representing programs in deep learning systems. It\ncompares graph convolutional networks using different graph representations in\nthe task of program embedding. It shows that the sparsity of control flow\ngraphs and the implicit aggregation of graph convolutional networks cause these\nmodels to perform worse than naive models. Therefore it concludes that simply\naugmenting purely linguistic or statistical models with formal information does\nnot perform well due to the nuanced nature of formal properties introducing\nmore noise than structure for graph convolutional networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:30:03 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Wright", "Austin P.", ""], ["Wiklicky", "Herbert", ""]]}, {"id": "2001.09203", "submitter": "Erez Yahalomi", "authors": "Erez Yahalomi", "title": "Modular network for high accuracy object detection", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel modular object detection convolutional neural network that\nsignificantly improves the accuracy of object detection. The network consists\nof two stages in a hierarchical structure. The first stage is a network that\ndetects general classes. The second stage consists of separate networks to\nrefine the classification and localization of each of the general classes\nobjects. Compared to a state of the art object detection networks the\nclassification error in the modular network is improved by approximately 3-5\ntimes, from 12% to 2.5 %-4.5%. This network is easy to implement and has a 0.94\nmAP. The network architecture can be a platform to improve the accuracy of\nwidespread state of the art object detection networks and other kinds of deep\nlearning networks. We show that a deep learning network initialized by transfer\nlearning becomes more accurate as the number of classes it later trained to\ndetect becomes smaller.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:38:22 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 15:50:45 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 19:03:31 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yahalomi", "Erez", ""]]}, {"id": "2001.09209", "submitter": "Mahdi Bohlouli", "authors": "Rasoul Kiani, Amin Keshavarzi, and Mahdi Bohlouli", "title": "Detection of Thin Boundaries between Different Types of Anomalies in\n  Outlier Detection using Enhanced Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection has received special attention in various fields, mainly\nfor those dealing with machine learning and artificial intelligence. As strong\noutliers, anomalies are divided into the point, contextual and collective\noutliers. The most important challenges in outlier detection include the thin\nboundary between the remote points and natural area, the tendency of new data\nand noise to mimic the real data, unlabelled datasets and different definitions\nfor outliers in different applications. Considering the stated challenges, we\ndefined new types of anomalies called Collective Normal Anomaly and Collective\nPoint Anomaly in order to improve a much better detection of the thin boundary\nbetween different types of anomalies. Basic domain-independent methods are\nintroduced to detect these defined anomalies in both unsupervised and\nsupervised datasets. The Multi-Layer Perceptron Neural Network is enhanced\nusing the Genetic Algorithm to detect newly defined anomalies with higher\nprecision so as to ensure a test error less than that calculated for the\nconventional Multi-Layer Perceptron Neural Network. Experimental results on\nbenchmark datasets indicated reduced error of anomaly detection process in\ncomparison to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:52:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kiani", "Rasoul", ""], ["Keshavarzi", "Amin", ""], ["Bohlouli", "Mahdi", ""]]}, {"id": "2001.09212", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Philip Bontrager, Sam Earle and Julian Togelius", "title": "PCGRL: Procedural Content Generation via Reinforcement Learning", "comments": "7 pages, 7 figures, 1 table, published at AIIDE2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how reinforcement learning can be used to train\nlevel-designing agents. This represents a new approach to procedural content\ngeneration in games, where level design is framed as a game, and the content\ngenerator itself is learned. By seeing the design problem as a sequential task,\nwe can use reinforcement learning to learn how to take the next action so that\nthe expected final level quality is maximized. This approach can be used when\nfew or no examples exist to train from, and the trained generator is very fast.\nWe investigate three different ways of transforming two-dimensional level\ndesign problems into Markov decision processes and apply these to three game\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:09:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:33:01 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 02:31:50 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Earle", "Sam", ""], ["Togelius", "Julian", ""]]}, {"id": "2001.09219", "submitter": "Q.Vera Liao", "authors": "Bhavya Ghai, Q. Vera Liao, Yunfeng Zhang, Rachel Bellamy, Klaus\n  Mueller", "title": "Explainable Active Learning (XAL): An Empirical Study of How Local\n  Explanations Impact Annotator Experience", "comments": "replacing with a draft accepted to CSCW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of Machine Learning technologies has created a rapidly\ngrowing demand for people who can train ML models. Some advocated the term\n\"machine teacher\" to refer to the role of people who inject domain knowledge\ninto ML models. One promising learning paradigm is Active Learning (AL), by\nwhich the model intelligently selects instances to query the machine teacher\nfor labels. However, in current AL settings, the human-AI interface remains\nminimal and opaque. We begin considering AI explanations as a core element of\nthe human-AI interface for teaching machines. When a human student learns, it\nis a common pattern to present one's own reasoning and solicit feedback from\nthe teacher. When a ML model learns and still makes mistakes, the human teacher\nshould be able to understand the reasoning underlying the mistakes. When the\nmodel matures, the machine teacher should be able to recognize its progress in\norder to trust and feel confident about their teaching outcome. Toward this\nvision, we propose a novel paradigm of explainable active learning (XAL), by\nintroducing techniques from the recently surging field of explainable AI (XAI)\ninto an AL setting. We conducted an empirical study comparing the model\nlearning outcomes, feedback content and experience with XAL, to that of\ntraditional AL and coactive learning (providing the model's prediction without\nthe explanation). Our study shows benefits of AI explanation as interfaces for\nmachine teaching--supporting trust calibration and enabling rich forms of\nteaching feedback, and potential drawbacks--anchoring effect with the model\njudgment and cognitive workload. Our study also reveals important individual\nfactors that mediate a machine teacher's reception to AI explanations,\nincluding task knowledge, AI experience and need for cognition. By reflecting\non the results, we suggest future directions and design implications for XAL.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:52:18 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 00:18:11 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 16:47:14 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 12:43:28 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ghai", "Bhavya", ""], ["Liao", "Q. Vera", ""], ["Zhang", "Yunfeng", ""], ["Bellamy", "Rachel", ""], ["Mueller", "Klaus", ""]]}, {"id": "2001.09221", "submitter": "Yang Chen", "authors": "Yang Chen, Weiran Wang, I-Fan Chen, Chao Wang", "title": "Data Techniques For Online End-to-end Speech Recognition", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners often need to build ASR systems for new use cases in a short\namount of time, given limited in-domain data. While recently developed\nend-to-end methods largely simplify the modeling pipelines, they still suffer\nfrom the data sparsity issue. In this work, we explore a few\nsimple-to-implement techniques for building online ASR systems in an end-to-end\nfashion, with a small amount of transcribed data in the target domain. These\ntechniques include data augmentation in the target domain, domain adaptation\nusing models previously trained on a large source domain, and knowledge\ndistillation on non-transcribed target domain data, using an adapted\nbi-directional model as the teacher; they are applicable in real scenarios with\ndifferent types of resources. Our experiments demonstrate that each technique\nis independently useful in the improvement of the online ASR performance in the\ntarget domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:59:46 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 22:58:12 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Chen", "Yang", ""], ["Wang", "Weiran", ""], ["Chen", "I-Fan", ""], ["Wang", "Chao", ""]]}, {"id": "2001.09223", "submitter": "Kezhi Wang", "authors": "Feibo Jiang, Kezhi Wang, Li Dong, Cunhua Pan, Kun Yang", "title": "Stacked Auto Encoder Based Deep Reinforcement Learning for Online\n  Resource Scheduling in Large-Scale MEC Networks", "comments": "Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online resource scheduling framework is proposed for minimizing the sum of\nweighted task latency for all the Internet of things (IoT) users, by optimizing\noffloading decision, transmission power and resource allocation in the\nlarge-scale mobile edge computing (MEC) system. Towards this end, a deep\nreinforcement learning (DRL) based solution is proposed, which includes the\nfollowing components. Firstly, a related and regularized stacked auto encoder\n(2r-SAE) with unsupervised learning is applied to perform data compression and\nrepresentation for high dimensional channel quality information (CQI) data,\nwhich can reduce the state space for DRL. Secondly, we present an adaptive\nsimulated annealing based approach (ASA) as the action search method of DRL, in\nwhich an adaptive h-mutation is used to guide the search direction and an\nadaptive iteration is proposed to enhance the search efficiency during the DRL\nprocess. Thirdly, a preserved and prioritized experience replay (2p-ER) is\nintroduced to assist the DRL to train the policy network and find the optimal\noffloading policy. Numerical results are provided to demonstrate that the\nproposed algorithm can achieve near-optimal performance while significantly\ndecreasing the computational time compared with existing benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:01:15 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 21:47:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Jiang", "Feibo", ""], ["Wang", "Kezhi", ""], ["Dong", "Li", ""], ["Pan", "Cunhua", ""], ["Yang", "Kun", ""]]}, {"id": "2001.09233", "submitter": "Kit Rodolfa", "authors": "Kit T. Rodolfa, Erika Salomon, Lauren Haynes, Ivan Higuera Mendieta,\n  Jamie Larson, Rayid Ghani", "title": "Case Study: Predictive Fairness to Reduce Misdemeanor Recidivism Through\n  Social Service Interventions", "comments": "12 pages, 4 figures, 1 algorithm. The definitive Version of Record\n  will be published in the proceedings of the Conference on Fairness,\n  Accountability, and Transparency (FAT* '20), January 27-30, 2020, Barcelona,\n  Spain", "journal-ref": null, "doi": "10.1145/3351095.3372863", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The criminal justice system is currently ill-equipped to improve outcomes of\nindividuals who cycle in and out of the system with a series of misdemeanor\noffenses. Often due to constraints of caseload and poor record linkage, prior\ninteractions with an individual may not be considered when an individual comes\nback into the system, let alone in a proactive manner through the application\nof diversion programs. The Los Angeles City Attorney's Office recently created\na new Recidivism Reduction and Drug Diversion unit (R2D2) tasked with reducing\nrecidivism in this population. Here we describe a collaboration with this new\nunit as a case study for the incorporation of predictive equity into machine\nlearning based decision making in a resource-constrained setting. The program\nseeks to improve outcomes by developing individually-tailored social service\ninterventions (i.e., diversions, conditional plea agreements, stayed\nsentencing, or other favorable case disposition based on appropriate social\nservice linkage rather than traditional sentencing methods) for individuals\nlikely to experience subsequent interactions with the criminal justice system,\na time and resource-intensive undertaking that necessitates an ability to focus\nresources on individuals most likely to be involved in a future case. Seeking\nto achieve both efficiency (through predictive accuracy) and equity (improving\noutcomes in traditionally under-served communities and working to mitigate\nexisting disparities in criminal justice outcomes), we discuss the equity\noutcomes we seek to achieve, describe the corresponding choice of a metric for\nmeasuring predictive fairness in this context, and explore a set of options for\nbalancing equity and efficiency when building and selecting machine learning\nmodels in an operational public policy setting.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:52:55 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rodolfa", "Kit T.", ""], ["Salomon", "Erika", ""], ["Haynes", "Lauren", ""], ["Mendieta", "Ivan Higuera", ""], ["Larson", "Jamie", ""], ["Ghani", "Rayid", ""]]}, {"id": "2001.09239", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski,\n  Joao Monteiro, Jan Trmal, Yoshua Bengio", "title": "Multi-task self-supervised learning for Robust Speech Recognition", "comments": "In Proc. of ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the growing interest in unsupervised learning, extracting meaningful\nknowledge from unlabelled audio remains an open challenge. To take a step in\nthis direction, we recently proposed a problem-agnostic speech encoder (PASE),\nthat combines a convolutional encoder followed by multiple neural networks,\ncalled workers, tasked to solve self-supervised problems (i.e., ones that do\nnot require manual annotations as ground truth). PASE was shown to capture\nrelevant speech information, including speaker voice-print and phonemes. This\npaper proposes PASE+, an improved version of PASE for robust speech recognition\nin noisy and reverberant environments. To this end, we employ an online speech\ndistortion module, that contaminates the input signals with a variety of random\ndisturbances. We then propose a revised encoder that better learns short- and\nlong-term speech dynamics with an efficient combination of recurrent and\nconvolutional networks. Finally, we refine the set of workers used in\nself-supervision to encourage better cooperation. Results on TIMIT, DIRHA and\nCHiME-5 show that PASE+ significantly outperforms both the previous version of\nPASE as well as common acoustic features. Interestingly, PASE+ learns\ntransferable representations suitable for highly mismatched acoustic\nconditions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 00:24:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 19:40:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Zhong", "Jianyuan", ""], ["Pascual", "Santiago", ""], ["Swietojanski", "Pawel", ""], ["Monteiro", "Joao", ""], ["Trmal", "Jan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.09244", "submitter": "Jincheng Du", "authors": "Andrei Lihu, Jincheng Du, Igor Barjaktarevic, Patrick Gerzanics and\n  Mark Harvilla", "title": "A Proof of Useful Work for Artificial Intelligence on the Blockchain", "comments": "24 pages, including 8 pages of supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin mining is a wasteful and resource-intensive process. To add a block\nof transactions to the blockchain, miners spend a considerable amount of\nenergy. The Bitcoin protocol, named 'proof of work' (PoW), resembles a lottery\nand the underlying computational work is not useful otherwise. In this paper,\nwe describe a novel 'proof of useful work' (PoUW) protocol based on training a\nmachine learning model on the blockchain. Miners get a chance to create new\ncoins after performing honest ML training work. Clients submit tasks and pay\nall training contributors. This is an extra incentive to participate in the\nnetwork because the system does not rely only on the lottery procedure. Using\nour consensus protocol, interested parties can order, complete, and verify\nuseful work in a distributed environment. We outline mechanisms to reward\nuseful work and punish malicious actors. We aim to build better AI systems\nusing the security of the blockchain.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:10:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Lihu", "Andrei", ""], ["Du", "Jincheng", ""], ["Barjaktarevic", "Igor", ""], ["Gerzanics", "Patrick", ""], ["Harvilla", "Mark", ""]]}, {"id": "2001.09245", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen, Ralph Abboud, Daniel Kroening", "title": "CounterExample Guided Neural Synthesis", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis is the generation of a program from a specification.\nCorrect synthesis is difficult, and methods that provide formal guarantees\nsuffer from scalability issues. On the other hand, neural networks are able to\ngenerate programs from examples quickly but are unable to guarantee that the\nprogram they output actually meets the logical specification. In this work we\ncombine neural networks with formal reasoning: using the latter to convert a\nlogical specification into a sequence of examples that guides the neural\nnetwork towards a correct solution, and to guarantee that any solution returned\nsatisfies the formal specification. We apply our technique to synthesising loop\ninvariants and compare the performance to existing solvers that use SMT and\nexisting techniques that use neural networks. Our results show that the formal\nreasoning based guidance improves the performance of the neural network\nsubstantially, nearly doubling the number of benchmarks it can solve.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:11:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Abboud", "Ralph", ""], ["Kroening", "Daniel", ""]]}, {"id": "2001.09249", "submitter": "Ahsan Ali Mr", "authors": "Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie\n  Baracaldo, Yi Zhou, Heiko Ludwig, Feng Yan, Yue Cheng", "title": "TiFL: A Tier-based Federated Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) enables learning a shared model across many clients\nwithout violating the privacy requirements. One of the key attributes in FL is\nthe heterogeneity that exists in both resource and data due to the differences\nin computation and communication capacity, as well as the quantity and content\nof data among different clients. We conduct a case study to show that\nheterogeneity in resource and data has a significant impact on training time\nand model accuracy in conventional FL systems. To this end, we propose TiFL, a\nTier-based Federated Learning System, which divides clients into tiers based on\ntheir training performance and selects clients from the same tier in each\ntraining round to mitigate the straggler problem caused by heterogeneity in\nresource and data quantity. To further tame the heterogeneity caused by non-IID\n(Independent and Identical Distribution) data and resources, TiFL employs an\nadaptive tier selection approach to update the tiering on-the-fly based on the\nobserved training performance and accuracy overtime. We prototype TiFL in a FL\ntestbed following Google's FL architecture and evaluate it using popular\nbenchmarks and the state-of-the-art FL benchmark LEAF. Experimental evaluation\nshows that TiFL outperforms the conventional FL in various heterogeneous\nconditions. With the proposed adaptive tier selection policy, we demonstrate\nthat TiFL achieves much faster training performance while keeping the same (and\nin some cases - better) test accuracy across the board.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:40:42 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chai", "Zheng", ""], ["Ali", "Ahsan", ""], ["Zawad", "Syed", ""], ["Truex", "Stacey", ""], ["Anwar", "Ali", ""], ["Baracaldo", "Nathalie", ""], ["Zhou", "Yi", ""], ["Ludwig", "Heiko", ""], ["Yan", "Feng", ""], ["Cheng", "Yue", ""]]}, {"id": "2001.09251", "submitter": "Vishnu Raj", "authors": "Vishnu Raj, Nancy Nayak and Sheetal Kalyani", "title": "Deep Reinforcement Learning based Blind mmWave MIMO Beam Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directional beamforming is a crucial component for realizing robust wireless\ncommunication systems using millimeter wave (mmWave) technology. Beam alignment\nusing brute-force search of the space introduces time overhead while location\naided blind beam alignment adds additional hardware requirements to the system.\nIn this paper, we introduce a method for blind beam alignment based on the RF\nfingerprints of user equipment obtained by the base stations. The proposed\nsystem performs blind beam alignment on a multiple base station cellular\nenvironment with multiple mobile users using deep reinforcement learning. We\npresent a novel neural network architecture that can handle a mix of both\ncontinuous and discrete actions and use policy gradient methods to train the\nmodel. Our results show that the proposed method can achieve a data rate of up\nto four times the traditional method without any overheads.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:47:06 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 14:02:45 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Raj", "Vishnu", ""], ["Nayak", "Nancy", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "2001.09254", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Karan Singh, Elad Hazan", "title": "Improper Learning for Non-Stochastic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of controlling a possibly unknown linear dynamical\nsystem with adversarial perturbations, adversarially chosen convex loss\nfunctions, and partially observed states, known as non-stochastic control. We\nintroduce a controller parametrization based on the denoised observations, and\nprove that applying online gradient descent to this parametrization yields a\nnew controller which attains sublinear regret vs. a large class of closed-loop\npolicies. In the fully-adversarial setting, our controller attains an optimal\nregret bound of $\\sqrt{T}$-when the system is known, and, when combined with an\ninitial stage of least-squares estimation, $T^{2/3}$ when the system is\nunknown; both yield the first sublinear regret for the partially observed\nsetting.\n  Our bounds are the first in the non-stochastic control setting that compete\nwith \\emph{all} stabilizing linear dynamical controllers, not just state\nfeedback. Moreover, in the presence of semi-adversarial noise containing both\nstochastic and adversarial components, our controller attains the optimal\nregret bounds of $\\mathrm{poly}(\\log T)$ when the system is known, and\n$\\sqrt{T}$ when unknown. To our knowledge, this gives the first end-to-end\n$\\sqrt{T}$ regret for online Linear Quadratic Gaussian controller, and applies\nin a more general setting with adversarial losses and semi-adversarial noise.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 02:12:48 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 03:03:45 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 23:48:03 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Simchowitz", "Max", ""], ["Singh", "Karan", ""], ["Hazan", "Elad", ""]]}, {"id": "2001.09277", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager, Henry D. Pfister, Rick M. B\\\"utler, Gabriele Liga,\n  Alex Alvarado", "title": "Model-Based Machine Learning for Joint Digital Backpropagation and PMD\n  Compensation", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-based machine-learning approach for\npolarization-multiplexed systems by parameterizing the split-step method for\nthe Manakov-PMD equation. This approach performs hardware-friendly DBP and\ndistributed PMD compensation with performance close to the PMD-free case.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:33:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""], ["B\u00fctler", "Rick M.", ""], ["Liga", "Gabriele", ""], ["Alvarado", "Alex", ""]]}, {"id": "2001.09292", "submitter": "Souvik Chakraborty", "authors": "Souvik Chakraborty and Sondipon Adhikari and Ranjan Ganguli", "title": "The role of surrogate models in the development of digital twins of\n  dynamic systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital twin technology has significant promise, relevance and potential of\nwidespread applicability in various industrial sectors such as aerospace,\ninfrastructure and automotive. However, the adoption of this technology has\nbeen slower due to the lack of clarity for specific applications. A discrete\ndamped dynamic system is used in this paper to explore the concept of a digital\ntwin. As digital twins are also expected to exploit data and computational\nmethods, there is a compelling case for the use of surrogate models in this\ncontext. Motivated by this synergy, we have explored the possibility of using\nsurrogate models within the digital twin technology. In particular, the use of\nGaussian process (GP) emulator within the digital twin technology is explored.\nGP has the inherent capability of addressing noise and sparse data and hence,\nmakes a compelling case to be used within the digital twin framework. Cases\ninvolving stiffness variation and mass variation are considered, individually\nand jointly along with different levels of noise and sparsity in data. Our\nnumerical simulation results clearly demonstrate that surrogate models such as\nGP emulators have the potential to be an effective tool for the development of\ndigital twins. Aspects related to data quality and sampling rate are analysed.\nKey concepts introduced in this paper are summarised and ideas for urgent\nfuture research needs are proposed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 10:48:35 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:44:50 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chakraborty", "Souvik", ""], ["Adhikari", "Sondipon", ""], ["Ganguli", "Ranjan", ""]]}, {"id": "2001.09309", "submitter": "Tsung-Han Wu", "authors": "Wei-Tsung Kao, Tsung-Han Wu, Po-Han Chi, Chun-Cheng Hsieh, Hung-Yi Lee", "title": "BERT's output layer recognizes all hidden layers? Some Intriguing\n  Phenomena and a simple way to boost BERT", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Bidirectional Encoder Representations from Transformers (BERT) have\nachieved tremendous success in many natural language processing (NLP) tasks, it\nremains a black box. A variety of previous works have tried to lift the veil of\nBERT and understand each layer's functionality. In this paper, we found that\nsurprisingly the output layer of BERT can reconstruct the input sentence by\ndirectly taking each layer of BERT as input, even though the output layer has\nnever seen the input other than the final hidden layer. This fact remains true\nacross a wide variety of BERT-based models, even when some layers are\nduplicated. Based on this observation, we propose a quite simple method to\nboost the performance of BERT. By duplicating some layers in the BERT-based\nmodels to make it deeper (no extra training required in this step), they obtain\nbetter performance in the downstream tasks after fine-tuning.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 13:35:34 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:54:30 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kao", "Wei-Tsung", ""], ["Wu", "Tsung-Han", ""], ["Chi", "Po-Han", ""], ["Hsieh", "Chun-Cheng", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "2001.09325", "submitter": "Nengli Lim", "authors": "Yueqin Li and Nengli Lim", "title": "Bayesian optimization for backpropagation in Monte-Carlo tree search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large domains, Monte-Carlo tree search (MCTS) is required to estimate the\nvalues of the states as efficiently and accurately as possible. However, the\nstandard update rule in backpropagation assumes a stationary distribution for\nthe returns, and particularly in min-max trees, convergence to the true value\ncan be slow because of averaging. We present two methods, Softmax MCTS and\nMonotone MCTS, which generalize previous attempts to improve upon the\nbackpropagation strategy. We demonstrate that both methods reduce to finding\noptimal monotone functions, which we do so by performing Bayesian optimization\nwith a Gaussian process (GP) prior. We conduct experiments on computer Go,\nwhere the returns are given by a deep value neural network, and show that our\nproposed framework outperforms previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:33:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Yueqin", ""], ["Lim", "Nengli", ""]]}, {"id": "2001.09326", "submitter": "Taras Kucherenko", "authors": "Taras Kucherenko, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter,\n  Simon Alexanderson, Iolanda Leite, Hedvig Kjellstr\\\"om", "title": "Gesticulator: A framework for semantically-aware speech-driven gesture\n  generation", "comments": "ICMI 2020 Best Paper Award. Code is available. 9 pages, 6 figures", "journal-ref": "Proceedings of the 2020 International Conference on Multimodal\n  Interaction (ICMI '20)", "doi": "10.1145/3382507.3418815", "report-no": null, "categories": "cs.HC cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During speech, people spontaneously gesticulate, which plays a key role in\nconveying information. Similarly, realistic co-speech gestures are crucial to\nenable natural and smooth interactions with social agents. Current end-to-end\nco-speech gesture generation systems use a single modality for representing\nspeech: either audio or text. These systems are therefore confined to producing\neither acoustically-linked beat gestures or semantically-linked gesticulation\n(e.g., raising a hand when saying \"high\"): they cannot appropriately learn to\ngenerate both gesture types. We present a model designed to produce arbitrary\nbeat and semantic gestures together. Our deep-learning based model takes both\nacoustic and semantic representations of speech as input, and generates\ngestures as a sequence of joint angle rotations as output. The resulting\ngestures can be applied to both virtual agents and humanoid robots. Subjective\nand objective evaluations confirm the success of our approach. The code and\nvideo are available at the project page\nhttps://svito-zar.github.io/gesticulator .\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:42:23 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:27:15 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 07:44:47 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 11:13:33 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 16:29:20 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Kucherenko", "Taras", ""], ["Jonell", "Patrik", ""], ["van Waveren", "Sanne", ""], ["Henter", "Gustav Eje", ""], ["Alexanderson", "Simon", ""], ["Leite", "Iolanda", ""], ["Kjellstr\u00f6m", "Hedvig", ""]]}, {"id": "2001.09327", "submitter": "Zexin Wang", "authors": "Zexin Wang, Vincent Y. F. Tan, Jonathan Scarlett", "title": "Tight Regret Bounds for Noisy Optimization of a Brownian Motion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Bayesian optimization of a one-dimensional\nBrownian motion in which the $T$ adaptively chosen observations are corrupted\nby Gaussian noise. We show that as the smallest possible expected simple regret\nand the smallest possible expected cumulative regret scale as $\\Omega(1 /\n\\sqrt{T \\log (T)}) \\cap \\mathcal{O}(\\log T / \\sqrt{T})$ and $\\Omega(\\sqrt{T /\n\\log (T)}) \\cap \\mathcal{O}(\\sqrt{T} \\cdot \\log T)$ respectively. Thus, our\nupper and lower bounds are tight up to a factor of $\\mathcal{O}( (\\log T)^{1.5}\n)$. The upper bound uses an algorithm based on confidence bounds and the Markov\nproperty of Brownian motion, and the lower bound is based on a reduction to\nbinary hypothesis testing.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:44:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Wang", "Zexin", ""], ["Tan", "Vincent Y. F.", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2001.09328", "submitter": "Zifeng Wang", "authors": "Zifeng Wang, Xi Chen, Rui Wen, Shao-Lun Huang", "title": "On the Fairness of Randomized Trials for Recommendation with\n  Heterogeneous Demographics and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observed events in recommendation are consequence of the decisions made by a\npolicy, thus they are usually selectively labeled, namely the data are Missing\nNot At Random (MNAR), which often causes large bias to the estimate of true\noutcomes risk. A general approach to correct MNAR bias is performing small\nRandomized Controlled Trials (RCTs), where an additional uniform policy is\nemployed to randomly assign items to each user. In this work, we concentrate on\nthe fairness of RCTs under both homogeneous and heterogeneous demographics,\nespecially analyzing the bias for the least favorable group on the latter\nsetting. Considering RCTs' limitations, we propose a novel Counterfactual\nRobust Risk Minimization (CRRM) framework, which is totally free of expensive\nRCTs, and derive its theoretical generalization error bound. At last, empirical\nexperiments are performed on synthetic tasks and real-world data sets,\nsubstantiating our method's superiority both in fairness and generalization.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 14:59:46 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:09:18 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wang", "Zifeng", ""], ["Chen", "Xi", ""], ["Wen", "Rui", ""], ["Huang", "Shao-Lun", ""]]}, {"id": "2001.09330", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri", "title": "Intent Classification in Question-Answering Using LSTM Architectures", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_11", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answering (QA) is certainly the best known and probably also one of\nthe most complex problem within Natural Language Processing (NLP) and\nartificial intelligence (AI). Since the complete solution to the problem of\nfinding a generic answer still seems far away, the wisest thing to do is to\nbreak down the problem by solving single simpler parts. Assuming a modular\napproach to the problem, we confine our research to intent classification for\nan answer, given a question. Through the use of an LSTM network, we show how\nthis type of classification can be approached effectively and efficiently, and\nhow it can be properly used within a basic prototype responder.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:07:07 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""]]}, {"id": "2001.09332", "submitter": "Amedeo Buonanno", "authors": "Giovanni Di Gennaro, Amedeo Buonanno, Antonio Di Girolamo, Armando\n  Ospedale, Francesco A.N. Palmieri, Gianfranco Fedele", "title": "An Analysis of Word2Vec for the Italian Language", "comments": "Presented at the 2019 Italian Workshop on Neural Networks (WIRN'19) -\n  June 2019", "journal-ref": "Progresses in Artificial Intelligence and Neural Systems. Smart\n  Innovation, Systems and Technologies, vol 184. Springer, Singapore - First\n  Online: July 2020", "doi": "10.1007/978-981-15-5093-5_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is fundamental in NLP tasks, because it is precisely from\nthe coding of semantic closeness between words that it is possible to think of\nteaching a machine to understand text. Despite the spread of word embedding\nconcepts, still few are the achievements in linguistic contexts other than\nEnglish. In this work, analysing the semantic capacity of the Word2Vec\nalgorithm, an embedding for the Italian language is produced. Parameter setting\nsuch as the number of epochs, the size of the context window and the number of\nnegatively backpropagated samples is explored.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:12:01 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Di Gennaro", "Giovanni", ""], ["Buonanno", "Amedeo", ""], ["Di Girolamo", "Antonio", ""], ["Ospedale", "Armando", ""], ["Palmieri", "Francesco A. N.", ""], ["Fedele", "Gianfranco", ""]]}, {"id": "2001.09335", "submitter": "Mattia Lecci", "authors": "Mattia Lecci, Paolo Testolina, Mattia Rebato, Alberto Testolin,\n  Michele Zorzi", "title": "Machine Learning-aided Design of Thinned Antenna Arrays for Optimized\n  Network Level Performance", "comments": "5 pages, 7 figures. This paper has been presented at EuCAP 2020.\n  Copyright IEEE 2020. Please cite it as: M. Lecci, P. Testolina, M. Rebato, A.\n  Testolin, and M. Zorzi, \"Machine Learning-aided Design of Thinned Antenna\n  Arrays for Optimized Network Level Performance,\" 14th European Conference on\n  Antennas and Propagation (EuCAP 2020), Copenhagen, Mar. 2020", "journal-ref": null, "doi": "10.23919/EuCAP48036.2020.9135310", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of millimeter wave (mmWave) communications, the combination\nof a detailed 5G network simulator with an accurate antenna radiation model is\nrequired to analyze the realistic performance of complex cellular scenarios.\nHowever, due to the complexity of both electromagnetic and network models, the\ndesign and optimization of antenna arrays is generally infeasible due to the\nrequired computational resources and simulation time. In this paper, we propose\na Machine Learning framework that enables a simulation-based optimization of\nthe antenna design. We show how learning methods are able to emulate a complex\nsimulator with a modest dataset obtained from it, enabling a global numerical\noptimization over a vast multi-dimensional parameter space in a reasonable\namount of time. Overall, our results show that the proposed methodology can be\nsuccessfully applied to the optimization of thinned antenna arrays.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:34:32 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:12:47 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Lecci", "Mattia", ""], ["Testolina", "Paolo", ""], ["Rebato", "Mattia", ""], ["Testolin", "Alberto", ""], ["Zorzi", "Michele", ""]]}, {"id": "2001.09336", "submitter": "Glen Chou", "authors": "Glen Chou, Necmiye Ozay, Dmitry Berenson", "title": "Learning Constraints from Locally-Optimal Demonstrations under Cost\n  Function Uncertainty", "comments": "Accepted to the IEEE Robotics and Automation Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for learning parametric constraints from\nlocally-optimal demonstrations, where the cost function being optimized is\nuncertain to the learner. Our method uses the Karush-Kuhn-Tucker (KKT)\noptimality conditions of the demonstrations within a mixed integer linear\nprogram (MILP) to learn constraints which are consistent with the local\noptimality of the demonstrations, by either using a known constraint\nparameterization or by incrementally growing a parameterization that is\nconsistent with the demonstrations. We provide theoretical guarantees on the\nconservativeness of the recovered safe/unsafe sets and analyze the limits of\nconstraint learnability when using locally-optimal demonstrations. We evaluate\nour method on high-dimensional constraints and systems by learning constraints\nfor 7-DOF arm and quadrotor examples, show that it outperforms competing\nconstraint-learning approaches, and can be effectively used to plan new\nconstraint-satisfying trajectories in the environment.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 15:57:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chou", "Glen", ""], ["Ozay", "Necmiye", ""], ["Berenson", "Dmitry", ""]]}, {"id": "2001.09346", "submitter": "Amirsina Torfi", "authors": "Amirsina Torfi, Edward A. Fox", "title": "CorGAN: Correlation-Capturing Convolutional Generative Adversarial\n  Networks for Generating Synthetic Healthcare Records", "comments": "Accepted to be published in the 33rd International FLAIRS Conference,\n  AI in Healthcare Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have demonstrated high-quality performance in areas such\nas image classification and speech processing. However, creating a deep\nlearning model using electronic health record (EHR) data, requires addressing\nparticular privacy challenges that are unique to researchers in this domain.\nThis matter focuses attention on generating realistic synthetic data while\nensuring privacy. In this paper, we propose a novel framework called\ncorrelation-capturing Generative Adversarial Network (CorGAN), to generate\nsynthetic healthcare records. In CorGAN we utilize Convolutional Neural\nNetworks to capture the correlations between adjacent medical features in the\ndata representation space by combining Convolutional Generative Adversarial\nNetworks and Convolutional Autoencoders. To demonstrate the model fidelity, we\nshow that CorGAN generates synthetic data with performance similar to that of\nreal data in various Machine Learning settings such as classification and\nprediction. We also give a privacy assessment and report on statistical\nanalysis regarding realistic characteristics of the synthetic data. The\nsoftware of this work is open-source and is available at:\nhttps://github.com/astorfi/cor-gan.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 18:43:47 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:22:37 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Torfi", "Amirsina", ""], ["Fox", "Edward A.", ""]]}, {"id": "2001.09360", "submitter": "Rishabh Iyer", "authors": "Rishabh Iyer", "title": "Robust Submodular Minimization with Applications to Cooperative Modeling", "comments": "To Appear in ECAI 2020. arXiv admin note: substantial text overlap\n  with arXiv:1906.06393", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Optimization is becoming increasingly important in machine learning\napplications. This paper studies the problem of robust submodular minimization\nsubject to combinatorial constraints. Constrained Submodular Minimization\narises in several applications such as co-operative cuts in image segmentation,\nco-operative matchings in image correspondence, etc. Many of these models are\ndefined over clusterings of data points (for example pixels in images), and it\nis important for these models to be robust to perturbations and uncertainty in\nthe data. While several existing papers have studied robust submodular\nmaximization, ours is the first work to study the minimization version under a\nbroad range of combinatorial constraints including cardinality, knapsack,\nmatroid as well as graph-based constraints such as cuts, paths, matchings, and\ntrees. In each case, we provide scalable approximation algorithms and also\nstudy hardness bounds. Finally, we empirically demonstrate the utility of our\nalgorithms on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 20:40:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Iyer", "Rishabh", ""]]}, {"id": "2001.09367", "submitter": "Andrew Roth", "authors": "Alexandre Bouchard-C\\^ot\\'e and Andrew Roth", "title": "Particle-Gibbs Sampling For Bayesian Feature Allocation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian feature allocation models are a popular tool for modelling data with\na combinatorial latent structure. Exact inference in these models is generally\nintractable and so practitioners typically apply Markov Chain Monte Carlo\n(MCMC) methods for posterior inference. The most widely used MCMC strategies\nrely on an element wise Gibbs update of the feature allocation matrix. These\nelement wise updates can be inefficient as features are typically strongly\ncorrelated. To overcome this problem we have developed a Gibbs sampler that can\nupdate an entire row of the feature allocation matrix in a single move.\nHowever, this sampler is impractical for models with a large number of features\nas the computational complexity scales exponentially in the number of features.\nWe develop a Particle Gibbs sampler that targets the same distribution as the\nrow wise Gibbs updates, but has computational complexity that only grows\nlinearly in the number of features. We compare the performance of our proposed\nmethods to the standard Gibbs sampler using synthetic data from a range of\nfeature allocation models. Our results suggest that row wise updates using the\nPG methodology can significantly improve the performance of samplers for\nfeature allocation models.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 22:11:51 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bouchard-C\u00f4t\u00e9", "Alexandre", ""], ["Roth", "Andrew", ""]]}, {"id": "2001.09373", "submitter": "John Kanu", "authors": "John Kanu, Eadom Dessalene, Xiaomin Lin, Cornelia Fermuller, Yiannis\n  Aloimonos", "title": "Following Instructions by Imagining and Reaching Visual Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditional methods for instruction-following typically assume prior\nlinguistic and perceptual knowledge, many recent works in reinforcement\nlearning (RL) have proposed learning policies end-to-end, typically by training\nneural networks to map joint representations of observations and instructions\ndirectly to actions. In this work, we present a novel framework for learning to\nperform temporally extended tasks using spatial reasoning in the RL framework,\nby sequentially imagining visual goals and choosing appropriate actions to\nfulfill imagined goals. Our framework operates on raw pixel images, assumes no\nprior linguistic or perceptual knowledge, and learns via intrinsic motivation\nand a single extrinsic reward signal measuring task completion. We validate our\nmethod in two environments with a robot arm in a simulated interactive 3D\nenvironment. Our method outperforms two flat architectures with raw-pixel and\nground-truth states, and a hierarchical architecture with ground-truth states\non object arrangement tasks.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 23:26:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Kanu", "John", ""], ["Dessalene", "Eadom", ""], ["Lin", "Xiaomin", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "2001.09377", "submitter": "Liyuan Zheng", "authors": "Liyuan Zheng, Lillian J. Ratliff", "title": "Constrained Upper Confidence Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained Markov Decision Processes are a class of stochastic decision\nproblems in which the decision maker must select a policy that satisfies\nauxiliary cost constraints. This paper extends upper confidence reinforcement\nlearning for settings in which the reward function and the constraints,\ndescribed by cost functions, are unknown a priori but the transition kernel is\nknown. Such a setting is well-motivated by a number of applications including\nexploration of unknown, potentially unsafe, environments. We present an\nalgorithm C-UCRL and show that it achieves sub-linear regret ($\nO(T^{\\frac{3}{4}}\\sqrt{\\log(T/\\delta)})$) with respect to the reward while\nsatisfying the constraints even while learning with probability $1-\\delta$.\nIllustrative examples are provided.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 00:23:02 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zheng", "Liyuan", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "2001.09382", "submitter": "Zhaocheng Zhu", "authors": "Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, Jian\n  Tang", "title": "GraphAF: a Flow-based Autoregressive Model for Molecular Graph\n  Generation", "comments": null, "journal-ref": "Published at ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular graph generation is a fundamental problem for drug discovery and\nhas been attracting growing attention. The problem is challenging since it\nrequires not only generating chemically valid molecular structures but also\noptimizing their chemical properties in the meantime. Inspired by the recent\nprogress in deep generative models, in this paper we propose a flow-based\nautoregressive model for graph generation called GraphAF. GraphAF combines the\nadvantages of both autoregressive and flow-based approaches and enjoys: (1)\nhigh model flexibility for data density estimation; (2) efficient parallel\ncomputation for training; (3) an iterative sampling process, which allows\nleveraging chemical domain knowledge for valency checking. Experimental results\nshow that GraphAF is able to generate 68% chemically valid molecules even\nwithout chemical knowledge rules and 100% valid molecules with chemical rules.\nThe training process of GraphAF is two times faster than the existing\nstate-of-the-art approach GCPN. After fine-tuning the model for goal-directed\nproperty optimization with reinforcement learning, GraphAF achieves\nstate-of-the-art performance on both chemical property optimization and\nconstrained property optimization.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 01:12:40 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:34:03 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shi", "Chence", ""], ["Xu", "Minkai", ""], ["Zhu", "Zhaocheng", ""], ["Zhang", "Weinan", ""], ["Zhang", "Ming", ""], ["Tang", "Jian", ""]]}, {"id": "2001.09384", "submitter": "Richard Nock", "authors": "Richard Nock and Wilko Henecka", "title": "Boosted and Differentially Private Ensembles of Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosted ensemble of decision tree (DT) classifiers are extremely popular in\ninternational competitions, yet to our knowledge nothing is formally known on\nhow to make them \\textit{also} differential private (DP), up to the point that\nrandom forests currently reign supreme in the DP stage. Our paper starts with\nthe proof that the privacy vs boosting picture for DT involves a notable and\ngeneral technical tradeoff: the sensitivity tends to increase with the boosting\nrate of the loss, for any proper loss. DT induction algorithms being\nfundamentally iterative, our finding implies non-trivial choices to select or\ntune the loss to balance noise against utility to split nodes. To address this,\nwe craft a new parametererized proper loss, called the M$\\alpha$-loss, which,\nas we show, allows to finely tune the tradeoff in the complete spectrum of\nsensitivity vs boosting guarantees. We then introduce \\textit{objective\ncalibration} as a method to adaptively tune the tradeoff during DT induction to\nlimit the privacy budget spent while formally being able to keep\nboosting-compliant convergence on limited-depth nodes with high probability.\nExtensive experiments on 19 UCI domains reveal that objective calibration is\nhighly competitive, even in the DP-free setting. Our approach tends to very\nsignificantly beat random forests, in particular on high DP regimes\n($\\varepsilon \\leq 0.1$) and even with boosted ensembles containing ten times\nless trees, which could be crucial to keep a key feature of DT models under\ndifferential privacy: interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 01:28:03 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 22:34:23 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Nock", "Richard", ""], ["Henecka", "Wilko", ""]]}, {"id": "2001.09388", "submitter": "Ning Yu", "authors": "Ning Yu, Zachary Tuttle, Carl Jake Thurnau, Emmanuel Mireku", "title": "AI-Powered GUI Attack and Its Defensive Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first Graphical User Interface (GUI) prototype was invented in the\n1970s, GUI systems have been deployed into various personal computer systems\nand server platforms. Recently, with the development of artificial intelligence\n(AI) technology, malicious malware powered by AI is emerging as a potential\nthreat to GUI systems. This type of AI-based cybersecurity attack, targeting at\nGUI systems, is explored in this paper. It is twofold: (1) A malware is\ndesigned to attack the existing GUI system by using AI-based object recognition\ntechniques. (2) Its defensive methods are discovered by generating adversarial\nexamples and other methods to alleviate the threats from the intelligent GUI\nattack. The results have shown that a generic GUI attack can be implemented and\nperformed in a simple way based on current AI techniques and its\ncountermeasures are temporary but effective to mitigate the threats of GUI\nattack so far.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:33:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yu", "Ning", ""], ["Tuttle", "Zachary", ""], ["Thurnau", "Carl Jake", ""], ["Mireku", "Emmanuel", ""]]}, {"id": "2001.09390", "submitter": "Ningyuan Chen", "authors": "Xiang Zhou, Yi Xiong, Ningyuan Chen, Xuefeng Gao", "title": "Regime Switching Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-armed bandit problem where the rewards exhibit regime\nswitching. Specifically, the distributions of the random rewards generated from\nall arms are modulated by a common underlying state modeled as a finite-state\nMarkov chain. The agent does not observe the underlying state and has to learn\nthe transition matrix and the reward distributions. We propose a learning\nalgorithm for this problem, building on spectral method-of-moments estimations\nfor hidden Markov models, belief error control in partially observable Markov\ndecision processes and upper-confidence-bound methods for online learning. We\nalso establish an upper bound $O(T^{2/3}\\sqrt{\\log T})$ for the proposed\nlearning algorithm where $T$ is the learning horizon. Finally, we conduct\nproof-of-concept experiments to illustrate the performance of the learning\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:50:56 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 15:13:46 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 16:35:36 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhou", "Xiang", ""], ["Xiong", "Yi", ""], ["Chen", "Ningyuan", ""], ["Gao", "Xuefeng", ""]]}, {"id": "2001.09394", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Pascal Van Hentenryck, Terrence WK Mak, Cuong\n  Tran, Federico Baldo, Michele Lombardi", "title": "Lagrangian Duality for Constrained Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the potential of Lagrangian duality for learning\napplications that feature complex constraints. Such constraints arise in many\nscience and engineering domains, where the task amounts to learning\noptimization problems which must be solved repeatedly and include hard physical\nand operational constraints. The paper also considers applications where the\nlearning task must enforce constraints on the predictor itself, either because\nthey are natural properties of the function to learn or because it is desirable\nfrom a societal standpoint to impose them. This paper demonstrates\nexperimentally that Lagrangian duality brings significant benefits for these\napplications. In energy domains, the combination of Lagrangian duality and deep\nlearning can be used to obtain state-of-the-art results to predict optimal\npower flows, in energy systems, and optimal compressor settings, in gas\nnetworks. In transprecision computing, Lagrangian duality can complement deep\nlearning to impose monotonicity constraints on the predictor without\nsacrificing accuracy. Finally, Lagrangian duality can be used to enforce\nfairness constraints on a predictor and obtain state-of-the-art results when\nminimizing disparate treatments.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 03:38:43 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:41:19 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Van Hentenryck", "Pascal", ""], ["Mak", "Terrence WK", ""], ["Tran", "Cuong", ""], ["Baldo", "Federico", ""], ["Lombardi", "Michele", ""]]}, {"id": "2001.09395", "submitter": "Shixia Liu", "authors": "Kelei Cao, Mengchen Liu, Hang Su, Jing Wu, Jun Zhu, Shixia Liu", "title": "Analyzing the Noise Robustness of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples, generated by adding small but intentionally\nimperceptible perturbations to normal examples, can mislead deep neural\nnetworks (DNNs) to make incorrect predictions. Although much work has been done\non both adversarial attack and defense, a fine-grained understanding of\nadversarial examples is still lacking. To address this issue, we present a\nvisual analysis method to explain why adversarial examples are misclassified.\nThe key is to compare and analyze the datapaths of both the adversarial and\nnormal examples. A datapath is a group of critical neurons along with their\nconnections. We formulate the datapath extraction as a subset selection problem\nand solve it by constructing and training a neural network. A multi-level\nvisualization consisting of a network-level visualization of data flows, a\nlayer-level visualization of feature maps, and a neuron-level visualization of\nlearned features, has been designed to help investigate how datapaths of\nadversarial and normal examples diverge and merge in the prediction process. A\nquantitative evaluation and a case study were conducted to demonstrate the\npromise of our method to explain the misclassification of adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 03:39:10 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Cao", "Kelei", ""], ["Liu", "Mengchen", ""], ["Su", "Hang", ""], ["Wu", "Jing", ""], ["Zhu", "Jun", ""], ["Liu", "Shixia", ""]]}, {"id": "2001.09396", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip\n  Schniter, Alyson K. Fletcher", "title": "Inference in Multi-Layer Networks with Matrix-Valued Unknowns", "comments": "3 figures, 6 pages (two-column) + Appendix. arXiv admin note: text\n  overlap with arXiv:1911.03409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the input and hidden variables of a\nstochastic multi-layer neural network from an observation of the output. The\nhidden variables in each layer are represented as matrices. This problem\napplies to signal recovery via deep generative prior models, multi-task and\nmixed regression and learning certain classes of two-layer neural networks. A\nunified approximation algorithm for both MAP and MMSE inference is proposed by\nextending a recently-developed Multi-Layer Vector Approximate Message Passing\n(ML-VAMP) algorithm to handle matrix-valued unknowns. It is shown that the\nperformance of the proposed Multi-Layer Matrix VAMP (ML-Mat-VAMP) algorithm can\nbe exactly predicted in a certain random large-system limit, where the\ndimensions $N\\times d$ of the unknown quantities grow as $N\\rightarrow\\infty$\nwith $d$ fixed. In the two-layer neural-network learning problem, this scaling\ncorresponds to the case where the number of input features and training samples\ngrow to infinity but the number of hidden nodes stays fixed. The analysis\nenables a precise prediction of the parameter and test error of the learning.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 04:00:24 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Schniter", "Philip", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "2001.09399", "submitter": "Suraj Padmanaban Kesavan", "authors": "Suraj P. Kesavan, Takanori Fujiwara, Jianping Kelvin Li, Caitlin Ross,\n  Misbah Mubarak, Christopher D. Carothers, Robert B. Ross, Kwan-Liu Ma", "title": "A Visual Analytics Framework for Reviewing Streaming Performance Data", "comments": "This is the author's preprint version that will be published in\n  Proceedings of IEEE Pacific Visualization Symposium, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.HC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and tuning the performance of extreme-scale parallel computing\nsystems demands a streaming approach due to the computational cost of applying\noffline algorithms to vast amounts of performance log data. Analyzing large\nstreaming data is challenging because the rate of receiving data and limited\ntime to comprehend data make it difficult for the analysts to sufficiently\nexamine the data without missing important changes or patterns. To support\nstreaming data analysis, we introduce a visual analytic framework comprising of\nthree modules: data management, analysis, and interactive visualization. The\ndata management module collects various computing and communication performance\nmetrics from the monitored system using streaming data processing techniques\nand feeds the data to the other two modules. The analysis module automatically\nidentifies important changes and patterns at the required latency. In\nparticular, we introduce a set of online and progressive analysis methods for\nnot only controlling the computational costs but also helping analysts better\nfollow the critical aspects of the analysis results. Finally, the interactive\nvisualization module provides the analysts with a coherent view of the changes\nand patterns in the continuously captured performance data. Through a\nmulti-faceted case study on performance analysis of parallel discrete-event\nsimulation, we demonstrate the effectiveness of our framework for identifying\nbottlenecks and locating outliers.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 04:34:22 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Kesavan", "Suraj P.", ""], ["Fujiwara", "Takanori", ""], ["Li", "Jianping Kelvin", ""], ["Ross", "Caitlin", ""], ["Mubarak", "Misbah", ""], ["Carothers", "Christopher D.", ""], ["Ross", "Robert B.", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2001.09419", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "LiteMORT: A memory efficient gradient boosting tree system on adaptive\n  compact distributions", "comments": "6 Pages,1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosted decision trees (GBDT) is the leading algorithm for many\ncommercial and academic data applications. We give a deep analysis of this\nalgorithm, especially the histogram technique, which is a basis for the\nregulized distribution with compact support. We present three new\nmodifications. 1) Share memory technique to reduce memory usage. In many cases,\nit only need the data source itself and no extra memory. 2) Implicit merging\nfor \"merge overflow problem\".\"merge overflow\" means that merge some small\ndatasets to huge datasets, which are too huge to be solved. By implicit\nmerging, we just need the original small datasets to train the GBDT model. 3)\nAdaptive resize algorithm of histogram bins to improve accuracy. Experiments on\ntwo large Kaggle competitions verified our methods. They use much less memory\nthan LightGBM and have higher accuracy. We have implemented these algorithms in\nan open-source package LiteMORT. The source codes are available at\nhttps://github.com/closest-git/LiteMORT\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 08:21:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2001.09464", "submitter": "Frank Emmert-Streib", "authors": "Frank Emmert-Streib, Olli Yli-Harja, and Matthias Dehmer", "title": "Explainable Artificial Intelligence and Machine Learning: A reality\n  rooted perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are used to the availability of big data generated in nearly all fields of\nscience as a consequence of technological progress. However, the analysis of\nsuch data possess vast challenges. One of these relates to the explainability\nof artificial intelligence (AI) or machine learning methods. Currently, many of\nsuch methods are non-transparent with respect to their working mechanism and\nfor this reason are called black box models, most notably deep learning\nmethods. However, it has been realized that this constitutes severe problems\nfor a number of fields including the health sciences and criminal justice and\narguments have been brought forward in favor of an explainable AI. In this\npaper, we do not assume the usual perspective presenting explainable AI as it\nshould be, but rather we provide a discussion what explainable AI can be. The\ndifference is that we do not present wishful thinking but reality grounded\nproperties in relation to a scientific theory beyond physics.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:09:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Emmert-Streib", "Frank", ""], ["Yli-Harja", "Olli", ""], ["Dehmer", "Matthias", ""]]}, {"id": "2001.09467", "submitter": "Harish Kumaar Venkataraman", "authors": "Harish Venkataraman, Derya Aksaray, Peter Seiler", "title": "Tractable Reinforcement Learning of Signal Temporal Logic Objectives", "comments": "Github code repository:\n  https://github.com/kumaa001/Tractable_RL_for_STL_Objectives. arXiv admin\n  note: text overlap with arXiv:1609.07409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal temporal logic (STL) is an expressive language to specify time-bound\nreal-world robotic tasks and safety specifications. Recently, there has been an\ninterest in learning optimal policies to satisfy STL specifications via\nreinforcement learning (RL). Learning to satisfy STL specifications often needs\na sufficient length of state history to compute reward and the next action. The\nneed for history results in exponential state-space growth for the learning\nproblem. Thus the learning problem becomes computationally intractable for most\nreal-world applications. In this paper, we propose a compact means to capture\nstate history in a new augmented state-space representation. An approximation\nto the objective (maximizing probability of satisfaction) is proposed and\nsolved for in the new augmented state-space. We show the performance bound of\nthe approximate solution and compare it with the solution of an existing\ntechnique via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:23:54 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:17:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Venkataraman", "Harish", ""], ["Aksaray", "Derya", ""], ["Seiler", "Peter", ""]]}, {"id": "2001.09485", "submitter": "Zafeirios Fountas PhD", "authors": "Cong Bao, Zafeirios Fountas, Temitayo Olugbade, Nadia\n  Bianchi-Berthouze", "title": "Multimodal Data Fusion based on the Global Workspace Theory", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network architecture, named the Global Workspace\nNetwork (GWN), which addresses the challenge of dynamic and unspecified\nuncertainties in multimodal data fusion. Our GWN is a model of attention across\nmodalities and evolving through time, and is inspired by the well-established\nGlobal Workspace Theory from the field of cognitive science. The GWN achieved\naverage F1 score of 0.92 for discrimination between pain patients and healthy\nparticipants and average F1 score = 0.75 for further classification of three\npain levels for a patient, both based on the multimodal EmoPain dataset\ncaptured from people with chronic pain and healthy people performing different\ntypes of exercise movements in unconstrained settings. In these tasks, the GWN\nsignificantly outperforms the typical fusion approach of merging by\nconcatenation. We further provide extensive analysis of the behaviour of the\nGWN and its ability to address uncertainties (hidden noise) in multimodal data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 16:52:43 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 15:00:13 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bao", "Cong", ""], ["Fountas", "Zafeirios", ""], ["Olugbade", "Temitayo", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "2001.09486", "submitter": "Aly El Gamal", "authors": "Rehana Mahfuz, Rajeev Sahay, Aly El Gamal", "title": "Ensemble Noise Simulation to Handle Uncertainty about Gradient-based\n  Adversarial Attacks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based adversarial attacks on neural networks can be crafted in a\nvariety of ways by varying either how the attack algorithm relies on the\ngradient, the network architecture used for crafting the attack, or both. Most\nrecent work has focused on defending classifiers in a case where there is no\nuncertainty about the attacker's behavior (i.e., the attacker is expected to\ngenerate a specific attack using a specific network architecture). However, if\nthe attacker is not guaranteed to behave in a certain way, the literature lacks\nmethods in devising a strategic defense. We fill this gap by simulating the\nattacker's noisy perturbation using a variety of attack algorithms based on\ngradients of various classifiers. We perform our analysis using a\npre-processing Denoising Autoencoder (DAE) defense that is trained with the\nsimulated noise. We demonstrate significant improvements in post-attack\naccuracy, using our proposed ensemble-trained defense, compared to a situation\nwhere no effort is made to handle uncertainty.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 17:12:47 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Mahfuz", "Rehana", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2001.09502", "submitter": "Isel Grau", "authors": "Isel Grau, Dipankar Sengupta, Maria M. Garcia Lorenzo, Ann Nowe", "title": "An interpretable semi-supervised classifier using two different\n  strategies for amended self-labeling", "comments": "Accepted at Special Session on Advances on Explainable Artificial\n  Intelligence, IEEE International Conference on Fuzzy Systems (FUZZ-IEEE\n  2020), IEEE World Congress on Computational Intelligence (WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of some machine learning applications, obtaining data\ninstances is a relatively easy process but labeling them could become quite\nexpensive or tedious. Such scenarios lead to datasets with few labeled\ninstances and a larger number of unlabeled ones. Semi-supervised classification\ntechniques combine labeled and unlabeled data during the learning phase in\norder to increase the classifier's generalization capability. Regrettably, most\nsuccessful semi-supervised classifiers do not allow explaining their outcome,\nthus behaving like black boxes. However, there is an increasing number of\nproblem domains in which experts demand a clear understanding of the decision\nprocess. In this paper, we report on an extended experimental study presenting\nan interpretable self-labeling grey-box classifier that uses a black box to\nestimate the missing class labels and a white box to explain the final\npredictions. Two different approaches for amending the self-labeling process\nare explored: a first one based on the confidence of the black box and the\nlatter one based on measures from Rough Set Theory. The results of the extended\nexperimental study support the interpretability by means of transparency and\nsimplicity of our classifier, while attaining superior prediction rates when\ncompared with state-of-the-art self-labeling classifiers reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 19:37:41 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 12:00:06 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Grau", "Isel", ""], ["Sengupta", "Dipankar", ""], ["Lorenzo", "Maria M. Garcia", ""], ["Nowe", "Ann", ""]]}, {"id": "2001.09519", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Pascal Clark, Rob Haynes, Hywel Richards, John\n  Bridle", "title": "Multi-task Learning for Voice Trigger Detection", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain, 2020, pp. 7449-7453", "doi": "10.1109/ICASSP40776.2020.9053577", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design of a voice trigger detection system for smart\nspeakers. In this study, we address two major challenges. The first is that the\ndetectors are deployed in complex acoustic environments with external noise and\nloud playback by the device itself. Secondly, collecting training examples for\na specific keyword or trigger phrase is challenging resulting in a scarcity of\ntrigger phrase specific training data. We describe a two-stage cascaded\narchitecture where a low-power detector is always running and listening for the\ntrigger phrase. If a detection is made at this stage, the candidate audio\nsegment is re-scored by larger, more complex models to verify that the segment\ncontains the trigger phrase. In this study, we focus our attention on the\narchitecture and design of these second-pass detectors. We start by training a\ngeneral acoustic model that produces phonetic transcriptions given a large\nlabelled training dataset. Next, we collect a much smaller dataset of examples\nthat are challenging for the baseline system. We then use multi-task learning\nto train a model to simultaneously produce accurate phonetic transcriptions on\nthe larger dataset \\emph{and} discriminate between true and easily confusable\nexamples using the smaller dataset. Our results demonstrate that the proposed\nmodel reduces errors by half compared to the baseline in a range of challenging\ntest conditions \\emph{without} requiring extra parameters.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:13:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 09:05:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Clark", "Pascal", ""], ["Haynes", "Rob", ""], ["Richards", "Hywel", ""], ["Bridle", "John", ""]]}, {"id": "2001.09521", "submitter": "Pierre-Henri Conze", "authors": "Pierre-Henri Conze, Ali Emre Kavur, Emilie Cornec-Le Gall, Naciye\n  Sinem Gezer, Yannick Le Meur, M. Alper Selver and Fran\\c{c}ois Rousseau", "title": "Abdominal multi-organ segmentation with cascaded convolutional and\n  adversarial deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective : Abdominal anatomy segmentation is crucial for numerous\napplications from computer-assisted diagnosis to image-guided surgery. In this\ncontext, we address fully-automated multi-organ segmentation from abdominal CT\nand MR images using deep learning. Methods: The proposed model extends standard\nconditional generative adversarial networks. Additionally to the discriminator\nwhich enforces the model to create realistic organ delineations, it embeds\ncascaded partially pre-trained convolutional encoder-decoders as generator.\nEncoder fine-tuning from a large amount of non-medical images alleviates data\nscarcity limitations. The network is trained end-to-end to benefit from\nsimultaneous multi-level segmentation refinements using auto-context. Results :\nEmployed for healthy liver, kidneys and spleen segmentation, our pipeline\nprovides promising results by outperforming state-of-the-art encoder-decoder\nschemes. Followed for the Combined Healthy Abdominal Organ Segmentation (CHAOS)\nchallenge organized in conjunction with the IEEE International Symposium on\nBiomedical Imaging 2019, it gave us the first rank for three competition\ncategories: liver CT, liver MR and multi-organ MR segmentation. Conclusion :\nCombining cascaded convolutional and adversarial networks strengthens the\nability of deep learning pipelines to automatically delineate multiple\nabdominal organs, with good generalization capability. Significance : The\ncomprehensive evaluation provided suggests that better guidance could be\nachieved to help clinicians in abdominal image interpretation and clinical\ndecision making.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:28:04 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Conze", "Pierre-Henri", ""], ["Kavur", "Ali Emre", ""], ["Gall", "Emilie Cornec-Le", ""], ["Gezer", "Naciye Sinem", ""], ["Meur", "Yannick Le", ""], ["Selver", "M. Alper", ""], ["Rousseau", "Fran\u00e7ois", ""]]}, {"id": "2001.09523", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Sayantan Bhadra, Frank J. Brooks, Hua Li, Mark A.\n  Anastasio", "title": "Progressively-Growing AmbientGANs For Learning Stochastic Object Models\n  From Imaging Measurements", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective optimization of medical imaging systems requires full\ncharacterization of all sources of randomness in the measured data, which\nincludes the variability within the ensemble of objects to-be-imaged. This can\nbe accomplished by establishing a stochastic object model (SOM) that describes\nthe variability in the class of objects to-be-imaged. Generative adversarial\nnetworks (GANs) can be potentially useful to establish SOMs because they hold\ngreat promise to learn generative models that describe the variability within\nan ensemble of training data. However, because medical imaging systems record\nimaging measurements that are noisy and indirect representations of object\nproperties, GANs cannot be directly applied to establish stochastic models of\nobjects to-be-imaged. To address this issue, an augmented GAN architecture\nnamed AmbientGAN was developed to establish SOMs from noisy and indirect\nmeasurement data. However, because the adversarial training can be unstable,\nthe applicability of the AmbientGAN can be potentially limited. In this work,\nwe propose a novel training strategy---Progressive Growing of AmbientGANs\n(ProAGAN)---to stabilize the training of AmbientGANs for establishing SOMs from\nnoisy and indirect imaging measurements. An idealized magnetic resonance (MR)\nimaging system and clinical MR brain images are considered. The proposed\nmethodology is evaluated by comparing signal detection performance computed by\nuse of ProAGAN-generated synthetic images and images that depict the true\nobject properties.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:33:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhou", "Weimin", ""], ["Bhadra", "Sayantan", ""], ["Brooks", "Frank J.", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.09526", "submitter": "Weimin Zhou", "authors": "Weimin Zhou, Mark A. Anastasio", "title": "Markov-Chain Monte Carlo Approximation of the Ideal Observer using\n  Generative Adversarial Networks", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ideal Observer (IO) performance has been advocated when optimizing\nmedical imaging systems for signal detection tasks. However, analytical\ncomputation of the IO test statistic is generally intractable. To approximate\nthe IO test statistic, sampling-based methods that employ Markov-Chain Monte\nCarlo (MCMC) techniques have been developed. However, current applications of\nMCMC techniques have been limited to several object models such as a lumpy\nobject model and a binary texture model, and it remains unclear how MCMC\nmethods can be implemented with other more sophisticated object models. Deep\nlearning methods that employ generative adversarial networks (GANs) hold great\npromise to learn stochastic object models (SOMs) from image data. In this\nstudy, we described a method to approximate the IO by applying MCMC techniques\nto SOMs learned by use of GANs. The proposed method can be employed with\narbitrary object models that can be learned by use of GANs, thereby the domain\nof applicability of MCMC techniques for approximating the IO performance is\nextended. In this study, both signal-known-exactly (SKE) and\nsignal-known-statistically (SKS) binary signal detection tasks are considered.\nThe IO performance computed by the proposed method is compared to that computed\nby the conventional MCMC method. The advantages of the proposed method are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:51:08 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Zhou", "Weimin", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.09528", "submitter": "Alberto Olmo", "authors": "Niharika Jain, Alberto Olmo, Sailik Sengupta, Lydia Manikonda,\n  Subbarao Kambhampati", "title": "Imperfect ImaGANation: Implications of GANs Exacerbating Biases on\n  Facial Data Augmentation and Snapchat Selfie Lenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that popular Generative Adversarial Networks (GANs)\nexacerbate biases along the axes of gender and skin tone when given a skewed\ndistribution of face-shots. While practitioners celebrate synthetic data\ngeneration using GANs as an economical way to augment data for training\ndata-hungry machine learning models, it is unclear whether they recognize the\nperils of such techniques when applied to real world datasets biased along\nlatent dimensions. Specifically, we show that (1) traditional GANs further skew\nthe distribution of a dataset consisting of engineering faculty headshots,\ngenerating minority modes less often and of worse quality and (2)\nimage-to-image translation (conditional) GANs also exacerbate biases by\nlightening skin color of non-white faces and transforming female facial\nfeatures to be masculine when generating faces of engineering professors. Thus,\nour study is meant to serve as a cautionary tale.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:57:26 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 23:13:23 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 02:13:46 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jain", "Niharika", ""], ["Olmo", "Alberto", ""], ["Sengupta", "Sailik", ""], ["Manikonda", "Lydia", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2001.09532", "submitter": "Diego Marcondes", "authors": "Diego Marcondes, Adilson Simonis and Junior Barrera", "title": "Learning the Hypotheses Space from data: Learning Space and U-curve\n  Property", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension of the classical agnostic PAC learning model\nin which learning problems are modelled not only by a Hypothesis Space\n$\\mathcal{H}$, but also by a Learning Space $\\mathbb{L}(\\mathcal{H})$, which is\na cover of $\\mathcal{H}$, constrained by a VC-dimension property, that is a\nsuitable domain for Model Selection algorithms. Our main contribution is a data\ndriven general learning algorithm to perform regularized Model Selection on\n$\\mathbb{L}(\\mathcal{H})$. A remarkable, formally proved, consequence of this\napproach are conditions on $\\mathbb{L}(\\mathcal{H})$ and on the loss function\nthat lead to estimated out-of-sample error surfaces which are true U-curves on\n$\\mathbb{L}(\\mathcal{H})$ chains, enabling a more efficient search on\n$\\mathbb{L}(\\mathcal{H})$. To our knowledge, this is the first rigorous result\nasserting that a non exhaustive search of a family of candidate models can\nreturn an optimal solution. In this new framework, an U-curve optimization\nalgorithm becomes a natural component of Model Selection, hence of learning\nalgorithms. The abstract general framework proposed here may have important\nimplications on modern learning models and on areas such as Neural Architecture\nSearch.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 22:29:33 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 13:55:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Marcondes", "Diego", ""], ["Simonis", "Adilson", ""], ["Barrera", "Junior", ""]]}, {"id": "2001.09545", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 00:19:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2001.09547", "submitter": "Manie Tadayon", "authors": "Manie Tadayon, Yumi Iwashita", "title": "A clustering approach to time series forecasting using neural networks:\n  A comparative study on distance-based vs. feature-based clustering methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting has gained lots of attention recently; this is\nbecause many real-world phenomena can be modeled as time series. The massive\nvolume of data and recent advancements in the processing power of the computers\nenable researchers to develop more sophisticated machine learning algorithms\nsuch as neural networks to forecast the time series data. In this paper, we\npropose various neural network architectures to forecast the time series data\nusing the dynamic measurements; moreover, we introduce various architectures on\nhow to combine static and dynamic measurements for forecasting. We also\ninvestigate the importance of performing techniques such as anomaly detection\nand clustering on forecasting accuracy. Our results indicate that clustering\ncan improve the overall prediction time as well as improve the forecasting\nperformance of the neural network. Furthermore, we show that feature-based\nclustering can outperform the distance-based clustering in terms of speed and\nefficiency. Finally, our results indicate that adding more predictors to\nforecast the target variable will not necessarily improve the forecasting\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 00:31:37 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 09:44:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Tadayon", "Manie", ""], ["Iwashita", "Yumi", ""]]}, {"id": "2001.09551", "submitter": "Joseph Bakarji", "authors": "Joseph Bakarji", "title": "Machine Learning for a Music Glove Instrument", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A music glove instrument equipped with force sensitive, flex and IMU sensors\nis trained on an electric piano to learn note sequences based on a time series\nof sensor inputs. Once trained, the glove is used on any surface to generate\nthe sequence of notes most closely related to the hand motion. The data is\ncollected manually by a performer wearing the glove and playing on an electric\nkeyboard. The feature space is designed to account for the key hand motion,\nsuch as the thumb-under movement. Logistic regression along with bayesian\nbelief networks are used learn the transition probabilities from one note to\nanother. This work demonstrates a data-driven approach for digital musical\ninstruments in general.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 01:08:11 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bakarji", "Joseph", ""]]}, {"id": "2001.09569", "submitter": "Rohan Paleja", "authors": "Rohan Paleja, Matthew Gombolay", "title": "Heterogeneous Learning from Demonstration", "comments": null, "journal-ref": "2019 14th Human-Robot Interaction (HRI) Pioneers Workshop", "doi": "10.1109/HRI.2019.8673267", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of human-robot systems able to leverage the strengths of both\nhumans and their robotic counterparts has been greatly sought after because of\nthe foreseen, broad-ranging impact across industry and research. We believe the\ntrue potential of these systems cannot be reached unless the robot is able to\nact with a high level of autonomy, reducing the burden of manual tasking or\nteleoperation. To achieve this level of autonomy, robots must be able to work\nfluidly with its human partners, inferring their needs without explicit\ncommands. This inference requires the robot to be able to detect and classify\nthe heterogeneity of its partners. We propose a framework for learning from\nheterogeneous demonstration based upon Bayesian inference and evaluate a suite\nof approaches on a real-world dataset of gameplay from StarCraft II. This\nevaluation provides evidence that our Bayesian approach can outperform\nconventional methods by up to 12.8$%$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 03:08:57 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 19:29:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Paleja", "Rohan", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2001.09576", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Dylan J. Foster", "title": "Naive Exploration is Optimal for Online LQR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online adaptive control of the linear quadratic\nregulator, where the true system parameters are unknown. We prove new upper and\nlower bounds demonstrating that the optimal regret scales as\n$\\widetilde{\\Theta}({\\sqrt{d_{\\mathbf{u}}^2 d_{\\mathbf{x}} T}})$, where $T$ is\nthe number of time steps, $d_{\\mathbf{u}}$ is the dimension of the input space,\nand $d_{\\mathbf{x}}$ is the dimension of the system state. Notably, our lower\nbounds rule out the possibility of a $\\mathrm{poly}(\\log{}T)$-regret algorithm,\nwhich had been conjectured due to the apparent strong convexity of the problem.\nOur upper bound is attained by a simple variant of $\\textit{{certainty\nequivalent control}}$, where the learner selects control inputs according to\nthe optimal controller for their estimate of the system while injecting\nexploratory random noise. While this approach was shown to achieve\n$\\sqrt{T}$-regret by (Mania et al. 2019), we show that if the learner\ncontinually refines their estimates of the system matrices, the method attains\noptimal dimension dependence as well.\n  Central to our upper and lower bounds is a new approach for controlling\nperturbations of Riccati equations called the $\\textit{self-bounding ODE\nmethod}$, which we use to derive suboptimality bounds for the certainty\nequivalent controller synthesized from estimated system dynamics. This in turn\nenables regret upper bounds which hold for $\\textit{any stabilizable instance}$\nand scale with natural control-theoretic quantities.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 03:44:54 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:37:04 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 01:13:25 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Simchowitz", "Max", ""], ["Foster", "Dylan J.", ""]]}, {"id": "2001.09595", "submitter": "Xi Liu", "authors": "Xi Liu, Li Li, Ping-Chun Hsieh, Muhe Xie, Yong Ge, Rui Chen", "title": "Developing Multi-Task Recommendations with Long-Term Rewards via Policy\n  Distilled Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosive growth of online products and content, recommendation\ntechniques have been considered as an effective tool to overcome information\noverload, improve user experience, and boost business revenue. In recent years,\nwe have observed a new desideratum of considering long-term rewards of multiple\nrelated recommendation tasks simultaneously. The consideration of long-term\nrewards is strongly tied to business revenue and growth. Learning multiple\ntasks simultaneously could generally improve the performance of individual task\ndue to knowledge sharing in multi-task learning. While a few existing works\nhave studied long-term rewards in recommendations, they mainly focus on a\nsingle recommendation task. In this paper, we propose {\\it PoDiRe}: a\n\\underline{po}licy \\underline{di}stilled \\underline{re}commender that can\naddress long-term rewards of recommendations and simultaneously handle multiple\nrecommendation tasks. This novel recommendation solution is based on a marriage\nof deep reinforcement learning and knowledge distillation techniques, which is\nable to establish knowledge sharing among different tasks and reduce the size\nof a learning model. The resulting model is expected to attain better\nperformance and lower response latency for real-time recommendation services.\nIn collaboration with Samsung Game Launcher, one of the world's largest\ncommercial mobile game platforms, we conduct a comprehensive experimental study\non large-scale real data with hundreds of millions of events and show that our\nsolution outperforms many state-of-the-art methods in terms of several standard\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 06:05:42 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Liu", "Xi", ""], ["Li", "Li", ""], ["Hsieh", "Ping-Chun", ""], ["Xie", "Muhe", ""], ["Ge", "Yong", ""], ["Chen", "Rui", ""]]}, {"id": "2001.09598", "submitter": "Yihao Huang", "authors": "Yihao Huang, Felix Juefei-Xu, Run Wang, Qing Guo, Xiaofei Xie, Lei Ma,\n  Jianwen Li, Weikai Miao, Yang Liu, Geguang Pu", "title": "FakeLocator: Robust Localization of GAN-Based Face Manipulations", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, full face synthesis and partial face manipulation by virtue of the\ngenerative adversarial networks (GANs) have raised wide public concerns. In the\nmulti-media forensics area, detecting and ultimately locating the image forgery\nhave become imperative. We investigated the architecture of existing GAN-based\nface manipulation methods and observed that the imperfection of upsampling\nmethods therewithin could be served as an important asset for GAN-synthesized\nfake images detection and forgery localization. Based on this basic\nobservation, we have proposed a novel approach to obtain high localization\naccuracy, at full resolution, on manipulated facial images. To the best of our\nknowledge, this is the very first attempt to solve the GAN-based fake\nlocalization problem with a gray-scale fakeness prediction map that preserves\nmore information of fake regions. To improve the universality of FakeLocator\nacross multifarious facial attributes, we introduce an attention mechanism to\nguide the training of the model. Experimental results on the CelebA and FFHQ\ndatabases with seven different state-of-the-art GAN-based face generation\nmethods show the effectiveness of our method. Compared with the baseline, our\nmethod performs two times better on various metrics. Moreover, the proposed\nmethod is robust against various real-world facial image degradations such as\nJPEG compression, low-resolution, noise, and blur.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 06:15:01 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 10:53:18 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 12:39:14 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Huang", "Yihao", ""], ["Juefei-Xu", "Felix", ""], ["Wang", "Run", ""], ["Guo", "Qing", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Li", "Jianwen", ""], ["Miao", "Weikai", ""], ["Liu", "Yang", ""], ["Pu", "Geguang", ""]]}, {"id": "2001.09608", "submitter": "Changjian Li", "authors": "Changjian Li", "title": "Some Insights into Lifelong Reinforcement Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:26:12 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Changjian", ""]]}, {"id": "2001.09610", "submitter": "Ibrahim Yilmaz", "authors": "Ibrahim Yilmaz", "title": "Practical Fast Gradient Sign Attack against Mammographic Image\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has been a topic of major research for many\nyears. Especially, with the emergence of deep neural network (DNN), these\nstudies have been tremendously successful. Today machines are capable of making\nfaster, more accurate decision than human. Thanks to the great development of\nmachine learning (ML) techniques, ML have been used many different fields such\nas education, medicine, malware detection, autonomous car etc. In spite of\nhaving this degree of interest and much successful research, ML models are\nstill vulnerable to adversarial attacks. Attackers can manipulate clean data in\norder to fool the ML classifiers to achieve their desire target. For instance;\na benign sample can be modified as a malicious sample or a malicious one can be\naltered as benign while this modification can not be recognized by human\nobserver. This can lead to many financial losses, or serious injuries, even\ndeaths. The motivation behind this paper is that we emphasize this issue and\nwant to raise awareness. Therefore, the security gap of mammographic image\nclassifier against adversarial attack is demonstrated. We use mamographic\nimages to train our model then evaluate our model performance in terms of\naccuracy. Later on, we poison original dataset and generate adversarial samples\nthat missclassified by the model. We then using structural similarity index\n(SSIM) analyze similarity between clean images and adversarial images. Finally,\nwe show how successful we are to misuse by using different poisoning factors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:37:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Yilmaz", "Ibrahim", ""]]}, {"id": "2001.09612", "submitter": "Irandokht Parviziomran", "authors": "Irandokht Parviziomran, Shun Cao, Haeyong Yang, Seungbae Park, and\n  Daehan Won", "title": "Optimization of Passive Chip Components Placement with Self-Alignment\n  Effect for Advanced Surface Mounting Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface mount technology (SMT) is an enhanced method in electronic packaging\nin which electronic components are placed directly on soldered printing circuit\nboard (PCB) and are permanently attached on PCB with the aim of reflow\nsoldering process. During reflow process, once deposited solder pastes start\nmelting, electronic components move in a direction that achieve their highest\nsymmetry. This motion is known as self-alignment since can correct potential\nmounting misalignment. In this study, two noticeable machine learning\nalgorithms, including support vector regression (SVR) and random forest\nregression (RFR) are proposed as a prediction technique to (1) diagnose the\nrelation among component self-alignment, deposited solder paste status and\nplacement machining parameters, (2) predict the final component position on PCB\nin x, y, and rotational directions before entering in the reflow process. Based\non the prediction result, a non-linear optimization model (NLP) is developed to\noptimize placement parameters at initial stage. Resultantly, RFR outperforms in\nterms of prediction model fitness and error. The optimization model is run for\n6 samples in which the minimum Euclidean distance from component position after\nreflow process from ideal position (i.e., the center of pads) is outlined as\n25.57 ({\\mu}m) regarding defined boundaries in model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:37:47 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Parviziomran", "Irandokht", ""], ["Cao", "Shun", ""], ["Yang", "Haeyong", ""], ["Park", "Seungbae", ""], ["Won", "Daehan", ""]]}, {"id": "2001.09619", "submitter": "Irandokht Parviziomran", "authors": "Irandokht Parviziomran, Shun Cao, Krishnaswami Srihari, and Daehan Won", "title": "Data-Driven Prediction Model of Components Shift during Reflow Process\n  in Surface Mount Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In surface mount technology (SMT), mounted components on soldered pads are\nsubject to move during reflow process. This capability is known as\nself-alignment and is the result of fluid dynamic behaviour of molten solder\npaste. This capability is critical in SMT because inaccurate self-alignment\ncauses defects such as overhanging, tombstoning, etc. while on the other side,\nit can enable components to be perfectly self-assembled on or near the desire\nposition. The aim of this study is to develop a machine learning model that\npredicts the components movement during reflow in x and y-directions as well as\nrotation. Our study is composed of two steps: (1) experimental data are studied\nto reveal the relationships between self-alignment and various factors\nincluding component geometry, pad geometry, etc. (2) advanced machine learning\nprediction models are applied to predict the distance and the direction of\ncomponents shift using support vector regression (SVR), neural network (NN),\nand random forest regression (RFR). As a result, RFR can predict components\nshift with the average fitness of 99%, 99%, and 96% and with average prediction\nerror of 13.47 (um), 12.02 (um), and 1.52 (deg.) for component shift in x, y,\nand rotational directions, respectively. This enhancement provides the future\ncapability of the parameters' optimization in the pick and placement machine to\ncontrol the best placement location and minimize the intrinsic defects caused\nby the self-alignment.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:00:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Parviziomran", "Irandokht", ""], ["Cao", "Shun", ""], ["Srihari", "Krishnaswami", ""], ["Won", "Daehan", ""]]}, {"id": "2001.09621", "submitter": "Matthias Fey", "authors": "Matthias Fey, Jan E. Lenssen, Christopher Morris, Jonathan Masci, Nils\n  M. Kriege", "title": "Deep Graph Matching Consensus", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a two-stage neural architecture for learning and refining\nstructural correspondences between graphs. First, we use localized node\nembeddings computed by a graph neural network to obtain an initial ranking of\nsoft correspondences between nodes. Secondly, we employ synchronous message\npassing networks to iteratively re-rank the soft correspondences to reach a\nmatching consensus in local neighborhoods between graphs. We show,\ntheoretically and empirically, that our message passing scheme computes a\nwell-founded measure of consensus for corresponding neighborhoods, which is\nthen used to guide the iterative re-ranking process. Our purely local and\nsparsity-aware architecture scales well to large, real-world inputs while still\nbeing able to recover global correspondences consistently. We demonstrate the\npractical effectiveness of our method on real-world tasks from the fields of\ncomputer vision and entity alignment between knowledge graphs, on which we\nimprove upon the current state-of-the-art. Our source code is available under\nhttps://github.com/rusty1s/ deep-graph-matching-consensus.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:05:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fey", "Matthias", ""], ["Lenssen", "Jan E.", ""], ["Morris", "Christopher", ""], ["Masci", "Jonathan", ""], ["Kriege", "Nils M.", ""]]}, {"id": "2001.09623", "submitter": "Melih Elibol", "authors": "Melih Elibol, Lihua Lei, Michael I. Jordan", "title": "Variance Reduction with Sparse Gradients", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction methods such as SVRG and SpiderBoost use a mixture of\nlarge and small batch gradients to reduce the variance of stochastic gradients.\nCompared to SGD, these methods require at least double the number of operations\nper update to model parameters. To reduce the computational cost of these\nmethods, we introduce a new sparsity operator: The random-top-k operator. Our\noperator reduces computational complexity by estimating gradient sparsity\nexhibited in a variety of applications by combining the top-k operator and the\nrandomized coordinate descent operator. With this operator, large batch\ngradients offer an extra benefit beyond variance reduction: A reliable estimate\nof gradient sparsity. Theoretically, our algorithm is at least as good as the\nbest algorithm (SpiderBoost), and further excels in performance whenever the\nrandom-top-k operator captures gradient sparsity. Empirically, our algorithm\nconsistently outperforms SpiderBoost using various models on various tasks\nincluding image classification, natural language processing, and sparse matrix\nfactorization. We also provide empirical evidence to support the intuition\nbehind our algorithm via a simple gradient entropy computation, which serves to\nquantify gradient sparsity at every iteration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:23:58 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Elibol", "Melih", ""], ["Lei", "Lihua", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2001.09631", "submitter": "Subhayan Mukherjee", "authors": "Subhayan Mukherjee, Aaron Zimmer, Xinyao Sun, Parwant Ghuman, Irene\n  Cheng", "title": "An Unsupervised Generative Neural Approach for InSAR Phase Filtering and\n  Coherence Estimation", "comments": "to be published in a future issue of IEEE Geoscience and Remote\n  Sensing Letters", "journal-ref": null, "doi": "10.1109/LGRS.2020.3010504", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase filtering and pixel quality (coherence) estimation is critical in\nproducing Digital Elevation Models (DEMs) from Interferometric Synthetic\nAperture Radar (InSAR) images, as it removes spatial inconsistencies (residues)\nand immensely improves the subsequent unwrapping. Large amount of InSAR data\nfacilitates Wide Area Monitoring (WAM) over geographical regions. Advances in\nparallel computing have accelerated Convolutional Neural Networks (CNNs),\ngiving them advantages over human performance on visual pattern recognition,\nwhich makes CNNs a good choice for WAM. Nevertheless, this research is largely\nunexplored. We thus propose \"GenInSAR\", a CNN-based generative model for joint\nphase filtering and coherence estimation, that directly learns the InSAR data\ndistribution. GenInSAR's unsupervised training on satellite and simulated noisy\nInSAR images outperforms other five related methods in total residue reduction\n(over 16.5% better on average) with less over-smoothing/artefacts around branch\ncuts. GenInSAR's Phase, and Coherence Root-Mean-Squared-Error and Phase Cosine\nError have average improvements of 0.54, 0.07, and 0.05 respectively compared\nto the related methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:50:39 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 03:29:41 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 22:33:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mukherjee", "Subhayan", ""], ["Zimmer", "Aaron", ""], ["Sun", "Xinyao", ""], ["Ghuman", "Parwant", ""], ["Cheng", "Irene", ""]]}, {"id": "2001.09636", "submitter": "Meysam Vakili", "authors": "Meysam Vakili, Mohammad Ghamsari and Masoumeh Rezaei", "title": "Performance Analysis and Comparison of Machine and Deep Learning\n  Algorithms for IoT Data Classification", "comments": "13 pages, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the growth of Internet of Things (IoT) as an emerging\ntechnology has been unbelievable. The number of networkenabled devices in IoT\ndomains is increasing dramatically, leading to the massive production of\nelectronic data. These data contain valuable information which can be used in\nvarious areas, such as science, industry, business and even social life. To\nextract and analyze this information and make IoT systems smart, the only\nchoice is entering artificial intelligence (AI) world and leveraging the power\nof machine learning and deep learning techniques. This paper evaluates the\nperformance of 11 popular machine and deep learning algorithms for\nclassification task using six IoT-related datasets. These algorithms are\ncompared according to several performance evaluation metrics including\nprecision, recall, f1-score, accuracy, execution time, ROC-AUC score and\nconfusion matrix. A specific experiment is also conducted to assess the\nconvergence speed of developed models. The comprehensive experiments indicated\nthat, considering all performance metrics, Random Forests performed better than\nother machine learning models, while among deep learning models, ANN and CNN\nachieved more interesting results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:14:11 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Vakili", "Meysam", ""], ["Ghamsari", "Mohammad", ""], ["Rezaei", "Masoumeh", ""]]}, {"id": "2001.09637", "submitter": "Angsheng Li", "authors": "Angsheng Li", "title": "Structural Information Learning Machinery: Learning from Observing,\n  Associating, Optimizing, Decoding, and Abstracting", "comments": "48 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose the model of {\\it structural information\nlearning machines} (SiLeM for short), leading to a mathematical definition of\nlearning by merging the theories of computation and information. Our model\nshows that the essence of learning is {\\it to gain information}, that to gain\ninformation is {\\it to eliminate uncertainty} embedded in a data space, and\nthat to eliminate uncertainty of a data space can be reduced to an optimization\nproblem, that is, an {\\it information optimization problem}, which can be\nrealized by a general {\\it encoding tree method}. The principle and criterion\nof the structural information learning machines are maximization of {\\it\ndecoding information} from the data points observed together with the\nrelationships among the data points, and semantical {\\it interpretation} of\nsyntactical {\\it essential structure}, respectively. A SiLeM machine learns the\nlaws or rules of nature. It observes the data points of real world, builds the\n{\\it connections} among the observed data and constructs a {\\it data space},\nfor which the principle is to choose the way of connections of data points so\nthat the {\\it decoding information} of the data space is maximized, finds the\n{\\it encoding tree} of the data space that minimizes the dynamical uncertainty\nof the data space, in which the encoding tree is hence referred to as a {\\it\ndecoder}, due to the fact that it has already eliminated the maximum amount of\nuncertainty embedded in the data space, interprets the {\\it semantics} of the\ndecoder, an encoding tree, to form a {\\it knowledge tree}, extracts the {\\it\nremarkable common features} for both semantical and syntactical features of the\nmodules decoded by a decoder to construct {\\it trees of abstractions},\nproviding the foundations for {\\it intuitive reasoning} in the learning when\nnew data are observed.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:14:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Angsheng", ""]]}, {"id": "2001.09650", "submitter": "Oshri Halimi", "authors": "Oshri Halimi, Ido Imanuel, Or Litany, Giovanni Trappolini, Emanuele\n  Rodol\\`a, Leonidas Guibas, Ron Kimmel", "title": "The Whole Is Greater Than the Sum of Its Nonrigid Parts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Aristotle, a philosopher in Ancient Greece, \"the whole is\ngreater than the sum of its parts\". This observation was adopted to explain\nhuman perception by the Gestalt psychology school of thought in the twentieth\ncentury. Here, we claim that observing part of an object which was previously\nacquired as a whole, one could deal with both partial matching and shape\ncompletion in a holistic manner. More specifically, given the geometry of a\nfull, articulated object in a given pose, as well as a partial scan of the same\nobject in a different pose, we address the problem of matching the part to the\nwhole while simultaneously reconstructing the new pose from its partial\nobservation. Our approach is data-driven, and takes the form of a Siamese\nautoencoder without the requirement of a consistent vertex labeling at\ninference time; as such, it can be used on unorganized point clouds as well as\non triangle meshes. We demonstrate the practical effectiveness of our model in\nthe applications of single-view deformable shape completion and dense shape\ncorrespondence, both on synthetic and real-world geometric data, where we\noutperform prior work on these tasks by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:48:01 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Halimi", "Oshri", ""], ["Imanuel", "Ido", ""], ["Litany", "Or", ""], ["Trappolini", "Giovanni", ""], ["Rodol\u00e0", "Emanuele", ""], ["Guibas", "Leonidas", ""], ["Kimmel", "Ron", ""]]}, {"id": "2001.09654", "submitter": "Catuscia Palamidessi", "authors": "Catuscia Palamidessi and Marco Romanelli", "title": "Feature selection in machine learning: R\\'enyi min-entropy vs Shannon\n  entropy", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection, in the context of machine learning, is the process of\nseparating the highly predictive feature from those that might be irrelevant or\nredundant. Information theory has been recognized as a useful concept for this\ntask, as the prediction power stems from the correlation, i.e., the mutual\ninformation, between features and labels. Many algorithms for feature selection\nin the literature have adopted the Shannon-entropy-based mutual information. In\nthis paper, we explore the possibility of using R\\'enyi min-entropy instead. In\nparticular, we propose an algorithm based on a notion of conditional R\\'enyi\nmin-entropy that has been recently adopted in the field of security and\nprivacy, and which is strictly related to the Bayes error. We prove that in\ngeneral the two approaches are incomparable, in the sense that we show that we\ncan construct datasets on which the R\\'enyi-based algorithm performs better\nthan the corresponding Shannon-based one, and datasets on which the situation\nis reversed. In practice, however, when considering datasets of real data, it\nseems that the R\\'enyi-based algorithm tends to outperform the other one. We\nhave effectuate several experiments on the BASEHOCK, SEMEION, and GISETTE\ndatasets, and in all of them we have indeed observed that the R\\'enyi-based\nalgorithm gives better results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:50:54 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Palamidessi", "Catuscia", ""], ["Romanelli", "Marco", ""]]}, {"id": "2001.09684", "submitter": "Muhammad Usama", "authors": "Inaam Ilahi, Muhammad Usama, Junaid Qadir, Muhammad Umar Janjua, Ala\n  Al-Fuqaha, Dinh Thai Hoang, and Dusit Niyato", "title": "Challenges and Countermeasures for Adversarial Attacks on Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has numerous applications in the real world\nthanks to its outstanding ability in quickly adapting to the surrounding\nenvironments. Despite its great advantages, DRL is susceptible to adversarial\nattacks, which precludes its use in real-life critical systems and applications\n(e.g., smart grids, traffic controls, and autonomous vehicles) unless its\nvulnerabilities are addressed and mitigated. Thus, this paper provides a\ncomprehensive survey that discusses emerging attacks in DRL-based systems and\nthe potential countermeasures to defend against these attacks. We first cover\nsome fundamental backgrounds about DRL and present emerging adversarial attacks\non machine learning techniques. We then investigate more details of the\nvulnerabilities that the adversary can exploit to attack DRL along with the\nstate-of-the-art countermeasures to prevent such attacks. Finally, we highlight\nopen issues and research challenges for developing solutions to deal with\nattacks for DRL-based intelligent systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 10:53:11 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ilahi", "Inaam", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Janjua", "Muhammad Umar", ""], ["Al-Fuqaha", "Ala", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""]]}, {"id": "2001.09685", "submitter": "Ziv Aharoni", "authors": "Ziv Aharoni, Oron Sabag, Haim Henry Permuter", "title": "Computing the Feedback Capacity of Finite State Channels using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method to compute the feedback capacity of\nchannels with memory using reinforcement learning (RL). In RL, one seeks to\nmaximize cumulative rewards collected in a sequential decision-making\nenvironment. This is done by collecting samples of the underlying environment\nand using them to learn the optimal decision rule. The main advantage of this\napproach is its computational efficiency, even in high dimensional problems.\nHence, RL can be used to estimate numerically the feedback capacity of unifilar\nfinite state channels (FSCs) with large alphabet size. The outcome of the RL\nalgorithm sheds light on the properties of the optimal decision rule, which in\nour case, is the optimal input distribution of the channel. These insights can\nbe converted into analytic, single-letter capacity expressions by solving\ncorresponding lower and upper bounds. We demonstrate the efficiency of this\nmethod by analytically solving the feedback capacity of the well-known Ising\nchannel with a ternary alphabet. We also provide a simple coding scheme that\nachieves the feedback capacity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 10:53:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Aharoni", "Ziv", ""], ["Sabag", "Oron", ""], ["Permuter", "Haim Henry", ""]]}, {"id": "2001.09695", "submitter": "\\'Alvaro L\\'opez Garc\\'ia", "authors": "Mar\\'ia Castrillo and \\'Alvaro L\\'opez Garc\\'ia", "title": "Estimation of high frequency nutrient concentrations from water quality\n  surrogates using machine learning methods", "comments": null, "journal-ref": "Water Research. Volume 172, 1 April 2020, 115490", "doi": "10.1016/j.watres.2020.115490", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous high frequency water quality monitoring is becoming a critical\ntask to support water management. Despite the advancements in sensor\ntechnologies, certain variables cannot be easily and/or economically monitored\nin-situ and in real time. In these cases, surrogate measures can be used to\nmake estimations by means of data-driven models. In this work, variables that\nare commonly measured in-situ are used as surrogates to estimate the\nconcentrations of nutrients in a rural catchment and in an urban one, making\nuse of machine learning models, specifically Random Forests. The results are\ncompared with those of linear modelling using the same number of surrogates,\nobtaining a reduction in the Root Mean Squared Error (RMSE) of up to 60.1%. The\nprofit from including up to seven surrogate sensors was computed, concluding\nthat adding more than 4 and 5 sensors in each of the catchments respectively\nwas not worthy in terms of error improvement.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:18:22 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Castrillo", "Mar\u00eda", ""], ["Garc\u00eda", "\u00c1lvaro L\u00f3pez", ""]]}, {"id": "2001.09696", "submitter": "Vincent Moens", "authors": "Vincent Moens, Simiao Yu, Gholamreza Salimi-Khorshidi", "title": "$\\P$ILCRO: Making Importance Landscapes Flat Again", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have had a great success in numerous tasks,\nincluding image classification, object detection, sequence modelling, and many\nmore. It is generally assumed that such neural networks are translation\ninvariant, meaning that they can detect a given feature independent of its\nlocation in the input image. While this is true for simple cases, where\nnetworks are composed of a restricted number of layer classes and where images\nare fairly simple, complex images with common state-of-the-art networks do not\nusually enjoy this property as one might hope. This paper shows that most of\nthe existing convolutional architectures define, at initialisation, a specific\nfeature importance landscape that conditions their capacity to attend to\ndifferent locations of the images later during training or even at test time.\nWe demonstrate how this phenomenon occurs under specific conditions and how it\ncan be adjusted under some assumptions. We derive the P-objective, or PILCRO\nfor Pixel-wise Importance Landscape Curvature Regularised Objective, a simple\nregularisation technique that favours weight configurations that produce\nsmooth, low-curvature importance landscapes that are conditioned on the data\nand not on the chosen architecture. Through extensive experiments, we further\nshow that P-regularised versions of popular computer vision networks have a\nflat importance landscape, train faster, result in a better accuracy and are\nmore robust to noise at test time, when compared to their original counterparts\nin common computer-vision classification settings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:20:56 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 11:41:02 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Moens", "Vincent", ""], ["Yu", "Simiao", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "2001.09697", "submitter": "Borja Molina Coronado", "authors": "Borja Molina-Coronado and Usue Mori and Alexander Mendiburu and Jos\\'e\n  Miguel-Alonso", "title": "Survey of Network Intrusion Detection Methods from the Perspective of\n  the Knowledge Discovery in Databases Process", "comments": null, "journal-ref": null, "doi": "10.1109/TNSM.2020.3016246", "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of cyberattacks which target information and communication\nsystems has been a focus of the research community for years. Network intrusion\ndetection is a complex problem which presents a diverse number of challenges.\nMany attacks currently remain undetected, while newer ones emerge due to the\nproliferation of connected devices and the evolution of communication\ntechnology. In this survey, we review the methods that have been applied to\nnetwork data with the purpose of developing an intrusion detector, but contrary\nto previous reviews in the area, we analyze them from the perspective of the\nKnowledge Discovery in Databases (KDD) process. As such, we discuss the\ntechniques used for the capture, preparation and transformation of the data, as\nwell as, the data mining and evaluation methods. In addition, we also present\nthe characteristics and motivations behind the use of each of these techniques\nand propose more adequate and up-to-date taxonomies and definitions for\nintrusion detectors based on the terminology used in the area of data mining\nand KDD. Special importance is given to the evaluation procedures followed to\nassess the different detectors, discussing their applicability in current real\nnetworks. Finally, as a result of this literature review, we investigate some\nopen issues which will need to be considered for further research in the area\nof network security.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:21:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Molina-Coronado", "Borja", ""], ["Mori", "Usue", ""], ["Mendiburu", "Alexander", ""], ["Miguel-Alonso", "Jos\u00e9", ""]]}, {"id": "2001.09700", "submitter": "Reihaneh Torkzadehmahani", "authors": "Reihaneh Torkzadehmahani, Peter Kairouz, Benedict Paten", "title": "DP-CGAN: Differentially Private Synthetic Data and Label Generation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are one of the well-known models to\ngenerate synthetic data including images, especially for research communities\nthat cannot use original sensitive datasets because they are not publicly\naccessible. One of the main challenges in this area is to preserve the privacy\nof individuals who participate in the training of the GAN models. To address\nthis challenge, we introduce a Differentially Private Conditional GAN (DP-CGAN)\ntraining framework based on a new clipping and perturbation strategy, which\nimproves the performance of the model while preserving privacy of the training\ndataset. DP-CGAN generates both synthetic data and corresponding labels and\nleverages the recently introduced Renyi differential privacy accountant to\ntrack the spent privacy budget. The experimental results show that DP-CGAN can\ngenerate visually and empirically promising results on the MNIST dataset with a\nsingle-digit epsilon parameter in differential privacy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:26:58 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Torkzadehmahani", "Reihaneh", ""], ["Kairouz", "Peter", ""], ["Paten", "Benedict", ""]]}, {"id": "2001.09725", "submitter": "Nitin Chandrachoodan", "authors": "Abinand Nallathambi and Nitin Chandrachoodan", "title": "Probabilistic spike propagation for FPGA implementation of spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of spiking neural networks requires fetching a large number of\nsynaptic weights to update postsynaptic neurons. This limits parallelism and\nbecomes a bottleneck for hardware.\n  We present an approach for spike propagation based on a probabilistic\ninterpretation of weights, thus reducing memory accesses and updates. We study\nthe effects of introducing randomness into the spike processing, and show on\nbenchmark networks that this can be done with minimal impact on the recognition\naccuracy.\n  We present an architecture and the trade-offs in accuracy on fully connected\nand convolutional networks for the MNIST and CIFAR10 datasets on the Xilinx\nZynq platform.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 06:55:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Nallathambi", "Abinand", ""], ["Chandrachoodan", "Nitin", ""]]}, {"id": "2001.09734", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "One Explanation Does Not Fit All: The Promise of Interactive\n  Explanations for Machine Learning Transparency", "comments": "Published in the Kunstliche Intelligenz journal, special issue on\n  Challenges in Interactive Machine Learning", "journal-ref": null, "doi": "10.1007/s13218-020-00637-y", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for transparency of predictive systems based on Machine Learning\nalgorithms arises as a consequence of their ever-increasing proliferation in\nthe industry. Whenever black-box algorithmic predictions influence human\naffairs, the inner workings of these algorithms should be scrutinised and their\ndecisions explained to the relevant stakeholders, including the system\nengineers, the system's operators and the individuals whose case is being\ndecided. While a variety of interpretability and explainability methods is\navailable, none of them is a panacea that can satisfy all diverse expectations\nand competing objectives that might be required by the parties involved. We\naddress this challenge in this paper by discussing the promises of Interactive\nMachine Learning for improved transparency of black-box systems using the\nexample of contrastive explanations -- a state-of-the-art approach to\nInterpretable Machine Learning.\n  Specifically, we show how to personalise counterfactual explanations by\ninteractively adjusting their conditional statements and extract additional\nexplanations by asking follow-up \"What if?\" questions. Our experience in\nbuilding, deploying and presenting this type of system allowed us to list\ndesired properties as well as potential limitations, which can be used to guide\nthe development of interactive explainers. While customising the medium of\ninteraction, i.e., the user interface comprising of various communication\nchannels, may give an impression of personalisation, we argue that adjusting\nthe explanation itself and its content is more important. To this end,\nproperties such as breadth, scope, context, purpose and target of the\nexplanation have to be considered, in addition to explicitly informing the\nexplainee about its limitations and caveats...\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 13:10:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2001.09735", "submitter": "Homayoun Valafar", "authors": "Nicholas Boltin, Daniel Vu, Bethany Janos, Alyssa Shofner, Joan\n  Culley, Homayoun Valafar", "title": "An AI model for Rapid and Accurate Identification of Chemical Agents in\n  Mass Casualty Incidents", "comments": "7 pages, published in HIMS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we examine the effectiveness of WISER in identification of a\nchemical culprit during a chemical based Mass Casualty Incident (MCI). We also\nevaluate and compare Binary Decision Tree (BDT) and Artificial Neural Networks\n(ANN) using the same experimental conditions as WISER. The reverse engineered\nset of Signs/Symptoms from the WISER application was used as the training set\nand 31,100 simulated patient records were used as the testing set. Three sets\nof simulated patient records were generated by 5%, 10% and 15% perturbation of\nthe Signs/Symptoms of each chemical record. While all three methods achieved a\n100% training accuracy, WISER, BDT and ANN produced performances in the range\nof: 1.8%-0%, 65%-26%, 67%-21% respectively. A preliminary investigation of\ndimensional reduction using ANN illustrated a dimensional collapse from 79\nvariables to 40 with little loss of classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:08:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Boltin", "Nicholas", ""], ["Vu", "Daniel", ""], ["Janos", "Bethany", ""], ["Shofner", "Alyssa", ""], ["Culley", "Joan", ""], ["Valafar", "Homayoun", ""]]}, {"id": "2001.09740", "submitter": "Hoda Sedighi", "authors": "Hoda Sedighi", "title": "Classification of human activity recognition using smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have been the most popular and widely used devices among means of\ncommunication. Nowadays, human activity recognition is possible on mobile\ndevices by embedded sensors, which can be exploited to manage user behavior on\nmobile devices by predicting user activity. To reach this aim, storing activity\ncharacteristics, Classification, and mapping them to a learning algorithm was\nstudied in this research. In this study, we applied categorization through deep\nbelief network to test and training data, which resulted in 98.25% correct\ndiagnosis in training data and 93.01% in test data. Therefore, in this study,\nwe prove that the deep belief network is a suitable method for this particular\npurpose.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 16:08:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sedighi", "Hoda", ""]]}, {"id": "2001.09746", "submitter": "Nuno Henriques", "authors": "Nuno A. C. Henriques, Helder Coelho, Leonel Garcia-Marques", "title": "SensAI+Expanse Emotional Valence Prediction Studies with Cognition and\n  Memory Integration", "comments": "Accepted as regular paper in COGNITIVE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The humans are affective and cognitive beings relying on memories for their\nindividual and social identities. Also, human dyadic bonds require some common\nbeliefs such as empathetic behaviour for better interaction. In this sense,\nresearch studies involving human-agent interaction should resource on affect,\ncognition, and memory integration. The developed artificial agent system\n(SensAI+Expanse) includes machine learning algorithms, heuristics, and memory\nas cognition aids towards emotional valence prediction on the interacting\nhuman. Further, an adaptive empathy score is always present in order to engage\nthe human in a recognisable interaction outcome. [...] The agent is resilient\non collecting data, adapts its cognitive processes to each human individual in\na learning best effort for proper contextualised prediction. The current study\nmake use of an achieved adaptive process. Also, the use of individual\nprediction models with specific options of the learning algorithm and\nevaluation metric from a previous research study. The accomplished solution\nincludes a highly performant prediction ability, an efficient energy use, and\nfeature importance explanation for predicted probabilities. Results of the\npresent study show evidence of significant emotional valence behaviour\ndifferences between some age ranges and gender combinations. Therefore, this\nwork contributes with an artificial intelligent agent able to assist on\ncognitive science studies. This ability is about affective disturbances by\nmeans of predicting human emotional valence contextualised in space and time.\nMoreover, contributes with learning processes and heuristics fit to the task\nincluding economy of cognition and memory to cope with the environment.\nFinally, these contributions include an achieved age and gender neutrality on\npredicting emotional valence states in context and with very good performance\nfor each individual.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:17:57 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 16:27:19 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 15:11:24 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Henriques", "Nuno A. C.", ""], ["Coelho", "Helder", ""], ["Garcia-Marques", "Leonel", ""]]}, {"id": "2001.09748", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "A Deep Learning Approach to Diagnosing Multiple Sclerosis from\n  Smartphone Data", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2020.3021143", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis (MS) affects the central nervous system with a wide range\nof symptoms. MS can, for example, cause pain, changes in mood and fatigue, and\nmay impair a person's movement, speech and visual functions. Diagnosis of MS\ntypically involves a combination of complex clinical assessments and tests to\nrule out other diseases with similar symptoms. New technologies, such as\nsmartphone monitoring in free-living conditions, could potentially aid in\nobjectively assessing the symptoms of MS by quantifying symptom presence and\nintensity over long periods of time. Here, we present a deep-learning approach\nto diagnosing MS from smartphone-derived digital biomarkers that uses a novel\ncombination of a multilayer perceptron with neural soft attention to improve\nlearning of patterns in long-term smartphone monitoring data. Using data from a\ncohort of 774 participants, we demonstrate that our deep-learning models are\nable to distinguish between people with and without MS with an area under the\nreceiver operating characteristic curve of 0.88 (95% CI: 0.70, 0.88). Our\nexperimental results indicate that digital biomarkers derived from smartphone\ndata could in the future be used as additional diagnostic criteria for MS.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:29:16 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 12:12:43 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 07:32:28 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "2001.09751", "submitter": "Dianbo Liu Dr", "authors": "Jianfei Cui, He Zhu, Hao Deng, Ziwei Chen, Dianbo Liu", "title": "Federated machine learning with Anonymous Random Hybridization (FeARH)\n  on medical records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sometimes electrical medical records are restricted and difficult to\ncentralize for machine learning, which could only be trained in distributed\nmanner that involved many institutions in the process. However, sometimes some\ninstitutions are likely to figure out the private data used for training\ncertain models based on the parameters they obtained, which is a violation of\nprivacy and certain regulations. Under those circumstances, we develop an\nalgorithm, called 'federated machine learning with anonymous random\nhybridization'(abbreviated as 'FeARH'), using mainly hybridization algorithm to\neliminate connections between medical record data and models' parameters, which\navoid untrustworthy institutions from stealing patients' private medical\nrecords. Based on our experiment, our new algorithm has similar AUCROC and\nAUCPR result compared with machine learning in centralized manner and original\nfederated machine learning, at the same time, our algorithm can greatly reduce\ndata transfer size in comparison with original federated machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 07:44:25 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 08:21:24 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Cui", "Jianfei", ""], ["Zhu", "He", ""], ["Deng", "Hao", ""], ["Chen", "Ziwei", ""], ["Liu", "Dianbo", ""]]}, {"id": "2001.09764", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan and Ioanna Panagiotou and Willow Livengood and Robert\n  Kane and Andrew Cohen", "title": "Perfecting the Crime Machine", "comments": "11 pages, 55 figures, fixed typos, added references in Introduction\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study explores using different machine learning techniques and workflows\nto predict crime related statistics, specifically crime type in Philadelphia.\nWe use crime location and time as main features, extract different features\nfrom the two features that our raw data has, and build models that would work\nwith large number of class labels. We use different techniques to extract\nvarious features including combining unsupervised learning techniques and try\nto predict the crime type. Some of the models that we use are Support Vector\nMachines, Decision Trees, Random Forest, K-Nearest Neighbors. We report that\nthe Random Forest as the best performing model to predict crime type with an\nerror log loss of 2.3120.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 23:25:40 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:13:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alparslan", "Yigit", ""], ["Panagiotou", "Ioanna", ""], ["Livengood", "Willow", ""], ["Kane", "Robert", ""], ["Cohen", "Andrew", ""]]}, {"id": "2001.09765", "submitter": "Benjamin Birnbaum", "authors": "Benjamin Birnbaum, Nathan Nussbaum, Katharina Seidl-Rathkopf, Monica\n  Agrawal, Melissa Estevez, Evan Estola, Joshua Haimson, Lucy He, Peter Larson,\n  Paul Richardson", "title": "Model-assisted cohort selection with bias analysis for generating\n  large-scale cohorts from the EHR for oncology research", "comments": "Word count: Abstract, 254; text, 3934 Keywords: electronic health\n  record; machine learning; cancer; real-world evidence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objective Electronic health records (EHRs) are a promising source of data for\nhealth outcomes research in oncology. A challenge in using EHR data is that\nselecting cohorts of patients often requires information in unstructured parts\nof the record. Machine learning has been used to address this, but even\nhigh-performing algorithms may select patients in a non-random manner and bias\nthe resulting cohort. To improve the efficiency of cohort selection while\nmeasuring potential bias, we introduce a technique called Model-Assisted Cohort\nSelection (MACS) with Bias Analysis and apply it to the selection of metastatic\nbreast cancer (mBC) patients. Materials and Methods We trained a model on\n17,263 patients using term-frequency inverse-document-frequency (TF-IDF) and\nlogistic regression. We used a test set of 17,292 patients to measure algorithm\nperformance and perform Bias Analysis. We compared the cohort generated by MACS\nto the cohort that would have been generated without MACS as reference\nstandard, first by comparing distributions of an extensive set of clinical and\ndemographic variables and then by comparing the results of two analyses\naddressing existing example research questions. Results Our algorithm had an\narea under the curve (AUC) of 0.976, a sensitivity of 96.0%, and an abstraction\nefficiency gain of 77.9%. During Bias Analysis, we found no large differences\nin baseline characteristics and no differences in the example analyses.\nConclusion MACS with bias analysis can significantly improve the efficiency of\ncohort selection on EHR data while instilling confidence that outcomes research\nperformed on the resulting cohort will not be biased.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 22:58:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Birnbaum", "Benjamin", ""], ["Nussbaum", "Nathan", ""], ["Seidl-Rathkopf", "Katharina", ""], ["Agrawal", "Monica", ""], ["Estevez", "Melissa", ""], ["Estola", "Evan", ""], ["Haimson", "Joshua", ""], ["He", "Lucy", ""], ["Larson", "Peter", ""], ["Richardson", "Paul", ""]]}, {"id": "2001.09769", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab and Jaydip Sen", "title": "Stock Price Prediction Using Convolutional Neural Networks on a\n  Multivariate Timeseries", "comments": "The paper will be published in the Proceedings of the \"National\n  Conference on Machine Learning and Artificial Intelligence\" which will be\n  organized in New Delhi, India, during February 1 - 3, 2020. It contains 7\n  pages, 3 figures, and 19 tables. arXiv admin note: substantial text overlap\n  with arXiv:1912.07700", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future movement of stock prices has been a subject matter of\nmany research work. In this work, we propose a hybrid approach for stock price\nprediction using machine learning and deep learning-based methods. We select\nthe NIFTY 50 index values of the National Stock Exchange of India, over a\nperiod of four years, from January 2015 till December 2019. Based on the NIFTY\ndata during the said period, we build various predictive models using machine\nlearning approaches, and then use those models to predict the Close value of\nNIFTY 50 for the year 2019, with a forecast horizon of one week. For predicting\nthe NIFTY index movement patterns, we use a number of classification methods,\nwhile for forecasting the actual Close values of NIFTY index, various\nregression models are built. We, then, augment our predictive power of the\nmodels by building a deep learning-based regression model using Convolutional\nNeural Network with a walk-forward validation. The CNN model is fine-tuned for\nits parameters so that the validation loss stabilizes with increasing number of\niterations, and the training and validation accuracies converge. We exploit the\npower of CNN in forecasting the future NIFTY index values using three\napproaches which differ in number of variables used in forecasting, number of\nsub-models used in the overall models and, size of the input data for training\nthe models. Extensive results are presented on various metrics for all\nclassification and regression models. The results clearly indicate that\nCNN-based multivariate forecasting model is the most effective and accurate in\npredicting the movement of NIFTY index values with a weekly forecast horizon.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 03:27:08 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}, {"id": "2001.09771", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "Moment-Matching Conditions for Exponential Families with Conditioning or\n  Hidden Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood learning with exponential families leads to\nmoment-matching of the sufficient statistics, a classic result. This can be\ngeneralized to conditional exponential families and/or when there are hidden\ndata. This document gives a first-principles explanation of these generalized\nmoment-matching conditions, along with a self-contained derivation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 15:31:16 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "2001.09773", "submitter": "Zachary Lipton", "authors": "Sina Fazelpour, Zachary C. Lipton", "title": "Algorithmic Fairness from a Non-ideal Perspective", "comments": "Accepted for publication at the AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent breakthroughs in predictive modeling, practitioners in\nboth industry and government have turned to machine learning with hopes of\noperationalizing predictions to drive automated decisions. Unfortunately, many\nsocial desiderata concerning consequential decisions, such as justice or\nfairness, have no natural formulation within a purely predictive framework. In\nefforts to mitigate these problems, researchers have proposed a variety of\nmetrics for quantifying deviations from various statistical parities that we\nmight expect to observe in a fair world and offered a variety of algorithms in\nattempts to satisfy subsets of these parities or to trade off the degree to\nwhich they are satisfied against utility. In this paper, we connect this\napproach to \\emph{fair machine learning} to the literature on ideal and\nnon-ideal methodological approaches in political philosophy. The ideal approach\nrequires positing the principles according to which a just world would operate.\nIn the most straightforward application of ideal theory, one supports a\nproposed policy by arguing that it closes a discrepancy between the real and\nthe perfectly just world. However, by failing to account for the mechanisms by\nwhich our non-ideal world arose, the responsibilities of various\ndecision-makers, and the impacts of proposed policies, naive applications of\nideal thinking can lead to misguided interventions. In this paper, we\ndemonstrate a connection between the fair machine learning literature and the\nideal approach in political philosophy, and argue that the increasingly\napparent shortcomings of proposed fair machine learning algorithms reflect\nbroader troubles faced by the ideal approach. We conclude with a critical\ndiscussion of the harms of misguided solutions, a reinterpretation of\nimpossibility results, and directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:44:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2001.09782", "submitter": "Tram Truong-Huu", "authors": "Tien-Dung Cao, Tram Truong-Huu, Hien Tran, and Khanh Tran", "title": "A Federated Learning Framework for Privacy-preserving and Parallel\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of such deep learning in practice has been hurdled by two\nissues: the computational cost of model training and the privacy issue of\ntraining data such as medical or healthcare records. The large size of both\nlearning models and datasets incurs a massive computational cost, requiring\nefficient approaches to speed up the training phase. While parallel and\ndistributed learning can address the issue of computational overhead,\npreserving the privacy of training data and intermediate results (e.g.,\ngradients) remains a hard problem. Enabling parallel training of deep learning\nmodels on distributed datasets while preserving data privacy is even more\ncomplex and challenging. In this paper, we develop and implement FEDF, a\ndistributed deep learning framework for privacy-preserving and parallel\ntraining. The framework allows a model to be learned on multiple\ngeographically-distributed training datasets (which may belong to different\nowners) while do not reveal any information of each dataset as well as the\nintermediate results. We formally prove the convergence of the learning model\nwhen training with the developed framework and its privacy-preserving property.\nWe carry out extensive experiments to evaluate the performance of the framework\nin terms of speedup ratio, the approximation to the upper-bound performance\n(when training centrally) and communication overhead between the master and\ntraining workers. The results show that the developed framework achieves a\nspeedup of up to 4.8x compared to the centralized training approach and\nmaintaining the performance approximation of the models within 4.5% of the\ncentrally-trained models. The proposed framework also significantly reduces the\namount of data exchanged between the master and training workers by up to 34%\ncompared to existing work.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 02:52:31 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:39:14 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Cao", "Tien-Dung", ""], ["Truong-Huu", "Tram", ""], ["Tran", "Hien", ""], ["Tran", "Khanh", ""]]}, {"id": "2001.09784", "submitter": "Dana Pessach", "authors": "Dana Pessach and Erez Shmueli", "title": "Algorithmic Fairness", "comments": "31 pages, 1 figure, This is a survey article that reviews the field\n  of algorithmic fairness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of decisions regarding the daily lives of human beings\nare being controlled by artificial intelligence (AI) algorithms in spheres\nranging from healthcare, transportation, and education to college admissions,\nrecruitment, provision of loans and many more realms. Since they now touch on\nmany aspects of our lives, it is crucial to develop AI algorithms that are not\nonly accurate but also objective and fair. Recent studies have shown that\nalgorithmic decision-making may be inherently prone to unfairness, even when\nthere is no intention for it. This paper presents an overview of the main\nconcepts of identifying, measuring and improving algorithmic fairness when\nusing AI algorithms. The paper begins by discussing the causes of algorithmic\nbias and unfairness and the common definitions and measures for fairness.\nFairness-enhancing mechanisms are then reviewed and divided into pre-process,\nin-process and post-process mechanisms. A comprehensive comparison of the\nmechanisms is then conducted, towards a better understanding of which\nmechanisms should be used in different scenarios. The paper then describes the\nmost commonly used fairness-related datasets in this field. Finally, the paper\nends by reviewing several emerging research sub-fields of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:01:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pessach", "Dana", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.09786", "submitter": "Somali Chaterji", "authors": "Somali Chaterji, Nathan DeLay, John Evans, Nathan Mosier, Bernard\n  Engel, Dennis Buckmaster and Ranveer Chandra", "title": "Artificial Intelligence for Digital Agriculture at Scale: Techniques,\n  Policies, and Challenges", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital agriculture has the promise to transform agricultural throughput. It\ncan do this by applying data science and engineering for mapping input factors\nto crop throughput, while bounding the available resources. In addition, as the\ndata volumes and varieties increase with the increase in sensor deployment in\nagricultural fields, data engineering techniques will also be instrumental in\ncollection of distributed data as well as distributed processing of the data.\nThese have to be done such that the latency requirements of the end users and\napplications are satisfied. Understanding how farm technology and big data can\nimprove farm productivity can significantly increase the world's food\nproduction by 2050 in the face of constrained arable land and with the water\nlevels receding. While much has been written about digital agriculture's\npotential, little is known about the economic costs and benefits of these\nemergent systems. In particular, the on-farm decision making processes, both in\nterms of adoption and optimal implementation, have not been adequately\naddressed. For example, if some algorithm needs data from multiple data owners\nto be pooled together, that raises the question of data ownership. This paper\nis the first one to bring together the important questions that will guide the\nend-to-end pipeline for the evolution of a new generation of digital\nagricultural solutions, driving the next revolution in agriculture and\nsustainability under one umbrella.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:02:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chaterji", "Somali", ""], ["DeLay", "Nathan", ""], ["Evans", "John", ""], ["Mosier", "Nathan", ""], ["Engel", "Bernard", ""], ["Buckmaster", "Dennis", ""], ["Chandra", "Ranveer", ""]]}, {"id": "2001.09795", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Patrick Uhr, Fabian Merges, Sanaz Mohammad Hassani,\n  Madjid Fathi", "title": "Practical Approach of Knowledge Management in Medical Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge organization, infrastructure, and knowledge-based activities are\nall subjects that help in the creation of business strategies for the new\nenterprise. In this paper, the first basics of knowledge-based systems are\nstudied. Practical issues and challenges of Knowledge Management (KM)\nimplementations are then illustrated. Finally, a comparison of different\nknowledge-based projects is presented along with abstracted information on\ntheir implementation, techniques, and results. Most of these projects are in\nthe field of medical science. Based on our study and evaluation of different KM\nprojects, we conclude that KM is being used in every science, industry, and\nbusiness. But its importance in medical science and assisted living projects\nare highlighted nowadays with the most of research institutes. Most medical\ncenters are interested in using knowledge-based services like portals and\nlearning techniques of knowledge for their future innovations and supports.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:39:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Uhr", "Patrick", ""], ["Merges", "Fabian", ""], ["Hassani", "Sanaz Mohammad", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09821", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee and Jia-Chun Lin", "title": "DALC: Distributed Automatic LSTM Customization for Fine-Grained Traffic\n  Speed Prediction", "comments": "12 pages, 5 figures, the 34th International Conference on Advanced\n  Information Networking and Applications (AINA 2020), Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, several approaches have been introduced for short-term\ntraffic prediction. However, providing fine-grained traffic prediction for\nlarge-scale transportation networks where numerous detectors are geographically\ndeployed to collect traffic data is still an open issue. To address this issue,\nin this paper, we formulate the problem of customizing an LSTM model for a\nsingle detector into a finite Markov decision process and then introduce an\nAutomatic LSTM Customization (ALC) algorithm to automatically customize an LSTM\nmodel for a single detector such that the corresponding prediction accuracy can\nbe as satisfactory as possible and the time consumption can be as low as\npossible. Based on the ALC algorithm, we introduce a distributed approach\ncalled Distributed Automatic LSTM Customization (DALC) to customize an LSTM\nmodel for every detector in large-scale transportation networks. Our experiment\ndemonstrates that the DALC provides higher prediction accuracy than several\napproaches provided by Apache Spark MLlib.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:25:36 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 12:44:23 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""]]}, {"id": "2001.09822", "submitter": "Mario Aguilar-Simon", "authors": "Andrew Brna, Ryan Brown, Patrick Connolly, Stephen Simons, Renee\n  Shimizu, Mario Aguilar-Simon", "title": "Uncertainty-based Modulation for Lifelong Learning", "comments": null, "journal-ref": "Neural Networks, Vol. 120, pp 129-142, 2019", "doi": "10.1016/j.neunet.2019.09.011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of machine learning algorithms for intelligent agents capable of\ncontinuous, lifelong learning is a critical objective for algorithms being\ndeployed on real-life systems in dynamic environments. Here we present an\nalgorithm inspired by neuromodulatory mechanisms in the human brain that\nintegrates and expands upon Stephen Grossberg\\'s ground-breaking Adaptive\nResonance Theory proposals. Specifically, it builds on the concept of\nuncertainty, and employs a series of neuromodulatory mechanisms to enable\ncontinuous learning, including self-supervised and one-shot learning. Algorithm\ncomponents were evaluated in a series of benchmark experiments that demonstrate\nstable learning without catastrophic forgetting. We also demonstrate the\ncritical role of developing these systems in a closed-loop manner where the\nenvironment and the agent\\'s behaviors constrain and guide the learning\nprocess. To this end, we integrated the algorithm into an embodied simulated\ndrone agent. The experiments show that the algorithm is capable of continuous\nlearning of new tasks and under changed conditions with high classification\naccuracy (greater than 94 percent) in a virtual environment, without\ncatastrophic forgetting. The algorithm accepts high dimensional inputs from any\nstate-of-the-art detection and feature extraction algorithms, making it a\nflexible addition to existing systems. We also describe future development\nefforts focused on imbuing the algorithm with mechanisms to seek out new\nknowledge as well as employ a broader range of neuromodulatory processes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:34:37 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Brna", "Andrew", ""], ["Brown", "Ryan", ""], ["Connolly", "Patrick", ""], ["Simons", "Stephen", ""], ["Shimizu", "Renee", ""], ["Aguilar-Simon", "Mario", ""]]}, {"id": "2001.09832", "submitter": "Olivier Teytaud", "authors": "Tristan Cazenave, Yen-Chi Chen, Guan-Wei Chen, Shi-Yu Chen, Xian-Dong\n  Chiu, Julien Dehos, Maria Elsa, Qucheng Gong, Hengyuan Hu, Vasil Khalidov,\n  Cheng-Ling Li, Hsin-I Lin, Yu-Jin Lin, Xavier Martinet, Vegard Mella, Jeremy\n  Rapin, Baptiste Roziere, Gabriel Synnaeve, Fabien Teytaud, Olivier Teytaud,\n  Shi-Cheng Ye, Yi-Jun Ye, Shi-Jim Yen, Sergey Zagoruyko", "title": "Polygames: Improved Zero Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since DeepMind's AlphaZero, Zero learning quickly became the state-of-the-art\nmethod for many board games. It can be improved using a fully convolutional\nstructure (no fully connected layer). Using such an architecture plus global\npooling, we can create bots independent of the board size. The training can be\nmade more robust by keeping track of the best checkpoints during the training\nand by training against them. Using these features, we release Polygames, our\nframework for Zero learning, with its library of games and its checkpoints. We\nwon against strong humans at the game of Hex in 19x19, which was often said to\nbe untractable for zero learning; and in Havannah. We also won several first\nplaces at the TAAI competitions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 14:49:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Cazenave", "Tristan", ""], ["Chen", "Yen-Chi", ""], ["Chen", "Guan-Wei", ""], ["Chen", "Shi-Yu", ""], ["Chiu", "Xian-Dong", ""], ["Dehos", "Julien", ""], ["Elsa", "Maria", ""], ["Gong", "Qucheng", ""], ["Hu", "Hengyuan", ""], ["Khalidov", "Vasil", ""], ["Li", "Cheng-Ling", ""], ["Lin", "Hsin-I", ""], ["Lin", "Yu-Jin", ""], ["Martinet", "Xavier", ""], ["Mella", "Vegard", ""], ["Rapin", "Jeremy", ""], ["Roziere", "Baptiste", ""], ["Synnaeve", "Gabriel", ""], ["Teytaud", "Fabien", ""], ["Teytaud", "Olivier", ""], ["Ye", "Shi-Cheng", ""], ["Ye", "Yi-Jun", ""], ["Yen", "Shi-Jim", ""], ["Zagoruyko", "Sergey", ""]]}, {"id": "2001.09841", "submitter": "Amir Mosavi Prof", "authors": "Javad Hassannataj Joloudari, Edris Hassannataj Joloudari, Hamid\n  Saadatfar, Mohammad GhasemiGol, Seyyed Mohammad Razavi, Amir Mosavi, Narjes\n  Nabipour, Shahaboddin Shamshirband, and Laszlo Nadai", "title": "Coronary Artery Disease Diagnosis; Ranking the Significant Features\n  Using Random Trees Model", "comments": "25 pages, 9 figures", "journal-ref": "International Journal of Environmental Research and Public Health,\n  2020", "doi": "10.3390/ijerph17030731", "report-no": null, "categories": "physics.med-ph cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heart disease is one of the most common diseases in middle-aged citizens.\nAmong the vast number of heart diseases, the coronary artery disease (CAD) is\nconsidered as a common cardiovascular disease with a high death rate. The most\npopular tool for diagnosing CAD is the use of medical imaging, e.g.,\nangiography. However, angiography is known for being costly and also associated\nwith a number of side effects. Hence, the purpose of this study is to increase\nthe accuracy of coronary heart disease diagnosis through selecting significant\npredictive features in order of their ranking. In this study, we propose an\nintegrated method using machine learning. The machine learning methods of\nrandom trees (RTs), decision tree of C5.0, support vector machine (SVM),\ndecision tree of Chi-squared automatic interaction detection (CHAID) are used\nin this study. The proposed method shows promising results and the study\nconfirms that RTs model outperforms other models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:01:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Joloudari", "Javad Hassannataj", ""], ["Joloudari", "Edris Hassannataj", ""], ["Saadatfar", "Hamid", ""], ["GhasemiGol", "Mohammad", ""], ["Razavi", "Seyyed Mohammad", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Shamshirband", "Shahaboddin", ""], ["Nadai", "Laszlo", ""]]}, {"id": "2001.09849", "submitter": "Yuqing Hu", "authors": "Yuqing Hu, Vincent Gripon, St\\'ephane Pateux", "title": "Graph-based Interpolation of Feature Vectors for Accurate Few-Shot\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In few-shot classification, the aim is to learn models able to discriminate\nclasses using only a small number of labeled examples. In this context, works\nhave proposed to introduce Graph Neural Networks (GNNs) aiming at exploiting\nthe information contained in other samples treated concurrently, what is\ncommonly referred to as the transductive setting in the literature. These GNNs\nare trained all together with a backbone feature extractor. In this paper, we\npropose a new method that relies on graphs only to interpolate feature vectors\ninstead, resulting in a transductive learning setting with no additional\nparameters to train. Our proposed method thus exploits two levels of\ninformation: a) transfer features obtained on generic datasets, b) transductive\ninformation obtained from other samples to be classified. Using standard\nfew-shot vision classification datasets, we demonstrate its ability to bring\nsignificant gains compared to other works.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:12:43 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 10:05:59 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:17:55 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 07:56:12 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Hu", "Yuqing", ""], ["Gripon", "Vincent", ""], ["Pateux", "St\u00e9phane", ""]]}, {"id": "2001.09876", "submitter": "Sandipan Sikdar", "authors": "Binny Mathew, Sandipan Sikdar, Florian Lemmerich and Markus Strohmaier", "title": "The POLAR Framework: Polar Opposites Enable Interpretability of\n  Pre-Trained Word Embeddings", "comments": "Accepted at Web Conference (WWW) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce POLAR - a framework that adds interpretability to pre-trained\nword embeddings via the adoption of semantic differentials. Semantic\ndifferentials are a psychometric construct for measuring the semantics of a\nword by analysing its position on a scale between two polar opposites (e.g.,\ncold -- hot, soft -- hard). The core idea of our approach is to transform\nexisting, pre-trained word embeddings via semantic differentials to a new\n\"polar\" space with interpretable dimensions defined by such polar opposites.\nOur framework also allows for selecting the most discriminative dimensions from\na set of polar dimensions provided by an oracle, i.e., an external source. We\ndemonstrate the effectiveness of our framework by deploying it to various\ndownstream tasks, in which our interpretable word embeddings achieve a\nperformance that is comparable to the original word embeddings. We also show\nthat the interpretable dimensions selected by our framework align with human\njudgement. Together, these results demonstrate that interpretability can be\nadded to word embeddings without compromising performance. Our work is relevant\nfor researchers and engineers interested in interpreting pre-trained word\nembeddings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:58:57 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:40:53 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mathew", "Binny", ""], ["Sikdar", "Sandipan", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2001.09877", "submitter": "Andreas Toftegaard Kristensen", "authors": "Andreas Toftegaard Kristensen, Andreas Burg, and Alexios\n  Balatsoukas-Stimming", "title": "Identification of Non-Linear RF Systems Using Backpropagation", "comments": "To be presented at the 2020 IEEE International Conference on\n  Communications (Workshop on Full-Duplex Communications for Future Wireless\n  Networks)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we use deep unfolding to view cascaded non-linear RF systems as\nmodel-based neural networks. This view enables the direct use of a wide range\nof neural network tools and optimizers to efficiently identify such cascaded\nmodels. We demonstrate the effectiveness of this approach through the example\nof digital self-interference cancellation in full-duplex communications where\nan IQ imbalance model and a non-linear PA model are cascaded in series. For a\nself-interference cancellation performance of approximately 44.5 dB, the number\nof model parameters can be reduced by 74% and the number of operations per\nsample can be reduced by 79% compared to an expanded linear-in-parameters\npolynomial model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:59:30 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 15:43:28 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 19:09:04 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Kristensen", "Andreas Toftegaard", ""], ["Burg", "Andreas", ""], ["Balatsoukas-Stimming", "Alexios", ""]]}, {"id": "2001.09882", "submitter": "Siheng Chen", "authors": "Vassilis N. Ioannidis and Siheng Chen and Georgios B. Giannakis", "title": "Efficient and Stable Graph Scattering Transforms via Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have well-documented performance in\nvarious graph learning tasks, but their analysis is still at its infancy. Graph\nscattering transforms (GSTs) offer training-free deep GCN models that extract\nfeatures from graph data, and are amenable to generalization and stability\nanalyses. The price paid by GSTs is exponential complexity in space and time\nthat increases with the number of layers. This discourages deployment of GSTs\nwhen a deep architecture is needed. The present work addresses the complexity\nlimitation of GSTs by introducing an efficient so-termed pruned (p)GST\napproach. The resultant pruning algorithm is guided by a\ngraph-spectrum-inspired criterion, and retains informative scattering features\non-the-fly while bypassing the exponential complexity associated with GSTs.\nStability of the novel pGSTs is also established when the input graph data or\nthe network structure are perturbed. Furthermore, the sensitivity of pGST to\nrandom and localized signal perturbations is investigated analytically and\nexperimentally. Numerical tests showcase that pGST performs comparably to the\nbaseline GST at considerable computational savings. Furthermore, pGST achieves\ncomparable performance to state-of-the-art GCNs in graph and 3D point cloud\nclassification tasks. Upon analyzing the pGST pruning patterns, it is shown\nthat graph data in different domains call for different network architectures,\nand that the pruning algorithm may be employed to guide the design choices for\ncontemporary GCNs.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:05:56 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ioannidis", "Vassilis N.", ""], ["Chen", "Siheng", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "2001.09886", "submitter": "Olga Mikheeva", "authors": "Olga Mikheeva, Ieva Kazlauskaite, Hedvig Kjellstr\\\"om, Carl Henrik Ek", "title": "Bayesian nonparametric shared multi-sequence time series segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method for segmenting time series data using\ntools from Bayesian nonparametrics. We consider the task of temporal\nsegmentation of a set of time series data into representative stationary\nsegments. We use Gaussian process (GP) priors to impose our knowledge about the\ncharacteristics of the underlying stationary segments, and use a nonparametric\ndistribution to partition the sequences into such segments, formulated in terms\nof a prior distribution on segment length. Given the segmentation, the model\ncan be viewed as a variant of a Gaussian mixture model where the mixture\ncomponents are described using the covariance function of a GP. We demonstrate\nthe effectiveness of our model on synthetic data as well as on real time-series\ndata of heartbeats where the task is to segment the indicative types of beats\nand to classify the heartbeat recordings into classes that correspond to\nhealthy and abnormal heart sounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:19:20 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Mikheeva", "Olga", ""], ["Kazlauskaite", "Ieva", ""], ["Kjellstr\u00f6m", "Hedvig", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "2001.09887", "submitter": "Yifan Cui", "authors": "Yifan Cui, Michael R. Kosorok, Erik Sverdrup, Stefan Wager, Ruoqing\n  Zhu", "title": "Estimating heterogeneous treatment effects with right-censored data via\n  causal survival forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forest-based methods have recently gained in popularity for non-parametric\ntreatment effect estimation. Building on this line of work, we introduce causal\nsurvival forests, which can be used to estimate heterogeneous treatment effects\nin a survival and observational setting where outcomes may be right-censored.\nOur approach relies on orthogonal estimating equations to robustly adjust for\nboth censoring and selection effects. In our experiments, we find our approach\nto perform well relative to a number of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:22:05 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 16:35:44 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Cui", "Yifan", ""], ["Kosorok", "Michael R.", ""], ["Sverdrup", "Erik", ""], ["Wager", "Stefan", ""], ["Zhu", "Ruoqing", ""]]}, {"id": "2001.09896", "submitter": "Vinicius Carid\\'a", "authors": "Amir Jalilifard, Vinicius F. Carid\\'a, Alex F. Mansano, Rogers S.\n  Cristo, Felipe Penhorate C. da Fonseca", "title": "Semantic Sensitive TF-IDF to Determine Word Relevance in Documents", "comments": "11 pages, 2 figures, 22 references", "journal-ref": null, "doi": "10.1007/978-981-33-6977-1", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword extraction has received an increasing attention as an important\nresearch topic which can lead to have advancements in diverse applications such\nas document context categorization, text indexing and document classification.\nIn this paper we propose STF-IDF, a novel semantic method based on TF-IDF, for\nscoring word importance of informal documents in a corpus. A set of nearly four\nmillion documents from health-care social media was collected and was trained\nin order to draw semantic model and to find the word embeddings. Then, the\nfeatures of semantic space were utilized to rearrange the original TF-IDF\nscores through an iterative solution so as to improve the moderate performance\nof this algorithm on informal texts. After testing the proposed method with 200\nrandomly chosen documents, our method managed to decrease the TF-IDF mean error\nrate by a factor of 50% and reaching the mean error of 13.7%, as opposed to\n27.2% of the original TF-IDF.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 00:23:11 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 23:52:07 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Jalilifard", "Amir", ""], ["Carid\u00e1", "Vinicius F.", ""], ["Mansano", "Alex F.", ""], ["Cristo", "Rogers S.", ""], ["da Fonseca", "Felipe Penhorate C.", ""]]}, {"id": "2001.09899", "submitter": "Juan Manuel Ortiz De Zarate", "authors": "Juan Manuel Ortiz de Zarate and Esteban Feuerstein", "title": "Vocabulary-based Method for Quantifying Controversy in Social Media", "comments": "arXiv admin note: text overlap with arXiv:1507.05224 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying controversial topics is not only interesting from a social point\nof view, it also enables the application of methods to avoid the information\nsegregation, creating better discussion contexts and reaching agreements in the\nbest cases. In this paper we develop a systematic method for controversy\ndetection based primarily on the jargon used by the communities in social\nmedia. Our method dispenses with the use of domain-specific knowledge, is\nlanguage-agnostic, efficient and easy to apply. We perform an extensive set of\nexperiments across many languages, regions and contexts, taking controversial\nand non-controversial topics. We find that our vocabulary-based measure\nperforms better than state of the art measures that are based only on the\ncommunity graph structure. Moreover, we shows that it is possible to detect\npolarization through text analysis.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:43:21 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["de Zarate", "Juan Manuel Ortiz", ""], ["Feuerstein", "Esteban", ""]]}, {"id": "2001.09900", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Mengting Wan, Stephen Guo, Kannan Achan, Philip S. Yu", "title": "BasConv: Aggregating Heterogeneous Interactions for Basket\n  Recommendation with Graph Convolutional Neural Network", "comments": "Accepted to SDM 2020, Our code is available online at\n  https://github.com/JimLiu96/basConv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within-basket recommendation reduces the exploration time of users, where the\nuser's intention of the basket matters. The intent of a shopping basket can be\nretrieved from both user-item collaborative filtering signals and multi-item\ncorrelations. By defining a basket entity to represent the basket intent, we\ncan model this problem as a basket-item link prediction task in the\nUser-Basket-Item~(UBI) graph. Previous work solves the problem by leveraging\nuser-item interactions and item-item interactions simultaneously. However,\ncollectivity and heterogeneity characteristics are hardly investigated before.\nCollectivity defines the semantics of each node which should be aggregated from\nboth directly and indirectly connected neighbors. Heterogeneity comes from\nmulti-type interactions as well as multi-type nodes in the UBI graph. To this\nend, we propose a new framework named \\textbf{BasConv}, which is based on the\ngraph convolutional neural network. Our BasConv model has three types of\naggregators specifically designed for three types of nodes. They collectively\nlearn node embeddings from both neighborhood and high-order context.\nAdditionally, the interactive layers in the aggregators can distinguish\ndifferent types of interactions. Extensive experiments on two real-world\ndatasets prove the effectiveness of BasConv. Our code is available online at\nhttps://github.com/JimLiu96/basConv.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 16:27:32 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 03:17:23 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Liu", "Zhiwei", ""], ["Wan", "Mengting", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""], ["Yu", "Philip S.", ""]]}, {"id": "2001.09902", "submitter": "Saeed Khaki", "authors": "Saeed Khaki, Zahra Khalilzadeh and Lizhi Wang", "title": "Predicting Yield Performance of Parents in Plant Breeding: A Neural\n  Collaborative Filtering Approach", "comments": "13 pages, 4 figures", "journal-ref": "PLoS ONE 15(5): e0233382 (2020)", "doi": "10.1371/journal.pone.0233382", "report-no": null, "categories": "cs.LG q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental corn hybrids are created in plant breeding programs by crossing\ntwo parents, so-called inbred and tester, together. Identification of best\nparent combinations for crossing is challenging since the total number of\npossible cross combinations of parents is large and it is impractical to test\nall possible cross combinations due to limited resources of time and budget. In\nthe 2020 Syngenta Crop Challenge, Syngenta released several large datasets that\nrecorded the historical yield performances of around 4% of total cross\ncombinations of 593 inbreds with 496 testers which were planted in 280\nlocations between 2016 and 2018 and asked participants to predict the yield\nperformance of cross combinations of inbreds and testers that have not been\nplanted based on the historical yield data collected from crossing other\ninbreds and testers. In this paper, we present a collaborative filtering method\nwhich is an ensemble of matrix factorization method and neural networks to\nsolve this problem. Our computational results suggested that the proposed model\nsignificantly outperformed other models such as LASSO, random forest (RF), and\nneural networks. Presented method and results were produced within the 2020\nSyngenta Crop Challenge.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:39:45 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 00:10:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khaki", "Saeed", ""], ["Khalilzadeh", "Zahra", ""], ["Wang", "Lizhi", ""]]}, {"id": "2001.09908", "submitter": "Chang Ye", "authors": "Chang Ye, Ahmed Khalifa, Philip Bontrager, Julian Togelius", "title": "Rotation, Translation, and Cropping for Zero-Shot Generalization", "comments": "IEEE Conference on Games 2020 Full Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has shown impressive performance on domains\nwith visual inputs, in particular various games. However, the agent is usually\ntrained on a fixed environment, e.g. a fixed number of levels. A growing mass\nof evidence suggests that these trained models fail to generalize to even\nslight variations of the environments they were trained on. This paper advances\nthe hypothesis that the lack of generalization is partly due to the input\nrepresentation, and explores how rotation, cropping and translation could\nincrease generality. We show that a cropped, translated and rotated observation\ncan get better generalization on unseen levels of two-dimensional arcade games\nfrom the GVGAI framework. The generality of the agents is evaluated on both\nhuman-designed and procedurally generated levels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:56:05 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 18:42:57 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 03:18:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ye", "Chang", ""], ["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Togelius", "Julian", ""]]}, {"id": "2001.09930", "submitter": "Xiaotong Jiang", "authors": "Xiaotong Jiang, Amanda E. Nelson, Rebecca J. Cleveland, Daniel P.\n  Beavers, Todd A. Schwartz, Liubov Arbeeva, Carolina Alvarez, Leigh F.\n  Callahan, Stephen Messier, Richard Loeser, Michael R. Kosorok", "title": "Technical Background for \"A Precision Medicine Approach to Develop and\n  Internally Validate Optimal Exercise and Weight Loss Treatments for\n  Overweight and Obese Adults with Knee Osteoarthritis\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide additional statistical background for the methodology developed in\nthe clinical analysis of knee osteoarthritis in \"A Precision Medicine Approach\nto Develop and Internally Validate Optimal Exercise and Weight Loss Treatments\nfor Overweight and Obese Adults with Knee Osteoarthritis\" (Jiang et al. 2020).\nJiang et al. 2020 proposed a pipeline to learn optimal treatment rules with\nprecision medicine models and compared them with zero-order models with a\nZ-test. The model performance was based on value functions, a scalar that\npredicts the future reward of each decision rule. The jackknife (i.e.,\nleave-one-out cross validation) method was applied to estimate the value\nfunction and its variance of several outcomes in IDEA. IDEA is a randomized\nclinical trial studying three interventions (exercise (E), dietary weight loss\n(D), and D+E) on overweight and obese participants with knee osteoarthritis. In\nthis report, we expand the discussion and justification with additional\nstatistical background. We elaborate more on the background of precision\nmedicine, the derivation of the jackknife estimator of value function and its\nestimated variance, the consistency property of jackknife estimator, as well as\nadditional simulation results that reflect more of the performance of jackknife\nestimators. We recommend reading Jiang et al. 2020 for clinical application and\ninterpretation of the optimal ITR of knee osteoarthritis as well as the overall\nunderstanding of the pipeline and recommend using this article to understand\nthe underlying statistical derivation and methodology.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:50:20 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 21:48:55 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 20:20:44 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jiang", "Xiaotong", ""], ["Nelson", "Amanda E.", ""], ["Cleveland", "Rebecca J.", ""], ["Beavers", "Daniel P.", ""], ["Schwartz", "Todd A.", ""], ["Arbeeva", "Liubov", ""], ["Alvarez", "Carolina", ""], ["Callahan", "Leigh F.", ""], ["Messier", "Stephen", ""], ["Loeser", "Richard", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "2001.09938", "submitter": "Venkatasubramanian Viswanathan", "authors": "Adarsh Dave and Jared Mitchell and Kirthevasan Kandasamy and Sven\n  Burke and Biswajit Paria and Barnabas Poczos and Jay Whitacre and\n  Venkatasubramanian Viswanathan", "title": "Autonomous discovery of battery electrolytes with robotic\n  experimentation and machine-learning", "comments": "23 pages, 4 figures, 10 pages of Extended Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovations in batteries take years to formulate and commercialize, requiring\nextensive experimentation during the design and optimization phases. We\napproached the design and selection of a battery electrolyte through a\nblack-box optimization algorithm directly integrated into a robotic test-stand.\nWe report here the discovery of a novel battery electrolyte by this experiment\ncompletely guided by the machine-learning software without human intervention.\nMotivated by the recent trend toward super-concentrated aqueous electrolytes\nfor high-performance batteries, we utilize Dragonfly - a Bayesian\nmachine-learning software package - to search mixtures of commonly used lithium\nand sodium salts for super-concentrated aqueous electrolytes with wide\nelectrochemical stability windows. Dragonfly autonomously managed the robotic\ntest-stand, recommending electrolyte designs to test and receiving experimental\nfeedback in real time. In 40 hours of continuous experimentation over a\nfour-dimensional design space with millions of potential candidates, Dragonfly\ndiscovered a novel, mixed-anion aqueous sodium electrolyte with a wider\nelectrochemical stability window than state-of-the-art sodium electrolyte. A\nhuman-guided design process may have missed this optimal electrolyte. This\nresult demonstrates the possibility of integrating robotics with\nmachine-learning to rapidly and autonomously discover novel battery materials.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:57:20 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Dave", "Adarsh", ""], ["Mitchell", "Jared", ""], ["Kandasamy", "Kirthevasan", ""], ["Burke", "Sven", ""], ["Paria", "Biswajit", ""], ["Poczos", "Barnabas", ""], ["Whitacre", "Jay", ""], ["Viswanathan", "Venkatasubramanian", ""]]}, {"id": "2001.09947", "submitter": "Sheela Ramanna", "authors": "Sheela Ramanna and Cenker Sengoz and Scott Kehler and Dat Pham", "title": "Near real-time map building with multi-class image set labelling and\n  classification of road conditions using convolutional neural networks", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weather is an important factor affecting transportation and road safety. In\nthis paper, we leverage state-of-the-art convolutional neural networks in\nlabelling images taken by street and highway cameras located across across\nNorth America. Road camera snapshots were used in experiments with multiple\ndeep learning frameworks to classify images by road condition. The training\ndata for these experiments used images labelled as dry, wet, snow/ice, poor,\nand offline. The experiments tested different configurations of six\nconvolutional neural networks (VGG-16, ResNet50, Xception, InceptionResNetV2,\nEfficientNet-B0 and EfficientNet-B4) to assess their suitability to this\nproblem. The precision, accuracy, and recall were measured for each framework\nconfiguration. In addition, the training sets were varied both in overall size\nand by size of individual classes. The final training set included 47,000\nimages labelled using the five aforementioned classes. The EfficientNet-B4\nframework was found to be most suitable to this problem, achieving validation\naccuracy of 90.6%, although EfficientNet-B0 achieved an accuracy of 90.3% with\nhalf the execution time. It was observed that VGG-16 with transfer learning\nproved to be very useful for data acquisition and pseudo-labelling with limited\nhardware resources, throughout this project. The EfficientNet-B4 framework was\nthen placed into a real-time production environment, where images could be\nclassified in real-time on an ongoing basis. The classified images were then\nused to construct a map showing real-time road conditions at various camera\nlocations across North America. The choice of these frameworks and our analysis\ntake into account unique requirements of real-time map building functions. A\ndetailed analysis of the process of semi-automated dataset labelling using\nthese frameworks is also presented in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:07:40 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ramanna", "Sheela", ""], ["Sengoz", "Cenker", ""], ["Kehler", "Scott", ""], ["Pham", "Dat", ""]]}, {"id": "2001.09957", "submitter": "David A. Monge Ph.D.", "authors": "Yisel Gar\\'i, David A. Monge, Elina Pacini, Cristian Mateos, and\n  Carlos Garc\\'ia Garino", "title": "Reinforcement Learning-based Application Autoscaling in the Cloud: A\n  Survey", "comments": "40 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has demonstrated a great potential for\nautomatically solving decision-making problems in complex uncertain\nenvironments. RL proposes a computational approach that allows learning through\ninteraction in an environment with stochastic behavior, where agents take\nactions to maximize some cumulative short-term and long-term rewards. Some of\nthe most impressive results have been shown in Game Theory where agents\nexhibited superhuman performance in games like Go or Starcraft 2, which led to\nits gradual adoption in many other domains, including Cloud Computing.\nTherefore, RL appears as a promising approach for Autoscaling in Cloud since it\nis possible to learn transparent (with no human intervention), dynamic (no\nstatic plans), and adaptable (constantly updated) resource management policies\nto execute applications. These are three important distinctive aspects to\nconsider in comparison with other widely used autoscaling policies that are\ndefined in an ad-hoc way or statically computed as in solutions based on\nmeta-heuristics. Autoscaling exploits the Cloud elasticity to optimize the\nexecution of applications according to given optimization criteria, which\ndemands to decide when and how to scale-up/down computational resources, and\nhow to assign them to the upcoming processing workload. Such actions have to be\ntaken considering that the Cloud is a dynamic and uncertain environment.\nMotivated by this, many works apply RL to the autoscaling problem in the Cloud.\nIn this work, we survey exhaustively those proposals from major venues, and\nuniformly compare them based on a set of proposed taxonomies. We also discuss\nopen problems and prospective research in the area.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:23:43 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 14:10:54 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 14:14:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Gar\u00ed", "Yisel", ""], ["Monge", "David A.", ""], ["Pacini", "Elina", ""], ["Mateos", "Cristian", ""], ["Garino", "Carlos Garc\u00eda", ""]]}, {"id": "2001.09977", "submitter": "Daniel de Freitas Adiwardana", "authors": "Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah\n  Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng\n  Lu, Quoc V. Le", "title": "Towards a Human-like Open-Domain Chatbot", "comments": "38 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meena, a multi-turn open-domain chatbot trained end-to-end on data\nmined and filtered from public domain social media conversations. This 2.6B\nparameter neural network is simply trained to minimize perplexity of the next\ntoken. We also propose a human evaluation metric called Sensibleness and\nSpecificity Average (SSA), which captures key elements of a human-like\nmulti-turn conversation. Our experiments show strong correlation between\nperplexity and SSA. The fact that the best perplexity end-to-end trained Meena\nscores high on SSA (72% on multi-turn evaluation) suggests that a human-level\nSSA of 86% is potentially within reach if we can better optimize perplexity.\nAdditionally, the full version of Meena (with a filtering mechanism and tuned\ndecoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots\nwe evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:58:14 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 07:36:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adiwardana", "Daniel", ""], ["Luong", "Minh-Thang", ""], ["So", "David R.", ""], ["Hall", "Jamie", ""], ["Fiedel", "Noah", ""], ["Thoppilan", "Romal", ""], ["Yang", "Zi", ""], ["Kulshreshtha", "Apoorv", ""], ["Nemade", "Gaurav", ""], ["Lu", "Yifeng", ""], ["Le", "Quoc V.", ""]]}, {"id": "2001.09993", "submitter": "Jean-Christophe Burnel", "authors": "Jean-Christophe Burnel (OBELIX), Kilian Fatras (OBELIX), Nicolas\n  Courty (OBELIX)", "title": "Generating Natural Adversarial Hyperspectral examples with a modified\n  Wasserstein GAN", "comments": "C&ESAR, Nov 2019, Rennes, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are a hot topic due to their abilities to fool a\nclassifier's prediction. There are two strategies to create such examples, one\nuses the attacked classifier's gradients, while the other only requires access\nto the clas-sifier's prediction. This is particularly appealing when the\nclassifier is not full known (black box model). In this paper, we present a new\nmethod which is able to generate natural adversarial examples from the true\ndata following the second paradigm. Based on Generative Adversarial Networks\n(GANs) [5], it reweights the true data empirical distribution to encourage the\nclassifier to generate ad-versarial examples. We provide a proof of concept of\nour method by generating adversarial hyperspectral signatures on a remote\nsensing dataset.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 07:32:46 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Burnel", "Jean-Christophe", "", "OBELIX"], ["Fatras", "Kilian", "", "OBELIX"], ["Courty", "Nicolas", "", "OBELIX"]]}, {"id": "2001.09994", "submitter": "Pirmin Lemberger", "authors": "Pirmin Lemberger and Ivan Panico", "title": "A Primer on Domain Adaptation", "comments": "31 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised machine learning assumes that the distribution of the\nsource samples used to train an algorithm is the same as the one of the target\nsamples on which it is supposed to make predictions. However, as any data\nscientist will confirm, this is hardly ever the case in practice. The set of\nstatistical and numerical methods that deal with such situations is known as\ndomain adaptation, a field with a long and rich history. The myriad of methods\navailable and the unfortunate lack of a clear and universally accepted\nterminology can however make the topic rather daunting for the newcomer.\nTherefore, rather than aiming at completeness, which leads to exhibiting a\ntedious catalog of methods, this pedagogical review aims at a coherent\npresentation of four important special cases: (1) prior shift, a situation in\nwhich training samples were selected according to their labels without any\nknowledge of their actual distribution in the target, (2) covariate shift which\ndeals with a situation where training examples were picked according to their\nfeatures but with some selection bias, (3) concept shift where the dependence\nof the labels on the features defers between the source and the target, and\nlast but not least (4) subspace mapping which deals with a situation where\nfeatures in the target have been subjected to an unknown distortion with\nrespect to the source features. In each case we first build an intuition, next\nwe provide the appropriate mathematical framework and eventually we describe a\npractical application.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:10:18 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 17:47:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Lemberger", "Pirmin", ""], ["Panico", "Ivan", ""]]}, {"id": "2001.10006", "submitter": "Molei Tao", "authors": "Molei Tao, Tomoki Ohsawa", "title": "Variational Optimization on Lie Groups, with Examples of Leading\n  (Generalized) Eigenvalue Problems", "comments": "Accepted by AISTATS 2020; never submitted elsewhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers smooth optimization of functions on Lie groups. By\ngeneralizing NAG variational principle in vector space (Wibisono et al., 2016)\nto Lie groups, continuous Lie-NAG dynamics which are guaranteed to converge to\nlocal optimum are obtained. They correspond to momentum versions of gradient\nflow on Lie groups. A particular case of $\\mathsf{SO}(n)$ is then studied in\ndetails, with objective functions corresponding to leading Generalized\nEigenValue problems: the Lie-NAG dynamics are first made explicit in\ncoordinates, and then discretized in structure preserving fashions, resulting\nin optimization algorithms with faithful energy behavior (due to conformal\nsymplecticity) and exactly remaining on the Lie group. Stochastic gradient\nversions are also investigated. Numerical experiments on both synthetic data\nand practical problem (LDA for MNIST) demonstrate the effectiveness of the\nproposed methods as optimization algorithms ($not$ as a classification method).\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:00:03 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tao", "Molei", ""], ["Ohsawa", "Tomoki", ""]]}, {"id": "2001.10025", "submitter": "Tim Barfoot", "authors": "Timothy D. Barfoot", "title": "Multivariate Gaussian Variational Inference by Natural Gradient Descent", "comments": "11 pages, 0 figures; second version fixed a single typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note reviews so-called Natural Gradient Descent (NGD) for\nmultivariate Gaussians. The Fisher Information Matrix (FIM) is derived for\nseveral different parameterizations of Gaussians. Careful attention is paid to\nthe symmetric nature of the covariance matrix when calculating derivatives. We\nshow that there are some advantages to choosing a parameterization comprising\nthe mean and inverse covariance matrix and provide a simple NGD update that\naccounts for the symmetric (and sparse) nature of the inverse covariance\nmatrix.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:20:03 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:54:16 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Barfoot", "Timothy D.", ""]]}, {"id": "2001.10054", "submitter": "Junyi Gao", "authors": "Junyi Gao, Cao Xiao, Yasha Wang, Wen Tang, Lucas M. Glass, Jimeng Sun", "title": "StageNet: Stage-Aware Neural Networks for Health Risk Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380136", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has demonstrated success in health risk prediction especially\nfor patients with chronic and progressing conditions. Most existing works focus\non learning disease Network (StageNet) model to extract disease stage\ninformation from patient data and integrate it into risk prediction. StageNet\nis enabled by (1) a stage-aware long short-term memory (LSTM) module that\nextracts health stage variations unsupervisedly; (2) a stage-adaptive\nconvolutional module that incorporates stage-related progression patterns into\nrisk prediction. We evaluate StageNet on two real-world datasets and show that\nStageNet outperforms state-of-the-art models in risk prediction task and\npatient subtyping task. Compared to the best baseline model, StageNet achieves\nup to 12% higher AUPRC for risk prediction task on two real-world patient\ndatasets. StageNet also achieves over 58% higher Calinski-Harabasz score (a\ncluster quality metric) for a patient subtyping task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 17:50:36 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Gao", "Junyi", ""], ["Xiao", "Cao", ""], ["Wang", "Yasha", ""], ["Tang", "Wen", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.10055", "submitter": "Ganesh Ghalme", "authors": "Ganesh Ghalme, Swapnil Dhamal, Shweta Jain, Sujit Gujar, Y. Narahari", "title": "Ballooning Multi-Armed Bandits", "comments": "A full version of this paper is accepted in the Journal of Artificial\n  Intelligence (AIJ) of Elsevier. A preliminary version is published as an\n  extended abstract in AAMAS 2020. Proceedings of the 19th International\n  Conference on Autonomous Agents and MultiAgent Systems. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Ballooning Multi-Armed Bandits (BL-MAB), a novel\nextension of the classical stochastic MAB model. In the BL-MAB model, the set\nof available arms grows (or balloons) over time. In contrast to the classical\nMAB setting where the regret is computed with respect to the best arm overall,\nthe regret in a BL-MAB setting is computed with respect to the best available\narm at each time. We first observe that the existing stochastic MAB algorithms\nresult in linear regret for the BL-MAB model. We prove that, if the best arm is\nequally likely to arrive at any time instant, a sub-linear regret cannot be\nachieved. Next, we show that if the best arm is more likely to arrive in the\nearly rounds, one can achieve sub-linear regret. Our proposed algorithm\ndetermines (1) the fraction of the time horizon for which the newly arriving\narms should be explored and (2) the sequence of arm pulls in the exploitation\nphase from among the explored arms. Making reasonable assumptions on the\narrival distribution of the best arm in terms of the thinness of the\ndistribution's tail, we prove that the proposed algorithm achieves sub-linear\ninstance-independent regret. We further quantify explicit dependence of regret\non the arrival distribution parameters. We reinforce our theoretical findings\nwith extensive simulation results. We conclude by showing that our algorithm\nwould achieve sub-linear regret even if (a) the distributional parameters are\nnot exactly known, but are obtained using a reasonable learning mechanism or\n(b) the best arm is not more likely to arrive early, but a large fraction of\narms is likely to arrive relatively early.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 04:35:05 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 10:41:13 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 12:33:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ghalme", "Ganesh", ""], ["Dhamal", "Swapnil", ""], ["Jain", "Shweta", ""], ["Gujar", "Sujit", ""], ["Narahari", "Y.", ""]]}, {"id": "2001.10056", "submitter": "Markus Abel", "authors": "Markus Quade and Thomas Isele and Markus Abel", "title": "Explainable Machine Learning Control -- robust control and stability\n  analysis", "comments": "submitted to Physica D. arXiv admin note: text overlap with\n  arXiv:1612.05276", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.AO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the term explainable AI became known as an approach to produce\nmodels from artificial intelligence which allow interpretation. Since a long\ntime, there are models of symbolic regression in use that are perfectly\nexplainable and mathematically tractable: in this contribution we demonstrate\nhow to use symbolic regression methods to infer the optimal control of a\ndynamical system given one or several optimization criteria, or cost functions.\nIn previous publications, network control was achieved by automatized machine\nlearning control using genetic programming. Here, we focus on the subsequent\nanalysis of the analytical expressions which result from the machine learning.\nIn particular, we use AUTO to analyze the stability properties of the\ncontrolled oscillator system which served as our model. As a result, we show\nthat there is a considerable advantage of explainable models over less\naccessible neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 08:09:58 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Quade", "Markus", ""], ["Isele", "Thomas", ""], ["Abel", "Markus", ""]]}, {"id": "2001.10065", "submitter": "Lin Wu", "authors": "Deyin Liu, Lin Wu, Xue Li", "title": "Medi-Care AI: Predicting Medications From Billing Codes via Robust\n  Recurrent Neural Networks", "comments": "Under Review for Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an effective deep prediction framework based on\nrobust recurrent neural networks (RNNs) to predict the likely therapeutic\nclasses of medications a patient is taking, given a sequence of diagnostic\nbilling codes in their record. Accurately capturing the list of medications\ncurrently taken by a given patient is extremely challenging due to undefined\nerrors and omissions. We present a general robust framework that explicitly\nmodels the possible contamination through overtime decay mechanism on the input\nbilling codes and noise injection into the recurrent hidden states,\nrespectively. By doing this, billing codes are reformulated into its temporal\npatterns with decay rates on each medical variable, and the hidden states of\nRNNs are regularised by random noises which serve as dropout to improved RNNs\nrobustness towards data variability in terms of missing values and multiple\nerrors. The proposed method is extensively evaluated on real health care data\nto demonstrate its effectiveness in suggesting medication orders from\ncontaminated values.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:49:46 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Liu", "Deyin", ""], ["Wu", "Lin", ""], ["Li", "Xue", ""]]}, {"id": "2001.10070", "submitter": "Navdeep Kaur", "authors": "Navdeep Kaur and Gautam Kunapuli and Sriraam Natarajan", "title": "Non-Parametric Learning of Lifted Restricted Boltzmann Machines", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of discriminatively learning restricted Boltzmann\nmachines in the presence of relational data. Unlike previous approaches that\nemploy a rule learner (for structure learning) and a weight learner (for\nparameter learning) sequentially, we develop a gradient-boosted approach that\nperforms both simultaneously. Our approach learns a set of weak relational\nregression trees, whose paths from root to leaf are conjunctive clauses and\nrepresent the structure, and whose leaf values represent the parameters. When\nthe learned relational regression trees are transformed into a lifted RBM, its\nhidden nodes are precisely the conjunctive clauses derived from the relational\nregression trees. This leads to a more interpretable and explainable model. Our\nempirical evaluations clearly demonstrate this aspect, while displaying no loss\nin effectiveness of the learned models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 05:23:26 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kaur", "Navdeep", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2001.10073", "submitter": "Amir M. Mir", "authors": "Amir M. Mir, Mahdi Rahbar, Jalal A. Nasiri", "title": "LIBTwinSVM: A Library for Twin Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents LIBTwinSVM, a free, efficient, and open source library\nfor Twin Support Vector Machines (TSVMs). Our library provides a set of useful\nfunctionalities such as fast TSVMs estimators, model selection, visualization,\na graphical user interface (GUI) application, and a Python application\nprogramming interface (API). The benchmarks results indicate the effectiveness\nof the LIBTwinSVM library for large-scale classification problems. The source\ncode of LIBTwinSVM library, installation guide, documentation, and usage\nexamples are available at https://github.com/mir-am/LIBTwinSVM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 20:40:37 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mir", "Amir M.", ""], ["Rahbar", "Mahdi", ""], ["Nasiri", "Jalal A.", ""]]}, {"id": "2001.10092", "submitter": "Silviu Pitis", "authors": "Silviu Pitis and Michael R. Zhang", "title": "Objective Social Choice: Using Auxiliary Information to Improve Voting\n  Outcomes", "comments": "10 pages, 3 figures. To appear in proceedings of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How should one combine noisy information from diverse sources to make an\ninference about an objective ground truth? This frequently recurring, normative\nquestion lies at the core of statistics, machine learning, policy-making, and\neveryday life. It has been called \"combining forecasts\", \"meta-analysis\",\n\"ensembling\", and the \"MLE approach to voting\", among other names. Past studies\ntypically assume that noisy votes are identically and independently distributed\n(i.i.d.), but this assumption is often unrealistic. Instead, we assume that\nvotes are independent but not necessarily identically distributed and that our\nensembling algorithm has access to certain auxiliary information related to the\nunderlying model governing the noise in each vote. In our present work, we: (1)\ndefine our problem and argue that it reflects common and socially relevant real\nworld scenarios, (2) propose a multi-arm bandit noise model and count-based\nauxiliary information set, (3) derive maximum likelihood aggregation rules for\nranked and cardinal votes under our noise model, (4) propose, alternatively, to\nlearn an aggregation rule using an order-invariant neural network, and (5)\nempirically compare our rules to common voting rules and naive\nexperience-weighted modifications. We find that our rules successfully use\nauxiliary information to outperform the naive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:21:19 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pitis", "Silviu", ""], ["Zhang", "Michael R.", ""]]}, {"id": "2001.10098", "submitter": "Wenyu Zhang", "authors": "Wenyu Zhang, Devesh K. Jha, Emil Laftchiev, Daniel Nikovski", "title": "Multi-label Prediction in Time Series Data using Deep Neural Networks", "comments": "Accepted by IJPHM. Presented at PHM19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses a multi-label predictive fault classification problem\nfor multidimensional time-series data. While fault (event) detection problems\nhave been thoroughly studied in literature, most of the state-of-the-art\ntechniques can't reliably predict faults (events) over a desired future\nhorizon. In the most general setting of these types of problems, one or more\nsamples of data across multiple time series can be assigned several concurrent\nfault labels from a finite, known set and the task is to predict the\npossibility of fault occurrence over a desired time horizon. This type of\nproblem is usually accompanied by strong class imbalances where some classes\nare represented by only a few samples. Importantly, in many applications of the\nproblem such as fault prediction and predictive maintenance, it is exactly\nthese rare classes that are of most interest. To address the problem, this\npaper proposes a general approach that utilizes a multi-label recurrent neural\nnetwork with a new cost function that accentuates learning in the imbalanced\nclasses. The proposed algorithm is tested on two public benchmark datasets: an\nindustrial plant dataset from the PHM Society Data Challenge, and a human\nactivity recognition dataset. The results are compared with state-of-the-art\ntechniques for time-series classification and evaluation is performed using the\nF1-score, precision and recall.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:35:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Zhang", "Wenyu", ""], ["Jha", "Devesh K.", ""], ["Laftchiev", "Emil", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2001.10102", "submitter": "Jerome Friedman", "authors": "Jerome H. Friedman", "title": "Predicting Regression Probability Distributions with Imperfect Data\n  Through Optimal Transformations", "comments": "33 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of regression analysis is to predict the value of a numeric outcome\nvariable y given a vector of joint values of other (predictor) variables x.\nUsually a particular x-vector does not specify a repeatable value for y, but\nrather a probability distribution of possible y--values, p(y|x). This\ndistribution has a location, scale and shape, all of which can depend on x, and\nare needed to infer likely values for y given x. Regression methods usually\nassume that training data y-values are perfect numeric realizations from some\nwell behaived p(y|x). Often actual training data y-values are discrete,\ntruncated and/or arbitrary censored. Regression procedures based on an optimal\ntransformation strategy are presented for estimating location, scale and shape\nof p(y|x) as general functions of x, in the possible presence of such imperfect\ntraining data. In addition, validation diagnostics are presented to ascertain\nthe quality of the solutions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:13:29 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Friedman", "Jerome H.", ""]]}, {"id": "2001.10109", "submitter": "Kriton Konstantinidis", "authors": "Alexandros Haliassos, Kriton Konstantinidis, Danilo P. Mandic", "title": "Supervised Learning for Non-Sequential Data: A Canonical Polyadic\n  Decomposition Approach", "comments": "Accepted at IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient modelling of feature interactions underpins supervised learning for\nnon-sequential tasks, characterized by a lack of inherent ordering of features\n(variables). The brute force approach of learning a parameter for each\ninteraction of every order comes at an exponential computational and memory\ncost (Curse of Dimensionality). To alleviate this issue, it has been proposed\nto implicitly represent the model parameters as a tensor, the order of which is\nequal to the number of features; for efficiency, it can be further factorized\ninto a compact Tensor Train (TT) format. However, both TT and other Tensor\nNetworks (TNs), such as Tensor Ring and Hierarchical Tucker, are sensitive to\nthe ordering of their indices (and hence to the features). To establish the\ndesired invariance to feature ordering, we propose to represent the weight\ntensor through the Canonical Polyadic (CP) Decomposition (CPD), and introduce\nthe associated inference and learning algorithms, including suitable\nregularization and initialization schemes. It is demonstrated that the proposed\nCP-based predictor significantly outperforms other TN-based predictors on\nsparse data while exhibiting comparable performance on dense non-sequential\ntasks. Furthermore, for enhanced expressiveness, we generalize the framework to\nallow feature mapping to arbitrarily high-dimensional feature vectors. In\nconjunction with feature vector normalization, this is shown to yield dramatic\nimprovements in performance for dense non-sequential tasks, matching models\nsuch as fully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:38:40 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 09:10:27 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 09:29:17 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Haliassos", "Alexandros", ""], ["Konstantinidis", "Kriton", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2001.10110", "submitter": "Sebastian Grimberg", "authors": "Sebastian Grimberg, Charbel Farhat, Noah Youkilis", "title": "On the stability of projection-based model order reduction for\n  convection-dominated laminar and turbulent flows", "comments": "34 pages", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109681", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature on projection-based nonlinear model order reduction for\nfluid dynamics problems, it is often claimed that due to modal truncation, a\nprojection-based reduced-order model (PROM) does not resolve the dissipative\nregime of the turbulent energy cascade and therefore is numerically unstable.\nEfforts at addressing this claim have ranged from attempting to model the\neffects of the truncated modes to enriching the classical subspace of\napproximation in order to account for the truncated phenomena. This paper\nchallenges this claim. Exploring the relationship between projection-based\nmodel order reduction and semi-discretization and using numerical evidence from\nthree relevant flow problems, it argues in an orderly manner that the real\nculprit behind most if not all reported numerical instabilities of PROMs for\nturbulence and convection-dominated turbulent flow problems is the Galerkin\nframework that has been used for constructing the PROMs. The paper also shows\nthat alternatively, a Petrov-Galerkin framework can be used to construct\nnumerically stable PROMs for convection-dominated laminar as well as turbulent\nflow problems that are numerically stable and accurate, without resorting to\nadditional closure models or tailoring of the subspace of approximation. It\nalso shows that such alternative PROMs deliver significant speedup factors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:39:27 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Grimberg", "Sebastian", ""], ["Farhat", "Charbel", ""], ["Youkilis", "Noah", ""]]}, {"id": "2001.10112", "submitter": "Zhiyu Chen", "authors": "Zhiyu Chen, Haiyan Jia, Jeff Heflin, Brian D. Davison", "title": "Leveraging Schema Labels to Enhance Dataset Search", "comments": "Accepted at the 42nd European Conference on IR Research, ECIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A search engine's ability to retrieve desirable datasets is important for\ndata sharing and reuse. Existing dataset search engines typically rely on\nmatching queries to dataset descriptions. However, a user may not have enough\nprior knowledge to write a query using terms that match with description\ntext.We propose a novel schema label generation model which generates possible\nschema labels based on dataset table content. We incorporate the generated\nschema labels into a mixed ranking model which not only considers the relevance\nbetween the query and dataset metadata but also the similarity between the\nquery and generated schema labels. To evaluate our method on real-world\ndatasets, we create a new benchmark specifically for the dataset retrieval\ntask. Experiments show that our approach can effectively improve the precision\nand NDCG scores of the dataset retrieval task compared with baseline methods.\nWe also test on a collection of Wikipedia tables to show that the features\ngenerated from schema labels can improve the unsupervised and supervised web\ntable retrieval task as well.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 22:41:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Chen", "Zhiyu", ""], ["Jia", "Haiyan", ""], ["Heflin", "Jeff", ""], ["Davison", "Brian D.", ""]]}, {"id": "2001.10119", "submitter": "Chenghui Zhou", "authors": "Chenghui Zhou, Chun-Liang Li, Barnabas Poczos", "title": "Unsupervised Program Synthesis for Images By Sampling Without\n  Replacement", "comments": "Accepted to UAI 2021", "journal-ref": "UAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis has emerged as a successful approach to the image parsing\ntask. Most prior works rely on a two-step scheme involving supervised\npretraining of a Seq2Seq model with synthetic programs followed by\nreinforcement learning (RL) for fine-tuning with real reference images. Fully\nunsupervised approaches promise to train the model directly on the target\nimages without requiring curated pretraining datasets. However, they struggle\nwith the inherent sparsity of meaningful programs in the search space. In this\npaper, we present the first unsupervised algorithm capable of parsing\nconstructive solid geometry (CSG) images into context-free grammar (CFG)\nwithout pretraining via non-differentiable renderer. To tackle the\n\\emph{non-Markovian} sparse reward problem, we combine three key ingredients --\n(i) a grammar-encoded tree LSTM ensuring program validity (ii) entropy\nregularization and (iii) sampling without replacement from the CFG syntax tree.\nEmpirically, our algorithm recovers meaningful programs in large search spaces\n(up to $3.8 \\times 10^{28}$). Further, even though our approach is fully\nunsupervised, it generalizes better than supervised methods on the synthetic 2D\nCSG dataset. On the 2D computer aided design (CAD) dataset, our approach\nsignificantly outperforms the supervised pretrained model and is competitive to\nthe refined model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:30:33 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 21:11:14 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhou", "Chenghui", ""], ["Li", "Chun-Liang", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2001.10122", "submitter": "Seyed Mohammad Asghari", "authors": "Seyed Mohammad Asghari, Yi Ouyang, and Ashutosh Nayyar", "title": "Regret Bounds for Decentralized Learning in Cooperative Multi-Agent\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL)\nprimarily due to the dynamical environments and the decentralized information\namong agents. We attempt to solve this challenge in the context of\ndecentralized learning in multi-agent linear-quadratic (LQ) dynamical systems.\nWe begin with a simple setup consisting of two agents and two dynamically\ndecoupled stochastic linear systems, each system controlled by an agent. The\nsystems are coupled through a quadratic cost function. When both systems'\ndynamics are unknown and there is no communication among the agents, we show\nthat no learning policy can generate sub-linear in $T$ regret, where $T$ is the\ntime horizon. When only one system's dynamics are unknown and there is\none-directional communication from the agent controlling the unknown system to\nthe other agent, we propose a MARL algorithm based on the construction of an\nauxiliary single-agent LQ problem. The auxiliary single-agent problem in the\nproposed MARL algorithm serves as an implicit coordination mechanism among the\ntwo learning agents. This allows the agents to achieve a regret within\n$O(\\sqrt{T})$ of the regret of the auxiliary single-agent problem.\nConsequently, using existing results for single-agent LQ regret, our algorithm\nprovides a $\\tilde{O}(\\sqrt{T})$ regret bound. (Here $\\tilde{O}(\\cdot)$ hides\nconstants and logarithmic factors). Our numerical experiments indicate that\nthis bound is matched in practice. From the two-agent problem, we extend our\nresults to multi-agent LQ systems with certain communication patterns.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:37:41 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Asghari", "Seyed Mohammad", ""], ["Ouyang", "Yi", ""], ["Nayyar", "Ashutosh", ""]]}, {"id": "2001.10133", "submitter": "Ping Xu", "authors": "Ping Xu, Yue Wang, Xiang Chen, Zhi Tian", "title": "COKE: Communication-Censored Decentralized Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the decentralized optimization and learning problem where\nmultiple interconnected agents aim to learn an optimal decision function\ndefined over a reproducing kernel Hilbert space by jointly minimizing a global\nobjective function, with access to their own locally observed dataset. As a\nnon-parametric approach, kernel learning faces a major challenge in distributed\nimplementation: the decision variables of local objective functions are\ndata-dependent and thus cannot be optimized under the decentralized consensus\nframework without any raw data exchange among agents. To circumvent this major\nchallenge, we leverage the random feature (RF) approximation approach to enable\nconsensus on the function modeled in the RF space by data-independent\nparameters across different agents. We then design an iterative algorithm,\ntermed DKLA, for fast-convergent implementation via ADMM. Based on DKLA, we\nfurther develop a communication-censored kernel learning (COKE) algorithm that\nreduces the communication load of DKLA by preventing an agent from transmitting\nat every iteration unless its local updates are deemed informative. Theoretical\nresults in terms of linear convergence guarantee and generalization performance\nanalysis of DKLA and COKE are provided. Comprehensive tests on both synthetic\nand real datasets are conducted to verify the communication efficiency and\nlearning effectiveness of COKE.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 01:05:57 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 00:52:48 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Xu", "Ping", ""], ["Wang", "Yue", ""], ["Chen", "Xiang", ""], ["Tian", "Zhi", ""]]}, {"id": "2001.10155", "submitter": "Junyu Chen", "authors": "Junyu Chen, Eric C. Frey", "title": "Medical Image Segmentation via Unsupervised Convolutional Neural Network", "comments": "In Medical Imaging with Deep Learning (2020)", "journal-ref": null, "doi": null, "report-no": "MIDL/2020/ExtendedAbstract/XrbnSCv4LU", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the majority of the learning-based segmentation methods, a large quantity\nof high-quality training data is required. In this paper, we present a novel\nlearning-based segmentation model that could be trained semi- or un-\nsupervised. Specifically, in the unsupervised setting, we parameterize the\nActive contour without edges (ACWE) framework via a convolutional neural\nnetwork (ConvNet), and optimize the parameters of the ConvNet using a\nself-supervised method. In another setting (semi-supervised), the auxiliary\nsegmentation ground truth is used during training. We show that the method\nprovides fast and high-quality bone segmentation in the context of\nsingle-photon emission computed tomography (SPECT) image.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 03:56:42 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 19:29:41 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 03:35:21 GMT"}, {"version": "v4", "created": "Mon, 6 Jul 2020 16:09:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Chen", "Junyu", ""], ["Frey", "Eric C.", ""]]}, {"id": "2001.10156", "submitter": "Mehrdad Yousefzadeh", "authors": "Rayan Kanfar, Obai Shaikh, Mehrdad Yousefzadeh, Tapan Mukerji", "title": "Real-Time Well Log Prediction From Drilling Data Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.2523/IPTC-19693-MS", "report-no": null, "categories": "physics.geo-ph cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective is to study the feasibility of predicting subsurface rock\nproperties in wells from real-time drilling data. Geophysical logs, namely,\ndensity, porosity and sonic logs are of paramount importance for subsurface\nresource estimation and exploitation. These wireline petro-physical\nmeasurements are selectively deployed as they are expensive to acquire;\nmeanwhile, drilling information is recorded in every drilled well. Hence a\npredictive tool for wireline log prediction from drilling data can help\nmanagement make decisions about data acquisition, especially for delineation\nand production wells. This problem is non-linear with strong ineractions\nbetween drilling parameters; hence the potential for deep learning to address\nthis problem is explored. We present a workflow for data augmentation and\nfeature engineering using Distance-based Global Sensitivity Analysis. We\npropose an Inception-based Convolutional Neural Network combined with a\nTemporal Convolutional Network as the deep learning model. The model is\ndesigned to learn both low and high frequency content of the data. 12 wells\nfrom the Equinor dataset for the Volve field in the North Sea are used for\nlearning. The model predictions not only capture trends but are also physically\nconsistent across density, porosity, and sonic logs. On the test data, the mean\nsquare error reaches a low value of 0.04 but the correlation coefficient\nplateaus around 0.6. The model is able however to differentiate between\ndifferent types of rocks such as cemented sandstone, unconsolidated sands, and\nshale.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 03:57:31 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Kanfar", "Rayan", ""], ["Shaikh", "Obai", ""], ["Yousefzadeh", "Mehrdad", ""], ["Mukerji", "Tapan", ""]]}, {"id": "2001.10167", "submitter": "Lei Chen", "authors": "Lei Chen, Le Wu, Richang Hong, Kun Zhang, Meng Wang", "title": "Revisiting Graph based Collaborative Filtering: A Linear Residual Graph\n  Convolutional Network Approach", "comments": "The updated version is publised in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) are state-of-the-art graph based\nrepresentation learning models by iteratively stacking multiple layers of\nconvolution aggregation operations and non-linear activation operations.\nRecently, in Collaborative Filtering (CF) based Recommender Systems (RS), by\ntreating the user-item interaction behavior as a bipartite graph, some\nresearchers model higher-layer collaborative signals with GCNs. These GCN based\nrecommender models show superior performance compared to traditional works.\nHowever, these models suffer from training difficulty with non-linear\nactivations for large user-item graphs. Besides, most GCN based models could\nnot model deeper layers due to the over smoothing effect with the graph\nconvolution operation. In this paper, we revisit GCN based CF models from two\naspects. First, we empirically show that removing non-linearities would enhance\nrecommendation performance, which is consistent with the theories in simple\ngraph convolutional networks. Second, we propose a residual network structure\nthat is specifically designed for CF with user-item interaction modeling, which\nalleviates the over smoothing problem in graph convolution aggregation\noperation with sparse user-item interaction data. The proposed model is a\nlinear model and it is easy to train, scale to large datasets, and yield better\nefficiency and effectiveness on two real datasets. We publish the source code\nat https://github.com/newlei/LRGCCF.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:41:25 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Chen", "Lei", ""], ["Wu", "Le", ""], ["Hong", "Richang", ""], ["Zhang", "Kun", ""], ["Wang", "Meng", ""]]}, {"id": "2001.10178", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "An Adaptive and Near Parameter-free Evolutionary Computation Approach\n  Towards True Automation in AutoML", "comments": "18 pages (single column), 2 figures", "journal-ref": null, "doi": "10.1109/CEC48606.2020.9185770", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common claim of evolutionary computation methods is that they can achieve\ngood results without the need for human intervention. However, one criticism of\nthis is that there are still hyperparameters which must be tuned in order to\nachieve good performance. In this work, we propose a near \"parameter-free\"\ngenetic programming approach, which adapts the hyperparameter values throughout\nevolution without ever needing to be specified manually. We apply this to the\narea of automated machine learning (by extending TPOT), to produce pipelines\nwhich can effectively be claimed to be free from human input, and show that the\nresults are competitive with existing state-of-the-art which use hand-selected\nhyperparameter values. Pipelines begin with a randomly chosen estimator and\nevolve to competitive pipelines automatically. This work moves towards a truly\nautomatic approach to AutoML.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:44:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.10188", "submitter": "Muhammad Shahzad", "authors": "Muhammad Shahzad, Arif Iqbal Umar, Muazzam A. Khan, Syed Hamad\n  Shirazi, Zakir Khan, and Waqas Yousaf", "title": "Robust Method for Semantic Segmentation of Whole-Slide Blood Cell\n  Microscopic Image", "comments": "13 pages, 13 figures", "journal-ref": "Volume 2020, Article ID 4015323, 13 pages", "doi": "10.1155/2020/4015323", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous works on segmentation of SEM (scanning electron microscope) blood\ncell image ignore the semantic segmentation approach of whole-slide blood cell\nsegmentation. In the proposed work, we address the problem of whole-slide blood\ncell segmentation using the semantic segmentation approach. We design a novel\nconvolutional encoder-decoder framework along with VGG-16 as the pixel-level\nfeature extraction model. -e proposed framework comprises 3 main steps: First,\nall the original images along with manually generated ground truth masks of\neach blood cell type are passed through the preprocessing stage. In the\npreprocessing stage, pixel-level labeling, RGB to grayscale conversion of\nmasked image and pixel fusing, and unity mask generation are performed. After\nthat, VGG16 is loaded into the system, which acts as a pretrained pixel-level\nfeature extraction model. In the third step, the training process is initiated\non the proposed model. We have evaluated our network performance on three\nevaluation metrics. We obtained outstanding results with respect to classwise,\nas well as global and mean accuracies. Our system achieved classwise accuracies\nof 97.45%, 93.34%, and 85.11% for RBCs, WBCs, and platelets, respectively,\nwhile global and mean accuracies remain 97.18% and 91.96%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 06:32:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Shahzad", "Muhammad", ""], ["Umar", "Arif Iqbal", ""], ["Khan", "Muazzam A.", ""], ["Shirazi", "Syed Hamad", ""], ["Khan", "Zakir", ""], ["Yousaf", "Waqas", ""]]}, {"id": "2001.10189", "submitter": "Benjamin Sliwa", "authors": "Benjamin Sliwa and Nico Piatkowski and Christian Wietfeld", "title": "LIMITS: Lightweight Machine Learning for IoT Systems with Resource\n  Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting big data knowledge on small devices will pave the way for building\ntruly cognitive Internet of Things (IoT) systems. Although machine learning has\nled to great advancements for IoT-based data analytics, there remains a huge\nmethodological gap for the deployment phase of trained machine learning models.\nFor given resource-constrained platforms such as Microcontroller Units (MCUs),\nmodel choice and parametrization are typically performed based on heuristics or\nanalytical models. However, these approaches are only able to provide rough\nestimates of the required system resources as they do not consider the\ninterplay of hardware, compiler specific optimizations, and code dependencies.\nIn this paper, we present the novel open source framework LIghtweight Machine\nlearning for IoT Systems (LIMITS), which applies a platform-in-the-loop\napproach explicitly considering the actual compilation toolchain of the target\nIoT platform. LIMITS focuses on high level tasks such as experiment automation,\nplatform-specific code generation, and sweet spot determination. The solid\nfoundations of validated low-level model implementations are provided by the\ncoupled well-established data analysis framework Waikato Environment for\nKnowledge Analysis (WEKA). We apply and validate LIMITS in two case studies\nfocusing on cellular data rate prediction and radio-based vehicle\nclassification, where we compare different learning models and real world IoT\nplatforms with memory constraints from 16 kB to 4 MB and demonstrate its\npotential to catalyze the development of machine learning enabled IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 06:34:35 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sliwa", "Benjamin", ""], ["Piatkowski", "Nico", ""], ["Wietfeld", "Christian", ""]]}, {"id": "2001.10190", "submitter": "Tomohiko Nakamura", "authors": "Tomohiko Nakamura and Hiroshi Saruwatari", "title": "Time-Domain Audio Source Separation Based on Wave-U-Net Combined with\n  Discrete Wavelet Transform", "comments": "5 pages, to appear in IEEE International Conference on Acoustics,\n  Speech, and Signal Processing 2020 (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a time-domain audio source separation method using down-sampling\n(DS) and up-sampling (US) layers based on a discrete wavelet transform (DWT).\nThe proposed method is based on one of the state-of-the-art deep neural\nnetworks, Wave-U-Net, which successively down-samples and up-samples feature\nmaps. We find that this architecture resembles that of multiresolution\nanalysis, and reveal that the DS layers of Wave-U-Net cause aliasing and may\ndiscard information useful for the separation. Although the effects of these\nproblems may be reduced by training, to achieve a more reliable source\nseparation method, we should design DS layers capable of overcoming the\nproblems. With this belief, focusing on the fact that the DWT has an\nanti-aliasing filter and the perfect reconstruction property, we design the\nproposed layers. Experiments on music source separation show the efficacy of\nthe proposed method and the importance of simultaneously considering the\nanti-aliasing filters and the perfect reconstruction property.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 06:43:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Nakamura", "Tomohiko", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "2001.10208", "submitter": "Yichuan Charlie Tang", "authors": "Yichuan Charlie Tang", "title": "Towards Learning Multi-agent Negotiations via Self-Play", "comments": "Autonomous Driving Workshop, IEEE International Conference on\n  Computer Vision (ICCV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sophisticated, robust, and safe sequential decisions is at the heart\nof intelligent systems. This is especially critical for planning in complex\nmulti-agent environments, where agents need to anticipate other agents'\nintentions and possible future actions. Traditional methods formulate the\nproblem as a Markov Decision Process, but the solutions often rely on various\nassumptions and become brittle when presented with corner cases. In contrast,\ndeep reinforcement learning (Deep RL) has been very effective at finding\npolicies by simultaneously exploring, interacting, and learning from\nenvironments. Leveraging the powerful Deep RL paradigm, we demonstrate that an\niterative procedure of self-play can create progressively more diverse\nenvironments, leading to the learning of sophisticated and robust multi-agent\npolicies. We demonstrate this in a challenging multi-agent simulation of\nmerging traffic, where agents must interact and negotiate with others in order\nto successfully merge on or off the road. While the environment starts off\nsimple, we increase its complexity by iteratively adding an increasingly\ndiverse set of agents to the agent \"zoo\" as training progresses. Qualitatively,\nwe find that through self-play, our policies automatically learn interesting\nbehaviors such as defensive driving, overtaking, yielding, and the use of\nsignal lights to communicate intentions to other agents. In addition,\nquantitatively, we show a dramatic improvement of the success rate of merging\nmaneuvers from 63% to over 98%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 08:37:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tang", "Yichuan Charlie", ""]]}, {"id": "2001.10218", "submitter": "Hendrik Schr\\\"oter", "authors": "Hendrik Schr\\\"oter, Tobias Rosenkranz, Alberto N. Escalante B., Marc\n  Aubreville, Andreas Maier", "title": "CLCNet: Deep learning-based Noise Reduction for Hearing Aids using\n  Complex Linear Coding", "comments": "5 Pages, ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise reduction is an important part of modern hearing aids and is included\nin most commercially available devices. Deep learning-based state-of-the-art\nalgorithms, however, either do not consider real-time and frequency resolution\nconstrains or result in poor quality under very noisy conditions. To improve\nmonaural speech enhancement in noisy environments, we propose CLCNet, a\nframework based on complex valued linear coding. First, we define complex\nlinear coding (CLC) motivated by linear predictive coding (LPC) that is applied\nin the complex frequency domain. Second, we propose a framework that\nincorporates complex spectrogram input and coefficient output. Third, we define\na parametric normalization for complex valued spectrograms that complies with\nlow-latency and on-line processing. Our CLCNet was evaluated on a mixture of\nthe EUROM database and a real-world noise dataset recorded with hearing aids\nand compared to traditional real-valued Wiener-Filter gains.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:08:35 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Schr\u00f6ter", "Hendrik", ""], ["Rosenkranz", "Tobias", ""], ["B.", "Alberto N. Escalante", ""], ["Aubreville", "Marc", ""], ["Maier", "Andreas", ""]]}, {"id": "2001.10220", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Lawrence De Mol, Tim Verbelen and Bart Dhoedt", "title": "Learning to Catch Piglets in Flight", "comments": "Fast Neural Perception and Learning for Intelligent Vehicles and\n  Robotics workshop at IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Catching objects in-flight is an outstanding challenge in robotics. In this\npaper, we present a closed-loop control system fusing data from two sensor\nmodalities: an RGB-D camera and a radar. To develop and test our method, we\nstart with an easy to identify object: a stuffed Piglet. We implement and\ncompare two approaches to detect and track the object, and to predict the\ninterception point. A baseline model uses colour filtering for locating the\nthrown object in the environment, while the interception point is predicted\nusing a least squares regression over the physical ballistic trajectory\nequations. A deep learning based method uses artificial neural networks for\nboth object detection and interception point prediction. We show that we are\nable to successfully catch Piglet in 80% of the cases with our deep learning\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:13:17 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["De Mol", "Lawrence", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2001.10237", "submitter": "Jialin Dong", "authors": "Jialin Dong, Jun Zhang, Yuanming Shi, Jessie Hui Wang", "title": "Faster Activity and Data Detection in Massive Random Access: A\n  Multi-armed Bandit Approach", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the grant-free random access with massive IoT\ndevices. By embedding the data symbols in the signature sequences, joint device\nactivity detection and data decoding can be achieved, which, however,\nsignificantly increases the computational complexity. Coordinate descent\nalgorithms that enjoy a low per-iteration complexity have been employed to\nsolve the detection problem, but previous works typically employ a random\ncoordinate selection policy which leads to slow convergence. In this paper, we\ndevelop multi-armed bandit approaches for more efficient detection via\ncoordinate descent, which make a delicate trade-off between exploration and\nexploitation in coordinate selection. Specifically, we first propose a bandit\nbased strategy, i.e., Bernoulli sampling, to speed up the convergence rate of\ncoordinate descent, by learning which coordinates will result in more\naggressive descent of the objective function. To further improve the\nconvergence rate, an inner multi-armed bandit problem is established to learn\nthe exploration policy of Bernoulli sampling. Both convergence rate analysis\nand simulation results are provided to show that the proposed bandit based\nalgorithms enjoy faster convergence rates with a lower time complexity compared\nwith the state-of-the-art algorithm. Furthermore, our proposed algorithms are\napplicable to different scenarios, e.g., massive random access with\nlow-precision analog-to-digital converters (ADCs).\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:00:25 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Dong", "Jialin", ""], ["Zhang", "Jun", ""], ["Shi", "Yuanming", ""], ["Wang", "Jessie Hui", ""]]}, {"id": "2001.10238", "submitter": "Antoine Plumerault", "authors": "Antoine Plumerault, Herv\\'e Le Borgne, C\\'eline Hudelot", "title": "Controlling generative models with continuous factors of variations", "comments": "Accepted as a poster presentation at the International Conference for\n  Learning Representations (ICLR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep generative models are able to provide photo-realistic images as\nwell as visual or textual content embeddings useful to address various tasks of\ncomputer vision and natural language processing. Their usefulness is\nnevertheless often limited by the lack of control over the generative process\nor the poor understanding of the learned representation. To overcome these\nmajor issues, very recent work has shown the interest of studying the semantics\nof the latent space of generative models. In this paper, we propose to advance\non the interpretability of the latent space of generative models by introducing\na new method to find meaningful directions in the latent space of any\ngenerative model along which we can move to control precisely specific\nproperties of the generated image like the position or scale of the object in\nthe image. Our method does not require human annotations and is particularly\nwell suited for the search of directions encoding simple transformations of the\ngenerated image, such as translation, zoom or color variations. We demonstrate\nthe effectiveness of our method qualitatively and quantitatively, both for GANs\nand variational auto-encoders.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:04:04 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Plumerault", "Antoine", ""], ["Borgne", "Herv\u00e9 Le", ""], ["Hudelot", "C\u00e9line", ""]]}, {"id": "2001.10249", "submitter": "Milad Ramezani", "authors": "Milad Ramezani, Georgi Tinchev, Egor Iuganov and Maurice Fallon", "title": "Online LiDAR-SLAM for Legged Robots with Robust Registration and\n  Deep-Learned Loop Closure", "comments": "8 pages, 9 figures, accepted for IEEE International Conference on\n  Robotics and Automation (ICRA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a factor-graph LiDAR-SLAM system which incorporates\na state-of-the-art deeply learned feature-based loop closure detector to enable\na legged robot to localize and map in industrial environments. These facilities\ncan be badly lit and comprised of indistinct metallic structures, thus our\nsystem uses only LiDAR sensing and was developed to run on the quadruped\nrobot's navigation PC. Point clouds are accumulated using an inertial-kinematic\nstate estimator before being aligned using ICP registration. To close loops we\nuse a loop proposal mechanism which matches individual segments between clouds.\nWe trained a descriptor offline to match these segments. The efficiency of our\nmethod comes from carefully designing the network architecture to minimize the\nnumber of parameters such that this deep learning method can be deployed in\nreal-time using only the CPU of a legged robot, a major contribution of this\nwork. The set of odometry and loop closure factors are updated using pose graph\noptimization. Finally we present an efficient risk alignment prediction method\nwhich verifies the reliability of the registrations. Experimental results at an\nindustrial facility demonstrated the robustness and flexibility of our system,\nincluding autonomous following paths derived from the SLAM map.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:30:20 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ramezani", "Milad", ""], ["Tinchev", "Georgi", ""], ["Iuganov", "Egor", ""], ["Fallon", "Maurice", ""]]}, {"id": "2001.10269", "submitter": "Debo Cheng", "authors": "Debo Cheng (1), Jiuyong Li (1), Lin Liu (1), Jixue Liu (1), Kui Yu\n  (2), and Thuc Duy Le (1) ((1) School of Information Technology and\n  Mathematical Sciences, University of South Australia (2) School of Computer\n  Science and Information Engineering, Hefei University of Technology)", "title": "Causal query in observational data with hidden variables", "comments": "8 pages and 7 figures. The paper has been accepted by ECAI2020. We\n  have updated the proof of the Theorem 1 and removed Theorem 2 from the\n  conference version", "journal-ref": null, "doi": "10.3233/FAIA200390", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the problem of causal query in observational data with\nhidden variables, with the aim of seeking the change of an outcome when\n\"manipulating\" a variable while given a set of plausible confounding variables\nwhich affect the manipulated variable and the outcome. Such an \"experiment on\ndata\" to estimate the causal effect of the manipulated variable is useful for\nvalidating an experiment design using historical data or for exploring\nconfounders when studying a new relationship. However, existing data-driven\nmethods for causal effect estimation face some major challenges, including poor\nscalability with high dimensional data, low estimation accuracy due to\nheuristics used by the global causal structure learning algorithms, and the\nassumption of causal sufficiency when hidden variables are inevitable in data.\nIn this paper, we develop a theorem for using local search to find a superset\nof the adjustment (or confounding) variables for causal effect estimation from\nobservational data under a realistic pretreatment assumption. The theorem\nensures that the unbiased estimate of causal effect is included in the set of\ncausal effects estimated by the superset of adjustment variables. Based on the\ndeveloped theorem, we propose a data-driven algorithm for causal query.\nExperiments show that the proposed algorithm is faster and produces better\ncausal effect estimation than an existing data-driven causal effect estimation\nmethod with hidden variables. The causal effects estimated by the proposed\nalgorithm are as accurate as those by the state-of-the-art methods using domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:23:26 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 05:14:20 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 06:52:09 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 05:11:56 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cheng", "Debo", ""], ["Li", "Jiuyong", ""], ["Liu", "Lin", ""], ["Liu", "Jixue", ""], ["Yu", "Kui", ""], ["Le", "Thuc Duy", ""]]}, {"id": "2001.10280", "submitter": "Sandeep Pandey", "authors": "Sandeep Pandey, J\\\"org Schumacher", "title": "Reservoir computing model of two-dimensional turbulent convection", "comments": "16 pages, 12 figures", "journal-ref": "Phys. Rev. Fluids 5, 113506 (2020)", "doi": "10.1103/PhysRevFluids.5.113506", "report-no": null, "categories": "physics.flu-dyn cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is applied to model the large-scale evolution and the\nresulting low-order turbulence statistics of a two-dimensional turbulent\nRayleigh-B\\'{e}nard convection flow at a Rayleigh number ${\\rm Ra}=10^7$ and a\nPrandtl number ${\\rm Pr}=7$ in an extended domain with an aspect ratio of 6.\nOur data-driven approach which is based on a long-term direct numerical\nsimulation of the convection flow comprises a two-step procedure. (1) Reduction\nof the original simulation data by a Proper Orthogonal Decomposition (POD)\nsnapshot analysis and subsequent truncation to the first 150 POD modes which\nare associated with the largest total energy amplitudes. (2) Setup and\noptimization of a reservoir computing model to describe the dynamical evolution\nof these 150 degrees of freedom and thus the large-scale evolution of the\nconvection flow. The quality of the prediction of the reservoir computing model\nis comprehensively tested. At the core of the model is the reservoir, a very\nlarge sparse random network charcterized by the spectral radius of the\ncorresponding adjacency matrix and a few further hyperparameters which are\nvaried to investigate the quality of the prediction. Our work demonstrates that\nthe reservoir computing model is capable to model the large-scale structure and\nlow-order statistics of turbulent convection which can open new avenues for\nmodeling mesoscale convection processes in larger circulation models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:49:25 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 20:34:18 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Pandey", "Sandeep", ""], ["Schumacher", "J\u00f6rg", ""]]}, {"id": "2001.10283", "submitter": "Matias Bilkis", "authors": "M. Bilkis, M. Rosati, R. Morral Yepes and J. Calsamiglia", "title": "Real-time calibration of coherent-state receivers: learning by trial and\n  error", "comments": "14+3 pages, 11 figures", "journal-ref": "Phys. Rev. Research 2, 033295 (2020)", "doi": "10.1103/PhysRevResearch.2.033295", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal discrimination of coherent states of light with current\ntechnology is a key problem in classical and quantum communication, whose\nsolution would enable the realization of efficient receivers for long-distance\ncommunications in free-space and optical fiber channels. In this article, we\nshow that reinforcement learning (RL) protocols allow an agent to learn\nnear-optimal coherent-state receivers made of passive linear optics,\nphotodetectors and classical adaptive control. Each agent is trained and tested\nin real time over several runs of independent discrimination experiments and\nhas no knowledge about the energy of the states nor the receiver setup nor the\nquantum-mechanical laws governing the experiments. Based exclusively on the\nobserved photodetector outcomes, the agent adaptively chooses among a set of ~3\n10^3 possible receiver setups, and obtains a reward at the end of each\nexperiment if its guess is correct. At variance with previous applications of\nRL in quantum physics, the information gathered in each run is intrinsically\nstochastic and thus insufficient to evaluate exactly the performance of the\nchosen receiver. Nevertheless, we present families of agents that: (i) discover\na receiver beating the best Gaussian receiver after ~3 10^2 experiments; (ii)\nsurpass the cumulative reward of the best Gaussian receiver after ~10^3\nexperiments; (iii) simultaneously discover a near-optimal receiver and attain\nits cumulative reward after ~10^5 experiments. Our results show that RL\ntechniques are suitable for on-line control of quantum receivers and can be\nemployed for long-distance communications over potentially unknown channels.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:56:20 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Bilkis", "M.", ""], ["Rosati", "M.", ""], ["Yepes", "R. Morral", ""], ["Calsamiglia", "J.", ""]]}, {"id": "2001.10284", "submitter": "Prashan Madumal", "authors": "Prashan Madumal, Tim Miller, Liz Sonenberg, Frank Vetere", "title": "Distal Explanations for Model-free Explainable Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and evaluate a distal explanation model for\nmodel-free reinforcement learning agents that can generate explanations for\n`why' and `why not' questions. Our starting point is the observation that\ncausal models can generate opportunity chains that take the form of `A enables\nB and B causes C'. Using insights from an analysis of 240 explanations\ngenerated in a human-agent experiment, we define a distal explanation model\nthat can analyse counterfactuals and opportunity chains using decision trees\nand causal models. A recurrent neural network is employed to learn opportunity\nchains, and decision trees are used to improve the accuracy of task prediction\nand the generated counterfactuals. We computationally evaluate the model in 6\nreinforcement learning benchmarks using different reinforcement learning\nalgorithms. From a study with 90 human participants, we show that our distal\nexplanation model results in improved outcomes over three scenarios compared\nwith two baseline explanation models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:57:38 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 09:46:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Madumal", "Prashan", ""], ["Miller", "Tim", ""], ["Sonenberg", "Liz", ""], ["Vetere", "Frank", ""]]}, {"id": "2001.10290", "submitter": "Markus P\\\"uschel", "authors": "Markus P\\\"uschel and Chris Wendler", "title": "Discrete Signal Processing with Set Functions", "comments": "16 pages, submitted for publication", "journal-ref": "IEEE Transactions on Signal Processing, Vol. 69, pp. 1039-1053,\n  2021", "doi": "10.1109/TSP.2020.3046972", "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set functions are functions (or signals) indexed by the powerset (set of all\nsubsets) of a finite set N. They are fundamental and ubiquitous in many\napplication domains and have been used, for example, to formally describe or\nquantify loss functions for semantic image segmentation, the informativeness of\nsensors in sensor networks the utility of sets of items in recommender systems,\ncooperative games in game theory, or bidders in combinatorial auctions. In\nparticular, the subclass of submodular functions occurs in many optimization\nand machine learning problems. In this paper, we derive discrete-set signal\nprocessing (SP), a novel shift-invariant linear signal processing framework for\nset functions. Discrete-set SP considers different notions of shift obtained\nfrom set union and difference operations. For each shift it provides associated\nnotions of shift-invariant filters, convolution, Fourier transform, and\nfrequency response. We provide intuition for our framework using the concept of\ngeneralized coverage function that we define, identify multivariate mutual\ninformation as a special case of a discrete-set spectrum, and motivate\nfrequency ordering. Our work brings a new set of tools for analyzing and\nprocessing set functions, and, in particular, for dealing with their\nexponential nature. We show two prototypical applications and experiments:\ncompression in submodular function optimization and sampling for preference\nelicitation in combinatorial auctions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:19:57 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 09:10:41 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["P\u00fcschel", "Markus", ""], ["Wendler", "Chris", ""]]}, {"id": "2001.10318", "submitter": "Nikolaos Nikolaou", "authors": "Nikolaos Nikolaou, Henry Reeve, Gavin Brown", "title": "Margin Maximization as Lossless Maximal Compression", "comments": "19 pages Main Paper + 7 pages Supplementary Material, 7 Figures,\n  Submitted to the Machine Learning journal (11/11/19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ultimate goal of a supervised learning algorithm is to produce models\nconstructed on the training data that can generalize well to new examples. In\nclassification, functional margin maximization -- correctly classifying as many\ntraining examples as possible with maximal confidence --has been known to\nconstruct models with good generalization guarantees. This work gives an\ninformation-theoretic interpretation of a margin maximizing model on a\nnoiseless training dataset as one that achieves lossless maximal compression of\nsaid dataset -- i.e. extracts from the features all the useful information for\npredicting the label and no more. The connection offers new insights on\ngeneralization in supervised machine learning, showing margin maximization as a\nspecial case (that of classification) of a more general principle and explains\nthe success and potential limitations of popular learning algorithms like\ngradient boosting. We support our observations with theoretical arguments and\nempirical evidence and identify interesting directions for future work.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 13:40:22 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Nikolaou", "Nikolaos", ""], ["Reeve", "Henry", ""], ["Brown", "Gavin", ""]]}, {"id": "2001.10335", "submitter": "Georgios Leontidis", "authors": "Mamatha Thota, Stefanos Kollias, Mark Swainson, Georgios Leontidis", "title": "Multi-Source Deep Domain Adaptation for Quality Control in Retail Food\n  Packaging", "comments": "8 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retail food packaging contains information which informs choice and can be\nvital to consumer health, including product name, ingredients list, nutritional\ninformation, allergens, preparation guidelines, pack weight, storage and shelf\nlife information (use-by / best before dates). The presence and accuracy of\nsuch information is critical to ensure a detailed understanding of the product\nand to reduce the potential for health risks. Consequently, erroneous or\nillegible labeling has the potential to be highly detrimental to consumers and\nmany other stakeholders in the supply chain. In this paper, a multi-source deep\nlearning-based domain adaptation system is proposed and tested to identify and\nverify the presence and legibility of use-by date information from food\npackaging photos taken as part of the validation process as the products pass\nalong the food production line. This was achieved by improving the\ngeneralization of the techniques via making use of multi-source datasets in\norder to extract domain-invariant representations for all domains and aligning\ndistribution of all pairs of source and target domains in a common feature\nspace, along with the class boundaries. The proposed system performed very well\nin the conducted experiments, for automating the verification process and\nreducing labeling errors that could otherwise threaten public health and\ncontravene legal requirements for food packaging information and accuracy.\nComprehensive experiments on our food packaging datasets demonstrate that the\nproposed multi-source deep domain adaptation method significantly improves the\nclassification accuracy and therefore has great potential for application and\nbeneficial impact in food manufacturing control systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:16:58 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Thota", "Mamatha", ""], ["Kollias", "Stefanos", ""], ["Swainson", "Mark", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2001.10337", "submitter": "Michael Bloodgood", "authors": "Thomas Orth and Michael Bloodgood", "title": "Early Forecasting of Text Classification Accuracy and F-Measure with\n  Active Learning", "comments": "8 pages, 9 figures, 2 tables; published in Proceedings of the IEEE\n  14th International Conference on Semantic Computing (ICSC), San Diego, CA,\n  USA, pages 77-84, February 2020", "journal-ref": "In Proceedings of the 2020 IEEE 14th International Conference on\n  Semantic Computing (ICSC), pages 77-84, San Diego, CA, USA, February 2020.\n  IEEE", "doi": "10.1109/ICSC.2020.00018", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When creating text classification systems, one of the major bottlenecks is\nthe annotation of training data. Active learning has been proposed to address\nthis bottleneck using stopping methods to minimize the cost of data annotation.\nAn important capability for improving the utility of stopping methods is to\neffectively forecast the performance of the text classification models.\nForecasting can be done through the use of logarithmic models regressed on some\nportion of the data as learning is progressing. A critical unexplored question\nis what portion of the data is needed for accurate forecasting. There is a\ntension, where it is desirable to use less data so that the forecast can be\nmade earlier, which is more useful, versus it being desirable to use more data,\nso that the forecast can be more accurate. We find that when using active\nlearning it is even more important to generate forecasts earlier so as to make\nthem more useful and not waste annotation effort. We investigate the difference\nin forecasting difficulty when using accuracy and F-measure as the text\nclassification system performance metrics and we find that F-measure is more\ndifficult to forecast. We conduct experiments on seven text classification\ndatasets in different semantic domains with different characteristics and with\nthree different base machine learning algorithms. We find that forecasting is\neasiest for decision tree learning, moderate for Support Vector Machines, and\nmost difficult for neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:27:33 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 08:59:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Orth", "Thomas", ""], ["Bloodgood", "Michael", ""]]}, {"id": "2001.10338", "submitter": "Wei Pang Xubu", "authors": "Wei Pang", "title": "Short Text Classification via Term Graph", "comments": "9 pages, 15 figures, Short Text Classification, Term Graph", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text classi cation is a method for classifying short sentence with\nprede ned labels. However, short text is limited in shortness in text length\nthat leads to a challenging problem of sparse features. Most of existing\nmethods treat each short sentences as independently and identically distributed\n(IID), local context only in the sentence itself is focused and the relational\ninformation between sentences are lost. To overcome these limitations, we\npropose a PathWalk model that combine the strength of graph networks and short\nsentences to solve the sparseness of short text. Experimental results on four\ndifferent available datasets show that our PathWalk method achieves the\nstate-of-the-art results, demonstrating the efficiency and robustness of graph\nnetworks for short text classification.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:32:13 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pang", "Wei", ""]]}, {"id": "2001.10340", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Purvi Goel, Raviraj Joshi", "title": "Deep Learning for Hindi Text Classification: A Comparison", "comments": "Accepted at International Conference on Intelligent Human Computer\n  Interaction(IHCI) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-44689-5_9", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) and especially natural language text\nanalysis have seen great advances in recent times. Usage of deep learning in\ntext processing has revolutionized the techniques for text processing and\nachieved remarkable results. Different deep learning architectures like CNN,\nLSTM, and very recent Transformer have been used to achieve state of the art\nresults variety on NLP tasks. In this work, we survey a host of deep learning\narchitectures for text classification tasks. The work is specifically concerned\nwith the classification of Hindi text. The research in the classification of\nmorphologically rich and low resource Hindi language written in Devanagari\nscript has been limited due to the absence of large labeled corpus. In this\nwork, we used translated versions of English data-sets to evaluate models based\non CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based\non BERT and LASER are also compared to evaluate their effectiveness for the\nHindi language. The paper also serves as a tutorial for popular text\nclassification techniques.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 09:29:12 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Goel", "Purvi", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2001.10341", "submitter": "Ning Yang", "authors": "Huanrui Luo, Ning Yang, Philip S. Yu", "title": "Hybrid Deep Embedding for Recommendations with Dynamic Aspect-Level\n  Explanations", "comments": "2019 IEEE International Conference on Big Data (Big Data) Best Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable recommendation is far from being well solved partly due to three\nchallenges. The first is the personalization of preference learning, which\nrequires that different items/users have different contributions to the\nlearning of user preference or item quality. The second one is dynamic\nexplanation, which is crucial for the timeliness of recommendation\nexplanations. The last one is the granularity of explanations. In practice,\naspect-level explanations are more persuasive than item-level or user-level\nones. In this paper, to address these challenges simultaneously, we propose a\nnovel model called Hybrid Deep Embedding (HDE) for aspect-based explainable\nrecommendations, which can make recommendations with dynamic aspect-level\nexplanations. The main idea of HDE is to learn the dynamic embeddings of users\nand items for rating prediction and the dynamic latent aspect\npreference/quality vectors for the generation of aspect-level explanations,\nthrough fusion of the dynamic implicit feedbacks extracted from reviews and the\nattentive user-item interactions. Particularly, as the aspect\npreference/quality of users/items is learned automatically, HDE is able to\ncapture the impact of aspects that are not mentioned in reviews of a user or an\nitem. The extensive experiments conducted on real datasets verify the\nrecommending performance and explainability of HDE. The source code of our work\nis available at \\url{https://github.com/lola63/HDE-Python}\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:16:32 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Luo", "Huanrui", ""], ["Yang", "Ning", ""], ["Yu", "Philip S.", ""]]}, {"id": "2001.10343", "submitter": "Pratikkumar Prajapati", "authors": "Pratikkumar Prajapati", "title": "Predictive analysis of Bitcoin price considering social sentiments", "comments": "12 pages, 4 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the use of sentiment analysis on news and social media to\nanalyze and predict the price of Bitcoin. Bitcoin is the leading cryptocurrency\nand has the highest market capitalization among digital currencies. Predicting\nBitcoin values may help understand and predict potential market movement and\nfuture growth of the technology. Unlike (mostly) repeating phenomena like\nweather, cryptocurrency values do not follow a repeating pattern and mere past\nvalue of Bitcoin does not reveal any secret of future Bitcoin value. Humans\nfollow general sentiments and technical analysis to invest in the market. Hence\nconsidering people's sentiment can give a good degree of prediction. We focus\non using social sentiment as a feature to predict future Bitcoin value, and in\nparticular, consider Google News and Reddit posts. We find that social\nsentiment gives a good estimate of how future Bitcoin values may move. We\nachieve the lowest test RMSE of 434.87 using an LSTM that takes as inputs the\nhistorical price of various cryptocurrencies, the sentiment of news articles\nand the sentiment of Reddit posts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:08:05 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Prajapati", "Pratikkumar", ""]]}, {"id": "2001.10344", "submitter": "Joyjit Chatterjee", "authors": "Joyjit Chatterjee, Anita Thakur, Vajja Mukesh", "title": "A Novel Approach Towards Identification of Alcohol and Drug Induced\n  People", "comments": "Accepted and Presented at the IEEE International Conference on Recent\n  Trends in Electronics, Information & Communication Technology (RTEICT 2018),\n  May 2018, Bengaluru, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The paper proposes a novel approach towards identification of alcohol and\ndrug induced people, through the use of a wearable bracelet.As alcohol and drug\ninduced human people are in an unconscious state of mind, they need external\nhelp from the surroundings.With proposed Bracelet system we can identify the\nalcohol and drug indused people and warning trigger message is sent to their\ncare takers. There is a definite relationship between an individual's Blood\nAlcohol Content (BAC) and Pulse Rate to identify the alcohol or drug consumed\nperson .This relationship of pulse rate with BAC is sensed by piezoelectric\nsensor and warning system is developed as a Bracelet device . The viability of\nthe Bracelet is verified by Simulating a Database of 199 People's BAC and Pulse\nRate Features and classification is done among the Alcohol Induced and Normal\nPeople. For classification,Ensemble Boosted Tree Algorithm is used which is\nhaving 81.9% accuracy in decision.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:57:38 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Chatterjee", "Joyjit", ""], ["Thakur", "Anita", ""], ["Mukesh", "Vajja", ""]]}, {"id": "2001.10363", "submitter": "Xiao Liu", "authors": "Xiao Liu, Yuanwei Liu, Yue Chen, and H. Vincent Poor", "title": "RIS Enhanced Massive Non-orthogonal Multiple Access Networks: Deployment\n  and Passive Beamforming Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework is proposed for the deployment and passive beamforming\ndesign of a reconfigurable intelligent surface (RIS) with the aid of\nnon-orthogonal multiple access (NOMA) technology. The problem of joint\ndeployment, phase shift design, as well as power allocation is formulated for\nmaximizing the energy efficiency with considering users' particular data\nrequirements. To tackle this pertinent problem, machine learning approaches are\nadopted in two steps. Firstly, a novel long short-term memory (LSTM) based echo\nstate network (ESN) algorithm is proposed to predict users' tele-traffic demand\nby leveraging a real dataset. Secondly, a decaying double deep Q-network (D3QN)\nbased position-acquisition and phase-control algorithm is proposed to solve the\njoint problem of deployment and design of the RIS. In the proposed algorithm,\nthe base station, which controls the RIS by a controller, acts as an agent. The\nagent periodically observes the state of the RIS-enhanced system for attaining\nthe optimal deployment and design policies of the RIS by learning from its\nmistakes and the feedback of users. Additionally, it is proved that the\nproposed D3QN based deployment and design algorithm is capable of converging\nwithin mild conditions. Simulation results are provided for illustrating that\nthe proposed LSTM-based ESN algorithm is capable of striking a tradeoff between\nthe prediction accuracy and computational complexity. Finally, it is\ndemonstrated that the proposed D3QN based algorithm outperforms the benchmarks,\nwhile the NOMA-enhanced RIS system is capable of achieving higher energy\nefficiency than orthogonal multiple access (OMA) enabled RIS system.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:37:38 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Liu", "Xiao", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.10374", "submitter": "David Noever", "authors": "David Noever", "title": "The Enron Corpus: Where the Email Bodies are Buried?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To probe the largest public-domain email database for indicators of fraud, we\napply machine learning and accomplish four investigative tasks. First, we\nidentify persons of interest (POI), using financial records and email, and\nreport a peak accuracy of 95.7%. Secondly, we find any publicly exposed\npersonally identifiable information (PII) and discover 50,000 previously\nunreported instances. Thirdly, we automatically flag legally responsive emails\nas scored by human experts in the California electricity blackout lawsuit, and\nfind a peak 99% accuracy. Finally, we track three years of primary topics and\nsentiment across over 10,000 unique people before, during and after the onset\nof the corporate crisis. Where possible, we compare accuracy against execution\ntimes for 51 algorithms and report human-interpretable business rules that can\nscale to vast datasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 13:59:54 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Noever", "David", ""]]}, {"id": "2001.10378", "submitter": "Fei Chen", "authors": "Mi Luo, Fei Chen, Pengxiang Cheng, Zhenhua Dong, Xiuqiang He, Jiashi\n  Feng, Zhenguo Li", "title": "MetaSelector: Meta-Learning for Recommendation with User-Level Adaptive\n  Model Selection", "comments": "Accepted by WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems often face heterogeneous datasets containing highly\npersonalized historical data of users, where no single model could give the\nbest recommendation for every user. We observe this ubiquitous phenomenon on\nboth public and private datasets and address the model selection problem in\npursuit of optimizing the quality of recommendation for each user. We propose a\nmeta-learning framework to facilitate user-level adaptive model selection in\nrecommender systems. In this framework, a collection of recommenders is trained\nwith data from all users, on top of which a model selector is trained via\nmeta-learning to select the best single model for each user with the\nuser-specific historical data. We conduct extensive experiments on two public\ndatasets and a real-world production dataset, demonstrating that our proposed\nframework achieves improvements over single model baselines and sample-level\nmodel selector in terms of AUC and LogLoss. In particular, the improvements may\nlead to huge profit gain when deployed in online recommender systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:05:01 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 08:03:25 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 03:18:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Luo", "Mi", ""], ["Chen", "Fei", ""], ["Cheng", "Pengxiang", ""], ["Dong", "Zhenhua", ""], ["He", "Xiuqiang", ""], ["Feng", "Jiashi", ""], ["Li", "Zhenguo", ""]]}, {"id": "2001.10379", "submitter": "Qianyu Guo", "authors": "Qianyu Guo, Jianzhong Qi", "title": "SANST: A Self-Attentive Network for Next Point-of-Interest\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next point-of-interest (POI) recommendation aims to offer suggestions on\nwhich POI to visit next, given a user's POI visit history. This problem has a\nwide application in the tourism industry, and it is gaining an increasing\ninterest as more POI check-in data become available. The problem is often\nmodeled as a sequential recommendation problem to take advantage of the\nsequential patterns of user check-ins, e.g., people tend to visit Central Park\nafter The Metropolitan Museum of Art in New York City. Recently, self-attentive\nnetworks have been shown to be both effective and efficient in general\nsequential recommendation problems, e.g., to recommend products, video games,\nor movies. Directly adopting self-attentive networks for next POI\nrecommendation, however, may produce sub-optimal recommendations. This is\nbecause vanilla self-attentive networks do not consider the spatial and\ntemporal patterns of user check-ins, which are two critical features in next\nPOI recommendation. To address this limitation, in this paper, we propose a\nmodel named SANST that incorporates spatio-temporal patterns of user check-ins\ninto self-attentive networks. To incorporate the spatial patterns, we encode\nthe relative positions of POIs into their embeddings before feeding the\nembeddings into the self-attentive network. To incorporate the temporal\npatterns, we discretize the time of POI check-ins and model the temporal\nrelationship between POI check-ins by a relation-aware self-attention module.\nWe evaluate the performance of our SANST model with three real-world datasets.\nThe results show that SANST consistently outperforms the state-of-theart\nmodels, and the advantage in nDCG@10 is up to 13.65%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:21:09 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Guo", "Qianyu", ""], ["Qi", "Jianzhong", ""]]}, {"id": "2001.10380", "submitter": "Aladdin Ayesh", "authors": "Qadri Mishael and Aladdin Ayesh", "title": "Investigating Classification Techniques with Feature Selection For\n  Intention Mining From Twitter Feed", "comments": "24 pages, 7 figures, 6 tables, DRAFT journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the last decade, social networks became most popular medium for\ncommunication and interaction. As an example, micro-blogging service Twitter\nhas more than 200 million registered users who exchange more than 65 million\nposts per day. Users express their thoughts, ideas, and even their intentions\nthrough these tweets. Most of the tweets are written informally and often in\nslang language, that contains misspelt and abbreviated words. This paper\ninvestigates the problem of selecting features that affect extracting user's\nintention from Twitter feeds based on text mining techniques. It starts by\npresenting the method we used to construct our own dataset from extracted\nTwitter feeds. Following that, we present two techniques of feature selection\nfollowed by classification. In the first technique, we use Information Gain as\na one-phase feature selection, followed by supervised classification\nalgorithms. In the second technique, we use a hybrid approach based on forward\nfeature selection algorithm in which two feature selection techniques employed\nfollowed by classification algorithms. We examine these two techniques with\nfour classification algorithms. We evaluate them using our own dataset, and we\ncritically review the results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 11:55:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Mishael", "Qadri", ""], ["Ayesh", "Aladdin", ""]]}, {"id": "2001.10388", "submitter": "Bonifaz Stuhr", "authors": "Bonifaz Stuhr and J\\\"urgen Brauer", "title": "CSNNs: Unsupervised, Backpropagation-free Convolutional Neural Networks\n  for Representation Learning", "comments": "18 pages,18 figures, Author's extended version of the paper. Final\n  version presented at 18th IEEE International Conference on Machine Learning\n  and Applications (ICMLA). Boca Raton, Florida / USA. 2019", "journal-ref": null, "doi": "10.1109/ICMLA.2019.00265", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work combines Convolutional Neural Networks (CNNs), clustering via\nSelf-Organizing Maps (SOMs) and Hebbian Learning to propose the building blocks\nof Convolutional Self-Organizing Neural Networks (CSNNs), which learn\nrepresentations in an unsupervised and Backpropagation-free manner. Our\napproach replaces the learning of traditional convolutional layers from CNNs\nwith the competitive learning procedure of SOMs and simultaneously learns local\nmasks between those layers with separate Hebbian-like learning rules to\novercome the problem of disentangling factors of variation when filters are\nlearned through clustering. We investigate the learned representation by\ndesigning two simple models with our building blocks, achieving comparable\nperformance to many methods which use Backpropagation, while we reach\ncomparable performance on Cifar10 and give baseline performances on Cifar100,\nTiny ImageNet and a small subset of ImageNet for Backpropagation-free methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 14:57:39 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:47:08 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Stuhr", "Bonifaz", ""], ["Brauer", "J\u00fcrgen", ""]]}, {"id": "2001.10389", "submitter": "Jonathan Tuck", "authors": "Jonathan Tuck, Stephen Boyd", "title": "Eigen-Stratified Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stratified models depend in an arbitrary way on a selected categorical\nfeature that takes $K$ values, and depend linearly on the other $n$ features.\nLaplacian regularization with respect to a graph on the feature values can\ngreatly improve the performance of a stratified model, especially in the\nlow-data regime. A significant issue with Laplacian-regularized stratified\nmodels is that the model is $K$ times the size of the base model, which can be\nquite large.\n  We address this issue by formulating eigen-stratifed models, which are\nstratified models with an additional constraint that the model parameters are\nlinear combinations of some modest number $m$ of bottom eigenvectors of the\ngraph Laplacian, i.e., those associated with the $m$ smallest eigenvalues. With\neigen-stratified models, we only need to store the $m$ bottom eigenvectors and\nthe corresponding coefficients as the stratified model parameters. This leads\nto a reduction, sometimes large, of model size when $m \\leq n$ and $m \\ll K$.\nIn some cases, the additional regularization implicit in eigen-stratified\nmodels can improve out-of-sample performance over standard Laplacian\nregularized stratified models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 16:26:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tuck", "Jonathan", ""], ["Boyd", "Stephen", ""]]}, {"id": "2001.10394", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Sarunas Girdzijauskas", "title": "Graph Neighborhood Attentive Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning (NRL) is a powerful technique for learning\nlow-dimensional vector representation of high-dimensional and sparse graphs.\nMost studies explore the structure and metadata associated with the graph using\nrandom walks and employ an unsupervised or semi-supervised learning schemes.\nLearning in these methods is context-free, because only a single representation\nper node is learned. Recently studies have argued on the sufficiency of a\nsingle representation and proposed a context-sensitive approach that proved to\nbe highly effective in applications such as link prediction and ranking.\n  However, most of these methods rely on additional textual features that\nrequire RNNs or CNNs to capture high-level features or rely on a community\ndetection algorithm to identify multiple contexts of a node.\n  In this study, without requiring additional features nor a community\ndetection algorithm, we propose a novel context-sensitive algorithm called GAP\nthat learns to attend on different parts of a node's neighborhood using\nattentive pooling networks. We show the efficacy of GAP using three real-world\ndatasets on link prediction and node clustering tasks and compare it against 10\npopular and state-of-the-art (SOTA) baselines. GAP consistently outperforms\nthem and achieves up to ~9% and ~20% gain over the best performing methods on\nlink prediction and clustering tasks, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:05:48 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 09:20:57 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2001.10396", "submitter": "David Janz", "authors": "David Janz, David R. Burt, Javier Gonz\\'alez", "title": "Bandit optimisation of functions in the Mat\\'ern kernel RKHS", "comments": "AISTATS 2020, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimising functions in the reproducing kernel\nHilbert space (RKHS) of a Mat\\'ern kernel with smoothness parameter $\\nu$ over\nthe domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the\n$\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed\nsublinear regret for all $\\nu>1$ and $d \\geq 1$. Empirical validation suggests\nbetter performance and drastically improved computational scalablity compared\nwith its predecessor, Improved GP-UCB.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:09:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:50:32 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Janz", "David", ""], ["Burt", "David R.", ""], ["Gonz\u00e1lez", "Javier", ""]]}, {"id": "2001.10398", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Moritz Diehl, Bernhard Sch\\\"olkopf", "title": "A Kernel Mean Embedding Approach to Reducing Conservativeness in\n  Stochastic Programming and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply kernel mean embedding methods to sample-based stochastic\noptimization and control. Specifically, we use the reduced-set expansion method\nas a way to discard sampled scenarios. The effect of such constraint removal is\nimproved optimality and decreased conservativeness. This is achieved by solving\na distributional-distance-regularized optimization problem. We demonstrated\nthis optimization formulation is well-motivated in theory, computationally\ntractable and effective in numerical algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:11:50 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 21:11:59 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Diehl", "Moritz", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2001.10399", "submitter": "Taraneh Younesian", "authors": "Taraneh Younesian, Zilong Zhao, Amirmasoud Ghiassi, Robert Birke,\n  Lydia Y. Chen", "title": "QActor: On-line Active Learning for Noisy Labeled Stream Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noisy labeled data is more a norm than a rarity for self-generated content\nthat is continuously published on the web and social media. Due to privacy\nconcerns and governmental regulations, such a data stream can only be stored\nand used for learning purposes in a limited duration. To overcome the noise in\nthis on-line scenario we propose QActor which novel combines: the selection of\nsupposedly clean samples via quality models and actively querying an oracle for\nthe most informative true labels. While the former can suffer from low data\nvolumes of on-line scenarios, the latter is constrained by the availability and\ncosts of human experts. QActor swiftly combines the merits of quality models\nfor data filtering and oracle queries for cleaning the most informative data.\nThe objective of QActor is to leverage the stringent oracle budget to robustly\nmaximize the learning accuracy. QActor explores various strategies combining\ndifferent query allocations and uncertainty measures. A central feature of\nQActor is to dynamically adjust the query limit according to the learning loss\nfor each data batch. We extensively evaluate different image datasets fed into\nthe classifier that can be standard machine learning (ML) models or deep neural\nnetworks (DNN) with noise label ratios ranging between 30% and 80%. Our results\nshow that QActor can nearly match the optimal accuracy achieved using only\nclean data at the cost of at most an additional 6% of ground truth data from\nthe oracle.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:13:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Younesian", "Taraneh", ""], ["Zhao", "Zilong", ""], ["Ghiassi", "Amirmasoud", ""], ["Birke", "Robert", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "2001.10402", "submitter": "Mohammad Mohammadi Amiri Dr.", "authors": "Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, H.\n  Vincent Poor", "title": "Convergence of Update Aware Device Scheduling for Federated Learning at\n  the Wireless Edge", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study federated learning (FL) at the wireless edge, where power-limited\ndevices with local datasets collaboratively train a joint model with the help\nof a remote parameter server (PS). We assume that the devices are connected to\nthe PS through a bandwidth-limited shared wireless channel. At each iteration\nof FL, a subset of the devices are scheduled to transmit their local model\nupdates to the PS over orthogonal channel resources, while each participating\ndevice must compress its model update to accommodate to its link capacity. We\ndesign novel scheduling and resource allocation policies that decide on the\nsubset of the devices to transmit at each round, and how the resources should\nbe allocated among the participating devices, not only based on their channel\nconditions, but also on the significance of their local model updates. We then\nestablish convergence of a wireless FL algorithm with device scheduling, where\ndevices have limited capacity to convey their messages. The results of\nnumerical experiments show that the proposed scheduling policy, based on both\nthe channel conditions and the significance of the local model updates,\nprovides a better long-term performance than scheduling policies based only on\neither of the two metrics individually. Furthermore, we observe that when the\ndata is independent and identically distributed (i.i.d.) across devices,\nselecting a single device at each round provides the best performance, while\nwhen the data distribution is non-i.i.d., scheduling multiple devices at each\nround improves the performance. This observation is verified by the convergence\nresult, which shows that the number of scheduled devices should increase for a\nless diverse and more biased data distribution.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:15:22 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 11:18:57 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Amiri", "Mohammad Mohammadi", ""], ["Gunduz", "Deniz", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2001.10420", "submitter": "Gustavo De Rosa", "authors": "Gustavo Henrique de Rosa, Jo\\~ao Paulo Papa, Alexandre Xavier Falc\\~ao", "title": "OPFython: A Python-Inspired Optimum-Path Forest Classifier", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning techniques have been paramount throughout the last years,\nbeing applied in a wide range of tasks, such as classification, object\nrecognition, person identification, and image segmentation. Nevertheless,\nconventional classification algorithms, e.g., Logistic Regression, Decision\nTrees, and Bayesian classifiers, might lack complexity and diversity, not\nsuitable when dealing with real-world data. A recent graph-inspired classifier,\nknown as the Optimum-Path Forest, has proven to be a state-of-the-art\ntechnique, comparable to Support Vector Machines and even surpassing it in some\ntasks. This paper proposes a Python-based Optimum-Path Forest framework,\ndenoted as OPFython, where all of its functions and classes are based upon the\noriginal C language implementation. Additionally, as OPFython is a Python-based\nlibrary, it provides a more friendly environment and a faster prototyping\nworkspace than the C language.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:46:19 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 14:06:47 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["de Rosa", "Gustavo Henrique", ""], ["Papa", "Jo\u00e3o Paulo", ""], ["Falc\u00e3o", "Alexandre Xavier", ""]]}, {"id": "2001.10422", "submitter": "Arber Zela", "authors": "Arber Zela, Julien Siems, Frank Hutter", "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural\n  Architecture Search", "comments": "In: International Conference on Learning Representations (ICLR 2020);\n  19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still\na lack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS\nmethods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:50:22 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 22:48:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zela", "Arber", ""], ["Siems", "Julien", ""], ["Hutter", "Frank", ""]]}, {"id": "2001.10460", "submitter": "Etai Littwin", "authors": "Etai Littwin, Tomer Galanti, Lior Wolf", "title": "On Random Kernels of Residual Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive finite width and depth corrections for the Neural Tangent Kernel\n(NTK) of ResNets and DenseNets. Our analysis reveals that finite size residual\narchitectures are initialized much closer to the \"kernel regime\" than their\nvanilla counterparts: while in networks that do not use skip connections,\nconvergence to the NTK requires one to fix the depth, while increasing the\nlayers' width. Our findings show that in ResNets, convergence to the NTK may\noccur when depth and width simultaneously tend to infinity, provided with a\nproper initialization. In DenseNets, however, convergence of the NTK to its\nlimit as the width tends to infinity is guaranteed, at a rate that is\nindependent of both the depth and scale of the weights. Our experiments\nvalidate the theoretical results and demonstrate the advantage of deep ResNets\nand DenseNets for kernel regression with random gradient features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:47:53 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 01:33:58 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:43:28 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 14:12:19 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Littwin", "Etai", ""], ["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "2001.10468", "submitter": "Firas Kassawat", "authors": "Firas Kassawat, Debanjan Chaudhuri, Jens Lehmann", "title": "Incorporating Joint Embeddings into Goal-Oriented Dialogues with\n  Multi-Task Learning", "comments": "The Semantic Web - 16th International Conference, ESWC 2019,\n  Portoro\\v{z}, Slovenia, June 2-6, 2019, Proceedings, page 225-239", "journal-ref": null, "doi": "10.1007/978-3-030-21348-0_15", "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder neural network models have recently shown\npromising results in goal-oriented dialogue systems. However, these models\nstruggle to reason over and incorporate state-full knowledge while preserving\ntheir end-to-end text generation functionality. Since such models can greatly\nbenefit from user intent and knowledge graph integration, in this paper we\npropose an RNN-based end-to-end encoder-decoder architecture which is trained\nwith joint embeddings of the knowledge graph and the corpus as input. The model\nprovides an additional integration of user intent along with text generation,\ntrained with a multi-task learning paradigm along with an additional\nregularization technique to penalize generating the wrong entity as output. The\nmodel further incorporates a Knowledge Graph entity lookup during inference to\nguarantee the generated output is state-full based on the local knowledge graph\nprovided. We finally evaluated the model using the BLEU score, empirical\nevaluation depicts that our proposed architecture can aid in the betterment of\ntask-oriented dialogue system`s performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassawat", "Firas", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""]]}, {"id": "2001.10474", "submitter": "Modjtaba Shokrian Zini", "authors": "Modjtaba Shokrian Zini, Mohammad Pedramfar, Matthew Riemer, Miao Liu", "title": "Coagent Networks Revisited", "comments": "Added multiple experiments and new results to the previous version\n  \"Parameter Sharing in Coagent Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is aiming to discuss and close some of the gaps in the literature\non models using options (and more generally coagents). Briefly surveying the\ntheory behind these models, it also aims to provide a unifying point of view on\nthe many diverse examples that fall under a same category called coagent\nnetwork. Motivated by the result of [10] on parameter sharing of options, we\nrevisit the theory of (a)synchronous Coagent Network [8] by generalizing the\nresult to the context where parameters are shared among the function\napproximators of coagents. The proof is more intuitive and uses the concept of\nexecution paths in a coagent network. Theoretically, this informs us of some\nnecessary modifications to the algorithms found in the literature which make\nthem more mathematically accurate. It also allows us to introduce a new simple\noption framework, Feedforward Option Network, which outperforms the previous\noption models in time to convergence and stability in the famous nonstationary\nFour Rooms task. In addition, a stabilization effect is observed in\nhierarchical models which justify the unnecessity of the target network in\ntraining such models. Finally, we publish our code which allows us to be\nflexible in our experiments settings.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:31:23 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 11:09:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zini", "Modjtaba Shokrian", ""], ["Pedramfar", "Mohammad", ""], ["Riemer", "Matthew", ""], ["Liu", "Miao", ""]]}, {"id": "2001.10477", "submitter": "Andrea Rocchetto", "authors": "Carlo Ciliberto, Andrea Rocchetto, Alessandro Rudi, Leonard Wossnig", "title": "Statistical Limits of Supervised Quantum Learning", "comments": "v3: 6 pages, journal version, title changed (previous title \"The\n  Statistical Limits of Supervised Quantum Learning\"), other minor\n  improvements; v2: 6 pages, title changed (previous title \"Fast quantum\n  learning with statistical guarantees\"), format changed to two-columns, typos\n  corrected, remarks that better clarify the limitations of our analysis added", "journal-ref": "Phys. Rev. A 102, 042414 (2020)", "doi": "10.1103/PhysRevA.102.042414", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the framework of statistical learning theory it is possible to bound\nthe minimum number of samples required by a learner to reach a target accuracy.\nWe show that if the bound on the accuracy is taken into account, quantum\nmachine learning algorithms for supervised learning---for which statistical\nguarantees are available---cannot achieve polylogarithmic runtimes in the input\ndimension. We conclude that, when no further assumptions on the problem are\nmade, quantum machine learning algorithms for supervised learning can have at\nmost polynomial speedups over efficient classical algorithms, even in cases\nwhere quantum access to the data is naturally available.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:35:32 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:10:57 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 09:36:24 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Rocchetto", "Andrea", ""], ["Rudi", "Alessandro", ""], ["Wossnig", "Leonard", ""]]}, {"id": "2001.10485", "submitter": "Cheng Yang", "authors": "Cheng Yang, Gene Cheung, Wei Hu", "title": "Graph Metric Learning via Gershgorin Disc Alignment", "comments": "accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast general projection-free metric learning framework, where\nthe minimization objective $\\min_{\\textbf{M} \\in \\mathcal{S}} Q(\\textbf{M})$ is\na convex differentiable function of the metric matrix $\\textbf{M}$, and\n$\\textbf{M}$ resides in the set $\\mathcal{S}$ of generalized graph Laplacian\nmatrices for connected graphs with positive edge weights and node degrees.\nUnlike low-rank metric matrices common in the literature, $\\mathcal{S}$\nincludes the important positive-diagonal-only matrices as a special case in the\nlimit. The key idea for fast optimization is to rewrite the positive definite\ncone constraint in $\\mathcal{S}$ as signal-adaptive linear constraints via\nGershgorin disc alignment, so that the alternating optimization of the diagonal\nand off-diagonal terms in $\\textbf{M}$ can be solved efficiently as linear\nprograms via Frank-Wolfe iterations. We prove that the Gershgorin discs can be\naligned perfectly using the first eigenvector $\\textbf{v}$ of $\\textbf{M}$,\nwhich we update iteratively using Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) with warm start as diagonal / off-diagonal terms\nare optimized. Experiments show that our efficiently computed graph metric\nmatrices outperform metrics learned using competing methods in terms of\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:44:01 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:09:24 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 14:02:27 GMT"}, {"version": "v4", "created": "Mon, 9 Mar 2020 22:42:43 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Yang", "Cheng", ""], ["Cheung", "Gene", ""], ["Hu", "Wei", ""]]}, {"id": "2001.10494", "submitter": "Feiyang Cai", "authors": "Feiyang Cai and Xenofon Koutsoukos", "title": "Real-time Out-of-distribution Detection in Learning-Enabled\n  Cyber-Physical Systems", "comments": "Accepted by 11th International Conference on Cyber-Physical Systems\n  (ICCPS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) greatly benefit by using machine learning\ncomponents that can handle the uncertainty and variability of the real-world.\nTypical components such as deep neural networks, however, introduce new types\nof hazards that may impact system safety. The system behavior depends on data\nthat are available only during runtime and may be different than the data used\nfor training. Out-of-distribution data may lead to a large error and compromise\nsafety. The paper considers the problem of efficiently detecting\nout-of-distribution data in CPS control systems. Detection must be robust and\nlimit the number of false alarms while being computational efficient for\nreal-time monitoring. The proposed approach leverages inductive conformal\nprediction and anomaly detection for developing a method that has a\nwell-calibrated false alarm rate. We use variational autoencoders and deep\nsupport vector data description to learn models that can be used efficiently\ncompute the nonconformity of new inputs relative to the training set and enable\nreal-time detection of out-of-distribution high-dimensional inputs. We\ndemonstrate the method using an advanced emergency braking system and a\nself-driving end-to-end controller implemented in an open source simulator for\nself-driving cars. The simulation results show very small number of false\npositives and detection delay while the execution time is comparable to the\nexecution time of the original machine learning components.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:51:07 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Cai", "Feiyang", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "2001.10495", "submitter": "Amar Budhiraja", "authors": "Amar Budhiraja, Gaurush Hiranandani, Darshak Chhatbar, Aditya Sinha,\n  Navya Yarrabelly, Ayush Choure, Oluwasanmi Koyejo, Prateek Jain", "title": "Rich-Item Recommendations for Rich-Users: Exploiting Dynamic and Static\n  Side Information", "comments": "The first two authors contributed equally. 21 pages, 8 figures and 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of recommendation system where the users\nand items to be recommended are rich data structures with multiple entity types\nand with multiple sources of side-information in the form of graphs. We provide\na general formulation for the problem that captures the complexities of modern\nreal-world recommendations and generalizes many existing formulations. In our\nformulation, each user/document that requires a recommendation and each item or\ntag that is to be recommended, both are modeled by a set of static entities and\na dynamic component. The relationships between entities are captured by several\nweighted bipartite graphs. To effectively exploit these complex interactions\nand learn the recommendation model, we propose MEDRES- a multiple graph-CNN\nbased novel deep-learning architecture. MEDRES uses AL-GCN, a novel graph\nconvolution network block, that harnesses strong representative features from\nthe underlying graphs. Moreover, in order to capture highly heterogeneous\nengagement of different users with the system and constraints on the number of\nitems to be recommended, we propose a novel ranking metric pAp@k along with a\nmethod to optimize the metric directly. We demonstrate effectiveness of our\nmethod on two benchmarks: a) citation data, b) Flickr data. In addition, we\npresent two real-world case studies of our formulation and the MEDRES\narchitecture. We show how our technique can be used to naturally model the\nmessage recommendation problem and the teams recommendation problem in the\nMicrosoft Teams (MSTeams) product and demonstrate that it is 5-6% points more\naccurate than the production-grade models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:53:38 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 12:34:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Budhiraja", "Amar", ""], ["Hiranandani", "Gaurush", ""], ["Chhatbar", "Darshak", ""], ["Sinha", "Aditya", ""], ["Yarrabelly", "Navya", ""], ["Choure", "Ayush", ""], ["Koyejo", "Oluwasanmi", ""], ["Jain", "Prateek", ""]]}, {"id": "2001.10505", "submitter": "Ashkan Haji Hosseinloo", "authors": "Ashkan Haji Hosseinloo, Alexander Ryzhov, Aldo Bischi, Henni Ouerdane,\n  Konstantin Turitsyn, Munther A. Dahleh", "title": "Data-driven control of micro-climate in buildings: an event-triggered\n  reinforcement learning approach", "comments": null, "journal-ref": "Applied Energy vol. 277, 115451 (2020)", "doi": "10.1016/j.apenergy.2020.115451", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart buildings have great potential for shaping an energy-efficient,\nsustainable, and more economic future for our planet as buildings account for\napproximately 40% of the global energy consumption. Future of the smart\nbuildings lies in using sensory data for adaptive decision making and control\nthat is currently gloomed by the key challenge of learning a good control\npolicy in a short period of time in an online and continuing fashion. To tackle\nthis challenge, an event-triggered -- as opposed to classic time-triggered --\nparadigm, is proposed in which learning and control decisions are made when\nevents occur and enough information is collected. Events are characterized by\ncertain design conditions and they occur when the conditions are met, for\ninstance, when a certain state threshold is reached. By systematically\nadjusting the time of learning and control decisions, the proposed framework\ncan potentially reduce the variance in learning, and consequently, improve the\ncontrol process. We formulate the micro-climate control problem based on\nsemi-Markov decision processes that allow for variable-time state transitions\nand decision making. Using extended policy gradient theorems and temporal\ndifference methods in a reinforcement learning set-up, we propose two learning\nalgorithms for event-triggered control of micro-climate in buildings. We show\nthe efficacy of our proposed approach via designing a smart learning thermostat\nthat simultaneously optimizes energy consumption and occupants' comfort in a\ntest building.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:20:43 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 19:11:14 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hosseinloo", "Ashkan Haji", ""], ["Ryzhov", "Alexander", ""], ["Bischi", "Aldo", ""], ["Ouerdane", "Henni", ""], ["Turitsyn", "Konstantin", ""], ["Dahleh", "Munther A.", ""]]}, {"id": "2001.10509", "submitter": "Christoph Studer", "authors": "Ramina Ghods, Andrew S. Lan, Tom Goldstein, Christoph Studer", "title": "MSE-Optimal Neural Network Initialization via Layer Fusion", "comments": "Extended version of the CISS 2020 paper containing the proof for\n  convolutional layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art performance for a range of\nclassification and inference tasks. However, the use of stochastic gradient\ndescent combined with the nonconvexity of the underlying optimization problems\nrenders parameter learning susceptible to initialization. To address this\nissue, a variety of methods that rely on random parameter initialization or\nknowledge distillation have been proposed in the past. In this paper, we\npropose FuseInit, a novel method to initialize shallower networks by fusing\nneighboring layers of deeper networks that are trained with random\ninitialization. We develop theoretical results and efficient algorithms for\nmean-square error (MSE)-optimal fusion of neighboring dense-dense,\nconvolutional-dense, and convolutional-convolutional layers. We show\nexperiments for a range of classification and regression datasets, which\nsuggest that deeper neural networks are less sensitive to initialization and\nshallower networks can perform better (sometimes as well as their deeper\ncounterparts) if initialized with FuseInit.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:25:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ghods", "Ramina", ""], ["Lan", "Andrew S.", ""], ["Goldstein", "Tom", ""], ["Studer", "Christoph", ""]]}, {"id": "2001.10516", "submitter": "Hao Xu", "authors": "Hao Xu, Shengqi Sang and Haiping Lu", "title": "Tri-graph Information Propagation for Polypharmacy Side Effect\n  Prediction", "comments": "Presented at NeruIPS 2019 Graph Representation Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of drug combinations often leads to polypharmacy side effects (POSE).\nA recent method formulates POSE prediction as a link prediction problem on a\ngraph of drugs and proteins, and solves it with Graph Convolutional Networks\n(GCNs). However, due to the complex relationships in POSE, this method has high\ncomputational cost and memory demand. This paper proposes a flexible Tri-graph\nInformation Propagation (TIP) model that operates on three subgraphs to learn\nrepresentations progressively by propagation from protein-protein graph to\ndrug-drug graph via protein-drug graph. Experiments show that TIP improves\naccuracy by 7%+, time efficiency by 83$\\times$, and space efficiency by\n3$\\times$.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:39:11 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Xu", "Hao", ""], ["Sang", "Shengqi", ""], ["Lu", "Haiping", ""]]}, {"id": "2001.10523", "submitter": "Carlos Villacampa-Calvo", "authors": "Carlos Villacampa-Calvo, Bryan Zaldivar, Eduardo C. Garrido-Merch\\'an,\n  Daniel Hern\\'andez-Lobato", "title": "Multi-class Gaussian Process Classification with Noisy Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a common practice in the machine learning community to assume that the\nobserved data are noise-free in the input attributes. Nevertheless, scenarios\nwith input noise are common in real problems, as measurements are never\nperfectly accurate. If this input noise is not taken into account, a supervised\nmachine learning method is expected to perform sub-optimally. In this paper, we\nfocus on multi-class classification problems and use Gaussian processes (GPs)\nas the underlying classifier. Motivated by a data set coming from the\nastrophysics domain, we hypothesize that the observed data may contain noise in\nthe inputs. Therefore, we devise several multi-class GP classifiers that can\naccount for input noise. Such classifiers can be efficiently trained using\nvariational inference to approximate the posterior distribution of the latent\nvariables of the model. Moreover, in some situations, the amount of noise can\nbe known before-hand. If this is the case, it can be readily introduced in the\nproposed methods. This prior information is expected to lead to better\nperformance results. We have evaluated the proposed methods by carrying out\nseveral experiments, involving synthetic and real data. These include several\ndata sets from the UCI repository, the MNIST data set and a data set coming\nfrom astrophysics. The results obtained show that, although the classification\nerror is similar across methods, the predictive distribution of the proposed\nmethods is better, in terms of the test log-likelihood, than the predictive\ndistribution of a classifier based on GPs that ignores input noise.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:55:13 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 11:16:24 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 13:41:55 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Villacampa-Calvo", "Carlos", ""], ["Zaldivar", "Bryan", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2001.10528", "submitter": "Geoff Pleiss", "authors": "Geoff Pleiss, Tianyi Zhang, Ethan R. Elenberg, Kilian Q. Weinberger", "title": "Identifying Mislabeled Data using the Area Under the Margin Ranking", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all data in a typical training set help with generalization; some samples\ncan be overly ambiguous or outrightly mislabeled. This paper introduces a new\nmethod to identify such samples and mitigate their impact when training neural\nnetworks. At the heart of our algorithm is the Area Under the Margin (AUM)\nstatistic, which exploits differences in the training dynamics of clean and\nmislabeled samples. A simple procedure - adding an extra class populated with\npurposefully mislabeled threshold samples - learns a AUM upper bound that\nisolates mislabeled data. This approach consistently improves upon prior work\non synthetic and real-world datasets. On the WebVision50 classification task\nour method removes 17% of training data, yielding a 1.6% (absolute) improvement\nin test error. On CIFAR100 removing 13% of the data leads to a 1.2% drop in\nerror.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 18:59:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:41:30 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 18:55:17 GMT"}, {"version": "v4", "created": "Wed, 23 Dec 2020 14:01:54 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Pleiss", "Geoff", ""], ["Zhang", "Tianyi", ""], ["Elenberg", "Ethan R.", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2001.10529", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Chao-Han Huck Yang, Javier Tejedor", "title": "Submodular Rank Aggregation on Score-based Permutations for Distributed\n  Automatic Speech Recognition", "comments": "Accepted to ICASSP 2020. Please download the pdf to view Figure 1.\n  arXiv admin note: substantial text overlap with arXiv:1707.01166", "journal-ref": "IEEE ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed automatic speech recognition (ASR) requires to aggregate outputs\nof distributed deep neural network (DNN)-based models. This work studies the\nuse of submodular functions to design a rank aggregation on score-based\npermutations, which can be used for distributed ASR systems in both supervised\nand unsupervised modes. Specifically, we compose an aggregation rank function\nbased on the Lovasz Bregman divergence for setting up linear structured convex\nand nested structured concave functions. The algorithm is based on stochastic\ngradient descent (SGD) and can obtain well-trained aggregation models. Our\nexperiments on the distributed ASR system show that the submodular rank\naggregation can obtain higher speech recognition accuracy than traditional\naggregation methods like Adaboost. Code is available\nonline~\\footnote{https://github.com/uwjunqi/Subrank}.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:46:41 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Qi", "Jun", ""], ["Yang", "Chao-Han Huck", ""], ["Tejedor", "Javier", ""]]}, {"id": "2001.10560", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Hajira Jabeen, Charles Tapley Hoyt, and Jens Lehman", "title": "The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a\n  Focus on Reproducibility and Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an emerging trend of embedding knowledge graphs (KGs) in continuous\nvector spaces in order to use those for machine learning tasks. Recently, many\nknowledge graph embedding (KGE) models have been proposed that learn low\ndimensional representations while trying to maintain the structural properties\nof the KGs such as the similarity of nodes depending on their edges to other\nnodes. KGEs can be used to address tasks within KGs such as the prediction of\nnovel links and the disambiguation of entities. They can also be used for\ndownstream tasks like question answering and fact-checking. Overall, these\ntasks are relevant for the semantic web community. Despite their popularity,\nthe reproducibility of KGE experiments and the transferability of proposed KGE\nmodels to research fields outside the machine learning community can be a major\nchallenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge\ngraph embeddings that we have developed with a strong focus on reproducibility\nand transferability. The KEEN Universe currently consists of the Python\npackages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge\nEmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:12:37 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ali", "Mehdi", ""], ["Jabeen", "Hajira", ""], ["Hoyt", "Charles Tapley", ""], ["Lehman", "Jens", ""]]}, {"id": "2001.10568", "submitter": "Seyed Alireza Razavi", "authors": "Alireza Razavi", "title": "Landmark2Vec: An Unsupervised Neural Network-Based Landmark Positioning\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Neural Network-based method for unsupervised landmarks map estimation from\nmeasurements taken from landmarks is introduced. The measurements needed for\ntraining the network are the signals observed/received from landmarks by an\nagent. The definition of landmarks, agent, and the measurements taken by agent\nfrom landmarks is rather broad here: landmarks can be visual objects, e.g.,\npoles along a road, with measurements being the size of landmark in a visual\nsensor mounted on a vehicle (agent), or they can be radio transmitters, e.g.,\nWiFi access points inside a building, with measurements being the Received\nSignal Strength (RSS) heard from them by a mobile device carried by a person\n(agent). The goal of the map estimation is then to find the positions of\nlandmarks up to a scale, rotation, and shift (i.e., the topological map of the\nlandmarks). Assuming that there are $L$ landmarks, the measurements will be $L\n\\times 1$ vectors collected over the area. A shallow network then will be\ntrained to learn the map without any ground truth information.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:39:55 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Razavi", "Alireza", ""]]}, {"id": "2001.10570", "submitter": "Luca Luceri", "authors": "Luca Luceri, Silvia Giordano, Emilio Ferrara", "title": "Detecting Troll Behavior via Inverse Reinforcement Learning: A Case\n  Study of Russian Trolls in the 2016 US Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the 2016 US Presidential election, social media abuse has been\neliciting massive concern in the academic community and beyond. Preventing and\nlimiting the malicious activity of users, such as trolls and bots, in their\nmanipulation campaigns is of paramount importance for the integrity of\ndemocracy, public health, and more. However, the automated detection of troll\naccounts is an open challenge. In this work, we propose an approach based on\nInverse Reinforcement Learning (IRL) to capture troll behavior and identify\ntroll accounts. We employ IRL to infer a set of online incentives that may\nsteer user behavior, which in turn highlights behavioral differences between\ntroll and non-troll accounts, enabling their accurate classification. As a\nstudy case, we consider the troll accounts identified by the US Congress during\nthe investigation of Russian meddling in the 2016 US Presidential election. We\nreport promising results: the IRL-based approach is able to accurately detect\ntroll accounts (AUC=89.1%). The differences in the predictive features between\nthe two classes of accounts enables a principled understanding of the\ndistinctive behaviors reflecting the incentives trolls and non-trolls respond\nto.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:50:19 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:12:23 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 17:43:28 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Luceri", "Luca", ""], ["Giordano", "Silvia", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2001.10616", "submitter": "Yuling Jiao", "authors": "Jian Huang, Yuling Jiao, Lican Kang, Jin Liu, Yanyan Liu, Xiliang Lu,\n  and Yuanyuan Yang", "title": "On Newton Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening and working set techniques are important approaches to reducing the\nsize of an optimization problem. They have been widely used in accelerating\nfirst-order methods for solving large-scale sparse learning problems. In this\npaper, we develop a new screening method called Newton screening (NS) which is\na generalized Newton method with a built-in screening mechanism. We derive an\nequivalent KKT system for the Lasso and utilize a generalized Newton method to\nsolve the KKT equations. Based on this KKT system, a built-in working set with\na relatively small size is first determined using the sum of primal and dual\nvariables generated from the previous iteration, then the primal variable is\nupdated by solving a least-squares problem on the working set and the dual\nvariable updated based on a closed-form expression. Moreover, we consider a\nsequential version of Newton screening (SNS) with a warm-start strategy. We\nshow that NS possesses an optimal convergence property in the sense that it\nachieves one-step local convergence. Under certain regularity conditions on the\nfeature matrix, we show that SNS hits a solution with the same signs as the\nunderlying true target and achieves a sharp estimation error bound with high\nprobability. Simulation studies and real data analysis support our theoretical\nresults and demonstrate that SNS is faster and more accurate than several\nstate-of-the-art methods in our comparative studies.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 11:25:33 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 16:09:52 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Kang", "Lican", ""], ["Liu", "Jin", ""], ["Liu", "Yanyan", ""], ["Lu", "Xiliang", ""], ["Yang", "Yuanyuan", ""]]}, {"id": "2001.10623", "submitter": "Nikita Zhivotovskiy", "authors": "Gergely Neu and Nikita Zhivotovskiy", "title": "Fast Rates for Online Prediction with Abstention", "comments": "19 pages, minor corrections, to appear in COLT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of sequential prediction of individual $\\{0, 1\\}$-sequences\nwith expert advice, we show that by allowing the learner to abstain from the\nprediction by paying a cost marginally smaller than $\\frac 12$ (say, $0.49$),\nit is possible to achieve expected regret bounds that are independent of the\ntime horizon $T$. We exactly characterize the dependence on the abstention cost\n$c$ and the number of experts $N$ by providing matching upper and lower bounds\nof order $\\frac{\\log N}{1-2c}$, which is to be contrasted with the best\npossible rate of $\\sqrt{T\\log N}$ that is available without the option to\nabstain. We also discuss various extensions of our model, including a setting\nwhere the sequence of abstention costs can change arbitrarily over time, where\nwe show regret bounds interpolating between the slow and the fast rates\nmentioned above, under some natural assumptions on the sequence of abstention\ncosts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:34:55 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 19:07:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Neu", "Gergely", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2001.10632", "submitter": "Arunan Sivanathan", "authors": "Arunan Sivanathan", "title": "IoT Behavioral Monitoring via Network Traffic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart homes, enterprises, and cities are increasingly being equipped with a\nplethora of Internet of Things (IoT), ranging from smart-lights to security\ncameras. While IoT networks have the potential to benefit our lives, they\ncreate privacy and security challenges not seen with traditional IT networks.\nDue to the lack of visibility, operators of such smart environments are not\noften aware of their IoT assets, let alone whether each IoT device is\nfunctioning properly safe from cyber-attacks. This thesis is the culmination of\nour efforts to develop techniques to profile the network behavioral pattern of\nIoTs, automate IoT classification, deduce their operating context, and detect\nanomalous behavior indicative of cyber-attacks.\n  We begin this thesis by surveying IoT ecosystem, while reviewing current\napproaches to vulnerability assessments, intrusion detection, and behavioral\nmonitoring. For our first contribution, we collect traffic traces and\ncharacterize the network behavior of IoT devices via attributes from traffic\npatterns. We develop a robust machine learning-based inference engine trained\nwith these attributes and demonstrate real-time classification of 28 IoT\ndevices with over 99% accuracy. Our second contribution enhances the\nclassification by reducing the cost of attribute extraction while also\nidentifying IoT device states. Prototype implementation and evaluation\ndemonstrate the ability of our supervised machine learning method to detect\nbehavioral changes for five IoT devices. Our third and final contribution\ndevelops a modularized unsupervised inference engine that dynamically\naccommodates the addition of new IoT devices and/or updates to existing ones,\nwithout requiring system-wide retraining of the model. We demonstrate via\nexperiments that our model can automatically detect attacks and firmware\nchanges in ten IoT devices with over 94% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 23:13:12 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Sivanathan", "Arunan", ""]]}, {"id": "2001.10642", "submitter": "Kazuhiko Shinoda", "authors": "Kazuhiko Shinoda, Hirotaka Kaji, Masashi Sugiyama", "title": "Binary Classification from Positive Data with Skewed Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive-confidence (Pconf) classification [Ishida et al., 2018] is a\npromising weakly-supervised learning method which trains a binary classifier\nonly from positive data equipped with confidence. However, in practice, the\nconfidence may be skewed by bias arising in an annotation process. The Pconf\nclassifier cannot be properly learned with skewed confidence, and consequently,\nthe classification performance might be deteriorated. In this paper, we\nintroduce the parameterized model of the skewed confidence, and propose the\nmethod for selecting the hyperparameter which cancels out the negative impact\nof skewed confidence under the assumption that we have the misclassification\nrate of positive samples as a prior knowledge. We demonstrate the effectiveness\nof the proposed method through a synthetic experiment with simple linear models\nand benchmark problems with neural network models. We also apply our method to\ndrivers' drowsiness prediction to show that it works well with a real-world\nproblem where confidence is obtained based on manual annotation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 00:04:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Shinoda", "Kazuhiko", ""], ["Kaji", "Hirotaka", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2001.10648", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi and Mohamed Ali Kaafar", "title": "Modelling and Quantifying Membership Information Leakage in Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have been shown to be vulnerable to membership\ninference attacks, i.e., inferring whether individuals' data have been used for\ntraining models. The lack of understanding about factors contributing success\nof these attacks motivates the need for modelling membership information\nleakage using information theory and for investigating properties of machine\nlearning models and training algorithms that can reduce membership information\nleakage. We use conditional mutual information leakage to measure the amount of\ninformation leakage from the trained machine learning model about the presence\nof an individual in the training dataset. We devise an upper bound for this\nmeasure of information leakage using Kullback--Leibler divergence that is more\namenable to numerical computation. We prove a direct relationship between the\nKullback--Leibler membership information leakage and the probability of success\nfor a hypothesis-testing adversary examining whether a particular data record\nbelongs to the training dataset of a machine learning model. We show that the\nmutual information leakage is a decreasing function of the training dataset\nsize and the regularization weight. We also prove that, if the sensitivity of\nthe machine learning model (defined in terms of the derivatives of the fitness\nwith respect to model parameters) is high, more membership information is\npotentially leaked. This illustrates that complex models, such as deep neural\nnetworks, are more susceptible to membership inference attacks in comparison to\nsimpler models with fewer degrees of freedom. We show that the amount of the\nmembership information leakage is reduced by\n$\\mathcal{O}(\\log^{1/2}(\\delta^{-1})\\epsilon^{-1})$ when using Gaussian\n$(\\epsilon,\\delta)$-differentially-private additive noises.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 00:42:08 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 00:43:42 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Farokhi", "Farhad", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "2001.10652", "submitter": "Weijia Zhang", "authors": "Weijia Zhang, Lin Liu, Jiuyong Li", "title": "Treatment effect estimation with disentangled latent factors", "comments": "Published in the Proceedings of the 35th AAAI Conference on\n  Artificial Intelligence (AAAI'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research has been devoted to the problem of estimating treatment effects\nfrom observational data; however, most methods assume that the observed\nvariables only contain confounders, i.e., variables that affect both the\ntreatment and the outcome. Unfortunately, this assumption is frequently\nviolated in real-world applications, since some variables only affect the\ntreatment but not the outcome, and vice versa. Moreover, in many cases only the\nproxy variables of the underlying confounding factors can be observed. In this\nwork, we first show the importance of differentiating confounding factors from\ninstrumental and risk factors for both average and conditional average\ntreatment effect estimation, and then we propose a variational inference\napproach to simultaneously infer latent factors from the observed variables,\ndisentangle the factors into three disjoint sets corresponding to the\ninstrumental, confounding, and risk factors, and use the disentangled factors\nfor treatment effect estimation. Experimental results demonstrate the\neffectiveness of the proposed method on a wide range of synthetic, benchmark,\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:00:36 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 02:28:34 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 13:42:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhang", "Weijia", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""]]}, {"id": "2001.10655", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Regularization Helps with Mitigating Poisoning Attacks:\n  Distributionally-Robust Machine Learning Using the Wasserstein Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use distributionally-robust optimization for machine learning to mitigate\nthe effect of data poisoning attacks. We provide performance guarantees for the\ntrained model on the original data (not including the poison records) by\ntraining the model for the worst-case distribution on a neighbourhood around\nthe empirical distribution (extracted from the training dataset corrupted by a\npoisoning attack) defined using the Wasserstein distance. We relax the\ndistributionally-robust machine learning problem by finding an upper bound for\nthe worst-case fitness based on the empirical sampled-averaged fitness and the\nLipschitz-constant of the fitness function (on the data for given model\nparameters) as regularizer. For regression models, we prove that this\nregularizer is equal to the dual norm of the model parameters. We use the Wine\nQuality dataset, the Boston Housing Market dataset, and the Adult dataset for\ndemonstrating the results of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:16:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2001.10657", "submitter": "Patrick Dallaire", "authors": "Patrick Dallaire, Luca Ambrogioni, Ludovic Trottier, Umut\n  G\\\"u\\c{c}l\\\"u, Max Hinne, Philippe Gigu\\`ere, Brahim Chaib-Draa, Marcel van\n  Gerven, and Francois Laviolette", "title": "The Indian Chefs Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Indian Chefs Process (ICP), a Bayesian\nnonparametric prior on the joint space of infinite directed acyclic graphs\n(DAGs) and orders that generalizes Indian Buffet Processes. As our construction\nshows, the proposed distribution relies on a latent Beta Process controlling\nboth the orders and outgoing connection probabilities of the nodes, and yields\na probability distribution on sparse infinite graphs. The main advantage of the\nICP over previously proposed Bayesian nonparametric priors for DAG structures\nis its greater flexibility. To the best of our knowledge, the ICP is the first\nBayesian nonparametric model supporting every possible DAG. We demonstrate the\nusefulness of the ICP on learning the structure of deep generative sigmoid\nnetworks as well as convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 01:28:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Dallaire", "Patrick", ""], ["Ambrogioni", "Luca", ""], ["Trottier", "Ludovic", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["Hinne", "Max", ""], ["Gigu\u00e8re", "Philippe", ""], ["Chaib-Draa", "Brahim", ""], ["van Gerven", "Marcel", ""], ["Laviolette", "Francois", ""]]}, {"id": "2001.10685", "submitter": "Joseph Bullock", "authors": "Tomaz Logar, Joseph Bullock, Edoardo Nemni, Lars Bromley, John A.\n  Quinn, Miguel Luengo-Oroz", "title": "PulseSatellite: A tool using human-AI feedback loops for satellite image\n  analysis in humanitarian contexts", "comments": "2 pages, 2 figures", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence, New\n  York, United States, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanitarian response to natural disasters and conflicts can be assisted by\nsatellite image analysis. In a humanitarian context, very specific satellite\nimage analysis tasks must be done accurately and in a timely manner to provide\noperational support. We present PulseSatellite, a collaborative satellite image\nanalysis tool which leverages neural network models that can be retrained\non-the fly and adapted to specific humanitarian contexts and geographies. We\npresent two case studies, in mapping shelters and floods respectively, that\nillustrate the capabilities of PulseSatellite.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 04:09:51 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Logar", "Tomaz", ""], ["Bullock", "Joseph", ""], ["Nemni", "Edoardo", ""], ["Bromley", "Lars", ""], ["Quinn", "John A.", ""], ["Luengo-Oroz", "Miguel", ""]]}, {"id": "2001.10696", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Shanlin Xiao, Zhiyi Yu", "title": "Spiking Inception Module for Multi-layer Unsupervised Spiking Neural\n  Networks", "comments": "Published at the 2020 International Joint Conference on Neural\n  Networks (IJCNN); Extended from arXiv:2001.01680", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-8", "doi": "10.1109/IJCNN48605.2020.9207161", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Network (SNN), as a brain-inspired approach, is attracting\nattention due to its potential to produce ultra-high-energy-efficient hardware.\nCompetitive learning based on Spike-Timing-Dependent Plasticity (STDP) is a\npopular method to train an unsupervised SNN. However, previous unsupervised\nSNNs trained through this method are limited to a shallow network with only one\nlearnable layer and cannot achieve satisfactory results when compared with\nmulti-layer SNNs. In this paper, we eased this limitation by: 1)We proposed a\nSpiking Inception (Sp-Inception) module, inspired by the Inception module in\nthe Artificial Neural Network (ANN) literature. This module is trained through\nSTDP-based competitive learning and outperforms the baseline modules on\nlearning capability, learning efficiency, and robustness. 2)We proposed a\nPooling-Reshape-Activate (PRA) layer to make the Sp-Inception module stackable.\n3)We stacked multiple Sp-Inception modules to construct multi-layer SNNs. Our\nalgorithm outperforms the baseline algorithms on the hand-written digit\nclassification task, and reaches state-of-the-art results on the MNIST dataset\namong the existing unsupervised SNNs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 05:40:29 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:27:10 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 16:04:17 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 13:37:10 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 20:59:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.10710", "submitter": "Souvik Kundu", "authors": "Souvik Kundu, Mahdi Nazemi, Massoud Pedram, Keith M. Chugg, Peter A.\n  Beerel", "title": "Pre-defined Sparsity for Low-Complexity Convolutional Neural Networks", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high energy cost of processing deep convolutional neural networks impedes\ntheir ubiquitous deployment in energy-constrained platforms such as embedded\nsystems and IoT devices. This work introduces convolutional layers with\npre-defined sparse 2D kernels that have support sets that repeat periodically\nwithin and across filters. Due to the efficient storage of our periodic sparse\nkernels, the parameter savings can translate into considerable improvements in\nenergy efficiency due to reduced DRAM accesses, thus promising significant\nimprovements in the trade-off between energy consumption and accuracy for both\ntraining and inference. To evaluate this approach, we performed experiments\nwith two widely accepted datasets, CIFAR-10 and Tiny ImageNet in sparse\nvariants of the ResNet18 and VGG16 architectures. Compared to baseline models,\nour proposed sparse variants require up to 82% fewer model parameters with\n5.6times fewer FLOPs with negligible loss in accuracy for ResNet18 on CIFAR-10.\nFor VGG16 trained on Tiny ImageNet, our approach requires 5.8times fewer FLOPs\nand up to 83.3% fewer model parameters with a drop in top-5 (top-1) accuracy of\nonly 1.2% (2.1%). We also compared the performance of our proposed\narchitectures with that of ShuffleNet andMobileNetV2. Using similar\nhyperparameters and FLOPs, our ResNet18 variants yield an average accuracy\nimprovement of 2.8%.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 07:10:56 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:26:39 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Kundu", "Souvik", ""], ["Nazemi", "Mahdi", ""], ["Pedram", "Massoud", ""], ["Chugg", "Keith M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2001.10726", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Hao Wang, Enrique Alba, Thomas B\\\"ack", "title": "Bayesian Neural Architecture Search using A Training-Free Performance\n  Metric", "comments": null, "journal-ref": "Applied Soft Computing, p.107356 (2021)", "doi": "10.1016/j.asoc.2021.107356", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a powerful approach for time series\nprediction. However, their performance is strongly affected by their\narchitecture and hyperparameter settings. The architecture optimization of RNNs\nis a time-consuming task, where the search space is typically a mixture of\nreal, integer and categorical values. To allow for shrinking and expanding the\nsize of the network, the representation of architectures often has a variable\nlength. In this paper, we propose to tackle the architecture optimization\nproblem with a variant of the Bayesian Optimization (BO) algorithm. To reduce\nthe evaluation time of candidate architectures the Mean Absolute Error Random\nSampling (MRS), a training-free method to estimate the network performance, is\nadopted as the objective function for BO. Also, we propose three fixed-length\nencoding schemes to cope with the variable-length architecture representation.\nThe result is a new perspective on accurate and efficient design of RNNs, that\nwe validate on three problems. Our findings show that 1) the BO algorithm can\nexplore different network architectures using the proposed encoding schemes and\nsuccessfully designs well-performing architectures, and 2) the optimization\ntime is significantly reduced by using MRS, without compromising the\nperformance as compared to the architectures obtained from the actual training\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:42:58 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 07:48:42 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Wang", "Hao", ""], ["Alba", "Enrique", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2001.10741", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Marcel Wever, Eyke H\\\"ullermeier", "title": "Extreme Algorithm Selection With Dyadic Feature Representation", "comments": "Published at Discovery Science 2020", "journal-ref": null, "doi": "10.1007/978-3-030-61527-7_21", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithm selection (AS) deals with selecting an algorithm from a fixed set\nof candidate algorithms most suitable for a specific instance of an algorithmic\nproblem, e.g., choosing solvers for SAT problems. Benchmark suites for AS\nusually comprise candidate sets consisting of at most tens of algorithms,\nwhereas in combined algorithm selection and hyperparameter optimization\nproblems the number of candidates becomes intractable, impeding to learn\neffective meta-models and thus requiring costly online performance evaluations.\nTherefore, here we propose the setting of extreme algorithm selection (XAS)\nwhere we consider fixed sets of thousands of candidate algorithms, facilitating\nmeta learning. We assess the applicability of state-of-the-art AS techniques to\nthe XAS setting and propose approaches leveraging a dyadic feature\nrepresentation in which both problem instances and algorithms are described. We\nfind the latter to improve significantly over the current state of the art in\nvarious metrics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:40:58 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:56:33 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Tornede", "Alexander", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2001.10742", "submitter": "Ming Yin", "authors": "Ming Yin and Yu-Xiang Wang (University of California Santa Barbara)", "title": "Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement\n  Learning", "comments": "Includes appendix. Accepted for AISTATS 2020", "journal-ref": "International Conference on Artificial Intelligence and\n  Statistics, 108 (2020) 3948-3958", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of off-policy evaluation for reinforcement learning,\nwhere the goal is to estimate the expected reward of a target policy $\\pi$\nusing offline data collected by running a logging policy $\\mu$. Standard\nimportance-sampling based approaches for this problem suffer from a variance\nthat scales exponentially with time horizon $H$, which motivates a splurge of\nrecent interest in alternatives that break the \"Curse of Horizon\" (Liu et al.\n2018, Xie et al. 2019). In particular, it was shown that a marginalized\nimportance sampling (MIS) approach can be used to achieve an estimation error\nof order $O(H^3/ n)$ in mean square error (MSE) under an episodic Markov\nDecision Process model with finite states and potentially infinite actions. The\nMSE bound however is still a factor of $H$ away from a Cramer-Rao lower bound\nof order $\\Omega(H^2/n)$. In this paper, we prove that with a simple\nmodification to the MIS estimator, we can asymptotically attain the Cramer-Rao\nlower bound, provided that the action space is finite. We also provide a\ngeneral method for constructing MIS estimators with high-probability error\nbounds.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:56:26 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yin", "Ming", "", "University of California Santa Barbara"], ["Wang", "Yu-Xiang", "", "University of California Santa Barbara"]]}, {"id": "2001.10789", "submitter": "Dan Barnes", "authors": "Dan Barnes and Ingmar Posner", "title": "Under the Radar: Learning to Predict Robust Keypoints for Odometry\n  Estimation and Metric Localisation in Radar", "comments": "Video summary: https://youtu.be/L-PO7nxWpJU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a self-supervised framework for learning to detect robust\nkeypoints for odometry estimation and metric localisation in radar. By\nembedding a differentiable point-based motion estimator inside our\narchitecture, we learn keypoint locations, scores and descriptors from\nlocalisation error alone. This approach avoids imposing any assumption on what\nmakes a robust keypoint and crucially allows them to be optimised for our\napplication. Furthermore the architecture is sensor agnostic and can be applied\nto most modalities. We run experiments on 280km of real world driving from the\nOxford Radar RobotCar Dataset and improve on the state-of-the-art in\npoint-based radar odometry, reducing errors by up to 45% whilst running an\norder of magnitude faster, simultaneously solving metric loop closures.\nCombining these outputs, we provide a framework capable of full mapping and\nlocalisation with radar in urban environments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 12:59:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 10:36:00 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 13:43:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Barnes", "Dan", ""], ["Posner", "Ingmar", ""]]}, {"id": "2001.10816", "submitter": "Siddharth Sigtia", "authors": "Siddharth Sigtia, Erik Marchi, Sachin Kajarekar, Devang Naik, John\n  Bridle", "title": "Multi-task Learning for Speaker Verification and Voice Trigger Detection", "comments": null, "journal-ref": "International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Spain, 2020, pp. 6844-6848", "doi": "10.1109/ICASSP40776.2020.9054760", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech transcription and speaker recognition are usually treated as\nseparate tasks even though they are interdependent. In this study, we\ninvestigate training a single network to perform both tasks jointly. We train\nthe network in a supervised multi-task learning setup, where the speech\ntranscription branch of the network is trained to minimise a phonetic\nconnectionist temporal classification (CTC) loss while the speaker recognition\nbranch of the network is trained to label the input sequence with the correct\nlabel for the speaker. We present a large-scale empirical study where the model\nis trained using several thousand hours of labelled training data for each\ntask. We evaluate the speech transcription branch of the network on a voice\ntrigger detection task while the speaker recognition branch is evaluated on a\nspeaker verification task. Results demonstrate that the network is able to\nencode both phonetic \\emph{and} speaker information in its learnt\nrepresentations while yielding accuracies at least as good as the baseline\nmodels for each task, with the same number of parameters as the independent\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 21:19:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sigtia", "Siddharth", ""], ["Marchi", "Erik", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""], ["Bridle", "John", ""]]}, {"id": "2001.10817", "submitter": "Soonshin Seo", "authors": "Soonshin Seo, Ji-Hwan Kim", "title": "MCSAE: Masked Cross Self-Attentive Encoding for Speaker Embedding", "comments": "5 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, a self-attention mechanism has been applied for speaker embedding\nencoding. Previous studies focused on training the self-attention in a\nhigh-level layer, such as the last pooling layer. However, the effect of\nlow-level features was reduced in the speaker embedding encoding. Therefore, we\npropose masked cross self-attentive encoding (MCSAE) using ResNet. It focuses\non the features of both high-level and lowlevel layers. Based on multi-layer\naggregation, the output features of each residual layer are used for the MCSAE.\nIn the MCSAE, cross self-attention module is trained the interdependence of\neach input features. A random masking regularization module also applied to\npreventing overfitting problem. As such, the MCSAE enhances the weight of\nframes representing the speaker information. Then, the output features are\nconcatenated and encoded to the speaker embedding. Therefore, a more\ninformative speaker embedding is encoded by using the MCSAE. The experimental\nresults showed an equal error rate of 2.63% and a minimum detection cost\nfunction of 0.1453 using the VoxCeleb1 evaluation dataset. These were improved\nperformances compared with the previous self-attentive encoding and\nstate-of-the-art encoding methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:09:11 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 18:47:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 08:05:36 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 07:19:37 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Seo", "Soonshin", ""], ["Kim", "Ji-Hwan", ""]]}, {"id": "2001.10818", "submitter": "George Wynne", "authors": "George Wynne, Fran\\c{c}ois-Xavier Briol and Mark Girolami", "title": "Convergence Guarantees for Gaussian Process Means With Misspecified\n  Likelihoods and Smoothness", "comments": "Accepted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG cs.NA math.NA stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are ubiquitous in machine learning, statistics, and\napplied mathematics. They provide a flexible modelling framework for\napproximating functions, whilst simultaneously quantifying uncertainty.\nHowever, this is only true when the model is well-specified, which is often not\nthe case in practice. In this paper, we study the properties of Gaussian\nprocess means when the smoothness of the model and the likelihood function are\nmisspecified. In this setting, an important theoretical question of practial\nrelevance is how accurate the Gaussian process approximations will be given the\ndifficulty of the problem, our model and the extent of the misspecification.\nThe answer to this problem is particularly useful since it can inform our\nchoice of model and experimental design. In particular, we describe how the\nexperimental design and choice of kernel and kernel hyperparameters can be\nadapted to alleviate model misspecification.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 13:28:27 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:52:29 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 12:33:03 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wynne", "George", ""], ["Briol", "Fran\u00e7ois-Xavier", ""], ["Girolami", "Mark", ""]]}, {"id": "2001.10820", "submitter": "Gopi Kishan", "authors": "Gopi Kishan", "title": "Reproducibility Challenge NeurIPS 2019 Report on \"Competitive Gradient\n  Descent\"", "comments": "9 Pages. arXiv admin note: substantial text overlap with 1905.12103;\n  substantial text overlap with arXiv:1905.12103 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a report for reproducibility challenge of NeurlIPS 2019 on the paper\nCompetitive Gradient Descent (Schafer et al., 2019). The paper introduces a\nnovel algorithm for the numerical computation of Nash equilibria of competitive\ntwo-player games. It avoids oscillatory and divergent behaviours seen in\nalternating gradient descent. The purpose of this report is to critically\nexamine the reproducibility of the work by (Schafer et al., 2019), within the\nframework of the NeurIPS 2019 Reproducibility Challenge. The experiments\nreplicated in this report confirms the results of the original study. Moreover,\nthis project offers a Python (Pytorch based) implementation of the proposed CGD\nalgorithm which can be found at the following public git repository:\n(https://github.com/GopiKishan14/Reproducibility_Challenge_NeurIPS_2019)\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 11:51:38 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kishan", "Gopi", ""]]}, {"id": "2001.10822", "submitter": "Pranay Dighe", "authors": "Pranay Dighe, Saurabh Adya, Nuoyu Li, Srikanth Vishnubhotla, Devang\n  Naik, Adithya Sagar, Ying Ma, Stephen Pulman, Jason Williams", "title": "Lattice-based Improvements for Voice Triggering Using Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-triggered smart assistants often rely on detection of a trigger-phrase\nbefore they start listening for the user request. Mitigation of false triggers\nis an important aspect of building a privacy-centric non-intrusive smart\nassistant. In this paper, we address the task of false trigger mitigation (FTM)\nusing a novel approach based on analyzing automatic speech recognition (ASR)\nlattices using graph neural networks (GNN). The proposed approach uses the fact\nthat decoding lattice of a falsely triggered audio exhibits uncertainties in\nterms of many alternative paths and unexpected words on the lattice arcs as\ncompared to the lattice of a correctly triggered audio. A pure trigger-phrase\ndetector model doesn't fully utilize the intent of the user speech whereas by\nusing the complete decoding lattice of user audio, we can effectively mitigate\nspeech not intended for the smart assistant. We deploy two variants of GNNs in\nthis paper based on 1) graph convolution layers and 2) self-attention mechanism\nrespectively. Our experiments demonstrate that GNNs are highly accurate in FTM\ntask by mitigating ~87% of false triggers at 99% true positive rate (TPR).\nFurthermore, the proposed models are fast to train and efficient in parameter\nrequirements.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 01:34:15 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Dighe", "Pranay", ""], ["Adya", "Saurabh", ""], ["Li", "Nuoyu", ""], ["Vishnubhotla", "Srikanth", ""], ["Naik", "Devang", ""], ["Sagar", "Adithya", ""], ["Ma", "Ying", ""], ["Pulman", "Stephen", ""], ["Williams", "Jason", ""]]}, {"id": "2001.10829", "submitter": "Georgios Papoudakis", "authors": "Georgios Papoudakis, Stefano V. Albrecht", "title": "Variational Autoencoders for Opponent Modeling in Multi-Agent Systems", "comments": "AAAI-20 Workshop on Reinforcement Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent systems exhibit complex behaviors that emanate from the\ninteractions of multiple agents in a shared environment. In this work, we are\ninterested in controlling one agent in a multi-agent system and successfully\nlearn to interact with the other agents that have fixed policies. Modeling the\nbehavior of other agents (opponents) is essential in understanding the\ninteractions of the agents in the system. By taking advantage of recent\nadvances in unsupervised learning, we propose modeling opponents using\nvariational autoencoders. Additionally, many existing methods in the literature\nassume that the opponent models have access to opponent's observations and\nactions during both training and execution. To eliminate this assumption, we\npropose a modification that attempts to identify the underlying opponent model\nusing only local information of our agent, such as its observations, actions,\nand rewards. The experiments indicate that our opponent modeling methods\nachieve equal or greater episodic returns in reinforcement learning tasks\nagainst another modeling method.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 13:38:59 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Papoudakis", "Georgios", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2001.10830", "submitter": "Sayantan Bhadra Mr.", "authors": "Sayantan Bhadra, Weimin Zhou, and Mark A. Anastasio", "title": "Medical image reconstruction with image-adaptive priors learned by use\n  of generative adversarial networks", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image reconstruction is typically an ill-posed inverse problem. In\norder to address such ill-posed problems, the prior distribution of the sought\nafter object property is usually incorporated by means of some\nsparsity-promoting regularization. Recently, prior distributions for images\nestimated using generative adversarial networks (GANs) have shown great promise\nin regularizing some of these image reconstruction problems. In this work, we\napply an image-adaptive GAN-based reconstruction method (IAGAN) to reconstruct\nhigh fidelity images from incomplete medical imaging data. It is observed that\nthe IAGAN method can potentially recover fine structures in the object that are\nrelevant for medical diagnosis but may be oversmoothed in reconstructions with\ntraditional sparsity-promoting regularization.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 23:39:47 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Bhadra", "Sayantan", ""], ["Zhou", "Weimin", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2001.10832", "submitter": "Rohith Aralikatti", "authors": "Rohith Aralikatti, Sharad Roy, Abhinav Thanda, Dilip Kumar Margam,\n  Pujitha Appan Kandala, Tanay Sharma and Shankar M Venkatesan", "title": "Audio-Visual Decision Fusion for WFST-based and seq2seq Models", "comments": "Submitted for review to ICASSP 2020 on October 21st, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under noisy conditions, speech recognition systems suffer from high Word\nError Rates (WER). In such cases, information from the visual modality\ncomprising the speaker lip movements can help improve the performance. In this\nwork, we propose novel methods to fuse information from audio and visual\nmodalities at inference time. This enables us to train the acoustic and visual\nmodels independently. First, we train separate RNN-HMM based acoustic and\nvisual models. A common WFST generated by taking a special union of the HMM\ncomponents is used for decoding using a modified Viterbi algorithm. Second, we\ntrain separate seq2seq acoustic and visual models. The decoding step is\nperformed simultaneously for both modalities using shallow fusion while\nmaintaining a common hypothesis beam. We also present results for a novel\nseq2seq fusion without the weighing parameter. We present results at varying\nSNR and show that our methods give significant improvements over acoustic-only\nWER.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 13:45:08 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Aralikatti", "Rohith", ""], ["Roy", "Sharad", ""], ["Thanda", "Abhinav", ""], ["Margam", "Dilip Kumar", ""], ["Kandala", "Pujitha Appan", ""], ["Sharma", "Tanay", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "2001.10866", "submitter": "Hugo Abreu Mendes", "authors": "Hugo Abreu Mendes, Henrique Ferreira Nunes, Manoel da Nobrega Marinho,\n  Paulo Salgado Gomes de Mattos Neto", "title": "Data integration and prediction models of photovoltaic production from\n  Brazilian northeastern", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All productive branches of society need an estimate to be able to control\ntheir expenses well. In the energy business, electric utilities use this\ninformation to control the power flow in the grid. For better energy production\nestimation of photovoltaic systems, it is necessary to join multiples\ngeospatial and meteorological variables. This work proposes the creation of a\nsatellite data integration platform, with production estimation models, base\nstations measurement and actual production capacity. This work presents\nstatistical, probabilistic and artificial intelligence models that generate\nspatial and temporal production estimates that could improve production gains\nas well as facilitate the monitoring and supervision of new enterprises are\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 14:39:33 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 01:13:36 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mendes", "Hugo Abreu", ""], ["Nunes", "Henrique Ferreira", ""], ["Marinho", "Manoel da Nobrega", ""], ["Neto", "Paulo Salgado Gomes de Mattos", ""]]}, {"id": "2001.10872", "submitter": "Alessio Figalli", "authors": "Oksana Berezniuk, Alessio Figalli, Raffaele Ghigliazza, Kharen\n  Musaelian", "title": "A scale-dependent notion of effective dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a notion of \"effective dimension\" of a statistical model based\non the number of cubes of size $1/\\sqrt{n}$ needed to cover the model space\nwhen endowed with the Fisher Information Matrix as metric, $n$ being the number\nof observations. The number of observations fixes a natural scale or\nresolution. The effective dimension is then measured via the spectrum of the\nFisher Information Matrix regularized using this natural scale.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 14:48:51 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Berezniuk", "Oksana", ""], ["Figalli", "Alessio", ""], ["Ghigliazza", "Raffaele", ""], ["Musaelian", "Kharen", ""]]}, {"id": "2001.10876", "submitter": "Alessio Brutti", "authors": "Gianmarco Cerutti, Rahul Prasad, Alessio Brutti, and Elisabetta\n  Farella", "title": "Compact recurrent neural networks for acoustic event detection on\n  low-energy low-complexity platforms", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2020.2969775", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outdoor acoustic events detection is an exciting research field but\nchallenged by the need for complex algorithms and deep learning techniques,\ntypically requiring many computational, memory, and energy resources. This\nchallenge discourages IoT implementation, where an efficient use of resources\nis required. However, current embedded technologies and microcontrollers have\nincreased their capabilities without penalizing energy efficiency. This paper\naddresses the application of sound event detection at the edge, by optimizing\ndeep learning techniques on resource-constrained embedded platforms for the\nIoT. The contribution is two-fold: firstly, a two-stage student-teacher\napproach is presented to make state-of-the-art neural networks for sound event\ndetection fit on current microcontrollers; secondly, we test our approach on an\nARM Cortex M4, particularly focusing on issues related to 8-bits quantization.\nOur embedded implementation can achieve 68% accuracy in recognition on\nUrbansound8k, not far from state-of-the-art performance, with an inference time\nof 125 ms for each second of the audio stream, and power consumption of 5.5 mW\nin just 34.3 kB of RAM.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 14:56:52 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Cerutti", "Gianmarco", ""], ["Prasad", "Rahul", ""], ["Brutti", "Alessio", ""], ["Farella", "Elisabetta", ""]]}, {"id": "2001.10883", "submitter": "Max Berrendorf", "authors": "Diana Davletshina, Valentyn Melnychuk, Viet Tran, Hitansh Singla, Max\n  Berrendorf, Evgeniy Faerman, Michael Fromm, and Matthias Schubert", "title": "Unsupervised Anomaly Detection for X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining labels for medical (image) data requires scarce and expensive\nexperts. Moreover, due to ambiguous symptoms, single images rarely suffice to\ncorrectly diagnose a medical condition. Instead, it often requires to take\nadditional background information such as the patient's medical history or test\nresults into account. Hence, instead of focusing on uninterpretable black-box\nsystems delivering an uncertain final diagnosis in an end-to-end-fashion, we\ninvestigate how unsupervised methods trained on images without anomalies can be\nused to assist doctors in evaluating X-ray images of hands. Our method\nincreases the efficiency of making a diagnosis and reduces the risk of missing\nimportant regions. Therefore, we adopt state-of-the-art approaches for\nunsupervised learning to detect anomalies and show how the outputs of these\nmethods can be explained. To reduce the effect of noise, which often can be\nmistaken for an anomaly, we introduce a powerful preprocessing pipeline. We\nprovide an extensive evaluation of different approaches and demonstrate\nempirically that even without labels it is possible to achieve satisfying\nresults on a real-world dataset of X-ray images of hands. We also evaluate the\nimportance of preprocessing and one of our main findings is that without it,\nmost of our approaches perform not better than random. To foster\nreproducibility and accelerate research we make our code publicly available at\nhttps://github.com/Valentyn1997/xray\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:14:56 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 12:26:37 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Davletshina", "Diana", ""], ["Melnychuk", "Valentyn", ""], ["Tran", "Viet", ""], ["Singla", "Hitansh", ""], ["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Fromm", "Michael", ""], ["Schubert", "Matthias", ""]]}, {"id": "2001.10893", "submitter": "Peter Fenner", "authors": "Peter Fenner, Edward O. Pyzer-Knapp", "title": "Privacy-Preserving Gaussian Process Regression -- A Modular Approach to\n  the Application of Homomorphic Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of machine learning relies on the use of large amounts of data to train\nmodels to make predictions. When this data comes from multiple sources, for\nexample when evaluation of data against a machine learning model is offered as\na service, there can be privacy issues and legal concerns over the sharing of\ndata. Fully homomorphic encryption (FHE) allows data to be computed on whilst\nencrypted, which can provide a solution to the problem of data privacy.\nHowever, FHE is both slow and restrictive, so existing algorithms must be\nmanipulated to make them work efficiently under the FHE paradigm. Some commonly\nused machine learning algorithms, such as Gaussian process regression, are\npoorly suited to FHE and cannot be manipulated to work both efficiently and\naccurately. In this paper, we show that a modular approach, which applies FHE\nto only the sensitive steps of a workflow that need protection, allows one\nparty to make predictions on their data using a Gaussian process regression\nmodel built from another party's data, without either party gaining access to\nthe other's data, in a way which is both accurate and efficient. This\nconstruction is, to our knowledge, the first example of an effectively\nencrypted Gaussian process.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 11:50:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Fenner", "Peter", ""], ["Pyzer-Knapp", "Edward O.", ""]]}, {"id": "2001.10900", "submitter": "Roman Pflugfelder", "authors": "Roman Pflugfelder, Axel Weissenfeld, Julian Wagner", "title": "On Learning Vehicle Detection in Satellite Video", "comments": "accepted by Computer Vision Winter Workshop\n  (https://cvww2020.vicos.si)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle detection in aerial and satellite images is still challenging due to\ntheir tiny appearance in pixels compared to the overall size of remote sensing\nimagery. Classical methods of object detection very often fail in this scenario\ndue to violation of implicit assumptions made such as rich texture, small to\nmoderate ratios between image size and object size. Satellite video is a very\nnew modality which introduces temporal consistency as inductive bias.\nApproaches for vehicle detection in satellite video use either background\nsubtraction, frame differencing or subspace methods showing moderate\nperformance (0.26 - 0.82 $F_1$ score). This work proposes to apply recent work\non deep learning for wide-area motion imagery (WAMI) on satellite video. We\nshow in a first approach comparable results (0.84 $F_1$) on Planet's SkySat-1\nLasVegas video with room for further improvement.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:35:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Pflugfelder", "Roman", ""], ["Weissenfeld", "Axel", ""], ["Wagner", "Julian", ""]]}, {"id": "2001.10913", "submitter": "Andrea Banino", "authors": "Andrea Banino, Adri\\`a Puigdom\\`enech Badia, Raphael K\\\"oster, Martin\n  J. Chadwick, Vinicius Zambaldi, Demis Hassabis, Caswell Barry, Matthew\n  Botvinick, Dharshan Kumaran, Charles Blundell", "title": "MEMO: A Deep Network for Flexible Combination of Episodic Memories", "comments": "9 pages, 2 figures, 3 tables, to be published as a conference paper\n  at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research developing neural network architectures with external memory\nhave often used the benchmark bAbI question and answering dataset which\nprovides a challenging number of tasks requiring reasoning. Here we employed a\nclassic associative inference task from the memory-based reasoning neuroscience\nliterature in order to more carefully probe the reasoning capacity of existing\nmemory-augmented architectures. This task is thought to capture the essence of\nreasoning -- the appreciation of distant relationships among elements\ndistributed across multiple facts or memories. Surprisingly, we found that\ncurrent architectures struggle to reason over long distance associations.\nSimilar results were obtained on a more complex task involving finding the\nshortest path between nodes in a path. We therefore developed MEMO, an\narchitecture endowed with the capacity to reason over longer distances. This\nwas accomplished with the addition of two novel components. First, it\nintroduces a separation between memories (facts) stored in external memory and\nthe items that comprise these facts in external memory. Second, it makes use of\nan adaptive retrieval mechanism, allowing a variable number of \"memory hops\"\nbefore the answer is produced. MEMO is capable of solving our novel reasoning\ntasks, as well as match state of the art results in bAbI.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 15:56:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Banino", "Andrea", ""], ["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["K\u00f6ster", "Raphael", ""], ["Chadwick", "Martin J.", ""], ["Zambaldi", "Vinicius", ""], ["Hassabis", "Demis", ""], ["Barry", "Caswell", ""], ["Botvinick", "Matthew", ""], ["Kumaran", "Dharshan", ""], ["Blundell", "Charles", ""]]}, {"id": "2001.10916", "submitter": "Sherif Saad", "authors": "William Briguglio and Sherif Saad", "title": "Interpreting Machine Learning Malware Detectors Which Leverage N-gram\n  Analysis", "comments": "18 pages, The 12th International Symposium on Foundations & Practice\n  of Security, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cyberattack detection and prevention systems, cybersecurity analysts\nalways prefer solutions that are as interpretable and understandable as\nrule-based or signature-based detection. This is because of the need to tune\nand optimize these solutions to mitigate and control the effect of false\npositives and false negatives. Interpreting machine learning models is a new\nand open challenge. However, it is expected that an interpretable machine\nlearning solution will be domain-specific. For instance, interpretable\nsolutions for machine learning models in healthcare are different than\nsolutions in malware detection. This is because the models are complex, and\nmost of them work as a black-box. Recently, the increased ability for malware\nauthors to bypass antimalware systems has forced security specialists to look\nto machine learning for creating robust detection systems. If these systems are\nto be relied on in the industry, then, among other challenges, they must also\nexplain their predictions. The objective of this paper is to evaluate the\ncurrent state-of-the-art ML models interpretability techniques when applied to\nML-based malware detectors. We demonstrate interpretability techniques in\npractice and evaluate the effectiveness of existing interpretability techniques\nin the malware analysis domain.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:10:50 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Briguglio", "William", ""], ["Saad", "Sherif", ""]]}, {"id": "2001.10964", "submitter": "Arjun Punjabi", "authors": "Arjun Punjabi, Jonas Schmid, Aggelos K. Katsaggelos", "title": "Examining the Benefits of Capsule Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks are a recently developed class of neural networks that\npotentially address some of the deficiencies with traditional convolutional\nneural networks. By replacing the standard scalar activations with vectors, and\nby connecting the artificial neurons in a new way, capsule networks aim to be\nthe next great development for computer vision applications. However, in order\nto determine whether these networks truly operate differently than traditional\nnetworks, one must look at the differences in the capsule features. To this\nend, we perform several analyses with the purpose of elucidating capsule\nfeatures and determining whether they perform as described in the initial\npublication. First, we perform a deep visualization analysis to visually\ncompare capsule features and convolutional neural network features. Then, we\nlook at the ability for capsule features to encode information across the\nvector components and address what changes in the capsule architecture provides\nthe most benefit. Finally, we look at how well the capsule features are able to\nencode instantiation parameters of class objects via visual transformations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:18:43 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Punjabi", "Arjun", ""], ["Schmid", "Jonas", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "2001.10972", "submitter": "Samuele Tosatto", "authors": "Samuele Tosatto, Riad Akrour, Jan Peters", "title": "An Upper Bound of the Bias of Nadaraya-Watson Kernel Regression under\n  Lipschitz Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nadaraya-Watson kernel estimator is among the most popular nonparameteric\nregression technique thanks to its simplicity. Its asymptotic bias has been\nstudied by Rosenblatt in 1969 and has been reported in a number of related\nliterature. However, Rosenblatt's analysis is only valid for infinitesimal\nbandwidth. In contrast, we propose in this paper an upper bound of the bias\nwhich holds for finite bandwidths. Moreover, contrarily to the classic analysis\nwe allow for discontinuous first order derivative of the regression function,\nwe extend our bounds for multidimensional domains and we include the knowledge\nof the bound of the regression function when it exists and if it is known, to\nobtain a tighter bound. We believe that this work has potential applications in\nthose fields where some hard guarantees on the error are needed\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:33:58 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 09:01:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Tosatto", "Samuele", ""], ["Akrour", "Riad", ""], ["Peters", "Jan", ""]]}, {"id": "2001.10977", "submitter": "Xiaoli Liu", "authors": "Xiaoli Liu, Pan Hu, Zhi Mao, Po-Chih Kuo, Peiyao Li, Chao Liu, Jie Hu,\n  Deyu Li, Desen Cao, Roger G. Mark, Leo Anthony Celi, Zhengbo Zhang, Feihu\n  Zhou", "title": "Interpretable Machine Learning Model for Early Prediction of Mortality\n  in Elderly Patients with Multiple Organ Dysfunction Syndrome (MODS): a\n  Multicenter Retrospective Study and Cross Validation", "comments": "33 pages, 14 figures, 14 tables, article, Co-author: Xiaoli Liu and\n  Pan Hu, Co-correspondence: Feihu Zhou and Zhengbo Zhang", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Elderly patients with MODS have high risk of death and poor\nprognosis. The performance of current scoring systems assessing the severity of\nMODS and its mortality remains unsatisfactory. This study aims to develop an\ninterpretable and generalizable model for early mortality prediction in elderly\npatients with MODS. Methods: The MIMIC-III, eICU-CRD and PLAGH-S databases were\nemployed for model generation and evaluation. We used the eXtreme Gradient\nBoosting model with the SHapley Additive exPlanations method to conduct early\nand interpretable predictions of patients' hospital outcome. Three types of\ndata source combinations and five typical evaluation indexes were adopted to\ndevelop a generalizable model. Findings: The interpretable model, with optimal\nperformance developed by using MIMIC-III and eICU-CRD datasets, was separately\nvalidated in MIMIC-III, eICU-CRD and PLAGH-S datasets (no overlapping with\ntraining set). The performances of the model in predicting hospital mortality\nas validated by the three datasets were: AUC of 0.858, sensitivity of 0.834 and\nspecificity of 0.705; AUC of 0.849, sensitivity of 0.763 and specificity of\n0.784; and AUC of 0.838, sensitivity of 0.882 and specificity of 0.691,\nrespectively. Comparisons of AUC between this model and baseline models with\nMIMIC-III dataset validation showed superior performances of this model; In\naddition, comparisons in AUC between this model and commonly used clinical\nscores showed significantly better performance of this model. Interpretation:\nThe interpretable machine learning model developed in this study using fused\ndatasets with large sample sizes was robust and generalizable. This model\noutperformed the baseline models and several clinical scores for early\nprediction of mortality in elderly ICU patients. The interpretative nature of\nthis model provided clinicians with the ranking of mortality risk features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:34 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Liu", "Xiaoli", ""], ["Hu", "Pan", ""], ["Mao", "Zhi", ""], ["Kuo", "Po-Chih", ""], ["Li", "Peiyao", ""], ["Liu", "Chao", ""], ["Hu", "Jie", ""], ["Li", "Deyu", ""], ["Cao", "Desen", ""], ["Mark", "Roger G.", ""], ["Celi", "Leo Anthony", ""], ["Zhang", "Zhengbo", ""], ["Zhou", "Feihu", ""]]}, {"id": "2001.10980", "submitter": "Jing Jiang", "authors": "Jing Jiang", "title": "Multimodal Story Generation on Plural Images", "comments": "This is an undergraduate project report. Completed Dec. 2019 at the\n  Cooper Union", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, text generation models take in a sequence of text as input,\nand iteratively generate the next most probable word using pre-trained\nparameters. In this work, we propose the architecture to use images instead of\ntext as the input of the text generation model, called StoryGen. In the\narchitecture, we design a Relational Text Data Generator algorithm that relates\ndifferent features from multiple images. The output samples from the model\ndemonstrate the ability to generate meaningful paragraphs of text containing\nthe extracted features from the input images. This is an undergraduate project\nreport. Completed Dec. 2019 at the Cooper Union.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:39:00 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 10:44:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Jiang", "Jing", ""]]}, {"id": "2001.10995", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson", "title": "The Case for Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key distinguishing property of a Bayesian approach is marginalization\ninstead of optimization, not the prior, or Bayes rule. Bayesian inference is\nespecially compelling for deep neural networks. (1) Neural networks are\ntypically underspecified by the data, and can represent many different but high\nperforming models corresponding to different settings of parameters, which is\nexactly when marginalization will make the biggest difference for both\ncalibration and accuracy. (2) Deep ensembles have been mistaken as competing\napproaches to Bayesian methods, but can be seen as approximate Bayesian\nmarginalization. (3) The structure of neural networks gives rise to a\nstructured prior in function space, which reflects the inductive biases of\nneural networks that help them generalize. (4) The observed correlation between\nparameters in flat regions of the loss and a diversity of solutions that\nprovide good generalization is further conducive to Bayesian marginalization,\nas flat regions occupy a large volume in a high dimensional space, and each\ndifferent solution will make a good contribution to a Bayesian model average.\n(5) Recent practical advances for Bayesian deep learning provide improvements\nin accuracy and calibration compared to standard training, while retaining\nscalability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:08:52 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Wilson", "Andrew Gordon", ""]]}, {"id": "2001.10996", "submitter": "Anders Bredahl Kock", "authors": "Anders Bredahl Kock, David Preinerstorfer, Bezirgen Veliyev", "title": "Functional Sequential Treatment Allocation with Covariates", "comments": "The material in this paper replaces the material on covariates in\n  [v5] of \"Functional Sequential Treatment Allocation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multi-armed bandit problem with covariates. Given a realization\nof the covariate vector, instead of targeting the treatment with highest\nconditional expectation, the decision maker targets the treatment which\nmaximizes a general functional of the conditional potential outcome\ndistribution, e.g., a conditional quantile, trimmed mean, or a socio-economic\nfunctional such as an inequality, welfare or poverty measure. We develop\nexpected regret lower bounds for this problem, and construct a near minimax\noptimal assignment policy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:08:53 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Kock", "Anders Bredahl", ""], ["Preinerstorfer", "David", ""], ["Veliyev", "Bezirgen", ""]]}, {"id": "2001.10999", "submitter": "Shitong Zhu", "authors": "Shitong Zhu, Zhongjie Wang, Xun Chen, Shasha Li, Umar Iqbal, Zhiyun\n  Qian, Kevin S. Chan, Srikanth V. Krishnamurthy, Zubair Shafiq", "title": "A4 : Evading Learning-based Adblockers", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts by online ad publishers to circumvent traditional ad blockers towards\nregaining fiduciary benefits, have been demonstrably successful. As a result,\nthere have recently emerged a set of adblockers that apply machine learning\ninstead of manually curated rules and have been shown to be more robust in\nblocking ads on websites including social media sites such as Facebook. Among\nthese, AdGraph is arguably the state-of-the-art learning-based adblocker. In\nthis paper, we develop A4, a tool that intelligently crafts adversarial samples\nof ads to evade AdGraph. Unlike the popular research on adversarial samples\nagainst images or videos that are considered less- to un-restricted, the\nsamples that A4 generates preserve application semantics of the web page, or\nare actionable. Through several experiments we show that A4 can bypass AdGraph\nabout 60% of the time, which surpasses the state-of-the-art attack by a\nsignificant margin of 84.3%; in addition, changes to the visual layout of the\nweb page due to these perturbations are imperceptible. We envision the\nalgorithmic framework proposed in A4 is also promising in improving adversarial\nattacks against other learning-based web applications with similar\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:13:12 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Zhu", "Shitong", ""], ["Wang", "Zhongjie", ""], ["Chen", "Xun", ""], ["Li", "Shasha", ""], ["Iqbal", "Umar", ""], ["Qian", "Zhiyun", ""], ["Chan", "Kevin S.", ""], ["Krishnamurthy", "Srikanth V.", ""], ["Shafiq", "Zubair", ""]]}, {"id": "2001.11019", "submitter": "Andrew Titus", "authors": "Andrew Titus, Jan Silovsky, Nanxin Chen, Roger Hsiao, Mary Young and\n  Arnab Ghoshal", "title": "Improving Language Identification for Multilingual Speakers", "comments": "5 pages, 2 figures. Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language identification (LID) technologies have improved in recent\nyears from discriminating largely distinct languages to discriminating highly\nsimilar languages or even dialects of the same language. One aspect that has\nbeen mostly neglected, however, is discrimination of languages for multilingual\nspeakers, despite being a primary target audience of many systems that utilize\nLID technologies. As we show in this work, LID systems can have a high average\naccuracy for most combinations of languages while greatly underperforming for\nothers when accented speech is present. We address this by using\ncoarser-grained targets for the acoustic LID model and integrating its outputs\nwith interaction context signals in a context-aware model to tailor the system\nto each user. This combined system achieves an average 97% accuracy across all\nlanguage combinations while improving worst-case accuracy by over 60% relative\nto our baseline.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:58:11 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Titus", "Andrew", ""], ["Silovsky", "Jan", ""], ["Chen", "Nanxin", ""], ["Hsiao", "Roger", ""], ["Young", "Mary", ""], ["Ghoshal", "Arnab", ""]]}, {"id": "2001.11027", "submitter": "Volker Tresp", "authors": "Volker Tresp and Sahand Sharifzadeh and Dario Konopatzki and Yunpu Ma", "title": "The Tensor Brain: Semantic Decoding for Perception and Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse perception and memory, using mathematical models for knowledge\ngraphs and tensors, to gain insights into the corresponding functionalities of\nthe human mind. Our discussion is based on the concept of propositional\nsentences consisting of \\textit{subject-predicate-object} (SPO) triples for\nexpressing elementary facts. SPO sentences are the basis for most natural\nlanguages but might also be important for explicit perception and declarative\nmemories, as well as intra-brain communication and the ability to argue and\nreason. A set of SPO sentences can be described as a knowledge graph, which can\nbe transformed into an adjacency tensor. We introduce tensor models, where\nconcepts have dual representations as indices and associated embeddings, two\nconstructs we believe are essential for the understanding of implicit and\nexplicit perception and memory in the brain. We argue that a biological\nrealization of perception and memory imposes constraints on information\nprocessing. In particular, we propose that explicit perception and declarative\nmemories require a semantic decoder, which, in a simple realization, is based\non four layers: First, a sensory memory layer, as a buffer for sensory input,\nsecond, an index layer representing concepts, third, a memoryless\nrepresentation layer for the broadcasting of information ---the \"blackboard\",\nor the \"canvas\" of the brain--- and fourth, a working memory layer as a\nprocessing center and data buffer. We discuss the operations of the four layers\nand relate them to the global workspace theory. In a Bayesian brain\ninterpretation, semantic memory defines the prior for observable triple\nstatements. We propose that ---in evolution and during development--- semantic\nmemory, episodic memory, and natural language evolved as emergent properties in\nagents' process to gain a deeper understanding of sensory information.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 07:48:01 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:21:01 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 08:41:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Tresp", "Volker", ""], ["Sharifzadeh", "Sahand", ""], ["Konopatzki", "Dario", ""], ["Ma", "Yunpu", ""]]}, {"id": "2001.11031", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller and Torsten En{\\ss}lin", "title": "Bayesian Reasoning with Trained Neural Networks", "comments": null, "journal-ref": "Entropy 2021, 23(6), 693", "doi": "10.3390/e23060693", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We showed how to use trained neural networks to perform Bayesian reasoning in\norder to solve tasks outside their initial scope. Deep generative models\nprovide prior knowledge, and classification/regression networks impose\nconstraints. The tasks at hand were formulated as Bayesian inference problems,\nwhich we approximately solved through variational or sampling techniques. The\napproach built on top of already trained networks, and the addressable\nquestions grew super-exponentially with the number of available networks. In\nits simplest form, the approach yielded conditional generative models. However,\nmultiple simultaneous constraints constitute elaborate questions. We compared\nthe approach to specifically trained generators, showed how to solve riddles,\nand demonstrated its compatibility with state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:00:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:00:05 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 09:55:29 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten", ""]]}, {"id": "2001.11055", "submitter": "Isaac Dunn", "authors": "Isaac Dunn, Laura Hanu, Hadrien Pouget, Daniel Kroening, Tom Melham", "title": "Evaluating Robustness to Context-Sensitive Feature Perturbations of\n  Different Granularities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We cannot guarantee that training datasets are representative of the\ndistribution of inputs that will be encountered during deployment. So we must\nhave confidence that our models do not over-rely on this assumption. To this\nend, we introduce a new method that identifies context-sensitive feature\nperturbations (e.g. shape, location, texture, colour) to the inputs of image\nclassifiers. We produce these changes by performing small adjustments to the\nactivation values of different layers of a trained generative neural network.\nPerturbing at layers earlier in the generator causes changes to coarser-grained\nfeatures; perturbations further on cause finer-grained changes. Unsurprisingly,\nwe find that state-of-the-art classifiers are not robust to any such changes.\nMore surprisingly, when it comes to coarse-grained feature changes, we find\nthat adversarial training against pixel-space perturbations is not just\nunhelpful: it is counterproductive.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:20:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:39:38 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:58:39 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Dunn", "Isaac", ""], ["Hanu", "Laura", ""], ["Pouget", "Hadrien", ""], ["Kroening", "Daniel", ""], ["Melham", "Tom", ""]]}, {"id": "2001.11062", "submitter": "Olivia Brown", "authors": "Stephen Mell, Olivia Brown, Justin Goodwin, Sung-Hyun Son", "title": "Safe Predictors for Enforcing Input-Output Specifications", "comments": "10 pages, 5 figures, paper accepted to the NeurIPS 2019 Workshop on\n  Machine Learning with Guarantees and the NeurIPS 2019 Workshop on Safety and\n  Robustness in Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for designing correct-by-construction neural networks\n(and other machine learning models) that are guaranteed to be consistent with a\ncollection of input-output specifications before, during, and after algorithm\ntraining. Our method involves designing a constrained predictor for each set of\ncompatible constraints, and combining them safely via a convex combination of\ntheir predictions. We demonstrate our approach on synthetic datasets and an\naircraft collision avoidance problem.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:39:22 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mell", "Stephen", ""], ["Brown", "Olivia", ""], ["Goodwin", "Justin", ""], ["Son", "Sung-Hyun", ""]]}, {"id": "2001.11077", "submitter": "Pawe{\\l} Ksieniewicz", "authors": "Pawe{\\l} Ksieniewicz, Pawe{\\l} Zyblewski", "title": "stream-learn -- open-source Python library for difficult data stream\n  batch analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  stream-learn is a Python package compatible with scikit-learn and developed\nfor the drifting and imbalanced data stream analysis. Its main component is a\nstream generator, which allows to produce a synthetic data stream that may\nincorporate each of the three main concept drift types (i.e. sudden, gradual\nand incremental drift) in their recurring or non-recurring versions. The\npackage allows conducting experiments following established evaluation\nmethodologies (i.e. Test-Then-Train and Prequential). In addition, estimators\nadapted for data stream classification have been implemented, including both\nsimple classifiers and state-of-art chunk-based and online classifier\nensembles. To improve computational efficiency, package utilises its own\nimplementations of prediction metrics for imbalanced binary classification\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:15:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ksieniewicz", "Pawe\u0142", ""], ["Zyblewski", "Pawe\u0142", ""]]}, {"id": "2001.11085", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir, A Papazafeiropoulos, P. Kourtessis, and S. Chatzinotas", "title": "Deep Channel Learning For Large Intelligent Surfaces Aided mm-Wave\n  Massive MIMO Systems", "comments": "Accepted paper in IEEE Wireless Communications Letters", "journal-ref": "vol. 9, no. 9, pp. 1447-1451, Sept. 2020", "doi": "10.1109/LWC.2020.2993699", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter presents the first work introducing a deep learning (DL)\nframework for channel estimation in large intelligent surface (LIS) assisted\nmassive MIMO (multiple-input multiple-output) systems. A twin convolutional\nneural network (CNN) architecture is designed and it is fed with the received\npilot signals to estimate both direct and cascaded channels. In a multi-user\nscenario, each user has access to the CNN to estimate its own channel. The\nperformance of the proposed DL approach is evaluated and compared with\nstate-of-the-art DL-based techniques and its superior performance is\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:44:21 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 18:32:02 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 10:50:37 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Papazafeiropoulos", "A", ""], ["Kourtessis", "P.", ""], ["Chatzinotas", "S.", ""]]}, {"id": "2001.11086", "submitter": "Xiaowei Jia", "authors": "Xiaowei Jia, Jared Willard, Anuj Karpatne, Jordan S Read, Jacob A\n  Zwart, Michael Steinbach, Vipin Kumar", "title": "Physics-Guided Machine Learning for Scientific Discovery: An Application\n  in Simulating Lake Temperature Profiles", "comments": "arXiv admin note: text overlap with arXiv:1810.13075", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-based models of dynamical systems are often used to study engineering\nand environmental systems. Despite their extensive use, these models have\nseveral well-known limitations due to simplified representations of the\nphysical processes being modeled or challenges in selecting appropriate\nparameters. While-state-of-the-art machine learning models can sometimes\noutperform physics-based models given ample amount of training data, they can\nproduce results that are physically inconsistent. This paper proposes a\nphysics-guided recurrent neural network model (PGRNN) that combines RNNs and\nphysics-based models to leverage their complementary strengths and improves the\nmodeling of physical processes. Specifically, we show that a PGRNN can improve\nprediction accuracy over that of physics-based models, while generating outputs\nconsistent with physical laws. An important aspect of our PGRNN approach lies\nin its ability to incorporate the knowledge encoded in physics-based models.\nThis allows training the PGRNN model using very few true observed data while\nalso ensuring high prediction accuracy. Although we present and evaluate this\nmethodology in the context of modeling the dynamics of temperature in lakes, it\nis applicable more widely to a range of scientific and engineering disciplines\nwhere physics-based (also known as mechanistic) models are used, e.g., climate\nscience, materials science, computational chemistry, and biomedicine.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:44:45 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 20:00:14 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 14:47:28 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Jia", "Xiaowei", ""], ["Willard", "Jared", ""], ["Karpatne", "Anuj", ""], ["Read", "Jordan S", ""], ["Zwart", "Jacob A", ""], ["Steinbach", "Michael", ""], ["Kumar", "Vipin", ""]]}, {"id": "2001.11091", "submitter": "Mohamad Ballout", "authors": "Mohamad Ballout, Mohammad Tuqan, Daniel Asmar, Elie Shammas, George\n  Sakr", "title": "The benefits of synthetic data for action categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the value of using synthetically produced videos as\ntraining data for neural networks used for action categorization. Motivated by\nthe fact that texture and background of a video play little to no significant\nroles in optical flow, we generated simplified texture-less and background-less\nvideos and utilized the synthetic data to train a Temporal Segment Network\n(TSN). The results demonstrated that augmenting TSN with simplified synthetic\ndata improved the original network accuracy (68.5%), achieving 71.8% on HMDB-51\nwhen adding 4,000 videos and 72.4% when adding 8,000 videos. Also, training\nusing simplified synthetic videos alone on 25 classes of UCF-101 achieved\n30.71% when trained on 2500 videos and 52.7% when trained on 5000 videos.\nFinally, results showed that when reducing the number of real videos of UCF-25\nto 10% and combining them with synthetic videos, the accuracy drops to only\n85.41%, compared to a drop to 77.4% when no synthetic data is added.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 17:23:02 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ballout", "Mohamad", ""], ["Tuqan", "Mohammad", ""], ["Asmar", "Daniel", ""], ["Shammas", "Elie", ""], ["Sakr", "George", ""]]}, {"id": "2001.11101", "submitter": "Zhecheng Wang", "authors": "Zhecheng Wang, Haoyuan Li, Ram Rajagopal", "title": "Urban2Vec: Incorporating Street View Imagery and POIs for Multi-Modal\n  Urban Neighborhood Embedding", "comments": "To appear in Proceedings of the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding intrinsic patterns and predicting spatiotemporal\ncharacteristics of cities require a comprehensive representation of urban\nneighborhoods. Existing works relied on either inter- or intra-region\nconnectivities to generate neighborhood representations but failed to fully\nutilize the informative yet heterogeneous data within neighborhoods. In this\nwork, we propose Urban2Vec, an unsupervised multi-modal framework which\nincorporates both street view imagery and point-of-interest (POI) data to learn\nneighborhood embeddings. Specifically, we use a convolutional neural network to\nextract visual features from street view images while preserving geospatial\nsimilarity. Furthermore, we model each POI as a bag-of-words containing its\ncategory, rating, and review information. Analog to document embedding in\nnatural language processing, we establish the semantic similarity between\nneighborhood (\"document\") and the words from its surrounding POIs in the vector\nspace. By jointly encoding visual, textual, and geospatial information into the\nneighborhood representation, Urban2Vec can achieve performances better than\nbaseline models and comparable to fully-supervised methods in downstream\nprediction tasks. Extensive experiments on three U.S. metropolitan areas also\ndemonstrate the model interpretability, generalization capability, and its\nvalue in neighborhood similarity analysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:30:53 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Zhecheng", ""], ["Li", "Haoyuan", ""], ["Rajagopal", "Ram", ""]]}, {"id": "2001.11102", "submitter": "Yifeng Gao", "authors": "Yifeng Gao, Jessica Lin, Constantin Brif", "title": "Ensemble Grammar Induction For Detecting Anomalies in Time Series", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Time series anomaly detection is an important task, with applications in a\nbroad variety of domains. Many approaches have been proposed in recent years,\nbut often they require that the length of the anomalies be known in advance and\nprovided as an input parameter. This limits the practicality of the algorithms,\nas such information is often unknown in advance, or anomalies with different\nlengths might co-exist in the data. To address this limitation, previously, a\nlinear time anomaly detection algorithm based on grammar induction has been\nproposed. While the algorithm can find variable-length patterns, it still\nrequires preselecting values for at least two parameters at the discretization\nstep. How to choose these parameter values properly is still an open problem.\nIn this paper, we introduce a grammar-induction-based anomaly detection method\nutilizing ensemble learning. Instead of using a particular choice of parameter\nvalues for anomaly detection, the method generates the final result based on a\nset of results obtained using different parameter values. We demonstrate that\nthe proposed ensemble approach can outperform existing grammar-induction-based\napproaches with different criteria for selection of parameter values. We also\nshow that the proposed approach can achieve performance similar to that of the\nstate-of-the-art distance-based anomaly detection algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:33:03 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Gao", "Yifeng", ""], ["Lin", "Jessica", ""], ["Brif", "Constantin", ""]]}, {"id": "2001.11103", "submitter": "Wally Melnitchouk", "authors": "Yasir Alanazi, N. Sato, Tianbo Liu, W. Melnitchouk, Pawel Ambrozewicz,\n  Florian Hauenstein, Michelle P. Kuchera, Evan Pritchard, Michael Robertson,\n  Ryan Strauss, Luisa Velasco, Yaohang Li", "title": "Simulation of electron-proton scattering events by a Feature-Augmented\n  and Transformed Generative Adversarial Network (FAT-GAN)", "comments": "7 pages, 5 figures, expanded author list, paper accepted in IJCAI21", "journal-ref": null, "doi": null, "report-no": "JLAB-THY-20-3136", "categories": "hep-ph cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply generative adversarial network (GAN) technology to build an event\ngenerator that simulates particle production in electron-proton scattering that\nis free of theoretical assumptions about underlying particle dynamics. The\ndifficulty of efficiently training a GAN event simulator lies in learning the\ncomplicated patterns of the distributions of the particles physical properties.\nWe develop a GAN that selects a set of transformed features from particle\nmomenta that can be generated easily by the generator, and uses these to\nproduce a set of augmented features that improve the sensitivity of the\ndiscriminator. The new Feature-Augmented and Transformed GAN (FAT-GAN) is able\nto faithfully reproduce the distribution of final state electron momenta in\ninclusive electron scattering, without the need for input derived from\ndomain-based theoretical assumptions. The developed technology can play a\nsignificant role in boosting the science of existing and future accelerator\nfacilities, such as the Electron-Ion Collider.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:35:33 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 19:10:19 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Alanazi", "Yasir", ""], ["Sato", "N.", ""], ["Liu", "Tianbo", ""], ["Melnitchouk", "W.", ""], ["Ambrozewicz", "Pawel", ""], ["Hauenstein", "Florian", ""], ["Kuchera", "Michelle P.", ""], ["Pritchard", "Evan", ""], ["Robertson", "Michael", ""], ["Strauss", "Ryan", ""], ["Velasco", "Luisa", ""], ["Li", "Yaohang", ""]]}, {"id": "2001.11107", "submitter": "Marios Mattheakis M", "authors": "Marios Mattheakis, David Sondak, Akshunna S. Dogra, and Pavlos\n  Protopapas", "title": "Hamiltonian Neural Networks for solving differential equations", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a wave of interest in applying machine learning to study\ndynamical systems. In particular, neural networks have been applied to solve\nthe equations of motion, and therefore, track the evolution of a system. In\ncontrast to other applications of neural networks and machine learning,\ndynamical systems -- depending on their underlying symmetries -- possess\ninvariants such as energy, momentum, and angular momentum. Traditional\nnumerical iteration methods usually violate these conservation laws,\npropagating errors in time, and reducing the predictability of the method. We\npresent a Hamiltonian neural network that solves the differential equations\nthat govern dynamical systems. This unsupervised model is learning solutions\nthat satisfy identically, up to an arbitrarily small error, Hamilton's\nequations and, therefore, conserve the Hamiltonian invariants. Once it is\noptimized, the proposed architecture is considered a symplectic unit due to the\nintroduction of an efficient parametric form of solutions. In addition, by\nsharing the network parameters and the choice of an appropriate activation\nfunction drastically improve the predictability of the network. An error\nanalysis is derived and states that the numerical errors depend on the overall\nnetwork performance. The symplectic architecture is then employed to solve the\nequations for the nonlinear oscillator and the chaotic Henon-Heiles dynamical\nsystem. In both systems, the symplectic Euler integrator requires two orders\nmore evaluation points than the Hamiltonian network in order to achieve the\nsame order of the numerical error in the predicted phase space trajectories.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 21:48:35 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 04:31:20 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Mattheakis", "Marios", ""], ["Sondak", "David", ""], ["Dogra", "Akshunna S.", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "2001.11113", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson", "title": "GradientDICE: Rethinking Generalized Offline Estimation of Stationary\n  Values", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GradientDICE for estimating the density ratio between the state\ndistribution of the target policy and the sampling distribution in off-policy\nreinforcement learning. GradientDICE fixes several problems of GenDICE (Zhang\net al., 2020), the state-of-the-art for estimating such density ratios. Namely,\nthe optimization problem in GenDICE is not a convex-concave saddle-point\nproblem once nonlinearity in optimization variable parameterization is\nintroduced to ensure positivity, so any primal-dual algorithm is not guaranteed\nto converge or find the desired solution. However, such nonlinearity is\nessential to ensure the consistency of GenDICE even with a tabular\nrepresentation. This is a fundamental contradiction, resulting from GenDICE's\noriginal formulation of the optimization problem. In GradientDICE, we optimize\na different objective from GenDICE by using the Perron-Frobenius theorem and\neliminating GenDICE's use of divergence. Consequently, nonlinearity in\nparameterization is not necessary for GradientDICE, which is provably\nconvergent under linear function approximation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:10:11 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:25:06 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 17:12:32 GMT"}, {"version": "v4", "created": "Mon, 8 Jun 2020 00:17:19 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2020 23:58:06 GMT"}, {"version": "v6", "created": "Fri, 31 Jul 2020 18:17:50 GMT"}, {"version": "v7", "created": "Thu, 26 Nov 2020 17:49:45 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2001.11114", "submitter": "Liang Mi", "authors": "Jos\\'e Bento and Liang Mi", "title": "Multi-Marginal Optimal Transport Defines a Generalized Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Optimal transport (OT) problem is rapidly finding its way into machine\nlearning. Favoring its use are its metric properties. Many problems admit\nsolutions that guarantee only for objects embedded in metric spaces, and the\nuse of non-metrics can complicate them. Multi-marginal OT (MMOT) generalizes OT\nto simultaneously transporting multiple distributions. It captures important\nrelations that are missed if the transport is pairwise. Research on MMOT,\nhowever, has been focused on its existence, uniqueness, practical algorithms,\nand the choice of cost functions. There is a lack of discussion on the metric\nproperties of MMOT, which limits its theoretical and practical use. Here, we\nprove that (pairwise) MMOT defines a generalized metric. We first explain the\ndifficulty of proving this via two negative results. Afterwards, we prove key\nintermediate steps and then MMOT's metric properties. Finally, we show that the\ngeneralized triangle inequality of MMOT cannot be improved.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:10:15 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:03:28 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 08:27:56 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 10:17:44 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Bento", "Jos\u00e9", ""], ["Mi", "Liang", ""]]}, {"id": "2001.11121", "submitter": "Zuohui Fu", "authors": "Zuohui Fu, Yikun Xian, Shijie Geng, Yingqiang Ge, Yuting Wang, Xin\n  Dong, Guang Wang and Gerard de Melo", "title": "ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional\n  GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of cross-lingual transfer learning approaches based on neural\nnetworks have been proposed for the case when large amounts of parallel text\nare at our disposal. However, in many real-world settings, the size of parallel\nannotated training data is restricted. Additionally, prior cross-lingual\nmapping research has mainly focused on the word level. This raises the question\nof whether such techniques can also be applied to effortlessly obtain\ncross-lingually aligned sentence representations. To this end, we propose an\nAdversarial Bi-directional Sentence Embedding Mapping (ABSent) framework, which\nlearns mappings of cross-lingual sentence representations from limited\nquantities of parallel data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 22:44:05 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Fu", "Zuohui", ""], ["Xian", "Yikun", ""], ["Geng", "Shijie", ""], ["Ge", "Yingqiang", ""], ["Wang", "Yuting", ""], ["Dong", "Xin", ""], ["Wang", "Guang", ""], ["de Melo", "Gerard", ""]]}, {"id": "2001.11128", "submitter": "Kazuya Kawakami", "authors": "Kazuya Kawakami, Luyu Wang, Chris Dyer, Phil Blunsom, Aaron van den\n  Oord", "title": "Learning Robust and Multilingual Speech Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised speech representation learning has shown remarkable success at\nfinding representations that correlate with phonetic structures and improve\ndownstream speech recognition performance. However, most research has been\nfocused on evaluating the representations in terms of their ability to improve\nthe performance of speech recognition systems on read English (e.g. Wall Street\nJournal and LibriSpeech). This evaluation methodology overlooks two important\ndesiderata that speech representations should have: robustness to domain shifts\nand transferability to other languages. In this paper we learn representations\nfrom up to 8000 hours of diverse and noisy speech data and evaluate the\nrepresentations by looking at their robustness to domain shifts and their\nability to improve recognition performance in many languages. We find that our\nrepresentations confer significant robustness advantages to the resulting\nrecognition systems: we see significant improvements in out-of-domain transfer\nrelative to baseline feature sets and the features likewise provide\nimprovements in 25 phonetically diverse languages including tonal languages and\nlow-resource languages.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:24:56 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kawakami", "Kazuya", ""], ["Wang", "Luyu", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""], ["Oord", "Aaron van den", ""]]}, {"id": "2001.11137", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan, Ken Alparslan, Jeremy Keim-Shenk, Shweta Khade,\n  Rachel Greenstadt", "title": "Adversarial Attacks on Convolutional Neural Networks in Facial\n  Recognition Domain", "comments": "18 pages, 8 figures, fixed typos, replotted figures, restyled the\n  plots and tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Numerous recent studies have demonstrated how Deep Neural Network (DNN)\nclassifiers can be fooled by adversarial examples, in which an attacker adds\nperturbations to an original sample, causing the classifier to misclassify the\nsample. Adversarial attacks that render DNNs vulnerable in real life represent\na serious threat in autonomous vehicles, malware filters, or biometric\nauthentication systems. In this paper, we apply Fast Gradient Sign Method to\nintroduce perturbations to a facial image dataset and then test the output on a\ndifferent classifier that we trained ourselves, to analyze transferability of\nthis method. Next, we craft a variety of different black-box attack algorithms\non a facial image dataset assuming minimal adversarial knowledge, to further\nassess the robustness of DNNs in facial recognition. While experimenting with\ndifferent image distortion techniques, we focus on modifying single optimal\npixels by a large amount, or modifying all pixels by a smaller amount, or\ncombining these two attack approaches. While our single-pixel attacks achieved\nabout a 15% average decrease in classifier confidence level for the actual\nclass, the all-pixel attacks were more successful and achieved up to an 84%\naverage decrease in confidence, along with an 81.6% misclassification rate, in\nthe case of the attack that we tested with the highest levels of perturbation.\nEven with these high levels of perturbation, the face images remained\nidentifiable to a human. Understanding how these noised and perturbed images\nbaffle the classification algorithms can yield valuable advances in the\ntraining of DNNs against defense-aware adversarial attacks, as well as adaptive\nnoise reduction techniques. We hope our research may help to advance the study\nof adversarial attacks on DNNs and defensive mechanisms to counteract them,\nparticularly in the facial recognition domain.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:25:05 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:19:12 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 07:43:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Alparslan", "Yigit", ""], ["Alparslan", "Ken", ""], ["Keim-Shenk", "Jeremy", ""], ["Khade", "Shweta", ""], ["Greenstadt", "Rachel", ""]]}, {"id": "2001.11143", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, S. S. Ravi, Ian Davidson", "title": "A Graph-Based Approach for Active Learning in Regression", "comments": "SDM 2020 camera-ready. 9 pages, 4 figures, links to supplementary\n  material available at\n  https://sdm2020.s3-us-west-1.amazonaws.com/supplementary.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to reduce labeling efforts by selectively asking humans\nto annotate the most important data points from an unlabeled pool and is an\nexample of human-machine interaction. Though active learning has been\nextensively researched for classification and ranking problems, it is\nrelatively understudied for regression problems. Most existing active learning\nfor regression methods use the regression function learned at each active\nlearning iteration to select the next informative point to query. This\nintroduces several challenges such as handling noisy labels, parameter\nuncertainty and overcoming initially biased training data. Instead, we propose\na feature-focused approach that formulates both sequential and batch-mode\nactive regression as a novel bipartite graph optimization problem. We conduct\nexperiments on both noise-free and noisy settings. Our experimental results on\nbenchmark data sets demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:59:43 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Zhang", "Hongjing", ""], ["Ravi", "S. S.", ""], ["Davidson", "Ian", ""]]}, {"id": "2001.11152", "submitter": "Ankur Singh", "authors": "Ankur Singh", "title": "Adversarial Incremental Learning", "comments": "I want my draft to be withdrawn from arXiv. I don't want to make the\n  idea public right now. I understand now that it can't be completely removed.\n  So at least if it can't be completely removed you can direct users to the\n  latest version which doesn't has the PDF and not the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning performs really well in a wide variety of tasks, it\nstill suffers from catastrophic forgetting -- the tendency of neural networks\nto forget previously learned information upon learning new tasks where previous\ndata is not available. Earlier methods of incremental learning tackle this\nproblem by either using a part of the old dataset, by generating exemplars or\nby using memory networks. Although, these methods have shown good results but\nusing exemplars or generating them, increases memory and computation\nrequirements. To solve these problems we propose an adversarial discriminator\nbased method that does not make use of old data at all while training on new\ntasks. We particularly tackle the class incremental learning problem in image\nclassification, where data is provided in a class-based sequential manner. For\nthis problem, the network is trained using an adversarial loss along with the\ntraditional cross-entropy loss. The cross-entropy loss helps the network\nprogressively learn new classes while the adversarial loss helps in preserving\ninformation about the existing classes. Using this approach, we are able to\noutperform other state-of-the-art methods on CIFAR-100, SVHN, and MNIST\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 02:25:35 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:30:22 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Singh", "Ankur", ""]]}, {"id": "2001.11154", "submitter": "Siwei Feng", "authors": "Siwei Feng and Han Yu", "title": "Multi-Participant Multi-Class Vertical Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a privacy-preserving paradigm for training\ncollective machine learning models with locally stored data from multiple\nparticipants. Vertical federated learning (VFL) deals with the case where\nparticipants sharing the same sample ID space but having different feature\nspaces, while label information is owned by one participant. Current studies of\nVFL only support two participants, and mostly focus on binaryclass logistic\nregression problems. In this paper, we propose the Multi-participant\nMulti-class Vertical Federated Learning (MMVFL) framework for multi-class VFL\nproblems involving multiple parties. Extending the idea of multi-view learning\n(MVL), MMVFL enables label sharing from its owner to other VFL participants in\na privacypreserving manner. To demonstrate the effectiveness of MMVFL, a\nfeature selection scheme is incorporated into MMVFL to compare its performance\nagainst supervised feature selection and MVL-based approaches. Experiment\nresults on real-world datasets show that MMVFL can effectively share label\ninformation among multiple VFL participants and match multi-class\nclassification performance of existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 02:39:50 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Feng", "Siwei", ""], ["Yu", "Han", ""]]}, {"id": "2001.11158", "submitter": "Tien Dung Nguyen", "authors": "Tien-Dung Nguyen, Tomasz Maszczyk, Katarzyna Musial, Marc-Andre\n  Z\\\"oller, Bogdan Gabrys", "title": "AVATAR -- Machine Learning Pipeline Evaluation Using Surrogate Model", "comments": "The Eighteenth International Symposium on Intelligent Data Analysis,\n  IDA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of machine learning (ML) pipelines is essential during\nautomatic ML pipeline composition and optimisation. The previous methods such\nas Bayesian-based and genetic-based optimisation, which are implemented in\nAuto-Weka, Auto-sklearn and TPOT, evaluate pipelines by executing them.\nTherefore, the pipeline composition and optimisation of these methods requires\na tremendous amount of time that prevents them from exploring complex pipelines\nto find better predictive models. To further explore this research challenge,\nwe have conducted experiments showing that many of the generated pipelines are\ninvalid, and it is unnecessary to execute them to find out whether they are\ngood pipelines. To address this issue, we propose a novel method to evaluate\nthe validity of ML pipelines using a surrogate model (AVATAR). The AVATAR\nenables to accelerate automatic ML pipeline composition and optimisation by\nquickly ignoring invalid pipelines. Our experiments show that the AVATAR is\nmore efficient in evaluating complex pipelines in comparison with the\ntraditional evaluation approaches requiring their execution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 02:53:29 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 01:00:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Nguyen", "Tien-Dung", ""], ["Maszczyk", "Tomasz", ""], ["Musial", "Katarzyna", ""], ["Z\u00f6ller", "Marc-Andre", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "2001.11168", "submitter": "Ryoya Yamasaki", "authors": "Ryoya Yamasaki, Toshiyuki Tanaka", "title": "Kernel Selection for Modal Linear Regression: Optimal Kernel and IRLS\n  Algorithm", "comments": "7 pages, 4 figures, published in the proceedings of the 18th IEEE\n  International Conference on Machine Learning and Applications - ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modal linear regression (MLR) is a method for obtaining a conditional mode\npredictor as a linear model. We study kernel selection for MLR from two\nperspectives: \"which kernel achieves smaller error?\" and \"which kernel is\ncomputationally efficient?\". First, we show that a Biweight kernel is optimal\nin the sense of minimizing an asymptotic mean squared error of a resulting MLR\nparameter. This result is derived from our refined analysis of an asymptotic\nstatistical behavior of MLR. Secondly, we provide a kernel class for which\niteratively reweighted least-squares algorithm (IRLS) is guaranteed to\nconverge, and especially prove that IRLS with an Epanechnikov kernel terminates\nin a finite number of iterations. Simulation studies empirically verified that\nusing a Biweight kernel provides good estimation accuracy and that using an\nEpanechnikov kernel is computationally efficient. Our results improve MLR of\nwhich existing studies often stick to a Gaussian kernel and modal EM algorithm\nspecialized for it, by providing guidelines of kernel selection.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:57:07 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Yamasaki", "Ryoya", ""], ["Tanaka", "Toshiyuki", ""]]}, {"id": "2001.11171", "submitter": "George Berry", "authors": "George Berry, Antonio Sirianni, Ingmar Weber, Jisun An, Michael Macy", "title": "Going beyond accuracy: estimating homophily in social networks using\n  predictions", "comments": "19 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In online social networks, it is common to use predictions of node categories\nto estimate measures of homophily and other relational properties. However,\nonline social network data often lacks basic demographic information about the\nnodes. Researchers must rely on predicted node attributes to estimate measures\nof homophily, but little is known about the validity of these measures. We show\nthat estimating homophily in a network can be viewed as a dyadic prediction\nproblem, and that homophily estimates are unbiased when dyad-level residuals\nsum to zero in the network. Node-level prediction models, such as the use of\nnames to classify ethnicity or gender, do not generally have this property and\ncan introduce large biases into homophily estimates. Bias occurs due to error\nautocorrelation along dyads. Importantly, node-level classification performance\nis not a reliable indicator of estimation accuracy for homophily. We compare\nestimation strategies that make predictions at the node and dyad levels,\nevaluating performance in different settings. We propose a novel \"ego-alter\"\nmodeling approach that outperforms standard node and dyad classification\nstrategies. While this paper focuses on homophily, results generalize to other\nrelational measures which aggregate predictions along the dyads in a network.\nWe conclude with suggestions for research designs to study homophily in online\nnetworks. Code for this paper is available at\nhttps://github.com/georgeberry/autocorr.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 04:37:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Berry", "George", ""], ["Sirianni", "Antonio", ""], ["Weber", "Ingmar", ""], ["An", "Jisun", ""], ["Macy", "Michael", ""]]}, {"id": "2001.11175", "submitter": "Jongmin Yu", "authors": "Jongmin Yu, Duyong Kim, Younkwan Lee, and Moongu Jeon", "title": "Unsupervised Pixel-level Road Defect Detection via Adversarial\n  Image-to-Frequency Transform", "comments": "Submitted to IV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past few years, the performance of road defect detection has been\nremarkably improved thanks to advancements on various studies on computer\nvision and deep learning. Although a large-scale and well-annotated datasets\nenhance the performance of detecting road pavement defects to some extent, it\nis still challengeable to derive a model which can perform reliably for various\nroad conditions in practice, because it is intractable to construct a dataset\nconsidering diverse road conditions and defect patterns. To end this, we\npropose an unsupervised approach to detecting road defects, using Adversarial\nImage-to-Frequency Transform (AIFT). AIFT adopts the unsupervised manner and\nadversarial learning in deriving the defect detection model, so AIFT does not\nneed annotations for road pavement defects. We evaluate the efficiency of AIFT\nusing GAPs384 dataset, Cracktree200 dataset, CRACK500 dataset, and CFD dataset.\nThe experimental results demonstrate that the proposed approach detects various\nroad detects, and it outperforms existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 04:50:00 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 04:27:32 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yu", "Jongmin", ""], ["Kim", "Duyong", ""], ["Lee", "Younkwan", ""], ["Jeon", "Moongu", ""]]}, {"id": "2001.11177", "submitter": "Fatemeh Amini", "authors": "Fatemeh Amini and Guiping Hu", "title": "A Hybrid Two-layer Feature Selection Method Using GeneticAlgorithm and\n  Elastic Net", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2020.114072", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection, as a critical pre-processing step for machine learning,\naims at determining representative predictors from a high-dimensional feature\nspace dataset to improve the prediction accuracy. However, the increase in\nfeature space dimensionality, comparing to the number of observations, poses a\nsevere challenge to many existing feature selection methods with respect to\ncomputational efficiency and prediction performance. This paper presents a new\nhybrid two-layer feature selection approach that combines a wrapper and an\nembedded method in constructing an appropriate subset of predictors. In the\nfirst layer of the proposed method, the Genetic Algorithm(GA) has been adopted\nas a wrapper to search for the optimal subset of predictors, which aims to\nreduce the number of predictors and the prediction error. As one of the\nmeta-heuristic approaches, GA is selected due to its computational efficiency;\nhowever, GAs do not guarantee the optimality. To address this issue, a second\nlayer is added to the proposed method to eliminate any remaining\nredundant/irrelevant predictors to improve the prediction accuracy. Elastic\nNet(EN) has been selected as the embedded method in the second layer because of\nits flexibility in adjusting the penalty terms in regularization process and\ntime efficiency. This hybrid two-layer approach has been applied on a Maize\ngenetic dataset from NAM population, which consists of multiple subsets of\ndatasets with different ratio of the number of predictors to the number of\nobservations. The numerical results confirm the superiority of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 05:01:30 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Amini", "Fatemeh", ""], ["Hu", "Guiping", ""]]}, {"id": "2001.11181", "submitter": "Se-Eun Yoon", "authors": "Se-eun Yoon, Hyungseok Song, Kijung Shin, and Yung Yi", "title": "How Much and When Do We Need Higher-order Information in Hypergraphs? A\n  Case Study on Hyperedge Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380016", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hypergraphs provide a natural way of representing group relations, whose\ncomplexity motivates an extensive array of prior work to adopt some form of\nabstraction and simplification of higher-order interactions. However, the\nfollowing question has yet to be addressed: How much abstraction of group\ninteractions is sufficient in solving a hypergraph task, and how different such\nresults become across datasets? This question, if properly answered, provides a\nuseful engineering guideline on how to trade off between complexity and\naccuracy of solving a downstream task. To this end, we propose a method of\nincrementally representing group interactions using a notion of n-projected\ngraph whose accumulation contains information on up to n-way interactions, and\nquantify the accuracy of solving a task as n grows for various datasets. As a\ndownstream task, we consider hyperedge prediction, an extension of link\nprediction, which is a canonical task for evaluating graph models. Through\nexperiments on 15 real-world datasets, we draw the following messages: (a)\nDiminishing returns: small n is enough to achieve accuracy comparable with\nnear-perfect approximations, (b) Troubleshooter: as the task becomes more\nchallenging, larger n brings more benefit, and (c) Irreducibility: datasets\nwhose pairwise interactions do not tell much about higher-order interactions\nlose much accuracy when reduced to pairwise abstractions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 05:21:19 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 01:35:49 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 13:17:54 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Yoon", "Se-eun", ""], ["Song", "Hyungseok", ""], ["Shin", "Kijung", ""], ["Yi", "Yung", ""]]}, {"id": "2001.11194", "submitter": "Xinhan Di", "authors": "Yuli Zhang, Yeyang He, Shaowen Zhu, Xinhan Di", "title": "The Direction-Aware, Learnable, Additive Kernels and the Adversarial\n  Network for Deep Floor Plan Recognition", "comments": "deep learning, floor plan, computer vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach for the recognition of elements in floor\nplan layouts. Besides of elements with common shapes, we aim to recognize\nelements with irregular shapes such as circular rooms and inclined walls.\nFurthermore, the reduction of noise in the semantic segmentation of the floor\nplan is on demand. To this end, we propose direction-aware, learnable, additive\nkernels in the application of both the context module and common convolutional\nblocks. We apply them for high performance of elements with both common and\nirregular shapes. Besides, an adversarial network with two discriminators is\nproposed to further improve the accuracy of the elements and to reduce the\nnoise of the semantic segmentation. Experimental results demonstrate the\nsuperiority and effectiveness of the proposed network over the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 07:10:39 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Zhang", "Yuli", ""], ["He", "Yeyang", ""], ["Zhu", "Shaowen", ""], ["Di", "Xinhan", ""]]}, {"id": "2001.11201", "submitter": "Vrettos Moulos", "authors": "Vrettos Moulos", "title": "Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence\n  Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian\n  Rewards", "comments": "31 pages, simulation results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an extension of the classic stochastic multi-armed bandit problem\nwhich involves multiple plays and Markovian rewards in the rested bandits\nsetting. In order to tackle this problem we consider an adaptive allocation\nrule which at each stage combines the information from the sample means of all\nthe arms, with the Kullback-Leibler upper confidence bound of a single arm\nwhich is selected in round-robin way. For rewards generated from a\none-parameter exponential family of Markov chains, we provide a finite-time\nupper bound for the regret incurred from this adaptive allocation rule, which\nreveals the logarithmic dependence of the regret on the time horizon, and which\nis asymptotically optimal. For our analysis we devise several concentration\nresults for Markov chains, including a maximal inequality for Markov chains,\nthat may be of interest in their own right. As a byproduct of our analysis we\nalso establish asymptotically optimal, finite-time guarantees for the case of\nmultiple plays, and i.i.d. rewards drawn from a one-parameter exponential\nfamily of probability densities. Additionally, we provide simulation results\nthat illustrate that calculating Kullback-Leibler upper confidence bounds in a\nround-robin way, is significantly more efficient than calculating them for\nevery arm at each round, and that the expected regrets of those two approaches\nbehave similarly.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:09:01 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 18:28:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Moulos", "Vrettos", ""]]}, {"id": "2001.11202", "submitter": "Can Taylan Sari", "authors": "C. T. Sari, C. Sokmensuer, and C. Gunduz-Demir", "title": "Image Embedded Segmentation: Uniting Supervised and Unsupervised\n  Objectives for Segmenting Histopathological Images", "comments": "This work has been submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new regularization method to train a fully\nconvolutional network for semantic tissue segmentation in histopathological\nimages. This method relies on the benefit of unsupervised learning, in the form\nof image reconstruction, for network training. To this end, it puts forward an\nidea of defining a new embedding that allows uniting the main supervised task\nof semantic segmentation and an auxiliary unsupervised task of image\nreconstruction into a single one and proposes to learn this united task by a\nsingle generative model. This embedding generates an output image by\nsuperimposing an input image on its segmentation map. Then, the method learns\nto translate the input image to this embedded output image using a conditional\ngenerative adversarial network, which is known as quite effective for\nimage-to-image translations. This proposal is different than the existing\napproach that uses image reconstruction for the same regularization purpose.\nThe existing approach considers segmentation and image reconstruction as two\nseparate tasks in a multi-task network, defines their losses independently, and\ncombines them in a joint loss function. However, the definition of such a\nfunction requires externally determining right contributions of the supervised\nand unsupervised losses that yield balanced learning between the segmentation\nand image reconstruction tasks. The proposed approach provides an easier\nsolution to this problem by uniting these two tasks into a single one, which\nintrinsically combines their losses. We test our approach on three datasets of\nhistopathological images. Our experiments demonstrate that it leads to better\nsegmentation results in these datasets, compared to its counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:09:38 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 10:22:35 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 11:18:20 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Sari", "C. T.", ""], ["Sokmensuer", "C.", ""], ["Gunduz-Demir", "C.", ""]]}, {"id": "2001.11212", "submitter": "Benjamin Regler", "authors": "Benjamin Regler, Matthias Scheffler, Luca M. Ghiringhelli", "title": "TCMI: a non-parametric mutual-dependence estimator for multivariate\n  continuous distributions", "comments": "36 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of relevant features, i.e., the driving variables that\ndetermine a process or the property of a system, is an essential part of the\nanalysis of data sets whose entries are described by a large number of\nvariables. The preferred measure for quantifying the relevance of nonlinear\nstatistical dependencies is mutual information, which requires as input\nprobability distributions. Probability distributions cannot be reliably sampled\nand estimated from limited data, especially for real-valued data samples such\nas lengths or energies. Here, we introduce total cumulative mutual information\n(TCMI), a measure of the relevance of mutual dependencies based on cumulative\nprobability distributions. TCMI can be estimated directly from sample data and\nis a non-parametric, robust and deterministic measure that facilitates\ncomparisons and rankings between feature sets with different cardinality. The\nranking induced by TCMI allows for feature selection, i.e., the identification\nof the set of relevant features that are statistical related to the process or\nthe property of a system, while taking into account the number of data samples\nas well as the cardinality of the feature subsets. We evaluate the performance\nof our measure with simulated data, compare its performance with similar\nmultivariate dependence measures, and demonstrate the effectiveness of our\nfeature selection method on a set of standard data sets and a typical scenario\nin materials science.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:42:25 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Regler", "Benjamin", ""], ["Scheffler", "Matthias", ""], ["Ghiringhelli", "Luca M.", ""]]}, {"id": "2001.11216", "submitter": "Xinjiang Wang", "authors": "Sheng Zhou, Xinjiang Wang, Ping Luo, Litong Feng, Wenjie Li, Wei Zhang", "title": "How Does BN Increase Collapsed Neural Network Filters?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving sparsity of deep neural networks (DNNs) is essential for network\ncompression and has drawn much attention. In this work, we disclose a harmful\nsparsifying process called filter collapse, which is common in DNNs with batch\nnormalization (BN) and rectified linear activation functions (e.g. ReLU, Leaky\nReLU). It occurs even without explicit sparsity-inducing regularizations such\nas $L_1$. This phenomenon is caused by the normalization effect of BN, which\ninduces a non-trainable region in the parameter space and reduces the network\ncapacity as a result. This phenomenon becomes more prominent when the network\nis trained with large learning rates (LR) or adaptive LR schedulers, and when\nthe network is finetuned. We analytically prove that the parameters of BN tend\nto become sparser during SGD updates with high gradient noise and that the\nsparsifying probability is proportional to the square of learning rate and\ninversely proportional to the square of the scale parameter of BN. To prevent\nthe undesirable collapsed filters, we propose a simple yet effective approach\nnamed post-shifted BN (psBN), which has the same representation ability as BN\nwhile being able to automatically make BN parameters trainable again as they\nsaturate during training. With psBN, we can recover collapsed filters and\nincrease the model performance in various tasks such as classification on\nCIFAR-10 and object detection on MS-COCO2017.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:00:08 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 01:31:33 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Zhou", "Sheng", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""], ["Feng", "Litong", ""], ["Li", "Wenjie", ""], ["Zhang", "Wei", ""]]}, {"id": "2001.11231", "submitter": "Szilard Aradi", "authors": "Szil\\'ard Aradi", "title": "Survey of Deep Reinforcement Learning for Motion Planning of Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic research in the field of autonomous vehicles has reached high\npopularity in recent years related to several topics as sensor technologies,\nV2X communications, safety, security, decision making, control, and even legal\nand standardization rules. Besides classic control design approaches,\nArtificial Intelligence and Machine Learning methods are present in almost all\nof these fields. Another part of research focuses on different layers of Motion\nPlanning, such as strategic decisions, trajectory planning, and control. A wide\nrange of techniques in Machine Learning itself have been developed, and this\narticle describes one of these fields, Deep Reinforcement Learning (DRL). The\npaper provides insight into the hierarchical motion planning problem and\ndescribes the basics of DRL. The main elements of designing such a system are\nthe modeling of the environment, the modeling abstractions, the description of\nthe state and the perception models, the appropriate rewarding, and the\nrealization of the underlying neural network. The paper describes vehicle\nmodels, simulation possibilities and computational requirements. Strategic\ndecisions on different layers and the observation models, e.g., continuous and\ndiscrete state representations, grid-based, and camera-based solutions are\npresented. The paper surveys the state-of-art solutions systematized by the\ndifferent tasks and levels of autonomous driving, such as car-following,\nlane-keeping, trajectory following, merging, or driving in dense traffic.\nFinally, open questions and future challenges are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 09:47:22 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Aradi", "Szil\u00e1rd", ""]]}, {"id": "2001.11235", "submitter": "Emiel Hoogeboom", "authors": "Emiel Hoogeboom, Taco S. Cohen, Jakub M. Tomczak", "title": "Learning Discrete Distributions by Dequantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Media is generally stored digitally and is therefore discrete. Many\nsuccessful deep distribution models in deep learning learn a density, i.e., the\ndistribution of a continuous random variable. Na\\\"ive optimization on discrete\ndata leads to arbitrarily high likelihoods, and instead, it has become standard\npractice to add noise to datapoints. In this paper, we present a general\nframework for dequantization that captures existing methods as a special case.\nWe derive two new dequantization objectives: importance-weighted (iw)\ndequantization and R\\'enyi dequantization. In addition, we introduce\nautoregressive dequantization (ARD) for more flexible dequantization\ndistributions. Empirically we find that iw and R\\'enyi dequantization\nconsiderably improve performance for uniform dequantization distributions. ARD\nachieves a negative log-likelihood of 3.06 bits per dimension on CIFAR10, which\nto the best of our knowledge is state-of-the-art among distribution models that\ndo not require autoregressive inverses for sampling.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 10:00:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Hoogeboom", "Emiel", ""], ["Cohen", "Taco S.", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "2001.11242", "submitter": "Tuomo Alasalmi", "authors": "Tuomo Alasalmi, Jaakko Suutala, Heli Koskim\\\"aki and Juha R\\\"oning", "title": "Better Multi-class Probability Estimates for Small Data Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classification applications require accurate probability estimates in\naddition to good class separation but often classifiers are designed focusing\nonly on the latter. Calibration is the process of improving probability\nestimates by post-processing but commonly used calibration algorithms work\npoorly on small data sets and assume the classification task to be binary. Both\nof these restrictions limit their real-world applicability. Previously\nintroduced Data Generation and Grouping algorithm alleviates the problem posed\nby small data sets and in this article, we will demonstrate that its\napplication to multi-class problems is also possible which solves the other\nlimitation. Our experiments show that calibration error can be decreased using\nthe proposed approach and the additional computational cost is acceptable.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 10:21:26 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Alasalmi", "Tuomo", ""], ["Suutala", "Jaakko", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "2001.11258", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Shriphani Palakodety, Jaime G. Carbonell", "title": "Harnessing Code Switching to Transcend the Linguistic Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code mixing (or code switching) is a common phenomenon observed in\nsocial-media content generated by a linguistically diverse user-base. Studies\nshow that in the Indian sub-continent, a substantial fraction of social media\nposts exhibit code switching. While the difficulties posed by code mixed\ndocuments to further downstream analyses are well-understood, lending\nvisibility to code mixed documents under certain scenarios may have utility\nthat has been previously overlooked. For instance, a document written in a\nmixture of multiple languages can be partially accessible to a wider audience;\nthis could be particularly useful if a considerable fraction of the audience\nlacks fluency in one of the component languages. In this paper, we provide a\nsystematic approach to sample code mixed documents leveraging a polyglot\nembedding based method that requires minimal supervision. In the context of the\n2019 India-Pakistan conflict triggered by the Pulwama terror attack, we\ndemonstrate an untapped potential of harnessing code mixing for human\nwell-being: starting from an existing hostility diffusing \\emph{hope speech}\nclassifier solely trained on English documents, code mixed documents are\nutilized as a bridge to retrieve \\emph{hope speech} content written in a\nlow-resource but widely used language - Romanized Hindi. Our proposed pipeline\nrequires minimal supervision and holds promise in substantially reducing web\nmoderation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:06 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:31:14 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Palakodety", "Shriphani", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "2001.11261", "submitter": "Mischa Schmidt", "authors": "Mischa Schmidt, Julia Gastinger, S\\'ebastien Nicolas, Anett Sch\\\"ulke\n  (NEC Laboratories Europe GmbH)", "title": "HAMLET -- A Learning Curve-Enabled Multi-Armed Bandit for Algorithm\n  Selection", "comments": "8 pages, 8 figures; IJCNN 2020: International Joint Conference on\n  Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated algorithm selection and hyperparameter tuning facilitates the\napplication of machine learning. Traditional multi-armed bandit strategies look\nto the history of observed rewards to identify the most promising arms for\noptimizing expected total reward in the long run. When considering limited time\nbudgets and computational resources, this backward view of rewards is\ninappropriate as the bandit should look into the future for anticipating the\nhighest final reward at the end of a specified time budget. This work addresses\nthat insight by introducing HAMLET, which extends the bandit approach with\nlearning curve extrapolation and computation time-awareness for selecting among\na set of machine learning algorithms. Results show that the HAMLET Variants 1-3\nexhibit equal or better performance than other bandit-based algorithm selection\nstrategies in experiments with recorded hyperparameter tuning traces for the\nmajority of considered time budgets. The best performing HAMLET Variant 3\ncombines learning curve extrapolation with the well-known upper confidence\nbound exploration bonus. That variant performs better than all non-HAMLET\npolicies with statistical significance at the 95% level for 1,485 runs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:28:39 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:37:16 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 06:56:35 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Schmidt", "Mischa", "", "NEC Laboratories Europe GmbH"], ["Gastinger", "Julia", "", "NEC Laboratories Europe GmbH"], ["Nicolas", "S\u00e9bastien", "", "NEC Laboratories Europe GmbH"], ["Sch\u00fclke", "Anett", "", "NEC Laboratories Europe GmbH"]]}, {"id": "2001.11263", "submitter": "Francesc Llu\\'is", "authors": "Francesc Llu\\'is, Pablo Mart\\'inez-Nuevo, Martin Bo M{\\o}ller, Sven\n  Ewan Shepstone", "title": "Sound field reconstruction in rooms: inpainting meets super-resolution", "comments": "Code: https://github.com/francesclluis/sound-field-neural-network", "journal-ref": "The Journal of the Acoustical Society of America 148, 649 (2020)", "doi": "10.1121/10.0001687", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a deep-learning-based method for sound field reconstruction is\nproposed. It is shown the possibility to reconstruct the magnitude of the sound\npressure in the frequency band 30-300 Hz for an entire room by using a very low\nnumber of irregularly distributed microphones arbitrarily arranged. Moreover,\nthe approach is agnostic to the location of the measurements in the Euclidean\nspace. In particular, the presented approach uses a limited number of arbitrary\ndiscrete measurements of the magnitude of the sound field pressure in order to\nextrapolate this field to a higher-resolution grid of discrete points in space\nwith a low computational complexity. The method is based on a U-net-like neural\nnetwork with partial convolutions trained solely on simulated data, which\nitself is constructed from numerical simulations of Green's function across\nthousands of common rectangular rooms. Although extensible to three dimensions\nand different room shapes, the method focuses on reconstructing a\ntwo-dimensional plane of a rectangular room from measurements of the\nthree-dimensional sound field. Experiments using simulated data together with\nan experimental validation in a real listening room are shown. The results\nsuggest a performance which may exceed conventional reconstruction techniques\nfor a low number of microphones and computational requirements.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:31:59 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 16:14:24 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Llu\u00eds", "Francesc", ""], ["Mart\u00ednez-Nuevo", "Pablo", ""], ["M\u00f8ller", "Martin Bo", ""], ["Shepstone", "Sven Ewan", ""]]}, {"id": "2001.11267", "submitter": "Ehsan Yaghoubi", "authors": "Ehsan Yaghoubi, Diana Borza, Aruna Kumar, Hugo Proen\\c{c}a", "title": "Person Re-identification: Implicitly Defining the Receptive Fields of\n  Deep Learning Classification Frameworks", "comments": "Submitted to PRL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{receptive fields} of deep learning classification models determine\nthe regions of the input data that have the most significance for providing\ncorrect decisions. The primary way to learn such receptive fields is to train\nthe models upon masked data, which helps the networks to ignore any unwanted\nregions, but has two major drawbacks: 1) it often yields edge-sensitive\ndecision processes; and 2) augments the computational cost of the inference\nphase considerably. This paper describes a solution for implicitly driving the\ninference of the networks' receptive fields, by creating synthetic learning\ndata composed of interchanged segments that should be \\emph{apriori}\nimportant/irrelevant for the network decision. In practice, we use a\nsegmentation module to distinguish between the foreground\n(important)/background (irrelevant) parts of each learning instance, and\nrandomly swap segments between image pairs, while keeping the class label\nexclusively consistent with the label of the deemed important segments. This\nstrategy typically drives the networks to early convergence and appropriate\nsolutions, where the identity and clutter descriptions are not correlated.\nMoreover, this data augmentation solution has various interesting properties:\n1) it is parameter-free; 2) it fully preserves the label information; and, 3)\nit is compatible with the typical data augmentation techniques. In the\nempirical validation, we considered the person re-identification problem and\nevaluated the effectiveness of the proposed solution in the well-known\n\\emph{Richly Annotated Pedestrian} (RAP) dataset for two different settings\n(\\emph{upper-body} and \\emph{full-body}), observing highly competitive results\nover the state-of-the-art. Under a reproducible research paradigm, both the\ncode and the empirical evaluation protocol are available at\n\\url{https://github.com/Ehsan-Yaghoubi/reid-strong-baseline}.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:45:44 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 12:38:49 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 18:38:32 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 19:59:52 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Yaghoubi", "Ehsan", ""], ["Borza", "Diana", ""], ["Kumar", "Aruna", ""], ["Proen\u00e7a", "Hugo", ""]]}, {"id": "2001.11268", "submitter": "Lena Schmidt", "authors": "Lena Schmidt, Julie Weeds, Julian P. T. Higgins", "title": "Data Mining in Clinical Trial Text: Transformers for Classification and\n  Question Answering Tasks", "comments": null, "journal-ref": "HEALTHINF 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research on data extraction methods applies recent advances in natural\nlanguage processing to evidence synthesis based on medical texts. Texts of\ninterest include abstracts of clinical trials in English and in multilingual\ncontexts. The main focus is on information characterized via the Population,\nIntervention, Comparator, and Outcome (PICO) framework, but data extraction is\nnot limited to these fields. Recent neural network architectures based on\ntransformers show capacities for transfer learning and increased performance on\ndownstream natural language processing tasks such as universal reading\ncomprehension, brought forward by this architecture's use of contextualized\nword embeddings and self-attention mechanisms. This paper contributes to\nsolving problems related to ambiguity in PICO sentence prediction tasks, as\nwell as highlighting how annotations for training named entity recognition\nsystems are used to train a high-performing, but nevertheless flexible\narchitecture for question answering in systematic review automation.\nAdditionally, it demonstrates how the problem of insufficient amounts of\ntraining annotations for PICO entity extraction is tackled by augmentation. All\nmodels in this paper were created with the aim to support systematic review\n(semi)automation. They achieve high F1 scores, and demonstrate the feasibility\nof applying transformer-based classification methods to support data mining in\nthe biomedical literature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:45:59 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Schmidt", "Lena", ""], ["Weeds", "Julie", ""], ["Higgins", "Julian P. T.", ""]]}, {"id": "2001.11272", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Sara Silva, Leonardo Vanneschi", "title": "A Study of Fitness Landscapes for Neuroevolution", "comments": "IEE CEC submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitness landscapes are a useful concept to study the dynamics of\nmeta-heuristics. In the last two decades, they have been applied with success\nto estimate the optimization power of several types of evolutionary algorithms,\nincluding genetic algorithms and genetic programming. However, so far they have\nnever been used to study the performance of machine learning algorithms on\nunseen data, and they have never been applied to neuroevolution. This paper\naims at filling both these gaps, applying for the first time fitness landscapes\nto neuroevolution and using them to infer useful information about the\npredictive ability of the method. More specifically, we use a grammar-based\napproach to generate convolutional neural networks, and we study the dynamics\nof three different mutations to evolve them. To characterize fitness\nlandscapes, we study autocorrelation and entropic measure of ruggedness. The\nresults show that these measures are appropriate for estimating both the\noptimization power and the generalization ability of the considered\nneuroevolution configurations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:53:55 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Silva", "Sara", ""], ["Vanneschi", "Leonardo", ""]]}, {"id": "2001.11274", "submitter": "Alfonso White", "authors": "Alfonso White, Daniela M. Romano", "title": "Scalable Psychological Momentum Forecasting in Esports", "comments": "8 pages, 8 figures", "journal-ref": "Proceedings of Workshop SUM '20: State-based User Modelling, The\n  13th ACM International Conference on Web Search and Data Mining (WSDM '20),\n  2020", "doi": "10.13140/RG.2.2.21224.21769", "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world of competitive Esports and video gaming has seen and continues to\nexperience steady growth in popularity and complexity. Correspondingly, more\nresearch on the topic is being published, ranging from social network analyses\nto the benchmarking of advanced artificial intelligence systems in playing\nagainst humans. In this paper, we present ongoing work on an intelligent agent\nrecommendation engine that suggests actions to players in order to maximise\nsuccess and enjoyment, both in the space of in-game choices, as well as\ndecisions made around play session timing in the broader context. By leveraging\ntemporal data and appropriate models, we show that a learned representation of\nplayer psychological momentum, and of tilt, can be used, in combination with\nplayer expertise, to achieve state-of-the-art performance in pre- and\npost-draft win prediction. Our progress toward fulfilling the potential for\nderiving optimal recommendations is documented.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:57:40 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 01:16:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["White", "Alfonso", ""], ["Romano", "Daniela M.", ""]]}, {"id": "2001.11279", "submitter": "Victor-Alexandru Darvariu", "authors": "Victor-Alexandru Darvariu, Stephen Hailes, Mirco Musolesi", "title": "Improving the Robustness of Graphs through Reinforcement Learning and\n  Graph Neural Networks", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs can be used to represent and reason about real world systems and a\nvariety of metrics have been devised to quantify their global characteristics.\nAn important property is robustness to failures and attacks, which is relevant\nfor the infrastructure and communication networks that power modern society.\nPrior work on making topological modifications to a graph, e.g., adding edges,\nin order to increase robustness is typically based on local and spectral\nproperties or a shallow search since robustness is expensive to compute\ndirectly. However, such strategies are necessarily suboptimal.\n  In this work, we present RNet-DQN, an approach for constructing networks that\nuses Reinforcement Learning to address improving the robustness of graphs to\nrandom and targeted removals of nodes. In particular, the approach relies on\nchanges in the estimated robustness as a reward signal and Graph Neural\nNetworks for representing states. Experiments on synthetic and real-world\ngraphs show that this approach can deliver performance superior to existing\nmethods while being much cheaper to evaluate and generalizing to out-of-sample\ngraphs, as well as to larger out-of-distribution graphs in some cases. The\napproach is readily applicable to optimizing other global structural properties\nof graphs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:11:45 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 20:38:53 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 10:24:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Darvariu", "Victor-Alexandru", ""], ["Hailes", "Stephen", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2001.11297", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Nasrullah Sheikh, Alberto Montresor", "title": "Which way? Direction-Aware Attributed Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding algorithms are used to efficiently represent (encode) a graph\nin a low-dimensional continuous vector space that preserves the most important\nproperties of the graph. One aspect that is often overlooked is whether the\ngraph is directed or not. Most studies ignore the directionality, so as to\nlearn high-quality representations optimized for node classification. On the\nother hand, studies that capture directionality are usually effective on link\nprediction but do not perform well on other tasks. This preliminary study\npresents a novel text-enriched, direction-aware algorithm called DIAGRAM ,\nbased on a carefully designed multi-objective model to learn embeddings that\npreserve the direction of edges, textual features and graph context of nodes.\nAs a result, our algorithm does not have to trade one property for another and\njointly learns high-quality representations for multiple network analysis\ntasks. We empirically show that DIAGRAM significantly outperforms six\nstate-of-the-art baselines, both direction-aware and oblivious ones,on link\nprediction and network reconstruction experiments using two popular datasets.\nIt also achieves a comparable performance on node classification experiments\nagainst these baselines using the same datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:08:19 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Sheikh", "Nasrullah", ""], ["Montresor", "Alberto", ""]]}, {"id": "2001.11314", "submitter": "Yu-Kun Li", "authors": "Dongling Xiao, Han Zhang, Yukun Li, Yu Sun, Hao Tian, Hua Wu and\n  Haifeng Wang", "title": "ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework\n  for Natural Language Generation", "comments": "The source codes and pre-trained models have been released at\n  https://github.com/PaddlePaddle/ERNIE. We have also updated the performances\n  of ERNIE-GEN under a larger scaled pre-training corpora in appendix A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current pre-training works in natural language generation pay little\nattention to the problem of exposure bias on downstream tasks. To address this\nissue, we propose an enhanced multi-flow sequence to sequence pre-training and\nfine-tuning framework named ERNIE-GEN, which bridges the discrepancy between\ntraining and inference with an infilling generation mechanism and a noise-aware\ngeneration method. To make generation closer to human writing patterns, this\nframework introduces a span-by-span generation flow that trains the model to\npredict semantically-complete spans consecutively rather than predicting word\nby word. Unlike existing pre-training methods, ERNIE-GEN incorporates\nmulti-granularity target sampling to construct pre-training data, which\nenhances the correlation between encoder and decoder. Experimental results\ndemonstrate that ERNIE-GEN achieves state-of-the-art results with a much\nsmaller amount of pre-training data and parameters on a range of language\ngeneration tasks, including abstractive summarization (Gigaword and\nCNN/DailyMail), question generation (SQuAD), dialogue generation (Persona-Chat)\nand generative question answering (CoQA).\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 02:54:49 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 06:48:44 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 08:09:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xiao", "Dongling", ""], ["Zhang", "Han", ""], ["Li", "Yukun", ""], ["Sun", "Yu", ""], ["Tian", "Hao", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2001.11316", "submitter": "Akbar Karimi", "authors": "Akbar Karimi, Leonardo Rossi, Andrea Prati", "title": "Adversarial Training for Aspect-Based Sentiment Analysis with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of\nsentiments and their targets. Collecting labeled data for this task in order to\nhelp neural networks generalize better can be laborious and time-consuming. As\nan alternative, similar data to the real-world examples can be produced\nartificially through an adversarial process which is carried out in the\nembedding space. Although these examples are not real sentences, they have been\nshown to act as a regularization method which can make neural networks more\nrobust. In this work, we apply adversarial training, which was put forward by\nGoodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model\nproposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and\nAspect Sentiment Classification in sentiment analysis. After improving the\nresults of post-trained BERT by an ablation study, we propose a novel\narchitecture called BERT Adversarial Training (BAT) to utilize adversarial\ntraining in ABSA. The proposed model outperforms post-trained BERT in both\ntasks. To the best of our knowledge, this is the first study on the application\nof adversarial training in ABSA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:53:58 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 12:33:57 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 13:39:32 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 07:39:17 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Karimi", "Akbar", ""], ["Rossi", "Leonardo", ""], ["Prati", "Andrea", ""]]}, {"id": "2001.11342", "submitter": "Xiaoran Cai", "authors": "Xiaoran Cai, Xiaopeng Mo, Junyang Chen, and Jie Xu", "title": "D2D-Enabled Data Sharing for Distributed Machine Learning at Wireless\n  Network Edge", "comments": "Submit to IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge learning is an emerging technique that enables distributed edge\ndevices to collaborate in training shared machine learning models by exploiting\ntheir local data samples and communication and computation resources. To deal\nwith the straggler dilemma issue faced in this technique, this paper proposes a\nnew device to device enabled data sharing approach, in which different edge\ndevices share their data samples among each other over communication links, in\norder to properly adjust their computation loads for increasing the training\nspeed. Under this setup, we optimize the radio resource allocation for both\ndata sharing and distributed training, with the objective of minimizing the\ntotal training delay under fixed numbers of local and global iterations.\nNumerical results show that the proposed data sharing design significantly\nreduces the training delay, and also enhances the training accuracy when the\ndata samples are non independent and identically distributed among edge\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 01:49:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Cai", "Xiaoran", ""], ["Mo", "Xiaopeng", ""], ["Chen", "Junyang", ""], ["Xu", "Jie", ""]]}, {"id": "2001.11349", "submitter": "Ioannis Papantonis", "authors": "Ioannis Papantonis, Vaishak Belle", "title": "On Constraint Definability in Tractable Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating constraints is a major concern in probabilistic machine\nlearning. A wide variety of problems require predictions to be integrated with\nreasoning about constraints, from modelling routes on maps to approving loan\npredictions. In the former, we may require the prediction model to respect the\npresence of physical paths between the nodes on the map, and in the latter, we\nmay require that the prediction model respect fairness constraints that ensure\nthat outcomes are not subject to bias. Broadly speaking, constraints may be\nprobabilistic, logical or causal, but the overarching challenge is to determine\nif and how a model can be learnt that handles all the declared constraints. To\nthe best of our knowledge, this is largely an open problem. In this paper, we\nconsider a mathematical inquiry on how the learning of tractable probabilistic\nmodels, such as sum-product networks, is possible while incorporating\nconstraints.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:05:56 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Papantonis", "Ioannis", ""], ["Belle", "Vaishak", ""]]}, {"id": "2001.11355", "submitter": "Jia Guo", "authors": "Jia Guo and Chenyang Yang", "title": "Constructing Deep Neural Networks with a Priori Knowledge of Wireless\n  Tasks", "comments": "30 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1910.13728", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been employed for designing wireless systems\nin many aspects, say transceiver design, resource optimization, and information\nprediction. Existing works either use the fully-connected DNN or the DNNs with\nparticular architectures developed in other domains. While generating labels\nfor supervised learning and gathering training samples are time-consuming or\ncost-prohibitive, how to develop DNNs with wireless priors for reducing\ntraining complexity remains open. In this paper, we show that two kinds of\npermutation invariant properties widely existed in wireless tasks can be\nharnessed to reduce the number of model parameters and hence the sample and\ncomputational complexity for training. We find special architecture of DNNs\nwhose input-output relationships satisfy the properties, called permutation\ninvariant DNN (PINN), and augment the data with the properties. By learning the\nimpact of the scale of a wireless system, the size of the constructed PINNs can\nflexibly adapt to the input data dimension. We take predictive resource\nallocation and interference coordination as examples to show how the PINNs can\nbe employed for learning the optimal policy with unsupervised and supervised\nlearning. Simulations results demonstrate a dramatic gain of the proposed PINNs\nin terms of reducing training complexity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:54:42 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Guo", "Jia", ""], ["Yang", "Chenyang", ""]]}, {"id": "2001.11359", "submitter": "Xiaodong Yang", "authors": "Yiqiang Chen, Xiaodong Yang, Xin Qin, Han Yu, Biao Chen, Zhiqi Shen", "title": "FOCUS: Dealing with Label Quality Disparity in Federated Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous systems with End-Edge-Cloud architecture are increasingly being\nused in healthcare applications. Federated Learning (FL) is highly useful for\nsuch applications, due to silo effect and privacy preserving. Existing FL\napproaches generally do not account for disparities in the quality of local\ndata labels. However, the clients in ubiquitous systems tend to suffer from\nlabel noise due to varying skill-levels, biases or malicious tampering of the\nannotators. In this paper, we propose Federated Opportunistic Computing for\nUbiquitous Systems (FOCUS) to address this challenge. It maintains a small set\nof benchmark samples on the FL server and quantifies the credibility of the\nclient local data without directly observing them by computing the mutual\ncross-entropy between performance of the FL model on the local datasets and\nthat of the client local FL model on the benchmark dataset. Then, a credit\nweighted orchestration is performed to adjust the weight assigned to clients in\nthe FL model based on their credibility values. FOCUS has been experimentally\nevaluated on both synthetic data and real-world data. The results show that it\neffectively identifies clients with noisy labels and reduces their impact on\nthe model performance, thereby significantly outperforming existing FL\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 09:31:01 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Chen", "Yiqiang", ""], ["Yang", "Xiaodong", ""], ["Qin", "Xin", ""], ["Yu", "Han", ""], ["Chen", "Biao", ""], ["Shen", "Zhiqi", ""]]}, {"id": "2001.11360", "submitter": "Murali Karthick Baskar", "authors": "Martin Karafi\\'at, Murali Karthick Baskar, Igor Sz\\\"oke, Hari Krishna\n  Vydana, Karel Vesel\\'y, Jan \"Honza'' \\v{C}ernock\\'y", "title": "BUT Opensat 2019 Speech Recognition System", "comments": "REJECTED in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes the BUT Automatic Speech Recognition (ASR) systems\nsubmitted for OpenSAT evaluations under two domain categories such as low\nresourced languages and public safety communications. The first was challenging\ndue to lack of training data, therefore various architectures and multilingual\napproaches were employed. The combination led to superior performance. The\nsecond domain was challenging due to recording in extreme conditions such as\nspecific channel, speaker under stress and high levels of noise. Data\naugmentation process was inevitable to get reasonably good performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:35:34 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Karafi\u00e1t", "Martin", ""], ["Baskar", "Murali Karthick", ""], ["Sz\u00f6ke", "Igor", ""], ["Vydana", "Hari Krishna", ""], ["Vesel\u00fd", "Karel", ""], ["\u010cernock\u00fd", "Jan \"Honza''", ""]]}, {"id": "2001.11363", "submitter": "Rahul Duggal", "authors": "Rahul Duggal, Scott Freitas, Cao Xiao, Duen Horng Chau, Jimeng Sun", "title": "REST: Robust and Efficient Neural Networks for Sleep Monitoring in the\n  Wild", "comments": "Accepted to WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380241", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, significant attention has been devoted towards integrating\ndeep learning technologies in the healthcare domain. However, to safely and\npractically deploy deep learning models for home health monitoring, two\nsignificant challenges must be addressed: the models should be (1) robust\nagainst noise; and (2) compact and energy-efficient. We propose REST, a new\nmethod that simultaneously tackles both issues via 1) adversarial training and\ncontrolling the Lipschitz constant of the neural network through spectral\nregularization while 2) enabling neural network compression through sparsity\nregularization. We demonstrate that REST produces highly-robust and efficient\nmodels that substantially outperform the original full-sized models in the\npresence of noise. For the sleep staging task over single-channel\nelectroencephalogram (EEG), the REST model achieves a macro-F1 score of 0.67\nvs. 0.39 achieved by a state-of-the-art model in the presence of Gaussian noise\nwhile obtaining 19x parameter reduction and 15x MFLOPS reduction on two large,\nreal-world EEG datasets. By deploying these models to an Android application on\na smartphone, we quantitatively observe that REST allows models to achieve up\nto 17x energy reduction and 9x faster inference. We open-source the code\nrepository with this paper: https://github.com/duggalrahul/REST.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 17:23:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Duggal", "Rahul", ""], ["Freitas", "Scott", ""], ["Xiao", "Cao", ""], ["Chau", "Duen Horng", ""], ["Sun", "Jimeng", ""]]}, {"id": "2001.11366", "submitter": "Anna Bosman", "authors": "Mamuku Mokuwe, Michael Burke, Anna Sergeevna Bosman", "title": "Black-Box Saliency Map Generation Using Bayesian Optimisation", "comments": "Submitted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency maps are often used in computer vision to provide intuitive\ninterpretations of what input regions a model has used to produce a specific\nprediction. A number of approaches to saliency map generation are available,\nbut most require access to model parameters. This work proposes an approach for\nsaliency map generation for black-box models, where no access to model\nparameters is available, using a Bayesian optimisation sampling method. The\napproach aims to find the global salient image region responsible for a\nparticular (black-box) model's prediction. This is achieved by a sampling-based\napproach to model perturbations that seeks to localise salient regions of an\nimage to the black-box model. Results show that the proposed approach to\nsaliency map generation outperforms grid-based perturbation approaches, and\nperforms similarly to gradient-based approaches which require access to model\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:39:12 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Mokuwe", "Mamuku", ""], ["Burke", "Michael", ""], ["Bosman", "Anna Sergeevna", ""]]}, {"id": "2001.11396", "submitter": "Matthew Willetts", "authors": "Miguel Morin, Matthew Willetts", "title": "Non-Determinism in TensorFlow ResNets", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the stochasticity in training ResNets for image classification\non GPUs in TensorFlow is dominated by the non-determinism from GPUs, rather\nthan by the initialisation of the weights and biases of the network or by the\nsequence of minibatches given. The standard deviation of test set accuracy is\n0.02 with fixed seeds, compared to 0.027 with different seeds---nearly 74\\% of\nthe standard deviation of a ResNet model is non-deterministic. For test set\nloss the ratio of standard deviations is more than 80\\%. These results call for\nmore robust evaluation strategies of deep learning models, as a significant\namount of the variation in results across runs can arise simply from GPU\nrandomness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:29:13 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Morin", "Miguel", ""], ["Willetts", "Matthew", ""]]}, {"id": "2001.11399", "submitter": "Bojan Kostic", "authors": "Bojan Kostic, Romain Crastes dit Sourd, Stephane Hess, Joachim\n  Scheiner, Christian Holz-Rau, Francisco C. Pereira", "title": "Uncovering life-course patterns with causal discovery and survival\n  analysis", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel approach and an exploratory study for modelling life event\nchoices and occurrence from a probabilistic perspective through causal\ndiscovery and survival analysis. Our approach is formulated as a bi-level\nproblem. In the upper level, we build the life events graph, using causal\ndiscovery tools. In the lower level, for the pairs of life events,\ntime-to-event modelling through survival analysis is applied to model\ntime-dependent transition probabilities. Several life events were analysed,\nsuch as getting married, buying a new car, child birth, home relocation and\ndivorce, together with the socio-demographic attributes for survival modelling,\nsome of which are age, nationality, number of children, number of cars and home\nownership. The data originates from a survey conducted in Dortmund, Germany,\nwith the questionnaire containing a series of retrospective questions about\nresidential and employment biography, travel behaviour and holiday trips, as\nwell as socio-economic characteristic. Although survival analysis has been used\nin the past to analyse life-course data, this is the first time that a bi-level\nmodel has been formulated. The inclusion of a causal discovery algorithm in the\nupper-level allows us to first identify causal relationships between\nlife-course events and then understand the factors that might influence\ntransition rates between events. This is very different from more classic\nchoice models where causal relationships are subject to expert interpretations\nbased on model results.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:30:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Kostic", "Bojan", ""], ["Sourd", "Romain Crastes dit", ""], ["Hess", "Stephane", ""], ["Scheiner", "Joachim", ""], ["Holz-Rau", "Christian", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2001.11400", "submitter": "Abin Jose", "authors": "Abin Jose, Erik Stefan Ottlik, Christian Rohlfing, Jens-Rainer Ohm", "title": "Optimized Feature Space Learning for Generating Efficient Binary Codes\n  for Image Retrieval", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an approach for learning low dimensional optimized\nfeature space with minimum intra-class variance and maximum inter-class\nvariance. We address the problem of high-dimensionality of feature vectors\nextracted from neural networks by taking care of the global statistics of\nfeature space. Classical approach of Linear Discriminant Analysis (LDA) is\ngenerally used for generating an optimized low dimensional feature space for\nsingle-labeled images. Since, image retrieval involves both multi-labeled and\nsingle-labeled images, we utilize the equivalence between LDA and Canonical\nCorrelation Analysis (CCA) to generate an optimized feature space for\nsingle-labeled images and use CCA to generate an optimized feature space for\nmulti-labeled images. Our approach correlates the projections of feature\nvectors with label vectors in our CCA based network architecture. The neural\nnetwork minimize a loss function which maximizes the correlation coefficients.\nWe binarize our generated feature vectors with the popular Iterative\nQuantization (ITQ) approach and also propose an ensemble network to generate\nbinary codes of desired bit length for image retrieval. Our measurement of mean\naverage precision shows competitive results on other state-of-the-art\nsingle-labeled and multi-labeled image retrieval datasets.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:30:31 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Jose", "Abin", ""], ["Ottlik", "Erik Stefan", ""], ["Rohlfing", "Christian", ""], ["Ohm", "Jens-Rainer", ""]]}, {"id": "2001.11402", "submitter": "Jiancan Wu", "authors": "Jiancan Wu, Xiangnan He, Xiang Wang, Qifan Wang, Weijian Chen, Jianxun\n  Lian, Xing Xie", "title": "Graph Convolution Machine for Context-aware Recommender System", "comments": "19 pages, 4 figures, 4 tables. Accepted by Frontiers of Computer\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The latest advance in recommendation shows that better user and item\nrepresentations can be learned via performing graph convolutions on the\nuser-item interaction graph. However, such finding is mostly restricted to the\ncollaborative filtering (CF) scenario, where the interaction contexts are not\navailable. In this work, we extend the advantages of graph convolutions to\ncontext-aware recommender system (CARS, which represents a generic type of\nmodels that can handle various side information). We propose \\textit{Graph\nConvolution Machine} (GCM), an end-to-end framework that consists of three\ncomponents: an encoder, graph convolution (GC) layers, and a decoder. The\nencoder projects users, items, and contexts into embedding vectors, which are\npassed to the GC layers that refine user and item embeddings with context-aware\ngraph convolutions on user-item graph. The decoder digests the refined\nembeddings to output the prediction score by considering the interactions among\nuser, item, and context embeddings. We conduct experiments on three real-world\ndatasets from Yelp and Amazon, validating the effectiveness of GCM and the\nbenefits of performing graph convolutions for CARS. Our implementations are\navailable at \\url{https://github.com/wujcan/GCM}.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:32:08 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:32:00 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 09:46:14 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wu", "Jiancan", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Wang", "Qifan", ""], ["Chen", "Weijian", ""], ["Lian", "Jianxun", ""], ["Xie", "Xing", ""]]}, {"id": "2001.11406", "submitter": "Helard Becerra Martinez Dr", "authors": "Helard Martinez, M. C. Farias, A. Hines", "title": "NAViDAd: A No-Reference Audio-Visual Quality Metric Based on a Deep\n  Autoencoder", "comments": "5 pages", "journal-ref": "2019 27th European Signal Processing Conference (EUSIPCO), IEEE,\n  2019, pp 1-5", "doi": "10.23919/EUSIPCO.2019.8902975", "report-no": null, "categories": "cs.MM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of models for quality prediction of both audio and video\nsignals is a fairly mature field. But, although several multimodal models have\nbeen proposed, the area of audio-visual quality prediction is still an emerging\narea. In fact, despite the reasonable performance obtained by combination and\nparametric metrics, currently there is no reliable pixel-based audio-visual\nquality metric. The approach presented in this work is based on the assumption\nthat autoencoders, fed with descriptive audio and video features, might produce\na set of features that is able to describe the complex audio and video\ninteractions. Based on this hypothesis, we propose a No-Reference Audio-Visual\nQuality Metric Based on a Deep Autoencoder (NAViDAd). The model visual features\nare natural scene statistics (NSS) and spatial-temporal measures of the video\ncomponent. Meanwhile, the audio features are obtained by computing the\nspectrogram representation of the audio component. The model is formed by a\n2-layer framework that includes a deep autoencoder layer and a classification\nlayer. These two layers are stacked and trained to build the deep neural\nnetwork model. The model is trained and tested using a large set of stimuli,\ncontaining representative audio and video artifacts. The model performed well\nwhen tested against the UnB-AV and the LiveNetflix-II databases. %Results shows\nthat this type of approach produces quality scores that are highly correlated\nto subjective quality scores.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:40:08 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 19:08:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Martinez", "Helard", ""], ["Farias", "M. C.", ""], ["Hines", "A.", ""]]}, {"id": "2001.11409", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Attila Schulc, Elnar Hajiyev and Stefanos Zafeiriou", "title": "Analysing Affective Behavior in the First ABAW 2020 Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Affective Behavior Analysis in-the-wild (ABAW) 2020 Competition is the\nfirst Competition aiming at automatic analysis of the three main behavior tasks\nof valence-arousal estimation, basic expression recognition and action unit\ndetection. It is split into three Challenges, each one addressing a respective\nbehavior task. For the Challenges, we provide a common benchmark database,\nAff-Wild2, which is a large scale in-the-wild database and the first one\nannotated for all these three tasks. In this paper, we describe this\nCompetition, to be held in conjunction with the IEEE Conference on Face and\nGesture Recognition, May 2020, in Buenos Aires, Argentina. We present the three\nChallenges, with the utilized Competition corpora. We outline the evaluation\nmetrics, present both the baseline system and the top-3 performing teams'\nmethodologies per Challenge and finally present their obtained results. More\ninformation regarding the Competition, the leaderboard of each Challenge and\ndetails for accessing the utilized database, are provided in the Competition\nsite:\nhttp://ibug.doc.ic.ac.uk/resources/fg-2020-competition-affective-behavior-analysis.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:41:14 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 14:05:59 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Schulc", "Attila", ""], ["Hajiyev", "Elnar", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2001.11411", "submitter": "Maxim Panov", "authors": "Aleksandr Artemenkov and Maxim Panov", "title": "NCVis: Noise Contrastive Approach for Scalable Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern methods for data visualization via dimensionality reduction, such as\nt-SNE, usually have performance issues that prohibit their application to large\namounts of high-dimensional data. In this work, we propose NCVis -- a\nhigh-performance dimensionality reduction method built on a sound statistical\nbasis of noise contrastive estimation. We show that NCVis outperforms\nstate-of-the-art techniques in terms of speed while preserving the\nrepresentation quality of other methods. In particular, the proposed approach\nsuccessfully proceeds a large dataset of more than 1 million news headlines in\nseveral minutes and presents the underlying structure in a human-readable way.\nMoreover, it provides results consistent with classical methods like t-SNE on\nmore straightforward datasets like images of hand-written digits. We believe\nthat the broader usage of such software can significantly simplify the\nlarge-scale data analysis and lower the entry barrier to this area.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:43:50 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Artemenkov", "Aleksandr", ""], ["Panov", "Maxim", ""]]}, {"id": "2001.11419", "submitter": "Kyle Gilman", "authors": "Kyle Gilman and Laura Balzano", "title": "Grassmannian Optimization for Online Tensor Completion and Tracking with\n  the t-SVD", "comments": "13 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new fast streaming algorithm for the tensor completion problem\nof imputing missing entries of a low-tubal-rank tensor using the tensor\nsingular value decomposition (t-SVD) algebraic framework. We show the t-SVD is\na specialization of the well-studied block-term decomposition for third-order\ntensors, and we present an algorithm under this model that can track changing\nfree submodules from incomplete streaming 2-D data. We use principles from\nincremental gradient descent on the Grassmann manifold of subspaces to solve\nthe tensor completion problem with linear complexity and constant memory in the\nnumber of time samples. Our results are competitive in accuracy but much faster\nin compute time than state-of-the-art tensor completion algorithms on real\napplications to recover temporal chemo-sensing and MRI data under limited\nsampling.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:56:14 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 00:28:26 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Gilman", "Kyle", ""], ["Balzano", "Laura", ""]]}, {"id": "2001.11443", "submitter": "Huy Tuan Pham", "authors": "Phan-Minh Nguyen, Huy Tuan Pham", "title": "A Rigorous Framework for the Mean Field Limit of Multilayer Neural\n  Networks", "comments": "116 pages. This version incorporates the content of the companion\n  note arXiv:2006.09355 (June 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a mathematically rigorous framework for multilayer neural networks\nin the mean field regime. As the network's widths increase, the network's\nlearning trajectory is shown to be well captured by a meaningful and\ndynamically nonlinear limit (the \\textit{mean field} limit), which is\ncharacterized by a system of ODEs. Our framework applies to a broad range of\nnetwork architectures, learning dynamics and network initializations. Central\nto the framework is the new idea of a \\textit{neuronal embedding}, which\ncomprises of a non-evolving probability space that allows to embed neural\nnetworks of arbitrary widths.\n  Using our framework, we prove several properties of large-width multilayer\nneural networks. Firstly we show that independent and identically distributed\ninitializations cause strong degeneracy effects on the network's learning\ntrajectory when the network's depth is at least four. Secondly we obtain\nseveral global convergence guarantees for feedforward multilayer networks under\na number of different setups. These include two-layer and three-layer networks\nwith independent and identically distributed initializations, and multilayer\nnetworks of arbitrary depths with a special type of correlated initializations\nthat is motivated by the new concept of \\textit{bidirectional diversity}.\nUnlike previous works that rely on convexity, our results admit non-convex\nlosses and hinge on a certain universal approximation property, which is a\ndistinctive feature of infinite-width neural networks and is shown to hold\nthroughout the training process. Aside from being the first known results for\nglobal convergence of multilayer networks in the mean field regime, they\ndemonstrate flexibility of our framework and incorporate several new ideas and\ninsights that depart from the conventional convex optimization wisdom.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 16:43:34 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 17:44:02 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nguyen", "Phan-Minh", ""], ["Pham", "Huy Tuan", ""]]}, {"id": "2001.11466", "submitter": "Laura Maria Palomino Marino", "authors": "Agust\\'in Alejandro Ortiz-D\\'iaz, Fabiano Baldo, Laura Mar\\'ia\n  Palomino Mari\\~no and Alberto Verdecia Cabrera", "title": "Fase-AL -- Adaptation of Fast Adaptive Stacking of Ensembles for\n  Supporting Active Learning", "comments": "10 pages, 6 figures", "journal-ref": "AIRCC, Volume 10, Number 01, January 2020. 7th International\n  Conference on Computer Science and Information Technology (CoSIT 2020). ISBN\n  : 978-1-925953-15-2", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification algorithms to mine data stream have been extensively studied\nin recent years. However, a lot of these algorithms are designed for supervised\nlearning which requires labeled instances. Nevertheless, the labeling of the\ndata is costly and time-consuming. Because of this, alternative learning\nparadigms have been proposed to reduce the cost of the labeling process without\nsignificant loss of model performance. Active learning is one of these\nparadigms, whose main objective is to build classification models that request\nthe lowest possible number of labeled examples achieving adequate levels of\naccuracy. Therefore, this work presents the FASE-AL algorithm which induces\nclassification models with non-labeled instances using Active Learning. FASE-AL\nis based on the algorithm Fast Adaptive Stacking of Ensembles (FASE). FASE is\nan ensemble algorithm that detects and adapts the model when the input data\nstream has concept drift. FASE-AL was compared with four different strategies\nof active learning found in the literature. Real and synthetic databases were\nused in the experiments. The algorithm achieves promising results in terms of\nthe percentage of correctly classified instances.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:25:47 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ortiz-D\u00edaz", "Agust\u00edn Alejandro", ""], ["Baldo", "Fabiano", ""], ["Mari\u00f1o", "Laura Mar\u00eda Palomino", ""], ["Cabrera", "Alberto Verdecia", ""]]}, {"id": "2001.11473", "submitter": "Gonzalo Rios", "authors": "Gonzalo Rios", "title": "Transport Gaussian Processes for Regression", "comments": "19 pages, 2 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) priors are non-parametric generative models with\nappealing modelling properties for Bayesian inference: they can model\nnon-linear relationships through noisy observations, have closed-form\nexpressions for training and inference, and are governed by interpretable\nhyperparameters. However, GP models rely on Gaussianity, an assumption that\ndoes not hold in several real-world scenarios, e.g., when observations are\nbounded or have extreme-value dependencies, a natural phenomenon in physics,\nfinance and social sciences. Although beyond-Gaussian stochastic processes have\ncaught the attention of the GP community, a principled definition and rigorous\ntreatment is still lacking. In this regard, we propose a methodology to\nconstruct stochastic processes, which include GPs, warped GPs, Student-t\nprocesses and several others under a single unified approach. We also provide\nformulas and algorithms for training and inference of the proposed models in\nthe regression problem. Our approach is inspired by layers-based models, where\neach proposed layer changes a specific property over the generated stochastic\nprocess. That, in turn, allows us to push-forward a standard Gaussian white\nnoise prior towards other more expressive stochastic processes, for which\nmarginals and copulas need not be Gaussian, while retaining the appealing\nproperties of GPs. We validate the proposed model through experiments with\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:44:21 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rios", "Gonzalo", ""]]}, {"id": "2001.11482", "submitter": "Zhuo Chen", "authors": "Zhuo Chen, Takuya Yoshioka, Liang Lu, Tianyan Zhou, Zhong Meng, Yi\n  Luo, Jian Wu, Xiong Xiao, Jinyu Li", "title": "Continuous speech separation: dataset and analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a dataset and protocols for evaluating continuous speech\nseparation algorithms. Most prior studies on speech separation use\npre-segmented signals of artificially mixed speech utterances which are mostly\n\\emph{fully} overlapped, and the algorithms are evaluated based on\nsignal-to-distortion ratio or similar performance metrics. However, in natural\nconversations, a speech signal is continuous, containing both overlapped and\noverlap-free components. In addition, the signal-based metrics have very weak\ncorrelations with automatic speech recognition (ASR) accuracy. We think that\nnot only does this make it hard to assess the practical relevance of the tested\nalgorithms, it also hinders researchers from developing systems that can be\nreadily applied to real scenarios. In this paper, we define continuous speech\nseparation (CSS) as a task of generating a set of non-overlapped speech signals\nfrom a \\textit{continuous} audio stream that contains multiple utterances that\nare \\emph{partially} overlapped by a varying degree. A new real recorded\ndataset, called LibriCSS, is derived from LibriSpeech by concatenating the\ncorpus utterances to simulate a conversation and capturing the audio replays\nwith far-field microphones. A Kaldi-based ASR evaluation protocol is also\nestablished by using a well-trained multi-conditional acoustic model. By using\nthis dataset, several aspects of a recently proposed speaker-independent CSS\nalgorithm are investigated. The dataset and evaluation scripts are available to\nfacilitate the research in this direction.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:01:31 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 03:25:41 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 09:13:27 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Chen", "Zhuo", ""], ["Yoshioka", "Takuya", ""], ["Lu", "Liang", ""], ["Zhou", "Tianyan", ""], ["Meng", "Zhong", ""], ["Luo", "Yi", ""], ["Wu", "Jian", ""], ["Xiao", "Xiong", ""], ["Li", "Jinyu", ""]]}, {"id": "2001.11486", "submitter": "Siham Tabik", "authors": "S. Tabik, R.F. Alvear-Sandoval, M.M. Ruiz, J.L. Sancho-G\\'omez, A.R.\n  Figueiras-Vidal, F. Herrera", "title": "MNIST-NET10: A heterogeneous deep networks fusion based on the degree of\n  certainty to reach 0.1 error rate. Ensembles overview and proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble methods have been widely used for improving the results of the best\nsingle classificationmodel. A large body of works have achieved better\nperformance mainly by applying one specific ensemble method. However, very few\nworks have explored complex fusion schemes using het-erogeneous ensembles with\nnew aggregation strategies. This paper is three-fold: 1) It provides an\noverview of the most popular ensemble methods, 2) analyzes several fusion\nschemes using MNIST as guiding thread and 3) introduces MNIST-NET10, a complex\nheterogeneous fusion architecture based on a degree of certainty aggregation\napproach; it combines two heterogeneous schemes from the perspective of data,\nmodel and fusion strategy. MNIST-NET10 reaches a new record in MNISTwith only\n10 misclassified images. Our analysis shows that such complex heterogeneous\nfusionarchitectures based on the degree of certainty can be considered as a way\nof taking benefit fromdiversity.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:13:28 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 15:19:48 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Tabik", "S.", ""], ["Alvear-Sandoval", "R. F.", ""], ["Ruiz", "M. M.", ""], ["Sancho-G\u00f3mez", "J. L.", ""], ["Figueiras-Vidal", "A. R.", ""], ["Herrera", "F.", ""]]}, {"id": "2001.11495", "submitter": "Rishabh Singh", "authors": "Rishabh Singh and Jose C. Principe", "title": "Towards a Kernel based Uncertainty Decomposition Framework for Data and\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new framework for quantifying predictive uncertainty\nfor both data and models that relies on projecting the data into a Gaussian\nreproducing kernel Hilbert space (RKHS) and transforming the data probability\ndensity function (PDF) in a way that quantifies the flow of its gradient as a\ntopological potential field quantified at all points in the sample space. This\nenables the decomposition of the PDF gradient flow by formulating it as a\nmoment decomposition problem using operators from quantum physics, specifically\nthe Schrodinger's formulation. We experimentally show that the higher order\nmodes systematically cluster the different tail regions of the PDF, thereby\nproviding unprecedented discriminative resolution of data regions having high\nepistemic uncertainty. In essence, this approach decomposes local realizations\nof the data PDF in terms of uncertainty moments. We apply this framework as a\nsurrogate tool for predictive uncertainty quantification of point-prediction\nneural network models, overcoming various limitations of conventional Bayesian\nbased uncertainty quantification methods. Experimental comparisons with some\nestablished methods illustrate performance advantages exhibited by our\nframework.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:35:36 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 10:21:43 GMT"}, {"version": "v3", "created": "Sun, 21 Jun 2020 06:24:31 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 14:42:13 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Singh", "Rishabh", ""], ["Principe", "Jose C.", ""]]}, {"id": "2001.11499", "submitter": "Jana \\v{C}avojsk\\'a", "authors": "Jana \\v{C}avojsk\\'a (1), Julian Petrasch (1), Nicolas J. Lehmann (1),\n  Agn\\`es Voisard (1), Peter B\\\"ottcher (2) ((1) Freie Universit\\\"at Berlin,\n  Institute of Computer Science, 14195 Berlin, Germany, (2) Freie Universit\\\"at\n  Berlin, Clinic for Small Animals, 14163 Berlin, Germany)", "title": "Estimating and abstracting the 3D structure of bones using neural\n  networks on X-ray (2D) images", "comments": "13 pages, 5 figures, 1 table, submitted to Communications Biology", "journal-ref": "Communications biology, 2020, 3(1), pp.1-13", "doi": "10.1038/s42003-020-1057-3", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a deep-learning based method for estimating the 3D\nstructure of a bone from a pair of 2D X-ray images. Our triplet loss-trained\nneural network selects the most closely matching 3D bone shape from a\npredefined set of shapes. Our predictions have an average root mean square\n(RMS) distance of 1.08 mm between the predicted and true shapes, making it more\naccurate than the average error achieved by eight other examined 3D bone\nreconstruction approaches. The prediction process that we use is fully\nautomated and unlike many competing approaches, it does not rely on any\nprevious knowledge about bone geometry. Additionally, our neural network can\ndetermine the identity of a bone based only on its X-ray image. It computes a\nlow-dimensional representation (\"embedding\") of each 2D X-ray image and\nhenceforth compares different X-ray images based only on their embeddings. An\nembedding holds enough information to uniquely identify the bone CT belonging\nto the input X-ray image with a 100% accuracy and can therefore serve as a kind\nof fingerprint for that bone. Possible applications include faster, image\ncontent-based bone database searches for forensic purposes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:41:17 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["\u010cavojsk\u00e1", "Jana", ""], ["Petrasch", "Julian", ""], ["Lehmann", "Nicolas J.", ""], ["Voisard", "Agn\u00e8s", ""], ["B\u00f6ttcher", "Peter", ""]]}, {"id": "2001.11539", "submitter": "Jiangbo Yuan", "authors": "Jiangbo Yuan, Bing Wu, Wanying Ding, Qing Ping, and Zhendong Yu", "title": "Adversarial Code Learning for Image Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the \"adversarial code learning\" (ACL) module that improves\noverall image generation performance to several types of deep models. Instead\nof performing a posterior distribution modeling in the pixel spaces of\ngenerators, ACLs aim to jointly learn a latent code with another image\nencoder/inference net, with a prior noise as its input. We conduct the learning\nin an adversarial learning process, which bears a close resemblance to the\noriginal GAN but again shifts the learning from image spaces to prior and\nlatent code spaces. ACL is a portable module that brings up much more\nflexibility and possibilities in generative model designs. First, it allows\nflexibility to convert non-generative models like Autoencoders and standard\nclassification models to decent generative models. Second, it enhances existing\nGANs' performance by generating meaningful codes and images from any part of\nthe prior. We have incorporated our ACL module with the aforementioned\nframeworks and have performed experiments on synthetic, MNIST, CIFAR-10, and\nCelebA datasets. Our models have achieved significant improvements which\ndemonstrated the generality for image generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 19:52:46 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Yuan", "Jiangbo", ""], ["Wu", "Bing", ""], ["Ding", "Wanying", ""], ["Ping", "Qing", ""], ["Yu", "Zhendong", ""]]}, {"id": "2001.11542", "submitter": "Ritwik Giri", "authors": "Bahareh Tolooshams, Ritwik Giri, Andrew H. Song, Umut Isik, Arvindh\n  Krishnaswamy", "title": "Channel-Attention Dense U-Net for Multichannel Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep learning has gained significant attention for speech\nenhancement recently. The state-of-the-art deep learning methods perform the\ntask by learning a ratio/binary mask that is applied to the mixture in the\ntime-frequency domain to produce the clean speech. Despite the great\nperformance in the single-channel setting, these frameworks lag in performance\nin the multichannel setting as the majority of these methods a) fail to exploit\nthe available spatial information fully, and b) still treat the deep\narchitecture as a black box which may not be well-suited for multichannel audio\nprocessing. This paper addresses these drawbacks, a) by utilizing complex ratio\nmasking instead of masking on the magnitude of the spectrogram, and more\nimportantly, b) by introducing a channel-attention mechanism inside the deep\narchitecture to mimic beamforming. We propose Channel-Attention Dense U-Net, in\nwhich we apply the channel-attention unit recursively on feature maps at every\nlayer of the network, enabling the network to perform non-linear beamforming.\nWe demonstrate the superior performance of the network against the\nstate-of-the-art approaches on the CHiME-3 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 19:56:52 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Giri", "Ritwik", ""], ["Song", "Andrew H.", ""], ["Isik", "Umut", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2001.11547", "submitter": "Lee Cooper", "authors": "Sanghoon Lee, Mohamed Amgad, Deepak R. Chittajallu, Matt McCormick,\n  Brian P Pollack, Habiba Elfandy, Hagar Hussein, David A Gutman, Lee AD Cooper", "title": "HistomicsML2.0: Fast interactive machine learning for whole slide\n  imaging data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting quantitative phenotypic information from whole-slide images\npresents significant challenges for investigators who are not experienced in\ndeveloping image analysis algorithms. We present new software that enables\nrapid learn-by-example training of machine learning classifiers for detection\nof histologic patterns in whole-slide imaging datasets. HistomicsML2.0 uses\nconvolutional networks to be readily adaptable to a variety of applications,\nprovides a web-based user interface, and is available as a software container\nto simplify deployment.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 20:10:26 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lee", "Sanghoon", ""], ["Amgad", "Mohamed", ""], ["Chittajallu", "Deepak R.", ""], ["McCormick", "Matt", ""], ["Pollack", "Brian P", ""], ["Elfandy", "Habiba", ""], ["Hussein", "Hagar", ""], ["Gutman", "David A", ""], ["Cooper", "Lee AD", ""]]}, {"id": "2001.11568", "submitter": "Edgar Minasyan", "authors": "Elad Hazan and Edgar Minasyan", "title": "Faster Projection-free Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many online learning problems the computational bottleneck for\ngradient-based methods is the projection operation. For this reason, in many\nproblems the most efficient algorithms are based on the Frank-Wolfe method,\nwhich replaces projections by linear optimization. In the general case,\nhowever, online projection-free methods require more iterations than\nprojection-based methods: the best known regret bound scales as $T^{3/4}$.\nDespite significant work on various variants of the Frank-Wolfe method, this\nbound has remained unchanged for a decade. In this paper we give an efficient\nprojection-free algorithm that guarantees $T^{2/3}$ regret for general online\nconvex optimization with smooth cost functions and one linear optimization\ncomputation per iteration. As opposed to previous Frank-Wolfe approaches, our\nalgorithm is derived using the Follow-the-Perturbed-Leader method and is\nanalyzed using an online primal-dual framework.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:18:39 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:36:31 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hazan", "Elad", ""], ["Minasyan", "Edgar", ""]]}, {"id": "2001.11569", "submitter": "Dongrui Wu", "authors": "Xiao Zhang, Dongrui Wu, Lieyun Ding, Hanbin Luo, Chin-Teng Lin,\n  Tzyy-Ping Jung, Ricardo Chavarriaga", "title": "Tiny noise, big mistakes: Adversarial perturbations induce errors in\n  Brain-Computer Interface spellers", "comments": null, "journal-ref": "National Science Review, 2020", "doi": "10.1093/nsr/nwaa233", "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An electroencephalogram (EEG) based brain-computer interface (BCI) speller\nallows a user to input text to a computer by thought. It is particularly useful\nto severely disabled individuals, e.g., amyotrophic lateral sclerosis patients,\nwho have no other effective means of communication with another person or a\ncomputer. Most studies so far focused on making EEG-based BCI spellers faster\nand more reliable; however, few have considered their security. This study, for\nthe first time, shows that P300 and steady-state visual evoked potential BCI\nspellers are very vulnerable, i.e., they can be severely attacked by\nadversarial perturbations, which are too tiny to be noticed when added to EEG\nsignals, but can mislead the spellers to spell anything the attacker wants. The\nconsequence could range from merely user frustration to severe misdiagnosis in\nclinical applications. We hope our research can attract more attention to the\nsecurity of EEG-based BCI spellers, and more broadly, EEG-based BCIs, which has\nreceived little attention before.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:18:46 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 02:58:43 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 15:47:20 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 23:14:34 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Wu", "Dongrui", ""], ["Ding", "Lieyun", ""], ["Luo", "Hanbin", ""], ["Lin", "Chin-Teng", ""], ["Jung", "Tzyy-Ping", ""], ["Chavarriaga", "Ricardo", ""]]}, {"id": "2001.11572", "submitter": "Christos Thrampoulidis", "authors": "Ganesh Kini and Christos Thrampoulidis", "title": "Analytic Study of Double Descent in Binary Classification: The Impact of\n  Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive empirical evidence reveals that, for a wide range of different\nlearning methods and datasets, the risk curve exhibits a double-descent (DD)\ntrend as a function of the model size. In a recent paper\n[Zeyu,Kammoun,Thrampoulidis,2019] the authors studied binary linear\nclassification models and showed that the test error of gradient descent (GD)\nwith logistic loss undergoes a DD. In this paper, we complement these results\nby extending them to GD with square loss. We show that the DD phenomenon\npersists, but we also identify several differences compared to logistic loss.\nThis emphasizes that crucial features of DD curves (such as their transition\nthreshold and global minima) depend both on the training data and on the\nlearning algorithm. We further study the dependence of DD curves on the size of\nthe training set. Similar to our earlier work, our results are analytic: we\nplot the DD curves by first deriving sharp asymptotics for the test error under\nGaussian features. Albeit simple, the models permit a principled study of DD\nfeatures, the outcomes of which theoretically corroborate related empirical\nfindings occurring in more complex learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:29:03 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kini", "Ganesh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2001.11578", "submitter": "Diego Marcondes", "authors": "Diego Marcondes, Adilson Simonis and Junior Barrera", "title": "Learning the Hypotheses Space from data Part II: Convergence and\n  Feasibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In part \\textit{I} we proposed a structure for a general Hypotheses Space\n$\\mathcal{H}$, the Learning Space $\\mathbb{L}(\\mathcal{H})$, which can be\nemployed to avoid \\textit{overfitting} when estimating in a complex space with\nrelative shortage of examples. Also, we presented the U-curve property, which\ncan be taken advantage of in order to select a Hypotheses Space without\nexhaustively searching $\\mathbb{L}(\\mathcal{H})$. In this paper, we carry\nfurther our agenda, by showing the consistency of a model selection framework\nbased on Learning Spaces, in which one selects from data the Hypotheses Space\non which to learn. The method developed in this paper adds to the\nstate-of-the-art in model selection, by extending Vapnik-Chervonenkis Theory to\n\\textit{random} Hypotheses Spaces, i.e., Hypotheses Spaces learned from data.\nIn this framework, one estimates a random subspace $\\hat{\\mathcal{M}} \\in\n\\mathbb{L}(\\mathcal{H})$ which converges with probability one to a target\nHypotheses Space $\\mathcal{M}^{\\star} \\in \\mathbb{L}(\\mathcal{H})$ with desired\nproperties. As the convergence implies asymptotic unbiased estimators, we have\na consistent framework for model selection, showing that it is feasible to\nlearn the Hypotheses Space from data. Furthermore, we show that the\ngeneralization errors of learning on $\\hat{\\mathcal{M}}$ are lesser than those\nwe commit when learning on $\\mathcal{H}$, so it is more efficient to learn on a\nsubspace learned from data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:48:37 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Marcondes", "Diego", ""], ["Simonis", "Adilson", ""], ["Barrera", "Junior", ""]]}, {"id": "2001.11588", "submitter": "Maryam Hasani-Shoreh", "authors": "Maryam Hasani-Shoreh, Renato Hermoza Aragon\\'es, Frank Neumann", "title": "Neural Networks in Evolutionary Dynamic Constrained Optimization:\n  Computational Cost and Benefits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) have been recently applied together with evolutionary\nalgorithms (EAs) to solve dynamic optimization problems. The applied NN\nestimates the position of the next optimum based on the previous time best\nsolutions. After detecting a change, the predicted solution can be employed to\nmove the EA's population to a promising region of the solution space in order\nto accelerate convergence and improve accuracy in tracking the optimum. While\nprevious works show improvement of the results, they neglect the overhead\ncreated by NN. In this work, we reflect the time spent on training NN in the\noptimization time and compare the results with a baseline EA. We explore if by\nconsidering the generated overhead, NN is still able to improve the results,\nand under which condition is able to do so.\n  The main difficulties to train the NN are: 1) to get enough samples to\ngeneralize predictions for new data, and 2) to obtain reliable samples. As NN\nneeds to collect data at each time step, if the time horizon is short, we will\nnot be able to collect enough samples to train the NN. To alleviate this, we\npropose to consider more individuals on each change to speed up sample\ncollection in shorter time steps. In environments with a high frequency of\nchanges, the solutions produced by EA are likely to be far from the real\noptimum. Using unreliable train data for the NN will, in consequence, produce\nunreliable predictions. Also, as the time spent for NN stays fixed regardless\nof the frequency, a higher frequency of change will mean a higher produced\noverhead by the NN in proportion to the EA. In general, after considering the\ngenerated overhead, we conclude that NN is not suitable in environments with a\nhigh frequency of changes and/or short time horizons. However, it can be\npromising for the low frequency of changes, and especially for the environments\nthat changes have a pattern.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 12:17:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hasani-Shoreh", "Maryam", ""], ["Aragon\u00e9s", "Renato Hermoza", ""], ["Neumann", "Frank", ""]]}, {"id": "2001.11595", "submitter": "Matteo Pirotta", "authors": "Jian Qian, Ronan Fruit, Matteo Pirotta, Alessandro Lazaric", "title": "Concentration Inequalities for Multinoulli Random Variables", "comments": "Tutorial at ALT'19 on Regret Minimization in Infinite-Horizon Finite\n  Markov Decision Processes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate concentration inequalities for Dirichlet and Multinomial\nrandom variables.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 22:44:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Qian", "Jian", ""], ["Fruit", "Ronan", ""], ["Pirotta", "Matteo", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2001.11612", "submitter": "Jindong Gu", "authors": "Jindong Gu, Volker Tresp", "title": "Search for Better Students to Learn Distilled Knowledge", "comments": null, "journal-ref": "24th European Conference on Artificial Intelligence (ECAI), 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation, as a model compression technique, has received great\nattention. The knowledge of a well-performed teacher is distilled to a student\nwith a small architecture. The architecture of the small student is often\nchosen to be similar to their teacher's, with fewer layers or fewer channels,\nor both. However, even with the same number of FLOPs or parameters, the\nstudents with different architecture can achieve different generalization\nability. The configuration of a student architecture requires intensive network\narchitecture engineering. In this work, instead of designing a good student\narchitecture manually, we propose to search for the optimal student\nautomatically. Based on L1-norm optimization, a subgraph from the teacher\nnetwork topology graph is selected as a student, the goal of which is to\nminimize the KL-divergence between student's and teacher's outputs. We verify\nthe proposal on CIFAR10 and CIFAR100 datasets. The empirical experiments show\nthat the learned student architecture achieves better performance than ones\nspecified manually. We also visualize and understand the architecture of the\nfound student.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 23:55:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Gu", "Jindong", ""], ["Tresp", "Volker", ""]]}, {"id": "2001.11628", "submitter": "Ryo Okumura", "authors": "Ryo Okumura, Masashi Okada and Tadahiro Taniguchi", "title": "Domain-Adversarial and Conditional State Space Model for Imitation\n  Learning", "comments": "Published at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State representation learning (SRL) in partially observable Markov decision\nprocesses has been studied to learn abstract features of data useful for robot\ncontrol tasks. For SRL, acquiring domain-agnostic states is essential for\nachieving efficient imitation learning. Without these states, imitation\nlearning is hampered by domain-dependent information useless for control.\nHowever, existing methods fail to remove such disturbances from the states when\nthe data from experts and agents show large domain shifts. To overcome this\nissue, we propose a domain-adversarial and conditional state space model\n(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and\ndynamics-aware states. DAC-SSM jointly optimizes the state inference,\nobservation reconstruction, forward dynamics, and reward models. To remove\ndomain-dependent information from the states, the model is trained with domain\ndiscriminators in an adversarial manner, and the reconstruction is conditioned\non domain labels. We experimentally evaluated the model predictive control\nperformance via imitation learning for continuous control of sparse reward\ntasks in simulators and compared it with the performance of the existing SRL\nmethod. The agents from DAC-SSM achieved performance comparable to experts and\nmore than twice the baselines. We conclude domain-agnostic states are essential\nfor imitation learning that has large domain shifts and can be obtained using\nDAC-SSM.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:39:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 06:51:25 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Okumura", "Ryo", ""], ["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2001.11631", "submitter": "Md Rashadul Hasan Rakib", "authors": "Md Rashadul Hasan Rakib, Norbert Zeh, Magdalena Jankowska, Evangelos\n  Milios", "title": "Enhancement of Short Text Clustering by Iterative Classification", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text clustering is a challenging task due to the lack of signal\ncontained in such short texts. In this work, we propose iterative\nclassification as a method to b o ost the clustering quality (e.g., accuracy)\nof short texts. Given a clustering of short texts obtained using an arbitrary\nclustering algorithm, iterative classification applies outlier removal to\nobtain outlier-free clusters. Then it trains a classification algorithm using\nthe non-outliers based on their cluster distributions. Using the trained\nclassification model, iterative classification reclassifies the outliers to\nobtain a new set of clusters. By repeating this several times, we obtain a much\nimproved clustering of texts. Our experimental results show that the proposed\nclustering enhancement method not only improves the clustering quality of\ndifferent clustering methods (e.g., k-means, k-means--, and hierarchical\nclustering) but also outperforms the state-of-the-art short text clustering\nmethods on several short text datasets by a statistically significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 02:12:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Rakib", "Md Rashadul Hasan", ""], ["Zeh", "Norbert", ""], ["Jankowska", "Magdalena", ""], ["Milios", "Evangelos", ""]]}, {"id": "2001.11643", "submitter": "Shabnam Rezaei", "authors": "Shabnam Rezaei and Sofiene Affes", "title": "ANN-Based Detection in MIMO-OFDM Systems with Low-Resolution ADCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-layer artificial neural network (ANN) that\nis trained with the Levenberg-Marquardt algorithm for use in signal detection\nover multiple-input multiple-output orthogonal frequency-division multiplexing\n(MIMO-OFDM) systems, particularly those with low-resolution analog-to-digital\nconverters (LR-ADCs). We consider a blind detection scheme where data symbol\nestimation is carried out without knowing the channel state information at the\nreceiver (CSIR)---in contrast to classical algorithms. The main power of the\nproposed ANN-based detector (ANND) lies in its versatile use with any\nmodulation scheme, blindly, yet without a change in its structure. We compare\nby simulations this new receiver with conventional ones, namely, the maximum\nlikelihood (ML), minimum mean square error (MMSE), and zero-forcing (ZF), in\nterms of symbol error rate (SER) performance. Results suggest that ANND\napproaches ML at much lower complexity, outperforms ZF over the entire range of\nassessed signal-to-noise ratio (SNR) values, and so does it also, though, with\nthe MMSE over different SNR ranges.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:38:42 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Rezaei", "Shabnam", ""], ["Affes", "Sofiene", ""]]}, {"id": "2001.11651", "submitter": "Yuguang Wang", "authors": "Kai Yi, Yi Guo, Yanan Fan, Jan Hamann, Yu Guang Wang", "title": "CosmoVAE: Variational Autoencoder for CMB Image Inpainting", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cosmic microwave background radiation (CMB) is critical to the understanding\nof the early universe and precise estimation of cosmological constants. Due to\nthe contamination of thermal dust noise in the galaxy, the CMB map that is an\nimage on the two-dimensional sphere has missing observations, mainly\nconcentrated on the equatorial region. The noise of the CMB map has a\nsignificant impact on the estimation precision for cosmological parameters.\nInpainting the CMB map can effectively reduce the uncertainty of parametric\nestimation. In this paper, we propose a deep learning-based variational\nautoencoder --- CosmoVAE, to restoring the missing observations of the CMB map.\nThe input and output of CosmoVAE are square images. To generate training,\nvalidation, and test data sets, we segment the full-sky CMB map into many small\nimages by Cartesian projection. CosmoVAE assigns physical quantities to the\nparameters of the VAE network by using the angular power spectrum of the\nGaussian random field as latent variables. CosmoVAE adopts a new loss function\nto improve the learning performance of the model, which consists of $\\ell_1$\nreconstruction loss, Kullback-Leibler divergence between the posterior\ndistribution of encoder network and the prior distribution of latent variables,\nperceptual loss, and total-variation regularizer. The proposed model achieves\nstate of the art performance for Planck \\texttt{Commander} 2018 CMB map\ninpainting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:54:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Yi", "Kai", ""], ["Guo", "Yi", ""], ["Fan", "Yanan", ""], ["Hamann", "Jan", ""], ["Wang", "Yu Guang", ""]]}, {"id": "2001.11653", "submitter": "Yuguang Wang", "authors": "Nicole Hallett, Kai Yi, Josef Dick, Christopher Hodge, Gerard Sutton,\n  Yu Guang Wang, Jingjing You", "title": "Deep Learning Based Unsupervised and Semi-supervised Classification for\n  Keratoconus", "comments": "7 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transparent cornea is the window of the eye, facilitating the entry of\nlight rays and controlling focusing the movement of the light within the eye.\nThe cornea is critical, contributing to 75% of the refractive power of the eye.\nKeratoconus is a progressive and multifactorial corneal degenerative disease\naffecting 1 in 2000 individuals worldwide. Currently, there is no cure for\nkeratoconus other than corneal transplantation for advanced stage keratoconus\nor corneal cross-linking, which can only halt KC progression. The ability to\naccurately identify subtle KC or KC progression is of vital clinical\nsignificance. To date, there has been little consensus on a useful model to\nclassify KC patients, which therefore inhibits the ability to predict disease\nprogression accurately.\n  In this paper, we utilised machine learning to analyse data from 124 KC\npatients, including topographical and clinical variables. Both supervised\nmultilayer perceptron and unsupervised variational autoencoder models were used\nto classify KC patients with reference to the existing Amsler-Krumeich (A-K)\nclassification system. Both methods result in high accuracy, with the\nunsupervised method showing better performance. The result showed that the\nunsupervised method with a selection of 29 variables could be a powerful tool\nto provide an automatic classification tool for clinicians. These outcomes\nprovide a platform for additional analysis for the progression and treatment of\nkeratoconus.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:56:12 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hallett", "Nicole", ""], ["Yi", "Kai", ""], ["Dick", "Josef", ""], ["Hodge", "Christopher", ""], ["Sutton", "Gerard", ""], ["Wang", "Yu Guang", ""], ["You", "Jingjing", ""]]}, {"id": "2001.11659", "submitter": "Ben Letham", "authors": "Benjamin Letham, Roberto Calandra, Akshara Rai, Eytan Bakshy", "title": "Re-Examining Linear Embeddings for High-Dimensional Bayesian\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular approach to optimize\nexpensive-to-evaluate black-box functions. A significant challenge in BO is to\nscale to high-dimensional parameter spaces while retaining sample efficiency. A\nsolution considered in existing literature is to embed the high-dimensional\nspace in a lower-dimensional manifold, often via a random linear embedding. In\nthis paper, we identify several crucial issues and misconceptions about the use\nof linear embeddings for BO. We study the properties of linear embeddings from\nthe literature and show that some of the design choices in current approaches\nadversely impact their performance. We show empirically that properly\naddressing these issues significantly improves the efficacy of linear\nembeddings for BO on a range of problems, including learning a gait policy for\nrobot locomotion.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:02:34 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 18:30:08 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Letham", "Benjamin", ""], ["Calandra", "Roberto", ""], ["Rai", "Akshara", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2001.11668", "submitter": "Dan Garber", "authors": "Dan Garber", "title": "On the Convergence of Stochastic Gradient Descent with Low-Rank\n  Projections for Convex Low-Rank Matrix Problems", "comments": "Accepted to Conference on Learning Theory 2020 (COLT 2020). This\n  version fixes some minor errors in previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the use of Stochastic Gradient Descent (SGD) for solving convex\noptimization problems that serve as highly popular convex relaxations for many\nimportant low-rank matrix recovery problems such as \\textit{matrix completion},\n\\textit{phase retrieval}, and more. The computational limitation of applying\nSGD to solving these relaxations in large-scale is the need to compute a\npotentially high-rank singular value decomposition (SVD) on each iteration in\norder to enforce the low-rank-promoting constraint. We begin by considering a\nsimple and natural sufficient condition so that these relaxations indeed admit\nlow-rank solutions. This condition is also necessary for a certain notion of\nlow-rank-robustness to hold. Our main result shows that under this condition\nwhich involves the eigenvalues of the gradient vector at optimal points, SGD\nwith mini-batches, when initialized with a \"warm-start\" point, produces\niterates that are low-rank with high probability, and hence only a low-rank SVD\ncomputation is required on each iteration. This suggests that SGD may indeed be\npractically applicable to solving large-scale convex relaxations of low-rank\nmatrix recovery problems. Our theoretical results are accompanied with\nsupporting preliminary empirical evidence. As a side benefit, our analysis is\nquite simple and short.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 06:00:34 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 14:26:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Garber", "Dan", ""]]}, {"id": "2001.11673", "submitter": "Mehrdad Alizadeh", "authors": "Mehrdad Alizadeh, Barbara Di Eugenio", "title": "Augmenting Visual Question Answering with Semantic Frame Information in\n  a Multitask Learning Approach", "comments": "14th IEEE International Conference on SEMANTIC COMPUTING, 8 Pages,\n  February 2020, San Diego CA USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual Question Answering (VQA) concerns providing answers to Natural\nLanguage questions about images. Several deep neural network approaches have\nbeen proposed to model the task in an end-to-end fashion. Whereas the task is\ngrounded in visual processing, if the question focuses on events described by\nverbs, the language understanding component becomes crucial. Our hypothesis is\nthat models should be aware of verb semantics, as expressed via semantic role\nlabels, argument types, and/or frame elements. Unfortunately, no VQA dataset\nexists that includes verb semantic information. Our first contribution is a new\nVQA dataset (imSituVQA) that we built by taking advantage of the imSitu\nannotations. The imSitu dataset consists of images manually labeled with\nsemantic frame elements, mostly taken from FrameNet. Second, we propose a\nmultitask CNN-LSTM VQA model that learns to classify the answers as well as the\nsemantic frame elements. Our experiments show that semantic frame element\nclassification helps the VQA system avoid inconsistent responses and improves\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 06:31:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Alizadeh", "Mehrdad", ""], ["Di Eugenio", "Barbara", ""]]}, {"id": "2001.11688", "submitter": "Jee-Weon Jung", "authors": "Jee-weon Jung, Hye-jin Shim, Hee-Soo Heo, Ha-Jin Yu", "title": "A study on the role of subsidiary information in replay attack spoofing\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we analyze the role of various categories of subsidiary\ninformation in conducting replay attack spoofing detection: `Room Size',\n`Reverberation', `Speaker-to-ASV distance, `Attacker-to-Speaker distance', and\n`Replay Device Quality'. As a means of analyzing subsidiary information, we use\ntwo frameworks to either subtract or include a category of subsidiary\ninformation to the code extracted from a deep neural network. For subtraction,\nwe utilize an adversarial process framework which makes the code orthogonal to\nthe basis vectors of the subsidiary information. For addition, we utilize the\nmulti-task learning framework to include subsidiary information to the code.\nAll experiments are conducted using the ASVspoof 2019 physical access scenario\nwith the provided meta data. Through the analysis of the result of the two\napproaches, we conclude that various categories of subsidiary information does\nnot reside enough in the code when the deep neural network is trained for\nbinary classification. Explicitly including various categories of subsidiary\ninformation through the multi-task learning framework can help improve\nperformance in closed set condition.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:45:03 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Jung", "Jee-weon", ""], ["Shim", "Hye-jin", ""], ["Heo", "Hee-Soo", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "2001.11691", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, Ming Zhou", "title": "Self-Adversarial Learning with Comparative Discrimination for Text\n  Generation", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Generative Adversarial Networks (GANs) for text generation tend\nto have issues of reward sparsity and mode collapse that affect the quality and\ndiversity of generated samples. To address the issues, we propose a novel\nself-adversarial learning (SAL) paradigm for improving GANs' performance in\ntext generation. In contrast to standard GANs that use a binary classifier as\nits discriminator to predict whether a sample is real or generated, SAL employs\na comparative discriminator which is a pairwise classifier for comparing the\ntext quality between a pair of samples. During training, SAL rewards the\ngenerator when its currently generated sentence is found to be better than its\npreviously generated samples. This self-improvement reward mechanism allows the\nmodel to receive credits more easily and avoid collapsing towards the limited\nnumber of real samples, which not only helps alleviate the reward sparsity\nissue but also reduces the risk of mode collapse. Experiments on text\ngeneration benchmark datasets show that our proposed approach substantially\nimproves both the quality and the diversity, and yields more stable performance\ncompared to the previous GANs for text generation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:50:25 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:18:24 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Xu", "Ke", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "2001.11692", "submitter": "Xinyan Dai", "authors": "Xinyan Dai, Xiao Yan, Kaiwen Zhou, Yuxuan Wang, Han Yang, James Cheng", "title": "Convolutional Embedding for Edit Distance", "comments": "Accepted by the 43rd International ACM SIGIR Conference on Research\n  and Development in Information Retrieval, 2020", "journal-ref": null, "doi": "10.1145/3397271.3401045", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edit-distance-based string similarity search has many applications such as\nspell correction, data de-duplication, and sequence alignment. However,\ncomputing edit distance is known to have high complexity, which makes string\nsimilarity search challenging for large datasets. In this paper, we propose a\ndeep learning pipeline (called CNN-ED) that embeds edit distance into Euclidean\ndistance for fast approximate similarity search. A convolutional neural network\n(CNN) is used to generate fixed-length vector embeddings for a dataset of\nstrings and the loss function is a combination of the triplet loss and the\napproximation error. To justify our choice of using CNN instead of other\nstructures (e.g., RNN) as the model, theoretical analysis is conducted to show\nthat some basic operations in our CNN model preserve edit distance.\nExperimental results show that CNN-ED outperforms data-independent CGK\nembedding and RNN-based GRU embedding in terms of both accuracy and efficiency\nby a large margin. We also show that string similarity search can be\nsignificantly accelerated using CNN-based embeddings, sometimes by orders of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:53:10 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 02:38:26 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 06:27:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Dai", "Xinyan", ""], ["Yan", "Xiao", ""], ["Zhou", "Kaiwen", ""], ["Wang", "Yuxuan", ""], ["Yang", "Han", ""], ["Cheng", "James", ""]]}, {"id": "2001.11694", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu", "title": "Pseudo-Bidirectional Decoding for Local Sequence Transduction", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local sequence transduction (LST) tasks are sequence transduction tasks where\nthere exists massive overlapping between the source and target sequences, such\nas Grammatical Error Correction (GEC) and spell or OCR correction. Previous\nwork generally tackles LST tasks with standard sequence-to-sequence (seq2seq)\nmodels that generate output tokens from left to right and suffer from the issue\nof unbalanced outputs. Motivated by the characteristic of LST tasks, in this\npaper, we propose a simple but versatile approach named Pseudo-Bidirectional\nDecoding (PBD) for LST tasks. PBD copies the corresponding representation of\nsource tokens to the decoder as pseudo future context to enable the decoder to\nattends to its bi-directional context. In addition, the bidirectional decoding\nscheme and the characteristic of LST tasks motivate us to share the encoder and\nthe decoder of seq2seq models. The proposed PBD approach provides right side\ncontext information for the decoder and models the inductive bias of LST tasks,\nreducing the number of parameters by half and providing good regularization\neffects. Experimental results on several benchmark datasets show that our\napproach consistently improves the performance of standard seq2seq models on\nLST tasks.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:55:39 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 14:28:41 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 16:01:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Xu", "Ke", ""]]}, {"id": "2001.11704", "submitter": "Shay Moran", "authors": "Noga Alon and Alon Gonen and Elad Hazan and Shay Moran", "title": "Boosting Simple Learners", "comments": "A minor revision according to STOC reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a celebrated machine learning approach which is based on the idea\nof combining weak and moderately inaccurate hypotheses to a strong and accurate\none. We study boosting under the assumption that the weak hypotheses belong to\na class of bounded capacity. This assumption is inspired by the common\nconvention that weak hypotheses are \"rules-of-thumbs\" from an \"easy-to-learn\nclass\". (Schapire and Freund '12, Shalev-Shwartz and Ben-David '14.) Formally,\nwe assume the class of weak hypotheses has a bounded VC dimension. We focus on\ntwo main questions: (i) Oracle Complexity: How many weak hypotheses are needed\nin order to produce an accurate hypothesis? We design a novel boosting\nalgorithm and demonstrate that it circumvents a classical lower bound by Freund\nand Schapire ('95, '12). Whereas the lower bound shows that\n$\\Omega({1}/{\\gamma^2})$ weak hypotheses with $\\gamma$-margin are sometimes\nnecessary, our new method requires only $\\tilde{O}({1}/{\\gamma})$ weak\nhypothesis, provided that they belong to a class of bounded VC dimension.\nUnlike previous boosting algorithms which aggregate the weak hypotheses by\nmajority votes, the new boosting algorithm uses more complex (\"deeper\")\naggregation rules. We complement this result by showing that complex\naggregation rules are in fact necessary to circumvent the aforementioned lower\nbound. (ii) Expressivity: Which tasks can be learned by boosting weak\nhypotheses from a bounded VC class? Can complex concepts that are \"far away\"\nfrom the class be learned? Towards answering the first question we identify a\ncombinatorial-geometric parameter which captures the expressivity of\nbase-classes in boosting. As a corollary we provide an affirmative answer to\nthe second question for many well-studied classes, including half-spaces and\ndecision stumps. Along the way, we establish and exploit connections with\nDiscrepancy Theory.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:34:56 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 04:37:17 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 07:10:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Alon", "Noga", ""], ["Gonen", "Alon", ""], ["Hazan", "Elad", ""], ["Moran", "Shay", ""]]}, {"id": "2001.11708", "submitter": "Liang Liao", "authors": "Liang Liao and Stephen John Maybank", "title": "Generalized Visual Information Analysis via Tensorial Algebra", "comments": "42 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.AC math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher order data is modeled using matrices whose entries are numerical\narrays of a fixed size. These arrays, called t-scalars, form a commutative ring\nunder the convolution product. Matrices with elements in the ring of t-scalars\nare referred to as t-matrices. The t-matrices can be scaled, added and\nmultiplied in the usual way. There are t-matrix generalizations of positive\nmatrices, orthogonal matrices and Hermitian symmetric matrices. With the\nt-matrix model, it is possible to generalize many well-known matrix algorithms.\nIn particular, the t-matrices are used to generalize the SVD (Singular Value\nDecomposition), HOSVD (High Order SVD), PCA (Principal Component Analysis),\n2DPCA (Two Dimensional PCA) and GCA (Grassmannian Component Analysis). The\ngeneralized t-matrix algorithms, namely TSVD, THOSVD,TPCA, T2DPCA and TGCA, are\napplied to low-rank approximation, reconstruction,and supervised classification\nof images. Experiments show that the t-matrix algorithms compare favorably with\nstandard matrix algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:47:35 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 10:58:56 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Liao", "Liang", ""], ["Maybank", "Stephen John", ""]]}, {"id": "2001.11713", "submitter": "Ruoxuan Xiong", "authors": "Kun Kuang, Ruoxuan Xiong, Peng Cui, Susan Athey, Bo Li", "title": "Stable Prediction with Model Misspecification and Agnostic Distribution\n  Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many machine learning algorithms, two main assumptions are required to\nguarantee performance. One is that the test data are drawn from the same\ndistribution as the training data, and the other is that the model is correctly\nspecified. In real applications, however, we often have little prior knowledge\non the test data and on the underlying true model. Under model\nmisspecification, agnostic distribution shift between training and test data\nleads to inaccuracy of parameter estimation and instability of prediction\nacross unknown test data. To address these problems, we propose a novel\nDecorrelated Weighting Regression (DWR) algorithm which jointly optimizes a\nvariable decorrelation regularizer and a weighted regression model. The\nvariable decorrelation regularizer estimates a weight for each sample such that\nvariables are decorrelated on the weighted training data. Then, these weights\nare used in the weighted regression to improve the accuracy of estimation on\nthe effect of each variable, thus help to improve the stability of prediction\nacross unknown test data. Extensive experiments clearly demonstrate that our\nDWR algorithm can significantly improve the accuracy of parameter estimation\nand stability of prediction with model misspecification and agnostic\ndistribution shift.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:56:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kuang", "Kun", ""], ["Xiong", "Ruoxuan", ""], ["Cui", "Peng", ""], ["Athey", "Susan", ""], ["Li", "Bo", ""]]}, {"id": "2001.11715", "submitter": "Zhibo Liu", "authors": "Zhibo Liu, Feng Gao, Yizhou Wang", "title": "A Generative Adversarial Network for AI-Aided Chair Design", "comments": "6 pages, 5 figures, accepted at MIPR2019", "journal-ref": null, "doi": "10.1109/MIPR.2019.00098", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for improving human design of chairs. The goal of the\nmethod is generating enormous chair candidates in order to facilitate human\ndesigner by creating sketches and 3d models accordingly based on the generated\nchair design. It consists of an image synthesis module, which learns the\nunderlying distribution of training dataset, a super-resolution module, which\nimprove quality of generated image and human involvements. Finally, we manually\npick one of the generated candidates to create a real life chair for\nillustration.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 08:57:32 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Liu", "Zhibo", ""], ["Gao", "Feng", ""], ["Wang", "Yizhou", ""]]}, {"id": "2001.11716", "submitter": "Jia Peng", "authors": "Peng Jia, Xiyu Li, Zhengyang Li, Weinan Wang, Dongmei Cai", "title": "Point Spread Function Modelling for Wide Field Small Aperture Telescopes\n  with a Denoising Autoencoder", "comments": "10 pages, 10 figures, Published by MNRAS", "journal-ref": null, "doi": "10.1093/mnras/staa319", "report-no": null, "categories": "astro-ph.IM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point spread function reflects the state of an optical telescope and it\nis important for data post-processing methods design. For wide field small\naperture telescopes, the point spread function is hard to model, because it is\naffected by many different effects and has strong temporal and spatial\nvariations. In this paper, we propose to use the denoising autoencoder, a type\nof deep neural network, to model the point spread function of wide field small\naperture telescopes. The denoising autoencoder is a pure data based point\nspread function modelling method, which uses calibration data from real\nobservations or numerical simulated results as point spread function templates.\nAccording to real observation conditions, different levels of random noise or\naberrations are added to point spread function templates, making them as\nrealizations of the point spread function, i.e., simulated star images. Then we\ntrain the denoising autoencoder with realizations and templates of the point\nspread function. After training, the denoising autoencoder learns the manifold\nspace of the point spread function and can map any star images obtained by wide\nfield small aperture telescopes directly to its point spread function, which\ncould be used to design data post-processing or optical system alignment\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:00:08 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 13:23:35 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Jia", "Peng", ""], ["Li", "Xiyu", ""], ["Li", "Zhengyang", ""], ["Wang", "Weinan", ""], ["Cai", "Dongmei", ""]]}, {"id": "2001.11718", "submitter": "Tsubasa Takahashi", "authors": "Hajime Ono and Tsubasa Takahashi", "title": "Locally Private Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study locally differentially private algorithms for reinforcement learning\nto obtain a robust policy that performs well across distributed private\nenvironments. Our algorithm protects the information of local agents' models\nfrom being exploited by adversarial reverse engineering. Since a local policy\nis strongly being affected by the individual environment, the output of the\nagent may release the private information unconsciously. In our proposed\nalgorithm, local agents update the model in their environments and report noisy\ngradients designed to satisfy local differential privacy (LDP) that gives a\nrigorous local privacy guarantee. By utilizing a set of reported noisy\ngradients, a central aggregator updates its model and delivers it to different\nlocal agents. In our empirical evaluation, we demonstrate how our method\nperforms well under LDP. To the best of our knowledge, this is the first work\nthat actualizes distributed reinforcement learning under LDP. This work enables\nus to obtain a robust agent that performs well across distributed private\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:03:23 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ono", "Hajime", ""], ["Takahashi", "Tsubasa", ""]]}, {"id": "2001.11739", "submitter": "Jonathan Bac", "authors": "Jonathan Bac, Andrei Zinovyev", "title": "Local intrinsic dimensionality estimators based on concentration of\n  measure", "comments": "to be published in the International Joint Conference On Neural\n  Networks (IJCNN) held as part of the IEEE World Congress On Computational\n  Intelligence (WCCI), July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic dimensionality (ID) is one of the most fundamental characteristics\nof multi-dimensional data point clouds. Knowing ID is crucial to choose the\nappropriate machine learning approach as well as to understand its behavior and\nvalidate it. ID can be computed globally for the whole data point distribution,\nor computed locally in different regions of the data space. In this paper, we\nintroduce new local estimators of ID based on linear separability of\nmulti-dimensional data point clouds, which is one of the manifestations of\nconcentration of measure. We empirically study the properties of these\nestimators and compare them with other recently introduced ID estimators\nexploiting various effects of measure concentration. Observed differences\nbetween estimators can be used to anticipate their behaviour in practical\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:49:09 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 15:41:08 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 10:54:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bac", "Jonathan", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "2001.11757", "submitter": "Giorgio Visani Mr", "authors": "Giorgio Visani, Enrico Bagli, Federico Chesani, Alessandro Poluzzi and\n  Davide Capuzzo", "title": "Statistical stability indices for LIME: obtaining reliable explanations\n  for Machine Learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays we are witnessing a transformation of the business processes towards\na more computation driven approach. The ever increasing usage of Machine\nLearning techniques is the clearest example of such trend.\n  This sort of revolution is often providing advantages, such as an increase in\nprediction accuracy and a reduced time to obtain the results. However, these\nmethods present a major drawback: it is very difficult to understand on what\ngrounds the algorithm took the decision.\n  To address this issue we consider the LIME method. We give a general\nbackground on LIME then, we focus on the stability issue: employing the method\nrepeated times, under the same conditions, may yield to different explanations.\n  Two complementary indices are proposed, to measure LIME stability. It is\nimportant for the practitioner to be aware of the issue, as well as to have a\ntool for spotting it. Stability guarantees LIME explanations to be reliable,\ntherefore a stability assessment, made through the proposed indices, is\ncrucial.\n  As a case study, we apply both Machine Learning and classical statistical\ntechniques to Credit Risk data. We test LIME on the Machine Learning algorithm\nand check its stability. Eventually, we examine the goodness of the\nexplanations returned.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:39:46 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 09:30:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Visani", "Giorgio", ""], ["Bagli", "Enrico", ""], ["Chesani", "Federico", ""], ["Poluzzi", "Alessandro", ""], ["Capuzzo", "Davide", ""]]}, {"id": "2001.11760", "submitter": "Prashant Singh", "authors": "Mattias {\\AA}kesson, Prashant Singh, Fredrik Wrede, Andreas Hellander", "title": "Convolutional Neural Networks as Summary Statistics for Approximate\n  Bayesian Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation is widely used in systems biology for\ninferring parameters in stochastic gene regulatory network models. Its\nperformance hinges critically on the ability to summarize high-dimensional\nsystem responses such as time series into a few informative, low-dimensional\nsummary statistics. The quality of those statistics acutely impacts the\naccuracy of the inference task. Existing methods to select the best subset out\nof a pool of candidate statistics do not scale well with large pools of several\ntens to hundreds of candidate statistics. Since high quality statistics are\nimperative for good performance, this becomes a serious bottleneck when\nperforming inference on complex and high-dimensional problems. This paper\nproposes a convolutional neural network architecture for automatically learning\ninformative summary statistics of temporal responses. We show that the proposed\nnetwork can effectively circumvent the statistics selection problem of the\npreprocessing step for ABC inference. The proposed approach is demonstrated on\ntwo benchmark problem and one challenging inference problem learning parameters\nin a high-dimensional stochastic genetic oscillator. We also study the impact\nof experimental design on network performance by comparing different data\nrichness and data acquisition strategies.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:46:30 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:07:49 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 22:24:44 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 11:59:18 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 10:23:42 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["\u00c5kesson", "Mattias", ""], ["Singh", "Prashant", ""], ["Wrede", "Fredrik", ""], ["Hellander", "Andreas", ""]]}, {"id": "2001.11767", "submitter": "Johannes Hofmanninger", "authors": "Johannes Hofmanninger, Florian Prayer, Jeanny Pan, Sebastian Rohrich,\n  Helmut Prosch and Georg Langs", "title": "Automatic lung segmentation in routine imaging is primarily a data\n  diversity problem, not a methodology problem", "comments": "10 pages, 5 figures, 5 tables", "journal-ref": "Eur Radiol Exp 4, 50 (2020)", "doi": "10.1186/s41747-020-00173-2", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated segmentation of anatomical structures is a crucial step in image\nanalysis. For lung segmentation in computed tomography, a variety of approaches\nexist, involving sophisticated pipelines trained and validated on different\ndatasets. However, the clinical applicability of these approaches across\ndiseases remains limited. We compared four generic deep learning approaches\ntrained on various datasets and two readily available lung segmentation\nalgorithms. We performed evaluation on routine imaging data with more than six\ndifferent disease patterns and three published data sets. Using different deep\nlearning approaches, mean Dice similarity coefficients (DSCs) on test datasets\nvaried not over 0.02. When trained on a diverse routine dataset (n = 36) a\nstandard approach (U-net) yields a higher DSC (0.97 $\\pm$ 0.05) compared to\ntraining on public datasets such as Lung Tissue Research Consortium (0.94 $\\pm$\n0.13, p = 0.024) or Anatomy 3 (0.92 $\\pm$ 0.15, p = 0.001). Trained on routine\ndata (n = 231) covering multiple diseases, U-net compared to reference methods\nyields a DSC of 0.98 $\\pm$ 0.03 versus 0.94 $\\pm$ 0.12 (p = 0.024).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:01:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:02:26 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Hofmanninger", "Johannes", ""], ["Prayer", "Florian", ""], ["Pan", "Jeanny", ""], ["Rohrich", "Sebastian", ""], ["Prosch", "Helmut", ""], ["Langs", "Georg", ""]]}, {"id": "2001.11771", "submitter": "Antonio Carta", "authors": "Antonio Carta, Alessandro Sperduti, Davide Bacciu", "title": "Encoding-based Memory Modules for Recurrent Neural Networks", "comments": "preprint submitted at Elsevier Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to solve sequential tasks with recurrent models requires the ability\nto memorize long sequences and to extract task-relevant features from them. In\nthis paper, we study the memorization subtask from the point of view of the\ndesign and training of recurrent neural networks. We propose a new model, the\nLinear Memory Network, which features an encoding-based memorization component\nbuilt with a linear autoencoder for sequences. We extend the memorization\ncomponent with a modular memory that encodes the hidden state sequence at\ndifferent sampling frequencies. Additionally, we provide a specialized training\nalgorithm that initializes the memory to efficiently encode the hidden\nactivations of the network. The experimental results on synthetic and\nreal-world datasets show that specializing the training algorithm to train the\nmemorization component always improves the final performance whenever the\nmemorization of long sequences is necessary to solve the problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:14:27 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Carta", "Antonio", ""], ["Sperduti", "Alessandro", ""], ["Bacciu", "Davide", ""]]}, {"id": "2001.11775", "submitter": "Hye Won Chung", "authors": "Daesung Kim and Hye Won Chung", "title": "Binary Classification with XOR Queries: Fundamental Limits and An\n  Efficient Algorithm", "comments": "Accepted to IEEE Transactions on Information Theory. 37 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a query-based data acquisition problem for binary classification\nof unknown labels, which has diverse applications in communications,\ncrowdsourcing, recommender systems and active learning. To ensure reliable\nrecovery of unknown labels with as few number of queries as possible, we\nconsider an effective query type that asks \"group attribute\" of a chosen subset\nof objects. In particular, we consider the problem of classifying $m$ binary\nlabels with XOR queries that ask whether the number of objects having a given\nattribute in the chosen subset of size $d$ is even or odd. The subset size $d$,\nwhich we call query degree, can be varying over queries. We consider a general\nnoise model where the accuracy of answers on queries changes depending both on\nthe worker (the data provider) and query degree $d$. For this general model, we\ncharacterize the information-theoretic limit on the optimal number of queries\nto reliably recover $m$ labels in terms of a given combination of degree-$d$\nqueries and noise parameters. Further, we propose an efficient inference\nalgorithm that achieves this limit even when the noise parameters are unknown.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:23:02 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 05:39:42 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Kim", "Daesung", ""], ["Chung", "Hye Won", ""]]}, {"id": "2001.11786", "submitter": "Shuaiqiang Liu", "authors": "Shuaiqiang Liu, \\'Alvaro Leitao, Anastasia Borovykh, Cornelis W.\n  Oosterlee", "title": "On Calibration Neural Networks for extracting implied information from\n  American options", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting implied information, like volatility and/or dividend, from\nobserved option prices is a challenging task when dealing with American\noptions, because of the computational costs needed to solve the corresponding\nmathematical problem many thousands of times. We will employ a data-driven\nmachine learning approach to estimate the Black-Scholes implied volatility and\nthe dividend yield for American options in a fast and robust way. To determine\nthe implied volatility, the inverse function is approximated by an artificial\nneural network on the computational domain of interest, which decouples the\noffline (training) and online (prediction) phases and thus eliminates the need\nfor an iterative process. For the implied dividend yield, we formulate the\ninverse problem as a calibration problem and determine simultaneously the\nimplied volatility and dividend yield. For this, a generic and robust\ncalibration framework, the Calibration Neural Network (CaNN), is introduced to\nestimate multiple parameters. It is shown that machine learning can be used as\nan efficient numerical technique to extract implied information from American\noptions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:10:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Liu", "Shuaiqiang", ""], ["Leitao", "\u00c1lvaro", ""], ["Borovykh", "Anastasia", ""], ["Oosterlee", "Cornelis W.", ""]]}, {"id": "2001.11801", "submitter": "Allard Hendriksen", "authors": "Allard A. Hendriksen, Daniel M. Pelt and K. Joost Batenburg", "title": "Noise2Inverse: Self-supervised deep convolutional denoising for\n  tomography", "comments": "This paper appears in: IEEE Transactions on Computational Imaging On\n  page(s): 1320-1335 Print ISSN: 2333-9403 Online ISSN: 2333-9403 Digital\n  Object Identifier: 10.1109/TCI.2020.3019647", "journal-ref": null, "doi": "10.1109/TCI.2020.3019647", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a high-quality image from noisy indirect measurements is an\nimportant problem with many applications. For such inverse problems, supervised\ndeep convolutional neural network (CNN)-based denoising methods have shown\nstrong results, but the success of these supervised methods critically depends\non the availability of a high-quality training dataset of similar measurements.\nFor image denoising, methods are available that enable training without a\nseparate training dataset by assuming that the noise in two different pixels is\nuncorrelated. However, this assumption does not hold for inverse problems,\nresulting in artifacts in the denoised images produced by existing methods.\nHere, we propose Noise2Inverse, a deep CNN-based denoising method for linear\nimage reconstruction algorithms that does not require any additional clean or\nnoisy data. Training a CNN-based denoiser is enabled by exploiting the noise\nmodel to compute multiple statistically independent reconstructions. We develop\na theoretical framework which shows that such training indeed obtains a\ndenoising CNN, assuming the measured noise is element-wise independent and\nzero-mean. On simulated CT datasets, Noise2Inverse demonstrates an improvement\nin peak signal-to-noise ratio and structural similarity index compared to\nstate-of-the-art image denoising methods and conventional reconstruction\nmethods, such as Total-Variation Minimization. We also demonstrate that the\nmethod is able to significantly reduce noise in challenging real-world\nexperimental datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:50:24 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 13:25:56 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 08:27:07 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Hendriksen", "Allard A.", ""], ["Pelt", "Daniel M.", ""], ["Batenburg", "K. Joost", ""]]}, {"id": "2001.11802", "submitter": "Adonis Bogris", "authors": "Stavros Deligiannidis, Adonis Bogris, Charis Mesaritakis, Yannis\n  Kopsinis", "title": "Compensation of Fiber Nonlinearities in Digital Coherent Systems\n  Leveraging Long Short-Term Memory Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JLT.2020.3007919", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce for the first time the utilization of Long short-term memory\n(LSTM) neural network architectures for the compensation of fiber\nnonlinearities in digital coherent systems. We conduct numerical simulations\nconsidering either C-band or O-band transmission systems for single channel and\nmulti-channel 16-QAM modulation format with polarization multiplexing. A\ndetailed analysis regarding the effect of the number of hidden units and the\nlength of the word of symbols that trains the LSTM algorithm and corresponds to\nthe considered channel memory is conducted in order to reveal the limits of\nLSTM based receiver with respect to performance and complexity. The numerical\nresults show that LSTM Neural Networks can be very efficient as post processors\nof optical receivers which classify data that have undergone non-linear\nimpairments in fiber and provide superior performance compared to digital back\npropagation, especially in the multi-channel transmission scenario. The\ncomplexity analysis shows that LSTM becomes more complex as the number of\nhidden units and the channel memory increase can be less complex than DBP in\nlong distances (> 1000 km).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:50:48 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 09:27:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Deligiannidis", "Stavros", ""], ["Bogris", "Adonis", ""], ["Mesaritakis", "Charis", ""], ["Kopsinis", "Yannis", ""]]}, {"id": "2001.11818", "submitter": "Tzu-Chi Yen", "authors": "Tzu-Chi Yen, Daniel B. Larremore", "title": "Community Detection in Bipartite Networks with Stochastic Blockmodels", "comments": "17 pages, 6 figures. Code is available at\n  https://github.com/junipertcy/bipartiteSBM and a documentation at\n  https://docs.netscied.tw/bipartiteSBM/index.html", "journal-ref": "Phys. Rev. E 102, 032309 (2020)", "doi": "10.1103/PhysRevE.102.032309", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In bipartite networks, community structures are restricted to being\ndisassortative, in that nodes of one type are grouped according to common\npatterns of connection with nodes of the other type. This makes the stochastic\nblock model (SBM), a highly flexible generative model for networks with block\nstructure, an intuitive choice for bipartite community detection. However,\ntypical formulations of the SBM do not make use of the special structure of\nbipartite networks. Here we introduce a Bayesian nonparametric formulation of\nthe SBM and a corresponding algorithm to efficiently find communities in\nbipartite networks which parsimoniously chooses the number of communities. The\nbiSBM improves community detection results over general SBMs when data are\nnoisy, improves the model resolution limit by a factor of $\\sqrt{2}$, and\nexpands our understanding of the complicated optimization landscape associated\nwith community detection tasks. A direct comparison of certain terms of the\nprior distributions in the biSBM and a related high-resolution hierarchical SBM\nalso reveals a counterintuitive regime of community detection problems,\npopulated by smaller and sparser networks, where nonhierarchical models\noutperform their more flexible counterpart.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 05:58:19 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 07:38:24 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Yen", "Tzu-Chi", ""], ["Larremore", "Daniel B.", ""]]}, {"id": "2001.11819", "submitter": "Dan Piponi", "authors": "Dan Piponi, Dave Moore, Joshua V. Dillon", "title": "Joint Distributions for TensorFlow Probability", "comments": "Based on extended abstract submitted to PROBPROG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central tenet of probabilistic programming is that a model is specified\nexactly once in a canonical representation which is usable by inference\nalgorithms. We describe JointDistributions, a family of declarative\nrepresentations of directed graphical models in TensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 01:00:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Piponi", "Dan", ""], ["Moore", "Dave", ""], ["Dillon", "Joshua V.", ""]]}, {"id": "2001.11821", "submitter": "Jean-Philippe Fauvelle", "authors": "Alexandre Dey, Marc Velay, Jean-Philippe Fauvelle, Sylvain Navers", "title": "Adversarial vs behavioural-based defensive AI with joint, continual and\n  active learning: automated evaluation of robustness to deception, poisoning\n  and concept drift", "comments": "in French. European Cyber Week - CESAR/IAD Conference - Artificial\n  Intelligence and Defence, French Ministry of Defence, Nov 2019, Rennes,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence (AI) have brought new\ncapabilities to behavioural analysis (UEBA) for cyber-security consisting in\nthe detection of hostile action based on the unusual nature of events observed\non the Information System.In our previous work (presented at C\\&ESAR 2018 and\nFIC 2019), we have associated deep neural networks auto-encoders for anomaly\ndetection and graph-based events correlation to address major limitations in\nUEBA systems. This resulted in reduced false positive and false negative rates,\nimproved alert explainability, while maintaining real-time performances and\nscalability. However, we did not address the natural evolution of behaviours\nthrough time, also known as concept drift. To maintain effective detection\ncapabilities, an anomaly-based detection system must be continually trained,\nwhich opens a door to an adversary that can conduct the so-called\n\"frog-boiling\" attack by progressively distilling unnoticed attack traces\ninside the behavioural models until the complete attack is considered normal.\nIn this paper, we present a solution to effectively mitigate this attack by\nimproving the detection process and efficiently leveraging human expertise. We\nalso present preliminary work on adversarial AI conducting deception attack,\nwhich, in term, will be used to help assess and improve the defense system.\nThese defensive and offensive AI implement joint, continual and active\nlearning, in a step that is necessary in assessing, validating and certifying\nAI-based defensive solutions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:54:36 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Dey", "Alexandre", ""], ["Velay", "Marc", ""], ["Fauvelle", "Jean-Philippe", ""], ["Navers", "Sylvain", ""]]}, {"id": "2001.11825", "submitter": "Alexandros Arvanitakis", "authors": "A.D. Arvanitakis", "title": "Recursion and evolution: Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG math.LO q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-editing algorithm is one that edits its program. The present paper\nstudies evolution of self-editing algorithms that undergo some form of natural\nor artificial selection. We show that such an algorithm may be simply\nprogrammed, by a procedure we call diagonalization, so as to use selection as\nan information, to adjust accordingly its genetic behavior. We provide a lot of\nexamples regarding this principle, including ones that diagonalization is used\nto evolve its own mechanism. (This last one being possible due to self-editing\nproperty and to the general nature of this procedure).\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:04:52 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 07:21:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Arvanitakis", "A. D.", ""]]}, {"id": "2001.11841", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Tim Verbelen, Johannes Nauta, Cedric De Boom and Bart\n  Dhoedt", "title": "Learning Perception and Planning with Deep Active Inference", "comments": "Accepted on ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a process theory of the brain that states that all living\norganisms infer actions in order to minimize their (expected) free energy.\nHowever, current experiments are limited to predefined, often discrete, state\nspaces. In this paper we use recent advances in deep learning to learn the\nstate space and approximate the necessary probability distributions to engage\nin active inference.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 12:27:05 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 12:50:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Verbelen", "Tim", ""], ["Nauta", "Johannes", ""], ["De Boom", "Cedric", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2001.11842", "submitter": "Li Zhang", "authors": "Li Zhang, Yifeng Gao, Jessica Lin", "title": "Semantic Discord: Finding Unusual Local Patterns for Time Series", "comments": "Accepted by SDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding anomalous subsequence in a long time series is a very important but\ndifficult problem. Existing state-of-the-art methods have been focusing on\nsearching for the subsequence that is the most dissimilar to the rest of the\nsubsequences; however, they do not take into account the background patterns\nthat contain the anomalous candidates. As a result, such approaches are likely\nto miss local anomalies. We introduce a new definition named \\textit{semantic\ndiscord}, which incorporates the context information from larger subsequences\ncontaining the anomaly candidates. We propose an efficient algorithm with a\nderived lower bound that is up to 3 orders of magnitude faster than the brute\nforce algorithm in real world data. We demonstrate that our method\nsignificantly outperforms the state-of-the-art methods in locating anomalies by\nextensive experiments. We further explain the interpretability of semantic\ndiscord.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 07:38:17 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 04:38:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Li", ""], ["Gao", "Yifeng", ""], ["Lin", "Jessica", ""]]}, {"id": "2001.11844", "submitter": "Diep Do Ngoc", "authors": "Do Ngoc Diep", "title": "Statistical Tests and Confidential Intervals as Thresholds for Quantum\n  Neural Networks", "comments": "LaTeX2e, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some basic quantum neural networks were analyzed and constructed in the\nrecent work of the author \\cite{dndiep3}, published in International Journal of\nTheoretical Physics (2020). In particular the Least Quare Problem (LSP) and the\nLinear Regression Problem (LRP) was discussed. In this second paper we continue\nto analyze and construct the least square quantum neural network (LS-QNN), the\npolynomial interpolation quantum neural network (PI-QNN), the polynomial\nregression quantum neural network (PR-QNN) and chi-squared quantum neural\nnetwork ($\\chi^2$-QNN). We use the corresponding solution or tests as the\nthreshold for the corresponding training rules.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 05:41:04 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Diep", "Do Ngoc", ""]]}, {"id": "2001.11845", "submitter": "Seyed Hamid Rezatofighi", "authors": "Hamid Rezatofighi, Roman Kaskman, Farbod T. Motlagh, Qinfeng Shi,\n  Anton Milan, Daniel Cremers, Laura Leal-Taix\\'e, Ian Reid", "title": "Learn to Predict Sets Using Feed-Forward Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.00613", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the task of set prediction using deep feed-forward\nneural networks. A set is a collection of elements which is invariant under\npermutation and the size of a set is not fixed in advance. Many real-world\nproblems, such as image tagging and object detection, have outputs that are\nnaturally expressed as sets of entities. This creates a challenge for\ntraditional deep neural networks which naturally deal with structured outputs\nsuch as vectors, matrices or tensors. We present a novel approach for learning\nto predict sets with unknown permutation and cardinality using deep neural\nnetworks. In our formulation we define a likelihood for a set distribution\nrepresented by a) two discrete distributions defining the set cardinally and\npermutation variables, and b) a joint distribution over set elements with a\nfixed cardinality. Depending on the problem under consideration, we define\ndifferent training models for set prediction using deep neural networks. We\ndemonstrate the validity of our set formulations on relevant vision problems\nsuch as: 1)multi-label image classification where we achieve state-of-the-art\nperformance on the PASCAL VOC and MS COCO datasets, 2) object detection, for\nwhich our formulation outperforms state-of-the-art detectors such as Faster\nR-CNN and YOLO v3, and 3) a complex CAPTCHA test, where we observe that,\nsurprisingly, our set-based network acquired the ability of mimicking\narithmetics without any rules being coded.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 01:52:07 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Rezatofighi", "Hamid", ""], ["Kaskman", "Roman", ""], ["Motlagh", "Farbod T.", ""], ["Shi", "Qinfeng", ""], ["Milan", "Anton", ""], ["Cremers", "Daniel", ""], ["Leal-Taix\u00e9", "Laura", ""], ["Reid", "Ian", ""]]}, {"id": "2001.11846", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle and Rodolfo Anibal Lobo", "title": "Quaternion-Valued Recurrent Projection Neural Networks on Unit\n  Quaternions", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.09227", "journal-ref": null, "doi": "10.1016/j.tcs.2020.08.033", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypercomplex-valued neural networks, including quaternion-valued neural\nnetworks, can treat multi-dimensional data as a single entity. In this paper,\nwe present the quaternion-valued recurrent projection neural networks (QRPNNs).\nBriefly, QRPNNs are obtained by combining the non-local projection learning\nwith the quaternion-valued recurrent correlation neural network (QRCNNs). We\nshow that QRPNNs overcome the cross-talk problem of QRCNNs. Thus, they are\nappropriate to implement associative memories. Furthermore, computational\nexperiments reveal that QRPNNs exhibit greater storage capacity and noise\ntolerance than their corresponding QRCNNs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:45 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Valle", "Marcos Eduardo", ""], ["Lobo", "Rodolfo Anibal", ""]]}, {"id": "2001.11850", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Xinshi Chen, Yuan Yang, Arun Ramamurthy, Bo Li, Yuan Qi,\n  Le Song", "title": "Efficient Probabilistic Logic Reasoning with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Logic Networks (MLNs), which elegantly combine logic rules and\nprobabilistic graphical models, can be used to address many knowledge graph\nproblems. However, inference in MLN is computationally intensive, making the\nindustrial-scale application of MLN very difficult. In recent years, graph\nneural networks (GNNs) have emerged as efficient and effective tools for\nlarge-scale graph problems. Nevertheless, GNNs do not explicitly incorporate\nprior logic rules into the models, and may require many labeled examples for a\ntarget task. In this paper, we explore the combination of MLNs and GNNs, and\nuse graph neural networks for variational inference in MLN. We propose a GNN\nvariant, named ExpressGNN, which strikes a nice balance between the\nrepresentation power and the simplicity of the model. Our extensive experiments\non several benchmark datasets demonstrate that ExpressGNN leads to effective\nand efficient probabilistic logic reasoning.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:34:36 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 01:10:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zhang", "Yuyu", ""], ["Chen", "Xinshi", ""], ["Yang", "Yuan", ""], ["Ramamurthy", "Arun", ""], ["Li", "Bo", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "2001.11853", "submitter": "Felipe Carvalho", "authors": "Felipe Silva Carvalho, Jo\\~ao Pedro Braga", "title": "The G\\^ateaux-Hopfield Neural Network method", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work a new set of differential equations for the Hopfield\nNeural Network (HNN) method were established by means of the Linear Extended\nGateaux Derivative (LEGD). This new approach will be referred to as\nG\\^ateaux-Hopfiel Neural Network (GHNN). A first order Fredholm integral\nproblem was used to test this new method and it was found to converge 22 times\nfaster to the exact solutions for {\\alpha} > 1 if compared with the HNN integer\norder differential equations. Also a limit to the learning time is observed by\nanalysing the results for different values of {\\alpha}. The robustness and\nadvantages of this new method will be pointed out.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:31:49 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Carvalho", "Felipe Silva", ""], ["Braga", "Jo\u00e3o Pedro", ""]]}, {"id": "2001.11854", "submitter": "Song Bian", "authors": "Song Bian, Weiwen Jiang, Qing Lu, Yiyu Shi, Takashi Sato", "title": "NASS: Optimizing Secure Inference via Neural Architecture Search", "comments": "8 pages, 6 figures, in Proceedings of ECAI 2020, the 24th European\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing privacy concerns, neural network (NN) based secure\ninference (SI) schemes that simultaneously hide the client inputs and server\nmodels attract major research interests. While existing works focused on\ndeveloping secure protocols for NN-based SI, in this work, we take a different\napproach. We propose NASS, an integrated framework to search for tailored NN\narchitectures designed specifically for SI. In particular, we propose to model\ncryptographic protocols as design elements with associated reward functions.\nThe characterized models are then adopted in a joint optimization with\npredicted hyperparameters in identifying the best NN architectures that balance\nprediction accuracy and execution efficiency. In the experiment, it is\ndemonstrated that we can achieve the best of both worlds by using NASS, where\nthe prediction accuracy can be improved from 81.6% to 84.6%, while the\ninference runtime is reduced by 2x and communication bandwidth by 1.9x on the\nCIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 06:37:18 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 17:08:24 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 10:54:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bian", "Song", ""], ["Jiang", "Weiwen", ""], ["Lu", "Qing", ""], ["Shi", "Yiyu", ""], ["Sato", "Takashi", ""]]}, {"id": "2001.11897", "submitter": "Bobak Kiani", "authors": "Bobak Toussi Kiani, Seth Lloyd, Reevu Maity", "title": "Learning Unitaries by Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the hardness of learning unitary transformations in $U(d)$ via\ngradient descent on time parameters of alternating operator sequences. We\nprovide numerical evidence that, despite the non-convex nature of the loss\nlandscape, gradient descent always converges to the target unitary when the\nsequence contains $d^2$ or more parameters. Rates of convergence indicate a\n\"computational phase transition.\" With less than $d^2$ parameters, gradient\ndescent converges to a sub-optimal solution, whereas with more than $d^2$\nparameters, gradient descent converges exponentially to an optimal solution.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:20:55 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:23:35 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 21:05:43 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Kiani", "Bobak Toussi", ""], ["Lloyd", "Seth", ""], ["Maity", "Reevu", ""]]}, {"id": "2001.11905", "submitter": "Laurens Devos", "authors": "Laurens Devos, Wannes Meert, Jesse Davis", "title": "Verifying Tree Ensembles by Reasoning about Potential Instances", "comments": "Devos, Laurens, Wannes Meert, and Jesse Davis. \"Verifying tree\n  ensembles by reasoning about potential instances.\" Proceedings of the 2021\n  SIAM International Conference on Data Mining (SDM). Society for Industrial\n  and Applied Mathematics, 2021", "journal-ref": null, "doi": "10.1137/1.9781611976700.51", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine being able to ask questions to a black box model such as \"Which\nadversarial examples exist?\", \"Does a specific attribute have a\ndisproportionate effect on the model's prediction?\" or \"What kind of\npredictions could possibly be made for a partially described example?\" This\nlast question is particularly important if your partial description does not\ncorrespond to any observed example in your data, as it provides insight into\nhow the model will extrapolate to unseen data. These capabilities would be\nextremely helpful as they would allow a user to better understand the model's\nbehavior, particularly as it relates to issues such as robustness, fairness,\nand bias. In this paper, we propose such an approach for an ensemble of trees.\nSince, in general, this task is intractable we present a strategy that (1) can\nprune part of the input space given the question asked to simplify the problem;\nand (2) follows a divide and conquer approach that is incremental and can\nalways return some answers and indicates which parts of the input domains are\nstill uncertain. The usefulness of our approach is shown on a diverse set of\nuse cases.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 15:31:23 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 13:45:19 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 12:54:32 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Devos", "Laurens", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2001.11936", "submitter": "Amir Andalib", "authors": "Amir Andalib, Vahid Tabataba Vakili", "title": "An Autonomous Intrusion Detection System Using an Ensemble of Advanced\n  Learners", "comments": "5 pages", "journal-ref": "2020 28th Iranian Conference on Electrical Engineering (ICEE)", "doi": "10.1109/ICEE50131.2020.9260808", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intrusion detection system (IDS) is a vital security component of modern\ncomputer networks. With the increasing amount of sensitive services that use\ncomputer network-based infrastructures, IDSs need to be more intelligent and\nautonomous. Aside from autonomy, another important feature for an IDS is its\nability to detect zero-day attacks. To address these issues, in this paper, we\npropose an IDS which reduces the amount of manual interaction and needed expert\nknowledge and is able to yield acceptable performance under zero-day attacks.\nOur approach is to use three learning techniques in parallel: gated recurrent\nunit (GRU), convolutional neural network as deep techniques and random forest\nas an ensemble technique. These systems are trained in parallel and the results\nare combined under two logics: majority vote and \"OR\" logic. We use the NSL-KDD\ndataset to verify the proficiency of our proposed system. Simulation results\nshow that the system has the potential to operate with a very low technician\ninteraction under the zero-day attacks. We achieved 87:28% accuracy on the\nNSL-KDD's \"KDDTest+\" dataset and 76:61% accuracy on the challenging\n\"KDDTest-21\" with lower training time and lower needed computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:27:29 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 15:25:32 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Andalib", "Amir", ""], ["Vakili", "Vahid Tabataba", ""]]}, {"id": "2001.11939", "submitter": "Sophie Fosson", "authors": "Sophie M. Fosson", "title": "Centralized and distributed online learning for sparse time-varying\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The development of online algorithms to track time-varying systems has drawn\na lot of attention in the last years, in particular in the framework of online\nconvex optimization. Meanwhile, sparse time-varying optimization has emerged as\na powerful tool to deal with widespread applications, ranging from dynamic\ncompressed sensing to parsimonious system identification. In most of the\nliterature on sparse time-varying problems, some prior information on the\nsystem's evolution is assumed to be available. In contrast, in this paper, we\npropose an online learning approach, which does not employ a given model and is\nsuitable for adversarial frameworks. Specifically, we develop centralized and\ndistributed algorithms, and we theoretically analyze them in terms of dynamic\nregret, in an online learning perspective. Further, we propose numerical\nexperiments that illustrate their practical effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:29:38 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Fosson", "Sophie M.", ""]]}, {"id": "2001.11940", "submitter": "Basil Saeed", "authors": "Basil Saeed, Snigdha Panigrahi, Caroline Uhler", "title": "Causal Structure Discovery from Distributions Arising from Mixtures of\n  DAGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributions arising from a mixture of causal models, where each\nmodel is represented by a directed acyclic graph (DAG). We provide a graphical\nrepresentation of such mixture distributions and prove that this representation\nencodes the conditional independence relations of the mixture distribution. We\nthen consider the problem of structure learning based on samples from such\ndistributions. Since the mixing variable is latent, we consider causal\nstructure discovery algorithms such as FCI that can deal with latent variables.\nWe show that such algorithms recover a \"union\" of the component DAGs and can\nidentify variables whose conditional distribution across the component DAGs\nvary. We demonstrate our results on synthetic and real data showing that the\ninferred graph identifies nodes that vary between the different mixture\ncomponents. As an immediate application, we demonstrate how retrieval of this\ncausal information can be used to cluster samples according to each mixture\ncomponent.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:33:26 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 15:40:22 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Saeed", "Basil", ""], ["Panigrahi", "Snigdha", ""], ["Uhler", "Caroline", ""]]}, {"id": "2001.11946", "submitter": "Jennifer Sleeman", "authors": "Jennifer Sleeman, John Dorband, Milton Halem", "title": "A Hybrid Quantum enabled RBM Advantage: Convolutional Autoencoders For\n  Quantum Image Compression and Generative Learning", "comments": "18 figures, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how the D-Wave quantum computer could be used for machine\nlearning problems is of growing interest. Our work evaluates the feasibility of\nusing the D-Wave as a sampler for machine learning. We describe a hybrid system\nthat combines a classical deep neural network autoencoder with a quantum\nannealing Restricted Boltzmann Machine (RBM) using the D-Wave. We evaluate our\nhybrid autoencoder algorithm using two datasets, the MNIST dataset and MNIST\nFashion dataset. We evaluate the quality of this method by using a downstream\nclassification method where the training is based on quantum RBM-generated\nsamples. Our method overcomes two key limitations in the current 2000-qubit\nD-Wave processor, namely the limited number of qubits available to accommodate\ntypical problem sizes for fully connected quantum objective functions and\nsamples that are binary pixel representations. As a consequence of these\nlimitations we are able to show how we achieved nearly a 22-fold compression\nfactor of grayscale 28 x 28 sized images to binary 6 x 6 sized images with a\nlossy recovery of the original 28 x 28 grayscale images. We further show how\ngenerating samples from the D-Wave after training the RBM, resulted in 28 x 28\nimages that were variations of the original input data distribution, as opposed\nto recreating the training samples. We formulated an MNIST classification\nproblem using a deep convolutional neural network that used samples from a\nquantum RBM to train the MNIST classifier and compared the results with an\nMNIST classifier trained with the original MNIST training data set, as well as\nan MNIST classifier trained using classical RBM samples. Our hybrid autoencoder\napproach indicates advantage for RBM results relative to the use of a current\nRBM classical computer implementation for image-based machine learning and even\nmore promising results for the next generation D-Wave quantum system.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:44:24 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Sleeman", "Jennifer", ""], ["Dorband", "John", ""], ["Halem", "Milton", ""]]}, {"id": "2001.11950", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "Non-reversibly updating a uniform [0,1] value for Metropolis\n  accept/reject decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I show how it can be beneficial to express Metropolis accept/reject decisions\nin terms of comparison with a uniform [0,1] value, u, and to then update u\nnon-reversibly, as part of the Markov chain state, rather than sampling it\nindependently each iteration. This provides a small improvement for random walk\nMetropolis and Langevin updates in high dimensions. It produces a larger\nimprovement when using Langevin updates with persistent momentum, giving\nperformance comparable to that of Hamiltonian Monte Carlo (HMC) with long\ntrajectories. This is of significance when some variables are updated by other\nmethods, since if HMC is used, these updates can be done only between\ntrajectories, whereas they can be done more often with Langevin updates. I\ndemonstrate that for a problem with some continuous variables, updated by HMC\nor Langevin updates, and also discrete variables, updated by Gibbs sampling\nbetween updates of the continuous variables, Langevin with persistent momentum\nand non-reversible updates to u samples nearly a factor of two more efficiently\nthan HMC. Benefits are also seen for a Bayesian neural network model in which\nhyperparameters are updated by Gibbs sampling.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:57:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "2001.11951", "submitter": "S.H.Shabbeer Basha", "authors": "S.H.Shabbeer Basha, Sravan Kumar Vinakota, Shiv Ram Dubey, Viswanath\n  Pulabaigari, Snehasis Mukherjee", "title": "AutoFCL: Automatically Tuning Fully Connected Layers for Handling Small\n  Dataset", "comments": "This paper is published in Neural Computing & Applications Journal", "journal-ref": null, "doi": "10.1007/s00521-020-05549-4", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNN) have evolved as popular machine\nlearning models for image classification during the past few years, due to\ntheir ability to learn the problem-specific features directly from the input\nimages. The success of deep learning models solicits architecture engineering\nrather than hand-engineering the features. However, designing state-of-the-art\nCNN for a given task remains a non-trivial and challenging task, especially\nwhen training data size is less. To address this phenomena, transfer learning\nhas been used as a popularly adopted technique. While transferring the learned\nknowledge from one task to another, fine-tuning with the target-dependent Fully\nConnected (FC) layers generally produces better results over the target task.\nIn this paper, the proposed AutoFCL model attempts to learn the structure of FC\nlayers of a CNN automatically using Bayesian optimization. To evaluate the\nperformance of the proposed AutoFCL, we utilize five pre-trained CNN models\nsuch as VGG-16, ResNet, DenseNet, MobileNet, and NASNetMobile. The experiments\nare conducted on three benchmark datasets, namely CalTech-101, Oxford-102\nFlowers, and UC Merced Land Use datasets. Fine-tuning the newly learned\n(target-dependent) FC layers leads to state-of-the-art performance, according\nto the experiments carried out in this research. The proposed AutoFCL method\noutperforms the existing methods over CalTech-101 and Oxford-102 Flowers\ndatasets by achieving the accuracy of 94.38% and 98.89%, respectively. However,\nour method achieves comparable performance on the UC Merced Land Use dataset\nwith 96.83% accuracy. The source codes of this research are available at\nhttps://github.com/shabbeersh/AutoFCL.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 08:39:00 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 05:35:49 GMT"}, {"version": "v3", "created": "Mon, 30 Mar 2020 11:36:39 GMT"}, {"version": "v4", "created": "Thu, 28 Jan 2021 17:05:06 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Basha", "S. H. Shabbeer", ""], ["Vinakota", "Sravan Kumar", ""], ["Dubey", "Shiv Ram", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "2001.11956", "submitter": "Maleknaz Nayebi", "authors": "Yalda Hashemi, Maleknaz Nayebi, Giuliano Antoniol", "title": "Documentation of Machine Learning Software", "comments": "The paper is accepted for publication in 27th IEEE International\n  Conference on Software Analysis, Evolution and Reengineering (SANER 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning software documentation is different from most of the\ndocumentations that were studied in software engineering research. Often, the\nusers of these documentations are not software experts. The increasing interest\nin using data science and in particular, machine learning in different fields\nattracted scientists and engineers with various levels of knowledge about\nprogramming and software engineering. Our ultimate goal is automated generation\nand adaptation of machine learning software documents for users with different\nlevels of expertise. We are interested in understanding the nature and triggers\nof the problems and the impact of the users' levels of expertise in the process\nof documentation evolution. We will investigate the Stack Overflow Q/As and\nclassify the documentation related Q/As within the machine learning domain to\nunderstand the types and triggers of the problems as well as the potential\nchange requests to the documentation. We intend to use the results for building\non top of the state of the art techniques for automatic documentation\ngeneration and extending on the adoption, summarization, and explanation of\nsoftware functionalities.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 00:01:28 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hashemi", "Yalda", ""], ["Nayebi", "Maleknaz", ""], ["Antoniol", "Giuliano", ""]]}, {"id": "2001.11958", "submitter": "Xiao Liu", "authors": "Xiao Liu, Mingzhe Chen, Yuanwei Liu, Yue Chen, Shuguang Cui, and Lajos\n  Hanzo", "title": "Artificial Intelligence Aided Next-Generation Networks Relying on UAVs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) assisted unmanned aerial vehicle (UAV) aided\nnext-generation networking is proposed for dynamic environments. In the\nAI-enabled UAV-aided wireless networks (UAWN), multiple UAVs are employed as\naerial base stations, which are capable of rapidly adapting to the dynamic\nenvironment by collecting information about the users' position and\ntele-traffic demands, learning from the environment and acting upon the\nfeedback received from the users. Moreover, AI enables the interaction amongst\na swarm of UAVs for cooperative optimization of the system. As a benefit of the\nAI framework, several challenges of conventional UAWN may be circumvented,\nleading to enhanced network performance, improved reliability and agile\nadaptivity. As a further benefit, dynamic trajectory design and resource\nallocation are demonstrated. Finally, potential research challenges and\nopportunities are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:10:22 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Liu", "Xiao", ""], ["Chen", "Mingzhe", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""], ["Cui", "Shuguang", ""], ["Hanzo", "Lajos", ""]]}, {"id": "2001.11963", "submitter": "Liangping Ma", "authors": "Liangping Ma, John Kaewell", "title": "Fast Monte Carlo Dropout and Error Correction for Radio Transmitter\n  Classification", "comments": "Work completed in October, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo dropout may effectively capture model uncertainty in deep\nlearning, where a measure of uncertainty is obtained by using multiple\ninstances of dropout at test time. However, Monte Carlo dropout is applied\nacross the whole network and thus significantly increases the computational\ncomplexity, proportional to the number of instances. To reduce the\ncomputational complexity, at test time we enable dropout layers only near the\noutput of the neural network and reuse the computation from prior layers while\nkeeping, if any, other dropout layers disabled. Additionally, we leverage the\nside information about the ideal distributions for various input samples to do\n`error correction' on the predictions. We apply these techniques to the radio\nfrequency (RF) transmitter classification problem and show that the proposed\nalgorithm is able to provide better prediction uncertainty than the simple\nensemble average algorithm and can be used to effectively identify transmitters\nthat are not in the training data set while correctly classifying transmitters\nit has been trained on.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:26:13 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ma", "Liangping", ""], ["Kaewell", "John", ""]]}, {"id": "2001.11976", "submitter": "Sevegni Allognon", "authors": "Sevegni Odilon Clement Allognon, Alessandro L. Koerich, Alceu de S.\n  Britto Jr", "title": "Continuous Emotion Recognition via Deep Convolutional Autoencoder and\n  Support Vector Regressor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic facial expression recognition is an important research area in the\nemotion recognition and computer vision. Applications can be found in several\ndomains such as medical treatment, driver fatigue surveillance, sociable\nrobotics, and several other human-computer interaction systems. Therefore, it\nis crucial that the machine should be able to recognize the emotional state of\nthe user with high accuracy. In recent years, deep neural networks have been\nused with great success in recognizing emotions. In this paper, we present a\nnew model for continuous emotion recognition based on facial expression\nrecognition by using an unsupervised learning approach based on transfer\nlearning and autoencoders. The proposed approach also includes preprocessing\nand post-processing techniques which contribute favorably to improving the\nperformance of predicting the concordance correlation coefficient for arousal\nand valence dimensions. Experimental results for predicting spontaneous and\nnatural emotions on the RECOLA 2016 dataset have shown that the proposed\napproach based on visual information can achieve CCCs of 0.516 and 0.264 for\nvalence and arousal, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 17:47:16 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Allognon", "Sevegni Odilon Clement", ""], ["Koerich", "Alessandro L.", ""], ["Britto", "Alceu de S.", "Jr"]]}, {"id": "2001.11985", "submitter": "Denis Lukovnikov", "authors": "D. Lukovnikov, A. Fischer, J. Lehmann", "title": "Pretrained Transformers for Simple Question Answering over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering simple questions over knowledge graphs is a well-studied problem in\nquestion answering. Previous approaches for this task built on recurrent and\nconvolutional neural network based architectures that use pretrained word\nembeddings. It was recently shown that finetuning pretrained transformer\nnetworks (e.g. BERT) can outperform previous approaches on various natural\nlanguage processing tasks. In this work, we investigate how well BERT performs\non SimpleQuestions and provide an evaluation of both BERT and BiLSTM-based\nmodels in datasparse scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:14:17 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Lukovnikov", "D.", ""], ["Fischer", "A.", ""], ["Lehmann", "J.", ""]]}, {"id": "2001.11988", "submitter": "Philippe S\\\"unnen", "authors": "Massimo Fornasier, Hui Huang, Lorenzo Pareschi, Philippe S\\\"unnen", "title": "Consensus-Based Optimization on the Sphere: Convergence to Global\n  Minimizers and Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.AP math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the implementation of a new stochastic Kuramoto-Vicsek-type\nmodel for global optimization of nonconvex functions on the sphere. This model\nbelongs to the class of Consensus-Based Optimization. In fact, particles move\non the sphere driven by a drift towards an instantaneous consensus point, which\nis computed as a convex combination of particle locations, weighted by the cost\nfunction according to Laplace's principle, and it represents an approximation\nto a global minimizer. The dynamics is further perturbed by a random vector\nfield to favor exploration, whose variance is a function of the distance of the\nparticles to the consensus point. In particular, as soon as the consensus is\nreached the stochastic component vanishes. The main results of this paper are\nabout the proof of convergence of the numerical scheme to global minimizers\nprovided conditions of well-preparation of the initial datum. The proof\ncombines previous results of mean-field limit with a novel asymptotic analysis,\nand classical convergence results of numerical methods for SDE. We present\nseveral numerical experiments, which show that the algorithm proposed in the\npresent paper scales well with the dimension and is extremely versatile. To\nquantify the performances of the new approach, we show that the algorithm is\nable to perform essentially as good as ad hoc state of the art methods in\nchallenging problems in signal processing and machine learning, namely the\nphase retrieval problem and the robust subspace detection.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:23:26 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:37:45 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 12:56:59 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 10:52:08 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 09:03:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fornasier", "Massimo", ""], ["Huang", "Hui", ""], ["Pareschi", "Lorenzo", ""], ["S\u00fcnnen", "Philippe", ""]]}, {"id": "2001.11990", "submitter": "Serena Wang", "authors": "Serena Wang and Maya Gupta", "title": "Deontological Ethics By Monotonicity Shape Constraints", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how easy it is for modern machine-learned systems to violate\ncommon deontological ethical principles and social norms such as \"favor the\nless fortunate,\" and \"do not penalize good attributes.\" We propose that in some\ncases such ethical principles can be incorporated into a machine-learned model\nby adding shape constraints that constrain the model to respond only positively\nto relevant inputs. We analyze the relationship between these deontological\nconstraints that act on individuals and the consequentialist group-based\nfairness goals of one-sided statistical parity and equal opportunity. This\nstrategy works with sensitive attributes that are Boolean or real-valued such\nas income and age, and can help produce more responsible and trustworthy AI.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:27:27 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 00:20:00 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Serena", ""], ["Gupta", "Maya", ""]]}, {"id": "2001.11994", "submitter": "Hui Huang", "authors": "Massimo Fornasier, Hui Huang, Lorenzo Pareschi, Philippe S\\\"unnen", "title": "Consensus-Based Optimization on Hypersurfaces: Well-Posedness and\n  Mean-Field Limit", "comments": null, "journal-ref": null, "doi": "10.1142/S0218202520500530", "report-no": null, "categories": "math.AP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new stochastic differential model for global optimization of\nnonconvex functions on compact hypersurfaces. The model is inspired by the\nstochastic Kuramoto-Vicsek system and belongs to the class of Consensus-Based\nOptimization methods. In fact, particles move on the hypersurface driven by a\ndrift towards an instantaneous consensus point, computed as a convex\ncombination of the particle locations weighted by the cost function according\nto Laplace's principle. The consensus point represents an approximation to a\nglobal minimizer. The dynamics is further perturbed by a random vector field to\nfavor exploration, whose variance is a function of the distance of the\nparticles to the consensus point. In particular, as soon as the consensus is\nreached, then the stochastic component vanishes. In this paper, we study the\nwell-posedness of the model and we derive rigorously its mean-field\napproximation for large particle limit.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:33:08 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 11:06:36 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 11:08:04 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 19:37:11 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fornasier", "Massimo", ""], ["Huang", "Hui", ""], ["Pareschi", "Lorenzo", ""], ["S\u00fcnnen", "Philippe", ""]]}, {"id": "2001.12004", "submitter": "Joseph Suarez", "authors": "Joseph Suarez, Yilun Du, Igor Mordatch, Phillip Isola", "title": "Neural MMO v1.3: A Massively Multiagent Game Environment for Training\n  and Evaluating Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in multiagent intelligence research is fundamentally limited by the\nnumber and quality of environments available for study. In recent years,\nsimulated games have become a dominant research platform within reinforcement\nlearning, in part due to their accessibility and interpretability. Previous\nworks have targeted and demonstrated success on arcade, first person shooter\n(FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games.\nOur work considers massively multiplayer online role-playing games (MMORPGs or\nMMOs), which capture several complexities of real-world learning that are not\nwell modeled by any other game genre. We present Neural MMO, a massively\nmultiagent game environment inspired by MMOs and discuss our progress on two\nmore general challenges in multiagent systems engineering for AI research:\ndistributed infrastructure and game IO. We further demonstrate that standard\npolicy gradient methods and simple baseline models can learn interesting\nemergent exploration and specialization behaviors in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:50:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 01:58:32 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Suarez", "Joseph", ""], ["Du", "Yilun", ""], ["Mordatch", "Igor", ""], ["Isola", "Phillip", ""]]}, {"id": "2001.12006", "submitter": "Hrushikesh Mhaskar", "authors": "Charles K. Chui, Ningning Han, Hrushikesh N. Mhaskar", "title": "Theory inspired deep network for instantaneous-frequency extraction and\n  signal components recovery from discrete blind-source data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the inverse problem of recovering the unknown\nsignal components, along with extraction of their instantaneous frequencies\n(IFs), governed by the adaptive harmonic model (AHM), from discrete (and\npossibly non-uniform) samples of the blind-source composite signal.\n  None of the existing decomposition methods and algorithms, including the most\npopular empirical mode decomposition (EMD) computational scheme and its current\nmodifications, is capable of solving this inverse problem.\n  In order to meet the AHM formulation and to extract the IFs of the decomposed\ncomponents, called intrinsic mode functions (IMFs), each IMF of EMD is extended\nto an analytic function in the upper half of the complex plane via the Hilbert\ntransform, followed by taking the real part of the polar form of the analytic\nextension.\n  Unfortunately, this approach most often fails to resolve the inverse problem\nsatisfactorily.\n  More recently, to resolve the inverse problem, the notion of synchrosqueezed\nwavelet transform (SST) was proposed by Daubechies and Maes, and further\ndeveloped in many other papers, while a more direct method, called signal\nseparation operation (SSO), was proposed and developed in our previous work\npublished in the journal, Applied and Computational Harmonic Analysis, vol.\n30(2):243-261, 2016.\n  In the present paper, we propose a synthesis of SSO using a deep neural\nnetwork, based directly on a discrete sample set, that may be non-uniformly\nsampled, of the blind-source signal.\n  Our method is localized, as illustrated by a number of numerical examples,\nincluding components with different signal arrival and departure times.\n  It also yields short-term prediction of the signal components, along with\ntheir IFs.\n  Our neural networks are inspired by theory, designed so that they do not\nrequire any training in the traditional sense.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:54:00 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chui", "Charles K.", ""], ["Han", "Ningning", ""], ["Mhaskar", "Hrushikesh N.", ""]]}, {"id": "2001.12010", "submitter": "Jun-Jie Huang", "authors": "Jun-Jie Huang and Pier Luigi Dragotti", "title": "Learning Deep Analysis Dictionaries for Image Super-Resolution", "comments": "Accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3036902", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent success of deep neural networks and the recent efforts\nto develop multi-layer dictionary models, we propose a Deep Analysis dictionary\nModel (DeepAM) which is optimized to address a specific regression task known\nas single image super-resolution. Contrary to other multi-layer dictionary\nmodels, our architecture contains L layers of analysis dictionary and\nsoft-thresholding operators to gradually extract high-level features and a\nlayer of synthesis dictionary which is designed to optimize the regression task\nat hand. In our approach, each analysis dictionary is partitioned into two\nsub-dictionaries: an Information Preserving Analysis Dictionary (IPAD) and a\nClustering Analysis Dictionary (CAD). The IPAD together with the corresponding\nsoft-thresholds is designed to pass the key information from the previous layer\nto the next layer, while the CAD together with the corresponding\nsoft-thresholding operator is designed to produce a sparse feature\nrepresentation of its input data that facilitates discrimination of key\nfeatures. DeepAM uses both supervised and unsupervised setup. Simulation\nresults show that the proposed deep analysis dictionary model achieves better\nperformance compared to a deep neural network that has the same structure and\nis optimized using back-propagation when training datasets are small.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 18:59:35 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:37:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Huang", "Jun-Jie", ""], ["Dragotti", "Pier Luigi", ""]]}]