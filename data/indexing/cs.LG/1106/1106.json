[{"id": "1106.0221", "submitter": "J. J. Grefenstette", "authors": "J. J. Grefenstette, D. E. Moriarty, A. C. Schultz", "title": "Evolutionary Algorithms for Reinforcement Learning", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 11, pages\n  241-276, 1999", "doi": "10.1613/jair.613", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two distinct approaches to solving reinforcement learning problems,\nnamely, searching in value function space and searching in policy space.\nTemporal difference methods and evolutionary algorithms are well-known examples\nof these approaches. Kaelbling, Littman and Moore recently provided an\ninformative survey of temporal difference methods. This article focuses on the\napplication of evolutionary algorithms to the reinforcement learning problem,\nemphasizing alternative policy representations, credit assignment methods, and\nproblem-specific genetic operators. Strengths and weaknesses of the\nevolutionary approach to reinforcement learning are presented, along with a\nsurvey of representative applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 16:16:14 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Grefenstette", "J. J.", ""], ["Moriarty", "D. E.", ""], ["Schultz", "A. C.", ""]]}, {"id": "1106.0357", "submitter": "Mohamad Tarifi", "authors": "Mohamad Tarifi, Meera Sitharam, Jeffery Ho", "title": "Learning Hierarchical Sparse Representations using Iterative Dictionary\n  Learning and Dimension Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an elemental building block which combines Dictionary\nLearning and Dimension Reduction (DRDL). We show how this foundational element\ncan be used to iteratively construct a Hierarchical Sparse Representation (HSR)\nof a sensory stream. We compare our approach to existing models showing the\ngenerality of our simple prescription. We then perform preliminary experiments\nusing this framework, illustrating with the example of an object recognition\ntask using standard datasets. This work introduces the very first steps towards\nan integrated framework for designing and analyzing various computational tasks\nfrom learning to attention to action. The ultimate goal is building a\nmathematically rigorous, integrated theory of intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 02:31:04 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Tarifi", "Mohamad", ""], ["Sitharam", "Meera", ""], ["Ho", "Jeffery", ""]]}, {"id": "1106.0483", "submitter": "Xaq Pitkow", "authors": "Xaq Pitkow, Yashar Ahmadian, Ken D. Miller", "title": "Learning unbelievable marginal probabilities", "comments": "10 pages, 3 figures, submitted to NIPS*2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loopy belief propagation performs approximate inference on graphical models\nwith loops. One might hope to compensate for the approximation by adjusting\nmodel parameters. Learning algorithms for this purpose have been explored\npreviously, and the claim has been made that every set of locally consistent\nmarginals can arise from belief propagation run on a graphical model. On the\ncontrary, here we show that many probability distributions have marginals that\ncannot be reached by belief propagation using any set of model parameters or\nany learning algorithm. We call such marginals `unbelievable.' This problem\noccurs whenever the Hessian of the Bethe free energy is not positive-definite\nat the target marginals. All learning algorithms for belief propagation\nnecessarily fail in these cases, producing beliefs or sets of beliefs that may\neven be worse than the pre-learning approximation. We then show that averaging\ninaccurate beliefs, each obtained from belief propagation using model\nparameters perturbed about some learned mean values, can achieve the\nunbelievable marginals.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 18:48:59 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Pitkow", "Xaq", ""], ["Ahmadian", "Yashar", ""], ["Miller", "Ken D.", ""]]}, {"id": "1106.0518", "submitter": "Homin Lee", "authors": "Mahdi Cheraghchi, Adam Klivans, Pravesh Kothari, Homin K. Lee", "title": "Submodular Functions Are Noise Stable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that all non-negative submodular functions have high {\\em\nnoise-stability}. As a consequence, we obtain a polynomial-time learning\nalgorithm for this class with respect to any product distribution on\n$\\{-1,1\\}^n$ (for any constant accuracy parameter $\\epsilon$). Our algorithm\nalso succeeds in the agnostic setting. Previous work on learning submodular\nfunctions required either query access or strong assumptions about the types of\nsubmodular functions to be learned (and did not hold in the agnostic setting).\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2011 21:30:50 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 14:32:55 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Cheraghchi", "Mahdi", ""], ["Klivans", "Adam", ""], ["Kothari", "Pravesh", ""], ["Lee", "Homin K.", ""]]}, {"id": "1106.0666", "submitter": "Jonathan Baxter", "authors": "J. Baxter, P. L. Bartlett, L. Weaver", "title": "Experiments with Infinite-Horizon, Policy-Gradient Estimation", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 15, pages\n  351-381, 2001", "doi": "10.1613/jair.807", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present algorithms that perform gradient ascent of the\naverage reward in a partially observable Markov decision process (POMDP). These\nalgorithms are based on GPOMDP, an algorithm introduced in a companion paper\n(Baxter and Bartlett, this volume), which computes biased estimates of the\nperformance gradient in POMDPs. The algorithm's chief advantages are that it\nuses only one free parameter beta, which has a natural interpretation in terms\nof bias-variance trade-off, it requires no knowledge of the underlying state,\nand it can be applied to infinite state, control and observation spaces. We\nshow how the gradient estimates produced by GPOMDP can be used to perform\ngradient ascent, both with a traditional stochastic-gradient algorithm, and\nwith an algorithm based on conjugate-gradients that utilizes gradient\ninformation to bracket maxima in line searches. Experimental results are\npresented illustrating both the theoretical results of (Baxter and Bartlett,\nthis volume) on a toy problem, and practical aspects of the algorithms on a\nnumber of more realistic problems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 14:52:26 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 04:58:31 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Baxter", "J.", ""], ["Bartlett", "P. L.", ""], ["Weaver", "L.", ""]]}, {"id": "1106.0676", "submitter": "M. Kearns", "authors": "M. Kearns, D. Litman, S. Singh, M. Walker", "title": "Optimizing Dialogue Management with Reinforcement Learning: Experiments\n  with the NJFun System", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 16, pages\n  105-133, 2002", "doi": "10.1613/jair.859", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing the dialogue policy of a spoken dialogue system involves many\nnontrivial choices. This paper presents a reinforcement learning approach for\nautomatically optimizing a dialogue policy, which addresses the technical\nchallenges in applying reinforcement learning to a working dialogue system with\nhuman users. We report on the design, construction and empirical evaluation of\nNJFun, an experimental spoken dialogue system that provides users with access\nto information about fun things to do in New Jersey. Our results show that by\noptimizing its performance via reinforcement learning, NJFun measurably\nimproves system performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 14:55:23 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Kearns", "M.", ""], ["Litman", "D.", ""], ["Singh", "S.", ""], ["Walker", "M.", ""]]}, {"id": "1106.0681", "submitter": "C. Boutilier", "authors": "C. Boutilier, B. Price", "title": "Accelerating Reinforcement Learning through Implicit Imitation", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 19, pages\n  569-629, 2003", "doi": "10.1613/jair.898", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation can be viewed as a means of enhancing learning in multiagent\nenvironments. It augments an agent's ability to learn useful behaviors by\nmaking intelligent use of the knowledge implicit in behaviors demonstrated by\ncooperative teachers or other more experienced agents. We propose and study a\nformal model of implicit imitation that can accelerate reinforcement learning\ndramatically in certain cases. Roughly, by observing a mentor, a\nreinforcement-learning agent can extract information about its own capabilities\nin, and the relative value of, unvisited parts of the state space. We study two\nspecific instantiations of this model, one in which the learning agent and the\nmentor have identical abilities, and one designed to deal with agents and\nmentors with different action sets. We illustrate the benefits of implicit\nimitation by integrating it with prioritized sweeping, and demonstrating\nimproved performance and convergence through observation of single and multiple\nmentors. Though we make some stringent assumptions regarding observability and\npossible interactions, we briefly comment on extensions of the model that relax\nthese restricitions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 14:57:02 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Boutilier", "C.", ""], ["Price", "B.", ""]]}, {"id": "1106.0707", "submitter": "H. He", "authors": "H. He, D. Hu, X. Xu", "title": "Efficient Reinforcement Learning Using Recursive Least-Squares Methods", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 16, pages\n  259-292, 2002", "doi": "10.1613/jair.946", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recursive least-squares (RLS) algorithm is one of the most well-known\nalgorithms used in adaptive filtering, system identification and adaptive\ncontrol. Its popularity is mainly due to its fast convergence speed, which is\nconsidered to be optimal in practice. In this paper, RLS methods are used to\nsolve reinforcement learning problems, where two new reinforcement learning\nalgorithms using linear value function approximators are proposed and analyzed.\nThe two algorithms are called RLS-TD(lambda) and Fast-AHC (Fast Adaptive\nHeuristic Critic), respectively. RLS-TD(lambda) can be viewed as the extension\nof RLS-TD(0) from lambda=0 to general lambda within interval [0,1], so it is a\nmulti-step temporal-difference (TD) learning algorithm using RLS methods. The\nconvergence with probability one and the limit of convergence of RLS-TD(lambda)\nare proved for ergodic Markov chains. Compared to the existing LS-TD(lambda)\nalgorithm, RLS-TD(lambda) has advantages in computation and is more suitable\nfor online learning. The effectiveness of RLS-TD(lambda) is analyzed and\nverified by learning prediction experiments of Markov chains with a wide range\nof parameter settings. The Fast-AHC algorithm is derived by applying the\nproposed RLS-TD(lambda) algorithm in the critic network of the adaptive\nheuristic critic method. Unlike conventional AHC algorithm, Fast-AHC makes use\nof RLS methods to improve the learning-prediction efficiency in the critic.\nLearning control experiments of the cart-pole balancing and the acrobot\nswing-up problems are conducted to compare the data efficiency of Fast-AHC with\nconventional AHC. From the experimental results, it is shown that the data\nefficiency of learning control can also be improved by using RLS methods in the\nlearning-prediction process of the critic. The performance of Fast-AHC is also\ncompared with that of the AHC method using LS-TD(lambda). Furthermore, it is\ndemonstrated in the experiments that different initial values of the variance\nmatrix in RLS-TD(lambda) are required to get better performance not only in\nlearning prediction but also in learning control. The experimental results are\nanalyzed based on the existing theoretical work on the transient phase of\nforgetting factor RLS methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 16:44:06 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["He", "H.", ""], ["Hu", "D.", ""], ["Xu", "X.", ""]]}, {"id": "1106.0730", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald and Cosma Rohilla Shalizi", "title": "Rademacher complexity of stationary sequences", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to control the generalization error of time series models wherein\npast values of the outcome are used to predict future values. The results are\nbased on a generalization of standard i.i.d. concentration inequalities to\ndependent data without the mixing assumptions common in the time series\nsetting. Our proof and the result are simpler than previous analyses with\ndependent data or stochastic adversaries which use sequential Rademacher\ncomplexities rather than the expected Rademacher complexity for i.i.d.\nprocesses. We also derive empirical Rademacher results without mixing\nassumptions resulting in fully calculable upper bounds.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 19:09:31 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 22:40:23 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["McDonald", "Daniel J.", ""], ["Shalizi", "Cosma Rohilla", ""]]}, {"id": "1106.0800", "submitter": "Philipp Hennig PhD", "authors": "Philipp Hennig", "title": "Optimal Reinforcement Learning for Gaussian Systems", "comments": "final pre-conference version of this NIPS 2011 paper. Once again,\n  please note some nontrivial changes to exposition and interpretation of the\n  results, in particular in Equation (9) and Eqs. 11-14. The algorithm and\n  results have remained the same, but their theoretical interpretation has\n  changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation trade-off is among the central challenges of\nreinforcement learning. The optimal Bayesian solution is intractable in\ngeneral. This paper studies to what extent analytic statements about optimal\nlearning are possible if all beliefs are Gaussian processes. A first order\napproximation of learning of both loss and dynamics, for nonlinear,\ntime-varying systems in continuous time and space, subject to a relatively weak\nrestriction on the dynamics, is described by an infinite-dimensional partial\ndifferential equation. An approximate finite-dimensional projection gives an\nimpression for how this result may be helpful.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2011 08:14:59 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 16:11:15 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2011 15:01:11 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Hennig", "Philipp", ""]]}, {"id": "1106.0967", "submitter": "Ping Li", "authors": "Ping Li, Anshumali Shrivastava, Joshua Moore, Arnd Christian Konig", "title": "Hashing Algorithms for Large-Scale Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first demonstrate that b-bit minwise hashing, whose\nestimators are positive definite kernels, can be naturally integrated with\nlearning algorithms such as SVM and logistic regression. We adopt a simple\nscheme to transform the nonlinear (resemblance) kernel into linear (inner\nproduct) kernel; and hence large-scale problems can be solved extremely\nefficiently. Our method provides a simple effective solution to large-scale\nlearning in massive and extremely high-dimensional datasets, especially when\ndata do not fit in memory.\n  We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm\n(which is related the Count-Min (CM) sketch). Interestingly, VW has the same\nvariances as random projections. Our theoretical and empirical comparisons\nillustrate that usually $b$-bit minwise hashing is significantly more accurate\n(at the same storage) than VW (and random projections) in binary data.\nFurthermore, $b$-bit minwise hashing can be combined with VW to achieve further\nimprovements in terms of training speed, especially when $b$ is large.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 06:38:20 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Li", "Ping", ""], ["Shrivastava", "Anshumali", ""], ["Moore", "Joshua", ""], ["Konig", "Arnd Christian", ""]]}, {"id": "1106.0987", "submitter": "Junping Zhang", "authors": "Junping Zhang and Ziyu Xie and Stan Z. Li", "title": "Nearest Prime Simplicial Complex for Object Recognition", "comments": "16pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure representation of data distribution plays an important role in\nunderstanding the underlying mechanism of generating data. In this paper, we\npropose nearest prime simplicial complex approaches (NSC) by utilizing\npersistent homology to capture such structures. Assuming that each class is\nrepresented with a prime simplicial complex, we classify unlabeled samples\nbased on the nearest projection distances from the samples to the simplicial\ncomplexes. We also extend the extrapolation ability of these complexes with a\nprojection constraint term. Experiments in simulated and practical datasets\nindicate that compared with several published algorithms, the proposed NSC\napproaches achieve promising performance without losing the structure\nrepresentation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 08:32:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Zhang", "Junping", ""], ["Xie", "Ziyu", ""], ["Li", "Stan Z.", ""]]}, {"id": "1106.1113", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea, Elka Korutcheva", "title": "Complexity Analysis of Vario-eta through Structure", "comments": "13 pages, 2 figures, 14th International Workshop, IWCIA 2011, Madrid,\n  Spain, May 2011; Advances in Image Analysis and Applications, Research\n  Publishing Services 2011 ISBN 978-981-08-7923-5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based representations of images have recently acquired an important\nrole for classification purposes within the context of machine learning\napproaches. The underlying idea is to consider that relevant information of an\nimage is implicitly encoded into the relationships between more basic entities\nthat compose by themselves the whole image. The classification problem is then\nreformulated in terms of an optimization problem usually solved by a\ngradient-based search procedure. Vario-eta through structure is an approximate\nsecond order stochastic optimization technique that achieves a good trade-off\nbetween speed of convergence and the computational effort required. However,\nthe robustness of this technique for large scale problems has not been yet\nassessed. In this paper we firstly provide a theoretical justification of the\nassumptions made by this optimization procedure. Secondly, a complexity\nanalysis of the algorithm is performed to prove its suitability for large scale\nlearning problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 16:25:58 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Chinea", "Alejandro", ""], ["Korutcheva", "Elka", ""]]}, {"id": "1106.1157", "submitter": "Shakir Mohamed", "authors": "Shakir Mohamed, Katherine Heller and Zoubin Ghahramani", "title": "Bayesian and L1 Approaches to Sparse Unsupervised Learning", "comments": "In Proceedings of the 29th International Conference on Machine\n  Learning (ICML), Edinburgh, Scotland, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of L1 regularisation for sparse learning has generated immense\nresearch interest, with successful application in such diverse areas as signal\nacquisition, image coding, genomics and collaborative filtering. While existing\nwork highlights the many advantages of L1 methods, in this paper we find that\nL1 regularisation often dramatically underperforms in terms of predictive\nperformance when compared with other methods for inferring sparsity. We focus\non unsupervised latent variable models, and develop L1 minimising factor\nmodels, Bayesian variants of \"L1\", and Bayesian models with a stronger L0-like\nsparsity induced through spike-and-slab distributions. These spike-and-slab\nBayesian factor models encourage sparsity while accounting for uncertainty in a\nprincipled manner and avoiding unnecessary shrinkage of non-zero values. We\ndemonstrate on a number of data sets that in practice spike-and-slab Bayesian\nmethods outperform L1 minimisation, even on a computational budget. We thus\nhighlight the need to re-assess the wide use of L1 methods in sparsity-reliant\napplications, particularly when we care about generalising to previously unseen\ndata, and provide an alternative that, over many varying conditions, provides\nimproved generalisation performance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 19:24:44 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2011 00:37:47 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2012 04:15:40 GMT"}], "update_date": "2012-08-20", "authors_parsed": [["Mohamed", "Shakir", ""], ["Heller", "Katherine", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1106.1216", "submitter": "Ohad Shamir", "authors": "Shai Shalev-Shwartz and Ohad Shamir and Eran Tromer", "title": "Using More Data to Speed-up Training Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In many recent applications, data is plentiful. By now, we have a rather\nclear understanding of how more data can be used to improve the accuracy of\nlearning algorithms. Recently, there has been a growing interest in\nunderstanding how more data can be leveraged to reduce the required training\nruntime. In this paper, we study the runtime of learning as a function of the\nnumber of available training examples, and underscore the main high-level\ntechniques. We provide some initial positive results showing that the runtime\ncan decrease exponentially while only requiring a polynomial growth of the\nnumber of examples, and spell-out several interesting open problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 23:55:00 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2011 01:17:56 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""], ["Tromer", "Eran", ""]]}, {"id": "1106.1379", "submitter": "Dan Feldman PhD", "authors": "Dan Feldman, Michael Langberg", "title": "A Unified Framework for Approximating and Clustering Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $F$ of $n$ positive functions over a ground set $X$, we consider\nthe problem of computing $x^*$ that minimizes the expression $\\sum_{f\\in\nF}f(x)$, over $x\\in X$. A typical application is \\emph{shape fitting}, where we\nwish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from\na (possibly infinite) family $X$ of shapes. Here, each point $p\\in P$\ncorresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$,\nand we seek a shape $x$ that minimizes the sum of distances from each point in\n$P$. In the $k$-clustering variant, each $x\\in X$ is a tuple of $k$ shapes, and\n$f(x)$ is the distance from $p$ to its closest shape in $x$.\n  Our main result is a unified framework for constructing {\\em coresets} and\n{\\em approximate clustering} for such general sets of functions. To achieve our\nresults, we forge a link between the classic and well defined notion of\n$\\varepsilon$-approximations from the theory of PAC Learning and VC dimension,\nto the relatively new (and not so consistent) paradigm of coresets, which are\nsome kind of \"compressed representation\" of the input set $F$. Using\ntraditional techniques, a coreset usually implies an LTAS (linear time\napproximation scheme) for the corresponding optimization problem, which can be\ncomputed in parallel, via one pass over the data, and using only\npolylogarithmic space (i.e, in the streaming model).\n  We show how to generalize the results of our framework for squared distances\n(as in $k$-mean), distances to the $q$th power, and deterministic\nconstructions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2011 15:52:39 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2014 03:27:25 GMT"}, {"version": "v3", "created": "Wed, 29 Oct 2014 20:14:19 GMT"}, {"version": "v4", "created": "Sat, 28 May 2016 21:58:42 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Feldman", "Dan", ""], ["Langberg", "Michael", ""]]}, {"id": "1106.1622", "submitter": "Shai Shalev-Shwartz", "authors": "Shai Shalev-Shwartz and Alon Gonen and Ohad Shamir", "title": "Large-Scale Convex Minimization with a Low-Rank Constraint", "comments": "ICML 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of minimizing a convex function over the space of\nlarge matrices with low rank. While this optimization problem is hard in\ngeneral, we propose an efficient greedy algorithm and derive its formal\napproximation guarantees. Each iteration of the algorithm involves\n(approximately) finding the left and right singular vectors corresponding to\nthe largest singular value of a certain matrix, which can be calculated in\nlinear time. This leads to an algorithm which can scale to large matrices\narising in several applications such as matrix completion for collaborative\nfiltering and robust low rank matrix approximation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 19:07:09 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Gonen", "Alon", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.1651", "submitter": "Dimitris S. Papailiopoulos", "authors": "Megasthenis Asteris, Dimitris S. Papailiopoulos, and George N.\n  Karystinos", "title": "Sparse Principal Component of a Rank-deficient Matrix", "comments": "5 pages, 1 figure, to be presented at ISIT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying the sparse principal component of a\nrank-deficient matrix. We introduce auxiliary spherical variables and prove\nthat there exists a set of candidate index-sets (that is, sets of indices to\nthe nonzero elements of the vector argument) whose size is polynomially\nbounded, in terms of rank, and contains the optimal index-set, i.e. the\nindex-set of the nonzero elements of the optimal solution. Finally, we develop\nan algorithm that computes the optimal sparse principal component in polynomial\ntime for any sparsity degree.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 20:01:17 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Asteris", "Megasthenis", ""], ["Papailiopoulos", "Dimitris S.", ""], ["Karystinos", "George N.", ""]]}, {"id": "1106.1684", "submitter": "Mehmet Umut Sen Mr.", "authors": "Mehmet Umut Sen and Hakan Erdogan", "title": "Max-Margin Stacking and Sparse Regularization for Linear Classifier\n  Combination and Selection", "comments": "8 pages, 3 figures, 6 tables, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main principle of stacked generalization (or Stacking) is using a\nsecond-level generalizer to combine the outputs of base classifiers in an\nensemble. In this paper, we investigate different combination types under the\nstacking framework; namely weighted sum (WS), class-dependent weighted sum\n(CWS) and linear stacked generalization (LSG). For learning the weights, we\npropose using regularized empirical risk minimization with the hinge loss. In\naddition, we propose using group sparsity for regularization to facilitate\nclassifier selection. We performed experiments using two different ensemble\nsetups with differing diversities on 8 real-world datasets. Results show the\npower of regularized learning with the hinge loss function. Using sparse\nregularization, we are able to reduce the number of selected classifiers of the\ndiverse ensemble without sacrificing accuracy. With the non-diverse ensembles,\nwe even gain accuracy on average by using sparse regularization.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 23:03:47 GMT"}], "update_date": "2011-06-10", "authors_parsed": [["Sen", "Mehmet Umut", ""], ["Erdogan", "Hakan", ""]]}, {"id": "1106.1770", "submitter": "Jan Oksanen", "authors": "Jan Oksanen, Jarmo Lund\\'en, Visa Koivunen", "title": "Reinforcement learning based sensing policy optimization for energy\n  efficient cognitive radio networks", "comments": "10 pages, 13 figures, Accepted to Neurocomputing special issue:\n  Machine learning for signal processing, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a machine learning based collaborative multi-band\nspectrum sensing policy for cognitive radios. The proposed sensing policy\nguides secondary users to focus the search of unused radio spectrum to those\nfrequencies that persistently provide them high data rate. The proposed policy\nis based on machine learning, which makes it adaptive with the temporally and\nspatially varying radio spectrum. Furthermore, there is no need for dynamic\nmodeling of the primary activity since it is implicitly learned over time.\nEnergy efficiency is achieved by minimizing the number of assigned sensors per\neach subband under a constraint on miss detection probability. It is important\nto control the missed detections because they cause collisions with primary\ntransmissions and lead to retransmissions at both the primary and secondary\nuser. Simulations show that the proposed machine learning based sensing policy\nimproves the overall throughput of the secondary network and improves the\nenergy efficiency while controlling the miss detection probability.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 10:40:08 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2011 11:08:21 GMT"}, {"version": "v3", "created": "Tue, 4 Oct 2011 06:02:16 GMT"}], "update_date": "2011-10-05", "authors_parsed": [["Oksanen", "Jan", ""], ["Lund\u00e9n", "Jarmo", ""], ["Koivunen", "Visa", ""]]}, {"id": "1106.1887", "submitter": "Ali Jalali", "authors": "Ali Jalali and Sujay Sanghavi", "title": "Learning the Dependence Graph of Time Series with Latent Factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of learning, from samples, the dependency\nstructure of a system of linear stochastic differential equations, when some of\nthe variables are latent. In particular, we observe the time evolution of some\nvariables, and never observe other variables; from this, we would like to find\nthe dependency structure between the observed variables - separating out the\nspurious interactions caused by the (marginalizing out of the) latent\nvariables' time series. We develop a new method, based on convex optimization,\nto do so in the case when the number of latent variables is smaller than the\nnumber of observed ones. For the case when the dependency structure between the\nobserved variables is sparse, we theoretically establish a high-dimensional\nscaling result for structure recovery. We verify our theoretical result with\nboth synthetic and real data (from the stock market).\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 19:34:29 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2012 02:03:33 GMT"}, {"version": "v3", "created": "Fri, 16 Mar 2012 16:18:16 GMT"}, {"version": "v4", "created": "Tue, 1 May 2012 04:30:11 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Jalali", "Ali", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1106.1925", "submitter": "Ryan Adams", "authors": "Ryan Prescott Adams, Richard S. Zemel", "title": "Ranking via Sinkhorn Propagation", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of increasing importance to develop learning methods for ranking. In\ncontrast to many learning objectives, however, the ranking problem presents\ndifficulties due to the fact that the space of permutations is not smooth. In\nthis paper, we examine the class of rank-linear objective functions, which\nincludes popular metrics such as precision and discounted cumulative gain. In\nparticular, we observe that expectations of these gains are completely\ncharacterized by the marginals of the corresponding distribution over\npermutation matrices. Thus, the expectations of rank-linear objectives can\nalways be described through locations in the Birkhoff polytope, i.e.,\ndoubly-stochastic matrices (DSMs). We propose a technique for learning\nDSM-based ranking functions using an iterative projection operator known as\nSinkhorn normalization. Gradients of this operator can be computed via\nbackpropagation, resulting in an algorithm we call Sinkhorn propagation, or\nSinkProp. This approach can be combined with a wide range of gradient-based\napproaches to rank learning. We demonstrate the utility of SinkProp on several\ninformation retrieval data sets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 21:57:27 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2011 00:11:51 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Adams", "Ryan Prescott", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1106.1933", "submitter": "Puduru Reddy V", "authors": "Dario Bauso, Puduru Viswanadha Reddy and Tamer Basar", "title": "Lyapunov stochastic stability and control of robust dynamic coalitional\n  games with transferable utilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.SY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper considers a dynamic game with transferable utilities (TU), where\nthe characteristic function is a continuous-time bounded mean ergodic process.\nA central planner interacts continuously over time with the players by choosing\nthe instantaneous allocations subject to budget constraints. Before the game\nstarts, the central planner knows the nature of the process (bounded mean\nergodic), the bounded set from which the coalitions' values are sampled, and\nthe long run average coalitions' values. On the other hand, he has no knowledge\nof the underlying probability function generating the coalitions' values. Our\ngoal is to find allocation rules that use a measure of the extra reward that a\ncoalition has received up to the current time by re-distributing the budget\namong the players. The objective is two-fold: i) guaranteeing convergence of\nthe average allocations to the core (or a specific point in the core) of the\naverage game, ii) driving the coalitions' excesses to an a priori given cone.\nThe resulting allocation rules are robust as they guarantee the aforementioned\nconvergence properties despite the uncertain and time-varying nature of the\ncoaltions' values. We highlight three main contributions. First, we design an\nallocation rule based on full observation of the extra reward so that the\naverage allocation approaches a specific point in the core of the average game,\nwhile the coalitions' excesses converge to an a priori given direction. Second,\nwe design a new allocation rule based on partial observation on the extra\nreward so that the average allocation converges to the core of the average\ngame, while the coalitions' excesses converge to an a priori given cone. And\nthird, we establish connections to approachability theory and attainability\ntheory.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 23:55:58 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2012 18:19:52 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Bauso", "Dario", ""], ["Reddy", "Puduru Viswanadha", ""], ["Basar", "Tamer", ""]]}, {"id": "1106.2233", "submitter": "Xiaowen Dong", "authors": "Xiaowen Dong, Pascal Frossard, Pierre Vandergheynst and Nikolai\n  Nefedov", "title": "Clustering with Multi-Layer Graphs: A Spectral Perspective", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, vol. 60, no. 11, pp.\n  5820-5831, November 2012", "doi": "10.1109/TSP.2012.2212886", "report-no": null, "categories": "cs.LG cs.CV cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational data usually comes with a multimodal nature, which means that\nit can be naturally represented by a multi-layer graph whose layers share the\nsame set of vertices (users) with different edges (pairwise relationships). In\nthis paper, we address the problem of combining different layers of the\nmulti-layer graph for improved clustering of the vertices compared to using\nlayers independently. We propose two novel methods, which are based on joint\nmatrix factorization and graph regularization framework respectively, to\nefficiently combine the spectrum of the multiple graph layers, namely the\neigenvectors of the graph Laplacian matrices. In each case, the resulting\ncombination, which we call a \"joint spectrum\" of multiple graphs, is used for\nclustering the vertices. We evaluate our approaches by simulations with several\nreal world social network datasets. Results demonstrate the superior or\ncompetitive performance of the proposed methods over state-of-the-art technique\nand common baseline methods, such as co-regularization and summation of\ninformation from individual graphs.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 12:43:18 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Dong", "Xiaowen", ""], ["Frossard", "Pascal", ""], ["Vandergheynst", "Pierre", ""], ["Nefedov", "Nikolai", ""]]}, {"id": "1106.2363", "submitter": "Daniel Hsu", "authors": "Daniel Hsu, Sham M. Kakade, Tong Zhang", "title": "Random design analysis of ridge regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work gives a simultaneous analysis of both the ordinary least squares\nestimator and the ridge regression estimator in the random design setting under\nmild assumptions on the covariate/response distributions. In particular, the\nanalysis provides sharp results on the ``out-of-sample'' prediction error, as\nopposed to the ``in-sample'' (fixed design) error. The analysis also reveals\nthe effect of errors in the estimated covariance structure, as well as the\neffect of modeling errors, neither of which effects are present in the fixed\ndesign setting. The proofs of the main results are based on a simple\ndecomposition lemma combined with concentration inequalities for random vectors\nand matrices.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 01:08:48 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 02:16:11 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Hsu", "Daniel", ""], ["Kakade", "Sham M.", ""], ["Zhang", "Tong", ""]]}, {"id": "1106.2369", "submitter": "Daniel Hsu", "authors": "Miroslav Dudik, Daniel Hsu, Satyen Kale, Nikos Karampatziakis, John\n  Langford, Lev Reyzin, Tong Zhang", "title": "Efficient Optimal Learning for Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning in an online setting where the learner\nrepeatedly observes features, selects among a set of actions, and receives\nreward for the action taken. We provide the first efficient algorithm with an\noptimal regret. Our algorithm uses a cost sensitive classification learner as\nan oracle and has a running time $\\mathrm{polylog}(N)$, where $N$ is the number\nof classification rules among which the oracle might choose. This is\nexponentially faster than all previous algorithms that achieve optimal regret\nin this setting. Our formulation also enables us to create an algorithm with\nregret that is additive rather than multiplicative in feedback delay as in all\nprevious work.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 01:57:52 GMT"}], "update_date": "2011-06-17", "authors_parsed": [["Dudik", "Miroslav", ""], ["Hsu", "Daniel", ""], ["Kale", "Satyen", ""], ["Karampatziakis", "Nikos", ""], ["Langford", "John", ""], ["Reyzin", "Lev", ""], ["Zhang", "Tong", ""]]}, {"id": "1106.2429", "submitter": "Ohad Shamir", "authors": "Nicol\\`o Cesa-Bianchi and Ohad Shamir", "title": "Efficient Transductive Online Learning via Randomized Rounding", "comments": "To appear in a Festschrift in honor of V.N. Vapnik. Preliminary\n  version presented in NIPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most traditional online learning algorithms are based on variants of mirror\ndescent or follow-the-leader. In this paper, we present an online algorithm\nbased on a completely different approach, tailored for transductive settings,\nwhich combines \"random playout\" and randomized rounding of loss subgradients.\nAs an application of our approach, we present the first computationally\nefficient online algorithm for collaborative filtering with trace-norm\nconstrained matrices. As a second application, we solve an open question\nlinking batch learning and transductive online learning\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 12:30:05 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 14:22:14 GMT"}, {"version": "v3", "created": "Thu, 24 Nov 2011 05:11:33 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2013 10:55:26 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["Cesa-Bianchi", "Nicol\u00f2", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.2436", "submitter": "Ohad Shamir", "authors": "Shie Mannor and Ohad Shamir", "title": "From Bandits to Experts: On the Value of Side-Observations", "comments": "Presented at the NIPS 2011 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an adversarial online learning setting where a decision maker can\nchoose an action in every stage of the game. In addition to observing the\nreward of the chosen action, the decision maker gets side observations on the\nreward he would have obtained had he chosen some of the other actions. The\nobservation structure is encoded as a graph, where node i is linked to node j\nif sampling i provides information on the reward of j. This setting naturally\ninterpolates between the well-known \"experts\" setting, where the decision maker\ncan view all rewards, and the multi-armed bandits setting, where the decision\nmaker can only view the reward of the chosen action. We develop practical\nalgorithms with provable regret guarantees, which depend on non-trivial\ngraph-theoretic properties of the information feedback structure. We also\nprovide partially-matching lower bounds.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2011 13:11:33 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2011 22:33:57 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2011 15:55:47 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Mannor", "Shie", ""], ["Shamir", "Ohad", ""]]}, {"id": "1106.2662", "submitter": "Luca Rose", "authors": "Luca Rose, Samir M. Perlaza, Samson Lasaulce, M\\'erouane Debbah", "title": "Learning Equilibria with Partial Information in Decentralized Wireless\n  Networks", "comments": "16 pages, 5 figures, 1 table. To appear in IEEE Communication\n  Magazine, special Issue on Game Theory", "journal-ref": null, "doi": "10.1109/MCOM.2011.5978427", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, a survey of several important equilibrium concepts for\ndecentralized networks is presented. The term decentralized is used here to\nrefer to scenarios where decisions (e.g., choosing a power allocation policy)\nare taken autonomously by devices interacting with each other (e.g., through\nmutual interference). The iterative long-term interaction is characterized by\nstable points of the wireless network called equilibria. The interest in these\nequilibria stems from the relevance of network stability and the fact that they\ncan be achieved by letting radio devices to repeatedly interact over time. To\nachieve these equilibria, several learning techniques, namely, the best\nresponse dynamics, fictitious play, smoothed fictitious play, reinforcement\nlearning algorithms, and regret matching, are discussed in terms of information\nrequirements and convergence properties. Most of the notions introduced here,\nfor both equilibria and learning schemes, are illustrated by a simple case\nstudy, namely, an interference channel with two transmitter-receiver pairs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 09:58:36 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Rose", "Luca", ""], ["Perlaza", "Samir M.", ""], ["Lasaulce", "Samson", ""], ["Debbah", "M\u00e9rouane", ""]]}, {"id": "1106.2882", "submitter": "Andrei Soklakov N", "authors": "Andrei N. Soklakov", "title": "Learning, investments and derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent crisis and the following flight to simplicity put most derivative\nbusinesses around the world under considerable pressure. We argue that the\ntraditional modeling techniques must be extended to include product design. We\npropose a quantitative framework for creating products which meet the challenge\nof being optimal from the investors point of view while remaining relatively\nsimple and transparent.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 06:04:25 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Soklakov", "Andrei N.", ""]]}, {"id": "1106.3355", "submitter": "Ryan Martin", "authors": "Ryan Martin, Omkar Tilak", "title": "On epsilon-optimality of the pursuit learning algorithm", "comments": null, "journal-ref": "Journal of Applied Probability, 49(3), 795-805, 2012", "doi": "10.1239/jap/1346955334", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimator algorithms in learning automata are useful tools for adaptive,\nreal-time optimization in computer science and engineering applications. This\npaper investigates theoretical convergence properties for a special case of\nestimator algorithms: the pursuit learning algorithm. In this note, we identify\nand fill a gap in existing proofs of probabilistic convergence for pursuit\nlearning. It is tradition to take the pursuit learning tuning parameter to be\nfixed in practical applications, but our proof sheds light on the importance of\na vanishing sequence of tuning parameters in a theoretical convergence\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2011 21:32:26 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2012 21:36:51 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Martin", "Ryan", ""], ["Tilak", "Omkar", ""]]}, {"id": "1106.3395", "submitter": "Remi Flamary", "authors": "R\\'emi Flamary (LITIS), Alain Rakotomamonjy (LITIS)", "title": "Decoding finger movements from ECoG signals using switching linear\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges of ECoG-based Brain-Machine Interfaces is the\nmovement prediction of a human subject. Several methods exist to predict an arm\n2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is\nto predict individual finger movements (5-D trajectory). The difficulty lies in\nthe fact that there is no simple relation between ECoG signals and finger\nmovement. We propose in this paper to decode finger flexions using switching\nmodels. This method permits to simplify the system as it is now described as an\nensemble of linear models depending on an internal state. We show that an\ninteresting accuracy prediction can be obtained by such a model.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 06:53:47 GMT"}], "update_date": "2011-06-20", "authors_parsed": [["Flamary", "R\u00e9mi", "", "LITIS"], ["Rakotomamonjy", "Alain", "", "LITIS"]]}, {"id": "1106.3396", "submitter": "Remi Flamary", "authors": "R\\'emi Flamary (LITIS), Benjamin Labb\\'e (LITIS), Alain Rakotomamonjy\n  (LITIS)", "title": "Large margin filtering for signal sequence labeling", "comments": "IEEE International Conference on Acoustics Speech and Signal\n  Processing (ICASSP), 2010, Dallas : United States (2010)", "journal-ref": null, "doi": "10.1109/ICASSP.2010.5495281", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal Sequence Labeling consists in predicting a sequence of labels given an\nobserved sequence of samples. A naive way is to filter the signal in order to\nreduce the noise and to apply a classification algorithm on the filtered\nsamples. We propose in this paper to jointly learn the filter with the\nclassifier leading to a large margin filtering for classification. This method\nallows to learn the optimal cutoff frequency and phase of the filter that may\nbe different from zero. Two methods are proposed and tested on a toy dataset\nand on a real life BCI dataset from BCI Competition III.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 06:54:35 GMT"}], "update_date": "2011-06-20", "authors_parsed": [["Flamary", "R\u00e9mi", "", "LITIS"], ["Labb\u00e9", "Benjamin", "", "LITIS"], ["Rakotomamonjy", "Alain", "", "LITIS"]]}, {"id": "1106.3397", "submitter": "Remi Flamary", "authors": "Emilie Niaf (CREATIS), R\\'emi Flamary (LITIS), Carole Lartizien\n  (CREATIS), St\\'ephane Canu (LITIS)", "title": "Handling uncertainties in SVM classification", "comments": "IEEE Workshop on Statistical Signal Processing, Nice: France (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the pattern classification problem arising when\navailable target data include some uncertainty information. Target data\nconsidered here is either qualitative (a class label) or quantitative (an\nestimation of the posterior probability). Our main contribution is a SVM\ninspired formulation of this problem allowing to take into account class label\nthrough a hinge loss as well as probability estimates using epsilon-insensitive\ncost function together with a minimum norm (maximum margin) objective. This\nformulation shows a dual form leading to a quadratic problem and allows the use\nof a representer theorem and associated kernel. The solution provided can be\nused for both decision and posterior probability estimation. Based on empirical\nevidence our method outperforms regular SVM in terms of probability predictions\nand classification performances.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 06:55:24 GMT"}], "update_date": "2011-06-20", "authors_parsed": [["Niaf", "Emilie", "", "CREATIS"], ["Flamary", "R\u00e9mi", "", "LITIS"], ["Lartizien", "Carole", "", "CREATIS"], ["Canu", "St\u00e9phane", "", "LITIS"]]}, {"id": "1106.3651", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis", "title": "Robust Bayesian reinforcement learning through tight lower bounds", "comments": "Corrected version. 12 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Bayesian approach to sequential decision making, exact calculation of\nthe (subjective) utility is intractable. This extends to most special cases of\ninterest, such as reinforcement learning problems. While utility bounds are\nknown to exist for this problem, so far none of them were particularly tight.\nIn this paper, we show how to efficiently calculate a lower bound, which\ncorresponds to the utility of a near-optimal memoryless policy for the decision\nproblem, which is generally different from both the Bayes-optimal policy and\nthe policy which is optimal for the expected MDP under the current belief. We\nthen show how these can be applied to obtain robust exploration policies in a\nBayesian reinforcement learning setting.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 14:39:58 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2011 14:14:12 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Dimitrakakis", "Christos", ""]]}, {"id": "1106.3703", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky, Luis M. Rocha", "title": "Prediction and Modularity in Dynamical Systems", "comments": "v1 published in ECAL 2011 (European Conference on Artificial Life).\n  v2 fixes error in causal risk (number of parameters should be based on\n  training distribution)", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI cs.IT cs.LG cs.SY math.IT q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and understanding modular organizations is centrally important in\nthe study of complex systems. Several approaches to this problem have been\nadvanced, many framed in information-theoretic terms. Our treatment starts from\nthe complementary point of view of statistical modeling and prediction of\ndynamical systems. It is known that for finite amounts of training data,\nsimpler models can have greater predictive power than more complex ones. We use\nthe trade-off between model simplicity and predictive accuracy to generate\noptimal multiscale decompositions of dynamical networks into weakly-coupled,\nsimple modules. State-dependent and causal versions of our method are also\nproposed.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2011 04:20:16 GMT"}, {"version": "v2", "created": "Fri, 16 Jan 2015 06:53:24 GMT"}], "update_date": "2015-01-19", "authors_parsed": [["Kolchinsky", "Artemy", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1106.3725", "submitter": "S{\\l}awomir Staworko", "authors": "S{\\l}awomir Staworko, Piotr Wieczorek", "title": "Learning XML Twig Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning XML queries, path queries and tree\npattern queries, from examples given by the user. A learning algorithm takes on\nthe input a set of XML documents with nodes annotated by the user and returns a\nquery that selects the nodes in a manner consistent with the annotation. We\nstudy two learning settings that differ with the types of annotations. In the\nfirst setting the user may only indicate required nodes that the query must\nreturn. In the second, more general, setting, the user may also indicate\nforbidden nodes that the query must not return. The query may or may not return\nany node with no annotation. We formalize what it means for a class of queries\nto be \\emph{learnable}. One requirement is the existence of a learning\nalgorithm that is sound i.e., always returns a query consistent with the\nexamples given by the user. Furthermore, the learning algorithm should be\ncomplete i.e., able to produce every query with a sufficiently rich example.\nOther requirements involve tractability of learning and its robustness to\nnonessential examples. We show that the classes of simple path queries and\npath-subsumption-free tree queries are learnable from positive examples. The\nlearnability of the full class of tree pattern queries (and the full class of\npath queries) remains an open question. We show also that adding negative\nexamples to the picture renders the learning unfeasible.\n  Published in ICDT 2012, Berlin.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2011 09:29:54 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2011 12:48:41 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2012 20:28:35 GMT"}], "update_date": "2012-04-24", "authors_parsed": [["Staworko", "S\u0142awomir", ""], ["Wieczorek", "Piotr", ""]]}, {"id": "1106.4064", "submitter": "Simon Weber", "authors": "David Klein, Kyle Murray and Simon Weber", "title": "Algorithmic Programming Language Identification", "comments": "11 pages. Code:\n  https://github.com/simon-weber/Programming-Language-Identification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the amount of code that goes unidentified on the web, we\nintroduce a practical method for algorithmically identifying the programming\nlanguage of source code. Our work is based on supervised learning and\nintelligent statistical features. We also explored, but abandoned, a\ngrammatical approach. In testing, our implementation greatly outperforms that\nof an existing tool that relies on a Bayesian classifier. Code is written in\nPython and available under an MIT license.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 00:37:23 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2011 19:45:30 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Klein", "David", ""], ["Murray", "Kyle", ""], ["Weber", "Simon", ""]]}, {"id": "1106.4075", "submitter": "Haizhang Zhang", "authors": "Haizhang Zhang, Liang Zhao", "title": "On the Inclusion Relation of Reproducing Kernel Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help understand various reproducing kernels used in applied sciences, we\ninvestigate the inclusion relation of two reproducing kernel Hilbert spaces.\nCharacterizations in terms of feature maps of the corresponding reproducing\nkernels are established. A full table of inclusion relations among widely-used\ntranslation invariant kernels is given. Concrete examples for Hilbert-Schmidt\nkernels are presented as well. We also discuss the preservation of such a\nrelation under various operations of reproducing kernels. Finally, we briefly\ndiscuss the special inclusion with a norm equivalence.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 02:49:12 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Zhang", "Haizhang", ""], ["Zhao", "Liang", ""]]}, {"id": "1106.4251", "submitter": "Rina Foygel", "authors": "Rina Foygel, Ruslan Salakhutdinov, Ohad Shamir, and Nathan Srebro", "title": "Learning with the Weighted Trace-norm under Arbitrary Sampling\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide rigorous guarantees on learning with the weighted trace-norm under\narbitrary sampling distributions. We show that the standard weighted trace-norm\nmight fail when the sampling distribution is not a product distribution (i.e.\nwhen row and column indexes are not selected independently), present a\ncorrected variant for which we establish strong learning guarantees, and\ndemonstrate that it works better in practice. We provide guarantees when\nweighting by either the true or empirical sampling distribution, and suggest\nthat even if the true distribution is known (or is uniform), weighting by the\nempirical distribution may be beneficial.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 16:16:24 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Foygel", "Rina", ""], ["Salakhutdinov", "Ruslan", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""]]}, {"id": "1106.4355", "submitter": "Nikhil Rao", "authors": "Nikhil Rao, Benjamin Recht and Robert Nowak", "title": "Tight Measurement Bounds for Exact Recovery of Structured Sparse Signals", "comments": "Refined previous bound and added new experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard compressive sensing results state that to exactly recover an s\nsparse signal in R^p, one requires O(s. log(p)) measurements. While this bound\nis extremely useful in practice, often real world signals are not only sparse,\nbut also exhibit structure in the sparsity pattern. We focus on\ngroup-structured patterns in this paper. Under this model, groups of signal\ncoefficients are active (or inactive) together. The groups are predefined, but\nthe particular set of groups that are active (i.e., in the signal support) must\nbe learned from measurements. We show that exploiting knowledge of groups can\nfurther reduce the number of measurements required for exact signal recovery,\nand derive universal bounds for the number of measurements needed. The bound is\nuniversal in the sense that it only depends on the number of groups under\nconsideration, and not the particulars of the groups (e.g., compositions,\nsizes, extents, overlaps, etc.). Experiments show that our result holds for a\nvariety of overlapping group configurations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 00:45:59 GMT"}, {"version": "v2", "created": "Wed, 27 Jul 2011 02:25:06 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2011 02:16:55 GMT"}], "update_date": "2011-10-19", "authors_parsed": [["Rao", "Nikhil", ""], ["Recht", "Benjamin", ""], ["Nowak", "Robert", ""]]}, {"id": "1106.4572", "submitter": "A. Fern", "authors": "A. Fern, R. Givan, J. M. Siskind", "title": "Specific-to-General Learning for Temporal Events with Application to\n  Learning Event Definitions from Video", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 17, pages\n  379-449, 2002", "doi": "10.1613/jair.1050", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop, analyze, and evaluate a novel, supervised, specific-to-general\nlearner for a simple temporal logic and use the resulting algorithm to learn\nvisual event definitions from video sequences. First, we introduce a simple,\npropositional, temporal, event-description language called AMA that is\nsufficiently expressive to represent many events yet sufficiently restrictive\nto support learning. We then give algorithms, along with lower and upper\ncomplexity bounds, for the subsumption and generalization problems for AMA\nformulas. We present a positive-examples--only specific-to-general learning\nmethod based on these algorithms. We also present a polynomial-time--computable\n``syntactic'' subsumption test that implies semantic subsumption without being\nequivalent to it. A generalization algorithm based on syntactic subsumption can\nbe used in place of semantic generalization to improve the asymptotic\ncomplexity of the resulting learning algorithm. Finally, we apply this\nalgorithm to the task of learning relational event definitions from video and\nshow that it yields definitions that are competitive with hand-coded ones.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 20:58:18 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Fern", "A.", ""], ["Givan", "R.", ""], ["Siskind", "J. M.", ""]]}, {"id": "1106.4574", "submitter": "Karthik Sridharan Karthik Sridharan", "authors": "Andrew Cotter, Ohad Shamir, Nathan Srebro, Karthik Sridharan", "title": "Better Mini-Batch Algorithms via Accelerated Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch algorithms have been proposed as a way to speed-up stochastic\nconvex optimization problems. We study how such algorithms can be improved\nusing accelerated gradient methods. We provide a novel analysis, which shows\nhow standard gradient methods may sometimes be insufficient to obtain a\nsignificant speed-up and propose a novel accelerated gradient algorithm, which\ndeals with this deficiency, enjoys a uniformly superior guarantee and works\nwell in practice.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 20:59:20 GMT"}], "update_date": "2011-06-24", "authors_parsed": [["Cotter", "Andrew", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1106.5236", "submitter": "Andreas Argyriou", "authors": "Andreas Argyriou and Luca Baldassarre and Jean Morales and\n  Massimiliano Pontil", "title": "A General Framework for Structured Sparsity via Proximal Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generalized framework for structured sparsity. It extends the\nwell-known methods of Lasso and Group Lasso by incorporating additional\nconstraints on the variables as part of a convex optimization problem. This\nframework provides a straightforward way of favouring prescribed sparsity\npatterns, such as orderings, contiguous regions and overlapping groups, among\nothers. Existing optimization methods are limited to specific constraint sets\nand tend to not scale well with sample size and dimensionality. We propose a\nnovel first order proximal method, which builds upon results on fixed points\nand successive approximations. The algorithm can be applied to a general class\nof conic and norm constraints sets and relies on a proximity operator\nsubproblem which can be computed explicitly. Experiments on different\nregression problems demonstrate the efficiency of the optimization algorithm\nand its scalability with the size of the problem. They also demonstrate state\nof the art statistical performance, which improves over Lasso and StructOMP.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 17:03:44 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Argyriou", "Andreas", ""], ["Baldassarre", "Luca", ""], ["Morales", "Jean", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "1106.5267", "submitter": "E. Wiewiora", "authors": "E. Wiewiora", "title": "Potential-Based Shaping and Q-Value Initialization are Equivalent", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 19, pages\n  205-208, 2003", "doi": "10.1613/jair.1190", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shaping has proven to be a powerful but precarious means of improving\nreinforcement learning performance. Ng, Harada, and Russell (1999) proposed the\npotential-based shaping algorithm for adding shaping rewards in a way that\nguarantees the learner will learn optimal behavior. In this note, we prove\ncertain similarities between this shaping algorithm and the initialization step\nrequired for several reinforcement learning algorithms. More specifically, we\nprove that a reinforcement learner with initial Q-values based on the shaping\nalgorithm's potential function make the same updates throughout learning as a\nlearner receiving potential-based shaping rewards. We further prove that under\na broad category of policies, the behavior of these two learners are\nindistinguishable. The comparison provides intuition on the theoretical\nproperties of the shaping algorithm as well as a suggestion for a simpler\nmethod for capturing the algorithm's benefit. In addition, the equivalence\nraises previously unaddressed issues concerning the efficiency of learning with\npotential-based shaping.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2011 21:07:01 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Wiewiora", "E.", ""]]}, {"id": "1106.5294", "submitter": "Yohji Akama", "authors": "Yohji Akama", "title": "Set systems: order types, continuous nondeterministic deformations, and\n  quasi-orders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By reformulating a learning process of a set system L as a game between\nTeacher and Learner, we define the order type of L to be the order type of the\ngame tree, if the tree is well-founded. The features of the order type of L\n(dim L in symbol) are (1) We can represent any well-quasi-order (wqo for short)\nby the set system L of the upper-closed sets of the wqo such that the maximal\norder type of the wqo is equal to dim L. (2) dim L is an upper bound of the\nmind-change complexity of L. dim L is defined iff L has a finite elasticity (fe\nfor short), where, according to computational learning theory, if an indexed\nfamily of recursive languages has fe then it is learnable by an algorithm from\npositive data. Regarding set systems as subspaces of Cantor spaces, we prove\nthat fe of set systems is preserved by any continuous function which is\nmonotone with respect to the set-inclusion. By it, we prove that finite\nelasticity is preserved by various (nondeterministic) language operators\n(Kleene-closure, shuffle-closure, union, product, intersection,. . ..) The\nmonotone continuous functions represent nondeterministic computations. If a\nmonotone continuous function has a computation tree with each node followed by\nat most n immediate successors and the order type of a set system L is\n{\\alpha}, then the direct image of L is a set system of order type at most\nn-adic diagonal Ramsey number of {\\alpha}. Furthermore, we provide an\norder-type-preserving contravariant embedding from the category of quasi-orders\nand finitely branching simulations between them, into the complete category of\nsubspaces of Cantor spaces and monotone continuous functions having Girard's\nlinearity between them. Keyword: finite elasticity, shuffle-closure\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 04:55:23 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Akama", "Yohji", ""]]}, {"id": "1106.5341", "submitter": "Daniel Ly", "authors": "Daniel L. Ly and Ashutosh Saxena and Hod Lipson", "title": "Pose Estimation from a Single Depth Image for Arbitrary Kinematic\n  Skeletons", "comments": "2 pages, 2 figures, RGB-D workshop in Robotics: Science and Systems\n  (RSS 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for estimating pose information from a single depth image\ngiven an arbitrary kinematic structure without prior training. For an arbitrary\nskeleton and depth image, an evolutionary algorithm is used to find the optimal\nkinematic configuration to explain the observed image. Results show that our\napproach can correctly estimate poses of 39 and 78 degree-of-freedom models\nfrom a single depth image, even in cases of significant self-occlusion.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2011 09:47:28 GMT"}], "update_date": "2011-06-28", "authors_parsed": [["Ly", "Daniel L.", ""], ["Saxena", "Ashutosh", ""], ["Lipson", "Hod", ""]]}, {"id": "1106.5730", "submitter": "Benjamin Recht", "authors": "Feng Niu, Benjamin Recht, Christopher Re, Stephen J. Wright", "title": "HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient\n  Descent", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve\nstate-of-the-art performance on a variety of machine learning tasks. Several\nresearchers have recently proposed schemes to parallelize SGD, but all require\nperformance-destroying memory locking and synchronization. This work aims to\nshow using novel theoretical analysis, algorithms, and implementation that SGD\ncan be implemented without any locking. We present an update scheme called\nHOGWILD! which allows processors access to shared memory with the possibility\nof overwriting each other's work. We show that when the associated optimization\nproblem is sparse, meaning most gradient updates only modify small parts of the\ndecision variable, then HOGWILD! achieves a nearly optimal rate of convergence.\nWe demonstrate experimentally that HOGWILD! outperforms alternative schemes\nthat use locking by an order of magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 17:23:42 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2011 15:59:15 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Niu", "Feng", ""], ["Recht", "Benjamin", ""], ["Re", "Christopher", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1106.5826", "submitter": "Ali Jalali", "authors": "Ali Jalali and Pradeep Ravikumar and Sujay Sanghavi", "title": "A Dirty Model for Multiple Sparse Regression", "comments": "The primary result is accepted to NIPS 2010 for Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression -- finding an unknown vector from linear\nmeasurements -- is now known to be possible with fewer samples than variables,\nvia methods like the LASSO. We consider the multiple sparse linear regression\nproblem, where several related vectors -- with partially shared support sets --\nhave to be recovered. A natural question in this setting is whether one can use\nthe sharing to further decrease the overall number of samples required. A line\nof recent research has studied the use of \\ell_1/\\ell_q norm\nblock-regularizations with q>1 for such problems; however these could actually\nperform worse in sample complexity -- vis a vis solving each problem separately\nignoring sharing -- depending on the level of sharing.\n  We present a new method for multiple sparse linear regression that can\nleverage support and parameter overlap when it exists, but not pay a penalty\nwhen it does not. A very simple idea: we decompose the parameters into two\ncomponents and regularize these differently. We show both theoretically and\nempirically, our method strictly and noticeably outperforms both \\ell_1 or\n\\ell_1/\\ell_q methods, over the entire range of possible overlaps (except at\nboundary cases, where we match the best method). We also provide theoretical\nguarantees that the method performs well under high-dimensional scaling.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 00:53:15 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Jalali", "Ali", ""], ["Ravikumar", "Pradeep", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "1106.6104", "submitter": "Keqin Liu", "authors": "Sattar Vakili, Keqin Liu, Qing Zhao", "title": "Deterministic Sequencing of Exploration and Exploitation for Multi-Armed\n  Bandit Problems", "comments": "22 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Multi-Armed Bandit (MAB) problem, there is a given set of arms with\nunknown reward models. At each time, a player selects one arm to play, aiming\nto maximize the total expected reward over a horizon of length T. An approach\nbased on a Deterministic Sequencing of Exploration and Exploitation (DSEE) is\ndeveloped for constructing sequential arm selection policies. It is shown that\nfor all light-tailed reward distributions, DSEE achieves the optimal\nlogarithmic order of the regret, where regret is defined as the total expected\nreward loss against the ideal case with known reward models. For heavy-tailed\nreward distributions, DSEE achieves O(T^1/p) regret when the moments of the\nreward distributions exist up to the pth order for 1<p<=2 and O(T^1/(1+p/2))\nfor p>2. With the knowledge of an upperbound on a finite moment of the\nheavy-tailed reward distributions, DSEE offers the optimal logarithmic regret\norder. The proposed DSEE approach complements existing work on MAB by providing\ncorresponding results for general reward distributions. Furthermore, with a\nclearly defined tunable parameter-the cardinality of the exploration sequence,\nthe DSEE approach is easily extendable to variations of MAB, including MAB with\nvarious objectives, decentralized MAB with multiple players and incomplete\nreward observations under collisions, MAB with unknown Markov dynamics, and\ncombinatorial MAB with dependent arms that often arise in network optimization\nproblems such as the shortest path, the minimum spanning, and the dominating\nset problems under unknown random weights.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 02:12:32 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2011 04:40:06 GMT"}, {"version": "v3", "created": "Sat, 9 Mar 2013 20:17:17 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Vakili", "Sattar", ""], ["Liu", "Keqin", ""], ["Zhao", "Qing", ""]]}, {"id": "1106.6186", "submitter": "Jitesh Dundas", "authors": "Jitesh Dundas and David Chik", "title": "IBSEAD: - A Self-Evolving Self-Obsessed Learning Algorithm for Machine\n  Learning", "comments": "Keywords: Self-evolving algorithm; machine learning; decision-trees;\n  learning algorithms, Hidden Markov Models;\n  http://ijcset.excelingtech.co.uk/vol1issue4/14-vol1issue4.pdf", "journal-ref": "International Journal of Computer Science & Emerging Technologies\n  (E-ISSN: 2044-6004) 74 Volume 1, Issue 4, December 2010", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present IBSEAD or distributed autonomous entity systems based Interaction\n- a learning algorithm for the computer to self-evolve in a self-obsessed\nmanner. This learning algorithm will present the computer to look at the\ninternal and external environment in series of independent entities, which will\ninteract with each other, with and/or without knowledge of the computer's\nbrain. When a learning algorithm interacts, it does so by detecting and\nunderstanding the entities in the human algorithm. However, the problem with\nthis approach is that the algorithm does not consider the interaction of the\nthird party or unknown entities, which may be interacting with each other.\nThese unknown entities in their interaction with the non-computer entities make\nan effect in the environment that influences the information and the behaviour\nof the computer brain. Such details and the ability to process the dynamic and\nunsettling nature of these interactions are absent in the current learning\nalgorithm such as the decision tree learning algorithm. IBSEAD is able to\nevaluate and consider such algorithms and thus give us a better accuracy in\nsimulation of the highly evolved nature of the human brain. Processes such as\ndreams, imagination and novelty, that exist in humans are not fully simulated\nby the existing learning algorithms. Also, Hidden Markov models (HMM) are\nuseful in finding \"hidden\" entities, which may be known or unknown. However,\nthis model fails to consider the case of unknown entities which maybe unclear\nor unknown. IBSEAD is better because it considers three types of entities-\nknown, unknown and invisible. We present our case with a comparison of existing\nalgorithms in known environments and cases and present the results of the\nexperiments using dry run of the simulated runs of the existing machine\nlearning algorithms versus IBSEAD.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 11:08:35 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Dundas", "Jitesh", ""], ["Chik", "David", ""]]}, {"id": "1106.6258", "submitter": "Zakria Hussain", "authors": "Zakria Hussain and John Shawe-Taylor and Mario Marchand", "title": "A Note on Improved Loss Bounds for Multiple Kernel Learning", "comments": "Extended proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we correct an upper bound, presented in~\\cite{hs-11}, on the\ngeneralisation error of classifiers learned through multiple kernel learning.\nThe bound in~\\cite{hs-11} uses Rademacher complexity and has an\\emph{additive}\ndependence on the logarithm of the number of kernels and the margin achieved by\nthe classifier. However, there are some errors in parts of the proof which are\ncorrected in this paper. Unfortunately, the final result turns out to be a risk\nbound which has a \\emph{multiplicative} dependence on the logarithm of the\nnumber of kernels and the margin achieved by the classifier.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 15:03:58 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 19:40:40 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Hussain", "Zakria", ""], ["Shawe-Taylor", "John", ""], ["Marchand", "Mario", ""]]}]