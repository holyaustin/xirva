[{"id": "0910.0112", "submitter": "Rasmus Pagh", "authors": "Andrea Campagna and Rasmus Pagh", "title": "Finding Associations and Computing Similarity via Biased Pair Sampling", "comments": "This is an extended version of a paper that appeared at the IEEE\n  International Conference on Data Mining, 2009. The conference version is (c)\n  2009 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This version is ***superseded*** by a full version that can be found at\nhttp://www.itu.dk/people/pagh/papers/mining-jour.pdf, which contains stronger\ntheoretical results and fixes a mistake in the reporting of experiments.\n  Abstract: Sampling-based methods have previously been proposed for the\nproblem of finding interesting associations in data, even for low-support\nitems. While these methods do not guarantee precise results, they can be vastly\nmore efficient than approaches that rely on exact counting. However, for many\nsimilarity measures no such methods have been known. In this paper we show how\na wide variety of measures can be supported by a simple biased sampling method.\nThe method also extends to find high-confidence association rules. We\ndemonstrate theoretically that our method is superior to exact methods when the\nthreshold for \"interesting similarity/confidence\" is above the average pairwise\nsimilarity/confidence, and the average support is not too low. Our method is\nparticularly good when transactions contain many items. We confirm in\nexperiments on standard association mining benchmarks that this gives a\nsignificant speedup on real data sets (sometimes much larger than the\ntheoretical guarantees). Reductions in computation time of over an order of\nmagnitude, and significant savings in space, are observed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2009 09:02:54 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2010 09:32:14 GMT"}], "update_date": "2010-02-17", "authors_parsed": [["Campagna", "Andrea", ""], ["Pagh", "Rasmus", ""]]}, {"id": "0910.0239", "submitter": "Venkatesh Saligrama", "authors": "V. Saligrama, M. Zhao", "title": "Compressed Blind De-convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose the signal x is realized by driving a k-sparse signal u through an\narbitrary unknown stable discrete-linear time invariant system H. These types\nof processes arise naturally in Reflection Seismology. In this paper we are\ninterested in several problems: (a) Blind-Deconvolution: Can we recover both\nthe filter $H$ and the sparse signal $u$ from noisy measurements? (b)\nCompressive Sensing: Is x compressible in the conventional sense of compressed\nsensing? Namely, can x, u and H be reconstructed from a sparse set of\nmeasurements. We develop novel L1 minimization methods to solve both cases and\nestablish sufficient conditions for exact recovery for the case when the\nunknown system H is auto-regressive (i.e. all pole) of a known order. In the\ncompressed sensing/sampling setting it turns out that both H and x can be\nreconstructed from O(k log(n)) measurements under certain technical conditions\non the support structure of u. Our main idea is to pass x through a linear time\ninvariant system G and collect O(k log(n)) sequential measurements. The filter\nG is chosen suitably, namely, its associated Toeplitz matrix satisfies the RIP\nproperty. We develop a novel LP optimization algorithm and show that both the\nunknown filter H and the sparse input u can be reliably estimated.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2009 19:49:36 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2010 15:40:48 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Saligrama", "V.", ""], ["Zhao", "M.", ""]]}, {"id": "0910.0349", "submitter": "Claudia Marinica", "authors": "Claudia Marinica (LINA), Fabrice Guillet (LINA), Henri Briand (LINA)", "title": "Post-Processing of Discovered Association Rules Using Ontologies", "comments": null, "journal-ref": "The Second International Workshop on Domain Driven Data Mining\n  (DDDM 2008) in IEEE International Conference of Data Mining, Pisa : Italie\n  (2008)", "doi": "10.1109/ICDMW.2008.87", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Data Mining, the usefulness of association rules is strongly limited by\nthe huge amount of delivered rules. In this paper we propose a new approach to\nprune and filter discovered rules. Using Domain Ontologies, we strengthen the\nintegration of user knowledge in the post-processing task. Furthermore, an\ninteractive and iterative framework is designed to assist the user along the\nanalyzing task. On the one hand, we represent user domain knowledge using a\nDomain Ontology over database. On the other hand, a novel technique is\nsuggested to prune and to filter discovered rules. The proposed framework was\napplied successfully over the client database provided by Nantes Habitat.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2009 08:40:01 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Marinica", "Claudia", "", "LINA"], ["Guillet", "Fabrice", "", "LINA"], ["Briand", "Henri", "", "LINA"]]}, {"id": "0910.0483", "submitter": "Christos Dimitrakakis", "authors": "Christos Dimitrakakis, Aikaterini Mitrokotsa", "title": "Statistical Decision Making for Authentication and Intrusion Detection", "comments": "13 pages, 2 figures, to be presented at ICMLA 2009", "journal-ref": null, "doi": null, "report-no": "IAS-UVA-09-02", "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User authentication and intrusion detection differ from standard\nclassification problems in that while we have data generated from legitimate\nusers, impostor or intrusion data is scarce or non-existent. We review existing\ntechniques for dealing with this problem and propose a novel alternative based\non a principled statistical decision-making view point. We examine the\ntechnique on a toy problem and validate it on complex real-world data from an\nRFID based access control system. The results indicate that it can\nsignificantly outperform the classical world model approach. The method could\nbe more generally useful in other decision-making scenarios where there is a\nlack of adversary data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 19:43:40 GMT"}], "update_date": "2009-12-26", "authors_parsed": [["Dimitrakakis", "Christos", ""], ["Mitrokotsa", "Aikaterini", ""]]}, {"id": "0910.0610", "submitter": "Ambuj  Tewari", "authors": "Sham M. Kakade, Shai Shalev-Shwartz, Ambuj Tewari", "title": "Regularization Techniques for Learning with Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing body of learning problems for which it is natural to\norganize the parameters into matrix, so as to appropriately regularize the\nparameters under some matrix norm (in order to impose some more sophisticated\nprior knowledge). This work describes and analyzes a systematic method for\nconstructing such matrix-based, regularization methods. In particular, we focus\non how the underlying statistical properties of a given problem can help us\ndecide which regularization function is appropriate.\n  Our methodology is based on the known duality fact: that a function is\nstrongly convex with respect to some norm if and only if its conjugate function\nis strongly smooth with respect to the dual norm. This result has already been\nfound to be a key component in deriving and analyzing several learning\nalgorithms. We demonstrate the potential of this framework by deriving novel\ngeneralization and regret bounds for multi-task learning, multi-class learning,\nand kernel learning.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2009 14:48:46 GMT"}, {"version": "v2", "created": "Sun, 17 Oct 2010 21:34:13 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Kakade", "Sham M.", ""], ["Shalev-Shwartz", "Shai", ""], ["Tewari", "Ambuj", ""]]}, {"id": "0910.0668", "submitter": "Ahmed Abdel-Gawad", "authors": "Yuan Qi, Ahmed H. Abdel-Gawad and Thomas P. Minka", "title": "Variable sigma Gaussian processes: An expectation propagation\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide a probabilistic nonparametric representation\nof functions in regression, classification, and other problems. Unfortunately,\nexact learning with GPs is intractable for large datasets. A variety of\napproximate GP methods have been proposed that essentially map the large\ndataset into a small set of basis points. The most advanced of these, the\nvariable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have\nits own length scale. However, VSGP was only derived for regression. We\ndescribe how VSGP can be applied to classification and other problems, by\nderiving it as an expectation propagation algorithm. In this view, sparse GP\napproximations correspond to a KL-projection of the true posterior onto a\ncompact exponential family of GPs. VSGP constitutes one such family, and we\nshow how to enlarge this family to get additional accuracy. In particular, we\nshow that endowing each basis point with its own full covariance matrix\nprovides a significant increase in approximation power.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 03:30:13 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2009 21:52:48 GMT"}], "update_date": "2010-02-23", "authors_parsed": [["Qi", "Yuan", ""], ["Abdel-Gawad", "Ahmed H.", ""], ["Minka", "Thomas P.", ""]]}, {"id": "0910.0820", "submitter": "Rdv Ijcsis", "authors": "Adhistya Erna Permanasari, Dayang Rohaya Awang Rambli, Dhanapal Durai\n  Dominic", "title": "Prediction of Zoonosis Incidence in Human using Seasonal Auto Regressive\n  Integrated Moving Average (SARIMA)", "comments": "8 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 5, No. 1, pp. 103-110, September 2009, USA", "doi": null, "report-no": "ISSn 1947 5500", "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zoonosis refers to the transmission of infectious diseases from animal to\nhuman. The increasing number of zoonosis incidence makes the great losses to\nlives, including humans and animals, and also the impact in social economic. It\nmotivates development of a system that can predict the future number of\nzoonosis occurrences in human. This paper analyses and presents the use of\nSeasonal Autoregressive Integrated Moving Average (SARIMA) method for\ndeveloping a forecasting model that able to support and provide prediction\nnumber of zoonosis human incidence. The dataset for model development was\ncollected on a time series data of human tuberculosis occurrences in United\nStates which comprises of fourteen years of monthly data obtained from a study\npublished by Centers for Disease Control and Prevention (CDC). Several trial\nmodels of SARIMA were compared to obtain the most appropriate model. Then,\ndiagnostic tests were used to determine model validity. The result showed that\nthe SARIMA(9,0,14)(12,1,24)12 is the fittest model. While in the measure of\naccuracy, the selected model achieved 0.062 of Theils U value. It implied that\nthe model was highly accurate and a close fit. It was also indicated the\ncapability of final model to closely represent and made prediction based on the\ntuberculosis historical dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 18:36:11 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2009 11:05:26 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Permanasari", "Adhistya Erna", ""], ["Rambli", "Dayang Rohaya Awang", ""], ["Dominic", "Dhanapal Durai", ""]]}, {"id": "0910.0902", "submitter": "Sajid Siddiqi", "authors": "Sajid M. Siddiqi, Byron Boots, Geoffrey J. Gordon", "title": "Reduced-Rank Hidden Markov Models", "comments": "Updated robot experiment figure, added details on KDE, fixed a couple\n  of errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Reduced-Rank Hidden Markov Model (RR-HMM), a generalization\nof HMMs that can model smooth state evolution as in Linear Dynamical Systems\n(LDSs) as well as non-log-concave predictive distributions as in\ncontinuous-observation HMMs. RR-HMMs assume an m-dimensional latent state and n\ndiscrete observations, with a transition matrix of rank k <= m. This implies\nthe dynamics evolve in a k-dimensional subspace, while the shape of the set of\npredictive distributions is determined by m. Latent state belief is represented\nwith a k-dimensional state vector and inference is carried out entirely in R^k,\nmaking RR-HMMs as computationally efficient as k-state HMMs yet more\nexpressive. To learn RR-HMMs, we relax the assumptions of a recently proposed\nspectral learning algorithm for HMMs (Hsu, Kakade and Zhang 2009) and apply it\nto learn k-dimensional observable representations of rank-k RR-HMMs. The\nalgorithm is consistent and free of local optima, and we extend its performance\nguarantees to cover the RR-HMM case. We show how this algorithm can be used in\nconjunction with a kernel density estimator to efficiently model\nhigh-dimensional multivariate continuous data. We also relax the assumption\nthat single observations are sufficient to disambiguate state, and extend the\nalgorithm accordingly. Experiments on synthetic data and a toy video, as well\nas on a difficult robot vision modeling problem, yield accurate models that\ncompare favorably with standard alternatives in simulation quality and\nprediction capability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 06:00:47 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2009 07:52:37 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2009 23:31:57 GMT"}], "update_date": "2009-12-23", "authors_parsed": [["Siddiqi", "Sajid M.", ""], ["Boots", "Byron", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "0910.0921", "submitter": "Sewoong Oh", "authors": "Raghunandan H. Keshavan, Andrea Montanari, and Sewoong Oh", "title": "Low-rank Matrix Completion with Noisy Observations: a Quantitative\n  Comparison", "comments": "7 pages, 7 figures, 47th Allerton Conference on Communication Control\n  and Computing, 2009, invited paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of significant practical importance, namely, the\nreconstruction of a low-rank data matrix from a small subset of its entries.\nThis problem appears in many areas such as collaborative filtering, computer\nvision and wireless sensor networks. In this paper, we focus on the matrix\ncompletion problem in the case when the observed samples are corrupted by\nnoise. We compare the performance of three state-of-the-art matrix completion\nalgorithms (OptSpace, ADMiRA and FPCA) on a single simulation platform and\npresent numerical results. We show that in practice these efficient algorithms\ncan be used to reconstruct real data matrices, as well as randomly generated\nmatrices, accurately.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 04:41:05 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2009 23:56:31 GMT"}], "update_date": "2009-11-04", "authors_parsed": [["Keshavan", "Raghunandan H.", ""], ["Montanari", "Andrea", ""], ["Oh", "Sewoong", ""]]}, {"id": "0910.1273", "submitter": "Fabien Moutarde", "authors": "Taoufik Bdiri (CAOR), Fabien Moutarde (CAOR), Nicolas Bourdis (CAOR),\n  Bruno Steux (CAOR)", "title": "Adaboost with \"Keypoint Presence Features\" for Real-Time Vehicle Visual\n  Detection", "comments": null, "journal-ref": "16th World Congress on Intelligent Transport Systems (ITSwc'2009),\n  Su\\`ede (2009)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present promising results for real-time vehicle visual detection, obtained\nwith adaBoost using new original ?keypoints presence features?. These\nweak-classifiers produce a boolean response based on presence or absence in the\ntested image of a ?keypoint? (~ a SURF interest point) with a descriptor\nsufficiently similar (i.e. within a given distance) to a reference descriptor\ncharacterizing the feature. A first experiment was conducted on a public image\ndataset containing lateral-viewed cars, yielding 95% recall with 95% precision\non test set. Moreover, analysis of the positions of adaBoost-selected keypoints\nshow that they correspond to a specific part of the object category (such as\n?wheel? or ?side skirt?) and thus have a ?semantic? meaning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 14:26:01 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Bdiri", "Taoufik", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"], ["Bourdis", "Nicolas", "", "CAOR"], ["Steux", "Bruno", "", "CAOR"]]}, {"id": "0910.1293", "submitter": "Fabien Moutarde", "authors": "Bogdan Stanciulescu (CAOR), Amaury Breheret (CAOR), Fabien Moutarde\n  (CAOR)", "title": "Introducing New AdaBoost Features for Real-Time Vehicle Detection", "comments": null, "journal-ref": "COGIS'07 conference on COGnitive systems with Interactive Sensors,\n  Stanford, Palo Alto : United States (2007)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to improve the real-time object detection in complex\nrobotics applications, by exploring new visual features as AdaBoost weak\nclassifiers. These new features are symmetric Haar filters (enforcing global\nhorizontal and vertical symmetry) and N-connexity control points. Experimental\nevaluation on a car database show that the latter appear to provide the best\nresults for the vehicle-detection problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 15:42:03 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Stanciulescu", "Bogdan", "", "CAOR"], ["Breheret", "Amaury", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"]]}, {"id": "0910.1294", "submitter": "Fabien Moutarde", "authors": "Taoufik Bdiri (CAOR), Fabien Moutarde (CAOR), Bruno Steux (CAOR)", "title": "Visual object categorization with new keypoint-based adaBoost features", "comments": null, "journal-ref": "IEEE Symposium on Intelligent Vehicles (IV'2009), XiAn : China\n  (2009)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present promising results for visual object categorization, obtained with\nadaBoost using new original ?keypoints-based features?. These weak-classifiers\nproduce a boolean response based on presence or absence in the tested image of\na ?keypoint? (a kind of SURF interest point) with a descriptor sufficiently\nsimilar (i.e. within a given distance) to a reference descriptor characterizing\nthe feature. A first experiment was conducted on a public image dataset\ncontaining lateral-viewed cars, yielding 95% recall with 95% precision on test\nset. Preliminary tests on a small subset of a pedestrians database also gives\npromising 97% recall with 92 % precision, which shows the generality of our new\nfamily of features. Moreover, analysis of the positions of adaBoost-selected\nkeypoints show that they correspond to a specific part of the object category\n(such as ?wheel? or ?side skirt? in the case of lateral-cars) and thus have a\n?semantic? meaning. We also made a first test on video for detecting vehicles\nfrom adaBoostselected keypoints filtered in real-time from all detected\nkeypoints.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 15:42:30 GMT"}], "update_date": "2009-10-08", "authors_parsed": [["Bdiri", "Taoufik", "", "CAOR"], ["Moutarde", "Fabien", "", "CAOR"], ["Steux", "Bruno", "", "CAOR"]]}, {"id": "0910.1650", "submitter": "Dingyin Xia", "authors": "Dingyin Xia, Fei Wu, Xuqing Zhang, Yueting Zhuang", "title": "Local and global approaches of affinity propagation clustering for large\n  scale data", "comments": "9 pages", "journal-ref": "J Zhejiang Univ Sci A 2008 9(10):1373-1381", "doi": "10.1631/jzus.A0720058", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a new clustering algorithm called 'affinity propagation' (AP) has\nbeen proposed, which efficiently clustered sparsely related data by passing\nmessages between data points. However, we want to cluster large scale data\nwhere the similarities are not sparse in many cases. This paper presents two\nvariants of AP for grouping large scale data with a dense similarity matrix.\nThe local approach is partition affinity propagation (PAP) and the global\nmethod is landmark affinity propagation (LAP). PAP passes messages in the\nsubsets of data first and then merges them as the number of initial step of\niterations; it can effectively reduce the number of iterations of clustering.\nLAP passes messages between the landmark data points first and then clusters\nnon-landmark data points; it is a large global approximation method to speed up\nclustering. Experiments are conducted on many datasets, such as random data\npoints, manifold subspaces, images of faces and Chinese calligraphy, and the\nresults demonstrate that the two approaches are feasible and practicable.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2009 04:55:41 GMT"}], "update_date": "2009-10-12", "authors_parsed": [["Xia", "Dingyin", ""], ["Wu", "Fei", ""], ["Zhang", "Xuqing", ""], ["Zhuang", "Yueting", ""]]}, {"id": "0910.2034", "submitter": "Hugo Zanghi", "authors": "Hugo Zanghi, Franck Picard, Vincent Miele, Christophe Ambroise", "title": "Strategies for online inference of model-based clustering in large and\n  growing networks", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS359 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 2, 687-714", "doi": "10.1214/10-AOAS359", "report-no": "IMS-AOAS-AOAS359", "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we adapt online estimation strategies to perform model-based\nclustering on large networks. Our work focuses on two algorithms, the first\nbased on the SAEM algorithm, and the second on variational methods. These two\nstrategies are compared with existing approaches on simulated and real data. We\nuse the method to decipher the connexion structure of the political websphere\nduring the US political campaign in 2008. We show that our online EM-based\nalgorithms offer a good trade-off between precision and speed, when estimating\nparameters for mixture distributions in the context of random graphs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2009 19:36:16 GMT"}, {"version": "v2", "created": "Wed, 10 Nov 2010 09:02:00 GMT"}], "update_date": "2010-11-11", "authors_parsed": [["Zanghi", "Hugo", ""], ["Picard", "Franck", ""], ["Miele", "Vincent", ""], ["Ambroise", "Christophe", ""]]}, {"id": "0910.2065", "submitter": "Keqin Liu", "authors": "Keqin Liu and Qing Zhao", "title": "Distributed Learning in Multi-Armed Bandit with Multiple Players", "comments": "31 pages, 8 figures, revised paper submitted to IEEE Transactions on\n  Signal Processing, April, 2010, the pre-agreement in the decentralized TDFS\n  policy is eliminated to achieve a complete decentralization among players", "journal-ref": null, "doi": "10.1109/TSP.2010.2062509", "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate and study a decentralized multi-armed bandit (MAB) problem.\nThere are M distributed players competing for N independent arms. Each arm,\nwhen played, offers i.i.d. reward according to a distribution with an unknown\nparameter. At each time, each player chooses one arm to play without exchanging\nobservations or any information with other players. Players choosing the same\narm collide, and, depending on the collision model, either no one receives\nreward or the colliding players share the reward in an arbitrary way. We show\nthat the minimum system regret of the decentralized MAB grows with time at the\nsame logarithmic order as in the centralized counterpart where players act\ncollectively as a single entity by exchanging observations and making decisions\njointly. A decentralized policy is constructed to achieve this optimal order\nwhile ensuring fairness among players and without assuming any pre-agreement or\ninformation exchange among players. Based on a Time Division Fair Sharing\n(TDFS) of the M best arms, the proposed policy is constructed and its order\noptimality is proven under a general reward model. Furthermore, the basic\nstructure of the TDFS policy can be used with any order-optimal single-player\npolicy to achieve order optimality in the decentralized setting. We also\nestablish a lower bound on the system regret growth rate for a general class of\ndecentralized polices, to which the proposed policy belongs. This problem finds\npotential applications in cognitive radio networks, multi-channel communication\nsystems, multi-agent systems, web search and advertising, and social networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 00:50:19 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2009 17:26:06 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2010 18:04:14 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Liu", "Keqin", ""], ["Zhao", "Qing", ""]]}, {"id": "0910.2240", "submitter": "Zhu Han", "authors": "Zhu Han, Rong Zheng, Vincent H. Poor", "title": "Repeated Auctions with Learning for Spectrum Access in Cognitive Radio\n  Networks", "comments": "This paper is presented in Allerton Conference on Communication,\n  Control, and Computing 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, spectrum access in cognitive radio networks is modeled as a\nrepeated auction game subject to monitoring and entry costs. For secondary\nusers, sensing costs are incurred as the result of primary users' activity.\nFurthermore, each secondary user pays the cost of transmissions upon successful\nbidding for a channel. Knowledge regarding other secondary users' activity is\nlimited due to the distributed nature of the network. The resulting formulation\nis thus a dynamic game with incomplete information. In this paper, an efficient\nbidding learning algorithm is proposed based on the outcome of past\ntransactions. As demonstrated through extensive simulations, the proposed\ndistributed scheme outperforms a myopic one-stage algorithm, and can achieve a\ngood balance between efficiency and fairness.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 20:16:16 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Han", "Zhu", ""], ["Zheng", "Rong", ""], ["Poor", "Vincent H.", ""]]}, {"id": "0910.2279", "submitter": "Chunhua Shen", "authors": "Chunhua Shen, Junae Kim, Lei Wang, Anton van den Hengel", "title": "Positive Semidefinite Metric Learning with Boosting", "comments": "11 pages, Twenty-Third Annual Conference on Neural Information\n  Processing Systems (NIPS 2009), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of appropriate distance metrics is a critical problem in image\nclassification and retrieval. In this work, we propose a boosting-based\ntechnique, termed \\BoostMetric, for learning a Mahalanobis distance metric. One\nof the primary difficulties in learning such a metric is to ensure that the\nMahalanobis matrix remains positive semidefinite. Semidefinite programming is\nsometimes used to enforce this constraint, but does not scale well.\n\\BoostMetric is instead based on a key observation that any positive\nsemidefinite matrix can be decomposed into a linear positive combination of\ntrace-one rank-one matrices. \\BoostMetric thus uses rank-one positive\nsemidefinite matrices as weak learners within an efficient and scalable\nboosting-based learning process. The resulting method is easy to implement,\ndoes not require tuning, and can accommodate various types of constraints.\nExperiments on various datasets show that the proposed algorithm compares\nfavorably to those state-of-the-art methods in terms of classification accuracy\nand running time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 00:54:31 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Shen", "Chunhua", ""], ["Kim", "Junae", ""], ["Wang", "Lei", ""], ["Hengel", "Anton van den", ""]]}, {"id": "0910.2540", "submitter": "M. Tariq Banday", "authors": "M. Tariq Banday and Tariq R. Jan", "title": "Effectiveness and Limitations of Statistical Spam Filters", "comments": "International Conference on New Trends in Statistics and\n  Optimization, Organized by Department of Statistics, University of Kashmir,\n  Srinagar, India, from 20th to 23rd October, 2008", "journal-ref": "International Conference on New Trends in Statistics and\n  Optimization, Organized by Department of Statistics, University of Kashmir,\n  Srinagar, India, from 20th to 23rd October, 2008", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss the techniques involved in the design of the famous\nstatistical spam filters that include Naive Bayes, Term Frequency-Inverse\nDocument Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes\nAdditive Regression Tree. We compare these techniques with each other in terms\nof accuracy, recall, precision, etc. Further, we discuss the effectiveness and\nlimitations of statistical filters in filtering out various types of spam from\nlegitimate e-mails.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 07:43:03 GMT"}], "update_date": "2009-10-15", "authors_parsed": [["Banday", "M. Tariq", ""], ["Jan", "Tariq R.", ""]]}, {"id": "0910.3713", "submitter": "Brendan Juba", "authors": "Brendan Juba", "title": "On Learning Finite-State Quantum Sources", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the complexity of learning the distributions produced by\nfinite-state quantum sources. We show how prior techniques for learning hidden\nMarkov models can be adapted to the quantum generator model to find that the\nanalogous state of affairs holds: information-theoretically, a polynomial\nnumber of samples suffice to approximately identify the distribution, but\ncomputationally, the problem is as hard as learning parities with noise, a\nnotorious open question in computational learning theory.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 21:55:11 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Juba", "Brendan", ""]]}, {"id": "0910.4627", "submitter": "Francis Bach", "authors": "Francis Bach (INRIA Rocquencourt)", "title": "Self-concordant analysis for logistic regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the non-asymptotic theoretical work in regression is carried out for\nthe square loss, where estimators can be obtained through closed-form\nexpressions. In this paper, we use and extend tools from the convex\noptimization literature, namely self-concordant functions, to provide simple\nextensions of theoretical results for the square loss to the logistic loss. We\napply the extension techniques to logistic regression with regularization by\nthe $\\ell_2$-norm and regularization by the $\\ell_1$-norm, showing that new\nresults for binary classification through logistic regression can be easily\nderived from corresponding results for least-squares regression.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2009 07:10:24 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Bach", "Francis", "", "INRIA Rocquencourt"]]}, {"id": "0910.4683", "submitter": "Fedor Zhdanov", "authors": "Fedor Zhdanov and Vladimir Vovk", "title": "Competing with Gaussian linear experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online regression. We prove a theoretical bound on\nthe square loss of Ridge Regression. We do not make any assumptions about input\nvectors or outcomes. We also show that Bayesian Ridge Regression can be thought\nof as an online algorithm competing with all the Gaussian linear experts.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2009 22:40:40 GMT"}, {"version": "v2", "created": "Mon, 10 May 2010 23:01:30 GMT"}], "update_date": "2010-05-12", "authors_parsed": [["Zhdanov", "Fedor", ""], ["Vovk", "Vladimir", ""]]}, {"id": "0910.5260", "submitter": "Sewoong Oh", "authors": "Raghunandan H. Keshavan, Sewoong Oh", "title": "A Gradient Descent Algorithm on the Grassman Manifold for Matrix\n  Completion", "comments": "26 pages, 15 figures", "journal-ref": null, "doi": "10.1016/j.trc.2012.12.007", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reconstructing a low-rank matrix from a small\nsubset of its entries. In this paper, we describe the implementation of an\nefficient algorithm called OptSpace, based on singular value decomposition\nfollowed by local manifold optimization, for solving the low-rank matrix\ncompletion problem. It has been shown that if the number of revealed entries is\nlarge enough, the output of singular value decomposition gives a good estimate\nfor the original matrix, so that local optimization reconstructs the correct\nmatrix with high probability. We present numerical results which show that this\nalgorithm can reconstruct the low rank matrix exactly from a very small subset\nof its entries. We further study the robustness of the algorithm with respect\nto noise, and its performance on actual collaborative filtering datasets.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2009 22:19:31 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2009 23:35:13 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Keshavan", "Raghunandan H.", ""], ["Oh", "Sewoong", ""]]}, {"id": "0910.5454", "submitter": "Patrick C. McGuire", "authors": "P.C. McGuire, C. Gross, L. Wendt, A. Bonnici, V. Souza-Egipsy, J.\n  Ormo, E. Diaz-Martinez, B.H. Foing, R. Bose, S. Walter, M. Oesker, J. Ontrup,\n  R. Haschke, H. Ritter", "title": "The Cyborg Astrobiologist: Testing a Novelty-Detection Algorithm on Two\n  Mobile Exploration Systems at Rivas Vaciamadrid in Spain and at the Mars\n  Desert Research Station in Utah", "comments": "28 pages, 12 figures, accepted for publication in the International\n  Journal of Astrobiology", "journal-ref": "International Journal of Astrobiology, Vol. 9, pp. 11-27 (2010).", "doi": "10.1017/S1473550409990358", "report-no": null, "categories": "cs.CV astro-ph.EP astro-ph.IM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (ABRIDGED) In previous work, two platforms have been developed for testing\ncomputer-vision algorithms for robotic planetary exploration (McGuire et al.\n2004b,2005; Bartolo et al. 2007). The wearable-computer platform has been\ntested at geological and astrobiological field sites in Spain (Rivas\nVaciamadrid and Riba de Santiuste), and the phone-camera has been tested at a\ngeological field site in Malta. In this work, we (i) apply a Hopfield\nneural-network algorithm for novelty detection based upon color, (ii) integrate\na field-capable digital microscope on the wearable computer platform, (iii)\ntest this novelty detection with the digital microscope at Rivas Vaciamadrid,\n(iv) develop a Bluetooth communication mode for the phone-camera platform, in\norder to allow access to a mobile processing computer at the field sites, and\n(v) test the novelty detection on the Bluetooth-enabled phone-camera connected\nto a netbook computer at the Mars Desert Research Station in Utah. This systems\nengineering and field testing have together allowed us to develop a real-time\ncomputer-vision system that is capable, for example, of identifying lichens as\nnovel within a series of images acquired in semi-arid desert environments. We\nacquired sequences of images of geologic outcrops in Utah and Spain consisting\nof various rock types and colors to test this algorithm. The algorithm robustly\nrecognized previously-observed units by their color, while requiring only a\nsingle image or a few images to learn colors as familiar, demonstrating its\nfast learning capability.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 18:26:39 GMT"}], "update_date": "2010-01-08", "authors_parsed": [["McGuire", "P. C.", ""], ["Gross", "C.", ""], ["Wendt", "L.", ""], ["Bonnici", "A.", ""], ["Souza-Egipsy", "V.", ""], ["Ormo", "J.", ""], ["Diaz-Martinez", "E.", ""], ["Foing", "B. H.", ""], ["Bose", "R.", ""], ["Walter", "S.", ""], ["Oesker", "M.", ""], ["Ontrup", "J.", ""], ["Haschke", "R.", ""], ["Ritter", "H.", ""]]}, {"id": "0910.5461", "submitter": "Manqi Zhao", "authors": "Manqi Zhao and Venkatesh Saligrama", "title": "Anomaly Detection with Score functions based on Nearest Neighbor Graphs", "comments": "10 pages, 10 figures, accepted by NIPS 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel non-parametric adaptive anomaly detection algorithm for\nhigh dimensional data based on score functions derived from nearest neighbor\ngraphs on $n$-point nominal data. Anomalies are declared whenever the score of\na test sample falls below $\\alpha$, which is supposed to be the desired false\nalarm level. The resulting anomaly detector is shown to be asymptotically\noptimal in that it is uniformly most powerful for the specified false alarm\nlevel, $\\alpha$, for the case when the anomaly density is a mixture of the\nnominal and a known density. Our algorithm is computationally efficient, being\nlinear in dimension and quadratic in data size. It does not require choosing\ncomplicated tuning parameters or function approximation classes and it can\nadapt to local structure such as local change in dimensionality. We demonstrate\nthe algorithm on both artificial and real data sets in high dimensional feature\nspaces.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 18:46:41 GMT"}], "update_date": "2009-10-29", "authors_parsed": [["Zhao", "Manqi", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "0910.5761", "submitter": "Jose Bento", "authors": "Jose Bento, Andrea Montanari", "title": "Which graphical models are difficult to learn?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the structure of Ising models (pairwise\nbinary Markov random fields) from i.i.d. samples. While several methods have\nbeen proposed to accomplish this task, their relative merits and limitations\nremain somewhat obscure. By analyzing a number of concrete examples, we show\nthat low-complexity algorithms systematically fail when the Markov random field\ndevelops long-range correlations. More precisely, this phenomenon appears to be\nrelated to the Ising model phase transition (although it does not coincide with\nit).\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 01:10:44 GMT"}], "update_date": "2009-11-07", "authors_parsed": [["Bento", "Jose", ""], ["Montanari", "Andrea", ""]]}, {"id": "0910.5932", "submitter": "Prateek Jain", "authors": "Prateek Jain, Brian Kulis, Jason V. Davis, Inderjit S. Dhillon", "title": "Metric and Kernel Learning using a Linear Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric and kernel learning are important in several machine learning\napplications. However, most existing metric learning algorithms are limited to\nlearning metrics over low-dimensional data, while existing kernel learning\nalgorithms are often limited to the transductive setting and do not generalize\nto new data points. In this paper, we study metric learning as a problem of\nlearning a linear transformation of the input data. We show that for\nhigh-dimensional data, a particular framework for learning a linear\ntransformation of the data based on the LogDet divergence can be efficiently\nkernelized to learn a metric (or equivalently, a kernel function) over an\narbitrarily high dimensional space. We further demonstrate that a wide class of\nconvex loss functions for learning linear transformations can similarly be\nkernelized, thereby considerably expanding the potential applications of metric\nlearning. We demonstrate our learning approach by applying it to large-scale\nreal world problems in computer vision and text mining.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 18:19:03 GMT"}], "update_date": "2009-11-02", "authors_parsed": [["Jain", "Prateek", ""], ["Kulis", "Brian", ""], ["Davis", "Jason V.", ""], ["Dhillon", "Inderjit S.", ""]]}]