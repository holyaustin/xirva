[{"id": "1103.0086", "submitter": "Xin Liu", "authors": "Xin Liu and Gilles Tredan and Anwitaman Datta", "title": "A generic trust framework for large-scale open systems using machine\n  learning", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many large scale distributed systems and on the web, agents need to\ninteract with other unknown agents to carry out some tasks or transactions. The\nability to reason about and assess the potential risks in carrying out such\ntransactions is essential for providing a safe and reliable environment. A\ntraditional approach to reason about the trustworthiness of a transaction is to\ndetermine the trustworthiness of the specific agent involved, derived from the\nhistory of its behavior. As a departure from such traditional trust models, we\npropose a generic, machine learning approach based trust framework where an\nagent uses its own previous transactions (with other agents) to build a\nknowledge base, and utilize this to assess the trustworthiness of a transaction\nbased on associated features, which are capable of distinguishing successful\ntransactions from unsuccessful ones. These features are harnessed using\nappropriate machine learning algorithms to extract relationships between the\npotential transaction and previous transactions. The trace driven experiments\nusing real auction dataset show that this approach provides good accuracy and\nis highly efficient compared to other trust mechanisms, especially when\nhistorical information of the specific agent is rare, incomplete or inaccurate.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 06:03:15 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Liu", "Xin", ""], ["Tredan", "Gilles", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1103.0102", "submitter": "Dacheng Tao", "authors": "Tianyi Zhou and Dacheng Tao", "title": "Multi-label Learning via Structured Decomposition and Group Sparsity", "comments": "13 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In multi-label learning, each sample is associated with several labels.\nExisting works indicate that exploring correlations between labels improve the\nprediction performance. However, embedding the label correlations into the\ntraining process significantly increases the problem size. Moreover, the\nmapping of the label structure in the feature space is not clear. In this\npaper, we propose a novel multi-label learning method \"Structured Decomposition\n+ Group Sparsity (SDGS)\". In SDGS, we learn a feature subspace for each label\nfrom the structured decomposition of the training data, and predict the labels\nof a new sample from its group sparse representation on the multi-subspace\nobtained from the structured decomposition. In particular, in the training\nstage, we decompose the data matrix $X\\in R^{n\\times p}$ as\n$X=\\sum_{i=1}^kL^i+S$, wherein the rows of $L^i$ associated with samples that\nbelong to label $i$ are nonzero and consist a low-rank matrix, while the other\nrows are all-zeros, the residual $S$ is a sparse matrix. The row space of $L_i$\nis the feature subspace corresponding to label $i$. This decomposition can be\nefficiently obtained via randomized optimization. In the prediction stage, we\nestimate the group sparse representation of a new sample on the multi-subspace\nvia group \\emph{lasso}. The nonzero representation coefficients tend to\nconcentrate on the subspaces of labels that the sample belongs to, and thus an\neffective prediction can be obtained. We evaluate SDGS on several real datasets\nand compare it with popular methods. Results verify the effectiveness and\nefficiency of SDGS.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 08:15:28 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2011 00:00:13 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Zhou", "Tianyi", ""], ["Tao", "Dacheng", ""]]}, {"id": "1103.0398", "submitter": "Ronan Collobert", "authors": "Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray\n  Kavukcuoglu, Pavel Kuksa", "title": "Natural Language Processing (almost) from Scratch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified neural network architecture and learning algorithm that\ncan be applied to various natural language processing tasks including:\npart-of-speech tagging, chunking, named entity recognition, and semantic role\nlabeling. This versatility is achieved by trying to avoid task-specific\nengineering and therefore disregarding a lot of prior knowledge. Instead of\nexploiting man-made input features carefully optimized for each task, our\nsystem learns internal representations on the basis of vast amounts of mostly\nunlabeled training data. This work is then used as a basis for building a\nfreely available tagging system with good performance and minimal computational\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2011 11:34:50 GMT"}], "update_date": "2011-03-03", "authors_parsed": [["Collobert", "Ronan", ""], ["Weston", "Jason", ""], ["Bottou", "Leon", ""], ["Karlen", "Michael", ""], ["Kavukcuoglu", "Koray", ""], ["Kuksa", "Pavel", ""]]}, {"id": "1103.0598", "submitter": "Constantinos Daskalakis", "authors": "Constantinos Daskalakis, Ilias Diakonikolas, Rocco A. Servedio", "title": "Learning transformed product distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an unknown product distribution $X$ over\n$\\{0,1\\}^n$ using samples $f(X)$ where $f$ is a \\emph{known} transformation\nfunction. Each choice of a transformation function $f$ specifies a learning\nproblem in this framework.\n  Information-theoretic arguments show that for every transformation function\n$f$ the corresponding learning problem can be solved to accuracy $\\eps$, using\n$\\tilde{O}(n/\\eps^2)$ examples, by a generic algorithm whose running time may\nbe exponential in $n.$ We show that this learning problem can be\ncomputationally intractable even for constant $\\eps$ and rather simple\ntransformation functions. Moreover, the above sample complexity bound is nearly\noptimal for the general problem, as we give a simple explicit linear\ntransformation function $f(x)=w \\cdot x$ with integer weights $w_i \\leq n$ and\nprove that the corresponding learning problem requires $\\Omega(n)$ samples.\n  As our main positive result we give a highly efficient algorithm for learning\na sum of independent unknown Bernoulli random variables, corresponding to the\ntransformation function $f(x)= \\sum_{i=1}^n x_i$. Our algorithm learns to\n$\\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\\eps)$ number of\nsamples that is independent of $n.$ We also give an efficient algorithm that\nuses $\\log n \\cdot \\poly(1/\\eps)$ samples but has running time that is only\n$\\poly(\\log n, 1/\\eps).$\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2011 02:46:51 GMT"}], "update_date": "2011-03-04", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Diakonikolas", "Ilias", ""], ["Servedio", "Rocco A.", ""]]}, {"id": "1103.0769", "submitter": "Vassilis Kekatos", "authors": "Vassilis Kekatos and Georgios B. Giannakis", "title": "Sparse Volterra and Polynomial Regression Models: Recoverability and\n  Estimation", "comments": "20 pages, to appear in IEEE Trans. on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2011.2165952", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volterra and polynomial regression models play a major role in nonlinear\nsystem identification and inference tasks. Exciting applications ranging from\nneuroscience to genome-wide association analysis build on these models with the\nadditional requirement of parsimony. This requirement has high interpretative\nvalue, but unfortunately cannot be met by least-squares based or kernel\nregression methods. To this end, compressed sampling (CS) approaches, already\nsuccessful in linear regression settings, can offer a viable alternative. The\nviability of CS for sparse Volterra and polynomial models is the core theme of\nthis work. A common sparse regression task is initially posed for the two\nmodels. Building on (weighted) Lasso-based schemes, an adaptive RLS-type\nalgorithm is developed for sparse polynomial regressions. The identifiability\nof polynomial models is critically challenged by dimensionality. However,\nfollowing the CS principle, when these models are sparse, they could be\nrecovered by far fewer measurements. To quantify the sufficient number of\nmeasurements for a given level of sparsity, restricted isometry properties\n(RIP) are investigated in commonly met polynomial regression settings,\ngeneralizing known results for their linear counterparts. The merits of the\nnovel (weighted) adaptive CS algorithms to sparse polynomial modeling are\nverified through synthetic as well as real data tests for genotype-phenotype\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2011 20:21:28 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 00:03:45 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Kekatos", "Vassilis", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1103.0890", "submitter": "Qi Mao", "authors": "Qi Mao, Ivor W. Tsang", "title": "Efficient Multi-Template Learning for Structured Prediction", "comments": null, "journal-ref": "Efficient Multi-Template Learning for Structured Prediction. IEEE\n  Transactions on Neural Networks and Learning Systems, 24(2): 248 - 261, Feb\n  2013", "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional random field (CRF) and Structural Support Vector Machine\n(Structural SVM) are two state-of-the-art methods for structured prediction\nwhich captures the interdependencies among output variables. The success of\nthese methods is attributed to the fact that their discriminative models are\nable to account for overlapping features on the whole input observations. These\nfeatures are usually generated by applying a given set of templates on labeled\ndata, but improper templates may lead to degraded performance. To alleviate\nthis issue, in this paper, we propose a novel multiple template learning\nparadigm to learn structured prediction and the importance of each template\nsimultaneously, so that hundreds of arbitrary templates could be added into the\nlearning model without caution. This paradigm can be formulated as a special\nmultiple kernel learning problem with exponential number of constraints. Then\nwe introduce an efficient cutting plane algorithm to solve this problem in the\nprimal, and its convergence is presented. We also evaluate the proposed\nlearning paradigm on two widely-studied structured prediction tasks,\n\\emph{i.e.} sequence labeling and dependency parsing. Extensive experimental\nresults show that the proposed method outperforms CRFs and Structural SVMs due\nto exploiting the importance of each template. Our complexity analysis and\nempirical results also show that our proposed method is more efficient than\nOnlineMKL on very sparse and high-dimensional data. We further extend this\nparadigm for structured prediction using generalized $p$-block norm\nregularization with $p>1$, and experiments show competitive performances when\n$p \\in [1,2)$.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 13:08:59 GMT"}, {"version": "v2", "created": "Sat, 4 May 2013 13:57:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mao", "Qi", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1103.0941", "submitter": "Cosma Rohilla Shalizi", "authors": "Daniel J. McDonald, Cosma Rohilla Shalizi, Mark Schervish (Carnegie\n  Mellon University)", "title": "Estimating $\\beta$-mixing coefficients", "comments": "9 pages, accepted by AIStats. CMU Statistics Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on statistical learning for time series assumes the asymptotic\nindependence or ``mixing' of the data-generating process. These mixing\nassumptions are never tested, nor are there methods for estimating mixing rates\nfrom data. We give an estimator for the $\\beta$-mixing rate based on a single\nstationary sample path and show it is $L_1$-risk consistent.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 16:29:04 GMT"}], "update_date": "2011-03-07", "authors_parsed": [["McDonald", "Daniel J.", "", "Carnegie\n  Mellon University"], ["Shalizi", "Cosma Rohilla", "", "Carnegie\n  Mellon University"], ["Schervish", "Mark", "", "Carnegie\n  Mellon University"]]}, {"id": "1103.0942", "submitter": "Daniel McDonald", "authors": "Daniel J. McDonald, Cosma Rohilla Shalizi, Mark Schervish (Carnegie\n  Mellon University)", "title": "Generalization error bounds for stationary autoregressive models", "comments": "10 pages, 3 figures. CMU Statistics Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive generalization error bounds for stationary univariate\nautoregressive (AR) models. We show that imposing stationarity is enough to\ncontrol the Gaussian complexity without further regularization. This lets us\nuse structural risk minimization for model selection. We demonstrate our\nmethods by predicting interest rate movements.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 16:38:55 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2011 19:08:19 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["McDonald", "Daniel J.", "", "Carnegie\n  Mellon University"], ["Shalizi", "Cosma Rohilla", "", "Carnegie\n  Mellon University"], ["Schervish", "Mark", "", "Carnegie\n  Mellon University"]]}, {"id": "1103.0949", "submitter": "Cosma Rohilla Shalizi", "authors": "Cosma Rohilla Shalizi, Abigail Z. Jacobs, Kristina Lisa Klinkner,\n  Aaron Clauset", "title": "Adapting to Non-stationarity with Growing Expert Ensembles", "comments": "9 pages, 1 figure; CMU Statistics Technical Report. v2: Added\n  empirical example, revised discussion of related work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with time series with complex non-stationarities, low\nretrospective regret on individual realizations is a more appropriate goal than\nlow prospective risk in expectation. Online learning algorithms provide\npowerful guarantees of this form, and have often been proposed for use with\nnon-stationary processes because of their ability to switch between different\nforecasters or ``experts''. However, existing methods assume that the set of\nexperts whose forecasts are to be combined are all given at the start, which is\nnot plausible when dealing with a genuinely historical or evolutionary system.\nWe show how to modify the ``fixed shares'' algorithm for tracking the best\nexpert to cope with a steadily growing set of experts, obtained by fitting new\nmodels to new data as it becomes available, and obtain regret bounds for the\ngrowing ensemble.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 17:04:20 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2011 23:25:41 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Shalizi", "Cosma Rohilla", ""], ["Jacobs", "Abigail Z.", ""], ["Klinkner", "Kristina Lisa", ""], ["Clauset", "Aaron", ""]]}, {"id": "1103.1013", "submitter": "Qi Mao", "authors": "Qi Mao, Ivor W. Tsang", "title": "A Feature Selection Method for Multivariate Performance Measures", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2012", "doi": "10.1109/TPAMI.2012.266", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection with specific multivariate performance measures is the key\nto the success of many applications, such as image retrieval and text\nclassification. The existing feature selection methods are usually designed for\nclassification error. In this paper, we propose a generalized sparse\nregularizer. Based on the proposed regularizer, we present a unified feature\nselection framework for general loss functions. In particular, we study the\nnovel feature selection paradigm by optimizing multivariate performance\nmeasures. The resultant formulation is a challenging problem for\nhigh-dimensional data. Hence, a two-layer cutting plane algorithm is proposed\nto solve this problem, and the convergence is presented. In addition, we adapt\nthe proposed method to optimize multivariate measures for multiple instance\nlearning problems. The analyses by comparing with the state-of-the-art feature\nselection methods show that the proposed method is superior to others.\nExtensive experiments on large-scale and high-dimensional real world datasets\nshow that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a\nsmall subset of features, and achieves significantly improved performances over\nSVM$^{perf}$ in terms of $F_1$-score.\n", "versions": [{"version": "v1", "created": "Sat, 5 Mar 2011 07:10:41 GMT"}, {"version": "v2", "created": "Sat, 4 May 2013 14:48:06 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mao", "Qi", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1103.1417", "submitter": "Adel Javanmard", "authors": "Adel Javanmard, Andrea Montanari", "title": "Localization from Incomplete Noisy Distance Measurements", "comments": "46 pages, 8 figures, numerical experiments added. Journal version\n  (v1,v2: Conference versions, ISIT 2011); Journal of Foundations of\n  Computational Mathematics, 2012", "journal-ref": null, "doi": "10.1007/s10208-012-9129-5", "report-no": null, "categories": "math.ST cs.LG cs.SY math.OC math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of positioning a cloud of points in the Euclidean\nspace $\\mathbb{R}^d$, using noisy measurements of a subset of pairwise\ndistances. This task has applications in various areas, such as sensor network\nlocalization and reconstruction of protein conformations from NMR measurements.\nAlso, it is closely related to dimensionality reduction problems and manifold\nlearning, where the goal is to learn the underlying global geometry of a data\nset using local (or partial) metric information. Here we propose a\nreconstruction algorithm based on semidefinite programming. For a random\ngeometric graph model and uniformly bounded noise, we provide a precise\ncharacterization of the algorithm's performance: In the noiseless case, we find\na radius $r_0$ beyond which the algorithm reconstructs the exact positions (up\nto rigid transformations). In the presence of noise, we obtain upper and lower\nbounds on the reconstruction error that match up to a factor that depends only\non the dimension $d$, and the average degree of the nodes in the graph.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 02:34:40 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2011 03:40:10 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2011 06:15:01 GMT"}, {"version": "v4", "created": "Wed, 21 Nov 2012 02:31:50 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Javanmard", "Adel", ""], ["Montanari", "Andrea", ""]]}, {"id": "1103.1625", "submitter": "Jeff M Phillips", "authors": "Jeff M. Phillips, Suresh Venkatasubramanian", "title": "A Gentle Introduction to the Kernel Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document reviews the definition of the kernel distance, providing a\ngentle introduction tailored to a reader with background in theoretical\ncomputer science, but limited exposure to technology more common to machine\nlearning, functional analysis and geometric measure theory. The key aspect of\nthe kernel distance developed here is its interpretation as an L_2 distance\nbetween probability measures or various shapes (e.g. point sets, curves,\nsurfaces) embedded in a vector space (specifically an RKHS). This structure\nenables several elegant and efficient solutions to data analysis problems. We\nconclude with a glimpse into the mathematical underpinnings of this measure,\nhighlighting its recent independent evolution in two separate fields.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2011 20:50:55 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2011 23:22:09 GMT"}], "update_date": "2011-03-11", "authors_parsed": [["Phillips", "Jeff M.", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1103.1689", "submitter": "Morteza Ibrahimi", "authors": "Jos\\'e Bento and Morteza Ibrahimi and Andrea Montanari", "title": "Information Theoretic Limits on Learning Stochastic Differential\n  Equations", "comments": "6 pages, 2 figures, conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST q-fin.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the problem of learning the drift coefficient of a stochastic\ndifferential equation from a sample path. In this paper, we assume that the\ndrift is parametrized by a high dimensional vector. We address the question of\nhow long the system needs to be observed in order to learn this vector of\nparameters. We prove a general lower bound on this time complexity by using a\ncharacterization of mutual information as time integral of conditional\nvariance, due to Kadota, Zakai, and Ziv. This general lower bound is applied to\nspecific classes of linear and non-linear stochastic differential equations. In\nthe linear case, the problem under consideration is the one of learning a\nmatrix of interaction coefficients. We evaluate our lower bound for ensembles\nof sparse and dense random matrices. The resulting estimates match the\nqualitative behavior of upper bounds achieved by computationally efficient\nprocedures.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2011 02:03:17 GMT"}], "update_date": "2011-03-10", "authors_parsed": [["Bento", "Jos\u00e9", ""], ["Ibrahimi", "Morteza", ""], ["Montanari", "Andrea", ""]]}, {"id": "1103.2068", "submitter": "Tamara Kolda", "authors": "Justin D. Basilico and M. Arthur Munson and Tamara G. Kolda and Kevin\n  R. Dixon and W. Philip Kegelmeyer", "title": "COMET: A Recipe for Learning and Using Large Ensembles on Massive Data", "comments": null, "journal-ref": "ICDM 2011: Proceedings of the 2011 IEEE International Conference\n  on Data Mining, pp. 41-50, 2011", "doi": "10.1109/ICDM.2011.39", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COMET is a single-pass MapReduce algorithm for learning on large-scale data.\nIt builds multiple random forest ensembles on distributed blocks of data and\nmerges them into a mega-ensemble. This approach is appropriate when learning\nfrom massive-scale data that is too large to fit on a single machine. To get\nthe best accuracy, IVoting should be used instead of bagging to generate the\ntraining subset for each decision tree in the random forest. Experiments with\ntwo large datasets (5GB and 50GB compressed) show that COMET compares favorably\n(in both accuracy and training time) to learning on a subsample of data using a\nserial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble\nevaluation which dynamically decides how many ensemble members to evaluate per\ndata point; this can reduce evaluation cost by 100X or more.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2011 16:15:42 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2011 16:20:45 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["Basilico", "Justin D.", ""], ["Munson", "M. Arthur", ""], ["Kolda", "Tamara G.", ""], ["Dixon", "Kevin R.", ""], ["Kegelmeyer", "W. Philip", ""]]}, {"id": "1103.2491", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu, Hamidou Tembine and Tamer Basar", "title": "Heterogeneous Learning in Zero-Sum Stochastic Games with Incomplete\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.SY math.OC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Learning algorithms are essential for the applications of game theory in a\nnetworking environment. In dynamic and decentralized settings where the\ntraffic, topology and channel states may vary over time and the communication\nbetween agents is impractical, it is important to formulate and study games of\nincomplete information and fully distributed learning algorithms which for each\nagent requires a minimal amount of information regarding the remaining agents.\nIn this paper, we address this major challenge and introduce heterogeneous\nlearning schemes in which each agent adopts a distinct learning pattern in the\ncontext of games with incomplete information. We use stochastic approximation\ntechniques to show that the heterogeneous learning schemes can be studied in\nterms of their deterministic ordinary differential equation (ODE) counterparts.\nDepending on the learning rates of the players, these ODEs could be different\nfrom the standard replicator dynamics, (myopic) best response (BR) dynamics,\nlogit dynamics, and fictitious play dynamics. We apply the results to a class\nof security games in which the attacker and the defender adopt different\nlearning schemes due to differences in their rationality levels and the\ninformation they acquire.\n", "versions": [{"version": "v1", "created": "Sun, 13 Mar 2011 03:18:55 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Zhu", "Quanyan", ""], ["Tembine", "Hamidou", ""], ["Basar", "Tamer", ""]]}, {"id": "1103.2832", "submitter": "Yoshua Bengio", "authors": "Michael Mandel, Razvan Pascanu, Hugo Larochelle and Yoshua Bengio", "title": "Autotagging music with conditional restricted Boltzmann machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two applications of conditional restricted Boltzmann\nmachines (CRBMs) to the task of autotagging music. The first consists of\ntraining a CRBM to predict tags that a user would apply to a clip of a song\nbased on tags already applied by other users. By learning the relationships\nbetween tags, this model is able to pre-process training data to significantly\nimprove the performance of a support vector machine (SVM) autotagging. The\nsecond is the use of a discriminative RBM, a type of CRBM, to autotag music. By\nsimultaneously exploiting the relationships among tags and between tags and\naudio-based features, this model is able to significantly outperform SVMs,\nlogistic regression, and multi-layer perceptrons. In order to be applied to\nthis problem, the discriminative RBM was generalized to the multi-label setting\nand four different learning algorithms for it were evaluated, the first such\nin-depth analysis of which we are aware.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2011 02:39:31 GMT"}], "update_date": "2011-03-16", "authors_parsed": [["Mandel", "Michael", ""], ["Pascanu", "Razvan", ""], ["Larochelle", "Hugo", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1103.3095", "submitter": "Satyaki Mahalanabis", "authors": "Satyaki Mahalanabis", "title": "A note on active learning for smooth problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the disagreement coefficient of certain smooth hypothesis\nclasses is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby\nanswering a question posed in \\cite{friedman09}.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2011 04:54:58 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mahalanabis", "Satyaki", ""]]}, {"id": "1103.3541", "submitter": "Panayotis Mertikopoulos", "authors": "Panayotis Mertikopoulos and Elena V. Belmega and Aris L. Moustakas and\n  Samson Lasaulce", "title": "Distributed Learning Policies for Power Allocation in Multiple Access\n  Channels", "comments": "11 pages, 8 figures. Revised manuscript structure and added more\n  material and figures for the case of stochastically fluctuating channels.\n  This version will appear in the IEEE Journal on Selected Areas in\n  Communication, Special Issue on Game Theory in Wireless Communications", "journal-ref": "IEEE Journal on Selected Areas in Communication, vol. 30, no. 1,\n  pp. 1-11, January 2012", "doi": "10.1109/JSAC.2012.1201xx", "report-no": null, "categories": "cs.GT cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the problem of distributed power allocation for orthogonal\nmultiple access channels by considering a continuous non-cooperative game whose\nstrategy space represents the users' distribution of transmission power over\nthe network's channels. When the channels are static, we find that this game\nadmits an exact potential function and this allows us to show that it has a\nunique equilibrium almost surely. Furthermore, using the game's potential\nproperty, we derive a modified version of the replicator dynamics of\nevolutionary game theory which applies to this continuous game, and we show\nthat if the network's users employ a distributed learning scheme based on these\ndynamics, then they converge to equilibrium exponentially quickly. On the other\nhand, a major challenge occurs if the channels do not remain static but\nfluctuate stochastically over time, following a stationary ergodic process. In\nthat case, the associated ergodic game still admits a unique equilibrium, but\nthe learning analysis becomes much more complicated because the replicator\ndynamics are no longer deterministic. Nonetheless, by employing results from\nthe theory of stochastic approximation, we show that users still converge to\nthe game's unique equilibrium.\n  Our analysis hinges on a game-theoretical result which is of independent\ninterest: in finite player games which admit a (possibly nonlinear) convex\npotential function, the replicator dynamics (suitably modified to account for\nnonlinear payoffs) converge to an eps-neighborhood of an equilibrium at time of\norder O(log(1/eps)).\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2011 00:40:42 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2011 13:34:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mertikopoulos", "Panayotis", ""], ["Belmega", "Elena V.", ""], ["Moustakas", "Aris L.", ""], ["Lasaulce", "Samson", ""]]}, {"id": "1103.3735", "submitter": "Lihong Li", "authors": "Taesup Moon and Wei Chu and Lihong Li and Zhaohui Zheng and Yi Chang", "title": "Refining Recency Search Results with User Click Feedback", "comments": "22 pages, 9 figures, 1 table. A preliminary and shorter version\n  presented at CIKM-2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine-learned ranking systems for web search are often trained\nto capture stationary relevance of documents to queries, which has limited\nability to track non-stationary user intention in a timely manner. In recency\nsearch, for instance, the relevance of documents to a query on breaking news\noften changes significantly over time, requiring effective adaptation to user\nintention. In this paper, we focus on recency search and study a number of\nalgorithms to improve ranking results by leveraging user click feedback. Our\ncontributions are three-fold. First, we use real search sessions collected in a\nrandom exploration bucket for \\emph{reliable} offline evaluation of these\nalgorithms, which provides an unbiased comparison across algorithms without\nonline bucket tests. Second, we propose a re-ranking approach to improve search\nresults for recency queries using user clicks. Third, our empirical comparison\nof a dozen algorithms on real-life search data suggests importance of a few\nalgorithmic choices in these applications, including generalization across\ndifferent query-document pairs, specialization to popular queries, and\nreal-time adaptation of user clicks.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 00:08:45 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Moon", "Taesup", ""], ["Chu", "Wei", ""], ["Li", "Lihong", ""], ["Zheng", "Zhaohui", ""], ["Chang", "Yi", ""]]}, {"id": "1103.3787", "submitter": "Jun-ichi Inoue", "authors": "Jun-ichi Inoue", "title": "Pattern-recalling processes in quantum Hopfield networks far from\n  saturation", "comments": "10 pages, 3 figures, using jpconf.cls, Proc. of Statphys-Kolkata VII", "journal-ref": null, "doi": "10.1088/1742-6596/297/1/012012", "report-no": null, "categories": "cond-mat.dis-nn cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  As a mathematical model of associative memories, the Hopfield model was now\nwell-established and a lot of studies to reveal the pattern-recalling process\nhave been done from various different approaches. As well-known, a single\nneuron is itself an uncertain, noisy unit with a finite unnegligible error in\nthe input-output relation. To model the situation artificially, a kind of 'heat\nbath' that surrounds neurons is introduced. The heat bath, which is a source of\nnoise, is specified by the 'temperature'. Several studies concerning the\npattern-recalling processes of the Hopfield model governed by the\nGlauber-dynamics at finite temperature were already reported. However, we might\nextend the 'thermal noise' to the quantum-mechanical variant. In this paper, in\nterms of the stochastic process of quantum-mechanical Markov chain Monte Carlo\nmethod (the quantum MCMC), we analytically derive macroscopically deterministic\nequations of order parameters such as 'overlap' in a quantum-mechanical variant\nof the Hopfield neural networks (let us call \"quantum Hopfield model\" or\n\"quantum Hopfield networks\"). For the case in which non-extensive number $p$ of\npatterns are embedded via asymmetric Hebbian connections, namely, $p/N \\to 0$\nfor the number of neuron $N \\to \\infty$ ('far from saturation'), we evaluate\nthe recalling processes for one of the built-in patterns under the influence of\nquantum-mechanical noise.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 14:57:03 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Inoue", "Jun-ichi", ""]]}, {"id": "1103.4090", "submitter": "Luis Rocha", "authors": "An\\'alia Louren\\c{c}o, Michael Conover, Andrew Wong, Azadeh\n  Nematzadeh, Fengxia Pan, Hagit Shatkay, Luis M. Rocha", "title": "A Linear Classifier Based on Entity Recognition Tools and a Statistical\n  Approach to Method Extraction in the Protein-Protein Interaction Literature", "comments": "BMC Bioinformatics. In Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated, in the Article Classification and the Interaction Method\nsubtasks (ACT and IMT, respectively) of the Protein-Protein Interaction task of\nthe BioCreative III Challenge. For the ACT, we pursued an extensive testing of\navailable Named Entity Recognition and dictionary tools, and used the most\npromising ones to extend our Variable Trigonometric Threshold linear\nclassifier. For the IMT, we experimented with a primarily statistical approach,\nas opposed to employing a deeper natural language processing strategy. Finally,\nwe also studied the benefits of integrating the method extraction approach that\nwe have used for the IMT into the ACT pipeline. For the ACT, our linear article\nclassifier leads to a ranking and classification performance significantly\nhigher than all the reported submissions. For the IMT, our results are\ncomparable to those of other systems, which took very different approaches. For\nthe ACT, we show that the use of named entity recognition tools leads to a\nsubstantial improvement in the ranking and classification of articles relevant\nto protein-protein interaction. Thus, we show that our substantially expanded\nlinear classifier is a very competitive classifier in this domain. Moreover,\nthis classifier produces interpretable surfaces that can be understood as\n\"rules\" for human understanding of the classification. In terms of the IMT\ntask, in contrast to other participants, our approach focused on identifying\nsentences that are likely to bear evidence for the application of a PPI\ndetection method, rather than on classifying a document as relevant to a\nmethod. As BioCreative III did not perform an evaluation of the evidence\nprovided by the system, we have conducted a separate assessment; the evaluators\nagree that our tool is indeed effective in detecting relevant evidence for PPI\ndetection methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 17:33:32 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2011 17:46:37 GMT"}], "update_date": "2011-04-25", "authors_parsed": [["Louren\u00e7o", "An\u00e1lia", ""], ["Conover", "Michael", ""], ["Wong", "Andrew", ""], ["Nematzadeh", "Azadeh", ""], ["Pan", "Fengxia", ""], ["Shatkay", "Hagit", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1103.4204", "submitter": "Nikos Karampatziakis", "authors": "Daniel Hsu, Nikos Karampatziakis, John Langford, Alex Smola", "title": "Parallel Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study parallelization of online learning, a core primitive in\nmachine learning. In a parallel environment all known approaches for parallel\nonline learning lead to delayed updates, where the model is updated using\nout-of-date information. In the worst case, or when examples are temporally\ncorrelated, delay can have a very adverse effect on the learning algorithm.\nHere, we analyze and present preliminary empirical results on a set of learning\narchitectures based on a feature sharding approach that present various\ntradeoffs between delay, degree of parallelism, representation power and\nempirical performance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2011 04:54:35 GMT"}], "update_date": "2011-03-23", "authors_parsed": [["Hsu", "Daniel", ""], ["Karampatziakis", "Nikos", ""], ["Langford", "John", ""], ["Smola", "Alex", ""]]}, {"id": "1103.4480", "submitter": "Kishor Barman", "authors": "Kishor Barman, Onkar Dabeer", "title": "Clustered regression with unknown clusters", "comments": "9 pages, Submitted to KDD 2011, San Diego", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a collection of prediction experiments, which are clustered in\nthe sense that groups of experiments ex- hibit similar relationship between the\npredictor and response variables. The experiment clusters as well as the\nregres- sion relationships are unknown. The regression relation- ships define\nthe experiment clusters, and in general, the predictor and response variables\nmay not exhibit any clus- tering. We call this prediction problem clustered\nregres- sion with unknown clusters (CRUC) and in this paper we focus on linear\nregression. We study and compare several methods for CRUC, demonstrate their\napplicability to the Yahoo Learning-to-rank Challenge (YLRC) dataset, and in-\nvestigate an associated mathematical model. CRUC is at the crossroads of many\nprior works and we study several prediction algorithms with diverse origins: an\nadaptation of the expectation-maximization algorithm, an approach in- spired by\nK-means clustering, the singular value threshold- ing approach to matrix rank\nminimization under quadratic constraints, an adaptation of the Curds and Whey\nmethod in multiple regression, and a local regression (LoR) scheme reminiscent\nof neighborhood methods in collaborative filter- ing. Based on empirical\nevaluation on the YLRC dataset as well as simulated data, we identify the LoR\nmethod as a good practical choice: it yields best or near-best prediction\nperformance at a reasonable computational load, and it is less sensitive to the\nchoice of the algorithm parameter. We also provide some analysis of the LoR\nmethod for an asso- ciated mathematical model, which sheds light on optimal\nparameter choice and prediction performance.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 10:20:14 GMT"}], "update_date": "2011-03-24", "authors_parsed": [["Barman", "Kishor", ""], ["Dabeer", "Onkar", ""]]}, {"id": "1103.4487", "submitter": "Dan Ciresan", "authors": "Dan C. Cire\\c{s}an, Ueli Meier, Luca M. Gambardella and J\\\"urgen\n  Schmidhuber", "title": "Handwritten Digit Recognition with a Committee of Deep Neural Nets on\n  GPUs", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "IDSIA-03-11", "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 10:38:50 GMT"}], "update_date": "2011-03-24", "authors_parsed": [["Cire\u015fan", "Dan C.", ""], ["Meier", "Ueli", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1103.4601", "submitter": "Lihong Li", "authors": "Miroslav Dudik and John Langford and Lihong Li", "title": "Doubly Robust Policy Evaluation and Learning", "comments": "Published at ICML 2011, 8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study decision making in environments where the reward is only partially\nobserved, but can be modeled as a function of an action and an observed\ncontext. This setting, known as contextual bandits, encompasses a wide variety\nof applications including health-care policy and Internet advertising. A\ncentral task is evaluation of a new policy given historic data consisting of\ncontexts, actions and received rewards. The key challenge is that the past data\ntypically does not faithfully represent proportions of actions taken by a new\npolicy. Previous approaches rely either on models of rewards or models of the\npast policy. The former are plagued by a large bias whereas the latter have a\nlarge variance.\n  In this work, we leverage the strength and overcome the weaknesses of the two\napproaches by applying the doubly robust technique to the problems of policy\nevaluation and optimization. We prove that this approach yields accurate value\nestimates when we have either a good (but not necessarily consistent) model of\nrewards or a good (but not necessarily consistent) model of past policy.\nExtensive empirical comparison demonstrates that the doubly robust approach\nuniformly improves over existing techniques, achieving both lower variance in\nvalue estimation and better policies. As such, we expect the doubly robust\napproach to become common practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 19:37:45 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 02:38:18 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Dudik", "Miroslav", ""], ["Langford", "John", ""], ["Li", "Lihong", ""]]}, {"id": "1103.4896", "submitter": "Hugo Larochelle", "authors": "J\\'er\\^ome Louradour and Hugo Larochelle", "title": "Classification of Sets using Restricted Boltzmann Machines", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of classification when inputs correspond to sets of\nvectors. This setting occurs in many problems such as the classification of\npieces of mail containing several pages, of web sites with several sections or\nof images that have been pre-segmented into smaller regions. We propose\ngeneralizations of the restricted Boltzmann machine (RBM) that are appropriate\nin this context and explore how to incorporate different assumptions about the\nrelationship between the input sets and the target class within the RBM. In\nexperiments on standard multiple-instance learning datasets, we demonstrate the\ncompetitiveness of approaches based on RBMs and apply the proposed variants to\nthe problem of incoming mail classification.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 02:33:27 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Louradour", "J\u00e9r\u00f4me", ""], ["Larochelle", "Hugo", ""]]}, {"id": "1103.4904", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman", "title": "Distribution-Independent Evolvability of Linear Threshold Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valiant's (2007) model of evolvability models the evolutionary process of\nacquiring useful functionality as a restricted form of learning from random\nexamples. Linear threshold functions and their various subclasses, such as\nconjunctions and decision lists, play a fundamental role in learning theory and\nhence their evolvability has been the primary focus of research on Valiant's\nframework (2007). One of the main open problems regarding the model is whether\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\n2008). We show that the answer is negative. Our proof is based on a new\ncombinatorial parameter of a concept class that lower-bounds the complexity of\nlearning from correlations.\n  We contrast the lower bound with a proof that linear threshold functions\nhaving a non-negligible margin on the data points are evolvable\ndistribution-independently via a simple mutation algorithm. Our algorithm\nrelies on a non-linear loss function being used to select the hypotheses\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\nevolvability requires that the loss function satisfies several mild conditions\nthat are, for example, satisfied by the quadratic loss function studied in\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\nproperty of our evolution algorithm is monotonicity, that is the algorithm\nguarantees evolvability without any decreases in performance. Previously,\nmonotone evolvability was only shown for conjunctions with quadratic loss\n(Feldman, 2009) or when the distribution on the domain is severely restricted\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 04:34:42 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Feldman", "Vitaly", ""]]}, {"id": "1103.5985", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vit\\'anyi (CWI and University of Amsterdam)", "title": "On Empirical Entropy", "comments": "14 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a compression-based version of the empirical entropy of a finite\nstring over a finite alphabet. Whereas previously one considers the naked\nentropy of (possibly higher order) Markov processes, we consider the sum of the\ndescription of the random variable involved plus the entropy it induces. We\nassume only that the distribution involved is computable. To test the new\nnotion we compare the Normalized Information Distance (the similarity metric)\nwith a related measure based on Mutual Information in Shannon's framework. This\nway the similarities and differences of the last two concepts are exposed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Mar 2011 16:30:27 GMT"}], "update_date": "2011-04-05", "authors_parsed": [["Vit\u00e1nyi", "Paul M. B.", "", "CWI and University of Amsterdam"]]}]